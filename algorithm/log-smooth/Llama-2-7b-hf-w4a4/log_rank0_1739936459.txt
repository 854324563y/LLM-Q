[2025-02-19 03:40:59 root] (main_smooth.py 560): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-smooth/Llama-2-7b-hf-w4a4', save_dir='./log-smooth/quant/Llama-2-7b-hf-w4a4', resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=10, let=True, lwc=False, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, scale_calibration=True, compensation_calibration=False)
[2025-02-19 03:41:08 root] (main_smooth.py 627): INFO === start quantization ===
[2025-02-19 03:45:57 root] (main_smooth.py 658): INFO 288.8554861545563
[2025-02-19 03:46:27 root] (main_smooth.py 117): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-19 03:47:25 root] (main_smooth.py 161): INFO wikitext2 : nan
[2025-02-19 03:47:25 root] (main_smooth.py 117): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-19 03:48:54 root] (main_smooth.py 161): INFO c4 : nan
[2025-02-19 03:49:39 datasets.load] (load.py 1272): WARNING Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/winogrande/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2 (last modified on Tue Feb 18 03:11:31 2025) since it couldn't be found locally at winogrande., or remotely on the Hugging Face Hub.
[2025-02-19 04:58:34 root] (main_smooth.py 172): INFO {'wikitext2': nan, 'c4': nan, 'results': {'boolq': {'acc': 0.5660550458715596, 'acc_stderr': 0.008668405003744125}, 'hellaswag': {'acc': 0.2605058753236407, 'acc_stderr': 0.004380136468543944, 'acc_norm': 0.26010754829715194, 'acc_norm_stderr': 0.004377965074211625}, 'arc_challenge': {'acc': 0.23122866894197952, 'acc_stderr': 0.012320858834772273, 'acc_norm': 0.28242320819112626, 'acc_norm_stderr': 0.013155456884097222}, 'arc_easy': {'acc': 0.2474747474747475, 'acc_stderr': 0.008855114414834714, 'acc_norm': 0.25126262626262624, 'acc_norm_stderr': 0.008900141191221653}, 'winogrande': {'acc': 0.49171270718232046, 'acc_stderr': 0.014050555322824194}, 'piqa': {'acc': 0.5282916213275299, 'acc_stderr': 0.01164713417274932, 'acc_norm': 0.5212187159956474, 'acc_norm_stderr': 0.011655314732288858}}, 'versions': {'boolq': 1, 'hellaswag': 0, 'arc_challenge': 0, 'arc_easy': 0, 'winogrande': 0, 'piqa': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
