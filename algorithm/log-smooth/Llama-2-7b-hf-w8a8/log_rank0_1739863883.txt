[2025-02-18 07:31:23 root] (main_smooth.py 548): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-smooth/Llama-2-7b-hf-w8a8', save_dir='./log-smooth/quant/Llama-2-7b-hf-w8a8', resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=8, abits=8, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=10, let=True, lwc=False, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, scale_calibration=True, compensation_calibration=False)
[2025-02-18 07:35:46 root] (main_smooth.py 615): INFO === start quantization ===
[2025-02-18 07:40:19 root] (main_smooth.py 640): INFO 272.7904899120331
[2025-02-18 07:40:50 root] (main_smooth.py 117): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-18 07:41:43 root] (main_smooth.py 161): INFO wikitext2 : 5.588176250457764
[2025-02-18 07:41:43 root] (main_smooth.py 117): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-18 07:43:03 root] (main_smooth.py 161): INFO c4 : 7.107710361480713
[2025-02-18 07:43:13 datasets.load] (load.py 1272): WARNING Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hellaswag/512a66dd8b1b1643ab4a48aa4f150d04c91680da6a4096498a5e5f799623d5ae (last modified on Tue Feb 18 03:27:10 2025) since it couldn't be found locally at hellaswag., or remotely on the Hugging Face Hub.
