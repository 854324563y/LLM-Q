[2025-02-06 06:36:31 root] (main_quant_config.py 114): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log/0205-mpq', blocks_pkl='log/0205-divide/llama-7b-hf/llama-7b-hf_blocks.pkl', calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, reload=True, parallel=False, size_bound_factor=0.7, weight_quant_params={'per_channel_axes': [0], 'symmetric': False, 'dynamic_method': 'per_channel', 'group_size': None, 'lwc': False, 'disable_zero_point': False}, act_quant_params={'per_channel_axes': [], 'symmetric': False, 'dynamic_method': 'per_token'})
[2025-02-06 06:36:40 root] (main_quant_config.py 132): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-02-06 06:36:40 root] (main_quant_config.py 143): INFO [(0, 1), (1, 2), (2, 3), (3, 6), (6, 9), (9, 11), (11, 14), (14, 16), (16, 19), (19, 21), (21, 23), (23, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 30), (30, 31), (31, 32)]
