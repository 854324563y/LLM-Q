[2025-01-16 14:34:49 root] (main_calib_config.py 270): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-chat-hf', cache_dir='./cache', output_dir='./log/Llama-2-7b-chat-hf-w4a4-117', save_dir='./quant/Llama-2-7b-chat-hf-w4a4-117/save_dir', resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='./log/Llama-2-7b-chat-hf-116/quant_map_Llama-2-7b-chat-hf.pkl')
[2025-01-16 14:34:51 root] (main_calib_config.py 336): INFO === start quantization ===
[2025-01-16 14:34:51 root] (main_calib_config.py 342): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-01-16 14:34:51 root] (abq_llm_calib_config.py 82): INFO Starting ...
[2025-01-16 14:34:51 root] (abq_llm_calib_config.py 89): INFO Loaded quant_map from ./log/Llama-2-7b-chat-hf-116/quant_map_Llama-2-7b-chat-hf.pkl
[2025-01-16 14:34:55 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 0 ===
[2025-01-16 14:35:00 root] (abq_llm_calib_config.py 301): INFO use compensation vector
[2025-01-16 14:35:31 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 0 loss:0.014087580144405365 norm:0.012363630346953869 max memory_allocated 22886.16943359375 
[2025-01-16 14:36:02 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 1 loss:0.00836889911442995 norm:0.007101049181073904 max memory_allocated 22886.16943359375 
[2025-01-16 14:36:33 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 2 loss:0.006358313839882612 norm:0.0054352800361812115 max memory_allocated 22886.16943359375 
[2025-01-16 14:37:05 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 3 loss:0.005578682757914066 norm:0.00445870216935873 max memory_allocated 22886.16943359375 
[2025-01-16 14:37:36 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 4 loss:0.00525158504024148 norm:0.003835680428892374 max memory_allocated 22886.16943359375 
[2025-01-16 14:38:08 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 5 loss:0.005127922631800175 norm:0.0034007448703050613 max memory_allocated 22886.16943359375 
[2025-01-16 14:38:39 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 6 loss:0.004954040981829166 norm:0.0028795951511710882 max memory_allocated 22886.16943359375 
[2025-01-16 14:39:11 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 7 loss:0.004842613358050585 norm:0.002537224907428026 max memory_allocated 22886.16943359375 
[2025-01-16 14:39:42 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 8 loss:0.004882531706243753 norm:0.002822962822392583 max memory_allocated 22886.16943359375 
[2025-01-16 14:40:13 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 9 loss:0.00477618258446455 norm:0.002442149445414543 max memory_allocated 22886.16943359375 
[2025-01-16 14:40:45 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 10 loss:0.004654861055314541 norm:0.002213725820183754 max memory_allocated 22886.16943359375 
[2025-01-16 14:41:16 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 11 loss:0.004607368726283312 norm:0.0020445669069886208 max memory_allocated 22886.16943359375 
[2025-01-16 14:41:48 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 12 loss:0.0046168724074959755 norm:0.0022699555847793818 max memory_allocated 22886.16943359375 
[2025-01-16 14:42:19 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 13 loss:0.004489967133849859 norm:0.0019097926560789347 max memory_allocated 22886.16943359375 
[2025-01-16 14:42:51 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 14 loss:0.00449633551761508 norm:0.0018381309928372502 max memory_allocated 22886.16943359375 
[2025-01-16 14:43:22 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 15 loss:0.004493441432714462 norm:0.0018847305327653885 max memory_allocated 22886.16943359375 
[2025-01-16 14:43:53 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 16 loss:0.0044496809132397175 norm:0.001854999572969973 max memory_allocated 22886.16943359375 
[2025-01-16 14:44:25 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 17 loss:0.004427595995366573 norm:0.001728207222186029 max memory_allocated 22886.16943359375 
[2025-01-16 14:44:56 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 18 loss:0.0044431802816689014 norm:0.0016630495665594935 max memory_allocated 22886.16943359375 
[2025-01-16 14:45:28 root] (abq_llm_calib_config.py 361): INFO layer 0 iter 19 loss:0.004360618069767952 norm:0.001514299539849162 max memory_allocated 22886.16943359375 
[2025-01-16 14:45:37 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 1 ===
[2025-01-16 14:45:47 root] (abq_llm_calib_config.py 301): INFO use compensation vector
[2025-01-16 14:46:18 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 0 loss:0.037650421261787415 norm:0.021505631506443024 max memory_allocated 22887.84130859375 
[2025-01-16 14:46:50 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 1 loss:0.027634333819150925 norm:0.012427719309926033 max memory_allocated 22887.84130859375 
[2025-01-16 14:47:21 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 2 loss:0.023694848641753197 norm:0.007432121783494949 max memory_allocated 22887.84130859375 
[2025-01-16 14:47:53 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 3 loss:0.022386174649000168 norm:0.00921125989407301 max memory_allocated 22887.84130859375 
[2025-01-16 14:48:24 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 4 loss:0.021755751222372055 norm:0.009897816926240921 max memory_allocated 22887.84130859375 
[2025-01-16 14:48:55 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 5 loss:0.021318741142749786 norm:0.009048470295965672 max memory_allocated 22887.84130859375 
[2025-01-16 14:49:27 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 6 loss:0.02099362201988697 norm:0.00887385755777359 max memory_allocated 22887.84130859375 
[2025-01-16 14:49:58 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 7 loss:0.02074185013771057 norm:0.008280400186777115 max memory_allocated 22887.84130859375 
[2025-01-16 14:50:30 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 8 loss:0.020104391500353813 norm:0.008395366370677948 max memory_allocated 22887.84130859375 
[2025-01-16 14:51:01 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 9 loss:0.019933149218559265 norm:0.008047010749578476 max memory_allocated 22887.84130859375 
[2025-01-16 14:51:33 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 10 loss:0.019859079271554947 norm:0.009977597743272781 max memory_allocated 22887.84130859375 
[2025-01-16 14:52:04 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 11 loss:0.019899245351552963 norm:0.007966197095811367 max memory_allocated 22887.84130859375 
[2025-01-16 14:52:36 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 12 loss:0.01973056048154831 norm:0.00766683230176568 max memory_allocated 22887.84130859375 
[2025-01-16 14:53:07 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 13 loss:0.02000483311712742 norm:0.00791772361844778 max memory_allocated 22887.84130859375 
[2025-01-16 14:53:39 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 14 loss:0.020012492313981056 norm:0.007926903665065765 max memory_allocated 22887.84130859375 
[2025-01-16 14:54:10 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 15 loss:0.020254356786608696 norm:0.00880161952227354 max memory_allocated 22887.84130859375 
[2025-01-16 14:54:42 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 16 loss:0.019840769469738007 norm:0.008000805042684078 max memory_allocated 22887.84130859375 
[2025-01-16 14:55:13 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 17 loss:0.019641034305095673 norm:0.007575525902211666 max memory_allocated 22887.84130859375 
[2025-01-16 14:55:45 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 18 loss:0.01975410059094429 norm:0.007491359952837229 max memory_allocated 22887.84130859375 
[2025-01-16 14:56:16 root] (abq_llm_calib_config.py 361): INFO layer 1 iter 19 loss:0.01930377446115017 norm:0.007024256978183985 max memory_allocated 22887.84130859375 
[2025-01-16 14:56:25 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 2 ===
[2025-01-16 14:56:39 root] (abq_llm_calib_config.py 301): INFO use compensation vector
[2025-01-16 14:57:10 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 0 loss:0.0463651567697525 norm:0.009435256943106651 max memory_allocated 22889.51318359375 
[2025-01-16 14:57:42 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 1 loss:0.03801124915480614 norm:0.007219961378723383 max memory_allocated 22889.51318359375 
[2025-01-16 14:58:13 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 2 loss:0.03417119383811951 norm:0.005238017998635769 max memory_allocated 22889.51318359375 
[2025-01-16 14:58:45 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 3 loss:0.032664261758327484 norm:0.00417002197355032 max memory_allocated 22889.51318359375 
[2025-01-16 14:59:16 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 4 loss:0.03176870197057724 norm:0.0034569851122796535 max memory_allocated 22889.51318359375 
[2025-01-16 14:59:48 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 5 loss:0.031193014234304428 norm:0.0029013666789978743 max memory_allocated 22889.51318359375 
[2025-01-16 15:00:19 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 6 loss:0.030869878828525543 norm:0.002503721509128809 max memory_allocated 22889.51318359375 
[2025-01-16 15:00:51 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 7 loss:0.030690252780914307 norm:0.00221304502338171 max memory_allocated 22889.51318359375 
[2025-01-16 15:01:22 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 8 loss:0.030633224174380302 norm:0.002173870801925659 max memory_allocated 22889.51318359375 
[2025-01-16 15:01:54 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 9 loss:0.030529165640473366 norm:0.0020707682706415653 max memory_allocated 22889.51318359375 
[2025-01-16 15:02:25 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 10 loss:0.03050597943365574 norm:0.002012469805777073 max memory_allocated 22889.51318359375 
[2025-01-16 15:02:57 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 11 loss:0.03043709509074688 norm:0.00189363700337708 max memory_allocated 22889.51318359375 
[2025-01-16 15:03:28 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 12 loss:0.030414152890443802 norm:0.0018909648060798645 max memory_allocated 22889.51318359375 
[2025-01-16 15:04:00 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 13 loss:0.030441997572779655 norm:0.0018975483253598213 max memory_allocated 22889.51318359375 
[2025-01-16 15:04:31 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 14 loss:0.03042600117623806 norm:0.0018836291274055839 max memory_allocated 22889.51318359375 
[2025-01-16 15:05:03 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 15 loss:0.03043326735496521 norm:0.0018939534202218056 max memory_allocated 22889.51318359375 
[2025-01-16 15:05:34 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 16 loss:0.030442191287875175 norm:0.0018224093364551663 max memory_allocated 22889.51318359375 
[2025-01-16 15:06:06 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 17 loss:0.030383910983800888 norm:0.001764966524206102 max memory_allocated 22889.51318359375 
[2025-01-16 15:06:37 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 18 loss:0.03038780204951763 norm:0.0017289542593061924 max memory_allocated 22889.51318359375 
[2025-01-16 15:07:09 root] (abq_llm_calib_config.py 361): INFO layer 2 iter 19 loss:0.03039328008890152 norm:0.0017597464611753821 max memory_allocated 22889.51318359375 
[2025-01-16 15:07:18 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 3 ===
[2025-01-16 15:07:59 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 0 loss:0.058297235518693924 norm:0.002874641213566065 max memory_allocated 22891.06982421875 
[2025-01-16 15:08:30 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 1 loss:0.048807792365550995 norm:0.0018293728353455663 max memory_allocated 22891.06982421875 
[2025-01-16 15:09:01 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 2 loss:0.04412943124771118 norm:0.0025588595308363438 max memory_allocated 22891.06982421875 
[2025-01-16 15:09:33 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 3 loss:0.04239928349852562 norm:0.0015582374762743711 max memory_allocated 22891.06982421875 
[2025-01-16 15:10:04 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 4 loss:0.04147251695394516 norm:0.0015771653270348907 max memory_allocated 22891.06982421875 
[2025-01-16 15:10:35 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 5 loss:0.04114343971014023 norm:0.0014810741413384676 max memory_allocated 22891.06982421875 
[2025-01-16 15:11:07 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 6 loss:0.04102284088730812 norm:0.001471789670176804 max memory_allocated 22891.06982421875 
[2025-01-16 15:11:38 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 7 loss:0.040972571820020676 norm:0.0014591352082788944 max memory_allocated 22891.06982421875 
[2025-01-16 15:12:10 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 8 loss:0.040922101587057114 norm:0.0015087721403688192 max memory_allocated 22891.06982421875 
[2025-01-16 15:12:41 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 9 loss:0.04086076840758324 norm:0.0014656331622973084 max memory_allocated 22891.06982421875 
[2025-01-16 15:13:12 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 10 loss:0.04084007814526558 norm:0.001485274638980627 max memory_allocated 22891.06982421875 
[2025-01-16 15:13:44 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 11 loss:0.040798161178827286 norm:0.0014206881169229746 max memory_allocated 22891.06982421875 
[2025-01-16 15:14:15 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 12 loss:0.04076230525970459 norm:0.001452652388252318 max memory_allocated 22891.06982421875 
[2025-01-16 15:14:47 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 13 loss:0.04075673595070839 norm:0.0014482417609542608 max memory_allocated 22891.06982421875 
[2025-01-16 15:15:18 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 14 loss:0.04073438420891762 norm:0.0014022598043084145 max memory_allocated 22891.06982421875 
[2025-01-16 15:15:49 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 15 loss:0.04070711135864258 norm:0.0014355635503306985 max memory_allocated 22891.06982421875 
[2025-01-16 15:16:21 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 16 loss:0.040701061487197876 norm:0.0014307989040389657 max memory_allocated 22891.06982421875 
[2025-01-16 15:16:52 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 17 loss:0.04067611321806908 norm:0.0014127697795629501 max memory_allocated 22891.06982421875 
[2025-01-16 15:17:24 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 18 loss:0.04068417847156525 norm:0.0013974313624203205 max memory_allocated 22891.06982421875 
[2025-01-16 15:17:55 root] (abq_llm_calib_config.py 361): INFO layer 3 iter 19 loss:0.04068281501531601 norm:0.001439481507986784 max memory_allocated 22891.06982421875 
[2025-01-16 15:18:04 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 4 ===
[2025-01-16 15:18:46 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 0 loss:0.07659043371677399 norm:0.0029561459086835384 max memory_allocated 22892.74169921875 
[2025-01-16 15:19:17 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 1 loss:0.06313370168209076 norm:0.001848822459578514 max memory_allocated 22892.74169921875 
[2025-01-16 15:19:49 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 2 loss:0.05569068714976311 norm:0.0016417840961366892 max memory_allocated 22892.74169921875 
[2025-01-16 15:20:20 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 3 loss:0.05326954275369644 norm:0.0015149173559620976 max memory_allocated 22892.74169921875 
[2025-01-16 15:20:51 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 4 loss:0.05214838311076164 norm:0.0014182333834469318 max memory_allocated 22892.74169921875 
[2025-01-16 15:21:23 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 5 loss:0.051639705896377563 norm:0.0013908473774790764 max memory_allocated 22892.74169921875 
[2025-01-16 15:21:54 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 6 loss:0.05138847604393959 norm:0.0013590336311608553 max memory_allocated 22892.74169921875 
[2025-01-16 15:22:26 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 7 loss:0.05117259919643402 norm:0.0013711838982999325 max memory_allocated 22892.74169921875 
[2025-01-16 15:22:57 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 8 loss:0.05104442313313484 norm:0.0013337288983166218 max memory_allocated 22892.74169921875 
[2025-01-16 15:23:28 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 9 loss:0.05094058811664581 norm:0.0013393438421189785 max memory_allocated 22892.74169921875 
[2025-01-16 15:24:00 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 10 loss:0.05089171230792999 norm:0.0013442267663776875 max memory_allocated 22892.74169921875 
[2025-01-16 15:24:31 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 11 loss:0.05088336393237114 norm:0.0013702173018828034 max memory_allocated 22892.74169921875 
[2025-01-16 15:25:03 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 12 loss:0.0507892370223999 norm:0.001310593681409955 max memory_allocated 22892.74169921875 
[2025-01-16 15:25:34 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 13 loss:0.05073746666312218 norm:0.0013161326060071588 max memory_allocated 22892.74169921875 
[2025-01-16 15:26:05 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 14 loss:0.050702959299087524 norm:0.0012916818959638476 max memory_allocated 22892.74169921875 
[2025-01-16 15:26:37 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 15 loss:0.05067376792430878 norm:0.0013321696314960718 max memory_allocated 22892.74169921875 
[2025-01-16 15:27:08 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 16 loss:0.050647031515836716 norm:0.001336251269094646 max memory_allocated 22892.74169921875 
[2025-01-16 15:27:39 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 17 loss:0.05062730610370636 norm:0.0013555287150666118 max memory_allocated 22892.74169921875 
[2025-01-16 15:28:11 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 18 loss:0.050612498074769974 norm:0.0013336880365386605 max memory_allocated 22892.74169921875 
[2025-01-16 15:28:42 root] (abq_llm_calib_config.py 361): INFO layer 4 iter 19 loss:0.05059610307216644 norm:0.0012856193352490664 max memory_allocated 22892.74169921875 
[2025-01-16 15:28:51 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 5 ===
[2025-01-16 15:29:30 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 0 loss:0.08439619839191437 norm:0.003635973669588566 max memory_allocated 22894.41357421875 
[2025-01-16 15:30:02 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 1 loss:0.07211422175168991 norm:0.0025203546974807978 max memory_allocated 22894.41357421875 
[2025-01-16 15:30:33 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 2 loss:0.06426605582237244 norm:0.002239024266600609 max memory_allocated 22894.41357421875 
[2025-01-16 15:31:05 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 3 loss:0.061289723962545395 norm:0.0019755109678953886 max memory_allocated 22894.41357421875 
[2025-01-16 15:31:36 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 4 loss:0.0600862093269825 norm:0.001983499154448509 max memory_allocated 22894.41357421875 
[2025-01-16 15:32:07 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 5 loss:0.05960170179605484 norm:0.0018836541566997766 max memory_allocated 22894.41357421875 
[2025-01-16 15:32:39 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 6 loss:0.059306588023900986 norm:0.0018127762014046311 max memory_allocated 22894.41357421875 
[2025-01-16 15:33:10 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 7 loss:0.05919376015663147 norm:0.0018794970819726586 max memory_allocated 22894.41357421875 
[2025-01-16 15:33:42 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 8 loss:0.059102531522512436 norm:0.0017927333246916533 max memory_allocated 22894.41357421875 
[2025-01-16 15:34:13 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 9 loss:0.059049077332019806 norm:0.001853656372986734 max memory_allocated 22894.41357421875 
[2025-01-16 15:34:44 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 10 loss:0.05899284780025482 norm:0.0019088550470769405 max memory_allocated 22894.41357421875 
[2025-01-16 15:35:16 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 11 loss:0.05894043669104576 norm:0.0018322108080610633 max memory_allocated 22894.41357421875 
[2025-01-16 15:35:47 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 12 loss:0.05886576324701309 norm:0.0017593818483874202 max memory_allocated 22894.41357421875 
[2025-01-16 15:36:18 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 13 loss:0.05887634679675102 norm:0.0018105210037901998 max memory_allocated 22894.41357421875 
[2025-01-16 15:36:50 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 14 loss:0.05892099067568779 norm:0.0017502227565273643 max memory_allocated 22894.41357421875 
[2025-01-16 15:37:21 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 15 loss:0.05886971205472946 norm:0.0017701206961646676 max memory_allocated 22894.41357421875 
[2025-01-16 15:37:53 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 16 loss:0.0588323250412941 norm:0.0017166532343253493 max memory_allocated 22894.41357421875 
[2025-01-16 15:38:24 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 17 loss:0.05882841348648071 norm:0.0017901520477607846 max memory_allocated 22894.41357421875 
[2025-01-16 15:38:55 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 18 loss:0.05882320553064346 norm:0.0017871928866952658 max memory_allocated 22894.41357421875 
[2025-01-16 15:39:27 root] (abq_llm_calib_config.py 361): INFO layer 5 iter 19 loss:0.05877482146024704 norm:0.001661828369833529 max memory_allocated 22894.41357421875 
[2025-01-16 15:39:36 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 6 ===
[2025-01-16 15:40:15 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 0 loss:0.09059028327465057 norm:0.0030309422872960567 max memory_allocated 22896.08544921875 
[2025-01-16 15:40:47 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 1 loss:0.07899845391511917 norm:0.0022156918421387672 max memory_allocated 22896.08544921875 
[2025-01-16 15:41:18 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 2 loss:0.07182355225086212 norm:0.0020591886714100838 max memory_allocated 22896.08544921875 
[2025-01-16 15:41:49 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 3 loss:0.06944473087787628 norm:0.0018801908008754253 max memory_allocated 22896.08544921875 
[2025-01-16 15:42:21 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 4 loss:0.06845331937074661 norm:0.0018698991043493152 max memory_allocated 22896.08544921875 
[2025-01-16 15:42:52 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 5 loss:0.06802623718976974 norm:0.001861525815911591 max memory_allocated 22896.08544921875 
[2025-01-16 15:43:24 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 6 loss:0.06782882660627365 norm:0.0017907650908455253 max memory_allocated 22896.08544921875 
[2025-01-16 15:43:55 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 7 loss:0.06770142912864685 norm:0.0018049449427053332 max memory_allocated 22896.08544921875 
[2025-01-16 15:44:26 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 8 loss:0.06758090108633041 norm:0.0018565121572464705 max memory_allocated 22896.08544921875 
[2025-01-16 15:44:58 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 9 loss:0.06748638302087784 norm:0.0018581768963485956 max memory_allocated 22896.08544921875 
[2025-01-16 15:45:29 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 10 loss:0.06745529174804688 norm:0.0018042848678305745 max memory_allocated 22896.08544921875 
[2025-01-16 15:46:01 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 11 loss:0.06738889217376709 norm:0.0018634351436048746 max memory_allocated 22896.08544921875 
[2025-01-16 15:46:32 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 12 loss:0.06734799593687057 norm:0.001793552073650062 max memory_allocated 22896.08544921875 
[2025-01-16 15:47:03 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 13 loss:0.06731574982404709 norm:0.0018423473229631782 max memory_allocated 22896.08544921875 
[2025-01-16 15:47:35 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 14 loss:0.0672765001654625 norm:0.0018508128123357892 max memory_allocated 22896.08544921875 
[2025-01-16 15:48:06 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 15 loss:0.06725107878446579 norm:0.0018170960247516632 max memory_allocated 22896.08544921875 
[2025-01-16 15:48:38 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 16 loss:0.06724388897418976 norm:0.0018073883838951588 max memory_allocated 22896.08544921875 
[2025-01-16 15:49:09 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 17 loss:0.06723526120185852 norm:0.0018406526651233435 max memory_allocated 22896.08544921875 
[2025-01-16 15:49:40 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 18 loss:0.0671985000371933 norm:0.0017951184418052435 max memory_allocated 22896.08544921875 
[2025-01-16 15:50:12 root] (abq_llm_calib_config.py 361): INFO layer 6 iter 19 loss:0.0671551302075386 norm:0.0017427466809749603 max memory_allocated 22896.08544921875 
[2025-01-16 15:50:21 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 7 ===
[2025-01-16 15:50:59 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 0 loss:0.10719547420740128 norm:0.004219410475343466 max memory_allocated 22897.75732421875 
[2025-01-16 15:51:30 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 1 loss:0.09280641376972198 norm:0.0026961383409798145 max memory_allocated 22897.75732421875 
[2025-01-16 15:52:02 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 2 loss:0.08361009508371353 norm:0.002239551395177841 max memory_allocated 22897.75732421875 
[2025-01-16 15:52:33 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 3 loss:0.08006676286458969 norm:0.002012289594858885 max memory_allocated 22897.75732421875 
[2025-01-16 15:53:04 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 4 loss:0.07865948975086212 norm:0.0019731696229428053 max memory_allocated 22897.75732421875 
[2025-01-16 15:53:36 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 5 loss:0.07805752009153366 norm:0.0018418586114421487 max memory_allocated 22897.75732421875 
[2025-01-16 15:54:07 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 6 loss:0.07772044837474823 norm:0.0017739778850227594 max memory_allocated 22897.75732421875 
[2025-01-16 15:54:39 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 7 loss:0.07745033502578735 norm:0.0018032651860266924 max memory_allocated 22897.75732421875 
[2025-01-16 15:55:10 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 8 loss:0.07729179412126541 norm:0.0017783039947971702 max memory_allocated 22897.75732421875 
[2025-01-16 15:55:41 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 9 loss:0.07718643546104431 norm:0.0017355689778923988 max memory_allocated 22897.75732421875 
[2025-01-16 15:56:13 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 10 loss:0.0770508199930191 norm:0.0016270815394818783 max memory_allocated 22897.75732421875 
[2025-01-16 15:56:44 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 11 loss:0.07705220580101013 norm:0.0017602408770471811 max memory_allocated 22897.75732421875 
[2025-01-16 15:57:16 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 12 loss:0.0770106390118599 norm:0.0016761457081884146 max memory_allocated 22897.75732421875 
[2025-01-16 15:57:47 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 13 loss:0.07694633305072784 norm:0.0016983198001980782 max memory_allocated 22897.75732421875 
[2025-01-16 15:58:18 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 14 loss:0.07692615687847137 norm:0.0016492431750521064 max memory_allocated 22897.75732421875 
[2025-01-16 15:58:50 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 15 loss:0.07692082226276398 norm:0.0016605551354587078 max memory_allocated 22897.75732421875 
[2025-01-16 15:59:21 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 16 loss:0.07697133719921112 norm:0.0018550896784290671 max memory_allocated 22897.75732421875 
[2025-01-16 15:59:53 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 17 loss:0.07690902054309845 norm:0.0016634453786537051 max memory_allocated 22897.75732421875 
[2025-01-16 16:00:24 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 18 loss:0.07685685157775879 norm:0.0016874116845428944 max memory_allocated 22897.75732421875 
[2025-01-16 16:00:55 root] (abq_llm_calib_config.py 361): INFO layer 7 iter 19 loss:0.0768117755651474 norm:0.0016531990841031075 max memory_allocated 22897.75732421875 
[2025-01-16 16:01:04 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 8 ===
[2025-01-16 16:01:42 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 0 loss:0.11029098927974701 norm:0.003129031741991639 max memory_allocated 22899.42919921875 
[2025-01-16 16:02:13 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 1 loss:0.0978485569357872 norm:0.0020568931940943003 max memory_allocated 22899.42919921875 
[2025-01-16 16:02:45 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 2 loss:0.0900820940732956 norm:0.0018945324700325727 max memory_allocated 22899.42919921875 
[2025-01-16 16:03:16 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 3 loss:0.08733432739973068 norm:0.0017690769163891673 max memory_allocated 22899.42919921875 
[2025-01-16 16:03:47 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 4 loss:0.08627429604530334 norm:0.0017728067468851805 max memory_allocated 22899.42919921875 
[2025-01-16 16:04:19 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 5 loss:0.08577274531126022 norm:0.001679280656389892 max memory_allocated 22899.42919921875 
[2025-01-16 16:04:50 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 6 loss:0.0854211151599884 norm:0.0016753837699070573 max memory_allocated 22899.42919921875 
[2025-01-16 16:05:22 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 7 loss:0.08523404598236084 norm:0.0016605471028015018 max memory_allocated 22899.42919921875 
[2025-01-16 16:05:53 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 8 loss:0.08510025590658188 norm:0.0016698394902050495 max memory_allocated 22899.42919921875 
[2025-01-16 16:06:24 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 9 loss:0.08497609943151474 norm:0.0015968992374837399 max memory_allocated 22899.42919921875 
[2025-01-16 16:06:56 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 10 loss:0.08488041162490845 norm:0.0015464238822460175 max memory_allocated 22899.42919921875 
[2025-01-16 16:07:27 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 11 loss:0.08481258898973465 norm:0.001571308239363134 max memory_allocated 22899.42919921875 
[2025-01-16 16:07:59 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 12 loss:0.084754079580307 norm:0.0015853557270020247 max memory_allocated 22899.42919921875 
[2025-01-16 16:08:30 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 13 loss:0.08472791314125061 norm:0.0016032197745516896 max memory_allocated 22899.42919921875 
[2025-01-16 16:09:01 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 14 loss:0.08468174934387207 norm:0.0016027027741074562 max memory_allocated 22899.42919921875 
[2025-01-16 16:09:33 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 15 loss:0.08469988405704498 norm:0.001667040167376399 max memory_allocated 22899.42919921875 
[2025-01-16 16:10:04 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 16 loss:0.08464928716421127 norm:0.0016384930349886417 max memory_allocated 22899.42919921875 
[2025-01-16 16:10:36 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 17 loss:0.08463504910469055 norm:0.0016204665880650282 max memory_allocated 22899.42919921875 
[2025-01-16 16:11:07 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 18 loss:0.08464651554822922 norm:0.0015862348955124617 max memory_allocated 22899.42919921875 
[2025-01-16 16:11:38 root] (abq_llm_calib_config.py 361): INFO layer 8 iter 19 loss:0.08463890850543976 norm:0.0016037473687902093 max memory_allocated 22899.42919921875 
[2025-01-16 16:11:47 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 9 ===
[2025-01-16 16:12:25 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 0 loss:0.1129099577665329 norm:0.002404883038252592 max memory_allocated 22901.10107421875 
[2025-01-16 16:12:57 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 1 loss:0.10202454775571823 norm:0.0015788647579029202 max memory_allocated 22901.10107421875 
[2025-01-16 16:13:28 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 2 loss:0.09528198838233948 norm:0.0014101037522777915 max memory_allocated 22901.10107421875 
[2025-01-16 16:13:59 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 3 loss:0.09302465617656708 norm:0.0013226091396063566 max memory_allocated 22901.10107421875 
[2025-01-16 16:14:31 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 4 loss:0.09201355278491974 norm:0.0012820761185139418 max memory_allocated 22901.10107421875 
[2025-01-16 16:15:02 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 5 loss:0.0914958119392395 norm:0.0012261784868314862 max memory_allocated 22901.10107421875 
[2025-01-16 16:15:34 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 6 loss:0.09123007208108902 norm:0.001253129681572318 max memory_allocated 22901.10107421875 
[2025-01-16 16:16:05 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 7 loss:0.09104842692613602 norm:0.001229247311130166 max memory_allocated 22901.10107421875 
[2025-01-16 16:16:36 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 8 loss:0.09090770035982132 norm:0.0012194440932944417 max memory_allocated 22901.10107421875 
[2025-01-16 16:17:08 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 9 loss:0.09079942852258682 norm:0.001218342804349959 max memory_allocated 22901.10107421875 
[2025-01-16 16:17:39 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 10 loss:0.0907025933265686 norm:0.001240954385139048 max memory_allocated 22901.10107421875 
[2025-01-16 16:18:11 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 11 loss:0.0906243696808815 norm:0.00122902262955904 max memory_allocated 22901.10107421875 
[2025-01-16 16:18:42 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 12 loss:0.09056822955608368 norm:0.0012267058482393622 max memory_allocated 22901.10107421875 
[2025-01-16 16:19:13 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 13 loss:0.09051795303821564 norm:0.0011901035904884338 max memory_allocated 22901.10107421875 
[2025-01-16 16:19:45 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 14 loss:0.09048140794038773 norm:0.0011560952989384532 max memory_allocated 22901.10107421875 
[2025-01-16 16:20:16 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 15 loss:0.09046551585197449 norm:0.001176155754365027 max memory_allocated 22901.10107421875 
[2025-01-16 16:20:48 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 16 loss:0.09045456349849701 norm:0.0011700441827997565 max memory_allocated 22901.10107421875 
[2025-01-16 16:21:19 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 17 loss:0.09044156968593597 norm:0.0011841985397040844 max memory_allocated 22901.10107421875 
[2025-01-16 16:21:50 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 18 loss:0.09044823050498962 norm:0.0011844367254525423 max memory_allocated 22901.10107421875 
[2025-01-16 16:22:22 root] (abq_llm_calib_config.py 361): INFO layer 9 iter 19 loss:0.09044337272644043 norm:0.0012357914820313454 max memory_allocated 22901.10107421875 
[2025-01-16 16:22:31 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 10 ===
[2025-01-16 16:23:16 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 0 loss:0.11352092027664185 norm:0.001942233182489872 max memory_allocated 22902.77294921875 
[2025-01-16 16:23:47 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 1 loss:0.1048341616988182 norm:0.0014305179938673973 max memory_allocated 22902.77294921875 
[2025-01-16 16:24:18 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 2 loss:0.09878239780664444 norm:0.0012951991520822048 max memory_allocated 22902.77294921875 
[2025-01-16 16:24:50 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 3 loss:0.09667157381772995 norm:0.00121492356993258 max memory_allocated 22902.77294921875 
[2025-01-16 16:25:21 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 4 loss:0.0956728458404541 norm:0.0012344509596005082 max memory_allocated 22902.77294921875 
[2025-01-16 16:25:53 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 5 loss:0.09515741467475891 norm:0.0011981212301179767 max memory_allocated 22902.77294921875 
[2025-01-16 16:26:24 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 6 loss:0.09483962506055832 norm:0.0011566391913220286 max memory_allocated 22902.77294921875 
[2025-01-16 16:26:55 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 7 loss:0.09464260190725327 norm:0.001123518799431622 max memory_allocated 22902.77294921875 
[2025-01-16 16:27:27 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 8 loss:0.09446632117033005 norm:0.0011003584368154407 max memory_allocated 22902.77294921875 
[2025-01-16 16:27:58 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 9 loss:0.09436263144016266 norm:0.0010866891825571656 max memory_allocated 22902.77294921875 
[2025-01-16 16:28:30 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 10 loss:0.09435990452766418 norm:0.001108198193833232 max memory_allocated 22902.77294921875 
[2025-01-16 16:29:01 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 11 loss:0.09427140653133392 norm:0.001074769301339984 max memory_allocated 22902.77294921875 
[2025-01-16 16:29:33 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 12 loss:0.09421789646148682 norm:0.001098997425287962 max memory_allocated 22902.77294921875 
[2025-01-16 16:30:04 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 13 loss:0.09418554604053497 norm:0.001106027397327125 max memory_allocated 22902.77294921875 
[2025-01-16 16:30:35 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 14 loss:0.09417517483234406 norm:0.001070474972948432 max memory_allocated 22902.77294921875 
[2025-01-16 16:31:07 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 15 loss:0.09411212801933289 norm:0.001070148777216673 max memory_allocated 22902.77294921875 
[2025-01-16 16:31:38 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 16 loss:0.0940939411520958 norm:0.0010591491591185331 max memory_allocated 22902.77294921875 
[2025-01-16 16:32:10 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 17 loss:0.09408170729875565 norm:0.0010732507798820734 max memory_allocated 22902.77294921875 
[2025-01-16 16:32:41 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 18 loss:0.09406934678554535 norm:0.0010767204221338034 max memory_allocated 22902.77294921875 
[2025-01-16 16:33:12 root] (abq_llm_calib_config.py 361): INFO layer 10 iter 19 loss:0.09409070760011673 norm:0.001116553321480751 max memory_allocated 22902.77294921875 
[2025-01-16 16:33:21 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 11 ===
[2025-01-16 16:34:00 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 0 loss:0.11574458330869675 norm:0.00213134684599936 max memory_allocated 22904.44482421875 
[2025-01-16 16:34:32 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 1 loss:0.10693063586950302 norm:0.001494631520472467 max memory_allocated 22904.44482421875 
[2025-01-16 16:35:03 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 2 loss:0.10114312171936035 norm:0.0013711111387237906 max memory_allocated 22904.44482421875 
[2025-01-16 16:35:34 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 3 loss:0.09883099794387817 norm:0.001302431570366025 max memory_allocated 22904.44482421875 
[2025-01-16 16:36:06 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 4 loss:0.09778522700071335 norm:0.0012171511771157384 max memory_allocated 22904.44482421875 
[2025-01-16 16:36:37 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 5 loss:0.09730503708124161 norm:0.0011604047613218427 max memory_allocated 22904.44482421875 
[2025-01-16 16:37:09 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 6 loss:0.09702077507972717 norm:0.0011179381981492043 max memory_allocated 22904.44482421875 
[2025-01-16 16:37:40 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 7 loss:0.09684623032808304 norm:0.0011295246658846736 max memory_allocated 22904.44482421875 
[2025-01-16 16:38:11 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 8 loss:0.09672869741916656 norm:0.001169163966551423 max memory_allocated 22904.44482421875 
[2025-01-16 16:38:43 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 9 loss:0.09660906344652176 norm:0.0011222553439438343 max memory_allocated 22904.44482421875 
[2025-01-16 16:39:14 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 10 loss:0.09653884917497635 norm:0.0011142730945721269 max memory_allocated 22904.44482421875 
[2025-01-16 16:39:46 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 11 loss:0.0964428186416626 norm:0.0011368135455995798 max memory_allocated 22904.44482421875 
[2025-01-16 16:40:17 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 12 loss:0.09637841582298279 norm:0.0011335297022014856 max memory_allocated 22904.44482421875 
[2025-01-16 16:40:48 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 13 loss:0.09631925821304321 norm:0.00111130450386554 max memory_allocated 22904.44482421875 
[2025-01-16 16:41:20 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 14 loss:0.09627153724431992 norm:0.0011318852193653584 max memory_allocated 22904.44482421875 
[2025-01-16 16:41:51 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 15 loss:0.09629527479410172 norm:0.0011086531449109316 max memory_allocated 22904.44482421875 
[2025-01-16 16:42:23 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 16 loss:0.09628361463546753 norm:0.0011116939131170511 max memory_allocated 22904.44482421875 
[2025-01-16 16:42:54 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 17 loss:0.09624685347080231 norm:0.0010921981884166598 max memory_allocated 22904.44482421875 
[2025-01-16 16:43:25 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 18 loss:0.09623924642801285 norm:0.001052622334100306 max memory_allocated 22904.44482421875 
[2025-01-16 16:43:57 root] (abq_llm_calib_config.py 361): INFO layer 11 iter 19 loss:0.09626547992229462 norm:0.0010653496719896793 max memory_allocated 22904.44482421875 
[2025-01-16 16:44:06 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 12 ===
[2025-01-16 16:44:46 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 0 loss:0.11839770525693893 norm:0.001611929852515459 max memory_allocated 22906.11669921875 
[2025-01-16 16:45:17 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 1 loss:0.10991453379392624 norm:0.0012263079406693578 max memory_allocated 22906.11669921875 
[2025-01-16 16:45:48 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 2 loss:0.10407618433237076 norm:0.0011001199018210173 max memory_allocated 22906.11669921875 
[2025-01-16 16:46:20 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 3 loss:0.10199623554944992 norm:0.0010463617509230971 max memory_allocated 22906.11669921875 
[2025-01-16 16:46:51 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 4 loss:0.10099436342716217 norm:0.001052656676620245 max memory_allocated 22906.11669921875 
[2025-01-16 16:47:23 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 5 loss:0.10053873062133789 norm:0.0010286099277436733 max memory_allocated 22906.11669921875 
[2025-01-16 16:47:54 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 6 loss:0.10026078671216965 norm:0.0009899644646793604 max memory_allocated 22906.11669921875 
[2025-01-16 16:48:25 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 7 loss:0.10009697079658508 norm:0.0009664570679888129 max memory_allocated 22906.11669921875 
[2025-01-16 16:48:57 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 8 loss:0.09997108578681946 norm:0.0009514299454167485 max memory_allocated 22906.11669921875 
[2025-01-16 16:49:28 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 9 loss:0.0999053493142128 norm:0.0009367797174490988 max memory_allocated 22906.11669921875 
[2025-01-16 16:50:00 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 10 loss:0.09984609484672546 norm:0.0009557839366607368 max memory_allocated 22906.11669921875 
[2025-01-16 16:50:31 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 11 loss:0.09975321590900421 norm:0.000954059767536819 max memory_allocated 22906.11669921875 
[2025-01-16 16:51:02 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 12 loss:0.09966986626386642 norm:0.0009055830305442214 max memory_allocated 22906.11669921875 
[2025-01-16 16:51:34 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 13 loss:0.09962023794651031 norm:0.0009403286967426538 max memory_allocated 22906.11669921875 
[2025-01-16 16:52:05 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 14 loss:0.09961609542369843 norm:0.000928024179302156 max memory_allocated 22906.11669921875 
[2025-01-16 16:52:37 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 15 loss:0.09956575185060501 norm:0.000932635273784399 max memory_allocated 22906.11669921875 
[2025-01-16 16:53:08 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 16 loss:0.09955282509326935 norm:0.0009259539656341076 max memory_allocated 22906.11669921875 
[2025-01-16 16:53:39 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 17 loss:0.09956933557987213 norm:0.0009112291154451668 max memory_allocated 22906.11669921875 
[2025-01-16 16:54:11 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 18 loss:0.09955494105815887 norm:0.0009218931081704795 max memory_allocated 22906.11669921875 
[2025-01-16 16:54:42 root] (abq_llm_calib_config.py 361): INFO layer 12 iter 19 loss:0.09954998642206192 norm:0.0009278236539103091 max memory_allocated 22906.11669921875 
[2025-01-16 16:54:51 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 13 ===
[2025-01-16 16:55:33 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 0 loss:0.11525539308786392 norm:0.0014951821649447083 max memory_allocated 22907.78857421875 
[2025-01-16 16:56:04 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 1 loss:0.10765707492828369 norm:0.0011779452906921506 max memory_allocated 22907.78857421875 
[2025-01-16 16:56:35 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 2 loss:0.102211594581604 norm:0.0010871482081711292 max memory_allocated 22907.78857421875 
[2025-01-16 16:57:07 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 3 loss:0.10030948370695114 norm:0.0010095781181007624 max memory_allocated 22907.78857421875 
[2025-01-16 16:57:38 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 4 loss:0.09939148277044296 norm:0.0009861496509984136 max memory_allocated 22907.78857421875 
[2025-01-16 16:58:10 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 5 loss:0.0989278107881546 norm:0.0010205351281911135 max memory_allocated 22907.78857421875 
[2025-01-16 16:58:41 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 6 loss:0.09870007634162903 norm:0.0010141830425709486 max memory_allocated 22907.78857421875 
[2025-01-16 16:59:13 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 7 loss:0.09853953868150711 norm:0.0010154972551390529 max memory_allocated 22907.78857421875 
[2025-01-16 16:59:44 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 8 loss:0.098381906747818 norm:0.0009617771720513701 max memory_allocated 22907.78857421875 
[2025-01-16 17:00:15 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 9 loss:0.09827998280525208 norm:0.0009387297905050218 max memory_allocated 22907.78857421875 
[2025-01-16 17:00:47 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 10 loss:0.09820931404829025 norm:0.0009383577853441238 max memory_allocated 22907.78857421875 
[2025-01-16 17:01:18 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 11 loss:0.09817813336849213 norm:0.0009427712066099048 max memory_allocated 22907.78857421875 
[2025-01-16 17:01:50 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 12 loss:0.09813667833805084 norm:0.0009671003790572286 max memory_allocated 22907.78857421875 
[2025-01-16 17:02:21 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 13 loss:0.0981234610080719 norm:0.0009516938007436693 max memory_allocated 22907.78857421875 
[2025-01-16 17:02:52 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 14 loss:0.0980919674038887 norm:0.0009610566776245832 max memory_allocated 22907.78857421875 
[2025-01-16 17:03:24 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 15 loss:0.09804884344339371 norm:0.0009409183985553682 max memory_allocated 22907.78857421875 
[2025-01-16 17:03:55 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 16 loss:0.09801601618528366 norm:0.000977491494268179 max memory_allocated 22907.78857421875 
[2025-01-16 17:04:27 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 17 loss:0.09799861162900925 norm:0.0009640859789215028 max memory_allocated 22907.78857421875 
[2025-01-16 17:04:58 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 18 loss:0.09797775745391846 norm:0.0009483554749749601 max memory_allocated 22907.78857421875 
[2025-01-16 17:05:29 root] (abq_llm_calib_config.py 361): INFO layer 13 iter 19 loss:0.09795337170362473 norm:0.0009291578317061067 max memory_allocated 22907.78857421875 
[2025-01-16 17:05:38 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 14 ===
[2025-01-16 17:06:17 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 0 loss:0.12000686675310135 norm:0.0017005892004817724 max memory_allocated 22909.46044921875 
[2025-01-16 17:06:48 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 1 loss:0.11151783913373947 norm:0.001091594691388309 max memory_allocated 22909.46044921875 
[2025-01-16 17:07:19 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 2 loss:0.10526319593191147 norm:0.0009439696441404521 max memory_allocated 22909.46044921875 
[2025-01-16 17:07:51 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 3 loss:0.10283355414867401 norm:0.0008659798186272383 max memory_allocated 22909.46044921875 
[2025-01-16 17:08:22 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 4 loss:0.10175743699073792 norm:0.0008497495437040925 max memory_allocated 22909.46044921875 
[2025-01-16 17:08:54 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 5 loss:0.101264089345932 norm:0.0008311986457556486 max memory_allocated 22909.46044921875 
[2025-01-16 17:09:25 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 6 loss:0.10097436606884003 norm:0.0007873884169384837 max memory_allocated 22909.46044921875 
[2025-01-16 17:09:57 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 7 loss:0.100807785987854 norm:0.0007690746570006013 max memory_allocated 22909.46044921875 
[2025-01-16 17:10:28 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 8 loss:0.1007087454199791 norm:0.0007867979584261775 max memory_allocated 22909.46044921875 
[2025-01-16 17:10:59 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 9 loss:0.10060775279998779 norm:0.0007606076542288065 max memory_allocated 22909.46044921875 
[2025-01-16 17:11:31 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 10 loss:0.1005105972290039 norm:0.0007657370297238231 max memory_allocated 22909.46044921875 
[2025-01-16 17:12:02 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 11 loss:0.10046058148145676 norm:0.0007689614431001246 max memory_allocated 22909.46044921875 
[2025-01-16 17:12:34 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 12 loss:0.1004377007484436 norm:0.0007806787034496665 max memory_allocated 22909.46044921875 
[2025-01-16 17:13:05 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 13 loss:0.10036887973546982 norm:0.0007648921455256641 max memory_allocated 22909.46044921875 
[2025-01-16 17:13:37 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 14 loss:0.10031905025243759 norm:0.0007719614659436047 max memory_allocated 22909.46044921875 
[2025-01-16 17:14:08 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 15 loss:0.1002865731716156 norm:0.0007435893639922142 max memory_allocated 22909.46044921875 
[2025-01-16 17:14:39 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 16 loss:0.1002792939543724 norm:0.0007630617474205792 max memory_allocated 22909.46044921875 
[2025-01-16 17:15:11 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 17 loss:0.10026465356349945 norm:0.0007555002230219543 max memory_allocated 22909.46044921875 
[2025-01-16 17:15:42 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 18 loss:0.10028649121522903 norm:0.0007750426884740591 max memory_allocated 22909.46044921875 
[2025-01-16 17:16:14 root] (abq_llm_calib_config.py 361): INFO layer 14 iter 19 loss:0.10025088489055634 norm:0.0007475202437490225 max memory_allocated 22909.46044921875 
[2025-01-16 17:16:22 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 15 ===
[2025-01-16 17:17:01 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 0 loss:0.11978726089000702 norm:0.0026412419974803925 max memory_allocated 22911.13232421875 
[2025-01-16 17:17:33 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 1 loss:0.10998217761516571 norm:0.0013772848760709167 max memory_allocated 22911.13232421875 
[2025-01-16 17:18:04 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 2 loss:0.10341833531856537 norm:0.0011684081982821226 max memory_allocated 22911.13232421875 
[2025-01-16 17:18:35 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 3 loss:0.10100653767585754 norm:0.0010424823267385364 max memory_allocated 22911.13232421875 
[2025-01-16 17:19:07 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 4 loss:0.09988269954919815 norm:0.0010157587239518762 max memory_allocated 22911.13232421875 
[2025-01-16 17:19:38 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 5 loss:0.09933427721261978 norm:0.0010219038231298327 max memory_allocated 22911.13232421875 
[2025-01-16 17:20:10 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 6 loss:0.09904056042432785 norm:0.0009847008623182774 max memory_allocated 22911.13232421875 
[2025-01-16 17:20:41 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 7 loss:0.0988677367568016 norm:0.0009943090844899416 max memory_allocated 22911.13232421875 
[2025-01-16 17:21:12 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 8 loss:0.09872155636548996 norm:0.0009684975375421345 max memory_allocated 22911.13232421875 
[2025-01-16 17:21:44 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 9 loss:0.09860800206661224 norm:0.0009566177614033222 max memory_allocated 22911.13232421875 
[2025-01-16 17:22:15 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 10 loss:0.09853610396385193 norm:0.0009356471709907055 max memory_allocated 22911.13232421875 
[2025-01-16 17:22:47 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 11 loss:0.0984642505645752 norm:0.0009375171503052115 max memory_allocated 22911.13232421875 
[2025-01-16 17:23:18 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 12 loss:0.09839867800474167 norm:0.0009118347661569715 max memory_allocated 22911.13232421875 
[2025-01-16 17:23:50 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 13 loss:0.09833524376153946 norm:0.000893184042070061 max memory_allocated 22911.13232421875 
[2025-01-16 17:24:21 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 14 loss:0.09829225391149521 norm:0.0008695883443579078 max memory_allocated 22911.13232421875 
[2025-01-16 17:24:52 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 15 loss:0.09826470166444778 norm:0.0008689407259225845 max memory_allocated 22911.13232421875 
[2025-01-16 17:25:24 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 16 loss:0.09823717176914215 norm:0.0008560805581510067 max memory_allocated 22911.13232421875 
[2025-01-16 17:25:55 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 17 loss:0.09820051491260529 norm:0.0008411643211729825 max memory_allocated 22911.13232421875 
[2025-01-16 17:26:27 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 18 loss:0.09820473194122314 norm:0.0008334075100719929 max memory_allocated 22911.13232421875 
[2025-01-16 17:26:58 root] (abq_llm_calib_config.py 361): INFO layer 15 iter 19 loss:0.0981937050819397 norm:0.0008403495303355157 max memory_allocated 22911.13232421875 
[2025-01-16 17:27:07 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 16 ===
[2025-01-16 17:27:46 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 0 loss:0.11326292157173157 norm:0.0016043775249272585 max memory_allocated 22912.80419921875 
[2025-01-16 17:28:17 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 1 loss:0.10510565340518951 norm:0.001106426352635026 max memory_allocated 22912.80419921875 
[2025-01-16 17:28:49 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 2 loss:0.09959714114665985 norm:0.0009383254800923169 max memory_allocated 22912.80419921875 
[2025-01-16 17:29:20 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 3 loss:0.09778895974159241 norm:0.000864646804984659 max memory_allocated 22912.80419921875 
[2025-01-16 17:29:52 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 4 loss:0.09681855142116547 norm:0.0008416858036071062 max memory_allocated 22912.80419921875 
[2025-01-16 17:30:23 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 5 loss:0.09633834660053253 norm:0.0008020536624826491 max memory_allocated 22912.80419921875 
[2025-01-16 17:30:55 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 6 loss:0.09606269747018814 norm:0.0007695272797718644 max memory_allocated 22912.80419921875 
[2025-01-16 17:31:26 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 7 loss:0.09592076390981674 norm:0.0007465837989002466 max memory_allocated 22912.80419921875 
[2025-01-16 17:31:57 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 8 loss:0.09581326693296432 norm:0.0007540634251199663 max memory_allocated 22912.80419921875 
[2025-01-16 17:32:29 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 9 loss:0.09566677361726761 norm:0.0007146740681491792 max memory_allocated 22912.80419921875 
[2025-01-16 17:33:00 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 10 loss:0.09559313952922821 norm:0.0007188675226643682 max memory_allocated 22912.80419921875 
[2025-01-16 17:33:32 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 11 loss:0.0955037996172905 norm:0.0007033417350612581 max memory_allocated 22912.80419921875 
[2025-01-16 17:34:03 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 12 loss:0.09547045826911926 norm:0.0007120296359062195 max memory_allocated 22912.80419921875 
[2025-01-16 17:34:34 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 13 loss:0.09540566802024841 norm:0.0007096384651958942 max memory_allocated 22912.80419921875 
[2025-01-16 17:35:06 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 14 loss:0.09536361694335938 norm:0.000701098470017314 max memory_allocated 22912.80419921875 
[2025-01-16 17:35:37 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 15 loss:0.09530817717313766 norm:0.0006947243819013238 max memory_allocated 22912.80419921875 
[2025-01-16 17:36:09 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 16 loss:0.09527024626731873 norm:0.0006892321398481727 max memory_allocated 22912.80419921875 
[2025-01-16 17:36:40 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 17 loss:0.0952298566699028 norm:0.0006886054761707783 max memory_allocated 22912.80419921875 
[2025-01-16 17:37:11 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 18 loss:0.09519500285387039 norm:0.0006781226256862283 max memory_allocated 22912.80419921875 
[2025-01-16 17:37:43 root] (abq_llm_calib_config.py 361): INFO layer 16 iter 19 loss:0.0951845645904541 norm:0.0006717430660501122 max memory_allocated 22912.80419921875 
[2025-01-16 17:37:52 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 17 ===
[2025-01-16 17:38:31 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 0 loss:0.10957668721675873 norm:0.0012664507376030087 max memory_allocated 22914.47607421875 
[2025-01-16 17:39:03 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 1 loss:0.10378158837556839 norm:0.0009700717637315392 max memory_allocated 22914.47607421875 
[2025-01-16 17:39:34 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 2 loss:0.09957297891378403 norm:0.0008972876239567995 max memory_allocated 22914.47607421875 
[2025-01-16 17:40:05 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 3 loss:0.09805765748023987 norm:0.0008504515863023698 max memory_allocated 22914.47607421875 
[2025-01-16 17:40:37 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 4 loss:0.0971352830529213 norm:0.0008533378131687641 max memory_allocated 22914.47607421875 
[2025-01-16 17:41:08 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 5 loss:0.09665113687515259 norm:0.0008220926392823458 max memory_allocated 22914.47607421875 
[2025-01-16 17:41:40 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 6 loss:0.09641730785369873 norm:0.0007738525746390224 max memory_allocated 22914.47607421875 
[2025-01-16 17:42:11 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 7 loss:0.09628947079181671 norm:0.0007686548051424325 max memory_allocated 22914.47607421875 
[2025-01-16 17:42:42 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 8 loss:0.09620244055986404 norm:0.0008017157088033855 max memory_allocated 22914.47607421875 
[2025-01-16 17:43:14 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 9 loss:0.09611377120018005 norm:0.000764794007409364 max memory_allocated 22914.47607421875 
[2025-01-16 17:43:45 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 10 loss:0.09604042023420334 norm:0.0007731720106676221 max memory_allocated 22914.47607421875 
[2025-01-16 17:44:17 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 11 loss:0.09598985314369202 norm:0.00076227483805269 max memory_allocated 22914.47607421875 
[2025-01-16 17:44:48 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 12 loss:0.09596573561429977 norm:0.0007543251849710941 max memory_allocated 22914.47607421875 
[2025-01-16 17:45:19 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 13 loss:0.09594865143299103 norm:0.0007501687505282462 max memory_allocated 22914.47607421875 
[2025-01-16 17:45:51 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 14 loss:0.09593155235052109 norm:0.0007556888158433139 max memory_allocated 22914.47607421875 
[2025-01-16 17:46:22 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 15 loss:0.09588002413511276 norm:0.0007390068494714797 max memory_allocated 22914.47607421875 
[2025-01-16 17:46:54 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 16 loss:0.09583435207605362 norm:0.0007453652215190232 max memory_allocated 22914.47607421875 
[2025-01-16 17:47:25 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 17 loss:0.09583491086959839 norm:0.0007189643220044672 max memory_allocated 22914.47607421875 
[2025-01-16 17:47:56 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 18 loss:0.09583697468042374 norm:0.0007009003311395645 max memory_allocated 22914.47607421875 
[2025-01-16 17:48:28 root] (abq_llm_calib_config.py 361): INFO layer 17 iter 19 loss:0.0958242118358612 norm:0.0007187279406934977 max memory_allocated 22914.47607421875 
[2025-01-16 17:48:37 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 18 ===
[2025-01-16 17:49:17 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 0 loss:0.115277960896492 norm:0.0013342194724828005 max memory_allocated 22916.14794921875 
[2025-01-16 17:49:48 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 1 loss:0.10905291140079498 norm:0.0011180030414834619 max memory_allocated 22916.14794921875 
[2025-01-16 17:50:20 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 2 loss:0.10435193032026291 norm:0.00100837298668921 max memory_allocated 22916.14794921875 
[2025-01-16 17:50:51 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 3 loss:0.10272025316953659 norm:0.0009139659814536572 max memory_allocated 22916.14794921875 
[2025-01-16 17:51:23 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 4 loss:0.10173234343528748 norm:0.0009331281180493534 max memory_allocated 22916.14794921875 
[2025-01-16 17:51:54 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 5 loss:0.10126554220914841 norm:0.0009125678916461766 max memory_allocated 22916.14794921875 
[2025-01-16 17:52:25 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 6 loss:0.10103389620780945 norm:0.0008401734521612525 max memory_allocated 22916.14794921875 
[2025-01-16 17:52:57 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 7 loss:0.10091058909893036 norm:0.0008673868724144995 max memory_allocated 22916.14794921875 
[2025-01-16 17:53:28 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 8 loss:0.10079565644264221 norm:0.0008148347260430455 max memory_allocated 22916.14794921875 
[2025-01-16 17:54:00 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 9 loss:0.10069966316223145 norm:0.0008141217986121774 max memory_allocated 22916.14794921875 
[2025-01-16 17:54:31 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 10 loss:0.10060259699821472 norm:0.000817787426058203 max memory_allocated 22916.14794921875 
[2025-01-16 17:55:02 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 11 loss:0.1005195751786232 norm:0.0008297307067550719 max memory_allocated 22916.14794921875 
[2025-01-16 17:55:34 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 12 loss:0.10045311599969864 norm:0.0008368761045858264 max memory_allocated 22916.14794921875 
[2025-01-16 17:56:05 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 13 loss:0.10042177140712738 norm:0.0008617144776508212 max memory_allocated 22916.14794921875 
[2025-01-16 17:56:37 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 14 loss:0.10040640085935593 norm:0.0008424638654105365 max memory_allocated 22916.14794921875 
[2025-01-16 17:57:08 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 15 loss:0.10038085281848907 norm:0.00081204081652686 max memory_allocated 22916.14794921875 
[2025-01-16 17:57:40 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 16 loss:0.10035867244005203 norm:0.00083590840222314 max memory_allocated 22916.14794921875 
[2025-01-16 17:58:11 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 17 loss:0.10033200681209564 norm:0.0008420468075200915 max memory_allocated 22916.14794921875 
[2025-01-16 17:58:42 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 18 loss:0.10031257569789886 norm:0.0008234886918216944 max memory_allocated 22916.14794921875 
[2025-01-16 17:59:14 root] (abq_llm_calib_config.py 361): INFO layer 18 iter 19 loss:0.10030241310596466 norm:0.0008463438134640455 max memory_allocated 22916.14794921875 
[2025-01-16 17:59:23 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 19 ===
[2025-01-16 18:00:04 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 0 loss:0.12105334550142288 norm:0.0013014511205255985 max memory_allocated 22917.81982421875 
[2025-01-16 18:00:35 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 1 loss:0.1151403859257698 norm:0.0009592912392690778 max memory_allocated 22917.81982421875 
[2025-01-16 18:01:07 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 2 loss:0.1104062870144844 norm:0.0008114577503874898 max memory_allocated 22917.81982421875 
[2025-01-16 18:01:38 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 3 loss:0.1088477373123169 norm:0.0007678028778173029 max memory_allocated 22917.81982421875 
[2025-01-16 18:02:09 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 4 loss:0.10785380750894547 norm:0.0007165043498389423 max memory_allocated 22917.81982421875 
[2025-01-16 18:02:41 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 5 loss:0.10739496350288391 norm:0.0007038746261969209 max memory_allocated 22917.81982421875 
[2025-01-16 18:03:12 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 6 loss:0.1072121411561966 norm:0.0007037984905764461 max memory_allocated 22917.81982421875 
[2025-01-16 18:03:44 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 7 loss:0.10704656690359116 norm:0.0006869712378829718 max memory_allocated 22917.81982421875 
[2025-01-16 18:04:15 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 8 loss:0.10693585872650146 norm:0.000680312979966402 max memory_allocated 22917.81982421875 
[2025-01-16 18:04:46 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 9 loss:0.10684596747159958 norm:0.0006830843631178141 max memory_allocated 22917.81982421875 
[2025-01-16 18:05:18 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 10 loss:0.10679934173822403 norm:0.00070284801768139 max memory_allocated 22917.81982421875 
[2025-01-16 18:05:49 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 11 loss:0.10672158747911453 norm:0.0006922738975845277 max memory_allocated 22917.81982421875 
[2025-01-16 18:06:20 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 12 loss:0.10666989535093307 norm:0.0006917933351360261 max memory_allocated 22917.81982421875 
[2025-01-16 18:06:52 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 13 loss:0.10664092004299164 norm:0.0006594099686481059 max memory_allocated 22917.81982421875 
[2025-01-16 18:07:23 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 14 loss:0.1065995916724205 norm:0.0006649426650255919 max memory_allocated 22917.81982421875 
[2025-01-16 18:07:55 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 15 loss:0.10657333582639694 norm:0.0006499174050986767 max memory_allocated 22917.81982421875 
[2025-01-16 18:08:26 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 16 loss:0.1065416932106018 norm:0.0006403950392268598 max memory_allocated 22917.81982421875 
[2025-01-16 18:08:57 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 17 loss:0.10652457177639008 norm:0.000670969020575285 max memory_allocated 22917.81982421875 
[2025-01-16 18:09:29 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 18 loss:0.1065046489238739 norm:0.0006365315639413893 max memory_allocated 22917.81982421875 
[2025-01-16 18:10:00 root] (abq_llm_calib_config.py 361): INFO layer 19 iter 19 loss:0.10648348927497864 norm:0.0006374968215823174 max memory_allocated 22917.81982421875 
[2025-01-16 18:10:09 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 20 ===
[2025-01-16 18:10:49 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 0 loss:0.12883712351322174 norm:0.0014356025494635105 max memory_allocated 22919.49169921875 
[2025-01-16 18:11:20 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 1 loss:0.12267614156007767 norm:0.0011332872090861201 max memory_allocated 22919.49169921875 
[2025-01-16 18:11:51 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 2 loss:0.11783558875322342 norm:0.0012008005287498236 max memory_allocated 22919.49169921875 
[2025-01-16 18:12:23 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 3 loss:0.11625698953866959 norm:0.0010930821299552917 max memory_allocated 22919.49169921875 
[2025-01-16 18:12:54 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 4 loss:0.1152542233467102 norm:0.0010537971975281835 max memory_allocated 22919.49169921875 
[2025-01-16 18:13:26 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 5 loss:0.1147521436214447 norm:0.0010536687914282084 max memory_allocated 22919.49169921875 
[2025-01-16 18:13:57 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 6 loss:0.1144694834947586 norm:0.0009878297569230199 max memory_allocated 22919.49169921875 
[2025-01-16 18:14:28 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 7 loss:0.11428266763687134 norm:0.0009542885236442089 max memory_allocated 22919.49169921875 
[2025-01-16 18:15:00 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 8 loss:0.114151731133461 norm:0.0009489087387919426 max memory_allocated 22919.49169921875 
[2025-01-16 18:15:31 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 9 loss:0.11407718062400818 norm:0.0009485996561124921 max memory_allocated 22919.49169921875 
[2025-01-16 18:16:03 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 10 loss:0.11396953463554382 norm:0.0008959969272837043 max memory_allocated 22919.49169921875 
[2025-01-16 18:16:34 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 11 loss:0.11387073993682861 norm:0.0008885947754606605 max memory_allocated 22919.49169921875 
[2025-01-16 18:17:05 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 12 loss:0.11378905922174454 norm:0.000904255430214107 max memory_allocated 22919.49169921875 
[2025-01-16 18:17:37 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 13 loss:0.11372678726911545 norm:0.0009035835973918438 max memory_allocated 22919.49169921875 
[2025-01-16 18:18:08 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 14 loss:0.11367073655128479 norm:0.0009208844276145101 max memory_allocated 22919.49169921875 
[2025-01-16 18:18:40 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 15 loss:0.11363480985164642 norm:0.0008697736775502563 max memory_allocated 22919.49169921875 
[2025-01-16 18:19:11 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 16 loss:0.1136096939444542 norm:0.0009063313482329249 max memory_allocated 22919.49169921875 
[2025-01-16 18:19:42 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 17 loss:0.11359600722789764 norm:0.000908552436158061 max memory_allocated 22919.49169921875 
[2025-01-16 18:20:14 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 18 loss:0.1135653629899025 norm:0.0009113585110753775 max memory_allocated 22919.49169921875 
[2025-01-16 18:20:45 root] (abq_llm_calib_config.py 361): INFO layer 20 iter 19 loss:0.1135500892996788 norm:0.0009296006755903363 max memory_allocated 22919.49169921875 
[2025-01-16 18:20:54 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 21 ===
[2025-01-16 18:21:33 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 0 loss:0.13979527354240417 norm:0.0017682660836726427 max memory_allocated 22921.16357421875 
[2025-01-16 18:22:04 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 1 loss:0.13372698426246643 norm:0.0009003590676002204 max memory_allocated 22921.16357421875 
[2025-01-16 18:22:36 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 2 loss:0.12867045402526855 norm:0.0007411765400320292 max memory_allocated 22921.16357421875 
[2025-01-16 18:23:07 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 3 loss:0.12699486315250397 norm:0.0006943518528714776 max memory_allocated 22921.16357421875 
[2025-01-16 18:23:39 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 4 loss:0.12588556110858917 norm:0.0006665202090516686 max memory_allocated 22921.16357421875 
[2025-01-16 18:24:10 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 5 loss:0.12530040740966797 norm:0.0006363814463838935 max memory_allocated 22921.16357421875 
[2025-01-16 18:24:41 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 6 loss:0.1250416785478592 norm:0.0006499194423668087 max memory_allocated 22921.16357421875 
[2025-01-16 18:25:13 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 7 loss:0.12487949430942535 norm:0.0006127001834101975 max memory_allocated 22921.16357421875 
[2025-01-16 18:25:44 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 8 loss:0.12474510818719864 norm:0.0006004957831464708 max memory_allocated 22921.16357421875 
[2025-01-16 18:26:16 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 9 loss:0.12465261667966843 norm:0.0005868113366886973 max memory_allocated 22921.16357421875 
[2025-01-16 18:26:47 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 10 loss:0.12456952780485153 norm:0.0005797257763333619 max memory_allocated 22921.16357421875 
[2025-01-16 18:27:18 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 11 loss:0.12450742721557617 norm:0.0005815664771944284 max memory_allocated 22921.16357421875 
[2025-01-16 18:27:50 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 12 loss:0.12446115911006927 norm:0.0005901662516407669 max memory_allocated 22921.16357421875 
[2025-01-16 18:28:21 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 13 loss:0.12440723180770874 norm:0.000571976532228291 max memory_allocated 22921.16357421875 
[2025-01-16 18:28:53 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 14 loss:0.12435496598482132 norm:0.0005727616953663528 max memory_allocated 22921.16357421875 
[2025-01-16 18:29:24 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 15 loss:0.12431100010871887 norm:0.0005594471003860235 max memory_allocated 22921.16357421875 
[2025-01-16 18:29:55 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 16 loss:0.1242813691496849 norm:0.000561647757422179 max memory_allocated 22921.16357421875 
[2025-01-16 18:30:27 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 17 loss:0.12426456063985825 norm:0.0005592916277237236 max memory_allocated 22921.16357421875 
[2025-01-16 18:30:58 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 18 loss:0.12424759566783905 norm:0.0005616591079160571 max memory_allocated 22921.16357421875 
[2025-01-16 18:31:30 root] (abq_llm_calib_config.py 361): INFO layer 21 iter 19 loss:0.12423717230558395 norm:0.0005586284096352756 max memory_allocated 22921.16357421875 
[2025-01-16 18:31:38 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 22 ===
[2025-01-16 18:32:23 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 0 loss:0.15551972389221191 norm:0.0017909080488607287 max memory_allocated 22922.83544921875 
[2025-01-16 18:32:55 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 1 loss:0.14918634295463562 norm:0.0013491559075191617 max memory_allocated 22922.83544921875 
[2025-01-16 18:33:26 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 2 loss:0.14412511885166168 norm:0.0013148359721526504 max memory_allocated 22922.83544921875 
[2025-01-16 18:33:57 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 3 loss:0.1424611210823059 norm:0.0013291744980961084 max memory_allocated 22922.83544921875 
[2025-01-16 18:34:29 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 4 loss:0.14138257503509521 norm:0.001241473713889718 max memory_allocated 22922.83544921875 
[2025-01-16 18:35:00 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 5 loss:0.14089111983776093 norm:0.001230793772265315 max memory_allocated 22922.83544921875 
[2025-01-16 18:35:32 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 6 loss:0.1406860053539276 norm:0.0012134276330471039 max memory_allocated 22922.83544921875 
[2025-01-16 18:36:03 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 7 loss:0.14054074883460999 norm:0.0011454748455435038 max memory_allocated 22922.83544921875 
[2025-01-16 18:36:34 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 8 loss:0.14040476083755493 norm:0.001109225326217711 max memory_allocated 22922.83544921875 
[2025-01-16 18:37:06 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 9 loss:0.1402999311685562 norm:0.0011386575642973185 max memory_allocated 22922.83544921875 
[2025-01-16 18:37:37 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 10 loss:0.1402062177658081 norm:0.0011359475320205092 max memory_allocated 22922.83544921875 
[2025-01-16 18:38:09 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 11 loss:0.14013008773326874 norm:0.0011439736699685454 max memory_allocated 22922.83544921875 
[2025-01-16 18:38:40 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 12 loss:0.14008162915706635 norm:0.0011043180711567402 max memory_allocated 22922.83544921875 
[2025-01-16 18:39:12 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 13 loss:0.14002063870429993 norm:0.0011379611678421497 max memory_allocated 22922.83544921875 
[2025-01-16 18:39:43 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 14 loss:0.139977365732193 norm:0.00112657411955297 max memory_allocated 22922.83544921875 
[2025-01-16 18:40:14 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 15 loss:0.13991135358810425 norm:0.001070673461072147 max memory_allocated 22922.83544921875 
[2025-01-16 18:40:46 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 16 loss:0.1398673951625824 norm:0.0010395902208983898 max memory_allocated 22922.83544921875 
[2025-01-16 18:41:17 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 17 loss:0.13982948660850525 norm:0.0009970281971618533 max memory_allocated 22922.83544921875 
[2025-01-16 18:41:48 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 18 loss:0.13979321718215942 norm:0.0009808919858187437 max memory_allocated 22922.83544921875 
[2025-01-16 18:42:20 root] (abq_llm_calib_config.py 361): INFO layer 22 iter 19 loss:0.1397486925125122 norm:0.0010023560607805848 max memory_allocated 22922.83544921875 
[2025-01-16 18:42:29 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 23 ===
[2025-01-16 18:43:19 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 0 loss:0.1724979728460312 norm:0.0009755935752764344 max memory_allocated 22924.50732421875 
[2025-01-16 18:43:51 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 1 loss:0.1664615124464035 norm:0.000722021737601608 max memory_allocated 22924.50732421875 
[2025-01-16 18:44:22 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 2 loss:0.16113370656967163 norm:0.000655187526717782 max memory_allocated 22924.50732421875 
[2025-01-16 18:44:53 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 3 loss:0.15937818586826324 norm:0.0005865609273314476 max memory_allocated 22924.50732421875 
[2025-01-16 18:45:25 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 4 loss:0.1582113355398178 norm:0.0005529385525733232 max memory_allocated 22924.50732421875 
[2025-01-16 18:45:56 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 5 loss:0.15779809653759003 norm:0.0005374260945245624 max memory_allocated 22924.50732421875 
[2025-01-16 18:46:28 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 6 loss:0.15762139856815338 norm:0.0005223922780714929 max memory_allocated 22924.50732421875 
[2025-01-16 18:46:59 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 7 loss:0.15747621655464172 norm:0.000512712518684566 max memory_allocated 22924.50732421875 
[2025-01-16 18:47:30 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 8 loss:0.15734264254570007 norm:0.0005133931990712881 max memory_allocated 22924.50732421875 
[2025-01-16 18:48:02 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 9 loss:0.1572275608778 norm:0.0005035183858126402 max memory_allocated 22924.50732421875 
[2025-01-16 18:48:33 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 10 loss:0.15714094042778015 norm:0.000495589745696634 max memory_allocated 22924.50732421875 
[2025-01-16 18:49:05 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 11 loss:0.15707243978977203 norm:0.0004946855478920043 max memory_allocated 22924.50732421875 
[2025-01-16 18:49:36 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 12 loss:0.15701164305210114 norm:0.00048647861694917083 max memory_allocated 22924.50732421875 
[2025-01-16 18:50:07 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 13 loss:0.15696179866790771 norm:0.00047388632083311677 max memory_allocated 22924.50732421875 
[2025-01-16 18:50:39 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 14 loss:0.15691539645195007 norm:0.000474339525680989 max memory_allocated 22924.50732421875 
[2025-01-16 18:51:10 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 15 loss:0.15686535835266113 norm:0.0004706120234914124 max memory_allocated 22924.50732421875 
[2025-01-16 18:51:42 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 16 loss:0.15681974589824677 norm:0.00047808210365474224 max memory_allocated 22924.50732421875 
[2025-01-16 18:52:13 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 17 loss:0.15680325031280518 norm:0.00047090378939174116 max memory_allocated 22924.50732421875 
[2025-01-16 18:52:45 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 18 loss:0.1567678600549698 norm:0.000462240946944803 max memory_allocated 22924.50732421875 
[2025-01-16 18:53:16 root] (abq_llm_calib_config.py 361): INFO layer 23 iter 19 loss:0.15674589574337006 norm:0.0004649871843867004 max memory_allocated 22924.50732421875 
[2025-01-16 18:53:25 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 24 ===
[2025-01-16 18:54:06 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 0 loss:0.19805018603801727 norm:0.0024927679914981127 max memory_allocated 22926.17919921875 
[2025-01-16 18:54:37 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 1 loss:0.1901644468307495 norm:0.0014577622059732676 max memory_allocated 22926.17919921875 
[2025-01-16 18:55:09 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 2 loss:0.18346798419952393 norm:0.0013453684514388442 max memory_allocated 22926.17919921875 
[2025-01-16 18:55:40 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 3 loss:0.1809699833393097 norm:0.0013855687575414777 max memory_allocated 22926.17919921875 
[2025-01-16 18:56:12 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 4 loss:0.179598867893219 norm:0.001370759098790586 max memory_allocated 22926.17919921875 
[2025-01-16 18:56:43 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 5 loss:0.17910245060920715 norm:0.0013472939608618617 max memory_allocated 22926.17919921875 
[2025-01-16 18:57:14 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 6 loss:0.17884013056755066 norm:0.0012742941034957767 max memory_allocated 22926.17919921875 
[2025-01-16 18:57:46 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 7 loss:0.17864678800106049 norm:0.0012329183518886566 max memory_allocated 22926.17919921875 
[2025-01-16 18:58:17 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 8 loss:0.17847293615341187 norm:0.001212205970659852 max memory_allocated 22926.17919921875 
[2025-01-16 18:58:49 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 9 loss:0.17834141850471497 norm:0.0012171552516520023 max memory_allocated 22926.17919921875 
[2025-01-16 18:59:20 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 10 loss:0.178259015083313 norm:0.0011502050328999758 max memory_allocated 22926.17919921875 
[2025-01-16 18:59:51 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 11 loss:0.17817461490631104 norm:0.0011956051457673311 max memory_allocated 22926.17919921875 
[2025-01-16 19:00:23 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 12 loss:0.17807409167289734 norm:0.001184998545795679 max memory_allocated 22926.17919921875 
[2025-01-16 19:00:54 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 13 loss:0.17799219489097595 norm:0.001138232764787972 max memory_allocated 22926.17919921875 
[2025-01-16 19:01:26 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 14 loss:0.17797425389289856 norm:0.001173278084024787 max memory_allocated 22926.17919921875 
[2025-01-16 19:01:57 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 15 loss:0.17792189121246338 norm:0.0011346139945089817 max memory_allocated 22926.17919921875 
[2025-01-16 19:02:28 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 16 loss:0.17789284884929657 norm:0.001140412176027894 max memory_allocated 22926.17919921875 
[2025-01-16 19:03:00 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 17 loss:0.17782728374004364 norm:0.0010925435926765203 max memory_allocated 22926.17919921875 
[2025-01-16 19:03:31 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 18 loss:0.1777985543012619 norm:0.0011457426007837057 max memory_allocated 22926.17919921875 
[2025-01-16 19:04:03 root] (abq_llm_calib_config.py 361): INFO layer 24 iter 19 loss:0.17779473960399628 norm:0.0011501354165375233 max memory_allocated 22926.17919921875 
[2025-01-16 19:04:11 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 25 ===
[2025-01-16 19:04:56 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 0 loss:0.22549909353256226 norm:0.0019314039964228868 max memory_allocated 22927.85107421875 
[2025-01-16 19:05:27 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 1 loss:0.2167682647705078 norm:0.0012918331194669008 max memory_allocated 22927.85107421875 
[2025-01-16 19:05:59 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 2 loss:0.20926673710346222 norm:0.0011321860365569592 max memory_allocated 22927.85107421875 
[2025-01-16 19:06:30 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 3 loss:0.20664054155349731 norm:0.001115948660299182 max memory_allocated 22927.85107421875 
[2025-01-16 19:07:02 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 4 loss:0.2052472084760666 norm:0.0010559570509940386 max memory_allocated 22927.85107421875 
[2025-01-16 19:07:33 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 5 loss:0.2046988159418106 norm:0.0010203898418694735 max memory_allocated 22927.85107421875 
[2025-01-16 19:08:05 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 6 loss:0.20439712703227997 norm:0.0009708288125693798 max memory_allocated 22927.85107421875 
[2025-01-16 19:08:36 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 7 loss:0.20419172942638397 norm:0.000962688762228936 max memory_allocated 22927.85107421875 
[2025-01-16 19:09:07 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 8 loss:0.20402076840400696 norm:0.0009367004968225956 max memory_allocated 22927.85107421875 
[2025-01-16 19:09:39 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 9 loss:0.20386061072349548 norm:0.0009151982376351953 max memory_allocated 22927.85107421875 
[2025-01-16 19:10:10 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 10 loss:0.20374582707881927 norm:0.0009137776214629412 max memory_allocated 22927.85107421875 
[2025-01-16 19:10:42 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 11 loss:0.20360365509986877 norm:0.0008991083013825119 max memory_allocated 22927.85107421875 
[2025-01-16 19:11:13 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 12 loss:0.2035226821899414 norm:0.0008976180106401443 max memory_allocated 22927.85107421875 
[2025-01-16 19:11:44 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 13 loss:0.20341093838214874 norm:0.0008526826277375221 max memory_allocated 22927.85107421875 
[2025-01-16 19:12:16 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 14 loss:0.20332740247249603 norm:0.0008355696336366236 max memory_allocated 22927.85107421875 
[2025-01-16 19:12:47 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 15 loss:0.2032841444015503 norm:0.0008385888650082052 max memory_allocated 22927.85107421875 
[2025-01-16 19:13:19 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 16 loss:0.20322652161121368 norm:0.0008306756499223411 max memory_allocated 22927.85107421875 
[2025-01-16 19:13:50 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 17 loss:0.20322860777378082 norm:0.0008358470513485372 max memory_allocated 22927.85107421875 
[2025-01-16 19:14:21 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 18 loss:0.20318812131881714 norm:0.0008354021701961756 max memory_allocated 22927.85107421875 
[2025-01-16 19:14:53 root] (abq_llm_calib_config.py 361): INFO layer 25 iter 19 loss:0.2031785547733307 norm:0.0008414388867095113 max memory_allocated 22927.85107421875 
[2025-01-16 19:15:02 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 26 ===
[2025-01-16 19:15:40 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 0 loss:0.2547205090522766 norm:0.0014847342390567064 max memory_allocated 22929.52294921875 
[2025-01-16 19:16:12 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 1 loss:0.24589838087558746 norm:0.0011044701095670462 max memory_allocated 22929.52294921875 
[2025-01-16 19:16:43 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 2 loss:0.2384742945432663 norm:0.001032513566315174 max memory_allocated 22929.52294921875 
[2025-01-16 19:17:14 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 3 loss:0.23570671677589417 norm:0.0009791834745556116 max memory_allocated 22929.52294921875 
[2025-01-16 19:17:46 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 4 loss:0.23442700505256653 norm:0.0009390145423822105 max memory_allocated 22929.52294921875 
[2025-01-16 19:18:17 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 5 loss:0.23389476537704468 norm:0.00092587765539065 max memory_allocated 22929.52294921875 
[2025-01-16 19:18:49 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 6 loss:0.2336120456457138 norm:0.000910287955775857 max memory_allocated 22929.52294921875 
[2025-01-16 19:19:20 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 7 loss:0.2334161400794983 norm:0.0009137990418821573 max memory_allocated 22929.52294921875 
[2025-01-16 19:19:52 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 8 loss:0.2331535667181015 norm:0.0008823942625895143 max memory_allocated 22929.52294921875 
[2025-01-16 19:20:23 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 9 loss:0.2329537570476532 norm:0.0008398604113608599 max memory_allocated 22929.52294921875 
[2025-01-16 19:20:54 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 10 loss:0.23281124234199524 norm:0.000840422697365284 max memory_allocated 22929.52294921875 
[2025-01-16 19:21:26 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 11 loss:0.2327084243297577 norm:0.0008325929520651698 max memory_allocated 22929.52294921875 
[2025-01-16 19:21:57 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 12 loss:0.23264320194721222 norm:0.0008397461497224867 max memory_allocated 22929.52294921875 
[2025-01-16 19:22:29 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 13 loss:0.23254390060901642 norm:0.0008095166995190084 max memory_allocated 22929.52294921875 
[2025-01-16 19:23:00 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 14 loss:0.23245248198509216 norm:0.0008102272404357791 max memory_allocated 22929.52294921875 
[2025-01-16 19:23:31 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 15 loss:0.23235416412353516 norm:0.0008054784266278148 max memory_allocated 22929.52294921875 
[2025-01-16 19:24:03 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 16 loss:0.23231104016304016 norm:0.0008210281957872212 max memory_allocated 22929.52294921875 
[2025-01-16 19:24:34 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 17 loss:0.23225653171539307 norm:0.0008162031881511211 max memory_allocated 22929.52294921875 
[2025-01-16 19:25:06 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 18 loss:0.23224087059497833 norm:0.0008181752637028694 max memory_allocated 22929.52294921875 
[2025-01-16 19:25:37 root] (abq_llm_calib_config.py 361): INFO layer 26 iter 19 loss:0.23222079873085022 norm:0.0008244258351624012 max memory_allocated 22929.52294921875 
[2025-01-16 19:25:46 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 27 ===
[2025-01-16 19:26:26 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 0 loss:0.29543957114219666 norm:0.002361391671001911 max memory_allocated 22931.19482421875 
[2025-01-16 19:26:58 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 1 loss:0.2846551239490509 norm:0.0013786695199087262 max memory_allocated 22931.19482421875 
[2025-01-16 19:27:29 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 2 loss:0.2755197286605835 norm:0.0012583155184984207 max memory_allocated 22931.19482421875 
[2025-01-16 19:28:00 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 3 loss:0.2721773684024811 norm:0.0012525765923783183 max memory_allocated 22931.19482421875 
[2025-01-16 19:28:32 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 4 loss:0.27086836099624634 norm:0.0011605198960751295 max memory_allocated 22931.19482421875 
[2025-01-16 19:29:03 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 5 loss:0.2703874707221985 norm:0.001190590439364314 max memory_allocated 22931.19482421875 
[2025-01-16 19:29:35 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 6 loss:0.2700611650943756 norm:0.0011054313508793712 max memory_allocated 22931.19482421875 
[2025-01-16 19:30:06 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 7 loss:0.26987767219543457 norm:0.0011087693274021149 max memory_allocated 22931.19482421875 
[2025-01-16 19:30:38 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 8 loss:0.2696942389011383 norm:0.0011134578380733728 max memory_allocated 22931.19482421875 
[2025-01-16 19:31:09 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 9 loss:0.269488662481308 norm:0.0010834268759936094 max memory_allocated 22931.19482421875 
[2025-01-16 19:31:40 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 10 loss:0.2693440318107605 norm:0.001046781544573605 max memory_allocated 22931.19482421875 
[2025-01-16 19:32:12 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 11 loss:0.2692191004753113 norm:0.0010530524887144566 max memory_allocated 22931.19482421875 
[2025-01-16 19:32:43 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 12 loss:0.26910048723220825 norm:0.0010589391458779573 max memory_allocated 22931.19482421875 
[2025-01-16 19:33:15 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 13 loss:0.269019216299057 norm:0.0010510215070098639 max memory_allocated 22931.19482421875 
[2025-01-16 19:33:46 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 14 loss:0.2689377963542938 norm:0.0010444370564073324 max memory_allocated 22931.19482421875 
[2025-01-16 19:34:18 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 15 loss:0.2688831686973572 norm:0.001051692757755518 max memory_allocated 22931.19482421875 
[2025-01-16 19:34:49 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 16 loss:0.2688114047050476 norm:0.001019226387143135 max memory_allocated 22931.19482421875 
[2025-01-16 19:35:20 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 17 loss:0.2687811553478241 norm:0.0010138292564079165 max memory_allocated 22931.19482421875 
[2025-01-16 19:35:52 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 18 loss:0.26873672008514404 norm:0.0009963292395696044 max memory_allocated 22931.19482421875 
[2025-01-16 19:36:23 root] (abq_llm_calib_config.py 361): INFO layer 27 iter 19 loss:0.26869791746139526 norm:0.001029729493893683 max memory_allocated 22931.19482421875 
[2025-01-16 19:36:32 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 28 ===
[2025-01-16 19:36:40 root] (abq_llm_calib_config.py 301): INFO use compensation vector
[2025-01-16 19:37:11 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 0 loss:0.3370853066444397 norm:0.008783742785453796 max memory_allocated 22932.98193359375 
[2025-01-16 19:37:43 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 1 loss:0.3262251317501068 norm:0.0067859613336622715 max memory_allocated 22932.98193359375 
[2025-01-16 19:38:14 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 2 loss:0.31694671511650085 norm:0.00497591495513916 max memory_allocated 22932.98193359375 
[2025-01-16 19:38:46 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 3 loss:0.3134903311729431 norm:0.004045866895467043 max memory_allocated 22932.98193359375 
[2025-01-16 19:39:17 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 4 loss:0.3121192455291748 norm:0.0033301201183348894 max memory_allocated 22932.98193359375 
[2025-01-16 19:39:49 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 5 loss:0.3115924894809723 norm:0.0029141821432858706 max memory_allocated 22932.98193359375 
[2025-01-16 19:40:21 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 6 loss:0.31123921275138855 norm:0.0028407168574631214 max memory_allocated 22932.98193359375 
[2025-01-16 19:40:52 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 7 loss:0.31104254722595215 norm:0.0028655792120844126 max memory_allocated 22932.98193359375 
[2025-01-16 19:41:24 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 8 loss:0.3108161985874176 norm:0.002733401022851467 max memory_allocated 22932.98193359375 
[2025-01-16 19:41:55 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 9 loss:0.3105993866920471 norm:0.002603204222396016 max memory_allocated 22932.98193359375 
[2025-01-16 19:42:27 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 10 loss:0.3103908598423004 norm:0.002432282315567136 max memory_allocated 22932.98193359375 
[2025-01-16 19:42:58 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 11 loss:0.3102162480354309 norm:0.0023271185345947742 max memory_allocated 22932.98193359375 
[2025-01-16 19:43:30 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 12 loss:0.31007903814315796 norm:0.002259312430396676 max memory_allocated 22932.98193359375 
[2025-01-16 19:44:01 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 13 loss:0.31007120013237 norm:0.0023016873747110367 max memory_allocated 22932.98193359375 
[2025-01-16 19:44:33 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 14 loss:0.31001460552215576 norm:0.0022733912337571383 max memory_allocated 22932.98193359375 
[2025-01-16 19:45:04 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 15 loss:0.3099631369113922 norm:0.0022409576922655106 max memory_allocated 22932.98193359375 
[2025-01-16 19:45:36 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 16 loss:0.30993929505348206 norm:0.002301218919456005 max memory_allocated 22932.98193359375 
[2025-01-16 19:46:07 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 17 loss:0.30986663699150085 norm:0.002190923085436225 max memory_allocated 22932.98193359375 
[2025-01-16 19:46:39 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 18 loss:0.3098314106464386 norm:0.0022430350072681904 max memory_allocated 22932.98193359375 
[2025-01-16 19:47:10 root] (abq_llm_calib_config.py 361): INFO layer 28 iter 19 loss:0.3097572326660156 norm:0.0022079439368098974 max memory_allocated 22932.98193359375 
[2025-01-16 19:47:19 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 29 ===
[2025-01-16 19:47:29 root] (abq_llm_calib_config.py 301): INFO use compensation vector
[2025-01-16 19:48:00 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 0 loss:0.3960045576095581 norm:0.01509272214025259 max memory_allocated 22934.65380859375 
[2025-01-16 19:48:32 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 1 loss:0.3793403208255768 norm:0.010608989745378494 max memory_allocated 22934.65380859375 
[2025-01-16 19:49:03 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 2 loss:0.3665253520011902 norm:0.007225350476801395 max memory_allocated 22934.65380859375 
[2025-01-16 19:49:35 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 3 loss:0.36201515793800354 norm:0.005895831622183323 max memory_allocated 22934.65380859375 
[2025-01-16 19:50:06 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 4 loss:0.36039242148399353 norm:0.004948959220200777 max memory_allocated 22934.65380859375 
[2025-01-16 19:50:38 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 5 loss:0.35961857438087463 norm:0.004199446178972721 max memory_allocated 22934.65380859375 
[2025-01-16 19:51:09 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 6 loss:0.35912609100341797 norm:0.003657248802483082 max memory_allocated 22934.65380859375 
[2025-01-16 19:51:41 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 7 loss:0.35881760716438293 norm:0.0034602759405970573 max memory_allocated 22934.65380859375 
[2025-01-16 19:52:13 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 8 loss:0.3587395250797272 norm:0.0036416305229067802 max memory_allocated 22934.65380859375 
[2025-01-16 19:52:44 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 9 loss:0.35848137736320496 norm:0.0035438225604593754 max memory_allocated 22934.65380859375 
[2025-01-16 19:53:16 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 10 loss:0.3582513630390167 norm:0.0033050870988518 max memory_allocated 22934.65380859375 
[2025-01-16 19:53:47 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 11 loss:0.35810586810112 norm:0.003220605431124568 max memory_allocated 22934.65380859375 
[2025-01-16 19:54:19 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 12 loss:0.3579621911048889 norm:0.0030620202887803316 max memory_allocated 22934.65380859375 
[2025-01-16 19:54:50 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 13 loss:0.3577907383441925 norm:0.0029705814085900784 max memory_allocated 22934.65380859375 
[2025-01-16 19:55:22 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 14 loss:0.35779038071632385 norm:0.0030025532469153404 max memory_allocated 22934.65380859375 
[2025-01-16 19:55:53 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 15 loss:0.3577342927455902 norm:0.0029984256252646446 max memory_allocated 22934.65380859375 
[2025-01-16 19:56:25 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 16 loss:0.35760462284088135 norm:0.0028189111035317183 max memory_allocated 22934.65380859375 
[2025-01-16 19:56:56 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 17 loss:0.35756102204322815 norm:0.00276007829234004 max memory_allocated 22934.65380859375 
[2025-01-16 19:57:28 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 18 loss:0.35750913619995117 norm:0.0027297325432300568 max memory_allocated 22934.65380859375 
[2025-01-16 19:57:59 root] (abq_llm_calib_config.py 361): INFO layer 29 iter 19 loss:0.3574654161930084 norm:0.0027371146716177464 max memory_allocated 22934.65380859375 
[2025-01-16 19:58:08 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 30 ===
[2025-01-16 19:58:18 root] (abq_llm_calib_config.py 301): INFO use compensation vector
[2025-01-16 19:58:49 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 0 loss:2.103121280670166 norm:0.326318621635437 max memory_allocated 22936.32568359375 
[2025-01-16 19:59:21 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 1 loss:1.6556551456451416 norm:2.5730996131896973 max memory_allocated 22936.32568359375 
[2025-01-16 19:59:52 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 2 loss:1.0785419940948486 norm:0.7135233283042908 max memory_allocated 22936.32568359375 
[2025-01-16 20:00:24 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 3 loss:0.8887684345245361 norm:0.45392531156539917 max memory_allocated 22936.32568359375 
[2025-01-16 20:00:55 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 4 loss:0.8162841200828552 norm:0.5571789741516113 max memory_allocated 22936.32568359375 
[2025-01-16 20:01:27 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 5 loss:0.8357852697372437 norm:6.266217231750488 max memory_allocated 22936.32568359375 
[2025-01-16 20:01:58 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 6 loss:0.7087393999099731 norm:0.2732030153274536 max memory_allocated 22936.32568359375 
[2025-01-16 20:02:30 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 7 loss:0.6922082901000977 norm:0.24096959829330444 max memory_allocated 22936.32568359375 
[2025-01-16 20:03:01 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 8 loss:0.6684445142745972 norm:0.3084922432899475 max memory_allocated 22936.32568359375 
[2025-01-16 20:03:33 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 9 loss:0.6486436128616333 norm:0.2096838355064392 max memory_allocated 22936.32568359375 
[2025-01-16 20:04:04 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 10 loss:0.6311701536178589 norm:0.2294541299343109 max memory_allocated 22936.32568359375 
[2025-01-16 20:04:36 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 11 loss:0.619713306427002 norm:0.25893881916999817 max memory_allocated 22936.32568359375 
[2025-01-16 20:05:08 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 12 loss:0.6090115904808044 norm:0.20058859884738922 max memory_allocated 22936.32568359375 
[2025-01-16 20:05:39 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 13 loss:0.5991190671920776 norm:0.20544645190238953 max memory_allocated 22936.32568359375 
[2025-01-16 20:06:11 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 14 loss:0.5929582715034485 norm:0.18349619209766388 max memory_allocated 22936.32568359375 
[2025-01-16 20:06:42 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 15 loss:0.5848239064216614 norm:0.16768547892570496 max memory_allocated 22936.32568359375 
[2025-01-16 20:07:14 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 16 loss:0.578553318977356 norm:0.1721927970647812 max memory_allocated 22936.32568359375 
[2025-01-16 20:07:45 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 17 loss:0.5703731775283813 norm:0.15241821110248566 max memory_allocated 22936.32568359375 
[2025-01-16 20:08:17 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 18 loss:0.5670963525772095 norm:0.13016732037067413 max memory_allocated 22936.32568359375 
[2025-01-16 20:08:48 root] (abq_llm_calib_config.py 361): INFO layer 30 iter 19 loss:0.5585919618606567 norm:0.14586913585662842 max memory_allocated 22936.32568359375 
[2025-01-16 20:08:57 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 31 ===
[2025-01-16 20:09:07 root] (abq_llm_calib_config.py 301): INFO use compensation vector
[2025-01-16 20:09:38 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 0 loss:0.8274402618408203 norm:0.05126965045928955 max memory_allocated 22937.99755859375 
[2025-01-16 20:10:10 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 1 loss:0.7803855538368225 norm:0.03684846684336662 max memory_allocated 22937.99755859375 
[2025-01-16 20:10:41 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 2 loss:0.7462011575698853 norm:0.02589123696088791 max memory_allocated 22937.99755859375 
[2025-01-16 20:11:13 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 3 loss:0.7367083430290222 norm:0.023573782294988632 max memory_allocated 22937.99755859375 
[2025-01-16 20:11:44 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 4 loss:0.7315404415130615 norm:0.021300630643963814 max memory_allocated 22937.99755859375 
[2025-01-16 20:12:16 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 5 loss:0.7286401391029358 norm:0.019447078928351402 max memory_allocated 22937.99755859375 
[2025-01-16 20:12:47 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 6 loss:0.7259371280670166 norm:0.018309129402041435 max memory_allocated 22937.99755859375 
[2025-01-16 20:13:19 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 7 loss:0.7242213487625122 norm:0.017471781000494957 max memory_allocated 22937.99755859375 
[2025-01-16 20:13:50 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 8 loss:0.7227423787117004 norm:0.017555268481373787 max memory_allocated 22937.99755859375 
[2025-01-16 20:14:22 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 9 loss:0.7216558456420898 norm:0.017036203294992447 max memory_allocated 22937.99755859375 
[2025-01-16 20:14:53 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 10 loss:0.7210777997970581 norm:0.017088280990719795 max memory_allocated 22937.99755859375 
[2025-01-16 20:15:25 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 11 loss:0.7204903960227966 norm:0.017049936577677727 max memory_allocated 22937.99755859375 
[2025-01-16 20:15:56 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 12 loss:0.7205259203910828 norm:0.01766178384423256 max memory_allocated 22937.99755859375 
[2025-01-16 20:16:28 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 13 loss:0.7187707424163818 norm:0.01592838764190674 max memory_allocated 22937.99755859375 
[2025-01-16 20:16:59 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 14 loss:0.7184165120124817 norm:0.015636427327990532 max memory_allocated 22937.99755859375 
[2025-01-16 20:17:31 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 15 loss:0.7180621027946472 norm:0.01564086228609085 max memory_allocated 22937.99755859375 
[2025-01-16 20:18:03 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 16 loss:0.7190176248550415 norm:0.017304956912994385 max memory_allocated 22937.99755859375 
[2025-01-16 20:18:34 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 17 loss:0.7193931341171265 norm:0.01812691055238247 max memory_allocated 22937.99755859375 
[2025-01-16 20:19:06 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 18 loss:0.718586802482605 norm:0.017239300534129143 max memory_allocated 22937.99755859375 
[2025-01-16 20:19:37 root] (abq_llm_calib_config.py 361): INFO layer 31 iter 19 loss:0.717867374420166 norm:0.01612773723900318 max memory_allocated 22937.99755859375 
[2025-01-16 20:19:46 root] (main_calib_config.py 365): INFO 20695.441831111908
[2025-01-16 20:20:27 root] (main_calib_config.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-01-16 20:21:37 root] (main_calib_config.py 159): INFO wikitext2 : 7.754012107849121
[2025-01-16 20:21:37 root] (main_calib_config.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-01-16 20:23:26 root] (main_calib_config.py 159): INFO c4 : 9.871857643127441
[2025-01-16 21:41:29 root] (main_calib_config.py 170): INFO {'wikitext2': 7.754012107849121, 'c4': 9.871857643127441, 'results': {'hellaswag': {'acc': 0.5495917147978491, 'acc_stderr': 0.004965177633049919, 'acc_norm': 0.709520015933081, 'acc_norm_stderr': 0.004530560646902539}, 'winogrande': {'acc': 0.6432517758484609, 'acc_stderr': 0.013463393958028721}}, 'versions': {'hellaswag': 0, 'winogrande': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
