[2025-01-18 11:23:40 root] (main_calib_config.py 270): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-chat-hf', cache_dir='./cache', output_dir='./log/Llama-2-7b-chat-hf-w4a4-117-symmetrci', save_dir='./quant/Llama-2-7b-chat-hf-w4a4-117/save_dir-symmetric', resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=True, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='./log/Llama-2-7b-chat-hf-116/quant_map_Llama-2-7b-chat-hf.pkl')
[2025-01-18 11:23:42 root] (main_calib_config.py 337): INFO === start quantization ===
[2025-01-18 11:23:42 root] (main_calib_config.py 343): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-01-18 11:23:42 root] (abq_llm_calib_config.py 82): INFO Starting ...
[2025-01-18 11:23:42 root] (abq_llm_calib_config.py 89): INFO Loaded quant_map from ./log/Llama-2-7b-chat-hf-116/quant_map_Llama-2-7b-chat-hf.pkl
[2025-01-18 11:23:44 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 0 ===
[2025-01-18 11:23:48 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-01-18 11:24:18 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 0 loss:0.019646363332867622 norm:0.015577597543597221 max memory_allocated 22886.49365234375 
[2025-01-18 11:24:49 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 1 loss:0.010982850566506386 norm:0.008353632874786854 max memory_allocated 22886.49365234375 
[2025-01-18 11:25:20 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 2 loss:0.008159252814948559 norm:0.006059333682060242 max memory_allocated 22886.49365234375 
[2025-01-18 11:25:50 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 3 loss:0.006818506401032209 norm:0.004871797282248735 max memory_allocated 22886.49365234375 
[2025-01-18 11:26:21 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 4 loss:0.0060822442173957825 norm:0.003908638376742601 max memory_allocated 22886.49365234375 
[2025-01-18 11:26:52 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 5 loss:0.00591201102361083 norm:0.0036294215824455023 max memory_allocated 22886.49365234375 
[2025-01-18 11:27:23 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 6 loss:0.00573055911809206 norm:0.00313286273740232 max memory_allocated 22886.49365234375 
[2025-01-18 11:27:54 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 7 loss:0.005532651208341122 norm:0.0026896994095295668 max memory_allocated 22886.49365234375 
[2025-01-18 11:28:25 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 8 loss:0.005429590120911598 norm:0.002421923680230975 max memory_allocated 22886.49365234375 
[2025-01-18 11:28:56 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 9 loss:0.005338544957339764 norm:0.002306341892108321 max memory_allocated 22886.49365234375 
[2025-01-18 11:29:27 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 10 loss:0.005264108534902334 norm:0.0021255146712064743 max memory_allocated 22886.49365234375 
[2025-01-18 11:29:58 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 11 loss:0.005179825238883495 norm:0.002071272348985076 max memory_allocated 22886.49365234375 
[2025-01-18 11:30:29 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 12 loss:0.0051504778675735 norm:0.001988812815397978 max memory_allocated 22886.49365234375 
[2025-01-18 11:31:00 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 13 loss:0.0051445686258375645 norm:0.0020408101845532656 max memory_allocated 22886.49365234375 
[2025-01-18 11:31:31 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 14 loss:0.005073352251201868 norm:0.001853116205893457 max memory_allocated 22886.49365234375 
[2025-01-18 11:32:02 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 15 loss:0.0050102765671908855 norm:0.0016504661180078983 max memory_allocated 22886.49365234375 
[2025-01-18 11:32:33 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 16 loss:0.005014465190470219 norm:0.001800022553652525 max memory_allocated 22886.49365234375 
[2025-01-18 11:33:04 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 17 loss:0.0049973344430327415 norm:0.0016971230506896973 max memory_allocated 22886.49365234375 
[2025-01-18 11:33:35 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 18 loss:0.0049782246351242065 norm:0.001618700916878879 max memory_allocated 22886.49365234375 
[2025-01-18 11:34:06 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 19 loss:0.004947138950228691 norm:0.0015744487755000591 max memory_allocated 22886.49365234375 
[2025-01-18 11:34:15 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 1 ===
[2025-01-18 11:34:17 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-01-18 11:34:48 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 0 loss:0.054720982909202576 norm:0.035043906420469284 max memory_allocated 22888.16552734375 
[2025-01-18 11:35:19 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 1 loss:0.03796796500682831 norm:0.016633475199341774 max memory_allocated 22888.16552734375 
[2025-01-18 11:35:50 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 2 loss:0.032817110419273376 norm:0.019935619086027145 max memory_allocated 22888.16552734375 
[2025-01-18 11:36:21 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 3 loss:0.02941436506807804 norm:0.01670754700899124 max memory_allocated 22888.16552734375 
[2025-01-18 11:36:52 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 4 loss:0.028500057756900787 norm:0.013049264438450336 max memory_allocated 22888.16552734375 
[2025-01-18 11:37:23 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 5 loss:0.02798961102962494 norm:0.01194750890135765 max memory_allocated 22888.16552734375 
[2025-01-18 11:37:54 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 6 loss:0.027253368869423866 norm:0.01100283395498991 max memory_allocated 22888.16552734375 
[2025-01-18 11:38:25 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 7 loss:0.027060359716415405 norm:0.01109769195318222 max memory_allocated 22888.16552734375 
[2025-01-18 11:38:56 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 8 loss:0.02685518004000187 norm:0.011005369015038013 max memory_allocated 22888.16552734375 
[2025-01-18 11:39:27 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 9 loss:0.026679569855332375 norm:0.01120894867926836 max memory_allocated 22888.16552734375 
[2025-01-18 11:39:58 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 10 loss:0.026258552446961403 norm:0.010456165298819542 max memory_allocated 22888.16552734375 
[2025-01-18 11:40:29 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 11 loss:0.026360638439655304 norm:0.01026457641273737 max memory_allocated 22888.16552734375 
[2025-01-18 11:41:01 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 12 loss:0.026180602610111237 norm:0.01009841077029705 max memory_allocated 22888.16552734375 
[2025-01-18 11:41:32 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 13 loss:0.025881078094244003 norm:0.009453614242374897 max memory_allocated 22888.16552734375 
[2025-01-18 11:42:03 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 14 loss:0.025670595467090607 norm:0.009584130719304085 max memory_allocated 22888.16552734375 
[2025-01-18 11:42:34 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 15 loss:0.025728799402713776 norm:0.009165256284177303 max memory_allocated 22888.16552734375 
[2025-01-18 11:43:05 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 16 loss:0.02567482739686966 norm:0.00973505899310112 max memory_allocated 22888.16552734375 
[2025-01-18 11:43:36 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 17 loss:0.02556055225431919 norm:0.009133273735642433 max memory_allocated 22888.16552734375 
[2025-01-18 11:44:07 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 18 loss:0.025779185816645622 norm:0.010173311457037926 max memory_allocated 22888.16552734375 
[2025-01-18 11:44:38 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 19 loss:0.025552574545145035 norm:0.009266634471714497 max memory_allocated 22888.16552734375 
[2025-01-18 11:44:47 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 2 ===
[2025-01-18 11:44:49 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-01-18 11:45:20 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 0 loss:0.05922305956482887 norm:0.014421673491597176 max memory_allocated 22889.83740234375 
[2025-01-18 11:45:51 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 1 loss:0.04685094207525253 norm:0.009478844702243805 max memory_allocated 22889.83740234375 
[2025-01-18 11:46:22 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 2 loss:0.04140852764248848 norm:0.006976572331041098 max memory_allocated 22889.83740234375 
[2025-01-18 11:46:53 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 3 loss:0.038237594068050385 norm:0.005232189781963825 max memory_allocated 22889.83740234375 
[2025-01-18 11:47:25 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 4 loss:0.03669236972928047 norm:0.004078802652657032 max memory_allocated 22889.83740234375 
[2025-01-18 11:47:56 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 5 loss:0.035732854157686234 norm:0.003391972044482827 max memory_allocated 22889.83740234375 
[2025-01-18 11:48:27 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 6 loss:0.03509822115302086 norm:0.0027911202050745487 max memory_allocated 22889.83740234375 
[2025-01-18 11:48:58 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 7 loss:0.03467223420739174 norm:0.002366896951571107 max memory_allocated 22889.83740234375 
[2025-01-18 11:49:29 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 8 loss:0.0344940721988678 norm:0.002185824792832136 max memory_allocated 22889.83740234375 
[2025-01-18 11:50:00 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 9 loss:0.03437729924917221 norm:0.002216137247160077 max memory_allocated 22889.83740234375 
[2025-01-18 11:50:31 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 10 loss:0.034293029457330704 norm:0.0020931002218276262 max memory_allocated 22889.83740234375 
[2025-01-18 11:51:02 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 11 loss:0.03421255201101303 norm:0.0019221605034545064 max memory_allocated 22889.83740234375 
[2025-01-18 11:51:33 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 12 loss:0.034190092235803604 norm:0.001982796238735318 max memory_allocated 22889.83740234375 
[2025-01-18 11:52:04 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 13 loss:0.03412254527211189 norm:0.0018076843116432428 max memory_allocated 22889.83740234375 
[2025-01-18 11:52:35 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 14 loss:0.03409135341644287 norm:0.0018436913378536701 max memory_allocated 22889.83740234375 
[2025-01-18 11:53:06 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 15 loss:0.03403880447149277 norm:0.001802128623239696 max memory_allocated 22889.83740234375 
[2025-01-18 11:53:37 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 16 loss:0.0340602770447731 norm:0.0018832525238394737 max memory_allocated 22889.83740234375 
[2025-01-18 11:54:08 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 17 loss:0.034064214676618576 norm:0.0018932739039883018 max memory_allocated 22889.83740234375 
[2025-01-18 11:54:39 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 18 loss:0.03403536230325699 norm:0.0018969604279845953 max memory_allocated 22889.83740234375 
[2025-01-18 11:55:11 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 19 loss:0.034047242254018784 norm:0.0018857892137020826 max memory_allocated 22889.83740234375 
[2025-01-18 11:55:19 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 3 ===
[2025-01-18 11:55:53 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 0 loss:0.07201675325632095 norm:0.0047645871527493 max memory_allocated 22891.39404296875 
[2025-01-18 11:56:24 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 1 loss:0.05854911357164383 norm:0.0026288244407624006 max memory_allocated 22891.39404296875 
[2025-01-18 11:56:55 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 2 loss:0.052539680153131485 norm:0.002085625659674406 max memory_allocated 22891.39404296875 
[2025-01-18 11:57:26 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 3 loss:0.04908662289381027 norm:0.0017959049437195063 max memory_allocated 22891.39404296875 
[2025-01-18 11:57:57 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 4 loss:0.04739414155483246 norm:0.0016858032904565334 max memory_allocated 22891.39404296875 
[2025-01-18 11:58:28 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 5 loss:0.04646125063300133 norm:0.0016550002619624138 max memory_allocated 22891.39404296875 
[2025-01-18 11:58:59 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 6 loss:0.04612187668681145 norm:0.0016263613943010569 max memory_allocated 22891.39404296875 
[2025-01-18 11:59:29 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 7 loss:0.04601562023162842 norm:0.0016690311022102833 max memory_allocated 22891.39404296875 
[2025-01-18 12:00:00 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 8 loss:0.045922331511974335 norm:0.0016111445147544146 max memory_allocated 22891.39404296875 
[2025-01-18 12:00:31 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 9 loss:0.04589085653424263 norm:0.001586961094290018 max memory_allocated 22891.39404296875 
[2025-01-18 12:01:02 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 10 loss:0.04585142061114311 norm:0.0015954452101141214 max memory_allocated 22891.39404296875 
[2025-01-18 12:01:33 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 11 loss:0.045832302421331406 norm:0.0016467691166326404 max memory_allocated 22891.39404296875 
[2025-01-18 12:02:04 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 12 loss:0.045811016112565994 norm:0.001597098307684064 max memory_allocated 22891.39404296875 
[2025-01-18 12:02:35 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 13 loss:0.045752715319395065 norm:0.0019277628744021058 max memory_allocated 22891.39404296875 
[2025-01-18 12:03:06 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 14 loss:0.04572499170899391 norm:0.001545171719044447 max memory_allocated 22891.39404296875 
[2025-01-18 12:03:37 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 15 loss:0.04571440815925598 norm:0.001567797502502799 max memory_allocated 22891.39404296875 
[2025-01-18 12:04:08 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 16 loss:0.04569701850414276 norm:0.0015225892420858145 max memory_allocated 22891.39404296875 
[2025-01-18 12:04:39 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 17 loss:0.0456574410200119 norm:0.0015248474664986134 max memory_allocated 22891.39404296875 
[2025-01-18 12:05:10 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 18 loss:0.04564980790019035 norm:0.0015652516158297658 max memory_allocated 22891.39404296875 
[2025-01-18 12:05:41 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 19 loss:0.04563332349061966 norm:0.0015310588059946895 max memory_allocated 22891.39404296875 
[2025-01-18 12:05:50 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 4 ===
[2025-01-18 12:06:23 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 0 loss:0.10010171681642532 norm:0.004999240394681692 max memory_allocated 22893.06591796875 
[2025-01-18 12:06:54 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 1 loss:0.07867634296417236 norm:0.0024964301846921444 max memory_allocated 22893.06591796875 
[2025-01-18 12:07:25 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 2 loss:0.06827996671199799 norm:0.0020739685278385878 max memory_allocated 22893.06591796875 
[2025-01-18 12:07:56 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 3 loss:0.0625077411532402 norm:0.001907349331304431 max memory_allocated 22893.06591796875 
[2025-01-18 12:08:27 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 4 loss:0.05981754511594772 norm:0.0016711001517251134 max memory_allocated 22893.06591796875 
[2025-01-18 12:08:58 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 5 loss:0.05836072936654091 norm:0.0015472922241315246 max memory_allocated 22893.06591796875 
[2025-01-18 12:09:29 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 6 loss:0.057747893035411835 norm:0.0014990679919719696 max memory_allocated 22893.06591796875 
[2025-01-18 12:10:00 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 7 loss:0.05744088068604469 norm:0.001505644409917295 max memory_allocated 22893.06591796875 
[2025-01-18 12:10:31 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 8 loss:0.05715039372444153 norm:0.0014621083391830325 max memory_allocated 22893.06591796875 
[2025-01-18 12:11:02 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 9 loss:0.05698269605636597 norm:0.0015018950216472149 max memory_allocated 22893.06591796875 
[2025-01-18 12:11:33 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 10 loss:0.05683841183781624 norm:0.0015153487911447883 max memory_allocated 22893.06591796875 
[2025-01-18 12:12:04 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 11 loss:0.05673469230532646 norm:0.0015200234483927488 max memory_allocated 22893.06591796875 
[2025-01-18 12:12:35 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 12 loss:0.05669192597270012 norm:0.0014968994073569775 max memory_allocated 22893.06591796875 
[2025-01-18 12:13:06 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 13 loss:0.05660398676991463 norm:0.0014526601880788803 max memory_allocated 22893.06591796875 
[2025-01-18 12:13:36 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 14 loss:0.0564936101436615 norm:0.0014213453978300095 max memory_allocated 22893.06591796875 
[2025-01-18 12:14:07 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 15 loss:0.05644771829247475 norm:0.0014802428195253015 max memory_allocated 22893.06591796875 
[2025-01-18 12:14:38 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 16 loss:0.05637430027127266 norm:0.001426276401616633 max memory_allocated 22893.06591796875 
[2025-01-18 12:15:09 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 17 loss:0.05639190226793289 norm:0.0014461552491411567 max memory_allocated 22893.06591796875 
[2025-01-18 12:15:40 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 18 loss:0.056346695870161057 norm:0.0014290338149294257 max memory_allocated 22893.06591796875 
[2025-01-18 12:16:11 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 19 loss:0.05631504952907562 norm:0.001413899241015315 max memory_allocated 22893.06591796875 
[2025-01-18 12:16:20 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 5 ===
[2025-01-18 12:16:54 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 0 loss:0.10794051736593246 norm:0.006128679029643536 max memory_allocated 22894.73779296875 
[2025-01-18 12:17:25 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 1 loss:0.08806433528661728 norm:0.003376897657290101 max memory_allocated 22894.73779296875 
[2025-01-18 12:17:55 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 2 loss:0.07726535201072693 norm:0.002894066506996751 max memory_allocated 22894.73779296875 
[2025-01-18 12:18:26 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 3 loss:0.07147492468357086 norm:0.002501533832401037 max memory_allocated 22894.73779296875 
[2025-01-18 12:18:57 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 4 loss:0.06857757270336151 norm:0.002236816333606839 max memory_allocated 22894.73779296875 
[2025-01-18 12:19:28 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 5 loss:0.06711088120937347 norm:0.0021291114389896393 max memory_allocated 22894.73779296875 
[2025-01-18 12:19:59 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 6 loss:0.06640700995922089 norm:0.002089776797220111 max memory_allocated 22894.73779296875 
[2025-01-18 12:20:30 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 7 loss:0.06603820621967316 norm:0.0020239809527993202 max memory_allocated 22894.73779296875 
[2025-01-18 12:21:01 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 8 loss:0.06571970880031586 norm:0.001917380141094327 max memory_allocated 22894.73779296875 
[2025-01-18 12:21:32 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 9 loss:0.06553423404693604 norm:0.0019134067697450519 max memory_allocated 22894.73779296875 
[2025-01-18 12:22:03 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 10 loss:0.06537622958421707 norm:0.0018598590977489948 max memory_allocated 22894.73779296875 
[2025-01-18 12:22:34 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 11 loss:0.06530337035655975 norm:0.0019037006422877312 max memory_allocated 22894.73779296875 
[2025-01-18 12:23:05 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 12 loss:0.06522270292043686 norm:0.0018426980823278427 max memory_allocated 22894.73779296875 
[2025-01-18 12:23:36 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 13 loss:0.06517529487609863 norm:0.0018704324029386044 max memory_allocated 22894.73779296875 
[2025-01-18 12:24:07 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 14 loss:0.06509832292795181 norm:0.0018899465212598443 max memory_allocated 22894.73779296875 
[2025-01-18 12:24:38 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 15 loss:0.06503620743751526 norm:0.0018927565542981029 max memory_allocated 22894.73779296875 
[2025-01-18 12:25:09 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 16 loss:0.06497391313314438 norm:0.0018430378986522555 max memory_allocated 22894.73779296875 
[2025-01-18 12:25:40 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 17 loss:0.06493878364562988 norm:0.0018272004090249538 max memory_allocated 22894.73779296875 
[2025-01-18 12:26:11 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 18 loss:0.0649128258228302 norm:0.0018549752421677113 max memory_allocated 22894.73779296875 
[2025-01-18 12:26:42 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 19 loss:0.06485728919506073 norm:0.0017986743478104472 max memory_allocated 22894.73779296875 
[2025-01-18 12:26:50 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 6 ===
[2025-01-18 12:27:24 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 0 loss:0.11562368273735046 norm:0.00708987470716238 max memory_allocated 22896.40966796875 
[2025-01-18 12:27:55 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 1 loss:0.09612935781478882 norm:0.003465872723609209 max memory_allocated 22896.40966796875 
[2025-01-18 12:28:26 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 2 loss:0.0861402079463005 norm:0.002694466384127736 max memory_allocated 22896.40966796875 
[2025-01-18 12:28:57 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 3 loss:0.08032269775867462 norm:0.0024298084899783134 max memory_allocated 22896.40966796875 
[2025-01-18 12:29:28 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 4 loss:0.07766304165124893 norm:0.0023320764303207397 max memory_allocated 22896.40966796875 
[2025-01-18 12:29:59 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 5 loss:0.0764024555683136 norm:0.002230601152405143 max memory_allocated 22896.40966796875 
[2025-01-18 12:30:30 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 6 loss:0.0758788138628006 norm:0.0021394644863903522 max memory_allocated 22896.40966796875 
[2025-01-18 12:31:01 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 7 loss:0.0756140947341919 norm:0.002120337216183543 max memory_allocated 22896.40966796875 
[2025-01-18 12:31:31 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 8 loss:0.07537630200386047 norm:0.0020165240857750177 max memory_allocated 22896.40966796875 
[2025-01-18 12:32:02 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 9 loss:0.07519087195396423 norm:0.0020042043179273605 max memory_allocated 22896.40966796875 
[2025-01-18 12:32:33 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 10 loss:0.07503437995910645 norm:0.0019446033984422684 max memory_allocated 22896.40966796875 
[2025-01-18 12:33:04 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 11 loss:0.07490220665931702 norm:0.0019724913872778416 max memory_allocated 22896.40966796875 
[2025-01-18 12:33:35 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 12 loss:0.07480715960264206 norm:0.0019338408019393682 max memory_allocated 22896.40966796875 
[2025-01-18 12:34:06 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 13 loss:0.074770487844944 norm:0.002003786386922002 max memory_allocated 22896.40966796875 
[2025-01-18 12:34:37 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 14 loss:0.07469938695430756 norm:0.00196965248323977 max memory_allocated 22896.40966796875 
[2025-01-18 12:35:08 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 15 loss:0.07469645887613297 norm:0.0019268770702183247 max memory_allocated 22896.40966796875 
[2025-01-18 12:35:39 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 16 loss:0.0746496170759201 norm:0.0020063542760908604 max memory_allocated 22896.40966796875 
[2025-01-18 12:36:10 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 17 loss:0.07463114708662033 norm:0.0019294756930321455 max memory_allocated 22896.40966796875 
[2025-01-18 12:36:41 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 18 loss:0.07457487285137177 norm:0.0019130849977955222 max memory_allocated 22896.40966796875 
[2025-01-18 12:37:12 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 19 loss:0.0745726153254509 norm:0.0018525405321270227 max memory_allocated 22896.40966796875 
[2025-01-18 12:37:21 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 7 ===
[2025-01-18 12:37:54 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 0 loss:0.15874448418617249 norm:0.014301690272986889 max memory_allocated 22898.08154296875 
[2025-01-18 12:38:25 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 1 loss:0.12307018041610718 norm:0.004998304881155491 max memory_allocated 22898.08154296875 
[2025-01-18 12:38:56 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 2 loss:0.10534771531820297 norm:0.0038364031352102757 max memory_allocated 22898.08154296875 
[2025-01-18 12:39:27 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 3 loss:0.09641584753990173 norm:0.002988975727930665 max memory_allocated 22898.08154296875 
[2025-01-18 12:39:58 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 4 loss:0.09170398116111755 norm:0.0025597368367016315 max memory_allocated 22898.08154296875 
[2025-01-18 12:40:29 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 5 loss:0.08931063115596771 norm:0.00236681429669261 max memory_allocated 22898.08154296875 
[2025-01-18 12:41:00 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 6 loss:0.08817073702812195 norm:0.0023285960778594017 max memory_allocated 22898.08154296875 
[2025-01-18 12:41:31 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 7 loss:0.087424136698246 norm:0.0022077024914324284 max memory_allocated 22898.08154296875 
[2025-01-18 12:42:02 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 8 loss:0.08695846796035767 norm:0.0022159763611853123 max memory_allocated 22898.08154296875 
[2025-01-18 12:42:33 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 9 loss:0.08657389134168625 norm:0.0021282071247696877 max memory_allocated 22898.08154296875 
[2025-01-18 12:43:04 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 10 loss:0.0863119512796402 norm:0.0020204330794513226 max memory_allocated 22898.08154296875 
[2025-01-18 12:43:35 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 11 loss:0.08612525463104248 norm:0.0019735421519726515 max memory_allocated 22898.08154296875 
[2025-01-18 12:44:06 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 12 loss:0.08597997575998306 norm:0.0019685407169163227 max memory_allocated 22898.08154296875 
[2025-01-18 12:44:37 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 13 loss:0.08575110137462616 norm:0.001911953673698008 max memory_allocated 22898.08154296875 
[2025-01-18 12:45:08 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 14 loss:0.08559802919626236 norm:0.001870258478447795 max memory_allocated 22898.08154296875 
[2025-01-18 12:45:39 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 15 loss:0.085440993309021 norm:0.0018806547159329057 max memory_allocated 22898.08154296875 
[2025-01-18 12:46:10 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 16 loss:0.08537052571773529 norm:0.001898149261251092 max memory_allocated 22898.08154296875 
[2025-01-18 12:46:40 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 17 loss:0.08530205488204956 norm:0.001850518980063498 max memory_allocated 22898.08154296875 
[2025-01-18 12:47:11 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 18 loss:0.0852203220129013 norm:0.0018285451224073768 max memory_allocated 22898.08154296875 
[2025-01-18 12:47:42 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 19 loss:0.08516115695238113 norm:0.0018180659972131252 max memory_allocated 22898.08154296875 
[2025-01-18 12:47:51 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 8 ===
[2025-01-18 12:48:25 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 0 loss:0.1449834555387497 norm:0.007844336330890656 max memory_allocated 22899.75341796875 
[2025-01-18 12:48:56 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 1 loss:0.12133695185184479 norm:0.0034519860055297613 max memory_allocated 22899.75341796875 
[2025-01-18 12:49:27 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 2 loss:0.10875819623470306 norm:0.002837579697370529 max memory_allocated 22899.75341796875 
[2025-01-18 12:49:58 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 3 loss:0.10157988965511322 norm:0.002573273843154311 max memory_allocated 22899.75341796875 
[2025-01-18 12:50:29 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 4 loss:0.0982801616191864 norm:0.0021068821661174297 max memory_allocated 22899.75341796875 
[2025-01-18 12:50:59 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 5 loss:0.0966564416885376 norm:0.00195962842553854 max memory_allocated 22899.75341796875 
[2025-01-18 12:51:30 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 6 loss:0.09586194157600403 norm:0.001837603049352765 max memory_allocated 22899.75341796875 
[2025-01-18 12:52:01 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 7 loss:0.09540551900863647 norm:0.0018681976944208145 max memory_allocated 22899.75341796875 
[2025-01-18 12:52:32 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 8 loss:0.09506060928106308 norm:0.001881501986645162 max memory_allocated 22899.75341796875 
[2025-01-18 12:53:03 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 9 loss:0.09479320049285889 norm:0.001937342225573957 max memory_allocated 22899.75341796875 
[2025-01-18 12:53:34 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 10 loss:0.09457278996706009 norm:0.0019011867698282003 max memory_allocated 22899.75341796875 
[2025-01-18 12:54:05 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 11 loss:0.09440872818231583 norm:0.0018581114709377289 max memory_allocated 22899.75341796875 
[2025-01-18 12:54:36 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 12 loss:0.09425155073404312 norm:0.0018418917898088694 max memory_allocated 22899.75341796875 
[2025-01-18 12:55:07 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 13 loss:0.09417658299207687 norm:0.0019015774596482515 max memory_allocated 22899.75341796875 
[2025-01-18 12:55:38 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 14 loss:0.09403957426548004 norm:0.001882416196167469 max memory_allocated 22899.75341796875 
[2025-01-18 12:56:09 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 15 loss:0.09396311640739441 norm:0.0017876296769827604 max memory_allocated 22899.75341796875 
[2025-01-18 12:56:40 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 16 loss:0.09391659498214722 norm:0.001827075146138668 max memory_allocated 22899.75341796875 
[2025-01-18 12:57:11 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 17 loss:0.09384578466415405 norm:0.0018096971325576305 max memory_allocated 22899.75341796875 
[2025-01-18 12:57:42 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 18 loss:0.09377849102020264 norm:0.0017209448851644993 max memory_allocated 22899.75341796875 
[2025-01-18 12:58:13 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 19 loss:0.09373064339160919 norm:0.0018542770994827151 max memory_allocated 22899.75341796875 
[2025-01-18 12:58:22 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 9 ===
[2025-01-18 12:58:55 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 0 loss:0.14538457989692688 norm:0.006472135428339243 max memory_allocated 22901.42529296875 
[2025-01-18 12:59:26 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 1 loss:0.12481509149074554 norm:0.0026888472493737936 max memory_allocated 22901.42529296875 
[2025-01-18 12:59:57 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 2 loss:0.11378167569637299 norm:0.002148835454136133 max memory_allocated 22901.42529296875 
[2025-01-18 13:00:28 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 3 loss:0.10733776539564133 norm:0.0019015200668945909 max memory_allocated 22901.42529296875 
[2025-01-18 13:00:59 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 4 loss:0.10434519499540329 norm:0.0017997146351262927 max memory_allocated 22901.42529296875 
[2025-01-18 13:01:30 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 5 loss:0.10280565917491913 norm:0.001623968011699617 max memory_allocated 22901.42529296875 
[2025-01-18 13:02:01 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 6 loss:0.10203856974840164 norm:0.0015678280033171177 max memory_allocated 22901.42529296875 
[2025-01-18 13:02:32 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 7 loss:0.10161955654621124 norm:0.0015286230482161045 max memory_allocated 22901.42529296875 
[2025-01-18 13:03:03 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 8 loss:0.10135002434253693 norm:0.0014531095512211323 max memory_allocated 22901.42529296875 
[2025-01-18 13:03:34 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 9 loss:0.10115888714790344 norm:0.001425630529411137 max memory_allocated 22901.42529296875 
[2025-01-18 13:04:05 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 10 loss:0.10097372531890869 norm:0.001447561546228826 max memory_allocated 22901.42529296875 
[2025-01-18 13:04:36 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 11 loss:0.1007806584239006 norm:0.001431488897651434 max memory_allocated 22901.42529296875 
[2025-01-18 13:05:07 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 12 loss:0.10062237083911896 norm:0.0013769257348030806 max memory_allocated 22901.42529296875 
[2025-01-18 13:05:38 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 13 loss:0.10052134841680527 norm:0.001352317864075303 max memory_allocated 22901.42529296875 
[2025-01-18 13:06:09 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 14 loss:0.10039705038070679 norm:0.0013503781519830227 max memory_allocated 22901.42529296875 
[2025-01-18 13:06:40 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 15 loss:0.10035083442926407 norm:0.0013953171437606215 max memory_allocated 22901.42529296875 
[2025-01-18 13:07:11 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 16 loss:0.10029774904251099 norm:0.0013394441921263933 max memory_allocated 22901.42529296875 
[2025-01-18 13:07:42 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 17 loss:0.10026253014802933 norm:0.0012943792389705777 max memory_allocated 22901.42529296875 
[2025-01-18 13:08:13 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 18 loss:0.10022799670696259 norm:0.0012917773565277457 max memory_allocated 22901.42529296875 
[2025-01-18 13:08:44 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 19 loss:0.10021515935659409 norm:0.001322203897871077 max memory_allocated 22901.42529296875 
[2025-01-18 13:08:52 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 10 ===
[2025-01-18 13:09:26 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 0 loss:0.139339879155159 norm:0.0031435221899300814 max memory_allocated 22903.09716796875 
[2025-01-18 13:09:57 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 1 loss:0.12451434135437012 norm:0.002004932379350066 max memory_allocated 22903.09716796875 
[2025-01-18 13:10:28 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 2 loss:0.11566266417503357 norm:0.0017853353638201952 max memory_allocated 22903.09716796875 
[2025-01-18 13:10:59 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 3 loss:0.11000800877809525 norm:0.0015018810518085957 max memory_allocated 22903.09716796875 
[2025-01-18 13:11:30 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 4 loss:0.10757483541965485 norm:0.0014305382501333952 max memory_allocated 22903.09716796875 
[2025-01-18 13:12:01 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 5 loss:0.1063794195652008 norm:0.0013484647497534752 max memory_allocated 22903.09716796875 
[2025-01-18 13:12:32 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 6 loss:0.10566666722297668 norm:0.0013032378628849983 max memory_allocated 22903.09716796875 
[2025-01-18 13:13:03 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 7 loss:0.10525680333375931 norm:0.0012878227280452847 max memory_allocated 22903.09716796875 
[2025-01-18 13:13:34 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 8 loss:0.10498354583978653 norm:0.00126867915969342 max memory_allocated 22903.09716796875 
[2025-01-18 13:14:05 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 9 loss:0.1047474592924118 norm:0.0012401373824104667 max memory_allocated 22903.09716796875 
[2025-01-18 13:14:36 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 10 loss:0.10458916425704956 norm:0.0012266412377357483 max memory_allocated 22903.09716796875 
[2025-01-18 13:15:07 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 11 loss:0.10445509850978851 norm:0.00120388378854841 max memory_allocated 22903.09716796875 
[2025-01-18 13:15:38 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 12 loss:0.10435913503170013 norm:0.0012169545516371727 max memory_allocated 22903.09716796875 
[2025-01-18 13:16:08 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 13 loss:0.1042594164609909 norm:0.001232629525475204 max memory_allocated 22903.09716796875 
[2025-01-18 13:16:39 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 14 loss:0.10420787334442139 norm:0.0011782052461057901 max memory_allocated 22903.09716796875 
[2025-01-18 13:17:10 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 15 loss:0.10415510088205338 norm:0.0011901208199560642 max memory_allocated 22903.09716796875 
[2025-01-18 13:17:41 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 16 loss:0.10410629957914352 norm:0.0011775795137509704 max memory_allocated 22903.09716796875 
[2025-01-18 13:18:12 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 17 loss:0.10411567240953445 norm:0.0011939369142055511 max memory_allocated 22903.09716796875 
[2025-01-18 13:18:43 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 18 loss:0.1040743738412857 norm:0.0012101345928385854 max memory_allocated 22903.09716796875 
[2025-01-18 13:19:14 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 19 loss:0.10404159128665924 norm:0.0011947217863053083 max memory_allocated 22903.09716796875 
[2025-01-18 13:19:23 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 11 ===
[2025-01-18 13:19:57 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 0 loss:0.14703987538814545 norm:0.005511179566383362 max memory_allocated 22904.76904296875 
[2025-01-18 13:20:28 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 1 loss:0.12898968160152435 norm:0.0024237025063484907 max memory_allocated 22904.76904296875 
[2025-01-18 13:20:58 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 2 loss:0.11939868330955505 norm:0.0019313124939799309 max memory_allocated 22904.76904296875 
[2025-01-18 13:21:29 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 3 loss:0.1136004850268364 norm:0.0016745480243116617 max memory_allocated 22904.76904296875 
[2025-01-18 13:22:00 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 4 loss:0.1108585000038147 norm:0.0014787877444177866 max memory_allocated 22904.76904296875 
[2025-01-18 13:22:31 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 5 loss:0.1093214824795723 norm:0.001398744061589241 max memory_allocated 22904.76904296875 
[2025-01-18 13:23:02 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 6 loss:0.10858499258756638 norm:0.0013553195167332888 max memory_allocated 22904.76904296875 
[2025-01-18 13:23:33 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 7 loss:0.10807967185974121 norm:0.00136828632093966 max memory_allocated 22904.76904296875 
[2025-01-18 13:24:04 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 8 loss:0.10770951211452484 norm:0.001307714614085853 max memory_allocated 22904.76904296875 
[2025-01-18 13:24:35 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 9 loss:0.10747862607240677 norm:0.0012669104617089033 max memory_allocated 22904.76904296875 
[2025-01-18 13:25:06 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 10 loss:0.10729417949914932 norm:0.0012658528285101056 max memory_allocated 22904.76904296875 
[2025-01-18 13:25:37 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 11 loss:0.1071581095457077 norm:0.0012764802668243647 max memory_allocated 22904.76904296875 
[2025-01-18 13:26:08 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 12 loss:0.10701323300600052 norm:0.0012362879933789372 max memory_allocated 22904.76904296875 
[2025-01-18 13:26:39 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 13 loss:0.10691343992948532 norm:0.0012522789184004068 max memory_allocated 22904.76904296875 
[2025-01-18 13:27:10 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 14 loss:0.1068161278963089 norm:0.0012166210217401385 max memory_allocated 22904.76904296875 
[2025-01-18 13:27:41 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 15 loss:0.10676663368940353 norm:0.0011870048474520445 max memory_allocated 22904.76904296875 
[2025-01-18 13:28:12 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 16 loss:0.10669469088315964 norm:0.0011810596333816648 max memory_allocated 22904.76904296875 
[2025-01-18 13:28:43 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 17 loss:0.10665220022201538 norm:0.0012036734260618687 max memory_allocated 22904.76904296875 
[2025-01-18 13:29:14 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 18 loss:0.10661840438842773 norm:0.001179656945168972 max memory_allocated 22904.76904296875 
[2025-01-18 13:29:45 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 19 loss:0.10659253597259521 norm:0.0011893031187355518 max memory_allocated 22904.76904296875 
[2025-01-18 13:29:54 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 12 ===
[2025-01-18 13:30:27 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 0 loss:0.1495516002178192 norm:0.004001946654170752 max memory_allocated 22906.44091796875 
[2025-01-18 13:30:58 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 1 loss:0.1321895867586136 norm:0.0020223360043019056 max memory_allocated 22906.44091796875 
[2025-01-18 13:31:29 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 2 loss:0.12298153340816498 norm:0.0016489257104694843 max memory_allocated 22906.44091796875 
[2025-01-18 13:32:00 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 3 loss:0.1169256940484047 norm:0.0014034368796274066 max memory_allocated 22906.44091796875 
[2025-01-18 13:32:31 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 4 loss:0.11432909965515137 norm:0.0012890384532511234 max memory_allocated 22906.44091796875 
[2025-01-18 13:33:02 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 5 loss:0.1129893809556961 norm:0.0011984878219664097 max memory_allocated 22906.44091796875 
[2025-01-18 13:33:33 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 6 loss:0.1123134195804596 norm:0.0011419940274208784 max memory_allocated 22906.44091796875 
[2025-01-18 13:34:04 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 7 loss:0.11187490820884705 norm:0.0011912508634850383 max memory_allocated 22906.44091796875 
[2025-01-18 13:34:35 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 8 loss:0.11152390390634537 norm:0.0011505367001518607 max memory_allocated 22906.44091796875 
[2025-01-18 13:35:06 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 9 loss:0.11125077307224274 norm:0.0011280495673418045 max memory_allocated 22906.44091796875 
[2025-01-18 13:35:37 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 10 loss:0.1110917404294014 norm:0.001068547135218978 max memory_allocated 22906.44091796875 
[2025-01-18 13:36:08 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 11 loss:0.11096034198999405 norm:0.0011116618989035487 max memory_allocated 22906.44091796875 
[2025-01-18 13:36:39 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 12 loss:0.11080522835254669 norm:0.0010858940659090877 max memory_allocated 22906.44091796875 
[2025-01-18 13:37:10 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 13 loss:0.11070472747087479 norm:0.0010345695773139596 max memory_allocated 22906.44091796875 
[2025-01-18 13:37:41 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 14 loss:0.11065413802862167 norm:0.0010432464769110084 max memory_allocated 22906.44091796875 
[2025-01-18 13:38:11 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 15 loss:0.1105697751045227 norm:0.0010320995934307575 max memory_allocated 22906.44091796875 
[2025-01-18 13:38:42 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 16 loss:0.11052708327770233 norm:0.0010291284415870905 max memory_allocated 22906.44091796875 
[2025-01-18 13:39:13 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 17 loss:0.11046221107244492 norm:0.001002802513539791 max memory_allocated 22906.44091796875 
[2025-01-18 13:39:44 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 18 loss:0.11045181751251221 norm:0.0010103991953656077 max memory_allocated 22906.44091796875 
[2025-01-18 13:40:15 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 19 loss:0.11039073765277863 norm:0.0010155988857150078 max memory_allocated 22906.44091796875 
[2025-01-18 13:40:24 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 13 ===
[2025-01-18 13:40:58 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 0 loss:0.1445225328207016 norm:0.003721479792147875 max memory_allocated 22908.11279296875 
[2025-01-18 13:41:29 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 1 loss:0.1291818618774414 norm:0.0019245208241045475 max memory_allocated 22908.11279296875 
[2025-01-18 13:42:00 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 2 loss:0.1204950362443924 norm:0.0015415247762575746 max memory_allocated 22908.11279296875 
[2025-01-18 13:42:31 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 3 loss:0.11539941281080246 norm:0.0013740204740315676 max memory_allocated 22908.11279296875 
[2025-01-18 13:43:02 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 4 loss:0.11303961277008057 norm:0.001281430828385055 max memory_allocated 22908.11279296875 
[2025-01-18 13:43:33 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 5 loss:0.11164877563714981 norm:0.0012128094676882029 max memory_allocated 22908.11279296875 
[2025-01-18 13:44:03 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 6 loss:0.11085928231477737 norm:0.0011715684086084366 max memory_allocated 22908.11279296875 
[2025-01-18 13:44:34 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 7 loss:0.11045011878013611 norm:0.0011299740290269256 max memory_allocated 22908.11279296875 
[2025-01-18 13:45:05 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 8 loss:0.11016290634870529 norm:0.0010642663110047579 max memory_allocated 22908.11279296875 
[2025-01-18 13:45:36 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 9 loss:0.10993395000696182 norm:0.0010737915290519595 max memory_allocated 22908.11279296875 
[2025-01-18 13:46:07 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 10 loss:0.10972825437784195 norm:0.001048369682393968 max memory_allocated 22908.11279296875 
[2025-01-18 13:46:38 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 11 loss:0.10954713076353073 norm:0.001039232243783772 max memory_allocated 22908.11279296875 
[2025-01-18 13:47:09 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 12 loss:0.10945037752389908 norm:0.001056525856256485 max memory_allocated 22908.11279296875 
[2025-01-18 13:47:40 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 13 loss:0.10933229327201843 norm:0.001036013592965901 max memory_allocated 22908.11279296875 
[2025-01-18 13:48:11 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 14 loss:0.1091863140463829 norm:0.0010116328485310078 max memory_allocated 22908.11279296875 
[2025-01-18 13:48:42 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 15 loss:0.10913447290658951 norm:0.001010001404210925 max memory_allocated 22908.11279296875 
[2025-01-18 13:49:13 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 16 loss:0.10908176749944687 norm:0.0010119822109118104 max memory_allocated 22908.11279296875 
[2025-01-18 13:49:44 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 17 loss:0.10903288424015045 norm:0.0010004652431234717 max memory_allocated 22908.11279296875 
[2025-01-18 13:50:15 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 18 loss:0.10897872596979141 norm:0.0009740324458107352 max memory_allocated 22908.11279296875 
[2025-01-18 13:50:46 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 19 loss:0.10892467945814133 norm:0.0009645576355978847 max memory_allocated 22908.11279296875 
[2025-01-18 13:50:55 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 14 ===
[2025-01-18 13:51:29 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 0 loss:0.15069061517715454 norm:0.003632854437455535 max memory_allocated 22909.78466796875 
[2025-01-18 13:52:00 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 1 loss:0.1345982402563095 norm:0.0020136749371886253 max memory_allocated 22909.78466796875 
[2025-01-18 13:52:31 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 2 loss:0.12458633631467819 norm:0.0015072226524353027 max memory_allocated 22909.78466796875 
[2025-01-18 13:53:01 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 3 loss:0.1185561791062355 norm:0.0012881059665232897 max memory_allocated 22909.78466796875 
[2025-01-18 13:53:32 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 4 loss:0.11544949561357498 norm:0.0011109421029686928 max memory_allocated 22909.78466796875 
[2025-01-18 13:54:03 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 5 loss:0.11386492848396301 norm:0.001041972078382969 max memory_allocated 22909.78466796875 
[2025-01-18 13:54:34 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 6 loss:0.11294287443161011 norm:0.0009741588728502393 max memory_allocated 22909.78466796875 
[2025-01-18 13:55:05 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 7 loss:0.11255685240030289 norm:0.0009628342231735587 max memory_allocated 22909.78466796875 
[2025-01-18 13:55:36 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 8 loss:0.11228638142347336 norm:0.0009042710880748928 max memory_allocated 22909.78466796875 
[2025-01-18 13:56:07 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 9 loss:0.11210115253925323 norm:0.0008890713797882199 max memory_allocated 22909.78466796875 
[2025-01-18 13:56:38 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 10 loss:0.11191656440496445 norm:0.0009031279478222132 max memory_allocated 22909.78466796875 
[2025-01-18 13:57:09 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 11 loss:0.11179918050765991 norm:0.0008952927310019732 max memory_allocated 22909.78466796875 
[2025-01-18 13:57:40 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 12 loss:0.11170640587806702 norm:0.0008923449204303324 max memory_allocated 22909.78466796875 
[2025-01-18 13:58:11 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 13 loss:0.11157184094190598 norm:0.0008686298388056457 max memory_allocated 22909.78466796875 
[2025-01-18 13:58:42 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 14 loss:0.11146676540374756 norm:0.0008611015509814024 max memory_allocated 22909.78466796875 
[2025-01-18 13:59:13 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 15 loss:0.1113974004983902 norm:0.0008576512336730957 max memory_allocated 22909.78466796875 
[2025-01-18 13:59:44 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 16 loss:0.11133186519145966 norm:0.0008452596375718713 max memory_allocated 22909.78466796875 
[2025-01-18 14:00:15 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 17 loss:0.11130060255527496 norm:0.0008341972716152668 max memory_allocated 22909.78466796875 
[2025-01-18 14:00:46 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 18 loss:0.11128442734479904 norm:0.0008467987645417452 max memory_allocated 22909.78466796875 
[2025-01-18 14:01:17 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 19 loss:0.11122362315654755 norm:0.0008244841010309756 max memory_allocated 22909.78466796875 
[2025-01-18 14:01:26 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 15 ===
[2025-01-18 14:01:59 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 0 loss:0.1512656807899475 norm:0.005848044529557228 max memory_allocated 22911.45654296875 
[2025-01-18 14:02:30 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 1 loss:0.13301780819892883 norm:0.002547195414081216 max memory_allocated 22911.45654296875 
[2025-01-18 14:03:01 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 2 loss:0.12233258783817291 norm:0.0017538289539515972 max memory_allocated 22911.45654296875 
[2025-01-18 14:03:32 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 3 loss:0.11617865413427353 norm:0.0015315837226808071 max memory_allocated 22911.45654296875 
[2025-01-18 14:04:03 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 4 loss:0.11329185962677002 norm:0.0013769196812063456 max memory_allocated 22911.45654296875 
[2025-01-18 14:04:34 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 5 loss:0.11184947192668915 norm:0.001317818183451891 max memory_allocated 22911.45654296875 
[2025-01-18 14:05:05 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 6 loss:0.11115770787000656 norm:0.0012610084377229214 max memory_allocated 22911.45654296875 
[2025-01-18 14:05:36 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 7 loss:0.11073164641857147 norm:0.0012145545333623886 max memory_allocated 22911.45654296875 
[2025-01-18 14:06:07 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 8 loss:0.11047466099262238 norm:0.0011834169272333384 max memory_allocated 22911.45654296875 
[2025-01-18 14:06:38 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 9 loss:0.11023171246051788 norm:0.0011728368699550629 max memory_allocated 22911.45654296875 
[2025-01-18 14:07:09 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 10 loss:0.11002526432275772 norm:0.001107294810935855 max memory_allocated 22911.45654296875 
[2025-01-18 14:07:40 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 11 loss:0.10988062620162964 norm:0.0010828730883076787 max memory_allocated 22911.45654296875 
[2025-01-18 14:08:11 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 12 loss:0.109795480966568 norm:0.0010509324492886662 max memory_allocated 22911.45654296875 
[2025-01-18 14:08:42 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 13 loss:0.10971041023731232 norm:0.0010598739609122276 max memory_allocated 22911.45654296875 
[2025-01-18 14:09:13 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 14 loss:0.10966267436742783 norm:0.001048642210662365 max memory_allocated 22911.45654296875 
[2025-01-18 14:09:44 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 15 loss:0.10959863662719727 norm:0.0010592000326141715 max memory_allocated 22911.45654296875 
[2025-01-18 14:10:15 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 16 loss:0.10953138768672943 norm:0.0010427322704344988 max memory_allocated 22911.45654296875 
[2025-01-18 14:10:46 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 17 loss:0.10945554822683334 norm:0.0010178243974223733 max memory_allocated 22911.45654296875 
[2025-01-18 14:11:17 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 18 loss:0.10938575118780136 norm:0.0009719711379148066 max memory_allocated 22911.45654296875 
[2025-01-18 14:11:48 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 19 loss:0.10933288186788559 norm:0.0009726855205371976 max memory_allocated 22911.45654296875 
[2025-01-18 14:11:57 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 16 ===
[2025-01-18 14:12:30 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 0 loss:0.14256632328033447 norm:0.004129829816520214 max memory_allocated 22913.12841796875 
[2025-01-18 14:13:01 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 1 loss:0.12638673186302185 norm:0.001980285393074155 max memory_allocated 22913.12841796875 
[2025-01-18 14:13:32 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 2 loss:0.11789102107286453 norm:0.001485913759097457 max memory_allocated 22913.12841796875 
[2025-01-18 14:14:03 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 3 loss:0.11263628304004669 norm:0.001293573179282248 max memory_allocated 22913.12841796875 
[2025-01-18 14:14:34 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 4 loss:0.11033858358860016 norm:0.0011304249055683613 max memory_allocated 22913.12841796875 
[2025-01-18 14:15:05 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 5 loss:0.10909627377986908 norm:0.0010811879765242338 max memory_allocated 22913.12841796875 
[2025-01-18 14:15:36 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 6 loss:0.10838212072849274 norm:0.0010130800073966384 max memory_allocated 22913.12841796875 
[2025-01-18 14:16:07 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 7 loss:0.10794193297624588 norm:0.000982996542006731 max memory_allocated 22913.12841796875 
[2025-01-18 14:16:38 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 8 loss:0.10764347016811371 norm:0.0009573097340762615 max memory_allocated 22913.12841796875 
[2025-01-18 14:17:09 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 9 loss:0.107447549700737 norm:0.000940172525588423 max memory_allocated 22913.12841796875 
[2025-01-18 14:17:40 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 10 loss:0.10729804635047913 norm:0.00092302355915308 max memory_allocated 22913.12841796875 
[2025-01-18 14:18:11 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 11 loss:0.10715734958648682 norm:0.0009088695514947176 max memory_allocated 22913.12841796875 
[2025-01-18 14:18:42 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 12 loss:0.10705476254224777 norm:0.0008986309403553605 max memory_allocated 22913.12841796875 
[2025-01-18 14:19:13 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 13 loss:0.10695518553256989 norm:0.0008951069321483374 max memory_allocated 22913.12841796875 
[2025-01-18 14:19:44 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 14 loss:0.10687099397182465 norm:0.0008755721501074731 max memory_allocated 22913.12841796875 
[2025-01-18 14:20:15 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 15 loss:0.1067703515291214 norm:0.0008702757768332958 max memory_allocated 22913.12841796875 
[2025-01-18 14:20:46 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 16 loss:0.10668244957923889 norm:0.0008577911648899317 max memory_allocated 22913.12841796875 
[2025-01-18 14:21:17 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 17 loss:0.10661493986845016 norm:0.0008368908311240375 max memory_allocated 22913.12841796875 
[2025-01-18 14:21:48 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 18 loss:0.10653917491436005 norm:0.0008436172502115369 max memory_allocated 22913.12841796875 
[2025-01-18 14:22:19 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 19 loss:0.10648224502801895 norm:0.0008224004413932562 max memory_allocated 22913.12841796875 
[2025-01-18 14:22:27 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 17 ===
[2025-01-18 14:23:01 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 0 loss:0.140296071767807 norm:0.005723052192479372 max memory_allocated 22914.80029296875 
[2025-01-18 14:23:32 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 1 loss:0.1251639574766159 norm:0.0020091687329113483 max memory_allocated 22914.80029296875 
[2025-01-18 14:24:03 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 2 loss:0.1175958514213562 norm:0.0014994880184531212 max memory_allocated 22914.80029296875 
[2025-01-18 14:24:34 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 3 loss:0.11316359043121338 norm:0.0013164607807993889 max memory_allocated 22914.80029296875 
[2025-01-18 14:25:05 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 4 loss:0.11101586371660233 norm:0.001179332728497684 max memory_allocated 22914.80029296875 
[2025-01-18 14:25:36 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 5 loss:0.10961209237575531 norm:0.0011176882544532418 max memory_allocated 22914.80029296875 
[2025-01-18 14:26:07 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 6 loss:0.10891133546829224 norm:0.001061200280673802 max memory_allocated 22914.80029296875 
[2025-01-18 14:26:38 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 7 loss:0.10848899185657501 norm:0.0010165746789425611 max memory_allocated 22914.80029296875 
[2025-01-18 14:27:09 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 8 loss:0.10818691551685333 norm:0.0009739469387568533 max memory_allocated 22914.80029296875 
[2025-01-18 14:27:40 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 9 loss:0.10800628364086151 norm:0.0009552803821861744 max memory_allocated 22914.80029296875 
[2025-01-18 14:28:11 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 10 loss:0.10786065459251404 norm:0.0009506436763331294 max memory_allocated 22914.80029296875 
[2025-01-18 14:28:42 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 11 loss:0.1077638640999794 norm:0.0009343554847873747 max memory_allocated 22914.80029296875 
[2025-01-18 14:29:13 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 12 loss:0.10764102637767792 norm:0.0009301136014983058 max memory_allocated 22914.80029296875 
[2025-01-18 14:29:44 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 13 loss:0.10755198448896408 norm:0.0009179883636534214 max memory_allocated 22914.80029296875 
[2025-01-18 14:30:15 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 14 loss:0.10747841000556946 norm:0.0009256525081582367 max memory_allocated 22914.80029296875 
[2025-01-18 14:30:46 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 15 loss:0.10737397521734238 norm:0.0008883169502951205 max memory_allocated 22914.80029296875 
[2025-01-18 14:31:17 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 16 loss:0.10730426013469696 norm:0.0008772021974436939 max memory_allocated 22914.80029296875 
[2025-01-18 14:31:47 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 17 loss:0.1072467565536499 norm:0.0008833312313072383 max memory_allocated 22914.80029296875 
[2025-01-18 14:32:18 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 18 loss:0.10718700289726257 norm:0.0008657166035845876 max memory_allocated 22914.80029296875 
[2025-01-18 14:32:49 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 19 loss:0.1071331575512886 norm:0.0008658226579427719 max memory_allocated 22914.80029296875 
[2025-01-18 14:32:58 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 18 ===
[2025-01-18 14:33:32 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 0 loss:0.15626345574855804 norm:0.011844980530440807 max memory_allocated 22916.47216796875 
[2025-01-18 14:34:03 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 1 loss:0.1355881690979004 norm:0.002537786029279232 max memory_allocated 22916.47216796875 
[2025-01-18 14:34:34 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 2 loss:0.12571609020233154 norm:0.0018675844185054302 max memory_allocated 22916.47216796875 
[2025-01-18 14:35:05 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 3 loss:0.12039001286029816 norm:0.001585005084052682 max memory_allocated 22916.47216796875 
[2025-01-18 14:35:36 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 4 loss:0.11768298596143723 norm:0.001428696559742093 max memory_allocated 22916.47216796875 
[2025-01-18 14:36:07 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 5 loss:0.11570240557193756 norm:0.0012671031290665269 max memory_allocated 22916.47216796875 
[2025-01-18 14:36:38 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 6 loss:0.1147032231092453 norm:0.0012228073319420218 max memory_allocated 22916.47216796875 
[2025-01-18 14:37:09 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 7 loss:0.1141553595662117 norm:0.0012030871585011482 max memory_allocated 22916.47216796875 
[2025-01-18 14:37:40 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 8 loss:0.11382738500833511 norm:0.0011690616374835372 max memory_allocated 22916.47216796875 
[2025-01-18 14:38:11 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 9 loss:0.11355036497116089 norm:0.0010953701566904783 max memory_allocated 22916.47216796875 
[2025-01-18 14:38:42 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 10 loss:0.11336619406938553 norm:0.0010838538873940706 max memory_allocated 22916.47216796875 
[2025-01-18 14:39:13 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 11 loss:0.1132223829627037 norm:0.001047588186338544 max memory_allocated 22916.47216796875 
[2025-01-18 14:39:44 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 12 loss:0.1130644828081131 norm:0.0010110944276675582 max memory_allocated 22916.47216796875 
[2025-01-18 14:40:15 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 13 loss:0.11295478045940399 norm:0.0009895932162180543 max memory_allocated 22916.47216796875 
[2025-01-18 14:40:46 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 14 loss:0.11285116523504257 norm:0.000983620178885758 max memory_allocated 22916.47216796875 
[2025-01-18 14:41:16 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 15 loss:0.11278128623962402 norm:0.0009759875829331577 max memory_allocated 22916.47216796875 
[2025-01-18 14:41:47 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 16 loss:0.11266598105430603 norm:0.0009639805648475885 max memory_allocated 22916.47216796875 
[2025-01-18 14:42:18 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 17 loss:0.1125694215297699 norm:0.000924560590647161 max memory_allocated 22916.47216796875 
[2025-01-18 14:42:50 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 18 loss:0.11250439286231995 norm:0.0009062342578545213 max memory_allocated 22916.47216796875 
[2025-01-18 14:43:21 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 19 loss:0.11242330074310303 norm:0.0009377525420859456 max memory_allocated 22916.47216796875 
[2025-01-18 14:43:29 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 19 ===
[2025-01-18 14:44:03 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 0 loss:0.15432164072990417 norm:0.006235543172806501 max memory_allocated 22918.14404296875 
[2025-01-18 14:44:34 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 1 loss:0.13873930275440216 norm:0.002026710892096162 max memory_allocated 22918.14404296875 
[2025-01-18 14:45:05 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 2 loss:0.1305631399154663 norm:0.0015714495675638318 max memory_allocated 22918.14404296875 
[2025-01-18 14:45:36 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 3 loss:0.12572501599788666 norm:0.001305092591792345 max memory_allocated 22918.14404296875 
[2025-01-18 14:46:07 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 4 loss:0.12339526414871216 norm:0.0010971622541546822 max memory_allocated 22918.14404296875 
[2025-01-18 14:46:38 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 5 loss:0.1218574047088623 norm:0.001047318335622549 max memory_allocated 22918.14404296875 
[2025-01-18 14:47:09 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 6 loss:0.1209879219532013 norm:0.0010226685553789139 max memory_allocated 22918.14404296875 
[2025-01-18 14:47:40 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 7 loss:0.12061698734760284 norm:0.00096416991436854 max memory_allocated 22918.14404296875 
[2025-01-18 14:48:11 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 8 loss:0.12038195133209229 norm:0.0009626650135032833 max memory_allocated 22918.14404296875 
[2025-01-18 14:48:42 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 9 loss:0.1201654002070427 norm:0.0009422769071534276 max memory_allocated 22918.14404296875 
[2025-01-18 14:49:13 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 10 loss:0.12001171708106995 norm:0.0009052171371877193 max memory_allocated 22918.14404296875 
[2025-01-18 14:49:44 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 11 loss:0.11987356841564178 norm:0.0008523487485945225 max memory_allocated 22918.14404296875 
[2025-01-18 14:50:15 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 12 loss:0.11971581727266312 norm:0.0008157397387549281 max memory_allocated 22918.14404296875 
[2025-01-18 14:50:46 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 13 loss:0.1196165606379509 norm:0.0008147080079652369 max memory_allocated 22918.14404296875 
[2025-01-18 14:51:17 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 14 loss:0.1195058599114418 norm:0.0008021736866794527 max memory_allocated 22918.14404296875 
[2025-01-18 14:51:47 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 15 loss:0.1194513589143753 norm:0.0007925862446427345 max memory_allocated 22918.14404296875 
[2025-01-18 14:52:18 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 16 loss:0.11938855051994324 norm:0.000800791778601706 max memory_allocated 22918.14404296875 
[2025-01-18 14:52:49 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 17 loss:0.11930979788303375 norm:0.0007899879710748792 max memory_allocated 22918.14404296875 
[2025-01-18 14:53:20 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 18 loss:0.11924567073583603 norm:0.0007485058158636093 max memory_allocated 22918.14404296875 
[2025-01-18 14:53:51 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 19 loss:0.11918524652719498 norm:0.00073810457251966 max memory_allocated 22918.14404296875 
[2025-01-18 14:54:00 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 20 ===
[2025-01-18 14:54:34 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 0 loss:0.16493555903434753 norm:0.007595869246870279 max memory_allocated 22919.81591796875 
[2025-01-18 14:55:05 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 1 loss:0.14840270578861237 norm:0.0024262191727757454 max memory_allocated 22919.81591796875 
[2025-01-18 14:55:36 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 2 loss:0.13956673443317413 norm:0.0018492471426725388 max memory_allocated 22919.81591796875 
[2025-01-18 14:56:07 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 3 loss:0.13460673391819 norm:0.001537600765004754 max memory_allocated 22919.81591796875 
[2025-01-18 14:56:38 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 4 loss:0.1320972740650177 norm:0.0014306741068139672 max memory_allocated 22919.81591796875 
[2025-01-18 14:57:09 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 5 loss:0.1303991973400116 norm:0.0013920094352215528 max memory_allocated 22919.81591796875 
[2025-01-18 14:57:40 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 6 loss:0.12947899103164673 norm:0.0013298953417688608 max memory_allocated 22919.81591796875 
[2025-01-18 14:58:11 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 7 loss:0.12899039685726166 norm:0.001288216095417738 max memory_allocated 22919.81591796875 
[2025-01-18 14:58:42 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 8 loss:0.1286591738462448 norm:0.001240437151864171 max memory_allocated 22919.81591796875 
[2025-01-18 14:59:13 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 9 loss:0.12840211391448975 norm:0.0012041244190186262 max memory_allocated 22919.81591796875 
[2025-01-18 14:59:43 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 10 loss:0.12819786369800568 norm:0.0011640754528343678 max memory_allocated 22919.81591796875 
[2025-01-18 15:00:14 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 11 loss:0.1280234456062317 norm:0.0011859446531161666 max memory_allocated 22919.81591796875 
[2025-01-18 15:00:45 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 12 loss:0.12787969410419464 norm:0.0011152882361784577 max memory_allocated 22919.81591796875 
[2025-01-18 15:01:16 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 13 loss:0.12775374948978424 norm:0.0011710819089785218 max memory_allocated 22919.81591796875 
[2025-01-18 15:01:47 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 14 loss:0.12758253514766693 norm:0.001107091549783945 max memory_allocated 22919.81591796875 
[2025-01-18 15:02:18 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 15 loss:0.12747769057750702 norm:0.0010937177576124668 max memory_allocated 22919.81591796875 
[2025-01-18 15:02:49 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 16 loss:0.12739992141723633 norm:0.0011108902981504798 max memory_allocated 22919.81591796875 
[2025-01-18 15:03:20 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 17 loss:0.12730684876441956 norm:0.0010693902149796486 max memory_allocated 22919.81591796875 
[2025-01-18 15:03:51 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 18 loss:0.12719354033470154 norm:0.0010350244119763374 max memory_allocated 22919.81591796875 
[2025-01-18 15:04:22 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 19 loss:0.12714147567749023 norm:0.0010246351594105363 max memory_allocated 22919.81591796875 
[2025-01-18 15:04:31 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 21 ===
[2025-01-18 15:05:05 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 0 loss:0.17139127850532532 norm:0.006180133670568466 max memory_allocated 22921.48779296875 
[2025-01-18 15:05:36 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 1 loss:0.15733888745307922 norm:0.0020320150069892406 max memory_allocated 22921.48779296875 
[2025-01-18 15:06:07 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 2 loss:0.1494324952363968 norm:0.0013042737264186144 max memory_allocated 22921.48779296875 
[2025-01-18 15:06:38 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 3 loss:0.1447894126176834 norm:0.0010849711252376437 max memory_allocated 22921.48779296875 
[2025-01-18 15:07:09 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 4 loss:0.14281420409679413 norm:0.0009406379540450871 max memory_allocated 22921.48779296875 
[2025-01-18 15:07:40 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 5 loss:0.1414203643798828 norm:0.0008634834666736424 max memory_allocated 22921.48779296875 
[2025-01-18 15:08:10 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 6 loss:0.14055761694908142 norm:0.0008296516025438905 max memory_allocated 22921.48779296875 
[2025-01-18 15:08:41 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 7 loss:0.1401054859161377 norm:0.0007640374824404716 max memory_allocated 22921.48779296875 
[2025-01-18 15:09:12 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 8 loss:0.13988755643367767 norm:0.0007539145881310105 max memory_allocated 22921.48779296875 
[2025-01-18 15:09:43 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 9 loss:0.13971778750419617 norm:0.0007556502241641283 max memory_allocated 22921.48779296875 
[2025-01-18 15:10:14 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 10 loss:0.13955725729465485 norm:0.0007394782733172178 max memory_allocated 22921.48779296875 
[2025-01-18 15:10:45 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 11 loss:0.1394428014755249 norm:0.0007049749838188291 max memory_allocated 22921.48779296875 
[2025-01-18 15:11:16 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 12 loss:0.13934309780597687 norm:0.0007173711201176047 max memory_allocated 22921.48779296875 
[2025-01-18 15:11:47 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 13 loss:0.13922107219696045 norm:0.000696878763847053 max memory_allocated 22921.48779296875 
[2025-01-18 15:12:18 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 14 loss:0.13912981748580933 norm:0.0006770908948965371 max memory_allocated 22921.48779296875 
[2025-01-18 15:12:49 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 15 loss:0.13904547691345215 norm:0.000674744020216167 max memory_allocated 22921.48779296875 
[2025-01-18 15:13:20 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 16 loss:0.1389763057231903 norm:0.000660240650177002 max memory_allocated 22921.48779296875 
[2025-01-18 15:13:51 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 17 loss:0.13891126215457916 norm:0.000638302240986377 max memory_allocated 22921.48779296875 
[2025-01-18 15:14:22 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 18 loss:0.13885347545146942 norm:0.0006163913640193641 max memory_allocated 22921.48779296875 
[2025-01-18 15:14:53 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 19 loss:0.13881726562976837 norm:0.000635384873021394 max memory_allocated 22921.48779296875 
[2025-01-18 15:15:02 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 22 ===
[2025-01-18 15:15:36 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 0 loss:0.19590796530246735 norm:0.008217529393732548 max memory_allocated 22923.15966796875 
[2025-01-18 15:16:07 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 1 loss:0.1786300390958786 norm:0.0035545998252928257 max memory_allocated 22923.15966796875 
[2025-01-18 15:16:38 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 2 loss:0.16929036378860474 norm:0.002614704892039299 max memory_allocated 22923.15966796875 
[2025-01-18 15:17:08 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 3 loss:0.16292770206928253 norm:0.002207399345934391 max memory_allocated 22923.15966796875 
[2025-01-18 15:17:39 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 4 loss:0.16016885638237 norm:0.002013512421399355 max memory_allocated 22923.15966796875 
[2025-01-18 15:18:10 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 5 loss:0.15865619480609894 norm:0.0019299369305372238 max memory_allocated 22923.15966796875 
[2025-01-18 15:18:41 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 6 loss:0.15785102546215057 norm:0.001738585066050291 max memory_allocated 22923.15966796875 
[2025-01-18 15:19:12 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 7 loss:0.15747179090976715 norm:0.0016560606891289353 max memory_allocated 22923.15966796875 
[2025-01-18 15:19:43 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 8 loss:0.1572766751050949 norm:0.0016099278582260013 max memory_allocated 22923.15966796875 
[2025-01-18 15:20:14 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 9 loss:0.15706424415111542 norm:0.0015682325465604663 max memory_allocated 22923.15966796875 
[2025-01-18 15:20:45 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 10 loss:0.15692004561424255 norm:0.0015344824641942978 max memory_allocated 22923.15966796875 
[2025-01-18 15:21:16 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 11 loss:0.15674114227294922 norm:0.0014908881857991219 max memory_allocated 22923.15966796875 
[2025-01-18 15:21:47 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 12 loss:0.1565977782011032 norm:0.001396282110363245 max memory_allocated 22923.15966796875 
[2025-01-18 15:22:18 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 13 loss:0.15649351477622986 norm:0.001360134920105338 max memory_allocated 22923.15966796875 
[2025-01-18 15:22:49 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 14 loss:0.1563977301120758 norm:0.0012726224958896637 max memory_allocated 22923.15966796875 
[2025-01-18 15:23:20 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 15 loss:0.15631240606307983 norm:0.0012893814127892256 max memory_allocated 22923.15966796875 
[2025-01-18 15:23:51 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 16 loss:0.15625739097595215 norm:0.0013138744980096817 max memory_allocated 22923.15966796875 
[2025-01-18 15:24:22 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 17 loss:0.15618818998336792 norm:0.001184272114187479 max memory_allocated 22923.15966796875 
[2025-01-18 15:24:53 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 18 loss:0.15613104403018951 norm:0.001255903858691454 max memory_allocated 22923.15966796875 
[2025-01-18 15:25:24 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 19 loss:0.15608087182044983 norm:0.001171819749288261 max memory_allocated 22923.15966796875 
[2025-01-18 15:25:33 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 23 ===
[2025-01-18 15:26:07 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 0 loss:0.208912655711174 norm:0.004534796811640263 max memory_allocated 22924.83154296875 
[2025-01-18 15:26:38 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 1 loss:0.19439904391765594 norm:0.0018902599113062024 max memory_allocated 22924.83154296875 
[2025-01-18 15:27:09 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 2 loss:0.18608881533145905 norm:0.0012777185766026378 max memory_allocated 22924.83154296875 
[2025-01-18 15:27:40 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 3 loss:0.18076741695404053 norm:0.0010218936949968338 max memory_allocated 22924.83154296875 
[2025-01-18 15:28:11 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 4 loss:0.17822621762752533 norm:0.0008486545411869884 max memory_allocated 22924.83154296875 
[2025-01-18 15:28:42 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 5 loss:0.17676720023155212 norm:0.0007510103168897331 max memory_allocated 22924.83154296875 
[2025-01-18 15:29:13 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 6 loss:0.17619651556015015 norm:0.0007088014972396195 max memory_allocated 22924.83154296875 
[2025-01-18 15:29:44 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 7 loss:0.1759268194437027 norm:0.000684107537381351 max memory_allocated 22924.83154296875 
[2025-01-18 15:30:15 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 8 loss:0.1757371872663498 norm:0.0006646062829531729 max memory_allocated 22924.83154296875 
[2025-01-18 15:30:46 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 9 loss:0.1755780428647995 norm:0.0006527862278744578 max memory_allocated 22924.83154296875 
[2025-01-18 15:31:17 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 10 loss:0.17542095482349396 norm:0.0006337956874631345 max memory_allocated 22924.83154296875 
[2025-01-18 15:31:48 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 11 loss:0.1752709150314331 norm:0.0006143846549093723 max memory_allocated 22924.83154296875 
[2025-01-18 15:32:19 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 12 loss:0.17517408728599548 norm:0.0006122151389718056 max memory_allocated 22924.83154296875 
[2025-01-18 15:32:50 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 13 loss:0.1750771552324295 norm:0.0006108229281380773 max memory_allocated 22924.83154296875 
[2025-01-18 15:33:21 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 14 loss:0.17498569190502167 norm:0.0005789938732050359 max memory_allocated 22924.83154296875 
[2025-01-18 15:33:52 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 15 loss:0.17492176592350006 norm:0.0005737780593335629 max memory_allocated 22924.83154296875 
[2025-01-18 15:34:23 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 16 loss:0.17485035955905914 norm:0.0005704226205125451 max memory_allocated 22924.83154296875 
[2025-01-18 15:34:54 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 17 loss:0.17480257153511047 norm:0.0005601465818472207 max memory_allocated 22924.83154296875 
[2025-01-18 15:35:24 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 18 loss:0.174746572971344 norm:0.0005556646501645446 max memory_allocated 22924.83154296875 
[2025-01-18 15:35:55 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 19 loss:0.1747075915336609 norm:0.0005432273028418422 max memory_allocated 22924.83154296875 
[2025-01-18 15:36:04 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 24 ===
[2025-01-18 15:36:38 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 0 loss:0.24236369132995605 norm:0.006504388991743326 max memory_allocated 22926.50341796875 
[2025-01-18 15:37:09 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 1 loss:0.22420518100261688 norm:0.0027536035049706697 max memory_allocated 22926.50341796875 
[2025-01-18 15:37:40 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 2 loss:0.21330441534519196 norm:0.002065586857497692 max memory_allocated 22926.50341796875 
[2025-01-18 15:38:11 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 3 loss:0.20662999153137207 norm:0.001840338110923767 max memory_allocated 22926.50341796875 
[2025-01-18 15:38:42 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 4 loss:0.2030462622642517 norm:0.0016165936831384897 max memory_allocated 22926.50341796875 
[2025-01-18 15:39:13 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 5 loss:0.20095618069171906 norm:0.0015601556515321136 max memory_allocated 22926.50341796875 
[2025-01-18 15:39:44 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 6 loss:0.20006927847862244 norm:0.0015562019543722272 max memory_allocated 22926.50341796875 
[2025-01-18 15:40:15 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 7 loss:0.19962389767169952 norm:0.0014759311452507973 max memory_allocated 22926.50341796875 
[2025-01-18 15:40:46 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 8 loss:0.19929979741573334 norm:0.0014490234898403287 max memory_allocated 22926.50341796875 
[2025-01-18 15:41:17 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 9 loss:0.1990382969379425 norm:0.0013489804696291685 max memory_allocated 22926.50341796875 
[2025-01-18 15:41:47 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 10 loss:0.19882400333881378 norm:0.0013607897562906146 max memory_allocated 22926.50341796875 
[2025-01-18 15:42:18 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 11 loss:0.1986369490623474 norm:0.0013636683579534292 max memory_allocated 22926.50341796875 
[2025-01-18 15:42:49 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 12 loss:0.19847464561462402 norm:0.0013351074885576963 max memory_allocated 22926.50341796875 
[2025-01-18 15:43:20 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 13 loss:0.19835977256298065 norm:0.0013133365428075194 max memory_allocated 22926.50341796875 
[2025-01-18 15:43:51 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 14 loss:0.1982225775718689 norm:0.0013049659319221973 max memory_allocated 22926.50341796875 
[2025-01-18 15:44:22 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 15 loss:0.19815948605537415 norm:0.001333711901679635 max memory_allocated 22926.50341796875 
[2025-01-18 15:44:53 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 16 loss:0.1980854719877243 norm:0.0012946889037266374 max memory_allocated 22926.50341796875 
[2025-01-18 15:45:24 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 17 loss:0.19798864424228668 norm:0.001294478541240096 max memory_allocated 22926.50341796875 
[2025-01-18 15:45:55 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 18 loss:0.19795458018779755 norm:0.0012657438637688756 max memory_allocated 22926.50341796875 
[2025-01-18 15:46:26 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 19 loss:0.19790062308311462 norm:0.0013342362362891436 max memory_allocated 22926.50341796875 
[2025-01-18 15:46:35 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 25 ===
[2025-01-18 15:47:09 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 0 loss:0.2712467610836029 norm:0.006721121724694967 max memory_allocated 22928.17529296875 
[2025-01-18 15:47:40 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 1 loss:0.252740740776062 norm:0.0027842174749821424 max memory_allocated 22928.17529296875 
[2025-01-18 15:48:11 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 2 loss:0.24212229251861572 norm:0.002044720808044076 max memory_allocated 22928.17529296875 
[2025-01-18 15:48:42 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 3 loss:0.2347400039434433 norm:0.0016483223298564553 max memory_allocated 22928.17529296875 
[2025-01-18 15:49:13 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 4 loss:0.23110714554786682 norm:0.0014596153050661087 max memory_allocated 22928.17529296875 
[2025-01-18 15:49:44 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 5 loss:0.22924154996871948 norm:0.001351853716187179 max memory_allocated 22928.17529296875 
[2025-01-18 15:50:15 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 6 loss:0.22838038206100464 norm:0.001272956607863307 max memory_allocated 22928.17529296875 
[2025-01-18 15:50:45 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 7 loss:0.2278822511434555 norm:0.0011940544936805964 max memory_allocated 22928.17529296875 
[2025-01-18 15:51:16 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 8 loss:0.22758793830871582 norm:0.0011670072562992573 max memory_allocated 22928.17529296875 
[2025-01-18 15:51:47 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 9 loss:0.22736014425754547 norm:0.0011545621091499925 max memory_allocated 22928.17529296875 
[2025-01-18 15:52:18 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 10 loss:0.22715029120445251 norm:0.0011045904830098152 max memory_allocated 22928.17529296875 
[2025-01-18 15:52:49 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 11 loss:0.22690695524215698 norm:0.0010739383287727833 max memory_allocated 22928.17529296875 
[2025-01-18 15:53:20 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 12 loss:0.22680369019508362 norm:0.0010601731482893229 max memory_allocated 22928.17529296875 
[2025-01-18 15:53:51 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 13 loss:0.22666804492473602 norm:0.0010151879396289587 max memory_allocated 22928.17529296875 
[2025-01-18 15:54:22 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 14 loss:0.2265540510416031 norm:0.000999353127554059 max memory_allocated 22928.17529296875 
[2025-01-18 15:54:53 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 15 loss:0.22649215161800385 norm:0.0010162506951019168 max memory_allocated 22928.17529296875 
[2025-01-18 15:55:24 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 16 loss:0.22638097405433655 norm:0.0010131626622751355 max memory_allocated 22928.17529296875 
[2025-01-18 15:55:55 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 17 loss:0.22626155614852905 norm:0.0010209562024101615 max memory_allocated 22928.17529296875 
[2025-01-18 15:56:26 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 18 loss:0.2262364774942398 norm:0.0010299618588760495 max memory_allocated 22928.17529296875 
[2025-01-18 15:56:57 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 19 loss:0.22617118060588837 norm:0.0010147562716156244 max memory_allocated 22928.17529296875 
[2025-01-18 15:57:06 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 26 ===
[2025-01-18 15:57:40 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 0 loss:0.30494993925094604 norm:0.004706752020865679 max memory_allocated 22929.84716796875 
[2025-01-18 15:58:11 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 1 loss:0.28574156761169434 norm:0.002476235618814826 max memory_allocated 22929.84716796875 
[2025-01-18 15:58:42 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 2 loss:0.2742122411727905 norm:0.0017599682323634624 max memory_allocated 22929.84716796875 
[2025-01-18 15:59:13 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 3 loss:0.26731792092323303 norm:0.001526389503851533 max memory_allocated 22929.84716796875 
[2025-01-18 15:59:44 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 4 loss:0.26380038261413574 norm:0.0013168973382562399 max memory_allocated 22929.84716796875 
[2025-01-18 16:00:15 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 5 loss:0.2617642879486084 norm:0.0012364140711724758 max memory_allocated 22929.84716796875 
[2025-01-18 16:00:46 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 6 loss:0.2607744634151459 norm:0.0011670866515487432 max memory_allocated 22929.84716796875 
[2025-01-18 16:01:16 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 7 loss:0.2602804899215698 norm:0.0011225518537685275 max memory_allocated 22929.84716796875 
[2025-01-18 16:01:47 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 8 loss:0.2599089443683624 norm:0.0010889301775023341 max memory_allocated 22929.84716796875 
[2025-01-18 16:02:18 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 9 loss:0.2595715820789337 norm:0.0010492688743397593 max memory_allocated 22929.84716796875 
[2025-01-18 16:02:49 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 10 loss:0.2593054473400116 norm:0.0010318588465452194 max memory_allocated 22929.84716796875 
[2025-01-18 16:03:20 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 11 loss:0.25908663868904114 norm:0.0010217379312962294 max memory_allocated 22929.84716796875 
[2025-01-18 16:03:51 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 12 loss:0.25888773798942566 norm:0.0009864773601293564 max memory_allocated 22929.84716796875 
[2025-01-18 16:04:22 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 13 loss:0.25872841477394104 norm:0.000998089904896915 max memory_allocated 22929.84716796875 
[2025-01-18 16:04:53 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 14 loss:0.2585734724998474 norm:0.000965162122156471 max memory_allocated 22929.84716796875 
[2025-01-18 16:05:24 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 15 loss:0.2584463059902191 norm:0.0009603708749637008 max memory_allocated 22929.84716796875 
[2025-01-18 16:05:55 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 16 loss:0.2583068311214447 norm:0.000969038694165647 max memory_allocated 22929.84716796875 
[2025-01-18 16:06:26 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 17 loss:0.25820493698120117 norm:0.0009406745666638017 max memory_allocated 22929.84716796875 
[2025-01-18 16:06:57 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 18 loss:0.25810694694519043 norm:0.000940801459364593 max memory_allocated 22929.84716796875 
[2025-01-18 16:07:28 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 19 loss:0.2580077648162842 norm:0.0009178326581604779 max memory_allocated 22929.84716796875 
[2025-01-18 16:07:37 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 27 ===
[2025-01-18 16:08:11 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 0 loss:0.36340588331222534 norm:0.011264250613749027 max memory_allocated 22931.51904296875 
[2025-01-18 16:08:42 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 1 loss:0.33342185616493225 norm:0.004119670018553734 max memory_allocated 22931.51904296875 
[2025-01-18 16:09:13 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 2 loss:0.3179907202720642 norm:0.002426478546112776 max memory_allocated 22931.51904296875 
[2025-01-18 16:09:44 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 3 loss:0.30884140729904175 norm:0.0018756651552394032 max memory_allocated 22931.51904296875 
[2025-01-18 16:10:15 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 4 loss:0.30398255586624146 norm:0.0017071467591449618 max memory_allocated 22931.51904296875 
[2025-01-18 16:10:46 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 5 loss:0.30181604623794556 norm:0.0015479661524295807 max memory_allocated 22931.51904296875 
[2025-01-18 16:11:17 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 6 loss:0.30101901292800903 norm:0.0014871017774567008 max memory_allocated 22931.51904296875 
[2025-01-18 16:11:48 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 7 loss:0.30049771070480347 norm:0.0014574076049029827 max memory_allocated 22931.51904296875 
[2025-01-18 16:12:19 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 8 loss:0.30011940002441406 norm:0.001417414634488523 max memory_allocated 22931.51904296875 
[2025-01-18 16:12:50 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 9 loss:0.29983124136924744 norm:0.0014123074943199754 max memory_allocated 22931.51904296875 
[2025-01-18 16:13:21 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 10 loss:0.2996310293674469 norm:0.0013533843448385596 max memory_allocated 22931.51904296875 
[2025-01-18 16:13:52 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 11 loss:0.2993989884853363 norm:0.001329250168055296 max memory_allocated 22931.51904296875 
[2025-01-18 16:14:23 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 12 loss:0.29926586151123047 norm:0.0012668189592659473 max memory_allocated 22931.51904296875 
[2025-01-18 16:14:54 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 13 loss:0.2991364598274231 norm:0.001271727029234171 max memory_allocated 22931.51904296875 
[2025-01-18 16:15:25 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 14 loss:0.29904526472091675 norm:0.0012503797188401222 max memory_allocated 22931.51904296875 
[2025-01-18 16:15:56 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 15 loss:0.2989864945411682 norm:0.0013036818709224463 max memory_allocated 22931.51904296875 
[2025-01-18 16:16:26 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 16 loss:0.2988525331020355 norm:0.0012032834347337484 max memory_allocated 22931.51904296875 
[2025-01-18 16:16:57 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 17 loss:0.29873818159103394 norm:0.0011600672733038664 max memory_allocated 22931.51904296875 
[2025-01-18 16:17:28 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 18 loss:0.2986794114112854 norm:0.001183443469926715 max memory_allocated 22931.51904296875 
[2025-01-18 16:17:59 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 19 loss:0.2986404597759247 norm:0.001173828262835741 max memory_allocated 22931.51904296875 
[2025-01-18 16:18:08 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 28 ===
[2025-01-18 16:18:11 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-01-18 16:18:42 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 0 loss:0.3987591862678528 norm:0.015640653669834137 max memory_allocated 22933.30615234375 
[2025-01-18 16:19:13 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 1 loss:0.3757006525993347 norm:0.010537322610616684 max memory_allocated 22933.30615234375 
[2025-01-18 16:19:44 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 2 loss:0.361748069524765 norm:0.007881386205554008 max memory_allocated 22933.30615234375 
[2025-01-18 16:20:15 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 3 loss:0.3531356453895569 norm:0.006242664530873299 max memory_allocated 22933.30615234375 
[2025-01-18 16:20:46 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 4 loss:0.3489355444908142 norm:0.0052213845774531364 max memory_allocated 22933.30615234375 
[2025-01-18 16:21:17 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 5 loss:0.3470021188259125 norm:0.0044358111917972565 max memory_allocated 22933.30615234375 
[2025-01-18 16:21:49 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 6 loss:0.34610065817832947 norm:0.0037781749852001667 max memory_allocated 22933.30615234375 
[2025-01-18 16:22:20 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 7 loss:0.34552401304244995 norm:0.0034340687561780214 max memory_allocated 22933.30615234375 
[2025-01-18 16:22:51 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 8 loss:0.3452235758304596 norm:0.003406339092180133 max memory_allocated 22933.30615234375 
[2025-01-18 16:23:22 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 9 loss:0.3448626399040222 norm:0.003373760962858796 max memory_allocated 22933.30615234375 
[2025-01-18 16:23:53 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 10 loss:0.3446134030818939 norm:0.0032271139789372683 max memory_allocated 22933.30615234375 
[2025-01-18 16:24:24 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 11 loss:0.3443598747253418 norm:0.003074130741879344 max memory_allocated 22933.30615234375 
[2025-01-18 16:24:55 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 12 loss:0.34425801038742065 norm:0.0031861215829849243 max memory_allocated 22933.30615234375 
[2025-01-18 16:25:26 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 13 loss:0.3441319465637207 norm:0.0031319516710937023 max memory_allocated 22933.30615234375 
[2025-01-18 16:25:57 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 14 loss:0.34395480155944824 norm:0.0029848210979253054 max memory_allocated 22933.30615234375 
[2025-01-18 16:26:28 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 15 loss:0.3437601923942566 norm:0.0028358474373817444 max memory_allocated 22933.30615234375 
[2025-01-18 16:27:00 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 16 loss:0.3436151146888733 norm:0.0028229281306266785 max memory_allocated 22933.30615234375 
[2025-01-18 16:27:31 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 17 loss:0.34353554248809814 norm:0.002677327021956444 max memory_allocated 22933.30615234375 
[2025-01-18 16:28:02 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 18 loss:0.34350261092185974 norm:0.0027220535557717085 max memory_allocated 22933.30615234375 
[2025-01-18 16:28:33 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 19 loss:0.3434297442436218 norm:0.0027436392847448587 max memory_allocated 22933.30615234375 
[2025-01-18 16:28:42 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 29 ===
[2025-01-18 16:28:44 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-01-18 16:29:15 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 0 loss:0.4675334393978119 norm:0.02265806868672371 max memory_allocated 22934.97802734375 
[2025-01-18 16:29:46 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 1 loss:0.43602171540260315 norm:0.015231394208967686 max memory_allocated 22934.97802734375 
[2025-01-18 16:30:18 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 2 loss:0.4180193543434143 norm:0.010783176869153976 max memory_allocated 22934.97802734375 
[2025-01-18 16:30:49 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 3 loss:0.40664732456207275 norm:0.008086956106126308 max memory_allocated 22934.97802734375 
[2025-01-18 16:31:20 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 4 loss:0.4012736678123474 norm:0.006685501430183649 max memory_allocated 22934.97802734375 
[2025-01-18 16:31:51 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 5 loss:0.3990212380886078 norm:0.005672459490597248 max memory_allocated 22934.97802734375 
[2025-01-18 16:32:22 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 6 loss:0.397924542427063 norm:0.004844628274440765 max memory_allocated 22934.97802734375 
[2025-01-18 16:32:53 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 7 loss:0.3972381353378296 norm:0.0042980872094631195 max memory_allocated 22934.97802734375 
[2025-01-18 16:33:24 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 8 loss:0.39673683047294617 norm:0.003907265141606331 max memory_allocated 22934.97802734375 
[2025-01-18 16:33:55 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 9 loss:0.39645010232925415 norm:0.003913797903805971 max memory_allocated 22934.97802734375 
[2025-01-18 16:34:26 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 10 loss:0.3963457942008972 norm:0.00411180080845952 max memory_allocated 22934.97802734375 
[2025-01-18 16:34:57 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 11 loss:0.396099328994751 norm:0.003939324524253607 max memory_allocated 22934.97802734375 
[2025-01-18 16:35:28 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 12 loss:0.3958715498447418 norm:0.0037885967176407576 max memory_allocated 22934.97802734375 
[2025-01-18 16:36:00 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 13 loss:0.39568328857421875 norm:0.0035327677614986897 max memory_allocated 22934.97802734375 
[2025-01-18 16:36:31 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 14 loss:0.3955117464065552 norm:0.0035116784274578094 max memory_allocated 22934.97802734375 
[2025-01-18 16:37:02 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 15 loss:0.39544299244880676 norm:0.003475565230473876 max memory_allocated 22934.97802734375 
[2025-01-18 16:37:33 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 16 loss:0.39522597193717957 norm:0.003476447192952037 max memory_allocated 22934.97802734375 
[2025-01-18 16:38:04 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 17 loss:0.3950555622577667 norm:0.0031544347293674946 max memory_allocated 22934.97802734375 
[2025-01-18 16:38:35 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 18 loss:0.3949888348579407 norm:0.0031877299770712852 max memory_allocated 22934.97802734375 
[2025-01-18 16:39:06 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 19 loss:0.394931435585022 norm:0.0031795641407370567 max memory_allocated 22934.97802734375 
[2025-01-18 16:39:15 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 30 ===
[2025-01-18 16:39:18 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-01-18 16:39:49 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 0 loss:2.3843536376953125 norm:0.5118913650512695 max memory_allocated 22936.64990234375 
[2025-01-18 16:40:20 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 1 loss:1.797163724899292 norm:2.129871129989624 max memory_allocated 22936.64990234375 
[2025-01-18 16:40:51 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 2 loss:1.1697670221328735 norm:0.4766468405723572 max memory_allocated 22936.64990234375 
[2025-01-18 16:41:22 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 3 loss:1.0072360038757324 norm:0.42632436752319336 max memory_allocated 22936.64990234375 
[2025-01-18 16:41:53 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 4 loss:0.9548819065093994 norm:0.43709492683410645 max memory_allocated 22936.64990234375 
[2025-01-18 16:42:24 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 5 loss:0.8796550631523132 norm:0.33000099658966064 max memory_allocated 22936.64990234375 
[2025-01-18 16:42:55 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 6 loss:0.8423651456832886 norm:0.304555207490921 max memory_allocated 22936.64990234375 
[2025-01-18 16:43:26 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 7 loss:0.8189746141433716 norm:0.28385812044143677 max memory_allocated 22936.64990234375 
[2025-01-18 16:43:57 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 8 loss:0.792192280292511 norm:0.2865593433380127 max memory_allocated 22936.64990234375 
[2025-01-18 16:44:28 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 9 loss:0.7875288724899292 norm:0.2657121419906616 max memory_allocated 22936.64990234375 
[2025-01-18 16:45:00 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 10 loss:0.7527874708175659 norm:0.24837779998779297 max memory_allocated 22936.64990234375 
[2025-01-18 16:45:31 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 11 loss:0.7362574934959412 norm:0.2485058307647705 max memory_allocated 22936.64990234375 
[2025-01-18 16:46:02 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 12 loss:0.7307377457618713 norm:0.23192210495471954 max memory_allocated 22936.64990234375 
[2025-01-18 16:46:33 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 13 loss:0.7207668423652649 norm:0.8071203827857971 max memory_allocated 22936.64990234375 
[2025-01-18 16:47:04 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 14 loss:0.7044253945350647 norm:0.21654082834720612 max memory_allocated 22936.64990234375 
[2025-01-18 16:47:35 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 15 loss:0.6998006701469421 norm:0.20756569504737854 max memory_allocated 22936.64990234375 
[2025-01-18 16:48:06 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 16 loss:0.6929701566696167 norm:0.20226512849330902 max memory_allocated 22936.64990234375 
[2025-01-18 16:48:37 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 17 loss:0.6873488426208496 norm:0.19390466809272766 max memory_allocated 22936.64990234375 
[2025-01-18 16:49:08 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 18 loss:0.6861901879310608 norm:0.1859043538570404 max memory_allocated 22936.64990234375 
[2025-01-18 16:49:39 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 19 loss:0.6774049401283264 norm:0.17507584393024445 max memory_allocated 22936.64990234375 
[2025-01-18 16:49:48 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 31 ===
[2025-01-18 16:49:51 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-01-18 16:50:22 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 0 loss:1.2123546600341797 norm:0.093105748295784 max memory_allocated 22938.32177734375 
[2025-01-18 16:50:53 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 1 loss:1.120741844177246 norm:0.0675930380821228 max memory_allocated 22938.32177734375 
[2025-01-18 16:51:24 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 2 loss:1.0688003301620483 norm:0.054417017847299576 max memory_allocated 22938.32177734375 
[2025-01-18 16:51:55 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 3 loss:1.0359761714935303 norm:0.045980945229530334 max memory_allocated 22938.32177734375 
[2025-01-18 16:52:26 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 4 loss:1.023034691810608 norm:0.04085110127925873 max memory_allocated 22938.32177734375 
[2025-01-18 16:52:57 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 5 loss:1.0141887664794922 norm:0.03863371163606644 max memory_allocated 22938.32177734375 
[2025-01-18 16:53:29 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 6 loss:1.0089794397354126 norm:0.03560478985309601 max memory_allocated 22938.32177734375 
[2025-01-18 16:54:00 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 7 loss:1.0049214363098145 norm:0.03282187879085541 max memory_allocated 22938.32177734375 
[2025-01-18 16:54:31 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 8 loss:1.002082109451294 norm:0.031069515272974968 max memory_allocated 22938.32177734375 
[2025-01-18 16:55:02 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 9 loss:0.9997757077217102 norm:0.029479973018169403 max memory_allocated 22938.32177734375 
[2025-01-18 16:55:33 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 10 loss:0.9981985092163086 norm:0.027817443013191223 max memory_allocated 22938.32177734375 
[2025-01-18 16:56:04 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 11 loss:0.9965331554412842 norm:0.026628995314240456 max memory_allocated 22938.32177734375 
[2025-01-18 16:56:35 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 12 loss:0.9950620532035828 norm:0.026038961485028267 max memory_allocated 22938.32177734375 
[2025-01-18 16:57:06 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 13 loss:0.994045078754425 norm:0.02526504546403885 max memory_allocated 22938.32177734375 
[2025-01-18 16:57:37 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 14 loss:0.9931382536888123 norm:0.024813061580061913 max memory_allocated 22938.32177734375 
[2025-01-18 16:58:08 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 15 loss:0.9921807050704956 norm:0.024246884509921074 max memory_allocated 22938.32177734375 
[2025-01-18 16:58:39 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 16 loss:0.9919752478599548 norm:0.02443702518939972 max memory_allocated 22938.32177734375 
[2025-01-18 16:59:10 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 17 loss:0.9916756749153137 norm:0.024061067029833794 max memory_allocated 22938.32177734375 
[2025-01-18 16:59:42 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 18 loss:0.9908994436264038 norm:0.023667708039283752 max memory_allocated 22938.32177734375 
[2025-01-18 17:00:13 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 19 loss:0.9919813871383667 norm:0.02558606117963791 max memory_allocated 22938.32177734375 
[2025-01-18 17:00:22 root] (main_calib_config.py 366): INFO 20199.95935368538
[2025-01-18 17:00:48 root] (main_calib_config.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-01-18 17:01:58 root] (main_calib_config.py 159): INFO wikitext2 : 7.858763217926025
[2025-01-18 17:01:58 root] (main_calib_config.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-01-18 17:03:47 root] (main_calib_config.py 159): INFO c4 : 9.988214492797852
[2025-01-18 17:03:57 datasets.load] (load.py 1272): WARNING Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/winogrande/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2 (last modified on Sat Jan 18 09:57:04 2025) since it couldn't be found locally at winogrande., or remotely on the Hugging Face Hub.
[2025-01-18 18:22:04 root] (main_calib_config.py 170): INFO {'wikitext2': 7.858763217926025, 'c4': 9.988214492797852, 'results': {'winogrande': {'acc': 0.6361483820047356, 'acc_stderr': 0.013521488896883415}, 'hellaswag': {'acc': 0.5517825134435371, 'acc_stderr': 0.004962949784236048, 'acc_norm': 0.7039434375622386, 'acc_norm_stderr': 0.004555832462774587}}, 'versions': {'winogrande': 0, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
