[2025-01-09 12:10:10 root] (main_quant_config.py 113): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-chat-hf', cache_dir='./cache', output_dir='./log/Llama-2-7b-chat-hf-mpq-paral', blocks_pkl='log/Llama-2-7b-chat-hf-w4a4/Llama-2-7b-chat-hf_blocks.pkl', calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, reload=False, parallel=True, weight_quant_params={'per_channel_axes': [0], 'symmetric': False, 'dynamic_method': 'per_channel', 'group_size': None, 'lwc': False, 'disable_zero_point': False}, act_quant_params={'per_channel_axes': [], 'symmetric': False, 'dynamic_method': 'per_token'})
[2025-01-09 12:10:14 root] (main_quant_config.py 131): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-01-09 12:10:19 root] (block_wise_quant_config_search_parallel.py 458): INFO Using 2 GPUs for parallel search
[2025-01-09 12:10:19 root] (block_wise_quant_config_search_parallel.py 473): INFO Starting new batch: blocks 0 to 1
[2025-01-09 12:10:19 root] (block_wise_quant_config_search_parallel.py 474): INFO Available GPUs: 2
[2025-01-09 12:10:19 root] (block_wise_quant_config_search_parallel.py 487): INFO Got input for block 0
[2025-01-09 12:10:26 root] (block_wise_quant_config_search_parallel.py 487): INFO Got input for block 1
[2025-01-09 12:10:26 root] (block_wise_quant_config_search_parallel.py 498): INFO Preparing to assign block 0 to cuda:0
[2025-01-09 12:10:26 root] (block_wise_quant_config_search_parallel.py 507): INFO Successfully queued block 0 for processing on cuda:0
[2025-01-09 12:10:26 root] (block_wise_quant_config_search_parallel.py 498): INFO Preparing to assign block 1 to cuda:1
[2025-01-09 12:10:26 root] (block_wise_quant_config_search_parallel.py 507): INFO Successfully queued block 1 for processing on cuda:1
[2025-01-09 12:15:03 root] (block_wise_quant_config_search_parallel.py 513): INFO Successfully processed block 0
[2025-01-09 12:15:03 root] (block_wise_quant_config_search_parallel.py 513): INFO Successfully processed block 1
[2025-01-09 12:15:05 root] (block_wise_quant_config_search_parallel.py 473): INFO Starting new batch: blocks 2 to 3
[2025-01-09 12:15:05 root] (block_wise_quant_config_search_parallel.py 474): INFO Available GPUs: 2
[2025-01-09 12:15:05 root] (block_wise_quant_config_search_parallel.py 487): INFO Got input for block 2
[2025-01-09 12:15:07 root] (block_wise_quant_config_search_parallel.py 487): INFO Got input for block 3
[2025-01-09 12:15:07 root] (block_wise_quant_config_search_parallel.py 498): INFO Preparing to assign block 2 to cuda:0
[2025-01-09 12:15:07 root] (block_wise_quant_config_search_parallel.py 507): INFO Successfully queued block 2 for processing on cuda:0
[2025-01-09 12:15:07 root] (block_wise_quant_config_search_parallel.py 498): INFO Preparing to assign block 3 to cuda:1
[2025-01-09 12:15:07 root] (block_wise_quant_config_search_parallel.py 507): INFO Successfully queued block 3 for processing on cuda:1
[2025-01-09 12:19:21 root] (block_wise_quant_config_search_parallel.py 513): INFO Successfully processed block 2
[2025-01-09 12:19:21 root] (block_wise_quant_config_search_parallel.py 513): INFO Successfully processed block 3
[2025-01-09 12:19:23 root] (block_wise_quant_config_search_parallel.py 473): INFO Starting new batch: blocks 4 to 5
[2025-01-09 12:19:23 root] (block_wise_quant_config_search_parallel.py 474): INFO Available GPUs: 2
[2025-01-09 12:19:23 root] (block_wise_quant_config_search_parallel.py 487): INFO Got input for block 4
[2025-01-09 12:19:25 root] (block_wise_quant_config_search_parallel.py 487): INFO Got input for block 5
[2025-01-09 12:19:25 root] (block_wise_quant_config_search_parallel.py 498): INFO Preparing to assign block 4 to cuda:0
[2025-01-09 12:19:25 root] (block_wise_quant_config_search_parallel.py 507): INFO Successfully queued block 4 for processing on cuda:0
[2025-01-09 12:19:25 root] (block_wise_quant_config_search_parallel.py 498): INFO Preparing to assign block 5 to cuda:1
[2025-01-09 12:19:25 root] (block_wise_quant_config_search_parallel.py 507): INFO Successfully queued block 5 for processing on cuda:1
[2025-01-09 12:23:38 root] (block_wise_quant_config_search_parallel.py 513): INFO Successfully processed block 4
[2025-01-09 12:23:38 root] (block_wise_quant_config_search_parallel.py 513): INFO Successfully processed block 5
[2025-01-09 12:23:41 root] (block_wise_quant_config_search_parallel.py 473): INFO Starting new batch: blocks 6 to 7
[2025-01-09 12:23:41 root] (block_wise_quant_config_search_parallel.py 474): INFO Available GPUs: 2
[2025-01-09 12:23:41 root] (block_wise_quant_config_search_parallel.py 487): INFO Got input for block 6
[2025-01-09 12:23:42 root] (block_wise_quant_config_search_parallel.py 487): INFO Got input for block 7
[2025-01-09 12:23:42 root] (block_wise_quant_config_search_parallel.py 498): INFO Preparing to assign block 6 to cuda:0
[2025-01-09 12:23:42 root] (block_wise_quant_config_search_parallel.py 507): INFO Successfully queued block 6 for processing on cuda:0
[2025-01-09 12:23:42 root] (block_wise_quant_config_search_parallel.py 498): INFO Preparing to assign block 7 to cuda:1
[2025-01-09 12:23:42 root] (block_wise_quant_config_search_parallel.py 507): INFO Successfully queued block 7 for processing on cuda:1
[2025-01-09 12:23:50 root] (block_wise_quant_config_search_parallel.py 518): ERROR Error processing result 0: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 39.56 GiB of which 3.69 GiB is free. Process 3495714 has 18.55 GiB memory in use. Process 3517913 has 16.91 GiB memory in use. Process 3517912 has 414.00 MiB memory in use. Of the allocated memory 16.39 GiB is allocated by PyTorch, and 25.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
