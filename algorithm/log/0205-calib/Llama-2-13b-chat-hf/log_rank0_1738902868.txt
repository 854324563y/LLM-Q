[2025-02-07 04:34:28 root] (main_calib_config.py 270): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-chat-hf', cache_dir='./cache', output_dir='./log/0205-calib/Llama-2-13b-chat-hf', save_dir='./log/0205-calib/Llama-2-13b-chat-hf/save_dir', resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='./log/0205-mpq/Llama-2-13b-chat-hf/quant_map_Llama-2-13b-chat-hf.pkl')
[2025-02-07 04:34:39 root] (main_calib_config.py 337): INFO === start quantization ===
[2025-02-07 04:34:39 root] (main_calib_config.py 343): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-07 04:34:40 root] (abq_llm_calib_config.py 82): INFO Starting ...
[2025-02-07 04:34:40 root] (abq_llm_calib_config.py 89): INFO Loaded quant_map from ./log/0205-mpq/Llama-2-13b-chat-hf/quant_map_Llama-2-13b-chat-hf.pkl
[2025-02-07 04:34:55 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 0 ===
[2025-02-07 04:35:00 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 04:35:45 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 0 loss:0.014266678132116795 norm:0.01643488183617592 max memory_allocated 29716.09814453125 
[2025-02-07 04:36:32 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 1 loss:0.008417148143053055 norm:0.008663048036396503 max memory_allocated 29716.09814453125 
[2025-02-07 04:37:19 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 2 loss:0.006347667425870895 norm:0.0061410837806761265 max memory_allocated 29716.09814453125 
[2025-02-07 04:38:05 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 3 loss:0.005477842874825001 norm:0.005005998071283102 max memory_allocated 29716.09814453125 
[2025-02-07 04:38:52 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 4 loss:0.005091831088066101 norm:0.0039782593958079815 max memory_allocated 29716.09814453125 
[2025-02-07 04:39:38 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 5 loss:0.004835694562643766 norm:0.003537451382726431 max memory_allocated 29716.09814453125 
[2025-02-07 04:40:25 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 6 loss:0.004662588704377413 norm:0.003253669012337923 max memory_allocated 29716.09814453125 
[2025-02-07 04:41:12 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 7 loss:0.004561185836791992 norm:0.002979092299938202 max memory_allocated 29716.09814453125 
[2025-02-07 04:41:58 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 8 loss:0.004486996680498123 norm:0.0026900735683739185 max memory_allocated 29716.09814453125 
[2025-02-07 04:42:45 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 9 loss:0.0043929098173975945 norm:0.0024960660375654697 max memory_allocated 29716.09814453125 
[2025-02-07 04:43:32 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 10 loss:0.004342452622950077 norm:0.0023058922961354256 max memory_allocated 29716.09814453125 
[2025-02-07 04:44:18 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 11 loss:0.004304033704102039 norm:0.0021959347650408745 max memory_allocated 29716.09814453125 
[2025-02-07 04:45:05 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 12 loss:0.004254589788615704 norm:0.0021291514858603477 max memory_allocated 29716.09814453125 
[2025-02-07 04:45:52 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 13 loss:0.004236069042235613 norm:0.001967947231605649 max memory_allocated 29716.09814453125 
[2025-02-07 04:46:38 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 14 loss:0.004225065000355244 norm:0.0019728972110897303 max memory_allocated 29716.09814453125 
[2025-02-07 04:47:25 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 15 loss:0.004206860437989235 norm:0.0018293134635314345 max memory_allocated 29716.09814453125 
[2025-02-07 04:48:12 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 16 loss:0.004153699614107609 norm:0.0017480943351984024 max memory_allocated 29716.09814453125 
[2025-02-07 04:48:59 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 17 loss:0.004144788254052401 norm:0.0016777381533756852 max memory_allocated 29716.09814453125 
[2025-02-07 04:49:45 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 18 loss:0.004163767211139202 norm:0.001657002023421228 max memory_allocated 29716.09814453125 
[2025-02-07 04:50:32 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 19 loss:0.004153900779783726 norm:0.0016220444813370705 max memory_allocated 29716.09814453125 
[2025-02-07 04:50:45 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 1 ===
[2025-02-07 04:50:57 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 04:51:43 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 0 loss:0.035964369773864746 norm:0.013064385391771793 max memory_allocated 29716.16064453125 
[2025-02-07 04:52:30 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 1 loss:0.026251237839460373 norm:0.008348256349563599 max memory_allocated 29716.16064453125 
[2025-02-07 04:53:17 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 2 loss:0.021828822791576385 norm:0.006110724527388811 max memory_allocated 29716.16064453125 
[2025-02-07 04:54:04 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 3 loss:0.020377276465296745 norm:0.005134901963174343 max memory_allocated 29716.16064453125 
[2025-02-07 04:54:51 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 4 loss:0.019705191254615784 norm:0.004481630399823189 max memory_allocated 29716.16064453125 
[2025-02-07 04:55:38 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 5 loss:0.019334418699145317 norm:0.004036158788949251 max memory_allocated 29716.16064453125 
[2025-02-07 04:56:24 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 6 loss:0.019034866243600845 norm:0.003617621026933193 max memory_allocated 29716.16064453125 
[2025-02-07 04:57:11 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 7 loss:0.018810853362083435 norm:0.0032920334488153458 max memory_allocated 29716.16064453125 
[2025-02-07 04:57:58 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 8 loss:0.01864226534962654 norm:0.002957192249596119 max memory_allocated 29716.16064453125 
[2025-02-07 04:58:45 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 9 loss:0.018461577594280243 norm:0.0027471384964883327 max memory_allocated 29716.16064453125 
[2025-02-07 04:59:32 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 10 loss:0.018357159569859505 norm:0.0026845603715628386 max memory_allocated 29716.16064453125 
[2025-02-07 05:00:19 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 11 loss:0.01828823983669281 norm:0.0026373101864010096 max memory_allocated 29716.16064453125 
[2025-02-07 05:01:06 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 12 loss:0.018244251608848572 norm:0.002505464479327202 max memory_allocated 29716.16064453125 
[2025-02-07 05:01:52 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 13 loss:0.018156757578253746 norm:0.0024813523050397635 max memory_allocated 29716.16064453125 
[2025-02-07 05:02:39 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 14 loss:0.0181451216340065 norm:0.002370987320318818 max memory_allocated 29716.16064453125 
[2025-02-07 05:03:26 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 15 loss:0.01804179511964321 norm:0.002344237407669425 max memory_allocated 29716.16064453125 
[2025-02-07 05:04:13 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 16 loss:0.018099144101142883 norm:0.002315736375749111 max memory_allocated 29716.16064453125 
[2025-02-07 05:05:00 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 17 loss:0.01797444373369217 norm:0.002266709227114916 max memory_allocated 29716.16064453125 
[2025-02-07 05:05:47 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 18 loss:0.018058380112051964 norm:0.002245234791189432 max memory_allocated 29716.16064453125 
[2025-02-07 05:06:34 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 19 loss:0.017948931083083153 norm:0.002222623210400343 max memory_allocated 29716.16064453125 
[2025-02-07 05:06:47 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 2 ===
[2025-02-07 05:06:58 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 05:07:45 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 0 loss:0.044710759073495865 norm:0.009387203492224216 max memory_allocated 29718.22314453125 
[2025-02-07 05:08:31 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 1 loss:0.03627464920282364 norm:0.007241244427859783 max memory_allocated 29718.22314453125 
[2025-02-07 05:09:18 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 2 loss:0.03185848146677017 norm:0.0053047421388328075 max memory_allocated 29718.22314453125 
[2025-02-07 05:10:05 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 3 loss:0.03023594617843628 norm:0.0042372094467282295 max memory_allocated 29718.22314453125 
[2025-02-07 05:10:52 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 4 loss:0.029481517150998116 norm:0.003525662934407592 max memory_allocated 29718.22314453125 
[2025-02-07 05:11:39 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 5 loss:0.02893725223839283 norm:0.0029625259339809418 max memory_allocated 29718.22314453125 
[2025-02-07 05:12:26 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 6 loss:0.02851978689432144 norm:0.002538918051868677 max memory_allocated 29718.22314453125 
[2025-02-07 05:13:13 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 7 loss:0.02830265276134014 norm:0.002512820530682802 max memory_allocated 29718.22314453125 
[2025-02-07 05:14:00 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 8 loss:0.02812868170440197 norm:0.002319210208952427 max memory_allocated 29718.22314453125 
[2025-02-07 05:14:47 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 9 loss:0.02795317955315113 norm:0.002176645677536726 max memory_allocated 29718.22314453125 
[2025-02-07 05:15:34 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 10 loss:0.027877142652869225 norm:0.002084516454488039 max memory_allocated 29718.22314453125 
[2025-02-07 05:16:21 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 11 loss:0.02783547341823578 norm:0.002077818615362048 max memory_allocated 29718.22314453125 
[2025-02-07 05:17:08 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 12 loss:0.027829609811306 norm:0.0021251882426440716 max memory_allocated 29718.22314453125 
[2025-02-07 05:17:55 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 13 loss:0.02790648862719536 norm:0.002082876395434141 max memory_allocated 29718.22314453125 
[2025-02-07 05:18:42 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 14 loss:0.027872271835803986 norm:0.002158389426767826 max memory_allocated 29718.22314453125 
[2025-02-07 05:19:29 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 15 loss:0.027829231694340706 norm:0.0020744199864566326 max memory_allocated 29718.22314453125 
[2025-02-07 05:20:16 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 16 loss:0.027795972302556038 norm:0.0020053419284522533 max memory_allocated 29718.22314453125 
[2025-02-07 05:21:03 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 17 loss:0.027769440785050392 norm:0.0019872193224728107 max memory_allocated 29718.22314453125 
[2025-02-07 05:21:50 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 18 loss:0.02775084227323532 norm:0.0018902829615399241 max memory_allocated 29718.22314453125 
[2025-02-07 05:22:37 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 19 loss:0.027705103158950806 norm:0.0018681136425584555 max memory_allocated 29718.22314453125 
[2025-02-07 05:22:50 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 3 ===
[2025-02-07 05:23:49 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 0 loss:0.15672272443771362 norm:0.013564767315983772 max memory_allocated 29722.14111328125 
[2025-02-07 05:24:36 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 1 loss:0.10470836609601974 norm:0.009112551808357239 max memory_allocated 29722.14111328125 
[2025-02-07 05:25:23 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 2 loss:0.06956413388252258 norm:0.005426773801445961 max memory_allocated 29722.14111328125 
[2025-02-07 05:26:09 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 3 loss:0.0670258179306984 norm:0.0038842889480292797 max memory_allocated 29722.14111328125 
[2025-02-07 05:26:56 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 4 loss:0.06463190913200378 norm:0.003440574510022998 max memory_allocated 29722.14111328125 
[2025-02-07 05:27:43 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 5 loss:0.06334414333105087 norm:0.0038136299699544907 max memory_allocated 29722.14111328125 
[2025-02-07 05:28:30 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 6 loss:0.06237563118338585 norm:0.00379739748314023 max memory_allocated 29722.14111328125 
[2025-02-07 05:29:17 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 7 loss:0.06255050003528595 norm:0.004601935390383005 max memory_allocated 29722.14111328125 
[2025-02-07 05:30:03 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 8 loss:0.061388928443193436 norm:0.004000389017164707 max memory_allocated 29722.14111328125 
[2025-02-07 05:30:50 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 9 loss:0.059966906905174255 norm:0.0039618536829948425 max memory_allocated 29722.14111328125 
[2025-02-07 05:31:37 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 10 loss:0.05962267145514488 norm:0.003477663267403841 max memory_allocated 29722.14111328125 
[2025-02-07 05:32:24 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 11 loss:0.05988609790802002 norm:0.002596221398562193 max memory_allocated 29722.14111328125 
[2025-02-07 05:33:11 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 12 loss:0.05952700227499008 norm:0.002443576231598854 max memory_allocated 29722.14111328125 
[2025-02-07 05:33:57 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 13 loss:0.059802159667015076 norm:0.0030035939998924732 max memory_allocated 29722.14111328125 
[2025-02-07 05:34:44 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 14 loss:0.059582050889730453 norm:0.0028085510712116957 max memory_allocated 29722.14111328125 
[2025-02-07 05:35:31 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 15 loss:0.05946020409464836 norm:0.0031958126928657293 max memory_allocated 29722.14111328125 
[2025-02-07 05:36:18 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 16 loss:0.059554215520620346 norm:0.004141084849834442 max memory_allocated 29722.14111328125 
[2025-02-07 05:37:04 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 17 loss:0.060641273856163025 norm:0.004120990168303251 max memory_allocated 29722.14111328125 
[2025-02-07 05:37:51 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 18 loss:0.05956080183386803 norm:0.003500642953440547 max memory_allocated 29722.14111328125 
[2025-02-07 05:38:38 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 19 loss:0.05909797176718712 norm:0.002644413150846958 max memory_allocated 29722.14111328125 
[2025-02-07 05:38:52 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 4 ===
[2025-02-07 05:39:53 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 0 loss:0.08112752437591553 norm:0.0031781145371496677 max memory_allocated 29724.20361328125 
[2025-02-07 05:40:40 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 1 loss:0.07137127965688705 norm:0.002259882166981697 max memory_allocated 29724.20361328125 
[2025-02-07 05:41:27 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 2 loss:0.06487791985273361 norm:0.0020359449554234743 max memory_allocated 29724.20361328125 
[2025-02-07 05:42:13 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 3 loss:0.06258326023817062 norm:0.0018551904940977693 max memory_allocated 29724.20361328125 
[2025-02-07 05:43:00 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 4 loss:0.061394862830638885 norm:0.001807464170269668 max memory_allocated 29724.20361328125 
[2025-02-07 05:43:47 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 5 loss:0.060630399733781815 norm:0.001745077082887292 max memory_allocated 29724.20361328125 
[2025-02-07 05:44:34 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 6 loss:0.060174256563186646 norm:0.001723018242046237 max memory_allocated 29724.20361328125 
[2025-02-07 05:45:20 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 7 loss:0.05997999757528305 norm:0.0016494352603331208 max memory_allocated 29724.20361328125 
[2025-02-07 05:46:07 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 8 loss:0.059870198369026184 norm:0.0016747612971812487 max memory_allocated 29724.20361328125 
[2025-02-07 05:46:54 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 9 loss:0.05978450924158096 norm:0.0016191581962630153 max memory_allocated 29724.20361328125 
[2025-02-07 05:47:41 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 10 loss:0.05974128097295761 norm:0.001632536994293332 max memory_allocated 29724.20361328125 
[2025-02-07 05:48:27 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 11 loss:0.059671469032764435 norm:0.0016097855987027287 max memory_allocated 29724.20361328125 
[2025-02-07 05:49:14 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 12 loss:0.059595588594675064 norm:0.0015703861135989428 max memory_allocated 29724.20361328125 
[2025-02-07 05:50:01 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 13 loss:0.059554655104875565 norm:0.001590736792422831 max memory_allocated 29724.20361328125 
[2025-02-07 05:50:48 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 14 loss:0.05952475219964981 norm:0.0015959694283083081 max memory_allocated 29724.20361328125 
[2025-02-07 05:51:34 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 15 loss:0.05953847989439964 norm:0.0016744632739573717 max memory_allocated 29724.20361328125 
[2025-02-07 05:52:21 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 16 loss:0.05948644503951073 norm:0.0015277795027941465 max memory_allocated 29724.20361328125 
[2025-02-07 05:53:08 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 17 loss:0.05948002636432648 norm:0.0016000086907297373 max memory_allocated 29724.20361328125 
[2025-02-07 05:53:55 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 18 loss:0.0594637468457222 norm:0.0015609180554747581 max memory_allocated 29724.20361328125 
[2025-02-07 05:54:41 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 19 loss:0.05951455235481262 norm:0.0015665794489905238 max memory_allocated 29724.20361328125 
[2025-02-07 05:54:55 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 5 ===
[2025-02-07 05:55:56 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 0 loss:0.09239184856414795 norm:0.0045752315782010555 max memory_allocated 29726.26611328125 
[2025-02-07 05:56:42 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 1 loss:0.07983523607254028 norm:0.002628712449222803 max memory_allocated 29726.26611328125 
[2025-02-07 05:57:29 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 2 loss:0.07242988049983978 norm:0.0020888608414679766 max memory_allocated 29726.26611328125 
[2025-02-07 05:58:16 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 3 loss:0.06956782191991806 norm:0.0017615684773772955 max memory_allocated 29726.26611328125 
[2025-02-07 05:59:02 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 4 loss:0.06804156303405762 norm:0.0016678640386089683 max memory_allocated 29726.26611328125 
[2025-02-07 05:59:49 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 5 loss:0.06713201105594635 norm:0.0015574510907754302 max memory_allocated 29726.26611328125 
[2025-02-07 06:00:36 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 6 loss:0.06667213141918182 norm:0.001534661278128624 max memory_allocated 29726.26611328125 
[2025-02-07 06:01:22 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 7 loss:0.0664076879620552 norm:0.0015165538061410189 max memory_allocated 29726.26611328125 
[2025-02-07 06:02:09 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 8 loss:0.06624690443277359 norm:0.0014813051093369722 max memory_allocated 29726.26611328125 
[2025-02-07 06:02:56 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 9 loss:0.06610138714313507 norm:0.0014968985924497247 max memory_allocated 29726.26611328125 
[2025-02-07 06:03:43 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 10 loss:0.0659753754734993 norm:0.0014665996422991157 max memory_allocated 29726.26611328125 
[2025-02-07 06:04:29 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 11 loss:0.06594282388687134 norm:0.001460223225876689 max memory_allocated 29726.26611328125 
[2025-02-07 06:05:16 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 12 loss:0.06587576866149902 norm:0.0014428460272029042 max memory_allocated 29726.26611328125 
[2025-02-07 06:06:03 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 13 loss:0.0658387690782547 norm:0.0013969301944598556 max memory_allocated 29726.26611328125 
[2025-02-07 06:06:50 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 14 loss:0.0658063143491745 norm:0.0014213771792128682 max memory_allocated 29726.26611328125 
[2025-02-07 06:07:36 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 15 loss:0.0657927617430687 norm:0.0014439088990911841 max memory_allocated 29726.26611328125 
[2025-02-07 06:08:23 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 16 loss:0.06579749286174774 norm:0.0014382593799382448 max memory_allocated 29726.26611328125 
[2025-02-07 06:09:10 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 17 loss:0.06581435352563858 norm:0.0014370394637808204 max memory_allocated 29726.26611328125 
[2025-02-07 06:09:57 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 18 loss:0.06574662029743195 norm:0.0014063103590160608 max memory_allocated 29726.26611328125 
[2025-02-07 06:10:43 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 19 loss:0.0657152459025383 norm:0.0013940756907686591 max memory_allocated 29726.26611328125 
[2025-02-07 06:10:57 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 6 ===
[2025-02-07 06:11:58 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 0 loss:0.09862153977155685 norm:0.005267829168587923 max memory_allocated 29728.32861328125 
[2025-02-07 06:12:45 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 1 loss:0.08482509851455688 norm:0.0028531074058264494 max memory_allocated 29728.32861328125 
[2025-02-07 06:13:31 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 2 loss:0.07709350436925888 norm:0.002395469229668379 max memory_allocated 29728.32861328125 
[2025-02-07 06:14:18 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 3 loss:0.07437493652105331 norm:0.002062297658994794 max memory_allocated 29728.32861328125 
[2025-02-07 06:15:05 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 4 loss:0.0729462131857872 norm:0.001988841686397791 max memory_allocated 29728.32861328125 
[2025-02-07 06:15:52 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 5 loss:0.07215728610754013 norm:0.0019449748797342181 max memory_allocated 29728.32861328125 
[2025-02-07 06:16:38 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 6 loss:0.07170159369707108 norm:0.0018959242152050138 max memory_allocated 29728.32861328125 
[2025-02-07 06:17:25 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 7 loss:0.07144661247730255 norm:0.0018718003993853927 max memory_allocated 29728.32861328125 
[2025-02-07 06:18:12 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 8 loss:0.07128489017486572 norm:0.0017614357639104128 max memory_allocated 29728.32861328125 
[2025-02-07 06:18:59 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 9 loss:0.07117998600006104 norm:0.0017691501416265965 max memory_allocated 29728.32861328125 
[2025-02-07 06:19:45 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 10 loss:0.07108177244663239 norm:0.0017933712806552649 max memory_allocated 29728.32861328125 
[2025-02-07 06:20:32 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 11 loss:0.07102329283952713 norm:0.0017191946972161531 max memory_allocated 29728.32861328125 
[2025-02-07 06:21:19 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 12 loss:0.07099627703428268 norm:0.0017541003180667758 max memory_allocated 29728.32861328125 
[2025-02-07 06:22:06 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 13 loss:0.07090682536363602 norm:0.0017785723321139812 max memory_allocated 29728.32861328125 
[2025-02-07 06:22:53 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 14 loss:0.07085596024990082 norm:0.0018086318159475923 max memory_allocated 29728.32861328125 
[2025-02-07 06:23:39 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 15 loss:0.07077337801456451 norm:0.0017062223050743341 max memory_allocated 29728.32861328125 
[2025-02-07 06:24:26 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 16 loss:0.07073504477739334 norm:0.0017547383904457092 max memory_allocated 29728.32861328125 
[2025-02-07 06:25:13 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 17 loss:0.07069895416498184 norm:0.0017366847023367882 max memory_allocated 29728.32861328125 
[2025-02-07 06:26:00 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 18 loss:0.07063678652048111 norm:0.0016602517571300268 max memory_allocated 29728.32861328125 
[2025-02-07 06:26:46 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 19 loss:0.07060389220714569 norm:0.0017039551166817546 max memory_allocated 29728.32861328125 
[2025-02-07 06:27:00 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 7 ===
[2025-02-07 06:27:57 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 0 loss:0.11229412257671356 norm:0.006187399849295616 max memory_allocated 29730.39111328125 
[2025-02-07 06:28:43 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 1 loss:0.09703239798545837 norm:0.003047094214707613 max memory_allocated 29730.39111328125 
[2025-02-07 06:29:30 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 2 loss:0.08823713660240173 norm:0.002505091717466712 max memory_allocated 29730.39111328125 
[2025-02-07 06:30:17 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 3 loss:0.08497965335845947 norm:0.0021704360842704773 max memory_allocated 29730.39111328125 
[2025-02-07 06:31:04 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 4 loss:0.08337163925170898 norm:0.002005999442189932 max memory_allocated 29730.39111328125 
[2025-02-07 06:31:50 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 5 loss:0.08250974118709564 norm:0.0020483052358031273 max memory_allocated 29730.39111328125 
[2025-02-07 06:32:37 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 6 loss:0.08196593075990677 norm:0.0019559436477720737 max memory_allocated 29730.39111328125 
[2025-02-07 06:33:24 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 7 loss:0.08173336088657379 norm:0.001828000065870583 max memory_allocated 29730.39111328125 
[2025-02-07 06:34:11 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 8 loss:0.08157798647880554 norm:0.001852213405072689 max memory_allocated 29730.39111328125 
[2025-02-07 06:34:58 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 9 loss:0.08139540255069733 norm:0.0018553429981693625 max memory_allocated 29730.39111328125 
[2025-02-07 06:35:44 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 10 loss:0.08127440512180328 norm:0.0018230723217129707 max memory_allocated 29730.39111328125 
[2025-02-07 06:36:31 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 11 loss:0.08116935193538666 norm:0.001850757165811956 max memory_allocated 29730.39111328125 
[2025-02-07 06:37:18 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 12 loss:0.08107529580593109 norm:0.0018825579900294542 max memory_allocated 29730.39111328125 
[2025-02-07 06:38:05 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 13 loss:0.08099547028541565 norm:0.0017980356933549047 max memory_allocated 29730.39111328125 
[2025-02-07 06:38:51 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 14 loss:0.08095761388540268 norm:0.0018302320968359709 max memory_allocated 29730.39111328125 
[2025-02-07 06:39:38 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 15 loss:0.08096463978290558 norm:0.0017567991744726896 max memory_allocated 29730.39111328125 
[2025-02-07 06:40:25 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 16 loss:0.08084309101104736 norm:0.0017327327514067292 max memory_allocated 29730.39111328125 
[2025-02-07 06:41:12 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 17 loss:0.08083862066268921 norm:0.0017693208064883947 max memory_allocated 29730.39111328125 
[2025-02-07 06:41:58 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 18 loss:0.08088182657957077 norm:0.001856352319009602 max memory_allocated 29730.39111328125 
[2025-02-07 06:42:45 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 19 loss:0.0808594599366188 norm:0.001805375679396093 max memory_allocated 29730.39111328125 
[2025-02-07 06:42:59 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 8 ===
[2025-02-07 06:43:54 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 0 loss:0.11344701051712036 norm:0.004322524182498455 max memory_allocated 29732.45361328125 
[2025-02-07 06:44:41 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 1 loss:0.10035648196935654 norm:0.0023941388353705406 max memory_allocated 29732.45361328125 
[2025-02-07 06:45:28 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 2 loss:0.09238029271364212 norm:0.002011677483096719 max memory_allocated 29732.45361328125 
[2025-02-07 06:46:15 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 3 loss:0.0894375890493393 norm:0.0019218821544200182 max memory_allocated 29732.45361328125 
[2025-02-07 06:47:01 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 4 loss:0.08806505799293518 norm:0.0018165401415899396 max memory_allocated 29732.45361328125 
[2025-02-07 06:47:48 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 5 loss:0.08727765083312988 norm:0.0017675783019512892 max memory_allocated 29732.45361328125 
[2025-02-07 06:48:35 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 6 loss:0.08683981001377106 norm:0.0017079950775951147 max memory_allocated 29732.45361328125 
[2025-02-07 06:49:22 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 7 loss:0.08659939467906952 norm:0.001637797337025404 max memory_allocated 29732.45361328125 
[2025-02-07 06:50:09 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 8 loss:0.08640316873788834 norm:0.0016564971301704645 max memory_allocated 29732.45361328125 
[2025-02-07 06:50:55 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 9 loss:0.08622918277978897 norm:0.0016193203628063202 max memory_allocated 29732.45361328125 
[2025-02-07 06:51:42 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 10 loss:0.08612340688705444 norm:0.0016733149532228708 max memory_allocated 29732.45361328125 
[2025-02-07 06:52:29 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 11 loss:0.0860276073217392 norm:0.001609398634172976 max memory_allocated 29732.45361328125 
[2025-02-07 06:53:16 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 12 loss:0.08594081550836563 norm:0.0015876730903983116 max memory_allocated 29732.45361328125 
[2025-02-07 06:54:03 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 13 loss:0.08584832400083542 norm:0.0015933709219098091 max memory_allocated 29732.45361328125 
[2025-02-07 06:54:49 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 14 loss:0.08578012883663177 norm:0.0015828351024538279 max memory_allocated 29732.45361328125 
[2025-02-07 06:55:36 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 15 loss:0.08576495200395584 norm:0.001487004105001688 max memory_allocated 29732.45361328125 
[2025-02-07 06:56:23 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 16 loss:0.08574800938367844 norm:0.0015681002987548709 max memory_allocated 29732.45361328125 
[2025-02-07 06:57:10 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 17 loss:0.08576001971960068 norm:0.0015560979954898357 max memory_allocated 29732.45361328125 
[2025-02-07 06:57:57 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 18 loss:0.0856894701719284 norm:0.0015704771503806114 max memory_allocated 29732.45361328125 
[2025-02-07 06:58:43 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 19 loss:0.08564403653144836 norm:0.001534713082946837 max memory_allocated 29732.45361328125 
[2025-02-07 06:58:57 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 9 ===
[2025-02-07 06:59:55 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 0 loss:0.14188142120838165 norm:0.011258751153945923 max memory_allocated 29734.51611328125 
[2025-02-07 07:00:42 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 1 loss:0.11928889900445938 norm:0.0036099187564104795 max memory_allocated 29734.51611328125 
[2025-02-07 07:01:29 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 2 loss:0.1076483279466629 norm:0.0029181307181715965 max memory_allocated 29734.51611328125 
[2025-02-07 07:02:16 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 3 loss:0.10239487886428833 norm:0.0022719919215887785 max memory_allocated 29734.51611328125 
[2025-02-07 07:03:03 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 4 loss:0.10015980899333954 norm:0.002096334006637335 max memory_allocated 29734.51611328125 
[2025-02-07 07:03:49 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 5 loss:0.09891143441200256 norm:0.001908599166199565 max memory_allocated 29734.51611328125 
[2025-02-07 07:04:36 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 6 loss:0.09818614274263382 norm:0.0018340089591220021 max memory_allocated 29734.51611328125 
[2025-02-07 07:05:23 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 7 loss:0.09773825854063034 norm:0.0017794716404750943 max memory_allocated 29734.51611328125 
[2025-02-07 07:06:10 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 8 loss:0.09744007885456085 norm:0.0016810984816402197 max memory_allocated 29734.51611328125 
[2025-02-07 07:06:57 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 9 loss:0.09717585891485214 norm:0.0016701569547876716 max memory_allocated 29734.51611328125 
[2025-02-07 07:07:43 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 10 loss:0.09700416773557663 norm:0.0016521872021257877 max memory_allocated 29734.51611328125 
[2025-02-07 07:08:30 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 11 loss:0.09686657786369324 norm:0.0015992731787264347 max memory_allocated 29734.51611328125 
[2025-02-07 07:09:17 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 12 loss:0.09672388434410095 norm:0.0016064478550106287 max memory_allocated 29734.51611328125 
[2025-02-07 07:10:04 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 13 loss:0.09664378315210342 norm:0.0015423778677359223 max memory_allocated 29734.51611328125 
[2025-02-07 07:10:51 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 14 loss:0.09658128023147583 norm:0.0015636285534128547 max memory_allocated 29734.51611328125 
[2025-02-07 07:11:38 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 15 loss:0.09649589657783508 norm:0.0015870039351284504 max memory_allocated 29734.51611328125 
[2025-02-07 07:12:24 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 16 loss:0.09643828868865967 norm:0.0015657104086130857 max memory_allocated 29734.51611328125 
[2025-02-07 07:13:11 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 17 loss:0.09635695815086365 norm:0.0015027059707790613 max memory_allocated 29734.51611328125 
[2025-02-07 07:13:58 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 18 loss:0.09632380306720734 norm:0.0015948913060128689 max memory_allocated 29734.51611328125 
[2025-02-07 07:14:45 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 19 loss:0.09624779969453812 norm:0.0015789871104061604 max memory_allocated 29734.51611328125 
[2025-02-07 07:14:59 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 10 ===
[2025-02-07 07:15:59 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 0 loss:0.1273600310087204 norm:0.0040262555703520775 max memory_allocated 29736.57861328125 
[2025-02-07 07:16:45 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 1 loss:0.11536302417516708 norm:0.002061106963083148 max memory_allocated 29736.57861328125 
[2025-02-07 07:17:32 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 2 loss:0.10794982314109802 norm:0.0017246794886887074 max memory_allocated 29736.57861328125 
[2025-02-07 07:18:19 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 3 loss:0.10506685823202133 norm:0.0015012685908004642 max memory_allocated 29736.57861328125 
[2025-02-07 07:19:06 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 4 loss:0.10363301634788513 norm:0.001387062482535839 max memory_allocated 29736.57861328125 
[2025-02-07 07:19:53 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 5 loss:0.10283493250608444 norm:0.0013285954482853413 max memory_allocated 29736.57861328125 
[2025-02-07 07:20:40 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 6 loss:0.10237029939889908 norm:0.0012775894720107317 max memory_allocated 29736.57861328125 
[2025-02-07 07:21:26 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 7 loss:0.10211490094661713 norm:0.0012602321803569794 max memory_allocated 29736.57861328125 
[2025-02-07 07:22:13 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 8 loss:0.10197828710079193 norm:0.0012158012250438333 max memory_allocated 29736.57861328125 
[2025-02-07 07:23:00 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 9 loss:0.10182422399520874 norm:0.0012342521222308278 max memory_allocated 29736.57861328125 
[2025-02-07 07:23:47 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 10 loss:0.10170505195856094 norm:0.0012093691620975733 max memory_allocated 29736.57861328125 
[2025-02-07 07:24:34 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 11 loss:0.10161074250936508 norm:0.0012169713154435158 max memory_allocated 29736.57861328125 
[2025-02-07 07:25:21 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 12 loss:0.101533442735672 norm:0.0012288261204957962 max memory_allocated 29736.57861328125 
[2025-02-07 07:26:07 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 13 loss:0.101475790143013 norm:0.0011986270546913147 max memory_allocated 29736.57861328125 
[2025-02-07 07:26:54 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 14 loss:0.10141196846961975 norm:0.001172279822640121 max memory_allocated 29736.57861328125 
[2025-02-07 07:27:41 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 15 loss:0.10137995332479477 norm:0.0011667535873129964 max memory_allocated 29736.57861328125 
[2025-02-07 07:28:28 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 16 loss:0.1013668030500412 norm:0.0011611499357968569 max memory_allocated 29736.57861328125 
[2025-02-07 07:29:15 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 17 loss:0.10131620615720749 norm:0.0011663113255053759 max memory_allocated 29736.57861328125 
[2025-02-07 07:30:01 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 18 loss:0.10129676014184952 norm:0.0011460670502856374 max memory_allocated 29736.57861328125 
[2025-02-07 07:30:48 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 19 loss:0.10127246379852295 norm:0.001155866775661707 max memory_allocated 29736.57861328125 
[2025-02-07 07:31:02 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 11 ===
[2025-02-07 07:32:00 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 0 loss:0.12864625453948975 norm:0.003646922530606389 max memory_allocated 29738.64111328125 
[2025-02-07 07:32:47 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 1 loss:0.11752746254205704 norm:0.0016857400769367814 max memory_allocated 29738.64111328125 
[2025-02-07 07:33:34 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 2 loss:0.11088650673627853 norm:0.001415630686096847 max memory_allocated 29738.64111328125 
[2025-02-07 07:34:21 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 3 loss:0.10860566794872284 norm:0.0011918139643967152 max memory_allocated 29738.64111328125 
[2025-02-07 07:35:07 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 4 loss:0.10737665742635727 norm:0.001116408035159111 max memory_allocated 29738.64111328125 
[2025-02-07 07:35:54 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 5 loss:0.10666872560977936 norm:0.0010445257648825645 max memory_allocated 29738.64111328125 
[2025-02-07 07:36:41 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 6 loss:0.10627871006727219 norm:0.0010532441083341837 max memory_allocated 29738.64111328125 
[2025-02-07 07:37:28 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 7 loss:0.10606186836957932 norm:0.0010172517504543066 max memory_allocated 29738.64111328125 
[2025-02-07 07:38:15 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 8 loss:0.10589650273323059 norm:0.0010420556645840406 max memory_allocated 29738.64111328125 
[2025-02-07 07:39:01 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 9 loss:0.10574910044670105 norm:0.0009803336579352617 max memory_allocated 29738.64111328125 
[2025-02-07 07:39:48 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 10 loss:0.10564735531806946 norm:0.0009704465628601611 max memory_allocated 29738.64111328125 
[2025-02-07 07:40:35 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 11 loss:0.1055755466222763 norm:0.0009637685725465417 max memory_allocated 29738.64111328125 
[2025-02-07 07:41:22 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 12 loss:0.10552805662155151 norm:0.0009613997535780072 max memory_allocated 29738.64111328125 
[2025-02-07 07:42:09 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 13 loss:0.10550981014966965 norm:0.0009568132227286696 max memory_allocated 29738.64111328125 
[2025-02-07 07:42:56 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 14 loss:0.10546360909938812 norm:0.0009677314083091915 max memory_allocated 29738.64111328125 
[2025-02-07 07:43:43 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 15 loss:0.10540536791086197 norm:0.0009942774195224047 max memory_allocated 29738.64111328125 
[2025-02-07 07:44:29 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 16 loss:0.10535483807325363 norm:0.0010042815702036023 max memory_allocated 29738.64111328125 
[2025-02-07 07:45:16 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 17 loss:0.10532235354185104 norm:0.0009899995056912303 max memory_allocated 29738.64111328125 
[2025-02-07 07:46:03 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 18 loss:0.10531634092330933 norm:0.0009607939864508808 max memory_allocated 29738.64111328125 
[2025-02-07 07:46:50 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 19 loss:0.10528135299682617 norm:0.000952491769567132 max memory_allocated 29738.64111328125 
[2025-02-07 07:47:04 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 12 ===
[2025-02-07 07:48:00 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 0 loss:0.13487251102924347 norm:0.004104821011424065 max memory_allocated 29740.70361328125 
[2025-02-07 07:48:47 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 1 loss:0.123393215239048 norm:0.001944808871485293 max memory_allocated 29740.70361328125 
[2025-02-07 07:49:34 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 2 loss:0.11600537598133087 norm:0.0015728306025266647 max memory_allocated 29740.70361328125 
[2025-02-07 07:50:21 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 3 loss:0.11322212964296341 norm:0.0013303339947015047 max memory_allocated 29740.70361328125 
[2025-02-07 07:51:07 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 4 loss:0.11193882673978806 norm:0.001231472590006888 max memory_allocated 29740.70361328125 
[2025-02-07 07:51:54 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 5 loss:0.11126894503831863 norm:0.0011889637680724263 max memory_allocated 29740.70361328125 
[2025-02-07 07:52:41 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 6 loss:0.11082983762025833 norm:0.001117160078138113 max memory_allocated 29740.70361328125 
[2025-02-07 07:53:28 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 7 loss:0.11057101935148239 norm:0.001062579220160842 max memory_allocated 29740.70361328125 
[2025-02-07 07:54:15 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 8 loss:0.1103835329413414 norm:0.0010143419494852424 max memory_allocated 29740.70361328125 
[2025-02-07 07:55:01 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 9 loss:0.1102912425994873 norm:0.001068674959242344 max memory_allocated 29740.70361328125 
[2025-02-07 07:55:48 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 10 loss:0.11020884662866592 norm:0.0010692820651456714 max memory_allocated 29740.70361328125 
[2025-02-07 07:56:35 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 11 loss:0.11012407392263412 norm:0.001058118767105043 max memory_allocated 29740.70361328125 
[2025-02-07 07:57:22 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 12 loss:0.11005523800849915 norm:0.0010341104352846742 max memory_allocated 29740.70361328125 
[2025-02-07 07:58:09 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 13 loss:0.10999314486980438 norm:0.001023386139422655 max memory_allocated 29740.70361328125 
[2025-02-07 07:58:56 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 14 loss:0.10994424670934677 norm:0.0010406142100691795 max memory_allocated 29740.70361328125 
[2025-02-07 07:59:42 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 15 loss:0.10987390577793121 norm:0.0010797963477671146 max memory_allocated 29740.70361328125 
[2025-02-07 08:00:29 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 16 loss:0.10982492566108704 norm:0.001052226172760129 max memory_allocated 29740.70361328125 
[2025-02-07 08:01:16 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 17 loss:0.10980074107646942 norm:0.0010126186534762383 max memory_allocated 29740.70361328125 
[2025-02-07 08:02:03 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 18 loss:0.10980989038944244 norm:0.0010353478137403727 max memory_allocated 29740.70361328125 
[2025-02-07 08:02:50 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 19 loss:0.10979705303907394 norm:0.0010250837076455355 max memory_allocated 29740.70361328125 
[2025-02-07 08:03:03 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 13 ===
[2025-02-07 08:04:00 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 0 loss:0.13666433095932007 norm:0.0041702548041939735 max memory_allocated 29742.76611328125 
[2025-02-07 08:04:47 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 1 loss:0.12587261199951172 norm:0.0017064419807866216 max memory_allocated 29742.76611328125 
[2025-02-07 08:05:34 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 2 loss:0.11896950751543045 norm:0.0014013259205967188 max memory_allocated 29742.76611328125 
[2025-02-07 08:06:21 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 3 loss:0.11608418822288513 norm:0.0012081157183274627 max memory_allocated 29742.76611328125 
[2025-02-07 08:07:08 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 4 loss:0.11473779380321503 norm:0.0011588307097554207 max memory_allocated 29742.76611328125 
[2025-02-07 08:07:54 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 5 loss:0.11398249864578247 norm:0.0011087133316323161 max memory_allocated 29742.76611328125 
[2025-02-07 08:08:41 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 6 loss:0.11355482041835785 norm:0.0011579834390431643 max memory_allocated 29742.76611328125 
[2025-02-07 08:09:28 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 7 loss:0.11326289176940918 norm:0.0011109358165413141 max memory_allocated 29742.76611328125 
[2025-02-07 08:10:15 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 8 loss:0.11307662725448608 norm:0.0010724416933953762 max memory_allocated 29742.76611328125 
[2025-02-07 08:11:02 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 9 loss:0.1129499226808548 norm:0.0010604487033560872 max memory_allocated 29742.76611328125 
[2025-02-07 08:11:48 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 10 loss:0.11280400305986404 norm:0.0010469186818227172 max memory_allocated 29742.76611328125 
[2025-02-07 08:12:35 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 11 loss:0.11271414160728455 norm:0.0010618031956255436 max memory_allocated 29742.76611328125 
[2025-02-07 08:13:22 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 12 loss:0.11261672526597977 norm:0.001047781901434064 max memory_allocated 29742.76611328125 
[2025-02-07 08:14:09 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 13 loss:0.11253845691680908 norm:0.0010067584225907922 max memory_allocated 29742.76611328125 
[2025-02-07 08:14:56 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 14 loss:0.11248365789651871 norm:0.0010021210182458162 max memory_allocated 29742.76611328125 
[2025-02-07 08:15:43 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 15 loss:0.11241982877254486 norm:0.0010164519771933556 max memory_allocated 29742.76611328125 
[2025-02-07 08:16:29 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 16 loss:0.11240538954734802 norm:0.0009855368407443166 max memory_allocated 29742.76611328125 
[2025-02-07 08:17:16 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 17 loss:0.11237156391143799 norm:0.0010104477405548096 max memory_allocated 29742.76611328125 
[2025-02-07 08:18:03 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 18 loss:0.11232665181159973 norm:0.0010158309014514089 max memory_allocated 29742.76611328125 
[2025-02-07 08:18:50 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 19 loss:0.11228423565626144 norm:0.0009825138840824366 max memory_allocated 29742.76611328125 
[2025-02-07 08:19:03 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 14 ===
[2025-02-07 08:20:01 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 0 loss:0.13837972283363342 norm:0.0026366664096713066 max memory_allocated 29744.82861328125 
[2025-02-07 08:20:47 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 1 loss:0.1285131573677063 norm:0.0015911010559648275 max memory_allocated 29744.82861328125 
[2025-02-07 08:21:34 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 2 loss:0.1220463290810585 norm:0.0013057389296591282 max memory_allocated 29744.82861328125 
[2025-02-07 08:22:21 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 3 loss:0.119566410779953 norm:0.0011743833310902119 max memory_allocated 29744.82861328125 
[2025-02-07 08:23:08 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 4 loss:0.1184130534529686 norm:0.0010948715498670936 max memory_allocated 29744.82861328125 
[2025-02-07 08:23:54 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 5 loss:0.1176876574754715 norm:0.0010507226688787341 max memory_allocated 29744.82861328125 
[2025-02-07 08:24:41 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 6 loss:0.11725513637065887 norm:0.0010384971974417567 max memory_allocated 29744.82861328125 
[2025-02-07 08:25:28 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 7 loss:0.11694471538066864 norm:0.0009697048226371408 max memory_allocated 29744.82861328125 
[2025-02-07 08:26:15 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 8 loss:0.1167612299323082 norm:0.0009551880648359656 max memory_allocated 29744.82861328125 
[2025-02-07 08:27:02 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 9 loss:0.11661768704652786 norm:0.0009569730027578771 max memory_allocated 29744.82861328125 
[2025-02-07 08:27:49 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 10 loss:0.1164872795343399 norm:0.0009626911487430334 max memory_allocated 29744.82861328125 
[2025-02-07 08:28:35 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 11 loss:0.11639750003814697 norm:0.0009588710963726044 max memory_allocated 29744.82861328125 
[2025-02-07 08:29:22 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 12 loss:0.11632107943296432 norm:0.0009754693601280451 max memory_allocated 29744.82861328125 
[2025-02-07 08:30:09 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 13 loss:0.11627493053674698 norm:0.0009393783984705806 max memory_allocated 29744.82861328125 
[2025-02-07 08:30:56 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 14 loss:0.11622420698404312 norm:0.0010078037157654762 max memory_allocated 29744.82861328125 
[2025-02-07 08:31:43 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 15 loss:0.11616393178701401 norm:0.0009542773477733135 max memory_allocated 29744.82861328125 
[2025-02-07 08:32:29 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 16 loss:0.11613275110721588 norm:0.0009811128256842494 max memory_allocated 29744.82861328125 
[2025-02-07 08:33:16 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 17 loss:0.11610252410173416 norm:0.0009617367759346962 max memory_allocated 29744.82861328125 
[2025-02-07 08:34:03 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 18 loss:0.11607958376407623 norm:0.0009511466487310827 max memory_allocated 29744.82861328125 
[2025-02-07 08:34:50 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 19 loss:0.11605413258075714 norm:0.0009497462888248265 max memory_allocated 29744.82861328125 
[2025-02-07 08:35:04 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 15 ===
[2025-02-07 08:35:59 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 0 loss:0.13257767260074615 norm:0.0021743993274867535 max memory_allocated 29746.89111328125 
[2025-02-07 08:36:46 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 1 loss:0.1250850111246109 norm:0.0015246144030243158 max memory_allocated 29746.89111328125 
[2025-02-07 08:37:33 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 2 loss:0.11993281543254852 norm:0.001421653083525598 max memory_allocated 29746.89111328125 
[2025-02-07 08:38:19 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 3 loss:0.1180817186832428 norm:0.0012813705252483487 max memory_allocated 29746.89111328125 
[2025-02-07 08:39:06 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 4 loss:0.11704361438751221 norm:0.001199060003273189 max memory_allocated 29746.89111328125 
[2025-02-07 08:39:53 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 5 loss:0.11640992015600204 norm:0.0011732779676094651 max memory_allocated 29746.89111328125 
[2025-02-07 08:40:40 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 6 loss:0.11599582433700562 norm:0.0011560196289792657 max memory_allocated 29746.89111328125 
[2025-02-07 08:41:27 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 7 loss:0.11575420200824738 norm:0.0011254920391365886 max memory_allocated 29746.89111328125 
[2025-02-07 08:42:13 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 8 loss:0.11561708152294159 norm:0.0010900007328018546 max memory_allocated 29746.89111328125 
[2025-02-07 08:43:00 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 9 loss:0.11548907309770584 norm:0.0010691683273762465 max memory_allocated 29746.89111328125 
[2025-02-07 08:43:47 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 10 loss:0.11541658639907837 norm:0.0010939070489257574 max memory_allocated 29746.89111328125 
[2025-02-07 08:44:34 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 11 loss:0.11532121896743774 norm:0.0010549400467425585 max memory_allocated 29746.89111328125 
[2025-02-07 08:45:21 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 12 loss:0.11523576080799103 norm:0.0010542916133999825 max memory_allocated 29746.89111328125 
[2025-02-07 08:46:07 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 13 loss:0.11515339463949203 norm:0.0010430540423840284 max memory_allocated 29746.89111328125 
[2025-02-07 08:46:54 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 14 loss:0.11509490758180618 norm:0.0010699033737182617 max memory_allocated 29746.89111328125 
[2025-02-07 08:47:41 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 15 loss:0.11502963304519653 norm:0.0010646437294781208 max memory_allocated 29746.89111328125 
[2025-02-07 08:48:28 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 16 loss:0.11501869559288025 norm:0.0010657691163942218 max memory_allocated 29746.89111328125 
[2025-02-07 08:49:15 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 17 loss:0.11500392854213715 norm:0.0010638448875397444 max memory_allocated 29746.89111328125 
[2025-02-07 08:50:01 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 18 loss:0.11496298760175705 norm:0.0010342387249693274 max memory_allocated 29746.89111328125 
[2025-02-07 08:50:48 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 19 loss:0.11493352055549622 norm:0.001028409693390131 max memory_allocated 29746.89111328125 
[2025-02-07 08:51:02 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 16 ===
[2025-02-07 08:51:59 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 0 loss:0.13913872838020325 norm:0.003168007591739297 max memory_allocated 29748.95361328125 
[2025-02-07 08:52:46 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 1 loss:0.1295536458492279 norm:0.0017210057703778148 max memory_allocated 29748.95361328125 
[2025-02-07 08:53:33 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 2 loss:0.12340451031923294 norm:0.001515029463917017 max memory_allocated 29748.95361328125 
[2025-02-07 08:54:20 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 3 loss:0.1207580491900444 norm:0.00134883145801723 max memory_allocated 29748.95361328125 
[2025-02-07 08:55:06 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 4 loss:0.11945727467536926 norm:0.001242901780642569 max memory_allocated 29748.95361328125 
[2025-02-07 08:55:53 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 5 loss:0.11868377029895782 norm:0.0011498191161081195 max memory_allocated 29748.95361328125 
[2025-02-07 08:56:40 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 6 loss:0.1182335615158081 norm:0.001145198242738843 max memory_allocated 29748.95361328125 
[2025-02-07 08:57:27 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 7 loss:0.11793152242898941 norm:0.0010858841706067324 max memory_allocated 29748.95361328125 
[2025-02-07 08:58:14 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 8 loss:0.11773236095905304 norm:0.0011106623569503427 max memory_allocated 29748.95361328125 
[2025-02-07 08:59:01 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 9 loss:0.11758700013160706 norm:0.0010795887792482972 max memory_allocated 29748.95361328125 
[2025-02-07 08:59:47 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 10 loss:0.11748217046260834 norm:0.00107498187571764 max memory_allocated 29748.95361328125 
[2025-02-07 09:00:34 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 11 loss:0.11736761033535004 norm:0.0010754198301583529 max memory_allocated 29748.95361328125 
[2025-02-07 09:01:21 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 12 loss:0.11725714057683945 norm:0.0010296726832166314 max memory_allocated 29748.95361328125 
[2025-02-07 09:02:08 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 13 loss:0.11717389523983002 norm:0.001015816000290215 max memory_allocated 29748.95361328125 
[2025-02-07 09:02:55 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 14 loss:0.11707393825054169 norm:0.0009998390451073647 max memory_allocated 29748.95361328125 
[2025-02-07 09:03:41 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 15 loss:0.11704115569591522 norm:0.0010118130594491959 max memory_allocated 29748.95361328125 
[2025-02-07 09:04:28 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 16 loss:0.1169920414686203 norm:0.0010170552413910627 max memory_allocated 29748.95361328125 
[2025-02-07 09:05:15 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 17 loss:0.11695466190576553 norm:0.0009968875674530864 max memory_allocated 29748.95361328125 
[2025-02-07 09:06:02 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 18 loss:0.11692320555448532 norm:0.0010142640676349401 max memory_allocated 29748.95361328125 
[2025-02-07 09:06:49 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 19 loss:0.11689581722021103 norm:0.0009945461060851812 max memory_allocated 29748.95361328125 
[2025-02-07 09:07:02 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 17 ===
[2025-02-07 09:08:06 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 0 loss:0.13743941485881805 norm:0.0024538319557905197 max memory_allocated 29751.01611328125 
[2025-02-07 09:08:53 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 1 loss:0.1291288435459137 norm:0.0014567417092621326 max memory_allocated 29751.01611328125 
[2025-02-07 09:09:39 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 2 loss:0.12329315394163132 norm:0.001424951828084886 max memory_allocated 29751.01611328125 
[2025-02-07 09:10:26 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 3 loss:0.12085311114788055 norm:0.001256332965567708 max memory_allocated 29751.01611328125 
[2025-02-07 09:11:13 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 4 loss:0.1195768192410469 norm:0.001143667846918106 max memory_allocated 29751.01611328125 
[2025-02-07 09:12:00 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 5 loss:0.11881911754608154 norm:0.0010975680779665709 max memory_allocated 29751.01611328125 
[2025-02-07 09:12:47 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 6 loss:0.11840378493070602 norm:0.0010713085066527128 max memory_allocated 29751.01611328125 
[2025-02-07 09:13:34 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 7 loss:0.11816783249378204 norm:0.0010221624979749322 max memory_allocated 29751.01611328125 
[2025-02-07 09:14:20 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 8 loss:0.11802805215120316 norm:0.0010686344467103481 max memory_allocated 29751.01611328125 
[2025-02-07 09:15:07 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 9 loss:0.11790939420461655 norm:0.0011067568557336926 max memory_allocated 29751.01611328125 
[2025-02-07 09:15:54 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 10 loss:0.11779213696718216 norm:0.0010256827808916569 max memory_allocated 29751.01611328125 
[2025-02-07 09:16:41 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 11 loss:0.1177210882306099 norm:0.001068192534148693 max memory_allocated 29751.01611328125 
[2025-02-07 09:17:28 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 12 loss:0.11766596138477325 norm:0.0010574087500572205 max memory_allocated 29751.01611328125 
[2025-02-07 09:18:15 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 13 loss:0.11761673539876938 norm:0.0010393719421699643 max memory_allocated 29751.01611328125 
[2025-02-07 09:19:02 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 14 loss:0.11755721271038055 norm:0.001014331472106278 max memory_allocated 29751.01611328125 
[2025-02-07 09:19:49 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 15 loss:0.1175517812371254 norm:0.0010011978447437286 max memory_allocated 29751.01611328125 
[2025-02-07 09:20:35 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 16 loss:0.11754637956619263 norm:0.001030297251418233 max memory_allocated 29751.01611328125 
[2025-02-07 09:21:22 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 17 loss:0.11752216517925262 norm:0.0010320647852495313 max memory_allocated 29751.01611328125 
[2025-02-07 09:22:09 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 18 loss:0.11749144643545151 norm:0.000982843921519816 max memory_allocated 29751.01611328125 
[2025-02-07 09:22:56 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 19 loss:0.11747047305107117 norm:0.000991280423477292 max memory_allocated 29751.01611328125 
[2025-02-07 09:23:10 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 18 ===
[2025-02-07 09:24:09 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 0 loss:0.1352938711643219 norm:0.0019402940524742007 max memory_allocated 29753.07861328125 
[2025-02-07 09:24:56 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 1 loss:0.12780852615833282 norm:0.001229314599186182 max memory_allocated 29753.07861328125 
[2025-02-07 09:25:43 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 2 loss:0.12296675890684128 norm:0.0010807850630953908 max memory_allocated 29753.07861328125 
[2025-02-07 09:26:30 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 3 loss:0.12115564197301865 norm:0.0010255386587232351 max memory_allocated 29753.07861328125 
[2025-02-07 09:27:17 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 4 loss:0.12000854313373566 norm:0.0009853077353909612 max memory_allocated 29753.07861328125 
[2025-02-07 09:28:04 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 5 loss:0.1193065419793129 norm:0.0009539228631183505 max memory_allocated 29753.07861328125 
[2025-02-07 09:28:51 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 6 loss:0.11893048882484436 norm:0.0009246292756870389 max memory_allocated 29753.07861328125 
[2025-02-07 09:29:37 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 7 loss:0.11872212588787079 norm:0.0009335268405266106 max memory_allocated 29753.07861328125 
[2025-02-07 09:30:24 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 8 loss:0.11857074499130249 norm:0.0009150524856522679 max memory_allocated 29753.07861328125 
[2025-02-07 09:31:11 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 9 loss:0.1184619665145874 norm:0.0008783130906522274 max memory_allocated 29753.07861328125 
[2025-02-07 09:31:58 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 10 loss:0.11836663633584976 norm:0.0008506865706294775 max memory_allocated 29753.07861328125 
[2025-02-07 09:32:45 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 11 loss:0.11828409135341644 norm:0.000833517755381763 max memory_allocated 29753.07861328125 
[2025-02-07 09:33:32 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 12 loss:0.11819842457771301 norm:0.0008023441187106073 max memory_allocated 29753.07861328125 
[2025-02-07 09:34:19 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 13 loss:0.11815584450960159 norm:0.000802191614639014 max memory_allocated 29753.07861328125 
[2025-02-07 09:35:05 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 14 loss:0.11810342222452164 norm:0.0007902919314801693 max memory_allocated 29753.07861328125 
[2025-02-07 09:35:52 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 15 loss:0.11805737018585205 norm:0.0007810107781551778 max memory_allocated 29753.07861328125 
[2025-02-07 09:36:39 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 16 loss:0.11801185458898544 norm:0.0007649635663256049 max memory_allocated 29753.07861328125 
[2025-02-07 09:37:26 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 17 loss:0.11799802631139755 norm:0.0007949016289785504 max memory_allocated 29753.07861328125 
[2025-02-07 09:38:13 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 18 loss:0.11797000467777252 norm:0.0007808929076418281 max memory_allocated 29753.07861328125 
[2025-02-07 09:39:00 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 19 loss:0.11793850362300873 norm:0.0007850619731470942 max memory_allocated 29753.07861328125 
[2025-02-07 09:39:13 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 19 ===
[2025-02-07 09:40:11 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 0 loss:0.1388319432735443 norm:0.0018125622300431132 max memory_allocated 29755.14111328125 
[2025-02-07 09:40:58 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 1 loss:0.13184916973114014 norm:0.0013203106354922056 max memory_allocated 29755.14111328125 
[2025-02-07 09:41:45 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 2 loss:0.12679283320903778 norm:0.0012189553817734122 max memory_allocated 29755.14111328125 
[2025-02-07 09:42:32 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 3 loss:0.12478812038898468 norm:0.0011381714139133692 max memory_allocated 29755.14111328125 
[2025-02-07 09:43:19 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 4 loss:0.12359157204627991 norm:0.0010708050103858113 max memory_allocated 29755.14111328125 
[2025-02-07 09:44:06 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 5 loss:0.12283876538276672 norm:0.0010200481628999114 max memory_allocated 29755.14111328125 
[2025-02-07 09:44:53 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 6 loss:0.12242590636014938 norm:0.0009642083314247429 max memory_allocated 29755.14111328125 
[2025-02-07 09:45:39 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 7 loss:0.12219604104757309 norm:0.0009842171566560864 max memory_allocated 29755.14111328125 
[2025-02-07 09:46:26 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 8 loss:0.12206002324819565 norm:0.001003581564873457 max memory_allocated 29755.14111328125 
[2025-02-07 09:47:13 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 9 loss:0.12194548547267914 norm:0.0009565568179823458 max memory_allocated 29755.14111328125 
[2025-02-07 09:48:00 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 10 loss:0.12188910692930222 norm:0.0009617421310395002 max memory_allocated 29755.14111328125 
[2025-02-07 09:48:47 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 11 loss:0.12180884182453156 norm:0.0009479074506089091 max memory_allocated 29755.14111328125 
[2025-02-07 09:49:34 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 12 loss:0.12174294143915176 norm:0.0009199221385642886 max memory_allocated 29755.14111328125 
[2025-02-07 09:50:21 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 13 loss:0.12168662250041962 norm:0.0009020904544740915 max memory_allocated 29755.14111328125 
[2025-02-07 09:51:07 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 14 loss:0.12165115773677826 norm:0.0009220584761351347 max memory_allocated 29755.14111328125 
[2025-02-07 09:51:54 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 15 loss:0.12161734700202942 norm:0.0009089246159419417 max memory_allocated 29755.14111328125 
[2025-02-07 09:52:41 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 16 loss:0.12158871442079544 norm:0.0009364234283566475 max memory_allocated 29755.14111328125 
[2025-02-07 09:53:28 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 17 loss:0.12156672030687332 norm:0.0008976798853836954 max memory_allocated 29755.14111328125 
[2025-02-07 09:54:15 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 18 loss:0.12153252959251404 norm:0.0008861985406838357 max memory_allocated 29755.14111328125 
[2025-02-07 09:55:02 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 19 loss:0.12152225524187088 norm:0.0008939458057284355 max memory_allocated 29755.14111328125 
[2025-02-07 09:55:16 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 20 ===
[2025-02-07 09:56:12 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 0 loss:0.1389172524213791 norm:0.0016116478946059942 max memory_allocated 29757.20361328125 
[2025-02-07 09:56:59 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 1 loss:0.1330375075340271 norm:0.001126773189753294 max memory_allocated 29757.20361328125 
[2025-02-07 09:57:46 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 2 loss:0.12861591577529907 norm:0.001009632251225412 max memory_allocated 29757.20361328125 
[2025-02-07 09:58:33 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 3 loss:0.12725014984607697 norm:0.000983513193204999 max memory_allocated 29757.20361328125 
[2025-02-07 09:59:20 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 4 loss:0.126348614692688 norm:0.0009269075817428529 max memory_allocated 29757.20361328125 
[2025-02-07 10:00:07 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 5 loss:0.1257026046514511 norm:0.0009017969714477658 max memory_allocated 29757.20361328125 
[2025-02-07 10:00:54 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 6 loss:0.1253690868616104 norm:0.0008859065710566938 max memory_allocated 29757.20361328125 
[2025-02-07 10:01:40 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 7 loss:0.1251688450574875 norm:0.0008622512686997652 max memory_allocated 29757.20361328125 
[2025-02-07 10:02:27 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 8 loss:0.12503491342067719 norm:0.0008655624696984887 max memory_allocated 29757.20361328125 
[2025-02-07 10:03:14 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 9 loss:0.12494071573019028 norm:0.0008498029201291502 max memory_allocated 29757.20361328125 
[2025-02-07 10:04:01 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 10 loss:0.12486934661865234 norm:0.000864833069499582 max memory_allocated 29757.20361328125 
[2025-02-07 10:04:48 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 11 loss:0.124809131026268 norm:0.0008684921194799244 max memory_allocated 29757.20361328125 
[2025-02-07 10:05:35 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 12 loss:0.12474234402179718 norm:0.0008675371063873172 max memory_allocated 29757.20361328125 
[2025-02-07 10:06:22 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 13 loss:0.12469448149204254 norm:0.0008110889466479421 max memory_allocated 29757.20361328125 
[2025-02-07 10:07:09 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 14 loss:0.12464865297079086 norm:0.0007892035646364093 max memory_allocated 29757.20361328125 
[2025-02-07 10:07:56 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 15 loss:0.12460581958293915 norm:0.0007843700586818159 max memory_allocated 29757.20361328125 
[2025-02-07 10:08:43 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 16 loss:0.1245827004313469 norm:0.0007908810512162745 max memory_allocated 29757.20361328125 
[2025-02-07 10:09:29 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 17 loss:0.12455220520496368 norm:0.0007942495867609978 max memory_allocated 29757.20361328125 
[2025-02-07 10:10:16 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 18 loss:0.12453886866569519 norm:0.0007984168478287756 max memory_allocated 29757.20361328125 
[2025-02-07 10:11:03 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 19 loss:0.12453066557645798 norm:0.000809400575235486 max memory_allocated 29757.20361328125 
[2025-02-07 10:11:17 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 21 ===
[2025-02-07 10:12:24 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 0 loss:0.138305202126503 norm:0.0017497813096269965 max memory_allocated 29759.26611328125 
[2025-02-07 10:13:11 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 1 loss:0.1344960778951645 norm:0.00116931542288512 max memory_allocated 29759.26611328125 
[2025-02-07 10:13:57 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 2 loss:0.13239265978336334 norm:0.0010660956613719463 max memory_allocated 29759.26611328125 
[2025-02-07 10:14:44 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 3 loss:0.13063359260559082 norm:0.0010080988286063075 max memory_allocated 29759.26611328125 
[2025-02-07 10:15:31 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 4 loss:0.12947851419448853 norm:0.0009188629337586462 max memory_allocated 29759.26611328125 
[2025-02-07 10:16:18 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 5 loss:0.12880179286003113 norm:0.0009183169458992779 max memory_allocated 29759.26611328125 
[2025-02-07 10:17:05 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 6 loss:0.12844547629356384 norm:0.0008908333256840706 max memory_allocated 29759.26611328125 
[2025-02-07 10:17:52 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 7 loss:0.12826146185398102 norm:0.0008756968891248107 max memory_allocated 29759.26611328125 
[2025-02-07 10:18:39 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 8 loss:0.1281430721282959 norm:0.000840632535982877 max memory_allocated 29759.26611328125 
[2025-02-07 10:19:26 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 9 loss:0.1280810385942459 norm:0.0008333417936228216 max memory_allocated 29759.26611328125 
[2025-02-07 10:20:12 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 10 loss:0.12802092730998993 norm:0.0008249203092418611 max memory_allocated 29759.26611328125 
[2025-02-07 10:20:59 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 11 loss:0.1279633343219757 norm:0.0007982458919286728 max memory_allocated 29759.26611328125 
[2025-02-07 10:21:46 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 12 loss:0.1279401332139969 norm:0.0007907385588623583 max memory_allocated 29759.26611328125 
[2025-02-07 10:22:33 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 13 loss:0.12791158258914948 norm:0.0007967628189362586 max memory_allocated 29759.26611328125 
[2025-02-07 10:23:20 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 14 loss:0.1278650462627411 norm:0.0007723222952336073 max memory_allocated 29759.26611328125 
[2025-02-07 10:24:07 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 15 loss:0.12783095240592957 norm:0.0007488682749681175 max memory_allocated 29759.26611328125 
[2025-02-07 10:24:54 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 16 loss:0.12781259417533875 norm:0.0007225299486890435 max memory_allocated 29759.26611328125 
[2025-02-07 10:25:41 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 17 loss:0.12780123949050903 norm:0.000723734381608665 max memory_allocated 29759.26611328125 
[2025-02-07 10:26:28 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 18 loss:0.12780089676380157 norm:0.0007316741393879056 max memory_allocated 29759.26611328125 
[2025-02-07 10:27:15 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 19 loss:0.12779094278812408 norm:0.0007200049585662782 max memory_allocated 29759.26611328125 
[2025-02-07 10:27:28 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 22 ===
[2025-02-07 10:28:25 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 0 loss:0.14977075159549713 norm:0.0011780380737036467 max memory_allocated 29761.32861328125 
[2025-02-07 10:29:12 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 1 loss:0.14401790499687195 norm:0.0008288854151032865 max memory_allocated 29761.32861328125 
[2025-02-07 10:29:59 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 2 loss:0.1394057720899582 norm:0.0007251315983012319 max memory_allocated 29761.32861328125 
[2025-02-07 10:30:45 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 3 loss:0.13783690333366394 norm:0.0006681210943497717 max memory_allocated 29761.32861328125 
[2025-02-07 10:31:32 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 4 loss:0.13676957786083221 norm:0.0006488252547569573 max memory_allocated 29761.32861328125 
[2025-02-07 10:32:19 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 5 loss:0.13602082431316376 norm:0.000633192656096071 max memory_allocated 29761.32861328125 
[2025-02-07 10:33:06 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 6 loss:0.13568593561649323 norm:0.0006239393842406571 max memory_allocated 29761.32861328125 
[2025-02-07 10:33:53 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 7 loss:0.13551191985607147 norm:0.0006076863501220942 max memory_allocated 29761.32861328125 
[2025-02-07 10:34:40 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 8 loss:0.13539665937423706 norm:0.0005730036064051092 max memory_allocated 29761.32861328125 
[2025-02-07 10:35:27 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 9 loss:0.13531340658664703 norm:0.0005600301083177328 max memory_allocated 29761.32861328125 
[2025-02-07 10:36:14 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 10 loss:0.13523656129837036 norm:0.0005482569104060531 max memory_allocated 29761.32861328125 
[2025-02-07 10:37:01 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 11 loss:0.13518741726875305 norm:0.0005584847531281412 max memory_allocated 29761.32861328125 
[2025-02-07 10:37:47 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 12 loss:0.13512709736824036 norm:0.0005404629046097398 max memory_allocated 29761.32861328125 
[2025-02-07 10:38:34 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 13 loss:0.13507896661758423 norm:0.0005324981175363064 max memory_allocated 29761.32861328125 
[2025-02-07 10:39:21 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 14 loss:0.13505828380584717 norm:0.0005345368990674615 max memory_allocated 29761.32861328125 
[2025-02-07 10:40:08 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 15 loss:0.13502700626850128 norm:0.000518023211043328 max memory_allocated 29761.32861328125 
[2025-02-07 10:40:55 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 16 loss:0.13501130044460297 norm:0.00051477225497365 max memory_allocated 29761.32861328125 
[2025-02-07 10:41:42 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 17 loss:0.1349821835756302 norm:0.0005038471426814795 max memory_allocated 29761.32861328125 
[2025-02-07 10:42:29 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 18 loss:0.13494646549224854 norm:0.0005071962368674576 max memory_allocated 29761.32861328125 
[2025-02-07 10:43:16 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 19 loss:0.13492342829704285 norm:0.0004980259109288454 max memory_allocated 29761.32861328125 
[2025-02-07 10:43:30 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 23 ===
[2025-02-07 10:44:26 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 0 loss:0.1586981862783432 norm:0.0011068714084103703 max memory_allocated 29763.39111328125 
[2025-02-07 10:45:13 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 1 loss:0.15300814807415009 norm:0.0008668010705150664 max memory_allocated 29763.39111328125 
[2025-02-07 10:46:00 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 2 loss:0.14827367663383484 norm:0.0007581408135592937 max memory_allocated 29763.39111328125 
[2025-02-07 10:46:47 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 3 loss:0.1468145251274109 norm:0.0007212184718810022 max memory_allocated 29763.39111328125 
[2025-02-07 10:47:34 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 4 loss:0.14576196670532227 norm:0.0006984245264902711 max memory_allocated 29763.39111328125 
[2025-02-07 10:48:21 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 5 loss:0.1449742317199707 norm:0.0006840556161478162 max memory_allocated 29763.39111328125 
[2025-02-07 10:49:07 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 6 loss:0.14461059868335724 norm:0.0006624783272854984 max memory_allocated 29763.39111328125 
[2025-02-07 10:49:54 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 7 loss:0.14443746209144592 norm:0.0006371251656673849 max memory_allocated 29763.39111328125 
[2025-02-07 10:50:41 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 8 loss:0.14431330561637878 norm:0.0006323278066702187 max memory_allocated 29763.39111328125 
[2025-02-07 10:51:28 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 9 loss:0.14421318471431732 norm:0.000603847554884851 max memory_allocated 29763.39111328125 
[2025-02-07 10:52:15 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 10 loss:0.14411917328834534 norm:0.0005975321400910616 max memory_allocated 29763.39111328125 
[2025-02-07 10:53:02 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 11 loss:0.14405472576618195 norm:0.0005792536539956927 max memory_allocated 29763.39111328125 
[2025-02-07 10:53:49 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 12 loss:0.14401087164878845 norm:0.0005794829921796918 max memory_allocated 29763.39111328125 
[2025-02-07 10:54:36 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 13 loss:0.14396879076957703 norm:0.000591372954659164 max memory_allocated 29763.39111328125 
[2025-02-07 10:55:23 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 14 loss:0.14391614496707916 norm:0.0005743434885516763 max memory_allocated 29763.39111328125 
[2025-02-07 10:56:10 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 15 loss:0.1438770294189453 norm:0.0005833124159835279 max memory_allocated 29763.39111328125 
[2025-02-07 10:56:56 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 16 loss:0.14385072886943817 norm:0.0005748866824433208 max memory_allocated 29763.39111328125 
[2025-02-07 10:57:43 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 17 loss:0.14383485913276672 norm:0.0005853611510246992 max memory_allocated 29763.39111328125 
[2025-02-07 10:58:30 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 18 loss:0.14380860328674316 norm:0.0005650282837450504 max memory_allocated 29763.39111328125 
[2025-02-07 10:59:17 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 19 loss:0.14378871023654938 norm:0.0005694938590750098 max memory_allocated 29763.39111328125 
[2025-02-07 10:59:31 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 24 ===
[2025-02-07 11:00:32 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 0 loss:0.16761460900306702 norm:0.0013840083265677094 max memory_allocated 29765.45361328125 
[2025-02-07 11:01:19 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 1 loss:0.16241355240345 norm:0.0011387401027604938 max memory_allocated 29765.45361328125 
[2025-02-07 11:02:06 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 2 loss:0.1576920747756958 norm:0.0011048519518226385 max memory_allocated 29765.45361328125 
[2025-02-07 11:02:53 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 3 loss:0.1564120352268219 norm:0.001111441059038043 max memory_allocated 29765.45361328125 
[2025-02-07 11:03:40 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 4 loss:0.15549881756305695 norm:0.00105668930336833 max memory_allocated 29765.45361328125 
[2025-02-07 11:04:27 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 5 loss:0.1547994464635849 norm:0.0010105571709573269 max memory_allocated 29765.45361328125 
[2025-02-07 11:05:14 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 6 loss:0.15448680520057678 norm:0.001011229702271521 max memory_allocated 29765.45361328125 
[2025-02-07 11:06:00 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 7 loss:0.15433549880981445 norm:0.0009660513023845851 max memory_allocated 29765.45361328125 
[2025-02-07 11:06:47 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 8 loss:0.15421508252620697 norm:0.0009453633683733642 max memory_allocated 29765.45361328125 
[2025-02-07 11:07:34 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 9 loss:0.15412507951259613 norm:0.0009325647843070328 max memory_allocated 29765.45361328125 
[2025-02-07 11:08:21 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 10 loss:0.15406548976898193 norm:0.0009374907240271568 max memory_allocated 29765.45361328125 
[2025-02-07 11:09:08 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 11 loss:0.1540197730064392 norm:0.0009518745355308056 max memory_allocated 29765.45361328125 
[2025-02-07 11:09:55 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 12 loss:0.15396060049533844 norm:0.0009430813952349126 max memory_allocated 29765.45361328125 
[2025-02-07 11:10:42 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 13 loss:0.1539245843887329 norm:0.0009668439743109047 max memory_allocated 29765.45361328125 
[2025-02-07 11:11:29 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 14 loss:0.1538878083229065 norm:0.0009609106928110123 max memory_allocated 29765.45361328125 
[2025-02-07 11:12:15 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 15 loss:0.15387064218521118 norm:0.0009475749102421105 max memory_allocated 29765.45361328125 
[2025-02-07 11:13:02 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 16 loss:0.15383312106132507 norm:0.000956250645685941 max memory_allocated 29765.45361328125 
[2025-02-07 11:13:49 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 17 loss:0.15380045771598816 norm:0.0009477323619648814 max memory_allocated 29765.45361328125 
[2025-02-07 11:14:36 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 18 loss:0.15378011763095856 norm:0.0009685666300356388 max memory_allocated 29765.45361328125 
[2025-02-07 11:15:23 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 19 loss:0.15375368297100067 norm:0.0009386032470501959 max memory_allocated 29765.45361328125 
[2025-02-07 11:15:37 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 25 ===
[2025-02-07 11:16:36 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 0 loss:0.18184372782707214 norm:0.0011785576352849603 max memory_allocated 29767.51611328125 
[2025-02-07 11:17:23 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 1 loss:0.17610156536102295 norm:0.0008784800884313881 max memory_allocated 29767.51611328125 
[2025-02-07 11:18:10 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 2 loss:0.17097191512584686 norm:0.0007832697592675686 max memory_allocated 29767.51611328125 
[2025-02-07 11:18:56 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 3 loss:0.16938140988349915 norm:0.0007386869401670992 max memory_allocated 29767.51611328125 
[2025-02-07 11:19:43 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 4 loss:0.16821348667144775 norm:0.0006869991193525493 max memory_allocated 29767.51611328125 
[2025-02-07 11:20:30 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 5 loss:0.1673826277256012 norm:0.0006962589686736465 max memory_allocated 29767.51611328125 
[2025-02-07 11:21:17 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 6 loss:0.16703571379184723 norm:0.0006461893790401518 max memory_allocated 29767.51611328125 
[2025-02-07 11:22:03 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 7 loss:0.16686956584453583 norm:0.0006297400686889887 max memory_allocated 29767.51611328125 
[2025-02-07 11:22:50 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 8 loss:0.16674859821796417 norm:0.0006147318636067212 max memory_allocated 29767.51611328125 
[2025-02-07 11:23:37 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 9 loss:0.16665613651275635 norm:0.0005981300491839647 max memory_allocated 29767.51611328125 
[2025-02-07 11:24:24 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 10 loss:0.1665796935558319 norm:0.0005946826422587037 max memory_allocated 29767.51611328125 
[2025-02-07 11:25:11 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 11 loss:0.16652435064315796 norm:0.0005884923739358783 max memory_allocated 29767.51611328125 
[2025-02-07 11:25:57 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 12 loss:0.16648390889167786 norm:0.0005990170175209641 max memory_allocated 29767.51611328125 
[2025-02-07 11:26:44 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 13 loss:0.16642636060714722 norm:0.0006047974457032979 max memory_allocated 29767.51611328125 
[2025-02-07 11:27:31 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 14 loss:0.16638785600662231 norm:0.000616930949036032 max memory_allocated 29767.51611328125 
[2025-02-07 11:28:18 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 15 loss:0.16635942459106445 norm:0.0006316901417449117 max memory_allocated 29767.51611328125 
[2025-02-07 11:29:04 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 16 loss:0.16632509231567383 norm:0.0006085447384975851 max memory_allocated 29767.51611328125 
[2025-02-07 11:29:51 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 17 loss:0.16629275679588318 norm:0.0005911913467571139 max memory_allocated 29767.51611328125 
[2025-02-07 11:30:38 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 18 loss:0.1662577986717224 norm:0.0005765640526078641 max memory_allocated 29767.51611328125 
[2025-02-07 11:31:25 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 19 loss:0.16623835265636444 norm:0.0005764180095866323 max memory_allocated 29767.51611328125 
[2025-02-07 11:31:39 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 26 ===
[2025-02-07 11:32:39 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 0 loss:0.19717669486999512 norm:0.0011772209545597434 max memory_allocated 29769.57861328125 
[2025-02-07 11:33:25 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 1 loss:0.1909468173980713 norm:0.000935652235057205 max memory_allocated 29769.57861328125 
[2025-02-07 11:34:12 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 2 loss:0.18532320857048035 norm:0.0008286216761916876 max memory_allocated 29769.57861328125 
[2025-02-07 11:34:59 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 3 loss:0.1836550384759903 norm:0.0007869742694310844 max memory_allocated 29769.57861328125 
[2025-02-07 11:35:46 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 4 loss:0.18243408203125 norm:0.0007424245704896748 max memory_allocated 29769.57861328125 
[2025-02-07 11:36:32 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 5 loss:0.18164634704589844 norm:0.0007255824748426676 max memory_allocated 29769.57861328125 
[2025-02-07 11:37:19 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 6 loss:0.18131282925605774 norm:0.0007106433040462434 max memory_allocated 29769.57861328125 
[2025-02-07 11:38:06 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 7 loss:0.18113522231578827 norm:0.0006887830095365644 max memory_allocated 29769.57861328125 
[2025-02-07 11:38:53 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 8 loss:0.18102732300758362 norm:0.000679244811180979 max memory_allocated 29769.57861328125 
[2025-02-07 11:39:40 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 9 loss:0.18091881275177002 norm:0.000667286803945899 max memory_allocated 29769.57861328125 
[2025-02-07 11:40:26 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 10 loss:0.18083341419696808 norm:0.0006516149151138961 max memory_allocated 29769.57861328125 
[2025-02-07 11:41:13 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 11 loss:0.18077029287815094 norm:0.0006422559381462634 max memory_allocated 29769.57861328125 
[2025-02-07 11:42:00 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 12 loss:0.18071262538433075 norm:0.0006414692034013569 max memory_allocated 29769.57861328125 
[2025-02-07 11:42:47 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 13 loss:0.1806701421737671 norm:0.0006513212574645877 max memory_allocated 29769.57861328125 
[2025-02-07 11:43:34 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 14 loss:0.18062631785869598 norm:0.00063348124967888 max memory_allocated 29769.57861328125 
[2025-02-07 11:44:20 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 15 loss:0.1805802881717682 norm:0.0006187555845826864 max memory_allocated 29769.57861328125 
[2025-02-07 11:45:07 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 16 loss:0.1805523931980133 norm:0.0006226140540093184 max memory_allocated 29769.57861328125 
[2025-02-07 11:45:54 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 17 loss:0.18051567673683167 norm:0.00062035076553002 max memory_allocated 29769.57861328125 
[2025-02-07 11:46:41 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 18 loss:0.18048810958862305 norm:0.000624290551058948 max memory_allocated 29769.57861328125 
[2025-02-07 11:47:28 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 19 loss:0.18046677112579346 norm:0.0006099472520872951 max memory_allocated 29769.57861328125 
[2025-02-07 11:47:41 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 27 ===
[2025-02-07 11:48:40 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 0 loss:0.20017863810062408 norm:0.0009718762012198567 max memory_allocated 29771.64111328125 
[2025-02-07 11:49:27 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 1 loss:0.1985589563846588 norm:0.000823299924377352 max memory_allocated 29771.64111328125 
[2025-02-07 11:50:14 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 2 loss:0.19749754667282104 norm:0.0007626778678968549 max memory_allocated 29771.64111328125 
[2025-02-07 11:51:01 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 3 loss:0.1963324397802353 norm:0.0007134373299777508 max memory_allocated 29771.64111328125 
[2025-02-07 11:51:48 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 4 loss:0.19515956938266754 norm:0.0006714846822433174 max memory_allocated 29771.64111328125 
[2025-02-07 11:52:34 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 5 loss:0.19450464844703674 norm:0.0006322760600596666 max memory_allocated 29771.64111328125 
[2025-02-07 11:53:21 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 6 loss:0.19428518414497375 norm:0.0006370771443471313 max memory_allocated 29771.64111328125 
[2025-02-07 11:54:08 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 7 loss:0.1941620111465454 norm:0.0006044161855243146 max memory_allocated 29771.64111328125 
[2025-02-07 11:54:55 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 8 loss:0.1941034346818924 norm:0.0006160057964734733 max memory_allocated 29771.64111328125 
[2025-02-07 11:55:42 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 9 loss:0.19404391944408417 norm:0.000598501181229949 max memory_allocated 29771.64111328125 
[2025-02-07 11:56:28 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 10 loss:0.19400891661643982 norm:0.0005926776211708784 max memory_allocated 29771.64111328125 
[2025-02-07 11:57:15 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 11 loss:0.19398988783359528 norm:0.000583520857617259 max memory_allocated 29771.64111328125 
[2025-02-07 11:58:02 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 12 loss:0.1939893513917923 norm:0.0005839510122314095 max memory_allocated 29771.64111328125 
[2025-02-07 11:58:49 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 13 loss:0.19396349787712097 norm:0.0005607989151030779 max memory_allocated 29771.64111328125 
[2025-02-07 11:59:36 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 14 loss:0.1939590573310852 norm:0.0005707351956516504 max memory_allocated 29771.64111328125 
[2025-02-07 12:00:22 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 15 loss:0.19394634664058685 norm:0.0005596386035904288 max memory_allocated 29771.64111328125 
[2025-02-07 12:01:09 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 16 loss:0.19392946362495422 norm:0.0005484520806930959 max memory_allocated 29771.64111328125 
[2025-02-07 12:01:56 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 17 loss:0.19392624497413635 norm:0.0005420030793175101 max memory_allocated 29771.64111328125 
[2025-02-07 12:02:43 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 18 loss:0.19391778111457825 norm:0.0005407480639405549 max memory_allocated 29771.64111328125 
[2025-02-07 12:03:30 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 19 loss:0.19390980899333954 norm:0.0005448253941722214 max memory_allocated 29771.64111328125 
[2025-02-07 12:03:43 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 28 ===
[2025-02-07 12:04:41 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 0 loss:0.23513734340667725 norm:0.0040070354007184505 max memory_allocated 29773.70361328125 
[2025-02-07 12:05:28 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 1 loss:0.22774171829223633 norm:0.0030012456700205803 max memory_allocated 29773.70361328125 
[2025-02-07 12:06:15 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 2 loss:0.22131137549877167 norm:0.0027050625067204237 max memory_allocated 29773.70361328125 
[2025-02-07 12:07:01 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 3 loss:0.21915355324745178 norm:0.0027611705008894205 max memory_allocated 29773.70361328125 
[2025-02-07 12:07:48 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 4 loss:0.2176019847393036 norm:0.0023979104589670897 max memory_allocated 29773.70361328125 
[2025-02-07 12:08:35 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 5 loss:0.21684226393699646 norm:0.0025586707051843405 max memory_allocated 29773.70361328125 
[2025-02-07 12:09:22 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 6 loss:0.2165108472108841 norm:0.002419333439320326 max memory_allocated 29773.70361328125 
[2025-02-07 12:10:09 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 7 loss:0.21628430485725403 norm:0.002330104587599635 max memory_allocated 29773.70361328125 
[2025-02-07 12:10:55 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 8 loss:0.216103196144104 norm:0.002179559087380767 max memory_allocated 29773.70361328125 
[2025-02-07 12:11:42 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 9 loss:0.2159750610589981 norm:0.0021901698783040047 max memory_allocated 29773.70361328125 
[2025-02-07 12:12:29 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 10 loss:0.21588018536567688 norm:0.0023090261965990067 max memory_allocated 29773.70361328125 
[2025-02-07 12:13:16 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 11 loss:0.21577982604503632 norm:0.00227820104919374 max memory_allocated 29773.70361328125 
[2025-02-07 12:14:02 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 12 loss:0.21571138501167297 norm:0.0022647040896117687 max memory_allocated 29773.70361328125 
[2025-02-07 12:14:49 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 13 loss:0.21562309563159943 norm:0.0022410168312489986 max memory_allocated 29773.70361328125 
[2025-02-07 12:15:36 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 14 loss:0.21555034816265106 norm:0.0022336093243211508 max memory_allocated 29773.70361328125 
[2025-02-07 12:16:23 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 15 loss:0.21550719439983368 norm:0.002156307687982917 max memory_allocated 29773.70361328125 
[2025-02-07 12:17:10 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 16 loss:0.21546131372451782 norm:0.0021177150774747133 max memory_allocated 29773.70361328125 
[2025-02-07 12:17:56 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 17 loss:0.21541592478752136 norm:0.0019982890225946903 max memory_allocated 29773.70361328125 
[2025-02-07 12:18:43 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 18 loss:0.2154371589422226 norm:0.0021335124038159847 max memory_allocated 29773.70361328125 
[2025-02-07 12:19:30 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 19 loss:0.21536877751350403 norm:0.0020701915491372347 max memory_allocated 29773.70361328125 
[2025-02-07 12:19:44 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 29 ===
[2025-02-07 12:20:41 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 0 loss:0.2555416226387024 norm:0.0009540071478113532 max memory_allocated 29775.76611328125 
[2025-02-07 12:21:27 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 1 loss:0.24846328794956207 norm:0.0007437504245899618 max memory_allocated 29775.76611328125 
[2025-02-07 12:22:14 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 2 loss:0.24184012413024902 norm:0.0006979818572290242 max memory_allocated 29775.76611328125 
[2025-02-07 12:23:01 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 3 loss:0.2397499978542328 norm:0.0006878330605104566 max memory_allocated 29775.76611328125 
[2025-02-07 12:23:48 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 4 loss:0.23830072581768036 norm:0.0006412697257474065 max memory_allocated 29775.76611328125 
[2025-02-07 12:24:34 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 5 loss:0.2376551330089569 norm:0.0006226144032552838 max memory_allocated 29775.76611328125 
[2025-02-07 12:25:21 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 6 loss:0.23738065361976624 norm:0.0006155678420327604 max memory_allocated 29775.76611328125 
[2025-02-07 12:26:08 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 7 loss:0.2371734380722046 norm:0.0005906707374379039 max memory_allocated 29775.76611328125 
[2025-02-07 12:26:55 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 8 loss:0.23704414069652557 norm:0.0005738959880545735 max memory_allocated 29775.76611328125 
[2025-02-07 12:27:42 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 9 loss:0.23694412410259247 norm:0.0005737583269365132 max memory_allocated 29775.76611328125 
[2025-02-07 12:28:28 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 10 loss:0.23684526979923248 norm:0.0005617638817057014 max memory_allocated 29775.76611328125 
[2025-02-07 12:29:15 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 11 loss:0.23676475882530212 norm:0.0005643341573886573 max memory_allocated 29775.76611328125 
[2025-02-07 12:30:02 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 12 loss:0.23669886589050293 norm:0.0005492445197887719 max memory_allocated 29775.76611328125 
[2025-02-07 12:30:49 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 13 loss:0.23664860427379608 norm:0.0005363007658161223 max memory_allocated 29775.76611328125 
[2025-02-07 12:31:36 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 14 loss:0.23658213019371033 norm:0.0005200267187319696 max memory_allocated 29775.76611328125 
[2025-02-07 12:32:22 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 15 loss:0.2365434467792511 norm:0.0005226045032031834 max memory_allocated 29775.76611328125 
[2025-02-07 12:33:09 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 16 loss:0.2365165650844574 norm:0.0005159093998372555 max memory_allocated 29775.76611328125 
[2025-02-07 12:33:56 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 17 loss:0.2364712357521057 norm:0.0005051890038885176 max memory_allocated 29775.76611328125 
[2025-02-07 12:34:43 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 18 loss:0.2364407777786255 norm:0.0005062561249360442 max memory_allocated 29775.76611328125 
[2025-02-07 12:35:30 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 19 loss:0.2364068180322647 norm:0.0005030177417211235 max memory_allocated 29775.76611328125 
[2025-02-07 12:35:43 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 30 ===
[2025-02-07 12:36:39 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 0 loss:0.2842576503753662 norm:0.001195737742818892 max memory_allocated 29777.82861328125 
[2025-02-07 12:37:26 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 1 loss:0.2755233943462372 norm:0.0009177058818750083 max memory_allocated 29777.82861328125 
[2025-02-07 12:38:13 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 2 loss:0.26755771040916443 norm:0.000819659442640841 max memory_allocated 29777.82861328125 
[2025-02-07 12:39:00 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 3 loss:0.26494643092155457 norm:0.0007728441851213574 max memory_allocated 29777.82861328125 
[2025-02-07 12:39:46 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 4 loss:0.26336947083473206 norm:0.0007725261966697872 max memory_allocated 29777.82861328125 
[2025-02-07 12:40:33 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 5 loss:0.2627353072166443 norm:0.0007622658158652484 max memory_allocated 29777.82861328125 
[2025-02-07 12:41:20 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 6 loss:0.26244407892227173 norm:0.0007312194793485105 max memory_allocated 29777.82861328125 
[2025-02-07 12:42:07 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 7 loss:0.2622406482696533 norm:0.0007092482992447913 max memory_allocated 29777.82861328125 
[2025-02-07 12:42:54 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 8 loss:0.26209577918052673 norm:0.0006810993072576821 max memory_allocated 29777.82861328125 
[2025-02-07 12:43:40 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 9 loss:0.2619746923446655 norm:0.0006696333875879645 max memory_allocated 29777.82861328125 
[2025-02-07 12:44:27 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 10 loss:0.2618730068206787 norm:0.0006731122266501188 max memory_allocated 29777.82861328125 
[2025-02-07 12:45:14 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 11 loss:0.26177382469177246 norm:0.0006442953599616885 max memory_allocated 29777.82861328125 
[2025-02-07 12:46:01 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 12 loss:0.26169320940971375 norm:0.0006421813159249723 max memory_allocated 29777.82861328125 
[2025-02-07 12:46:47 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 13 loss:0.26162856817245483 norm:0.0006536681321449578 max memory_allocated 29777.82861328125 
[2025-02-07 12:47:34 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 14 loss:0.2615813910961151 norm:0.0006301846005953848 max memory_allocated 29777.82861328125 
[2025-02-07 12:48:21 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 15 loss:0.2615290880203247 norm:0.0006350931944325566 max memory_allocated 29777.82861328125 
[2025-02-07 12:49:08 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 16 loss:0.2614830434322357 norm:0.0006235686596482992 max memory_allocated 29777.82861328125 
[2025-02-07 12:49:55 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 17 loss:0.2614426016807556 norm:0.0006329995230771601 max memory_allocated 29777.82861328125 
[2025-02-07 12:50:41 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 18 loss:0.2614084780216217 norm:0.0006269394070841372 max memory_allocated 29777.82861328125 
[2025-02-07 12:51:28 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 19 loss:0.2613674998283386 norm:0.0006249205907806754 max memory_allocated 29777.82861328125 
[2025-02-07 12:51:42 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 31 ===
[2025-02-07 12:52:39 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 0 loss:0.3106265068054199 norm:0.0009914186084643006 max memory_allocated 29779.89111328125 
[2025-02-07 12:53:25 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 1 loss:0.3022465705871582 norm:0.0007386503275483847 max memory_allocated 29779.89111328125 
[2025-02-07 12:54:12 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 2 loss:0.2942022681236267 norm:0.0006643250817433 max memory_allocated 29779.89111328125 
[2025-02-07 12:54:59 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 3 loss:0.2914860248565674 norm:0.0006136376759968698 max memory_allocated 29779.89111328125 
[2025-02-07 12:55:45 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 4 loss:0.28994378447532654 norm:0.0005899819079786539 max memory_allocated 29779.89111328125 
[2025-02-07 12:56:32 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 5 loss:0.28940704464912415 norm:0.0005624477053061128 max memory_allocated 29779.89111328125 
[2025-02-07 12:57:19 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 6 loss:0.28915727138519287 norm:0.0005385844269767404 max memory_allocated 29779.89111328125 
[2025-02-07 12:58:06 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 7 loss:0.28898516297340393 norm:0.0005390639416873455 max memory_allocated 29779.89111328125 
[2025-02-07 12:58:52 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 8 loss:0.28883519768714905 norm:0.0005285660736262798 max memory_allocated 29779.89111328125 
[2025-02-07 12:59:39 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 9 loss:0.28870677947998047 norm:0.0005226858775131404 max memory_allocated 29779.89111328125 
[2025-02-07 13:00:26 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 10 loss:0.2886156141757965 norm:0.0005124987219460309 max memory_allocated 29779.89111328125 
[2025-02-07 13:01:13 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 11 loss:0.2885335087776184 norm:0.000514466199092567 max memory_allocated 29779.89111328125 
[2025-02-07 13:02:00 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 12 loss:0.28846293687820435 norm:0.0004972130409441888 max memory_allocated 29779.89111328125 
[2025-02-07 13:02:46 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 13 loss:0.2883981764316559 norm:0.0005012557958252728 max memory_allocated 29779.89111328125 
[2025-02-07 13:03:33 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 14 loss:0.2883395254611969 norm:0.0004953638999722898 max memory_allocated 29779.89111328125 
[2025-02-07 13:04:20 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 15 loss:0.2882838845252991 norm:0.000503046321682632 max memory_allocated 29779.89111328125 
[2025-02-07 13:05:07 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 16 loss:0.28824326395988464 norm:0.0004938915371894836 max memory_allocated 29779.89111328125 
[2025-02-07 13:05:53 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 17 loss:0.28819143772125244 norm:0.000485025200759992 max memory_allocated 29779.89111328125 
[2025-02-07 13:06:40 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 18 loss:0.2881697714328766 norm:0.0004922384396195412 max memory_allocated 29779.89111328125 
[2025-02-07 13:07:27 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 19 loss:0.2881336510181427 norm:0.00048614738625474274 max memory_allocated 29779.89111328125 
[2025-02-07 13:07:41 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 32 ===
[2025-02-07 13:08:36 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 0 loss:0.3254241645336151 norm:0.0013903279323130846 max memory_allocated 29781.95361328125 
[2025-02-07 13:09:23 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 1 loss:0.32278451323509216 norm:0.001130781602114439 max memory_allocated 29781.95361328125 
[2025-02-07 13:10:10 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 2 loss:0.3208658993244171 norm:0.000996183604001999 max memory_allocated 29781.95361328125 
[2025-02-07 13:10:57 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 3 loss:0.3186267614364624 norm:0.0009684098185971379 max memory_allocated 29781.95361328125 
[2025-02-07 13:11:43 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 4 loss:0.3170892000198364 norm:0.0009059763979166746 max memory_allocated 29781.95361328125 
[2025-02-07 13:12:30 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 5 loss:0.31668224930763245 norm:0.0008315592422150075 max memory_allocated 29781.95361328125 
[2025-02-07 13:13:17 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 6 loss:0.3164966106414795 norm:0.0008212605025619268 max memory_allocated 29781.95361328125 
[2025-02-07 13:14:04 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 7 loss:0.3163772225379944 norm:0.0007963190437294543 max memory_allocated 29781.95361328125 
[2025-02-07 13:14:50 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 8 loss:0.3162844181060791 norm:0.0007539066718891263 max memory_allocated 29781.95361328125 
[2025-02-07 13:15:37 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 9 loss:0.3162387013435364 norm:0.0007460351916961372 max memory_allocated 29781.95361328125 
[2025-02-07 13:16:24 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 10 loss:0.31619125604629517 norm:0.0007326557533815503 max memory_allocated 29781.95361328125 
[2025-02-07 13:17:11 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 11 loss:0.3161458373069763 norm:0.0007501129293814301 max memory_allocated 29781.95361328125 
[2025-02-07 13:17:58 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 12 loss:0.31612053513526917 norm:0.0007393761770799756 max memory_allocated 29781.95361328125 
[2025-02-07 13:18:44 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 13 loss:0.31610050797462463 norm:0.0007500183419324458 max memory_allocated 29781.95361328125 
[2025-02-07 13:19:31 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 14 loss:0.3160819411277771 norm:0.0007043267833068967 max memory_allocated 29781.95361328125 
[2025-02-07 13:20:18 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 15 loss:0.3160681128501892 norm:0.0006979273748584092 max memory_allocated 29781.95361328125 
[2025-02-07 13:21:05 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 16 loss:0.3160458505153656 norm:0.0006976371514610946 max memory_allocated 29781.95361328125 
[2025-02-07 13:21:51 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 17 loss:0.31602171063423157 norm:0.0006909410003572702 max memory_allocated 29781.95361328125 
[2025-02-07 13:22:38 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 18 loss:0.31600895524024963 norm:0.0006956344004720449 max memory_allocated 29781.95361328125 
[2025-02-07 13:23:25 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 19 loss:0.31600579619407654 norm:0.0006923853070475161 max memory_allocated 29781.95361328125 
[2025-02-07 13:23:39 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 33 ===
[2025-02-07 13:24:34 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 0 loss:0.37703099846839905 norm:0.0013604358537122607 max memory_allocated 29784.01611328125 
[2025-02-07 13:25:21 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 1 loss:0.3666256070137024 norm:0.0012627688702195883 max memory_allocated 29784.01611328125 
[2025-02-07 13:26:08 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 2 loss:0.3569277822971344 norm:0.0011681048199534416 max memory_allocated 29784.01611328125 
[2025-02-07 13:26:55 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 3 loss:0.35367515683174133 norm:0.0011129347840324044 max memory_allocated 29784.01611328125 
[2025-02-07 13:27:41 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 4 loss:0.35213568806648254 norm:0.0010831543477252126 max memory_allocated 29784.01611328125 
[2025-02-07 13:28:28 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 5 loss:0.3515945076942444 norm:0.001060399692505598 max memory_allocated 29784.01611328125 
[2025-02-07 13:29:15 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 6 loss:0.35129496455192566 norm:0.0010515887988731265 max memory_allocated 29784.01611328125 
[2025-02-07 13:30:02 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 7 loss:0.35111004114151 norm:0.0010611971374601126 max memory_allocated 29784.01611328125 
[2025-02-07 13:30:49 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 8 loss:0.35093405842781067 norm:0.0010369049850851297 max memory_allocated 29784.01611328125 
[2025-02-07 13:31:35 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 9 loss:0.35080206394195557 norm:0.000987306353636086 max memory_allocated 29784.01611328125 
[2025-02-07 13:32:22 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 10 loss:0.35067421197891235 norm:0.0009675134206190705 max memory_allocated 29784.01611328125 
[2025-02-07 13:33:09 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 11 loss:0.3505687415599823 norm:0.0009760961402207613 max memory_allocated 29784.01611328125 
[2025-02-07 13:33:56 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 12 loss:0.35047799348831177 norm:0.0009781988337635994 max memory_allocated 29784.01611328125 
[2025-02-07 13:34:42 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 13 loss:0.35040247440338135 norm:0.0009716809145174921 max memory_allocated 29784.01611328125 
[2025-02-07 13:35:29 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 14 loss:0.3503299653530121 norm:0.0009587262757122517 max memory_allocated 29784.01611328125 
[2025-02-07 13:36:16 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 15 loss:0.3502669930458069 norm:0.000982013763859868 max memory_allocated 29784.01611328125 
[2025-02-07 13:37:03 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 16 loss:0.35018959641456604 norm:0.0009591066627763212 max memory_allocated 29784.01611328125 
[2025-02-07 13:37:49 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 17 loss:0.3501303791999817 norm:0.0009635909809730947 max memory_allocated 29784.01611328125 
[2025-02-07 13:38:36 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 18 loss:0.35007792711257935 norm:0.0009514946141280234 max memory_allocated 29784.01611328125 
[2025-02-07 13:39:23 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 19 loss:0.35003766417503357 norm:0.0009500347659923136 max memory_allocated 29784.01611328125 
[2025-02-07 13:39:37 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 34 ===
[2025-02-07 13:40:35 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 0 loss:0.41701173782348633 norm:0.0017326148226857185 max memory_allocated 29786.07861328125 
[2025-02-07 13:41:22 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 1 loss:0.4056037664413452 norm:0.0013206219300627708 max memory_allocated 29786.07861328125 
[2025-02-07 13:42:08 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 2 loss:0.3952758312225342 norm:0.0011229062220081687 max memory_allocated 29786.07861328125 
[2025-02-07 13:42:55 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 3 loss:0.3919370174407959 norm:0.001133332378230989 max memory_allocated 29786.07861328125 
[2025-02-07 13:43:42 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 4 loss:0.3905896544456482 norm:0.0010319581488147378 max memory_allocated 29786.07861328125 
[2025-02-07 13:44:29 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 5 loss:0.39014944434165955 norm:0.0010035180021077394 max memory_allocated 29786.07861328125 
[2025-02-07 13:45:15 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 6 loss:0.38985276222229004 norm:0.0010303291492164135 max memory_allocated 29786.07861328125 
[2025-02-07 13:46:02 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 7 loss:0.3896123170852661 norm:0.0010098908096551895 max memory_allocated 29786.07861328125 
[2025-02-07 13:46:49 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 8 loss:0.3893709182739258 norm:0.0009732447797432542 max memory_allocated 29786.07861328125 
[2025-02-07 13:47:36 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 9 loss:0.38917872309684753 norm:0.0009154895669780672 max memory_allocated 29786.07861328125 
[2025-02-07 13:48:22 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 10 loss:0.3890150487422943 norm:0.0009211271535605192 max memory_allocated 29786.07861328125 
[2025-02-07 13:49:09 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 11 loss:0.3888615369796753 norm:0.0009539105230942369 max memory_allocated 29786.07861328125 
[2025-02-07 13:49:56 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 12 loss:0.3887229263782501 norm:0.0009231807198375463 max memory_allocated 29786.07861328125 
[2025-02-07 13:50:43 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 13 loss:0.3885808289051056 norm:0.0009192496072500944 max memory_allocated 29786.07861328125 
[2025-02-07 13:51:29 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 14 loss:0.38847312331199646 norm:0.0009608968975953758 max memory_allocated 29786.07861328125 
[2025-02-07 13:52:16 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 15 loss:0.38837331533432007 norm:0.0008951800409704447 max memory_allocated 29786.07861328125 
[2025-02-07 13:53:03 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 16 loss:0.3882957100868225 norm:0.000886808498762548 max memory_allocated 29786.07861328125 
[2025-02-07 13:53:50 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 17 loss:0.38820892572402954 norm:0.0008547031320631504 max memory_allocated 29786.07861328125 
[2025-02-07 13:54:36 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 18 loss:0.3881363868713379 norm:0.0008766231476329267 max memory_allocated 29786.07861328125 
[2025-02-07 13:55:23 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 19 loss:0.38807275891304016 norm:0.000846134964376688 max memory_allocated 29786.07861328125 
[2025-02-07 13:55:37 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 35 ===
[2025-02-07 13:56:32 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 0 loss:0.462826132774353 norm:0.0015472349477931857 max memory_allocated 29788.14111328125 
[2025-02-07 13:57:19 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 1 loss:0.45009878277778625 norm:0.0012136916629970074 max memory_allocated 29788.14111328125 
[2025-02-07 13:58:06 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 2 loss:0.43884342908859253 norm:0.0010469031985849142 max memory_allocated 29788.14111328125 
[2025-02-07 13:58:52 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 3 loss:0.43504202365875244 norm:0.0010070073185488582 max memory_allocated 29788.14111328125 
[2025-02-07 13:59:39 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 4 loss:0.4336073398590088 norm:0.0009822826832532883 max memory_allocated 29788.14111328125 
[2025-02-07 14:00:26 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 5 loss:0.433051198720932 norm:0.0009407387697137892 max memory_allocated 29788.14111328125 
[2025-02-07 14:01:13 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 6 loss:0.4326919913291931 norm:0.0009134263964369893 max memory_allocated 29788.14111328125 
[2025-02-07 14:02:00 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 7 loss:0.4324166774749756 norm:0.000903890875633806 max memory_allocated 29788.14111328125 
[2025-02-07 14:02:46 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 8 loss:0.4321818947792053 norm:0.0008573150844313204 max memory_allocated 29788.14111328125 
[2025-02-07 14:03:33 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 9 loss:0.43197891116142273 norm:0.0008365688845515251 max memory_allocated 29788.14111328125 
[2025-02-07 14:04:20 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 10 loss:0.4318017363548279 norm:0.0008372499723918736 max memory_allocated 29788.14111328125 
[2025-02-07 14:05:07 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 11 loss:0.43167492747306824 norm:0.0008257796871475875 max memory_allocated 29788.14111328125 
[2025-02-07 14:05:53 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 12 loss:0.431535542011261 norm:0.000823567621409893 max memory_allocated 29788.14111328125 
[2025-02-07 14:06:40 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 13 loss:0.43142473697662354 norm:0.0008160440484061837 max memory_allocated 29788.14111328125 
[2025-02-07 14:07:27 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 14 loss:0.431326299905777 norm:0.0008207792998291552 max memory_allocated 29788.14111328125 
[2025-02-07 14:08:14 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 15 loss:0.4312132000923157 norm:0.0008104774751700461 max memory_allocated 29788.14111328125 
[2025-02-07 14:09:01 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 16 loss:0.43112942576408386 norm:0.0008022342226468027 max memory_allocated 29788.14111328125 
[2025-02-07 14:09:47 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 17 loss:0.4310604929924011 norm:0.0008086610469035804 max memory_allocated 29788.14111328125 
[2025-02-07 14:10:34 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 18 loss:0.43098896741867065 norm:0.0007881880737841129 max memory_allocated 29788.14111328125 
[2025-02-07 14:11:21 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 19 loss:0.43095695972442627 norm:0.0007956866757012904 max memory_allocated 29788.14111328125 
[2025-02-07 14:11:35 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 36 ===
[2025-02-07 14:11:46 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 14:12:32 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 0 loss:0.5207423567771912 norm:0.009881841018795967 max memory_allocated 29790.34814453125 
[2025-02-07 14:13:19 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 1 loss:0.5048948526382446 norm:0.007500496692955494 max memory_allocated 29790.34814453125 
[2025-02-07 14:14:06 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 2 loss:0.4916762113571167 norm:0.0053476267494261265 max memory_allocated 29790.34814453125 
[2025-02-07 14:14:53 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 3 loss:0.48713091015815735 norm:0.004360576625913382 max memory_allocated 29790.34814453125 
[2025-02-07 14:15:40 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 4 loss:0.48539090156555176 norm:0.0034888428635895252 max memory_allocated 29790.34814453125 
[2025-02-07 14:16:27 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 5 loss:0.48461395502090454 norm:0.0029939203523099422 max memory_allocated 29790.34814453125 
[2025-02-07 14:17:14 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 6 loss:0.4841482639312744 norm:0.002861207816749811 max memory_allocated 29790.34814453125 
[2025-02-07 14:18:01 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 7 loss:0.48382043838500977 norm:0.0027563939802348614 max memory_allocated 29790.34814453125 
[2025-02-07 14:18:48 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 8 loss:0.48349156975746155 norm:0.0026622936129570007 max memory_allocated 29790.34814453125 
[2025-02-07 14:19:35 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 9 loss:0.4832143783569336 norm:0.00252029811963439 max memory_allocated 29790.34814453125 
[2025-02-07 14:20:22 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 10 loss:0.48296818137168884 norm:0.0023918519727885723 max memory_allocated 29790.34814453125 
[2025-02-07 14:21:09 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 11 loss:0.4827831983566284 norm:0.0023135708179324865 max memory_allocated 29790.34814453125 
[2025-02-07 14:21:56 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 12 loss:0.4826321005821228 norm:0.0022976959589868784 max memory_allocated 29790.34814453125 
[2025-02-07 14:22:42 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 13 loss:0.48251593112945557 norm:0.002348346170037985 max memory_allocated 29790.34814453125 
[2025-02-07 14:23:29 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 14 loss:0.4823615550994873 norm:0.0022785260807722807 max memory_allocated 29790.34814453125 
[2025-02-07 14:24:16 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 15 loss:0.48220983147621155 norm:0.0021701157093048096 max memory_allocated 29790.34814453125 
[2025-02-07 14:25:03 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 16 loss:0.4821264445781708 norm:0.002135932445526123 max memory_allocated 29790.34814453125 
[2025-02-07 14:25:50 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 17 loss:0.482097327709198 norm:0.002232025843113661 max memory_allocated 29790.34814453125 
[2025-02-07 14:26:37 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 18 loss:0.4820209741592407 norm:0.0022244486026465893 max memory_allocated 29790.34814453125 
[2025-02-07 14:27:24 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 19 loss:0.481927752494812 norm:0.0021466517355293036 max memory_allocated 29790.34814453125 
[2025-02-07 14:27:38 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 37 ===
[2025-02-07 14:27:51 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 14:28:38 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 0 loss:0.5778724551200867 norm:0.013060880824923515 max memory_allocated 29792.41064453125 
[2025-02-07 14:29:25 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 1 loss:0.560682475566864 norm:0.009794474579393864 max memory_allocated 29792.41064453125 
[2025-02-07 14:30:12 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 2 loss:0.5458440184593201 norm:0.007182614877820015 max memory_allocated 29792.41064453125 
[2025-02-07 14:30:59 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 3 loss:0.540852963924408 norm:0.0062886676751077175 max memory_allocated 29792.41064453125 
[2025-02-07 14:31:46 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 4 loss:0.538835883140564 norm:0.0053984117694199085 max memory_allocated 29792.41064453125 
[2025-02-07 14:32:32 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 5 loss:0.5378650426864624 norm:0.0048403050750494 max memory_allocated 29792.41064453125 
[2025-02-07 14:33:19 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 6 loss:0.5372605323791504 norm:0.004567408934235573 max memory_allocated 29792.41064453125 
[2025-02-07 14:34:06 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 7 loss:0.5369424819946289 norm:0.004540400579571724 max memory_allocated 29792.41064453125 
[2025-02-07 14:34:53 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 8 loss:0.5366193652153015 norm:0.0044759358279407024 max memory_allocated 29792.41064453125 
[2025-02-07 14:35:40 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 9 loss:0.5363897085189819 norm:0.004296041093766689 max memory_allocated 29792.41064453125 
[2025-02-07 14:36:27 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 10 loss:0.5361392498016357 norm:0.004036714322865009 max memory_allocated 29792.41064453125 
[2025-02-07 14:37:14 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 11 loss:0.5359373688697815 norm:0.004104375373572111 max memory_allocated 29792.41064453125 
[2025-02-07 14:38:01 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 12 loss:0.535852313041687 norm:0.0042205145582556725 max memory_allocated 29792.41064453125 
[2025-02-07 14:38:48 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 13 loss:0.5356900095939636 norm:0.004355278331786394 max memory_allocated 29792.41064453125 
[2025-02-07 14:39:35 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 14 loss:0.535580039024353 norm:0.0042403703555464745 max memory_allocated 29792.41064453125 
[2025-02-07 14:40:21 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 15 loss:0.5354640483856201 norm:0.004057052079588175 max memory_allocated 29792.41064453125 
[2025-02-07 14:41:08 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 16 loss:0.5351049304008484 norm:0.005426568444818258 max memory_allocated 29792.41064453125 
[2025-02-07 14:41:55 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 17 loss:0.5357347130775452 norm:0.011808649636805058 max memory_allocated 29792.41064453125 
[2025-02-07 14:42:42 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 18 loss:0.535999596118927 norm:0.007077533286064863 max memory_allocated 29792.41064453125 
[2025-02-07 14:43:29 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 19 loss:0.535595178604126 norm:0.007333249319344759 max memory_allocated 29792.41064453125 
[2025-02-07 14:43:43 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 38 ===
[2025-02-07 14:43:53 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 14:44:40 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 0 loss:0.6561936736106873 norm:0.01677626743912697 max memory_allocated 29794.47314453125 
[2025-02-07 14:45:27 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 1 loss:0.6354087591171265 norm:0.012655707076191902 max memory_allocated 29794.47314453125 
[2025-02-07 14:46:14 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 2 loss:0.620001494884491 norm:0.009196181781589985 max memory_allocated 29794.47314453125 
[2025-02-07 14:47:01 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 3 loss:0.6148278117179871 norm:0.00807129591703415 max memory_allocated 29794.47314453125 
[2025-02-07 14:47:48 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 4 loss:0.612783670425415 norm:0.007153757847845554 max memory_allocated 29794.47314453125 
[2025-02-07 14:48:35 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 5 loss:0.6116054058074951 norm:0.006349964998662472 max memory_allocated 29794.47314453125 
[2025-02-07 14:49:21 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 6 loss:0.6108725070953369 norm:0.005826055072247982 max memory_allocated 29794.47314453125 
[2025-02-07 14:50:08 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 7 loss:0.6104143857955933 norm:0.0055623408406972885 max memory_allocated 29794.47314453125 
[2025-02-07 14:50:55 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 8 loss:0.6100148558616638 norm:0.005326206795871258 max memory_allocated 29794.47314453125 
[2025-02-07 14:51:42 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 9 loss:0.6100634336471558 norm:0.005781382322311401 max memory_allocated 29794.47314453125 
[2025-02-07 14:52:29 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 10 loss:0.6098558306694031 norm:0.005657755769789219 max memory_allocated 29794.47314453125 
[2025-02-07 14:53:16 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 11 loss:0.609541654586792 norm:0.005505527835339308 max memory_allocated 29794.47314453125 
[2025-02-07 14:54:03 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 12 loss:0.6091271638870239 norm:0.004983857274055481 max memory_allocated 29794.47314453125 
[2025-02-07 14:54:50 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 13 loss:0.6089450120925903 norm:0.004623021464794874 max memory_allocated 29794.47314453125 
[2025-02-07 14:55:37 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 14 loss:0.6088645458221436 norm:0.0046263085678219795 max memory_allocated 29794.47314453125 
[2025-02-07 14:56:23 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 15 loss:0.6088678240776062 norm:0.004705088213086128 max memory_allocated 29794.47314453125 
[2025-02-07 14:57:10 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 16 loss:0.609068751335144 norm:0.005254089366644621 max memory_allocated 29794.47314453125 
[2025-02-07 14:57:57 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 17 loss:0.609000027179718 norm:0.005097276996821165 max memory_allocated 29794.47314453125 
[2025-02-07 14:58:44 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 18 loss:0.6088234782218933 norm:0.0048951925709843636 max memory_allocated 29794.47314453125 
[2025-02-07 14:59:31 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 19 loss:0.6089277267456055 norm:0.0049344380386173725 max memory_allocated 29794.47314453125 
[2025-02-07 14:59:45 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 39 ===
[2025-02-07 14:59:57 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 15:00:44 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 0 loss:0.8561553955078125 norm:0.041371025145053864 max memory_allocated 29796.53564453125 
[2025-02-07 15:01:30 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 1 loss:0.8163577318191528 norm:0.03088780678808689 max memory_allocated 29796.53564453125 
[2025-02-07 15:02:17 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 2 loss:0.7884211540222168 norm:0.021210823208093643 max memory_allocated 29796.53564453125 
[2025-02-07 15:03:04 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 3 loss:0.7786630392074585 norm:0.01861858181655407 max memory_allocated 29796.53564453125 
[2025-02-07 15:03:51 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 4 loss:0.7747547030448914 norm:0.017429012805223465 max memory_allocated 29796.53564453125 
[2025-02-07 15:04:38 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 5 loss:0.7717263102531433 norm:0.015555685386061668 max memory_allocated 29796.53564453125 
[2025-02-07 15:05:25 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 6 loss:0.7702736854553223 norm:0.015107587911188602 max memory_allocated 29796.53564453125 
[2025-02-07 15:06:12 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 7 loss:0.7687895894050598 norm:0.014051119796931744 max memory_allocated 29796.53564453125 
[2025-02-07 15:06:58 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 8 loss:0.7680539488792419 norm:0.014333648607134819 max memory_allocated 29796.53564453125 
[2025-02-07 15:07:45 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 9 loss:0.7672796249389648 norm:0.013816562481224537 max memory_allocated 29796.53564453125 
[2025-02-07 15:08:32 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 10 loss:0.7666075229644775 norm:0.013714933767914772 max memory_allocated 29796.53564453125 
[2025-02-07 15:09:19 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 11 loss:0.7656211256980896 norm:0.013227010145783424 max memory_allocated 29796.53564453125 
[2025-02-07 15:10:06 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 12 loss:0.7652630805969238 norm:0.012792546302080154 max memory_allocated 29796.53564453125 
[2025-02-07 15:10:53 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 13 loss:0.7648004293441772 norm:0.012854981236159801 max memory_allocated 29796.53564453125 
[2025-02-07 15:11:40 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 14 loss:0.7645056843757629 norm:0.012988429516553879 max memory_allocated 29796.53564453125 
[2025-02-07 15:12:27 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 15 loss:0.7646085619926453 norm:0.012942878529429436 max memory_allocated 29796.53564453125 
[2025-02-07 15:13:14 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 16 loss:0.764696478843689 norm:0.013440823182463646 max memory_allocated 29796.53564453125 
[2025-02-07 15:14:01 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 17 loss:0.7640993595123291 norm:0.01255619153380394 max memory_allocated 29796.53564453125 
[2025-02-07 15:14:47 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 18 loss:0.7632776498794556 norm:0.012056216597557068 max memory_allocated 29796.53564453125 
[2025-02-07 15:15:34 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 19 loss:0.7630012631416321 norm:0.011598276905715466 max memory_allocated 29796.53564453125 
[2025-02-07 15:15:48 root] (main_calib_config.py 366): INFO 38469.732082128525
[2025-02-07 15:16:55 root] (main_calib_config.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-07 15:18:50 root] (main_calib_config.py 159): INFO wikitext2 : 6.56608772277832
[2025-02-07 15:18:50 root] (main_calib_config.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-07 15:21:50 root] (main_calib_config.py 159): INFO c4 : 8.638179779052734
[2025-02-07 16:51:02 root] (main_calib_config.py 170): INFO {'wikitext2': 6.56608772277832, 'c4': 8.638179779052734, 'results': {'winogrande': {'acc': 0.6882399368587214, 'acc_stderr': 0.013018571197638548}, 'hellaswag': {'acc': 0.5872336188010356, 'acc_stderr': 0.004913253031155693, 'acc_norm': 0.7512447719577773, 'acc_norm_stderr': 0.0043140816086246455}}, 'versions': {'winogrande': 0, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
