[2025-02-06 06:51:52 root] (main_calib_config.py 270): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log/0205-calib/llama-7b-hf', save_dir='./log/0205-calib/llama-7b-hf/save_dir', resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='./log/0205-mpq/llama-7b-hf/quant_map_llama-7b-hf.pkl')
[2025-02-06 06:55:44 root] (main_calib_config.py 337): INFO === start quantization ===
[2025-02-06 06:55:45 root] (main_calib_config.py 343): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-02-06 06:55:45 root] (abq_llm_calib_config.py 82): INFO Starting ...
[2025-02-06 06:55:45 root] (abq_llm_calib_config.py 89): INFO Loaded quant_map from ./log/0205-mpq/llama-7b-hf/quant_map_llama-7b-hf.pkl
[2025-02-06 06:55:47 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 0 ===
[2025-02-06 06:55:50 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-06 06:56:24 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 0 loss:0.013734960928559303 norm:0.009583286941051483 max memory_allocated 22883.16943359375 
[2025-02-06 06:56:58 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 1 loss:0.00790032371878624 norm:0.004834079183638096 max memory_allocated 22883.16943359375 
[2025-02-06 06:57:33 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 2 loss:0.005707637406885624 norm:0.003338643815368414 max memory_allocated 22883.16943359375 
[2025-02-06 06:58:07 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 3 loss:0.005000347271561623 norm:0.002734009874984622 max memory_allocated 22883.16943359375 
[2025-02-06 06:58:41 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 4 loss:0.004767159465700388 norm:0.002283266745507717 max memory_allocated 22883.16943359375 
[2025-02-06 06:59:15 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 5 loss:0.004610852338373661 norm:0.0019730280619114637 max memory_allocated 22883.16943359375 
[2025-02-06 06:59:50 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 6 loss:0.004493312444537878 norm:0.0017808994743973017 max memory_allocated 22883.16943359375 
[2025-02-06 07:00:24 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 7 loss:0.004395391792058945 norm:0.0016293865628540516 max memory_allocated 22883.16943359375 
[2025-02-06 07:00:58 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 8 loss:0.004325904417783022 norm:0.0015229822602123022 max memory_allocated 22883.16943359375 
[2025-02-06 07:01:32 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 9 loss:0.004236532375216484 norm:0.001419181702658534 max memory_allocated 22883.16943359375 
[2025-02-06 07:02:07 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 10 loss:0.004197943489998579 norm:0.001337723690085113 max memory_allocated 22883.16943359375 
[2025-02-06 07:02:41 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 11 loss:0.004140255507081747 norm:0.0012969905510544777 max memory_allocated 22883.16943359375 
[2025-02-06 07:03:15 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 12 loss:0.004106681793928146 norm:0.0012213203590363264 max memory_allocated 22883.16943359375 
[2025-02-06 07:03:49 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 13 loss:0.004097229801118374 norm:0.0011459019733592868 max memory_allocated 22883.16943359375 
[2025-02-06 07:04:24 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 14 loss:0.004072686191648245 norm:0.0010956667829304934 max memory_allocated 22883.16943359375 
[2025-02-06 07:04:58 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 15 loss:0.0040730442851781845 norm:0.0010971021838486195 max memory_allocated 22883.16943359375 
[2025-02-06 07:05:32 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 16 loss:0.004054396413266659 norm:0.001027374528348446 max memory_allocated 22883.16943359375 
[2025-02-06 07:06:07 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 17 loss:0.004039865918457508 norm:0.0009772636694833636 max memory_allocated 22883.16943359375 
[2025-02-06 07:06:41 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 18 loss:0.004002112429589033 norm:0.000948736967984587 max memory_allocated 22883.16943359375 
[2025-02-06 07:07:15 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 19 loss:0.004006133880466223 norm:0.0009350760956294835 max memory_allocated 22883.16943359375 
[2025-02-06 07:07:25 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 1 ===
[2025-02-06 07:07:28 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-06 07:08:02 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 0 loss:0.02492748759686947 norm:0.01269181165844202 max memory_allocated 22884.84130859375 
[2025-02-06 07:08:36 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 1 loss:0.016235198825597763 norm:0.006198854185640812 max memory_allocated 22884.84130859375 
[2025-02-06 07:09:11 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 2 loss:0.01301298476755619 norm:0.004336359445005655 max memory_allocated 22884.84130859375 
[2025-02-06 07:09:45 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 3 loss:0.012087236158549786 norm:0.0034759517293423414 max memory_allocated 22884.84130859375 
[2025-02-06 07:10:20 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 4 loss:0.011722384952008724 norm:0.0031256405636668205 max memory_allocated 22884.84130859375 
[2025-02-06 07:10:54 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 5 loss:0.011478416621685028 norm:0.0027905716560781 max memory_allocated 22884.84130859375 
[2025-02-06 07:11:28 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 6 loss:0.011286488734185696 norm:0.002535872394219041 max memory_allocated 22884.84130859375 
[2025-02-06 07:12:03 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 7 loss:0.011102961376309395 norm:0.002298540435731411 max memory_allocated 22884.84130859375 
[2025-02-06 07:12:37 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 8 loss:0.010984901338815689 norm:0.0021196536254137754 max memory_allocated 22884.84130859375 
[2025-02-06 07:13:12 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 9 loss:0.01088201254606247 norm:0.001954808598384261 max memory_allocated 22884.84130859375 
[2025-02-06 07:13:46 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 10 loss:0.010812073945999146 norm:0.0017687705112621188 max memory_allocated 22884.84130859375 
[2025-02-06 07:14:20 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 11 loss:0.010749317705631256 norm:0.001621105708181858 max memory_allocated 22884.84130859375 
[2025-02-06 07:14:55 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 12 loss:0.010699865408241749 norm:0.0014604617608711123 max memory_allocated 22884.84130859375 
[2025-02-06 07:15:29 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 13 loss:0.010657109320163727 norm:0.0013613265473395586 max memory_allocated 22884.84130859375 
[2025-02-06 07:16:03 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 14 loss:0.01064634881913662 norm:0.0013346057385206223 max memory_allocated 22884.84130859375 
[2025-02-06 07:16:38 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 15 loss:0.01065096165984869 norm:0.0013135912595316768 max memory_allocated 22884.84130859375 
[2025-02-06 07:17:12 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 16 loss:0.010652855969965458 norm:0.001334396773017943 max memory_allocated 22884.84130859375 
[2025-02-06 07:17:47 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 17 loss:0.010719554498791695 norm:0.001267082174308598 max memory_allocated 22884.84130859375 
[2025-02-06 07:18:21 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 18 loss:0.01060464233160019 norm:0.0011714845895767212 max memory_allocated 22884.84130859375 
[2025-02-06 07:18:55 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 19 loss:0.010748300701379776 norm:0.0010971396695822477 max memory_allocated 22884.84130859375 
[2025-02-06 07:19:05 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 2 ===
[2025-02-06 07:19:08 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-06 07:19:42 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 0 loss:0.08787286281585693 norm:0.02794160135090351 max memory_allocated 22886.51318359375 
[2025-02-06 07:20:16 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 1 loss:0.044784098863601685 norm:0.014488611370325089 max memory_allocated 22886.51318359375 
[2025-02-06 07:20:51 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 2 loss:0.03179352730512619 norm:0.01082894578576088 max memory_allocated 22886.51318359375 
[2025-02-06 07:21:25 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 3 loss:0.02734236977994442 norm:0.010188938118517399 max memory_allocated 22886.51318359375 
[2025-02-06 07:22:00 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 4 loss:0.025483690202236176 norm:0.008551564067602158 max memory_allocated 22886.51318359375 
[2025-02-06 07:22:34 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 5 loss:0.024429596960544586 norm:0.007892291992902756 max memory_allocated 22886.51318359375 
[2025-02-06 07:23:09 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 6 loss:0.023945949971675873 norm:0.007171754725277424 max memory_allocated 22886.51318359375 
[2025-02-06 07:23:43 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 7 loss:0.02367347478866577 norm:0.006591313052922487 max memory_allocated 22886.51318359375 
[2025-02-06 07:24:18 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 8 loss:0.023653365671634674 norm:0.006384934298694134 max memory_allocated 22886.51318359375 
[2025-02-06 07:24:52 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 9 loss:0.02330995351076126 norm:0.006216969806700945 max memory_allocated 22886.51318359375 
[2025-02-06 07:25:26 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 10 loss:0.023660026490688324 norm:0.006467361468821764 max memory_allocated 22886.51318359375 
[2025-02-06 07:26:01 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 11 loss:0.023136768490076065 norm:0.0059769949875772 max memory_allocated 22886.51318359375 
[2025-02-06 07:26:36 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 12 loss:0.023102233186364174 norm:0.005646021105349064 max memory_allocated 22886.51318359375 
[2025-02-06 07:27:10 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 13 loss:0.023159775882959366 norm:0.005362422671169043 max memory_allocated 22886.51318359375 
[2025-02-06 07:27:44 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 14 loss:0.023012643679976463 norm:0.005267486907541752 max memory_allocated 22886.51318359375 
[2025-02-06 07:28:19 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 15 loss:0.022951873019337654 norm:0.00519266352057457 max memory_allocated 22886.51318359375 
[2025-02-06 07:28:53 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 16 loss:0.022814543917775154 norm:0.004929961636662483 max memory_allocated 22886.51318359375 
[2025-02-06 07:29:28 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 17 loss:0.022854909300804138 norm:0.0052543459460139275 max memory_allocated 22886.51318359375 
[2025-02-06 07:30:02 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 18 loss:0.022485539317131042 norm:0.004602036438882351 max memory_allocated 22886.51318359375 
[2025-02-06 07:30:37 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 19 loss:0.022666120901703835 norm:0.00470719626173377 max memory_allocated 22886.51318359375 
[2025-02-06 07:30:46 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 3 ===
[2025-02-06 07:31:23 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 0 loss:0.03860617056488991 norm:0.0024798070080578327 max memory_allocated 22888.06982421875 
[2025-02-06 07:31:57 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 1 loss:0.031408824026584625 norm:0.0012285213451832533 max memory_allocated 22888.06982421875 
[2025-02-06 07:32:32 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 2 loss:0.02791716158390045 norm:0.000939530844334513 max memory_allocated 22888.06982421875 
[2025-02-06 07:33:06 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 3 loss:0.026730146259069443 norm:0.0008633646066300571 max memory_allocated 22888.06982421875 
[2025-02-06 07:33:40 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 4 loss:0.02604200690984726 norm:0.0007900621858425438 max memory_allocated 22888.06982421875 
[2025-02-06 07:34:14 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 5 loss:0.025582361966371536 norm:0.0007643895805813372 max memory_allocated 22888.06982421875 
[2025-02-06 07:34:49 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 6 loss:0.02543429471552372 norm:0.0007906695827841759 max memory_allocated 22888.06982421875 
[2025-02-06 07:35:23 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 7 loss:0.025356078520417213 norm:0.0007642784621566534 max memory_allocated 22888.06982421875 
[2025-02-06 07:35:57 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 8 loss:0.025330800563097 norm:0.0007687988108955324 max memory_allocated 22888.06982421875 
[2025-02-06 07:36:32 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 9 loss:0.025326978415250778 norm:0.0007862398633733392 max memory_allocated 22888.06982421875 
[2025-02-06 07:37:06 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 10 loss:0.025296403095126152 norm:0.0007736147381365299 max memory_allocated 22888.06982421875 
[2025-02-06 07:37:40 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 11 loss:0.025241466239094734 norm:0.0007503494853153825 max memory_allocated 22888.06982421875 
[2025-02-06 07:38:14 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 12 loss:0.02523074299097061 norm:0.0007764705806039274 max memory_allocated 22888.06982421875 
[2025-02-06 07:38:49 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 13 loss:0.025222476571798325 norm:0.0007603823323734105 max memory_allocated 22888.06982421875 
[2025-02-06 07:39:23 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 14 loss:0.02522663213312626 norm:0.000806584779638797 max memory_allocated 22888.06982421875 
[2025-02-06 07:39:57 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 15 loss:0.025209739804267883 norm:0.0007650527404621243 max memory_allocated 22888.06982421875 
[2025-02-06 07:40:31 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 16 loss:0.0252220556139946 norm:0.0007942277006804943 max memory_allocated 22888.06982421875 
[2025-02-06 07:41:06 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 17 loss:0.025228379294276237 norm:0.0008140623685903847 max memory_allocated 22888.06982421875 
[2025-02-06 07:41:40 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 18 loss:0.02518947422504425 norm:0.0007371082901954651 max memory_allocated 22888.06982421875 
[2025-02-06 07:42:14 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 19 loss:0.02520201914012432 norm:0.0007619167445227504 max memory_allocated 22888.06982421875 
[2025-02-06 07:42:24 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 4 ===
[2025-02-06 07:43:01 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 0 loss:0.050977934151887894 norm:0.0026861459482461214 max memory_allocated 22889.74169921875 
[2025-02-06 07:43:35 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 1 loss:0.04204842448234558 norm:0.0016499178018420935 max memory_allocated 22889.74169921875 
[2025-02-06 07:44:10 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 2 loss:0.03715014457702637 norm:0.0014334640000015497 max memory_allocated 22889.74169921875 
[2025-02-06 07:44:44 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 3 loss:0.0353064127266407 norm:0.001313203596509993 max memory_allocated 22889.74169921875 
[2025-02-06 07:45:18 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 4 loss:0.03436996415257454 norm:0.001170777017250657 max memory_allocated 22889.74169921875 
[2025-02-06 07:45:53 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 5 loss:0.03398976847529411 norm:0.0011753516737371683 max memory_allocated 22889.74169921875 
[2025-02-06 07:46:27 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 6 loss:0.033803634345531464 norm:0.0011568376794457436 max memory_allocated 22889.74169921875 
[2025-02-06 07:47:01 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 7 loss:0.03373667225241661 norm:0.0011728014796972275 max memory_allocated 22889.74169921875 
[2025-02-06 07:47:35 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 8 loss:0.0336565263569355 norm:0.001104369293898344 max memory_allocated 22889.74169921875 
[2025-02-06 07:48:10 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 9 loss:0.03362051770091057 norm:0.0011408296413719654 max memory_allocated 22889.74169921875 
[2025-02-06 07:48:44 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 10 loss:0.033558569848537445 norm:0.0010781106539070606 max memory_allocated 22889.74169921875 
[2025-02-06 07:49:18 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 11 loss:0.03352262079715729 norm:0.0011493152705952525 max memory_allocated 22889.74169921875 
[2025-02-06 07:49:53 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 12 loss:0.03348896652460098 norm:0.001110148848965764 max memory_allocated 22889.74169921875 
[2025-02-06 07:50:27 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 13 loss:0.03343344107270241 norm:0.001100149005651474 max memory_allocated 22889.74169921875 
[2025-02-06 07:51:02 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 14 loss:0.033424440771341324 norm:0.0011378246126696467 max memory_allocated 22889.74169921875 
[2025-02-06 07:51:36 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 15 loss:0.03342805802822113 norm:0.0011643234174698591 max memory_allocated 22889.74169921875 
[2025-02-06 07:52:10 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 16 loss:0.03339916840195656 norm:0.001133041107095778 max memory_allocated 22889.74169921875 
[2025-02-06 07:52:44 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 17 loss:0.03341640904545784 norm:0.0011912217596545815 max memory_allocated 22889.74169921875 
[2025-02-06 07:53:18 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 18 loss:0.033416226506233215 norm:0.001119480119086802 max memory_allocated 22889.74169921875 
[2025-02-06 07:53:53 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 19 loss:0.03338484838604927 norm:0.0010593644110485911 max memory_allocated 22889.74169921875 
[2025-02-06 07:54:02 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 5 ===
[2025-02-06 07:54:40 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 0 loss:0.056465987116098404 norm:0.003070140490308404 max memory_allocated 22891.41357421875 
[2025-02-06 07:55:14 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 1 loss:0.04758331924676895 norm:0.0022778036072850227 max memory_allocated 22891.41357421875 
[2025-02-06 07:55:48 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 2 loss:0.04217901453375816 norm:0.0019825082272291183 max memory_allocated 22891.41357421875 
[2025-02-06 07:56:22 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 3 loss:0.040339428931474686 norm:0.0017185319447889924 max memory_allocated 22891.41357421875 
[2025-02-06 07:56:57 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 4 loss:0.039380963891744614 norm:0.0017186987679451704 max memory_allocated 22891.41357421875 
[2025-02-06 07:57:31 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 5 loss:0.03892168402671814 norm:0.0017758812755346298 max memory_allocated 22891.41357421875 
[2025-02-06 07:58:05 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 6 loss:0.03872890770435333 norm:0.0017421512166038156 max memory_allocated 22891.41357421875 
[2025-02-06 07:58:40 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 7 loss:0.03859490901231766 norm:0.0018165144138038158 max memory_allocated 22891.41357421875 
[2025-02-06 07:59:14 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 8 loss:0.03853490203619003 norm:0.0018278795760124922 max memory_allocated 22891.41357421875 
[2025-02-06 07:59:48 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 9 loss:0.038406357169151306 norm:0.0016391254030168056 max memory_allocated 22891.41357421875 
[2025-02-06 08:00:22 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 10 loss:0.03836355730891228 norm:0.0016130036674439907 max memory_allocated 22891.41357421875 
[2025-02-06 08:00:57 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 11 loss:0.038294464349746704 norm:0.0016115742037072778 max memory_allocated 22891.41357421875 
[2025-02-06 08:01:31 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 12 loss:0.038206055760383606 norm:0.001489055808633566 max memory_allocated 22891.41357421875 
[2025-02-06 08:02:05 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 13 loss:0.03820345550775528 norm:0.00153683265671134 max memory_allocated 22891.41357421875 
[2025-02-06 08:02:40 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 14 loss:0.038183167576789856 norm:0.0015938434517011046 max memory_allocated 22891.41357421875 
[2025-02-06 08:03:14 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 15 loss:0.038173459470272064 norm:0.0016096967738121748 max memory_allocated 22891.41357421875 
[2025-02-06 08:03:48 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 16 loss:0.03815903887152672 norm:0.0016470886766910553 max memory_allocated 22891.41357421875 
[2025-02-06 08:04:23 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 17 loss:0.03812284767627716 norm:0.001561185228638351 max memory_allocated 22891.41357421875 
[2025-02-06 08:04:57 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 18 loss:0.038104381412267685 norm:0.0015008816262707114 max memory_allocated 22891.41357421875 
[2025-02-06 08:05:31 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 19 loss:0.038108982145786285 norm:0.0015338874654844403 max memory_allocated 22891.41357421875 
[2025-02-06 08:05:41 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 6 ===
[2025-02-06 08:06:18 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 0 loss:0.06186109781265259 norm:0.003076458116993308 max memory_allocated 22893.08544921875 
[2025-02-06 08:06:52 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 1 loss:0.054038919508457184 norm:0.002508410718291998 max memory_allocated 22893.08544921875 
[2025-02-06 08:07:27 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 2 loss:0.049086086452007294 norm:0.0022311857901513577 max memory_allocated 22893.08544921875 
[2025-02-06 08:08:01 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 3 loss:0.04737664759159088 norm:0.002221886068582535 max memory_allocated 22893.08544921875 
[2025-02-06 08:08:35 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 4 loss:0.04654119908809662 norm:0.0020503178238868713 max memory_allocated 22893.08544921875 
[2025-02-06 08:09:09 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 5 loss:0.04617219418287277 norm:0.0019274404039606452 max memory_allocated 22893.08544921875 
[2025-02-06 08:09:44 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 6 loss:0.0459933802485466 norm:0.0018569150706753135 max memory_allocated 22893.08544921875 
[2025-02-06 08:10:18 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 7 loss:0.04587780311703682 norm:0.0018346395809203386 max memory_allocated 22893.08544921875 
[2025-02-06 08:10:52 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 8 loss:0.04581771045923233 norm:0.0019689069595187902 max memory_allocated 22893.08544921875 
[2025-02-06 08:11:27 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 9 loss:0.045761995017528534 norm:0.0019170597661286592 max memory_allocated 22893.08544921875 
[2025-02-06 08:12:01 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 10 loss:0.04572790861129761 norm:0.0018190413247793913 max memory_allocated 22893.08544921875 
[2025-02-06 08:12:35 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 11 loss:0.045700352638959885 norm:0.0018826593877747655 max memory_allocated 22893.08544921875 
[2025-02-06 08:13:10 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 12 loss:0.045665498822927475 norm:0.001814165967516601 max memory_allocated 22893.08544921875 
[2025-02-06 08:13:44 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 13 loss:0.045727550983428955 norm:0.002215246669948101 max memory_allocated 22893.08544921875 
[2025-02-06 08:14:18 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 14 loss:0.0456852950155735 norm:0.002007974311709404 max memory_allocated 22893.08544921875 
[2025-02-06 08:14:53 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 15 loss:0.04560525342822075 norm:0.0019629851449280977 max memory_allocated 22893.08544921875 
[2025-02-06 08:15:27 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 16 loss:0.04556625708937645 norm:0.0018836231902241707 max memory_allocated 22893.08544921875 
[2025-02-06 08:16:01 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 17 loss:0.0455356203019619 norm:0.0018359394744038582 max memory_allocated 22893.08544921875 
[2025-02-06 08:16:36 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 18 loss:0.045536261051893234 norm:0.0018321304814890027 max memory_allocated 22893.08544921875 
[2025-02-06 08:17:10 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 19 loss:0.045541830360889435 norm:0.0017879132647067308 max memory_allocated 22893.08544921875 
[2025-02-06 08:17:19 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 7 ===
[2025-02-06 08:17:57 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 0 loss:0.07133454084396362 norm:0.0033317061606794596 max memory_allocated 22894.75732421875 
[2025-02-06 08:18:31 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 1 loss:0.06240323185920715 norm:0.00218899454921484 max memory_allocated 22894.75732421875 
[2025-02-06 08:19:05 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 2 loss:0.05697125196456909 norm:0.0019067967077717185 max memory_allocated 22894.75732421875 
[2025-02-06 08:19:40 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 3 loss:0.05496496707201004 norm:0.0015841114800423384 max memory_allocated 22894.75732421875 
[2025-02-06 08:20:14 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 4 loss:0.05401518940925598 norm:0.0018518882570788264 max memory_allocated 22894.75732421875 
[2025-02-06 08:20:48 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 5 loss:0.053553856909275055 norm:0.0018053973326459527 max memory_allocated 22894.75732421875 
[2025-02-06 08:21:22 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 6 loss:0.05333959683775902 norm:0.001589341671206057 max memory_allocated 22894.75732421875 
[2025-02-06 08:21:57 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 7 loss:0.053225547075271606 norm:0.0016558790812268853 max memory_allocated 22894.75732421875 
[2025-02-06 08:22:31 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 8 loss:0.05317432060837746 norm:0.001700467662885785 max memory_allocated 22894.75732421875 
[2025-02-06 08:23:05 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 9 loss:0.05308334901928902 norm:0.0017101769335567951 max memory_allocated 22894.75732421875 
[2025-02-06 08:23:40 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 10 loss:0.0530509427189827 norm:0.001634083455428481 max memory_allocated 22894.75732421875 
[2025-02-06 08:24:14 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 11 loss:0.05296625196933746 norm:0.0015730684390291572 max memory_allocated 22894.75732421875 
[2025-02-06 08:24:48 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 12 loss:0.052950579673051834 norm:0.0016365583287552 max memory_allocated 22894.75732421875 
[2025-02-06 08:25:23 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 13 loss:0.052871573716402054 norm:0.0014998780097812414 max memory_allocated 22894.75732421875 
[2025-02-06 08:25:57 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 14 loss:0.052862294018268585 norm:0.0014827343402430415 max memory_allocated 22894.75732421875 
[2025-02-06 08:26:31 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 15 loss:0.05283202975988388 norm:0.0014753993600606918 max memory_allocated 22894.75732421875 
[2025-02-06 08:27:05 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 16 loss:0.05280889943242073 norm:0.0015189471887424588 max memory_allocated 22894.75732421875 
[2025-02-06 08:27:39 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 17 loss:0.05280287563800812 norm:0.0014535252703353763 max memory_allocated 22894.75732421875 
[2025-02-06 08:28:14 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 18 loss:0.052811868488788605 norm:0.0014400018844753504 max memory_allocated 22894.75732421875 
[2025-02-06 08:28:48 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 19 loss:0.05281662940979004 norm:0.0015004314482212067 max memory_allocated 22894.75732421875 
[2025-02-06 08:28:58 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 8 ===
[2025-02-06 08:29:35 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 0 loss:0.07502539455890656 norm:0.0032282730098813772 max memory_allocated 22896.42919921875 
[2025-02-06 08:30:09 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 1 loss:0.0671028345823288 norm:0.0017811635043472052 max memory_allocated 22896.42919921875 
[2025-02-06 08:30:44 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 2 loss:0.06174662336707115 norm:0.001746641006320715 max memory_allocated 22896.42919921875 
[2025-02-06 08:31:18 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 3 loss:0.05985281616449356 norm:0.001542711746878922 max memory_allocated 22896.42919921875 
[2025-02-06 08:31:52 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 4 loss:0.058972954750061035 norm:0.0014893169282004237 max memory_allocated 22896.42919921875 
[2025-02-06 08:32:27 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 5 loss:0.058504506945610046 norm:0.0014526192098855972 max memory_allocated 22896.42919921875 
[2025-02-06 08:33:01 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 6 loss:0.05822867155075073 norm:0.001438841107301414 max memory_allocated 22896.42919921875 
[2025-02-06 08:33:35 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 7 loss:0.05807827040553093 norm:0.0014508046442642808 max memory_allocated 22896.42919921875 
[2025-02-06 08:34:09 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 8 loss:0.05799614638090134 norm:0.0015200509224087 max memory_allocated 22896.42919921875 
[2025-02-06 08:34:44 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 9 loss:0.05789031833410263 norm:0.0014500892721116543 max memory_allocated 22896.42919921875 
[2025-02-06 08:35:18 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 10 loss:0.057817667722702026 norm:0.0014069739263504744 max memory_allocated 22896.42919921875 
[2025-02-06 08:35:52 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 11 loss:0.05777139961719513 norm:0.0014710125979036093 max memory_allocated 22896.42919921875 
[2025-02-06 08:36:26 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 12 loss:0.05768170580267906 norm:0.0014055699575692415 max memory_allocated 22896.42919921875 
[2025-02-06 08:37:01 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 13 loss:0.05761285871267319 norm:0.001415248611010611 max memory_allocated 22896.42919921875 
[2025-02-06 08:37:35 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 14 loss:0.057605013251304626 norm:0.0014392868615686893 max memory_allocated 22896.42919921875 
[2025-02-06 08:38:09 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 15 loss:0.057552918791770935 norm:0.0014033347833901644 max memory_allocated 22896.42919921875 
[2025-02-06 08:38:44 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 16 loss:0.057553526014089584 norm:0.001409705262631178 max memory_allocated 22896.42919921875 
[2025-02-06 08:39:18 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 17 loss:0.057541728019714355 norm:0.001365797477774322 max memory_allocated 22896.42919921875 
[2025-02-06 08:39:52 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 18 loss:0.05754300579428673 norm:0.0014092178316786885 max memory_allocated 22896.42919921875 
[2025-02-06 08:40:26 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 19 loss:0.057527996599674225 norm:0.0013922536745667458 max memory_allocated 22896.42919921875 
[2025-02-06 08:40:36 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 9 ===
[2025-02-06 08:41:13 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 0 loss:0.082990363240242 norm:0.0033625455107539892 max memory_allocated 22898.10107421875 
[2025-02-06 08:41:47 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 1 loss:0.07380436360836029 norm:0.0018188722897320986 max memory_allocated 22898.10107421875 
[2025-02-06 08:42:21 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 2 loss:0.06812386959791183 norm:0.0014794374583289027 max memory_allocated 22898.10107421875 
[2025-02-06 08:42:56 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 3 loss:0.06614075601100922 norm:0.0013439368922263384 max memory_allocated 22898.10107421875 
[2025-02-06 08:43:30 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 4 loss:0.06515727192163467 norm:0.001281824428588152 max memory_allocated 22898.10107421875 
[2025-02-06 08:44:05 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 5 loss:0.0646158754825592 norm:0.0012257042108103633 max memory_allocated 22898.10107421875 
[2025-02-06 08:44:39 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 6 loss:0.06435990333557129 norm:0.0012891844380646944 max memory_allocated 22898.10107421875 
[2025-02-06 08:45:13 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 7 loss:0.0642148107290268 norm:0.0012847052421420813 max memory_allocated 22898.10107421875 
[2025-02-06 08:45:47 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 8 loss:0.0640617087483406 norm:0.001226690597832203 max memory_allocated 22898.10107421875 
[2025-02-06 08:46:21 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 9 loss:0.06398028135299683 norm:0.001211299910210073 max memory_allocated 22898.10107421875 
[2025-02-06 08:46:56 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 10 loss:0.06391926854848862 norm:0.001189240487292409 max memory_allocated 22898.10107421875 
[2025-02-06 08:47:30 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 11 loss:0.06386696547269821 norm:0.0011189631186425686 max memory_allocated 22898.10107421875 
[2025-02-06 08:48:04 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 12 loss:0.06378403306007385 norm:0.0011510325130075216 max memory_allocated 22898.10107421875 
[2025-02-06 08:48:39 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 13 loss:0.06374766677618027 norm:0.0011733649298548698 max memory_allocated 22898.10107421875 
[2025-02-06 08:49:13 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 14 loss:0.06370687484741211 norm:0.0012063997564837337 max memory_allocated 22898.10107421875 
[2025-02-06 08:49:48 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 15 loss:0.0636628270149231 norm:0.001169330789707601 max memory_allocated 22898.10107421875 
[2025-02-06 08:50:22 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 16 loss:0.06364649534225464 norm:0.0011602749582380056 max memory_allocated 22898.10107421875 
[2025-02-06 08:50:57 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 17 loss:0.06363330781459808 norm:0.001176635967567563 max memory_allocated 22898.10107421875 
[2025-02-06 08:51:31 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 18 loss:0.06361209601163864 norm:0.0011582347797229886 max memory_allocated 22898.10107421875 
[2025-02-06 08:52:05 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 19 loss:0.06359649449586868 norm:0.0011409170692786574 max memory_allocated 22898.10107421875 
[2025-02-06 08:52:14 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 10 ===
[2025-02-06 08:52:51 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 0 loss:0.08398671448230743 norm:0.002047518268227577 max memory_allocated 22899.77294921875 
[2025-02-06 08:53:26 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 1 loss:0.07689236104488373 norm:0.0015349364839494228 max memory_allocated 22899.77294921875 
[2025-02-06 08:54:00 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 2 loss:0.0719173327088356 norm:0.0013766284100711346 max memory_allocated 22899.77294921875 
[2025-02-06 08:54:34 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 3 loss:0.07021500915288925 norm:0.0013307987246662378 max memory_allocated 22899.77294921875 
[2025-02-06 08:55:09 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 4 loss:0.06936277449131012 norm:0.0012383441207930446 max memory_allocated 22899.77294921875 
[2025-02-06 08:55:43 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 5 loss:0.06889771670103073 norm:0.0011965931626036763 max memory_allocated 22899.77294921875 
[2025-02-06 08:56:17 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 6 loss:0.06861843168735504 norm:0.0012337237130850554 max memory_allocated 22899.77294921875 
[2025-02-06 08:56:51 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 7 loss:0.06850709766149521 norm:0.0011827985290437937 max memory_allocated 22899.77294921875 
[2025-02-06 08:57:26 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 8 loss:0.06843669712543488 norm:0.0011707283556461334 max memory_allocated 22899.77294921875 
[2025-02-06 08:58:00 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 9 loss:0.06838473677635193 norm:0.0012180829653516412 max memory_allocated 22899.77294921875 
[2025-02-06 08:58:34 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 10 loss:0.06832317262887955 norm:0.0011535788653418422 max memory_allocated 22899.77294921875 
[2025-02-06 08:59:09 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 11 loss:0.06827232241630554 norm:0.0011632103705778718 max memory_allocated 22899.77294921875 
[2025-02-06 08:59:43 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 12 loss:0.06823877990245819 norm:0.001150183379650116 max memory_allocated 22899.77294921875 
[2025-02-06 09:00:17 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 13 loss:0.06823316961526871 norm:0.0011404943652451038 max memory_allocated 22899.77294921875 
[2025-02-06 09:00:51 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 14 loss:0.06819512695074081 norm:0.0011439913650974631 max memory_allocated 22899.77294921875 
[2025-02-06 09:01:26 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 15 loss:0.0681639239192009 norm:0.0011171310907229781 max memory_allocated 22899.77294921875 
[2025-02-06 09:02:00 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 16 loss:0.06813546270132065 norm:0.001095072366297245 max memory_allocated 22899.77294921875 
[2025-02-06 09:02:35 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 17 loss:0.06813615560531616 norm:0.0011092572240158916 max memory_allocated 22899.77294921875 
[2025-02-06 09:03:09 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 18 loss:0.06814715266227722 norm:0.00112248701043427 max memory_allocated 22899.77294921875 
[2025-02-06 09:03:44 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 19 loss:0.06811477243900299 norm:0.0010854188585653901 max memory_allocated 22899.77294921875 
[2025-02-06 09:03:53 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 11 ===
[2025-02-06 09:04:30 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 0 loss:0.08849386125802994 norm:0.0019957395270466805 max memory_allocated 22901.44482421875 
[2025-02-06 09:05:05 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 1 loss:0.08083455264568329 norm:0.0013402218464761972 max memory_allocated 22901.44482421875 
[2025-02-06 09:05:39 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 2 loss:0.07551955431699753 norm:0.0011881600366905332 max memory_allocated 22901.44482421875 
[2025-02-06 09:06:13 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 3 loss:0.07386838644742966 norm:0.0011289255926385522 max memory_allocated 22901.44482421875 
[2025-02-06 09:06:48 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 4 loss:0.07308463007211685 norm:0.001093065831810236 max memory_allocated 22901.44482421875 
[2025-02-06 09:07:22 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 5 loss:0.07258088886737823 norm:0.0010131611488759518 max memory_allocated 22901.44482421875 
[2025-02-06 09:07:56 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 6 loss:0.07236119359731674 norm:0.0009877965785562992 max memory_allocated 22901.44482421875 
[2025-02-06 09:08:31 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 7 loss:0.0721985474228859 norm:0.0009823569562286139 max memory_allocated 22901.44482421875 
[2025-02-06 09:09:05 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 8 loss:0.07209227234125137 norm:0.0009941859170794487 max memory_allocated 22901.44482421875 
[2025-02-06 09:09:39 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 9 loss:0.0720442682504654 norm:0.0010052219731733203 max memory_allocated 22901.44482421875 
[2025-02-06 09:10:13 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 10 loss:0.07198697328567505 norm:0.0010421309852972627 max memory_allocated 22901.44482421875 
[2025-02-06 09:10:48 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 11 loss:0.07194332778453827 norm:0.0010065652895718813 max memory_allocated 22901.44482421875 
[2025-02-06 09:11:22 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 12 loss:0.07189518213272095 norm:0.00100241310428828 max memory_allocated 22901.44482421875 
[2025-02-06 09:11:56 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 13 loss:0.07188672572374344 norm:0.001025167410261929 max memory_allocated 22901.44482421875 
[2025-02-06 09:12:31 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 14 loss:0.07185626029968262 norm:0.0009824654553085566 max memory_allocated 22901.44482421875 
[2025-02-06 09:13:05 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 15 loss:0.0718090832233429 norm:0.0009579819161444902 max memory_allocated 22901.44482421875 
[2025-02-06 09:13:39 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 16 loss:0.07179538905620575 norm:0.0010050522396340966 max memory_allocated 22901.44482421875 
[2025-02-06 09:14:13 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 17 loss:0.07178667932748795 norm:0.0009704569238238037 max memory_allocated 22901.44482421875 
[2025-02-06 09:14:48 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 18 loss:0.07175497710704803 norm:0.0009965451899915934 max memory_allocated 22901.44482421875 
[2025-02-06 09:15:22 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 19 loss:0.07174548506736755 norm:0.0009608582477085292 max memory_allocated 22901.44482421875 
[2025-02-06 09:15:31 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 12 ===
[2025-02-06 09:16:09 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 0 loss:0.08963999152183533 norm:0.0020338003523647785 max memory_allocated 22903.11669921875 
[2025-02-06 09:16:43 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 1 loss:0.08278953284025192 norm:0.001546535175293684 max memory_allocated 22903.11669921875 
[2025-02-06 09:17:18 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 2 loss:0.0776878073811531 norm:0.0013870771508663893 max memory_allocated 22903.11669921875 
[2025-02-06 09:17:52 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 3 loss:0.07594586908817291 norm:0.0012740150559693575 max memory_allocated 22903.11669921875 
[2025-02-06 09:18:26 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 4 loss:0.07504671066999435 norm:0.001297258073464036 max memory_allocated 22903.11669921875 
[2025-02-06 09:19:00 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 5 loss:0.0745147243142128 norm:0.0011546657187864184 max memory_allocated 22903.11669921875 
[2025-02-06 09:19:35 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 6 loss:0.0742345005273819 norm:0.0011807047994807363 max memory_allocated 22903.11669921875 
[2025-02-06 09:20:09 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 7 loss:0.0740089938044548 norm:0.00114400964230299 max memory_allocated 22903.11669921875 
[2025-02-06 09:20:43 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 8 loss:0.07389479130506516 norm:0.0011104976292699575 max memory_allocated 22903.11669921875 
[2025-02-06 09:21:18 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 9 loss:0.07378780841827393 norm:0.0010909342672675848 max memory_allocated 22903.11669921875 
[2025-02-06 09:21:52 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 10 loss:0.07370962202548981 norm:0.0010708285262808204 max memory_allocated 22903.11669921875 
[2025-02-06 09:22:26 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 11 loss:0.07366027683019638 norm:0.0010523044038563967 max memory_allocated 22903.11669921875 
[2025-02-06 09:23:01 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 12 loss:0.07360023260116577 norm:0.001062774914316833 max memory_allocated 22903.11669921875 
[2025-02-06 09:23:35 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 13 loss:0.0735628679394722 norm:0.001040163217112422 max memory_allocated 22903.11669921875 
[2025-02-06 09:24:09 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 14 loss:0.07354949414730072 norm:0.0010683288564905524 max memory_allocated 22903.11669921875 
[2025-02-06 09:24:44 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 15 loss:0.07349486649036407 norm:0.0010494454763829708 max memory_allocated 22903.11669921875 
[2025-02-06 09:25:18 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 16 loss:0.07348413020372391 norm:0.0010279006091877818 max memory_allocated 22903.11669921875 
[2025-02-06 09:25:52 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 17 loss:0.07347838580608368 norm:0.001007655868306756 max memory_allocated 22903.11669921875 
[2025-02-06 09:26:26 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 18 loss:0.07346273213624954 norm:0.0010446078376844525 max memory_allocated 22903.11669921875 
[2025-02-06 09:27:01 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 19 loss:0.07345987111330032 norm:0.0010479091433808208 max memory_allocated 22903.11669921875 
[2025-02-06 09:27:10 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 13 ===
[2025-02-06 09:27:47 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 0 loss:0.0903555154800415 norm:0.0021231963764876127 max memory_allocated 22904.78857421875 
[2025-02-06 09:28:22 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 1 loss:0.08380508422851562 norm:0.001149746822193265 max memory_allocated 22904.78857421875 
[2025-02-06 09:28:56 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 2 loss:0.07908385246992111 norm:0.001031253021210432 max memory_allocated 22904.78857421875 
[2025-02-06 09:29:30 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 3 loss:0.07740374654531479 norm:0.0009507398353889585 max memory_allocated 22904.78857421875 
[2025-02-06 09:30:05 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 4 loss:0.07658914476633072 norm:0.0009146592346951365 max memory_allocated 22904.78857421875 
[2025-02-06 09:30:39 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 5 loss:0.07610239088535309 norm:0.0009187553077936172 max memory_allocated 22904.78857421875 
[2025-02-06 09:31:13 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 6 loss:0.07583463191986084 norm:0.0008856597123667598 max memory_allocated 22904.78857421875 
[2025-02-06 09:31:48 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 7 loss:0.07569732517004013 norm:0.0008893581107258797 max memory_allocated 22904.78857421875 
[2025-02-06 09:32:22 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 8 loss:0.07557132840156555 norm:0.0008701121550984681 max memory_allocated 22904.78857421875 
[2025-02-06 09:32:56 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 9 loss:0.07548244297504425 norm:0.0008706001099199057 max memory_allocated 22904.78857421875 
[2025-02-06 09:33:30 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 10 loss:0.07542769610881805 norm:0.000863648543599993 max memory_allocated 22904.78857421875 
[2025-02-06 09:34:04 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 11 loss:0.07536206394433975 norm:0.0008462994010187685 max memory_allocated 22904.78857421875 
[2025-02-06 09:34:39 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 12 loss:0.07529855519533157 norm:0.0008297371678054333 max memory_allocated 22904.78857421875 
[2025-02-06 09:35:13 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 13 loss:0.07525798678398132 norm:0.0008234116248786449 max memory_allocated 22904.78857421875 
[2025-02-06 09:35:47 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 14 loss:0.07521697133779526 norm:0.000819287437479943 max memory_allocated 22904.78857421875 
[2025-02-06 09:36:21 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 15 loss:0.07518250495195389 norm:0.0008435298805125058 max memory_allocated 22904.78857421875 
[2025-02-06 09:36:56 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 16 loss:0.07515206933021545 norm:0.0008160004508681595 max memory_allocated 22904.78857421875 
[2025-02-06 09:37:30 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 17 loss:0.07515859603881836 norm:0.0008354661404155195 max memory_allocated 22904.78857421875 
[2025-02-06 09:38:04 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 18 loss:0.07513965666294098 norm:0.0008252383559010923 max memory_allocated 22904.78857421875 
[2025-02-06 09:38:38 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 19 loss:0.07514817267656326 norm:0.0008349187555722892 max memory_allocated 22904.78857421875 
[2025-02-06 09:38:48 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 14 ===
[2025-02-06 09:39:25 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 0 loss:0.09927050769329071 norm:0.002478063805028796 max memory_allocated 22906.46044921875 
[2025-02-06 09:39:59 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 1 loss:0.0910516008734703 norm:0.0016009167302399874 max memory_allocated 22906.46044921875 
[2025-02-06 09:40:34 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 2 loss:0.0853385180234909 norm:0.0013633954804390669 max memory_allocated 22906.46044921875 
[2025-02-06 09:41:08 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 3 loss:0.08342409133911133 norm:0.0013337242417037487 max memory_allocated 22906.46044921875 
[2025-02-06 09:41:42 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 4 loss:0.08246161788702011 norm:0.0012214642483741045 max memory_allocated 22906.46044921875 
[2025-02-06 09:42:17 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 5 loss:0.0819481834769249 norm:0.0011848232243210077 max memory_allocated 22906.46044921875 
[2025-02-06 09:42:51 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 6 loss:0.08163663744926453 norm:0.0011601618025451899 max memory_allocated 22906.46044921875 
[2025-02-06 09:43:25 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 7 loss:0.08147399127483368 norm:0.0011435648193582892 max memory_allocated 22906.46044921875 
[2025-02-06 09:44:00 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 8 loss:0.08134552091360092 norm:0.0011603081366047263 max memory_allocated 22906.46044921875 
[2025-02-06 09:44:34 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 9 loss:0.08119889348745346 norm:0.0011233738623559475 max memory_allocated 22906.46044921875 
[2025-02-06 09:45:08 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 10 loss:0.08109642565250397 norm:0.0010861015180125833 max memory_allocated 22906.46044921875 
[2025-02-06 09:45:42 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 11 loss:0.08101930469274521 norm:0.00111843750346452 max memory_allocated 22906.46044921875 
[2025-02-06 09:46:16 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 12 loss:0.08094942569732666 norm:0.0011213257675990462 max memory_allocated 22906.46044921875 
[2025-02-06 09:46:51 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 13 loss:0.08090687543153763 norm:0.001097630592994392 max memory_allocated 22906.46044921875 
[2025-02-06 09:47:25 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 14 loss:0.08091719448566437 norm:0.0011069482425227761 max memory_allocated 22906.46044921875 
[2025-02-06 09:47:59 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 15 loss:0.0809113085269928 norm:0.001121851266361773 max memory_allocated 22906.46044921875 
[2025-02-06 09:48:34 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 16 loss:0.08090393245220184 norm:0.0011080473195761442 max memory_allocated 22906.46044921875 
[2025-02-06 09:49:08 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 17 loss:0.08087016642093658 norm:0.0011042829137295485 max memory_allocated 22906.46044921875 
[2025-02-06 09:49:42 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 18 loss:0.08084186911582947 norm:0.0011009357403963804 max memory_allocated 22906.46044921875 
[2025-02-06 09:50:16 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 19 loss:0.0808330550789833 norm:0.0010966508416458964 max memory_allocated 22906.46044921875 
[2025-02-06 09:50:26 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 15 ===
[2025-02-06 09:51:03 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 0 loss:0.10238000750541687 norm:0.002172280801460147 max memory_allocated 22908.13232421875 
[2025-02-06 09:51:38 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 1 loss:0.0951639860868454 norm:0.0016487680841237307 max memory_allocated 22908.13232421875 
[2025-02-06 09:52:12 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 2 loss:0.08968770503997803 norm:0.0016709103947505355 max memory_allocated 22908.13232421875 
[2025-02-06 09:52:46 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 3 loss:0.0878712385892868 norm:0.0015266764676198363 max memory_allocated 22908.13232421875 
[2025-02-06 09:53:20 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 4 loss:0.08696189522743225 norm:0.0016117182094603777 max memory_allocated 22908.13232421875 
[2025-02-06 09:53:55 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 5 loss:0.08644448965787888 norm:0.001676559797488153 max memory_allocated 22908.13232421875 
[2025-02-06 09:54:29 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 6 loss:0.08614335209131241 norm:0.001547681400552392 max memory_allocated 22908.13232421875 
[2025-02-06 09:55:03 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 7 loss:0.08600550889968872 norm:0.001448710565455258 max memory_allocated 22908.13232421875 
[2025-02-06 09:55:38 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 8 loss:0.08588632941246033 norm:0.00143213733099401 max memory_allocated 22908.13232421875 
[2025-02-06 09:56:12 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 9 loss:0.08578815311193466 norm:0.0013829729286953807 max memory_allocated 22908.13232421875 
[2025-02-06 09:56:46 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 10 loss:0.08575709909200668 norm:0.0014249496161937714 max memory_allocated 22908.13232421875 
[2025-02-06 09:57:21 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 11 loss:0.08565295487642288 norm:0.0013643783750012517 max memory_allocated 22908.13232421875 
[2025-02-06 09:57:55 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 12 loss:0.08559931814670563 norm:0.0014298040186986327 max memory_allocated 22908.13232421875 
[2025-02-06 09:58:29 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 13 loss:0.08555062860250473 norm:0.001369002042338252 max memory_allocated 22908.13232421875 
[2025-02-06 09:59:04 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 14 loss:0.0855000913143158 norm:0.0014448288129642606 max memory_allocated 22908.13232421875 
[2025-02-06 09:59:38 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 15 loss:0.08547798544168472 norm:0.0014483119593933225 max memory_allocated 22908.13232421875 
[2025-02-06 10:00:12 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 16 loss:0.0854564905166626 norm:0.0013247276656329632 max memory_allocated 22908.13232421875 
[2025-02-06 10:00:46 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 17 loss:0.08543901145458221 norm:0.0013118295464664698 max memory_allocated 22908.13232421875 
[2025-02-06 10:01:21 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 18 loss:0.0854177251458168 norm:0.0013361149467527866 max memory_allocated 22908.13232421875 
[2025-02-06 10:01:55 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 19 loss:0.08539284765720367 norm:0.001249963417649269 max memory_allocated 22908.13232421875 
[2025-02-06 10:02:04 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 16 ===
[2025-02-06 10:02:42 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 0 loss:0.11254019290208817 norm:0.0025037580635398626 max memory_allocated 22909.80419921875 
[2025-02-06 10:03:16 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 1 loss:0.1038348376750946 norm:0.0017066348809748888 max memory_allocated 22909.80419921875 
[2025-02-06 10:03:50 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 2 loss:0.09776858985424042 norm:0.0016004684148356318 max memory_allocated 22909.80419921875 
[2025-02-06 10:04:24 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 3 loss:0.09576749801635742 norm:0.0015118338633328676 max memory_allocated 22909.80419921875 
[2025-02-06 10:04:59 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 4 loss:0.09475912153720856 norm:0.0014751795679330826 max memory_allocated 22909.80419921875 
[2025-02-06 10:05:33 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 5 loss:0.09425333887338638 norm:0.0014652684330940247 max memory_allocated 22909.80419921875 
[2025-02-06 10:06:07 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 6 loss:0.09400525689125061 norm:0.0014724518405273557 max memory_allocated 22909.80419921875 
[2025-02-06 10:06:41 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 7 loss:0.0937924012541771 norm:0.0014351012650877237 max memory_allocated 22909.80419921875 
[2025-02-06 10:07:16 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 8 loss:0.0936446413397789 norm:0.0013744015013799071 max memory_allocated 22909.80419921875 
[2025-02-06 10:07:50 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 9 loss:0.09351266920566559 norm:0.0013337722048163414 max memory_allocated 22909.80419921875 
[2025-02-06 10:08:24 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 10 loss:0.09338504821062088 norm:0.0013576650526374578 max memory_allocated 22909.80419921875 
[2025-02-06 10:08:59 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 11 loss:0.09332845360040665 norm:0.0013415892608463764 max memory_allocated 22909.80419921875 
[2025-02-06 10:09:33 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 12 loss:0.09325019270181656 norm:0.001297112787142396 max memory_allocated 22909.80419921875 
[2025-02-06 10:10:07 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 13 loss:0.09320264309644699 norm:0.0013039442710578442 max memory_allocated 22909.80419921875 
[2025-02-06 10:10:41 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 14 loss:0.09321297705173492 norm:0.0013200771063566208 max memory_allocated 22909.80419921875 
[2025-02-06 10:11:16 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 15 loss:0.093178890645504 norm:0.0012992906849831343 max memory_allocated 22909.80419921875 
[2025-02-06 10:11:50 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 16 loss:0.09313780814409256 norm:0.0012532452819868922 max memory_allocated 22909.80419921875 
[2025-02-06 10:12:24 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 17 loss:0.09312459081411362 norm:0.001287751947529614 max memory_allocated 22909.80419921875 
[2025-02-06 10:12:58 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 18 loss:0.09309592097997665 norm:0.0012710073497146368 max memory_allocated 22909.80419921875 
[2025-02-06 10:13:33 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 19 loss:0.0930815264582634 norm:0.0012979531893506646 max memory_allocated 22909.80419921875 
[2025-02-06 10:13:42 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 17 ===
[2025-02-06 10:14:20 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 0 loss:0.12404530495405197 norm:0.002155264839529991 max memory_allocated 22911.47607421875 
[2025-02-06 10:14:54 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 1 loss:0.11467066407203674 norm:0.0014800139470025897 max memory_allocated 22911.47607421875 
[2025-02-06 10:15:29 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 2 loss:0.10782972723245621 norm:0.0013658099342137575 max memory_allocated 22911.47607421875 
[2025-02-06 10:16:03 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 3 loss:0.10564809292554855 norm:0.0013002026826143265 max memory_allocated 22911.47607421875 
[2025-02-06 10:16:37 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 4 loss:0.10457369685173035 norm:0.0012387563474476337 max memory_allocated 22911.47607421875 
[2025-02-06 10:17:11 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 5 loss:0.10411156713962555 norm:0.0012095329584553838 max memory_allocated 22911.47607421875 
[2025-02-06 10:17:46 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 6 loss:0.10385072231292725 norm:0.0011261908803135157 max memory_allocated 22911.47607421875 
[2025-02-06 10:18:20 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 7 loss:0.10365032404661179 norm:0.0011467891745269299 max memory_allocated 22911.47607421875 
[2025-02-06 10:18:54 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 8 loss:0.10350365936756134 norm:0.0011152909137308598 max memory_allocated 22911.47607421875 
[2025-02-06 10:19:29 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 9 loss:0.10336516797542572 norm:0.0011361547512933612 max memory_allocated 22911.47607421875 
[2025-02-06 10:20:03 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 10 loss:0.10327786952257156 norm:0.0011110689956694841 max memory_allocated 22911.47607421875 
[2025-02-06 10:20:37 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 11 loss:0.10318423062562943 norm:0.0010665133595466614 max memory_allocated 22911.47607421875 
[2025-02-06 10:21:11 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 12 loss:0.10309035331010818 norm:0.0010334145044907928 max memory_allocated 22911.47607421875 
[2025-02-06 10:21:46 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 13 loss:0.10303924977779388 norm:0.0010261983843520284 max memory_allocated 22911.47607421875 
[2025-02-06 10:22:20 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 14 loss:0.10299351066350937 norm:0.0010405725333839655 max memory_allocated 22911.47607421875 
[2025-02-06 10:22:54 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 15 loss:0.10294140130281448 norm:0.0010256989626213908 max memory_allocated 22911.47607421875 
[2025-02-06 10:23:29 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 16 loss:0.10288725048303604 norm:0.0009960737079381943 max memory_allocated 22911.47607421875 
[2025-02-06 10:24:03 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 17 loss:0.10284880548715591 norm:0.0009842843282967806 max memory_allocated 22911.47607421875 
[2025-02-06 10:24:37 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 18 loss:0.1028522327542305 norm:0.0010082197841256857 max memory_allocated 22911.47607421875 
[2025-02-06 10:25:12 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 19 loss:0.10281545668840408 norm:0.0010145327541977167 max memory_allocated 22911.47607421875 
[2025-02-06 10:25:21 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 18 ===
[2025-02-06 10:25:59 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 0 loss:0.1367497593164444 norm:0.0017190357903018594 max memory_allocated 22913.14794921875 
[2025-02-06 10:26:33 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 1 loss:0.12770090997219086 norm:0.0012985920766368508 max memory_allocated 22913.14794921875 
[2025-02-06 10:27:07 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 2 loss:0.1209406778216362 norm:0.0012323444243520498 max memory_allocated 22913.14794921875 
[2025-02-06 10:27:41 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 3 loss:0.11893077194690704 norm:0.0012433752417564392 max memory_allocated 22913.14794921875 
[2025-02-06 10:28:16 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 4 loss:0.1179046630859375 norm:0.00119402923155576 max memory_allocated 22913.14794921875 
[2025-02-06 10:28:50 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 5 loss:0.11749700456857681 norm:0.0011811885051429272 max memory_allocated 22913.14794921875 
[2025-02-06 10:29:25 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 6 loss:0.11724749207496643 norm:0.0011783313238993287 max memory_allocated 22913.14794921875 
[2025-02-06 10:29:59 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 7 loss:0.11701470613479614 norm:0.0011662521865218878 max memory_allocated 22913.14794921875 
[2025-02-06 10:30:33 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 8 loss:0.11686760187149048 norm:0.0011672456748783588 max memory_allocated 22913.14794921875 
[2025-02-06 10:31:08 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 9 loss:0.11677887290716171 norm:0.0011400895891711116 max memory_allocated 22913.14794921875 
[2025-02-06 10:31:42 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 10 loss:0.11670117825269699 norm:0.0011014040792360902 max memory_allocated 22913.14794921875 
[2025-02-06 10:32:16 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 11 loss:0.11661321669816971 norm:0.0010868750978261232 max memory_allocated 22913.14794921875 
[2025-02-06 10:32:50 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 12 loss:0.1165061816573143 norm:0.0010816478170454502 max memory_allocated 22913.14794921875 
[2025-02-06 10:33:25 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 13 loss:0.1164563000202179 norm:0.0010544192045927048 max memory_allocated 22913.14794921875 
[2025-02-06 10:33:59 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 14 loss:0.11639082431793213 norm:0.0010749474167823792 max memory_allocated 22913.14794921875 
[2025-02-06 10:34:34 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 15 loss:0.11631565541028976 norm:0.001047738129273057 max memory_allocated 22913.14794921875 
[2025-02-06 10:35:08 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 16 loss:0.11627848446369171 norm:0.0010393677512183785 max memory_allocated 22913.14794921875 
[2025-02-06 10:35:42 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 17 loss:0.11622963100671768 norm:0.0010387301445007324 max memory_allocated 22913.14794921875 
[2025-02-06 10:36:16 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 18 loss:0.1161925345659256 norm:0.0010397207224741578 max memory_allocated 22913.14794921875 
[2025-02-06 10:36:50 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 19 loss:0.11616156250238419 norm:0.0010478937765583396 max memory_allocated 22913.14794921875 
[2025-02-06 10:37:00 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 19 ===
[2025-02-06 10:37:37 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 0 loss:0.15546950697898865 norm:0.0022173759061843157 max memory_allocated 22914.81982421875 
[2025-02-06 10:38:11 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 1 loss:0.1459171622991562 norm:0.0017750805709511042 max memory_allocated 22914.81982421875 
[2025-02-06 10:38:45 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 2 loss:0.13865795731544495 norm:0.001573840039782226 max memory_allocated 22914.81982421875 
[2025-02-06 10:39:20 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 3 loss:0.13631507754325867 norm:0.0015577028971165419 max memory_allocated 22914.81982421875 
[2025-02-06 10:39:54 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 4 loss:0.13525308668613434 norm:0.0014176176628097892 max memory_allocated 22914.81982421875 
[2025-02-06 10:40:28 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 5 loss:0.1348039209842682 norm:0.0014529662439599633 max memory_allocated 22914.81982421875 
[2025-02-06 10:41:03 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 6 loss:0.13454486429691315 norm:0.0013942422810941935 max memory_allocated 22914.81982421875 
[2025-02-06 10:41:37 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 7 loss:0.13432839512825012 norm:0.0013786708004772663 max memory_allocated 22914.81982421875 
[2025-02-06 10:42:11 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 8 loss:0.13414722681045532 norm:0.001370165147818625 max memory_allocated 22914.81982421875 
[2025-02-06 10:42:45 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 9 loss:0.13401640951633453 norm:0.0013415018329396844 max memory_allocated 22914.81982421875 
[2025-02-06 10:43:20 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 10 loss:0.1338733732700348 norm:0.0013380845775827765 max memory_allocated 22914.81982421875 
[2025-02-06 10:43:54 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 11 loss:0.13375256955623627 norm:0.0013282650616019964 max memory_allocated 22914.81982421875 
[2025-02-06 10:44:28 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 12 loss:0.13366132974624634 norm:0.001352186081930995 max memory_allocated 22914.81982421875 
[2025-02-06 10:45:03 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 13 loss:0.13359205424785614 norm:0.0013228015741333365 max memory_allocated 22914.81982421875 
[2025-02-06 10:45:37 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 14 loss:0.13353271782398224 norm:0.0013121512020006776 max memory_allocated 22914.81982421875 
[2025-02-06 10:46:11 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 15 loss:0.13347463309764862 norm:0.0012801375705748796 max memory_allocated 22914.81982421875 
[2025-02-06 10:46:46 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 16 loss:0.13344061374664307 norm:0.0013265743618831038 max memory_allocated 22914.81982421875 
[2025-02-06 10:47:20 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 17 loss:0.13342781364917755 norm:0.0013172486796975136 max memory_allocated 22914.81982421875 
[2025-02-06 10:47:54 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 18 loss:0.13338764011859894 norm:0.0012892077211290598 max memory_allocated 22914.81982421875 
[2025-02-06 10:48:28 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 19 loss:0.1333337426185608 norm:0.0012464516330510378 max memory_allocated 22914.81982421875 
[2025-02-06 10:48:38 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 20 ===
[2025-02-06 10:49:15 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 0 loss:0.18685297667980194 norm:0.0028566671535372734 max memory_allocated 22916.49169921875 
[2025-02-06 10:49:50 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 1 loss:0.17467746138572693 norm:0.0018961378373205662 max memory_allocated 22916.49169921875 
[2025-02-06 10:50:24 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 2 loss:0.16563504934310913 norm:0.0017166681354865432 max memory_allocated 22916.49169921875 
[2025-02-06 10:50:58 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 3 loss:0.1629137545824051 norm:0.0016831285320222378 max memory_allocated 22916.49169921875 
[2025-02-06 10:51:33 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 4 loss:0.1617480218410492 norm:0.0016228819731622934 max memory_allocated 22916.49169921875 
[2025-02-06 10:52:07 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 5 loss:0.16117307543754578 norm:0.0015309269074350595 max memory_allocated 22916.49169921875 
[2025-02-06 10:52:41 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 6 loss:0.16084402799606323 norm:0.0015281469095498323 max memory_allocated 22916.49169921875 
[2025-02-06 10:53:15 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 7 loss:0.16060711443424225 norm:0.0015381562989205122 max memory_allocated 22916.49169921875 
[2025-02-06 10:53:50 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 8 loss:0.16043977439403534 norm:0.0015125004574656487 max memory_allocated 22916.49169921875 
[2025-02-06 10:54:24 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 9 loss:0.1602051556110382 norm:0.00150598818436265 max memory_allocated 22916.49169921875 
[2025-02-06 10:54:58 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 10 loss:0.15996474027633667 norm:0.001450522686354816 max memory_allocated 22916.49169921875 
[2025-02-06 10:55:33 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 11 loss:0.15976473689079285 norm:0.0014177075354382396 max memory_allocated 22916.49169921875 
[2025-02-06 10:56:07 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 12 loss:0.1596313863992691 norm:0.0013988439459353685 max memory_allocated 22916.49169921875 
[2025-02-06 10:56:41 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 13 loss:0.15953734517097473 norm:0.0014320382615551353 max memory_allocated 22916.49169921875 
[2025-02-06 10:57:15 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 14 loss:0.159450963139534 norm:0.0014048365410417318 max memory_allocated 22916.49169921875 
[2025-02-06 10:57:50 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 15 loss:0.1593865156173706 norm:0.0013643259881064296 max memory_allocated 22916.49169921875 
[2025-02-06 10:58:24 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 16 loss:0.15931174159049988 norm:0.0013858816819265485 max memory_allocated 22916.49169921875 
[2025-02-06 10:58:58 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 17 loss:0.15922963619232178 norm:0.0013718061381950974 max memory_allocated 22916.49169921875 
[2025-02-06 10:59:32 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 18 loss:0.15917596220970154 norm:0.001412494108080864 max memory_allocated 22916.49169921875 
[2025-02-06 11:00:07 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 19 loss:0.15911677479743958 norm:0.0013991709565743804 max memory_allocated 22916.49169921875 
[2025-02-06 11:00:16 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 21 ===
[2025-02-06 11:00:54 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 0 loss:0.2160743772983551 norm:0.002859801985323429 max memory_allocated 22918.16357421875 
[2025-02-06 11:01:28 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 1 loss:0.20380131900310516 norm:0.0019961807411164045 max memory_allocated 22918.16357421875 
[2025-02-06 11:02:02 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 2 loss:0.19383098185062408 norm:0.0017848103307187557 max memory_allocated 22918.16357421875 
[2025-02-06 11:02:36 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 3 loss:0.19093991816043854 norm:0.0016561516094952822 max memory_allocated 22918.16357421875 
[2025-02-06 11:03:11 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 4 loss:0.18977411091327667 norm:0.001562301884405315 max memory_allocated 22918.16357421875 
[2025-02-06 11:03:45 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 5 loss:0.18927133083343506 norm:0.0015229458222165704 max memory_allocated 22918.16357421875 
[2025-02-06 11:04:19 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 6 loss:0.1889512836933136 norm:0.0015173364663496614 max memory_allocated 22918.16357421875 
[2025-02-06 11:04:53 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 7 loss:0.18865817785263062 norm:0.0014587875921279192 max memory_allocated 22918.16357421875 
[2025-02-06 11:05:28 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 8 loss:0.188472718000412 norm:0.0014584269374608994 max memory_allocated 22918.16357421875 
[2025-02-06 11:06:02 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 9 loss:0.18825316429138184 norm:0.0014792962465435266 max memory_allocated 22918.16357421875 
[2025-02-06 11:06:36 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 10 loss:0.1880468726158142 norm:0.001374121755361557 max memory_allocated 22918.16357421875 
[2025-02-06 11:07:10 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 11 loss:0.1878977119922638 norm:0.001418132334947586 max memory_allocated 22918.16357421875 
[2025-02-06 11:07:45 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 12 loss:0.187781423330307 norm:0.0013913026778027415 max memory_allocated 22918.16357421875 
[2025-02-06 11:08:19 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 13 loss:0.18770216405391693 norm:0.0014238214353099465 max memory_allocated 22918.16357421875 
[2025-02-06 11:08:53 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 14 loss:0.1875779628753662 norm:0.001469226903282106 max memory_allocated 22918.16357421875 
[2025-02-06 11:09:27 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 15 loss:0.1875084638595581 norm:0.0014323778450489044 max memory_allocated 22918.16357421875 
[2025-02-06 11:10:02 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 16 loss:0.18744239211082458 norm:0.00145749154035002 max memory_allocated 22918.16357421875 
[2025-02-06 11:10:36 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 17 loss:0.18739785254001617 norm:0.0015564326895400882 max memory_allocated 22918.16357421875 
[2025-02-06 11:11:10 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 18 loss:0.18733438849449158 norm:0.0014508251333609223 max memory_allocated 22918.16357421875 
[2025-02-06 11:11:44 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 19 loss:0.1872590184211731 norm:0.0013876749435439706 max memory_allocated 22918.16357421875 
[2025-02-06 11:11:54 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 22 ===
[2025-02-06 11:12:31 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 0 loss:0.2446124404668808 norm:0.002747030695900321 max memory_allocated 22919.83544921875 
[2025-02-06 11:13:06 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 1 loss:0.23210348188877106 norm:0.002107032109051943 max memory_allocated 22919.83544921875 
[2025-02-06 11:13:40 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 2 loss:0.22219814360141754 norm:0.0019676911178976297 max memory_allocated 22919.83544921875 
[2025-02-06 11:14:14 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 3 loss:0.219232439994812 norm:0.0018744005355983973 max memory_allocated 22919.83544921875 
[2025-02-06 11:14:49 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 4 loss:0.21825039386749268 norm:0.0020523332059383392 max memory_allocated 22919.83544921875 
[2025-02-06 11:15:23 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 5 loss:0.21772706508636475 norm:0.001899846363812685 max memory_allocated 22919.83544921875 
[2025-02-06 11:15:57 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 6 loss:0.2173633575439453 norm:0.0017778276233002543 max memory_allocated 22919.83544921875 
[2025-02-06 11:16:31 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 7 loss:0.2170376181602478 norm:0.0017131570493802428 max memory_allocated 22919.83544921875 
[2025-02-06 11:17:06 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 8 loss:0.21679557859897614 norm:0.0017497474327683449 max memory_allocated 22919.83544921875 
[2025-02-06 11:17:40 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 9 loss:0.2166018784046173 norm:0.0017420912627130747 max memory_allocated 22919.83544921875 
[2025-02-06 11:18:14 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 10 loss:0.21641285717487335 norm:0.0017393985763192177 max memory_allocated 22919.83544921875 
[2025-02-06 11:18:48 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 11 loss:0.21627773344516754 norm:0.001764993299730122 max memory_allocated 22919.83544921875 
[2025-02-06 11:19:22 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 12 loss:0.21617524325847626 norm:0.00172663782723248 max memory_allocated 22919.83544921875 
[2025-02-06 11:19:57 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 13 loss:0.21604983508586884 norm:0.0016731361392885447 max memory_allocated 22919.83544921875 
[2025-02-06 11:20:31 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 14 loss:0.2159116417169571 norm:0.0015721814706921577 max memory_allocated 22919.83544921875 
[2025-02-06 11:21:06 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 15 loss:0.21582460403442383 norm:0.0016074678860604763 max memory_allocated 22919.83544921875 
[2025-02-06 11:21:40 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 16 loss:0.21571768820285797 norm:0.001649245503358543 max memory_allocated 22919.83544921875 
[2025-02-06 11:22:14 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 17 loss:0.21561159193515778 norm:0.001589084160514176 max memory_allocated 22919.83544921875 
[2025-02-06 11:22:48 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 18 loss:0.21556802093982697 norm:0.0015542351175099611 max memory_allocated 22919.83544921875 
[2025-02-06 11:23:23 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 19 loss:0.21554602682590485 norm:0.0015484173782169819 max memory_allocated 22919.83544921875 
[2025-02-06 11:23:32 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 23 ===
[2025-02-06 11:24:09 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 0 loss:0.28369662165641785 norm:0.0036554348189383745 max memory_allocated 22921.50732421875 
[2025-02-06 11:24:44 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 1 loss:0.2706908881664276 norm:0.002765037352219224 max memory_allocated 22921.50732421875 
[2025-02-06 11:25:18 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 2 loss:0.25994643568992615 norm:0.002749956678599119 max memory_allocated 22921.50732421875 
[2025-02-06 11:25:52 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 3 loss:0.2567639648914337 norm:0.0025440556928515434 max memory_allocated 22921.50732421875 
[2025-02-06 11:26:27 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 4 loss:0.2555698752403259 norm:0.002460226183757186 max memory_allocated 22921.50732421875 
[2025-02-06 11:27:01 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 5 loss:0.25494521856307983 norm:0.0023288584779947996 max memory_allocated 22921.50732421875 
[2025-02-06 11:27:35 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 6 loss:0.2545875012874603 norm:0.002353786025196314 max memory_allocated 22921.50732421875 
[2025-02-06 11:28:09 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 7 loss:0.25431394577026367 norm:0.0022614155896008015 max memory_allocated 22921.50732421875 
[2025-02-06 11:28:44 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 8 loss:0.2540120482444763 norm:0.0022424350026994944 max memory_allocated 22921.50732421875 
[2025-02-06 11:29:18 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 9 loss:0.25377556681632996 norm:0.002225408097729087 max memory_allocated 22921.50732421875 
[2025-02-06 11:29:52 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 10 loss:0.253600150346756 norm:0.002162855351343751 max memory_allocated 22921.50732421875 
[2025-02-06 11:30:27 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 11 loss:0.25346922874450684 norm:0.0021370043978095055 max memory_allocated 22921.50732421875 
[2025-02-06 11:31:01 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 12 loss:0.25333210825920105 norm:0.002133223693817854 max memory_allocated 22921.50732421875 
[2025-02-06 11:31:35 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 13 loss:0.25319820642471313 norm:0.001996940467506647 max memory_allocated 22921.50732421875 
[2025-02-06 11:32:10 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 14 loss:0.25305962562561035 norm:0.0019697784446179867 max memory_allocated 22921.50732421875 
[2025-02-06 11:32:44 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 15 loss:0.25299400091171265 norm:0.002043310087174177 max memory_allocated 22921.50732421875 
[2025-02-06 11:33:18 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 16 loss:0.2529244124889374 norm:0.002051949966698885 max memory_allocated 22921.50732421875 
[2025-02-06 11:33:52 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 17 loss:0.25283125042915344 norm:0.00206452002748847 max memory_allocated 22921.50732421875 
[2025-02-06 11:34:27 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 18 loss:0.2528115510940552 norm:0.0020564328879117966 max memory_allocated 22921.50732421875 
[2025-02-06 11:35:01 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 19 loss:0.2526988387107849 norm:0.0020549192558974028 max memory_allocated 22921.50732421875 
[2025-02-06 11:35:10 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 24 ===
[2025-02-06 11:35:47 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 0 loss:0.3205374479293823 norm:0.0021331477910280228 max memory_allocated 22923.17919921875 
[2025-02-06 11:36:22 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 1 loss:0.3075075149536133 norm:0.0018178040627390146 max memory_allocated 22923.17919921875 
[2025-02-06 11:36:56 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 2 loss:0.295732706785202 norm:0.0015813034260645509 max memory_allocated 22923.17919921875 
[2025-02-06 11:37:30 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 3 loss:0.29239627718925476 norm:0.0015099546872079372 max memory_allocated 22923.17919921875 
[2025-02-06 11:38:04 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 4 loss:0.2913803160190582 norm:0.0014467560686171055 max memory_allocated 22923.17919921875 
[2025-02-06 11:38:39 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 5 loss:0.2908902168273926 norm:0.0013437477173283696 max memory_allocated 22923.17919921875 
[2025-02-06 11:39:13 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 6 loss:0.2905329167842865 norm:0.0013357197167351842 max memory_allocated 22923.17919921875 
[2025-02-06 11:39:47 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 7 loss:0.2902405560016632 norm:0.001298910123296082 max memory_allocated 22923.17919921875 
[2025-02-06 11:40:22 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 8 loss:0.290052592754364 norm:0.0012988564558327198 max memory_allocated 22923.17919921875 
[2025-02-06 11:40:56 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 9 loss:0.2898283302783966 norm:0.001260605058632791 max memory_allocated 22923.17919921875 
[2025-02-06 11:41:30 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 10 loss:0.2896887958049774 norm:0.0012694832403212786 max memory_allocated 22923.17919921875 
[2025-02-06 11:42:05 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 11 loss:0.28951364755630493 norm:0.0012786902952939272 max memory_allocated 22923.17919921875 
[2025-02-06 11:42:39 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 12 loss:0.28940489888191223 norm:0.0012785682920366526 max memory_allocated 22923.17919921875 
[2025-02-06 11:43:13 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 13 loss:0.28920942544937134 norm:0.0012162158964201808 max memory_allocated 22923.17919921875 
[2025-02-06 11:43:48 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 14 loss:0.28912004828453064 norm:0.0012467653723433614 max memory_allocated 22923.17919921875 
[2025-02-06 11:44:22 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 15 loss:0.28901705145835876 norm:0.0011999052949249744 max memory_allocated 22923.17919921875 
[2025-02-06 11:44:56 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 16 loss:0.2889240086078644 norm:0.0012073102407157421 max memory_allocated 22923.17919921875 
[2025-02-06 11:45:31 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 17 loss:0.28884977102279663 norm:0.0011885215062648058 max memory_allocated 22923.17919921875 
[2025-02-06 11:46:05 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 18 loss:0.288753479719162 norm:0.0011767905671149492 max memory_allocated 22923.17919921875 
[2025-02-06 11:46:39 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 19 loss:0.2886985242366791 norm:0.0011608662316575646 max memory_allocated 22923.17919921875 
[2025-02-06 11:46:48 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 25 ===
[2025-02-06 11:47:25 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 0 loss:0.36671289801597595 norm:0.002496760804206133 max memory_allocated 22924.85107421875 
[2025-02-06 11:48:00 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 1 loss:0.35265010595321655 norm:0.0020315113943070173 max memory_allocated 22924.85107421875 
[2025-02-06 11:48:34 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 2 loss:0.3401508331298828 norm:0.0018153565470129251 max memory_allocated 22924.85107421875 
[2025-02-06 11:49:08 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 3 loss:0.3363770842552185 norm:0.0017410704167559743 max memory_allocated 22924.85107421875 
[2025-02-06 11:49:43 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 4 loss:0.3353744149208069 norm:0.0016551563749089837 max memory_allocated 22924.85107421875 
[2025-02-06 11:50:17 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 5 loss:0.33489224314689636 norm:0.001623396878130734 max memory_allocated 22924.85107421875 
[2025-02-06 11:50:51 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 6 loss:0.33450639247894287 norm:0.0015489559154957533 max memory_allocated 22924.85107421875 
[2025-02-06 11:51:26 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 7 loss:0.3341864347457886 norm:0.0015299387741833925 max memory_allocated 22924.85107421875 
[2025-02-06 11:52:00 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 8 loss:0.3339186906814575 norm:0.0015414768131449819 max memory_allocated 22924.85107421875 
[2025-02-06 11:52:34 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 9 loss:0.33366602659225464 norm:0.0015284187393262982 max memory_allocated 22924.85107421875 
[2025-02-06 11:53:09 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 10 loss:0.3334418833255768 norm:0.0014882974792271852 max memory_allocated 22924.85107421875 
[2025-02-06 11:53:43 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 11 loss:0.3332681953907013 norm:0.0014707783702760935 max memory_allocated 22924.85107421875 
[2025-02-06 11:54:17 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 12 loss:0.3331649899482727 norm:0.0014916989021003246 max memory_allocated 22924.85107421875 
[2025-02-06 11:54:51 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 13 loss:0.3330478072166443 norm:0.0014623668976128101 max memory_allocated 22924.85107421875 
[2025-02-06 11:55:26 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 14 loss:0.3329043686389923 norm:0.0014369686832651496 max memory_allocated 22924.85107421875 
[2025-02-06 11:56:00 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 15 loss:0.33281996846199036 norm:0.0014284231001511216 max memory_allocated 22924.85107421875 
[2025-02-06 11:56:34 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 16 loss:0.33272063732147217 norm:0.0014471050817519426 max memory_allocated 22924.85107421875 
[2025-02-06 11:57:08 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 17 loss:0.3326716125011444 norm:0.0014394375029951334 max memory_allocated 22924.85107421875 
[2025-02-06 11:57:43 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 18 loss:0.33259591460227966 norm:0.0014365996466949582 max memory_allocated 22924.85107421875 
[2025-02-06 11:58:17 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 19 loss:0.3325270414352417 norm:0.0014310964616015553 max memory_allocated 22924.85107421875 
[2025-02-06 11:58:27 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 26 ===
[2025-02-06 11:59:04 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 0 loss:0.4215591847896576 norm:0.006174793932586908 max memory_allocated 22926.52294921875 
[2025-02-06 11:59:38 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 1 loss:0.4036804139614105 norm:0.0034702946431934834 max memory_allocated 22926.52294921875 
[2025-02-06 12:00:12 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 2 loss:0.3892595171928406 norm:0.0024679445195943117 max memory_allocated 22926.52294921875 
[2025-02-06 12:00:46 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 3 loss:0.3848065733909607 norm:0.0020405850373208523 max memory_allocated 22926.52294921875 
[2025-02-06 12:01:21 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 4 loss:0.3834920823574066 norm:0.0018443261506035924 max memory_allocated 22926.52294921875 
[2025-02-06 12:01:55 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 5 loss:0.38281118869781494 norm:0.001679434790275991 max memory_allocated 22926.52294921875 
[2025-02-06 12:02:29 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 6 loss:0.3823133111000061 norm:0.001596231129951775 max memory_allocated 22926.52294921875 
[2025-02-06 12:03:04 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 7 loss:0.38186824321746826 norm:0.0015076290583238006 max memory_allocated 22926.52294921875 
[2025-02-06 12:03:38 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 8 loss:0.38146886229515076 norm:0.001517258700914681 max memory_allocated 22926.52294921875 
[2025-02-06 12:04:12 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 9 loss:0.38120150566101074 norm:0.001509959576651454 max memory_allocated 22926.52294921875 
[2025-02-06 12:04:47 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 10 loss:0.38097262382507324 norm:0.0014595509273931384 max memory_allocated 22926.52294921875 
[2025-02-06 12:05:21 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 11 loss:0.3807324171066284 norm:0.0014449884183704853 max memory_allocated 22926.52294921875 
[2025-02-06 12:05:55 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 12 loss:0.3805808424949646 norm:0.0014395853504538536 max memory_allocated 22926.52294921875 
[2025-02-06 12:06:30 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 13 loss:0.3804123103618622 norm:0.001449266797862947 max memory_allocated 22926.52294921875 
[2025-02-06 12:07:04 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 14 loss:0.38030174374580383 norm:0.0014615750405937433 max memory_allocated 22926.52294921875 
[2025-02-06 12:07:38 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 15 loss:0.3801538050174713 norm:0.001404744223691523 max memory_allocated 22926.52294921875 
[2025-02-06 12:08:13 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 16 loss:0.38006213307380676 norm:0.0014136898098513484 max memory_allocated 22926.52294921875 
[2025-02-06 12:08:47 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 17 loss:0.37995150685310364 norm:0.0014108081813901663 max memory_allocated 22926.52294921875 
[2025-02-06 12:09:21 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 18 loss:0.3798532485961914 norm:0.0014028707519173622 max memory_allocated 22926.52294921875 
[2025-02-06 12:09:56 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 19 loss:0.3797706961631775 norm:0.0014031024184077978 max memory_allocated 22926.52294921875 
[2025-02-06 12:10:05 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 27 ===
[2025-02-06 12:10:42 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 0 loss:0.46725401282310486 norm:0.00483635114505887 max memory_allocated 22928.19482421875 
[2025-02-06 12:11:17 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 1 loss:0.45058560371398926 norm:0.003677209373563528 max memory_allocated 22928.19482421875 
[2025-02-06 12:11:51 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 2 loss:0.43602803349494934 norm:0.0031138937920331955 max memory_allocated 22928.19482421875 
[2025-02-06 12:12:25 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 3 loss:0.43186405301094055 norm:0.002960704732686281 max memory_allocated 22928.19482421875 
[2025-02-06 12:12:59 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 4 loss:0.43074673414230347 norm:0.002823862712830305 max memory_allocated 22928.19482421875 
[2025-02-06 12:13:34 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 5 loss:0.430168092250824 norm:0.002711516572162509 max memory_allocated 22928.19482421875 
[2025-02-06 12:14:08 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 6 loss:0.42973825335502625 norm:0.002615439472720027 max memory_allocated 22928.19482421875 
[2025-02-06 12:14:42 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 7 loss:0.4293924570083618 norm:0.0025968076661229134 max memory_allocated 22928.19482421875 
[2025-02-06 12:15:16 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 8 loss:0.429117351770401 norm:0.0026287678629159927 max memory_allocated 22928.19482421875 
[2025-02-06 12:15:51 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 9 loss:0.4289014935493469 norm:0.002596186939626932 max memory_allocated 22928.19482421875 
[2025-02-06 12:16:25 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 10 loss:0.428672730922699 norm:0.002576323924586177 max memory_allocated 22928.19482421875 
[2025-02-06 12:16:59 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 11 loss:0.4285176396369934 norm:0.0024955207481980324 max memory_allocated 22928.19482421875 
[2025-02-06 12:17:33 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 12 loss:0.4283790588378906 norm:0.002671724185347557 max memory_allocated 22928.19482421875 
[2025-02-06 12:18:08 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 13 loss:0.42824044823646545 norm:0.0025312171783298254 max memory_allocated 22928.19482421875 
[2025-02-06 12:18:42 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 14 loss:0.42811456322669983 norm:0.002619729842990637 max memory_allocated 22928.19482421875 
[2025-02-06 12:19:16 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 15 loss:0.42799627780914307 norm:0.002575524616986513 max memory_allocated 22928.19482421875 
[2025-02-06 12:19:50 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 16 loss:0.4278900623321533 norm:0.002648749388754368 max memory_allocated 22928.19482421875 
[2025-02-06 12:20:25 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 17 loss:0.4278242588043213 norm:0.002577942330390215 max memory_allocated 22928.19482421875 
[2025-02-06 12:20:59 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 18 loss:0.4277588129043579 norm:0.0026293937116861343 max memory_allocated 22928.19482421875 
[2025-02-06 12:21:34 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 19 loss:0.4276544451713562 norm:0.0024988281074911356 max memory_allocated 22928.19482421875 
[2025-02-06 12:21:43 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 28 ===
[2025-02-06 12:21:46 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-06 12:22:20 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 0 loss:0.5378039479255676 norm:0.013721713796257973 max memory_allocated 22929.98193359375 
[2025-02-06 12:22:54 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 1 loss:0.5188334584236145 norm:0.011708749458193779 max memory_allocated 22929.98193359375 
[2025-02-06 12:23:29 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 2 loss:0.5024234652519226 norm:0.008637424558401108 max memory_allocated 22929.98193359375 
[2025-02-06 12:24:03 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 3 loss:0.49766841530799866 norm:0.007668728940188885 max memory_allocated 22929.98193359375 
[2025-02-06 12:24:38 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 4 loss:0.4963398575782776 norm:0.006781409028917551 max memory_allocated 22929.98193359375 
[2025-02-06 12:25:12 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 5 loss:0.49543604254722595 norm:0.006117404904216528 max memory_allocated 22929.98193359375 
[2025-02-06 12:25:47 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 6 loss:0.49495765566825867 norm:0.005610448308289051 max memory_allocated 22929.98193359375 
[2025-02-06 12:26:21 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 7 loss:0.494612455368042 norm:0.005564779508858919 max memory_allocated 22929.98193359375 
[2025-02-06 12:26:55 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 8 loss:0.4943159818649292 norm:0.005488451104611158 max memory_allocated 22929.98193359375 
[2025-02-06 12:27:30 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 9 loss:0.49393922090530396 norm:0.005187343340367079 max memory_allocated 22929.98193359375 
[2025-02-06 12:28:04 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 10 loss:0.4936006963253021 norm:0.004908622242510319 max memory_allocated 22929.98193359375 
[2025-02-06 12:28:39 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 11 loss:0.49332642555236816 norm:0.004651240538805723 max memory_allocated 22929.98193359375 
[2025-02-06 12:29:13 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 12 loss:0.49309536814689636 norm:0.00455440254881978 max memory_allocated 22929.98193359375 
[2025-02-06 12:29:47 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 13 loss:0.49304017424583435 norm:0.0045951297506690025 max memory_allocated 22929.98193359375 
[2025-02-06 12:30:22 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 14 loss:0.49292412400245667 norm:0.004495703615248203 max memory_allocated 22929.98193359375 
[2025-02-06 12:30:56 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 15 loss:0.492765873670578 norm:0.0043857404962182045 max memory_allocated 22929.98193359375 
[2025-02-06 12:31:31 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 16 loss:0.4926196336746216 norm:0.0043218666687607765 max memory_allocated 22929.98193359375 
[2025-02-06 12:32:05 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 17 loss:0.4925197958946228 norm:0.004262621980160475 max memory_allocated 22929.98193359375 
[2025-02-06 12:32:40 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 18 loss:0.49245285987854004 norm:0.004258572123944759 max memory_allocated 22929.98193359375 
[2025-02-06 12:33:14 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 19 loss:0.4922843873500824 norm:0.0041646808385849 max memory_allocated 22929.98193359375 
[2025-02-06 12:33:23 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 29 ===
[2025-02-06 12:33:26 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-06 12:34:01 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 0 loss:0.6229354739189148 norm:0.015235936269164085 max memory_allocated 22931.65380859375 
[2025-02-06 12:34:35 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 1 loss:0.6005592942237854 norm:0.01125783659517765 max memory_allocated 22931.65380859375 
[2025-02-06 12:35:09 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 2 loss:0.5821350812911987 norm:0.008621416985988617 max memory_allocated 22931.65380859375 
[2025-02-06 12:35:44 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 3 loss:0.5771757960319519 norm:0.007511863484978676 max memory_allocated 22931.65380859375 
[2025-02-06 12:36:18 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 4 loss:0.5756409764289856 norm:0.006464568432420492 max memory_allocated 22931.65380859375 
[2025-02-06 12:36:53 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 5 loss:0.574704110622406 norm:0.0056778923608362675 max memory_allocated 22931.65380859375 
[2025-02-06 12:37:27 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 6 loss:0.5741071105003357 norm:0.005294385366141796 max memory_allocated 22931.65380859375 
[2025-02-06 12:38:02 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 7 loss:0.5736774802207947 norm:0.005079158116132021 max memory_allocated 22931.65380859375 
[2025-02-06 12:38:36 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 8 loss:0.5732706189155579 norm:0.004878298845142126 max memory_allocated 22931.65380859375 
[2025-02-06 12:39:10 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 9 loss:0.5730557441711426 norm:0.004791886080056429 max memory_allocated 22931.65380859375 
[2025-02-06 12:39:44 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 10 loss:0.5727554559707642 norm:0.004833944607526064 max memory_allocated 22931.65380859375 
[2025-02-06 12:40:19 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 11 loss:0.5724976658821106 norm:0.004555352032184601 max memory_allocated 22931.65380859375 
[2025-02-06 12:40:54 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 12 loss:0.5721762776374817 norm:0.00455693993717432 max memory_allocated 22931.65380859375 
[2025-02-06 12:41:28 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 13 loss:0.5720392465591431 norm:0.004454997833818197 max memory_allocated 22931.65380859375 
[2025-02-06 12:42:03 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 14 loss:0.571811318397522 norm:0.004321256652474403 max memory_allocated 22931.65380859375 
[2025-02-06 12:42:37 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 15 loss:0.5717301368713379 norm:0.004251100122928619 max memory_allocated 22931.65380859375 
[2025-02-06 12:43:11 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 16 loss:0.571599543094635 norm:0.004284434020519257 max memory_allocated 22931.65380859375 
[2025-02-06 12:43:46 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 17 loss:0.5714719295501709 norm:0.0041942475363612175 max memory_allocated 22931.65380859375 
[2025-02-06 12:44:20 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 18 loss:0.571412980556488 norm:0.004205605946481228 max memory_allocated 22931.65380859375 
[2025-02-06 12:44:55 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 19 loss:0.571414053440094 norm:0.004241563845425844 max memory_allocated 22931.65380859375 
[2025-02-06 12:45:04 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 30 ===
[2025-02-06 12:45:07 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-06 12:45:41 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 0 loss:0.8350460529327393 norm:0.03213385492563248 max memory_allocated 22933.32568359375 
[2025-02-06 12:46:16 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 1 loss:0.779504656791687 norm:0.019945340231060982 max memory_allocated 22933.32568359375 
[2025-02-06 12:46:50 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 2 loss:0.7419400215148926 norm:0.016689220443367958 max memory_allocated 22933.32568359375 
[2025-02-06 12:47:24 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 3 loss:0.7333501577377319 norm:0.018420448526740074 max memory_allocated 22933.32568359375 
[2025-02-06 12:47:59 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 4 loss:0.7300257682800293 norm:0.01983351819217205 max memory_allocated 22933.32568359375 
[2025-02-06 12:48:33 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 5 loss:0.7272626757621765 norm:0.020544828847050667 max memory_allocated 22933.32568359375 
[2025-02-06 12:49:08 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 6 loss:0.7251464128494263 norm:0.019560854882001877 max memory_allocated 22933.32568359375 
[2025-02-06 12:49:42 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 7 loss:0.7239023447036743 norm:0.01761282980442047 max memory_allocated 22933.32568359375 
[2025-02-06 12:50:16 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 8 loss:0.7234725952148438 norm:0.01736467145383358 max memory_allocated 22933.32568359375 
[2025-02-06 12:50:51 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 9 loss:0.7231263518333435 norm:0.01744079403579235 max memory_allocated 22933.32568359375 
[2025-02-06 12:51:25 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 10 loss:0.7222676277160645 norm:0.01793220080435276 max memory_allocated 22933.32568359375 
[2025-02-06 12:51:59 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 11 loss:0.7221803069114685 norm:0.017813628539443016 max memory_allocated 22933.32568359375 
[2025-02-06 12:52:34 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 12 loss:0.7216307520866394 norm:0.018674470484256744 max memory_allocated 22933.32568359375 
[2025-02-06 12:53:08 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 13 loss:0.7212204933166504 norm:0.018128281459212303 max memory_allocated 22933.32568359375 
[2025-02-06 12:53:42 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 14 loss:0.7209694385528564 norm:0.018526429310441017 max memory_allocated 22933.32568359375 
[2025-02-06 12:54:17 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 15 loss:0.7206469774246216 norm:0.018011042848229408 max memory_allocated 22933.32568359375 
[2025-02-06 12:54:51 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 16 loss:0.7212944030761719 norm:0.018587786704301834 max memory_allocated 22933.32568359375 
[2025-02-06 12:55:25 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 17 loss:0.7207355499267578 norm:0.018353590741753578 max memory_allocated 22933.32568359375 
[2025-02-06 12:56:00 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 18 loss:0.720388650894165 norm:0.0178801529109478 max memory_allocated 22933.32568359375 
[2025-02-06 12:56:34 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 19 loss:0.7202451825141907 norm:0.017607493326067924 max memory_allocated 22933.32568359375 
[2025-02-06 12:56:43 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 31 ===
[2025-02-06 12:56:46 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-06 12:57:21 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 0 loss:1.4956661462783813 norm:0.10133303701877594 max memory_allocated 22934.99755859375 
[2025-02-06 12:57:55 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 1 loss:1.3761638402938843 norm:0.07287362217903137 max memory_allocated 22934.99755859375 
[2025-02-06 12:58:30 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 2 loss:1.2931941747665405 norm:0.054009050130844116 max memory_allocated 22934.99755859375 
[2025-02-06 12:59:04 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 3 loss:1.2679065465927124 norm:0.05417630821466446 max memory_allocated 22934.99755859375 
[2025-02-06 12:59:38 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 4 loss:1.2563248872756958 norm:0.05202396959066391 max memory_allocated 22934.99755859375 
[2025-02-06 13:00:13 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 5 loss:1.248104214668274 norm:0.05093744024634361 max memory_allocated 22934.99755859375 
[2025-02-06 13:00:47 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 6 loss:1.2416458129882812 norm:0.050673436373472214 max memory_allocated 22934.99755859375 
[2025-02-06 13:01:21 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 7 loss:1.2373770475387573 norm:0.04988512769341469 max memory_allocated 22934.99755859375 
[2025-02-06 13:01:56 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 8 loss:1.2331345081329346 norm:0.047213587909936905 max memory_allocated 22934.99755859375 
[2025-02-06 13:02:30 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 9 loss:1.2301126718521118 norm:0.044792670756578445 max memory_allocated 22934.99755859375 
[2025-02-06 13:03:05 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 10 loss:1.2278265953063965 norm:0.044764839112758636 max memory_allocated 22934.99755859375 
[2025-02-06 13:03:39 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 11 loss:1.225515604019165 norm:0.044771529734134674 max memory_allocated 22934.99755859375 
[2025-02-06 13:04:13 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 12 loss:1.2246031761169434 norm:0.046296317130327225 max memory_allocated 22934.99755859375 
[2025-02-06 13:04:48 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 13 loss:1.2220393419265747 norm:0.045477475970983505 max memory_allocated 22934.99755859375 
[2025-02-06 13:05:22 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 14 loss:1.2217166423797607 norm:0.04564949870109558 max memory_allocated 22934.99755859375 
[2025-02-06 13:05:57 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 15 loss:1.2213696241378784 norm:0.0448116734623909 max memory_allocated 22934.99755859375 
[2025-02-06 13:06:31 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 16 loss:1.2214184999465942 norm:0.046819932758808136 max memory_allocated 22934.99755859375 
[2025-02-06 13:07:06 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 17 loss:1.2219444513320923 norm:0.046285923570394516 max memory_allocated 22934.99755859375 
[2025-02-06 13:07:40 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 18 loss:1.2193900346755981 norm:0.0430433452129364 max memory_allocated 22934.99755859375 
[2025-02-06 13:08:15 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 19 loss:1.2209078073501587 norm:0.04718061909079552 max memory_allocated 22934.99755859375 
[2025-02-06 13:08:24 root] (main_calib_config.py 366): INFO 22360.35723233223
[2025-02-06 13:08:56 root] (main_calib_config.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-02-06 13:10:13 root] (main_calib_config.py 159): INFO wikitext2 : 6.001820087432861
[2025-02-06 13:10:13 root] (main_calib_config.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-02-06 13:12:12 root] (main_calib_config.py 159): INFO c4 : 7.555294036865234
[2025-02-06 14:24:18 root] (main_calib_config.py 170): INFO {'wikitext2': 6.001820087432861, 'c4': 7.555294036865234, 'results': {'winogrande': {'acc': 0.6535122336227308, 'acc_stderr': 0.013373773411685651}, 'hellaswag': {'acc': 0.5445130452101175, 'acc_stderr': 0.004969968458256171, 'acc_norm': 0.7024497112129058, 'acc_norm_stderr': 0.004562462665505217}}, 'versions': {'winogrande': 0, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
