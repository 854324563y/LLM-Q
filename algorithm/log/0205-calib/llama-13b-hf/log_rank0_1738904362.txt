[2025-02-07 04:59:22 root] (main_calib_config.py 270): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log/0205-calib/llama-13b-hf', save_dir='./log/0205-calib/llama-13b-hf/save_dir', resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='./log/0205-mpq/llama-13b-hf/quant_map_llama-13b-hf.pkl')
[2025-02-07 04:59:36 root] (main_calib_config.py 337): INFO === start quantization ===
[2025-02-07 04:59:37 root] (main_calib_config.py 343): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-02-07 04:59:37 root] (abq_llm_calib_config.py 82): INFO Starting ...
[2025-02-07 04:59:37 root] (abq_llm_calib_config.py 89): INFO Loaded quant_map from ./log/0205-mpq/llama-13b-hf/quant_map_llama-13b-hf.pkl
[2025-02-07 04:59:40 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 0 ===
[2025-02-07 04:59:45 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 05:00:31 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 0 loss:0.01605958864092827 norm:0.009801873937249184 max memory_allocated 29713.09814453125 
[2025-02-07 05:01:18 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 1 loss:0.009453513659536839 norm:0.004967851564288139 max memory_allocated 29713.09814453125 
[2025-02-07 05:02:04 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 2 loss:0.0066170538775622845 norm:0.0032823148649185896 max memory_allocated 29713.09814453125 
[2025-02-07 05:02:50 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 3 loss:0.005773724522441626 norm:0.002529056742787361 max memory_allocated 29713.09814453125 
[2025-02-07 05:03:37 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 4 loss:0.005449662916362286 norm:0.0022517091128975153 max memory_allocated 29713.09814453125 
[2025-02-07 05:04:23 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 5 loss:0.005247075110673904 norm:0.001995778875425458 max memory_allocated 29713.09814453125 
[2025-02-07 05:05:09 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 6 loss:0.005054670386016369 norm:0.001767573761753738 max memory_allocated 29713.09814453125 
[2025-02-07 05:05:56 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 7 loss:0.004948112182319164 norm:0.0016095921164378524 max memory_allocated 29713.09814453125 
[2025-02-07 05:06:42 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 8 loss:0.004860798828303814 norm:0.0015087549109011889 max memory_allocated 29713.09814453125 
[2025-02-07 05:07:29 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 9 loss:0.004837755113840103 norm:0.0014721357729285955 max memory_allocated 29713.09814453125 
[2025-02-07 05:08:15 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 10 loss:0.004789960570633411 norm:0.0013533434830605984 max memory_allocated 29713.09814453125 
[2025-02-07 05:09:02 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 11 loss:0.00471409410238266 norm:0.001302957534790039 max memory_allocated 29713.09814453125 
[2025-02-07 05:09:48 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 12 loss:0.004690191708505154 norm:0.0012189511908218265 max memory_allocated 29713.09814453125 
[2025-02-07 05:10:35 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 13 loss:0.004678466357290745 norm:0.00117063382640481 max memory_allocated 29713.09814453125 
[2025-02-07 05:11:21 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 14 loss:0.004649223294109106 norm:0.0011198964202776551 max memory_allocated 29713.09814453125 
[2025-02-07 05:12:08 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 15 loss:0.004611405543982983 norm:0.001069297082722187 max memory_allocated 29713.09814453125 
[2025-02-07 05:12:54 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 16 loss:0.004591426812112331 norm:0.0010410089744254947 max memory_allocated 29713.09814453125 
[2025-02-07 05:13:40 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 17 loss:0.004587060771882534 norm:0.0010350177763029933 max memory_allocated 29713.09814453125 
[2025-02-07 05:14:27 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 18 loss:0.004560946952551603 norm:0.000984909012913704 max memory_allocated 29713.09814453125 
[2025-02-07 05:15:13 root] (abq_llm_calib_config.py 368): INFO layer 0 iter 19 loss:0.004579402040690184 norm:0.0009836864192038774 max memory_allocated 29713.09814453125 
[2025-02-07 05:15:27 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 1 ===
[2025-02-07 05:15:30 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 05:16:17 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 0 loss:0.026998113840818405 norm:0.012139590457081795 max memory_allocated 29713.09814453125 
[2025-02-07 05:17:04 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 1 loss:0.017024122178554535 norm:0.005841570906341076 max memory_allocated 29713.09814453125 
[2025-02-07 05:17:50 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 2 loss:0.013455549255013466 norm:0.003993852995336056 max memory_allocated 29713.09814453125 
[2025-02-07 05:18:37 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 3 loss:0.012366303242743015 norm:0.003154297824949026 max memory_allocated 29713.09814453125 
[2025-02-07 05:19:23 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 4 loss:0.011932588182389736 norm:0.002722801873460412 max memory_allocated 29713.09814453125 
[2025-02-07 05:20:10 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 5 loss:0.011703509837388992 norm:0.0025242071133106947 max memory_allocated 29713.09814453125 
[2025-02-07 05:20:56 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 6 loss:0.011520050466060638 norm:0.0023447161074727774 max memory_allocated 29713.09814453125 
[2025-02-07 05:21:43 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 7 loss:0.01136573776602745 norm:0.0021734964102506638 max memory_allocated 29713.09814453125 
[2025-02-07 05:22:30 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 8 loss:0.011218391358852386 norm:0.0020257956348359585 max memory_allocated 29713.09814453125 
[2025-02-07 05:23:16 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 9 loss:0.011097455397248268 norm:0.0018906798213720322 max memory_allocated 29713.09814453125 
[2025-02-07 05:24:03 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 10 loss:0.010987353511154652 norm:0.0017710392130538821 max memory_allocated 29713.09814453125 
[2025-02-07 05:24:49 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 11 loss:0.010910543613135815 norm:0.0016676430823281407 max memory_allocated 29713.09814453125 
[2025-02-07 05:25:36 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 12 loss:0.01082475483417511 norm:0.0015680664218962193 max memory_allocated 29713.09814453125 
[2025-02-07 05:26:22 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 13 loss:0.010761916637420654 norm:0.0014711391413584352 max memory_allocated 29713.09814453125 
[2025-02-07 05:27:09 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 14 loss:0.010705634020268917 norm:0.0013899635523557663 max memory_allocated 29713.09814453125 
[2025-02-07 05:27:55 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 15 loss:0.010664576664566994 norm:0.0012879765126854181 max memory_allocated 29713.09814453125 
[2025-02-07 05:28:42 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 16 loss:0.010629219934344292 norm:0.0011865070555359125 max memory_allocated 29713.09814453125 
[2025-02-07 05:29:29 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 17 loss:0.010610572062432766 norm:0.0011357140028849244 max memory_allocated 29713.09814453125 
[2025-02-07 05:30:15 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 18 loss:0.010609814897179604 norm:0.001150050899013877 max memory_allocated 29713.09814453125 
[2025-02-07 05:31:02 root] (abq_llm_calib_config.py 368): INFO layer 1 iter 19 loss:0.010639747604727745 norm:0.0011044811690226197 max memory_allocated 29713.09814453125 
[2025-02-07 05:31:15 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 2 ===
[2025-02-07 05:31:19 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 05:32:05 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 0 loss:0.03956931456923485 norm:0.010036425665020943 max memory_allocated 29715.22314453125 
[2025-02-07 05:32:52 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 1 loss:0.030401315540075302 norm:0.008907875046133995 max memory_allocated 29715.22314453125 
[2025-02-07 05:33:39 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 2 loss:0.02709205634891987 norm:0.007895578630268574 max memory_allocated 29715.22314453125 
[2025-02-07 05:34:25 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 3 loss:0.02617502771317959 norm:0.006788161117583513 max memory_allocated 29715.22314453125 
[2025-02-07 05:35:12 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 4 loss:0.025222064927220345 norm:0.006299297325313091 max memory_allocated 29715.22314453125 
[2025-02-07 05:35:58 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 5 loss:0.024335360154509544 norm:0.005863267928361893 max memory_allocated 29715.22314453125 
[2025-02-07 05:36:45 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 6 loss:0.023687725886702538 norm:0.00570144085213542 max memory_allocated 29715.22314453125 
[2025-02-07 05:37:31 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 7 loss:0.023403029888868332 norm:0.005634513683617115 max memory_allocated 29715.22314453125 
[2025-02-07 05:38:18 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 8 loss:0.0229000523686409 norm:0.00561552494764328 max memory_allocated 29715.22314453125 
[2025-02-07 05:39:05 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 9 loss:0.022768206894397736 norm:0.005399111192673445 max memory_allocated 29715.22314453125 
[2025-02-07 05:39:51 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 10 loss:0.022442610934376717 norm:0.005075686611235142 max memory_allocated 29715.22314453125 
[2025-02-07 05:40:38 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 11 loss:0.02229858562350273 norm:0.004819575697183609 max memory_allocated 29715.22314453125 
[2025-02-07 05:41:24 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 12 loss:0.02252686396241188 norm:0.005112905986607075 max memory_allocated 29715.22314453125 
[2025-02-07 05:42:11 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 13 loss:0.022202806547284126 norm:0.004743903875350952 max memory_allocated 29715.22314453125 
[2025-02-07 05:42:58 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 14 loss:0.022228453308343887 norm:0.004745060577988625 max memory_allocated 29715.22314453125 
[2025-02-07 05:43:44 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 15 loss:0.022087013348937035 norm:0.004493731074035168 max memory_allocated 29715.22314453125 
[2025-02-07 05:44:31 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 16 loss:0.022355686873197556 norm:0.00497659295797348 max memory_allocated 29715.22314453125 
[2025-02-07 05:45:17 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 17 loss:0.021758483722805977 norm:0.004454467445611954 max memory_allocated 29715.22314453125 
[2025-02-07 05:46:04 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 18 loss:0.02186148799955845 norm:0.004318098071962595 max memory_allocated 29715.22314453125 
[2025-02-07 05:46:51 root] (abq_llm_calib_config.py 368): INFO layer 2 iter 19 loss:0.021793968975543976 norm:0.0041932612657547 max memory_allocated 29715.22314453125 
[2025-02-07 05:47:04 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 3 ===
[2025-02-07 05:47:54 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 0 loss:0.043846845626831055 norm:0.0027634240686893463 max memory_allocated 29719.14111328125 
[2025-02-07 05:48:41 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 1 loss:0.03554008901119232 norm:0.0016773735405877233 max memory_allocated 29719.14111328125 
[2025-02-07 05:49:27 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 2 loss:0.03109639883041382 norm:0.0013285442255437374 max memory_allocated 29719.14111328125 
[2025-02-07 05:50:14 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 3 loss:0.02973189391195774 norm:0.0012407174799591303 max memory_allocated 29719.14111328125 
[2025-02-07 05:51:00 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 4 loss:0.02908460982143879 norm:0.0012381216511130333 max memory_allocated 29719.14111328125 
[2025-02-07 05:51:46 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 5 loss:0.02856842614710331 norm:0.0011526336893439293 max memory_allocated 29719.14111328125 
[2025-02-07 05:52:33 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 6 loss:0.028222667053341866 norm:0.0011556869139894843 max memory_allocated 29719.14111328125 
[2025-02-07 05:53:19 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 7 loss:0.028052978217601776 norm:0.0011750180274248123 max memory_allocated 29719.14111328125 
[2025-02-07 05:54:06 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 8 loss:0.027960442006587982 norm:0.0011352861765772104 max memory_allocated 29719.14111328125 
[2025-02-07 05:54:52 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 9 loss:0.02790212444961071 norm:0.001156918704509735 max memory_allocated 29719.14111328125 
[2025-02-07 05:55:38 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 10 loss:0.02782340720295906 norm:0.001095262123271823 max memory_allocated 29719.14111328125 
[2025-02-07 05:56:25 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 11 loss:0.027799734845757484 norm:0.0011504868743941188 max memory_allocated 29719.14111328125 
[2025-02-07 05:57:11 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 12 loss:0.027789529412984848 norm:0.0011820802465081215 max memory_allocated 29719.14111328125 
[2025-02-07 05:57:58 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 13 loss:0.02775193564593792 norm:0.0011070712935179472 max memory_allocated 29719.14111328125 
[2025-02-07 05:58:44 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 14 loss:0.0277340579777956 norm:0.0011637991992756724 max memory_allocated 29719.14111328125 
[2025-02-07 05:59:30 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 15 loss:0.02773488312959671 norm:0.0012267502024769783 max memory_allocated 29719.14111328125 
[2025-02-07 06:00:17 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 16 loss:0.027691790834069252 norm:0.0011040911776944995 max memory_allocated 29719.14111328125 
[2025-02-07 06:01:03 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 17 loss:0.027671517804265022 norm:0.0011159743880853057 max memory_allocated 29719.14111328125 
[2025-02-07 06:01:50 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 18 loss:0.02764824591577053 norm:0.001099646557122469 max memory_allocated 29719.14111328125 
[2025-02-07 06:02:36 root] (abq_llm_calib_config.py 368): INFO layer 3 iter 19 loss:0.027652183547616005 norm:0.0011635804548859596 max memory_allocated 29719.14111328125 
[2025-02-07 06:02:50 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 4 ===
[2025-02-07 06:03:40 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 0 loss:0.05423232540488243 norm:0.003110045799985528 max memory_allocated 29721.20361328125 
[2025-02-07 06:04:26 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 1 loss:0.04527139663696289 norm:0.0017580671701580286 max memory_allocated 29721.20361328125 
[2025-02-07 06:05:12 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 2 loss:0.040301840752363205 norm:0.0015438759000971913 max memory_allocated 29721.20361328125 
[2025-02-07 06:05:59 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 3 loss:0.03850231319665909 norm:0.0013717911206185818 max memory_allocated 29721.20361328125 
[2025-02-07 06:06:45 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 4 loss:0.0375664122402668 norm:0.0013226818991824985 max memory_allocated 29721.20361328125 
[2025-02-07 06:07:32 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 5 loss:0.03697379678487778 norm:0.0013375645503401756 max memory_allocated 29721.20361328125 
[2025-02-07 06:08:18 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 6 loss:0.036681268364191055 norm:0.0013371198438107967 max memory_allocated 29721.20361328125 
[2025-02-07 06:09:05 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 7 loss:0.036529019474983215 norm:0.0013154479674994946 max memory_allocated 29721.20361328125 
[2025-02-07 06:09:51 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 8 loss:0.03642437607049942 norm:0.0012235387694090605 max memory_allocated 29721.20361328125 
[2025-02-07 06:10:37 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 9 loss:0.03639880195260048 norm:0.0013186000287532806 max memory_allocated 29721.20361328125 
[2025-02-07 06:11:24 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 10 loss:0.03632538020610809 norm:0.0012468105414882302 max memory_allocated 29721.20361328125 
[2025-02-07 06:12:10 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 11 loss:0.03634236380457878 norm:0.0013227295130491257 max memory_allocated 29721.20361328125 
[2025-02-07 06:12:57 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 12 loss:0.036308594048023224 norm:0.0012783778365701437 max memory_allocated 29721.20361328125 
[2025-02-07 06:13:43 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 13 loss:0.03623514622449875 norm:0.001254252390936017 max memory_allocated 29721.20361328125 
[2025-02-07 06:14:30 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 14 loss:0.03616752475500107 norm:0.0011881821556016803 max memory_allocated 29721.20361328125 
[2025-02-07 06:15:16 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 15 loss:0.03613978624343872 norm:0.0011998891131952405 max memory_allocated 29721.20361328125 
[2025-02-07 06:16:03 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 16 loss:0.03615345433354378 norm:0.0011832647724077106 max memory_allocated 29721.20361328125 
[2025-02-07 06:16:49 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 17 loss:0.0361381471157074 norm:0.0012388875475153327 max memory_allocated 29721.20361328125 
[2025-02-07 06:17:35 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 18 loss:0.03614445775747299 norm:0.0012124425265938044 max memory_allocated 29721.20361328125 
[2025-02-07 06:18:22 root] (abq_llm_calib_config.py 368): INFO layer 4 iter 19 loss:0.03611409664154053 norm:0.0011911119800060987 max memory_allocated 29721.20361328125 
[2025-02-07 06:18:35 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 5 ===
[2025-02-07 06:19:26 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 0 loss:0.06280363351106644 norm:0.004271028097718954 max memory_allocated 29723.26611328125 
[2025-02-07 06:20:12 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 1 loss:0.05169343575835228 norm:0.0023653507232666016 max memory_allocated 29723.26611328125 
[2025-02-07 06:20:58 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 2 loss:0.04575726389884949 norm:0.0019792080856859684 max memory_allocated 29723.26611328125 
[2025-02-07 06:21:45 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 3 loss:0.0436561182141304 norm:0.0017291739350184798 max memory_allocated 29723.26611328125 
[2025-02-07 06:22:31 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 4 loss:0.04260267689824104 norm:0.0015684252139180899 max memory_allocated 29723.26611328125 
[2025-02-07 06:23:18 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 5 loss:0.04197970777750015 norm:0.0015781433321535587 max memory_allocated 29723.26611328125 
[2025-02-07 06:24:04 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 6 loss:0.04163689166307449 norm:0.0013994668843224645 max memory_allocated 29723.26611328125 
[2025-02-07 06:24:51 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 7 loss:0.04146966338157654 norm:0.0014110979391261935 max memory_allocated 29723.26611328125 
[2025-02-07 06:25:37 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 8 loss:0.041390106081962585 norm:0.0014900399837642908 max memory_allocated 29723.26611328125 
[2025-02-07 06:26:23 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 9 loss:0.04131029546260834 norm:0.001394443679600954 max memory_allocated 29723.26611328125 
[2025-02-07 06:27:10 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 10 loss:0.041221264749765396 norm:0.001396794687025249 max memory_allocated 29723.26611328125 
[2025-02-07 06:27:56 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 11 loss:0.041168589144945145 norm:0.0013761816080659628 max memory_allocated 29723.26611328125 
[2025-02-07 06:28:43 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 12 loss:0.04111385717988014 norm:0.001430572709068656 max memory_allocated 29723.26611328125 
[2025-02-07 06:29:29 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 13 loss:0.04112083837389946 norm:0.0014859772054478526 max memory_allocated 29723.26611328125 
[2025-02-07 06:30:16 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 14 loss:0.041116226464509964 norm:0.0014506932348012924 max memory_allocated 29723.26611328125 
[2025-02-07 06:31:02 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 15 loss:0.041065867990255356 norm:0.001483271480537951 max memory_allocated 29723.26611328125 
[2025-02-07 06:31:49 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 16 loss:0.04105691239237785 norm:0.0014410980511456728 max memory_allocated 29723.26611328125 
[2025-02-07 06:32:35 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 17 loss:0.041037652641534805 norm:0.00152875785715878 max memory_allocated 29723.26611328125 
[2025-02-07 06:33:21 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 18 loss:0.041016899049282074 norm:0.00143237819429487 max memory_allocated 29723.26611328125 
[2025-02-07 06:34:08 root] (abq_llm_calib_config.py 368): INFO layer 5 iter 19 loss:0.04101201146841049 norm:0.001410720287822187 max memory_allocated 29723.26611328125 
[2025-02-07 06:34:21 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 6 ===
[2025-02-07 06:35:12 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 0 loss:0.07846742123365402 norm:0.00346866762265563 max memory_allocated 29725.32861328125 
[2025-02-07 06:35:58 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 1 loss:0.06548964977264404 norm:0.0021321068052202463 max memory_allocated 29725.32861328125 
[2025-02-07 06:36:44 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 2 loss:0.057515811175107956 norm:0.001966054318472743 max memory_allocated 29725.32861328125 
[2025-02-07 06:37:31 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 3 loss:0.05455575883388519 norm:0.001722971210256219 max memory_allocated 29725.32861328125 
[2025-02-07 06:38:17 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 4 loss:0.05311763286590576 norm:0.0016299423296004534 max memory_allocated 29725.32861328125 
[2025-02-07 06:39:04 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 5 loss:0.05236310884356499 norm:0.0016000285977497697 max memory_allocated 29725.32861328125 
[2025-02-07 06:39:50 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 6 loss:0.051848847419023514 norm:0.0015429885825142264 max memory_allocated 29725.32861328125 
[2025-02-07 06:40:36 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 7 loss:0.05163656175136566 norm:0.0014949055621400476 max memory_allocated 29725.32861328125 
[2025-02-07 06:41:23 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 8 loss:0.05130279064178467 norm:0.001443865243345499 max memory_allocated 29725.32861328125 
[2025-02-07 06:42:09 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 9 loss:0.05112501233816147 norm:0.001415422186255455 max memory_allocated 29725.32861328125 
[2025-02-07 06:42:56 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 10 loss:0.05100250989198685 norm:0.0014490194153040648 max memory_allocated 29725.32861328125 
[2025-02-07 06:43:42 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 11 loss:0.05094650015234947 norm:0.0014534267829731107 max memory_allocated 29725.32861328125 
[2025-02-07 06:44:28 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 12 loss:0.05078232288360596 norm:0.0013548003043979406 max memory_allocated 29725.32861328125 
[2025-02-07 06:45:15 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 13 loss:0.05067690834403038 norm:0.0013126051053404808 max memory_allocated 29725.32861328125 
[2025-02-07 06:46:01 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 14 loss:0.05059346184134483 norm:0.001290242886170745 max memory_allocated 29725.32861328125 
[2025-02-07 06:46:48 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 15 loss:0.050635453313589096 norm:0.0013527900446206331 max memory_allocated 29725.32861328125 
[2025-02-07 06:47:34 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 16 loss:0.05058933421969414 norm:0.0013522135559469461 max memory_allocated 29725.32861328125 
[2025-02-07 06:48:21 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 17 loss:0.05063539370894432 norm:0.0012891311198472977 max memory_allocated 29725.32861328125 
[2025-02-07 06:49:07 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 18 loss:0.050648316740989685 norm:0.0013158652000129223 max memory_allocated 29725.32861328125 
[2025-02-07 06:49:54 root] (abq_llm_calib_config.py 368): INFO layer 6 iter 19 loss:0.05066424608230591 norm:0.0012887641787528992 max memory_allocated 29725.32861328125 
[2025-02-07 06:50:07 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 7 ===
[2025-02-07 06:50:57 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 0 loss:0.07528756558895111 norm:0.003741434309631586 max memory_allocated 29727.39111328125 
[2025-02-07 06:51:44 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 1 loss:0.06584791839122772 norm:0.002378603210672736 max memory_allocated 29727.39111328125 
[2025-02-07 06:52:30 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 2 loss:0.05987762659788132 norm:0.0020342268981039524 max memory_allocated 29727.39111328125 
[2025-02-07 06:53:17 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 3 loss:0.05784290283918381 norm:0.0018360181711614132 max memory_allocated 29727.39111328125 
[2025-02-07 06:54:03 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 4 loss:0.056932784616947174 norm:0.0016687324969097972 max memory_allocated 29727.39111328125 
[2025-02-07 06:54:49 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 5 loss:0.056375958025455475 norm:0.0016569587169215083 max memory_allocated 29727.39111328125 
[2025-02-07 06:55:36 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 6 loss:0.05603417754173279 norm:0.0015993796987459064 max memory_allocated 29727.39111328125 
[2025-02-07 06:56:22 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 7 loss:0.05584222078323364 norm:0.00164839718490839 max memory_allocated 29727.39111328125 
[2025-02-07 06:57:09 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 8 loss:0.05575012043118477 norm:0.0016234710346907377 max memory_allocated 29727.39111328125 
[2025-02-07 06:57:55 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 9 loss:0.055625855922698975 norm:0.001522228354588151 max memory_allocated 29727.39111328125 
[2025-02-07 06:58:42 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 10 loss:0.05556540936231613 norm:0.0015707461861893535 max memory_allocated 29727.39111328125 
[2025-02-07 06:59:28 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 11 loss:0.055490508675575256 norm:0.0014833189779892564 max memory_allocated 29727.39111328125 
[2025-02-07 07:00:14 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 12 loss:0.05545460060238838 norm:0.0015188453253358603 max memory_allocated 29727.39111328125 
[2025-02-07 07:01:01 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 13 loss:0.05540851503610611 norm:0.0015468052588403225 max memory_allocated 29727.39111328125 
[2025-02-07 07:01:47 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 14 loss:0.05540398508310318 norm:0.0014814571477472782 max memory_allocated 29727.39111328125 
[2025-02-07 07:02:34 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 15 loss:0.05540597438812256 norm:0.001585223013535142 max memory_allocated 29727.39111328125 
[2025-02-07 07:03:20 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 16 loss:0.05537186563014984 norm:0.001459890161640942 max memory_allocated 29727.39111328125 
[2025-02-07 07:04:07 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 17 loss:0.05533940717577934 norm:0.0014688362134620547 max memory_allocated 29727.39111328125 
[2025-02-07 07:04:53 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 18 loss:0.05535230413079262 norm:0.0016151105519384146 max memory_allocated 29727.39111328125 
[2025-02-07 07:05:39 root] (abq_llm_calib_config.py 368): INFO layer 7 iter 19 loss:0.05532794073224068 norm:0.0015361264813691378 max memory_allocated 29727.39111328125 
[2025-02-07 07:05:53 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 8 ===
[2025-02-07 07:06:43 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 0 loss:0.08041080087423325 norm:0.0035682441666722298 max memory_allocated 29729.45361328125 
[2025-02-07 07:07:30 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 1 loss:0.07077670097351074 norm:0.0018359895329922438 max memory_allocated 29729.45361328125 
[2025-02-07 07:08:16 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 2 loss:0.06519113481044769 norm:0.0015194168081507087 max memory_allocated 29729.45361328125 
[2025-02-07 07:09:03 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 3 loss:0.0631386861205101 norm:0.0013876435114070773 max memory_allocated 29729.45361328125 
[2025-02-07 07:09:49 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 4 loss:0.0621037520468235 norm:0.0012665565591305494 max memory_allocated 29729.45361328125 
[2025-02-07 07:10:35 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 5 loss:0.061552226543426514 norm:0.0013487741816788912 max memory_allocated 29729.45361328125 
[2025-02-07 07:11:22 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 6 loss:0.061127208173274994 norm:0.0012284343829378486 max memory_allocated 29729.45361328125 
[2025-02-07 07:12:08 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 7 loss:0.06091567873954773 norm:0.0012248442508280277 max memory_allocated 29729.45361328125 
[2025-02-07 07:12:55 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 8 loss:0.06077306717634201 norm:0.0012213424779474735 max memory_allocated 29729.45361328125 
[2025-02-07 07:13:41 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 9 loss:0.06066914647817612 norm:0.0011636213166639209 max memory_allocated 29729.45361328125 
[2025-02-07 07:14:28 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 10 loss:0.06065221130847931 norm:0.00127073482144624 max memory_allocated 29729.45361328125 
[2025-02-07 07:15:14 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 11 loss:0.060562968254089355 norm:0.0011804357636719942 max memory_allocated 29729.45361328125 
[2025-02-07 07:16:01 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 12 loss:0.060515180230140686 norm:0.0012319297529757023 max memory_allocated 29729.45361328125 
[2025-02-07 07:16:47 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 13 loss:0.060489438474178314 norm:0.0011896847281605005 max memory_allocated 29729.45361328125 
[2025-02-07 07:17:33 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 14 loss:0.060473643243312836 norm:0.001211119582876563 max memory_allocated 29729.45361328125 
[2025-02-07 07:18:20 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 15 loss:0.060456473380327225 norm:0.001242179423570633 max memory_allocated 29729.45361328125 
[2025-02-07 07:19:06 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 16 loss:0.06043866276741028 norm:0.0012763008708134294 max memory_allocated 29729.45361328125 
[2025-02-07 07:19:53 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 17 loss:0.06039918586611748 norm:0.0012355661019682884 max memory_allocated 29729.45361328125 
[2025-02-07 07:20:39 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 18 loss:0.06036277487874031 norm:0.001264417776837945 max memory_allocated 29729.45361328125 
[2025-02-07 07:21:26 root] (abq_llm_calib_config.py 368): INFO layer 8 iter 19 loss:0.06036214157938957 norm:0.0012081799795851111 max memory_allocated 29729.45361328125 
[2025-02-07 07:21:39 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 9 ===
[2025-02-07 07:22:30 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 0 loss:0.0849292129278183 norm:0.003144298680126667 max memory_allocated 29731.51611328125 
[2025-02-07 07:23:16 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 1 loss:0.07610486447811127 norm:0.001621051225811243 max memory_allocated 29731.51611328125 
[2025-02-07 07:24:02 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 2 loss:0.0705193430185318 norm:0.001439552870579064 max memory_allocated 29731.51611328125 
[2025-02-07 07:24:49 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 3 loss:0.06863689422607422 norm:0.00133910879958421 max memory_allocated 29731.51611328125 
[2025-02-07 07:25:35 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 4 loss:0.06771969050168991 norm:0.0012342011323198676 max memory_allocated 29731.51611328125 
[2025-02-07 07:26:22 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 5 loss:0.06718157231807709 norm:0.001242992002516985 max memory_allocated 29731.51611328125 
[2025-02-07 07:27:08 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 6 loss:0.06686189025640488 norm:0.0011903425911441445 max memory_allocated 29731.51611328125 
[2025-02-07 07:27:55 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 7 loss:0.06672414392232895 norm:0.0011651976965367794 max memory_allocated 29731.51611328125 
[2025-02-07 07:28:41 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 8 loss:0.06662847101688385 norm:0.0011281855404376984 max memory_allocated 29731.51611328125 
[2025-02-07 07:29:27 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 9 loss:0.06654170900583267 norm:0.001116522355005145 max memory_allocated 29731.51611328125 
[2025-02-07 07:30:14 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 10 loss:0.06644086539745331 norm:0.0011524998117238283 max memory_allocated 29731.51611328125 
[2025-02-07 07:31:00 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 11 loss:0.0663771703839302 norm:0.0011086981976404786 max memory_allocated 29731.51611328125 
[2025-02-07 07:31:47 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 12 loss:0.06634984165430069 norm:0.0011365622049197555 max memory_allocated 29731.51611328125 
[2025-02-07 07:32:33 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 13 loss:0.06631708145141602 norm:0.001164868357591331 max memory_allocated 29731.51611328125 
[2025-02-07 07:33:20 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 14 loss:0.06628134101629257 norm:0.0011295597068965435 max memory_allocated 29731.51611328125 
[2025-02-07 07:34:06 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 15 loss:0.06625331193208694 norm:0.001141542219556868 max memory_allocated 29731.51611328125 
[2025-02-07 07:34:53 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 16 loss:0.06625624746084213 norm:0.0011754996376112103 max memory_allocated 29731.51611328125 
[2025-02-07 07:35:39 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 17 loss:0.06625475734472275 norm:0.0012273882748559117 max memory_allocated 29731.51611328125 
[2025-02-07 07:36:25 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 18 loss:0.06623172760009766 norm:0.001187322661280632 max memory_allocated 29731.51611328125 
[2025-02-07 07:37:12 root] (abq_llm_calib_config.py 368): INFO layer 9 iter 19 loss:0.06621105968952179 norm:0.0011768166441470385 max memory_allocated 29731.51611328125 
[2025-02-07 07:37:25 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 10 ===
[2025-02-07 07:38:16 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 0 loss:0.0895121842622757 norm:0.0025124535895884037 max memory_allocated 29733.57861328125 
[2025-02-07 07:39:02 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 1 loss:0.08145411312580109 norm:0.0015184618532657623 max memory_allocated 29733.57861328125 
[2025-02-07 07:39:49 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 2 loss:0.07622775435447693 norm:0.0013337882701307535 max memory_allocated 29733.57861328125 
[2025-02-07 07:40:35 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 3 loss:0.07439356297254562 norm:0.0012478535063564777 max memory_allocated 29733.57861328125 
[2025-02-07 07:41:21 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 4 loss:0.07355788350105286 norm:0.001199189922772348 max memory_allocated 29733.57861328125 
[2025-02-07 07:42:08 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 5 loss:0.07299214601516724 norm:0.0011327533284202218 max memory_allocated 29733.57861328125 
[2025-02-07 07:42:54 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 6 loss:0.07267554849386215 norm:0.001111932098865509 max memory_allocated 29733.57861328125 
[2025-02-07 07:43:41 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 7 loss:0.07248233258724213 norm:0.0010795489652082324 max memory_allocated 29733.57861328125 
[2025-02-07 07:44:27 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 8 loss:0.07241582125425339 norm:0.00109595968388021 max memory_allocated 29733.57861328125 
[2025-02-07 07:45:13 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 9 loss:0.07232627272605896 norm:0.001082689967006445 max memory_allocated 29733.57861328125 
[2025-02-07 07:46:00 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 10 loss:0.07225052267313004 norm:0.0010562770767137408 max memory_allocated 29733.57861328125 
[2025-02-07 07:46:46 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 11 loss:0.07221321761608124 norm:0.001024642144329846 max memory_allocated 29733.57861328125 
[2025-02-07 07:47:33 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 12 loss:0.07218334823846817 norm:0.0010221974225714803 max memory_allocated 29733.57861328125 
[2025-02-07 07:48:19 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 13 loss:0.07217159867286682 norm:0.00104068114887923 max memory_allocated 29733.57861328125 
[2025-02-07 07:49:06 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 14 loss:0.0721532553434372 norm:0.0010141936363652349 max memory_allocated 29733.57861328125 
[2025-02-07 07:49:52 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 15 loss:0.07214854657649994 norm:0.0009995602304115891 max memory_allocated 29733.57861328125 
[2025-02-07 07:50:38 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 16 loss:0.0721396952867508 norm:0.0010225501609966159 max memory_allocated 29733.57861328125 
[2025-02-07 07:51:25 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 17 loss:0.07214300334453583 norm:0.0010533506283536553 max memory_allocated 29733.57861328125 
[2025-02-07 07:52:11 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 18 loss:0.07213158160448074 norm:0.001071543199941516 max memory_allocated 29733.57861328125 
[2025-02-07 07:52:58 root] (abq_llm_calib_config.py 368): INFO layer 10 iter 19 loss:0.07211842387914658 norm:0.0010839169844985008 max memory_allocated 29733.57861328125 
[2025-02-07 07:53:11 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 11 ===
[2025-02-07 07:54:02 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 0 loss:0.1011044830083847 norm:0.00214034179225564 max memory_allocated 29735.64111328125 
[2025-02-07 07:54:48 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 1 loss:0.09150917083024979 norm:0.0013987261336296797 max memory_allocated 29735.64111328125 
[2025-02-07 07:55:34 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 2 loss:0.0847993791103363 norm:0.001191216753795743 max memory_allocated 29735.64111328125 
[2025-02-07 07:56:21 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 3 loss:0.08232133835554123 norm:0.0010025789961218834 max memory_allocated 29735.64111328125 
[2025-02-07 07:57:07 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 4 loss:0.08128495514392853 norm:0.0009082327596843243 max memory_allocated 29735.64111328125 
[2025-02-07 07:57:54 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 5 loss:0.08062349259853363 norm:0.000870988704264164 max memory_allocated 29735.64111328125 
[2025-02-07 07:58:40 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 6 loss:0.08031077682971954 norm:0.0008603904279880226 max memory_allocated 29735.64111328125 
[2025-02-07 07:59:27 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 7 loss:0.08015035092830658 norm:0.0008510425104759634 max memory_allocated 29735.64111328125 
[2025-02-07 08:00:13 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 8 loss:0.08005616068840027 norm:0.0008389971335418522 max memory_allocated 29735.64111328125 
[2025-02-07 08:01:00 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 9 loss:0.07999208569526672 norm:0.000844326161313802 max memory_allocated 29735.64111328125 
[2025-02-07 08:01:46 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 10 loss:0.07994194328784943 norm:0.0008352604927495122 max memory_allocated 29735.64111328125 
[2025-02-07 08:02:33 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 11 loss:0.079893097281456 norm:0.000834929698612541 max memory_allocated 29735.64111328125 
[2025-02-07 08:03:19 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 12 loss:0.07984600961208344 norm:0.0008238572627305984 max memory_allocated 29735.64111328125 
[2025-02-07 08:04:05 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 13 loss:0.07982395589351654 norm:0.0008141538128256798 max memory_allocated 29735.64111328125 
[2025-02-07 08:04:52 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 14 loss:0.07979054003953934 norm:0.0008087076130323112 max memory_allocated 29735.64111328125 
[2025-02-07 08:05:38 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 15 loss:0.07977031916379929 norm:0.0007996905478648841 max memory_allocated 29735.64111328125 
[2025-02-07 08:06:25 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 16 loss:0.07975753396749496 norm:0.0008136203978210688 max memory_allocated 29735.64111328125 
[2025-02-07 08:07:11 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 17 loss:0.07974857836961746 norm:0.0008098221151158214 max memory_allocated 29735.64111328125 
[2025-02-07 08:07:58 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 18 loss:0.07972574234008789 norm:0.0008083879947662354 max memory_allocated 29735.64111328125 
[2025-02-07 08:08:44 root] (abq_llm_calib_config.py 368): INFO layer 11 iter 19 loss:0.07973358780145645 norm:0.0008249492384493351 max memory_allocated 29735.64111328125 
[2025-02-07 08:08:57 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 12 ===
[2025-02-07 08:09:48 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 0 loss:0.0972219929099083 norm:0.002102325204759836 max memory_allocated 29737.70361328125 
[2025-02-07 08:10:34 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 1 loss:0.09007197618484497 norm:0.0013306988403201103 max memory_allocated 29737.70361328125 
[2025-02-07 08:11:21 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 2 loss:0.08516891300678253 norm:0.001191050629131496 max memory_allocated 29737.70361328125 
[2025-02-07 08:12:07 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 3 loss:0.08372624963521957 norm:0.0011562518775463104 max memory_allocated 29737.70361328125 
[2025-02-07 08:12:53 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 4 loss:0.08287940919399261 norm:0.0011442399118095636 max memory_allocated 29737.70361328125 
[2025-02-07 08:13:40 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 5 loss:0.08230207860469818 norm:0.0011156190885230899 max memory_allocated 29737.70361328125 
[2025-02-07 08:14:26 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 6 loss:0.08200173825025558 norm:0.0010961825028061867 max memory_allocated 29737.70361328125 
[2025-02-07 08:15:13 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 7 loss:0.08180124312639236 norm:0.0010342723689973354 max memory_allocated 29737.70361328125 
[2025-02-07 08:15:59 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 8 loss:0.08169733732938766 norm:0.0010253635700792074 max memory_allocated 29737.70361328125 
[2025-02-07 08:16:46 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 9 loss:0.08161725103855133 norm:0.0010703152511268854 max memory_allocated 29737.70361328125 
[2025-02-07 08:17:32 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 10 loss:0.08156552165746689 norm:0.0010072337463498116 max memory_allocated 29737.70361328125 
[2025-02-07 08:18:18 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 11 loss:0.08147311955690384 norm:0.0010095433099195361 max memory_allocated 29737.70361328125 
[2025-02-07 08:19:05 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 12 loss:0.0814133733510971 norm:0.0009778565727174282 max memory_allocated 29737.70361328125 
[2025-02-07 08:19:51 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 13 loss:0.08138564974069595 norm:0.0009819521801546216 max memory_allocated 29737.70361328125 
[2025-02-07 08:20:38 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 14 loss:0.08134253323078156 norm:0.0009813971119001508 max memory_allocated 29737.70361328125 
[2025-02-07 08:21:24 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 15 loss:0.08132699877023697 norm:0.001005261787213385 max memory_allocated 29737.70361328125 
[2025-02-07 08:22:11 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 16 loss:0.08133064210414886 norm:0.0010249989572912455 max memory_allocated 29737.70361328125 
[2025-02-07 08:22:57 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 17 loss:0.08131326735019684 norm:0.0009775450453162193 max memory_allocated 29737.70361328125 
[2025-02-07 08:23:44 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 18 loss:0.08127966523170471 norm:0.0009739799425005913 max memory_allocated 29737.70361328125 
[2025-02-07 08:24:30 root] (abq_llm_calib_config.py 368): INFO layer 12 iter 19 loss:0.08125419914722443 norm:0.0009572631679475307 max memory_allocated 29737.70361328125 
[2025-02-07 08:24:44 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 13 ===
[2025-02-07 08:25:34 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 0 loss:0.10040724277496338 norm:0.002019583247601986 max memory_allocated 29739.76611328125 
[2025-02-07 08:26:20 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 1 loss:0.09352429211139679 norm:0.0014254739508032799 max memory_allocated 29739.76611328125 
[2025-02-07 08:27:07 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 2 loss:0.08841557800769806 norm:0.0012029047356918454 max memory_allocated 29739.76611328125 
[2025-02-07 08:27:53 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 3 loss:0.08695883303880692 norm:0.0011695739813148975 max memory_allocated 29739.76611328125 
[2025-02-07 08:28:40 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 4 loss:0.08603294938802719 norm:0.0011121575953438878 max memory_allocated 29739.76611328125 
[2025-02-07 08:29:26 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 5 loss:0.08542999625205994 norm:0.001065198564901948 max memory_allocated 29739.76611328125 
[2025-02-07 08:30:12 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 6 loss:0.08508969098329544 norm:0.0010376800782978535 max memory_allocated 29739.76611328125 
[2025-02-07 08:30:59 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 7 loss:0.08488866686820984 norm:0.0010343312751501799 max memory_allocated 29739.76611328125 
[2025-02-07 08:31:45 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 8 loss:0.08475533127784729 norm:0.0010134943295270205 max memory_allocated 29739.76611328125 
[2025-02-07 08:32:32 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 9 loss:0.08465692400932312 norm:0.0010074501624330878 max memory_allocated 29739.76611328125 
[2025-02-07 08:33:18 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 10 loss:0.0845886841416359 norm:0.0009989633690565825 max memory_allocated 29739.76611328125 
[2025-02-07 08:34:05 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 11 loss:0.08451391011476517 norm:0.0009982013143599033 max memory_allocated 29739.76611328125 
[2025-02-07 08:34:51 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 12 loss:0.08448982238769531 norm:0.0009789755567908287 max memory_allocated 29739.76611328125 
[2025-02-07 08:35:37 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 13 loss:0.0844256579875946 norm:0.0009716473869048059 max memory_allocated 29739.76611328125 
[2025-02-07 08:36:24 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 14 loss:0.08438332378864288 norm:0.0009855912066996098 max memory_allocated 29739.76611328125 
[2025-02-07 08:37:10 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 15 loss:0.08436369150876999 norm:0.0009423835435882211 max memory_allocated 29739.76611328125 
[2025-02-07 08:37:57 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 16 loss:0.08434803783893585 norm:0.0009495066478848457 max memory_allocated 29739.76611328125 
[2025-02-07 08:38:43 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 17 loss:0.08431702107191086 norm:0.000940654135774821 max memory_allocated 29739.76611328125 
[2025-02-07 08:39:30 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 18 loss:0.08429903537034988 norm:0.0009472183301113546 max memory_allocated 29739.76611328125 
[2025-02-07 08:40:16 root] (abq_llm_calib_config.py 368): INFO layer 13 iter 19 loss:0.08427997678518295 norm:0.000951638154219836 max memory_allocated 29739.76611328125 
[2025-02-07 08:40:30 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 14 ===
[2025-02-07 08:41:20 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 0 loss:0.10961924493312836 norm:0.0024399100802838802 max memory_allocated 29741.82861328125 
[2025-02-07 08:42:06 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 1 loss:0.10138696432113647 norm:0.0015530940145254135 max memory_allocated 29741.82861328125 
[2025-02-07 08:42:53 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 2 loss:0.0950416848063469 norm:0.001385083538480103 max memory_allocated 29741.82861328125 
[2025-02-07 08:43:39 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 3 loss:0.09302277863025665 norm:0.0013135932385921478 max memory_allocated 29741.82861328125 
[2025-02-07 08:44:26 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 4 loss:0.09202035516500473 norm:0.001192074385471642 max memory_allocated 29741.82861328125 
[2025-02-07 08:45:12 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 5 loss:0.09141422063112259 norm:0.0012116297148168087 max memory_allocated 29741.82861328125 
[2025-02-07 08:45:58 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 6 loss:0.09102793037891388 norm:0.001151102944277227 max memory_allocated 29741.82861328125 
[2025-02-07 08:46:45 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 7 loss:0.09084618091583252 norm:0.0011307611130177975 max memory_allocated 29741.82861328125 
[2025-02-07 08:47:31 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 8 loss:0.09067638218402863 norm:0.0011258877348154783 max memory_allocated 29741.82861328125 
[2025-02-07 08:48:18 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 9 loss:0.09057768434286118 norm:0.0011027470463886857 max memory_allocated 29741.82861328125 
[2025-02-07 08:49:04 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 10 loss:0.09050217270851135 norm:0.0011054303031414747 max memory_allocated 29741.82861328125 
[2025-02-07 08:49:51 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 11 loss:0.0904330164194107 norm:0.001115885330364108 max memory_allocated 29741.82861328125 
[2025-02-07 08:50:37 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 12 loss:0.09036806225776672 norm:0.001087423413991928 max memory_allocated 29741.82861328125 
[2025-02-07 08:51:23 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 13 loss:0.09029681235551834 norm:0.0010765311308205128 max memory_allocated 29741.82861328125 
[2025-02-07 08:52:10 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 14 loss:0.09023210406303406 norm:0.0010781895834952593 max memory_allocated 29741.82861328125 
[2025-02-07 08:52:56 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 15 loss:0.09023629873991013 norm:0.0010646081063896418 max memory_allocated 29741.82861328125 
[2025-02-07 08:53:43 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 16 loss:0.09021838009357452 norm:0.0010750415967777371 max memory_allocated 29741.82861328125 
[2025-02-07 08:54:29 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 17 loss:0.09016905725002289 norm:0.0010328397620469332 max memory_allocated 29741.82861328125 
[2025-02-07 08:55:16 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 18 loss:0.09016045182943344 norm:0.0010336266132071614 max memory_allocated 29741.82861328125 
[2025-02-07 08:56:02 root] (abq_llm_calib_config.py 368): INFO layer 14 iter 19 loss:0.09014413505792618 norm:0.0010460626799613237 max memory_allocated 29741.82861328125 
[2025-02-07 08:56:16 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 15 ===
[2025-02-07 08:57:06 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 0 loss:0.11533854156732559 norm:0.0025759581476449966 max memory_allocated 29743.89111328125 
[2025-02-07 08:57:52 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 1 loss:0.10781506448984146 norm:0.0016429629176855087 max memory_allocated 29743.89111328125 
[2025-02-07 08:58:39 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 2 loss:0.10220101475715637 norm:0.0015836720122024417 max memory_allocated 29743.89111328125 
[2025-02-07 08:59:25 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 3 loss:0.09996645152568817 norm:0.0014364431845024228 max memory_allocated 29743.89111328125 
[2025-02-07 09:00:11 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 4 loss:0.09875503182411194 norm:0.0013273591175675392 max memory_allocated 29743.89111328125 
[2025-02-07 09:00:58 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 5 loss:0.09803186357021332 norm:0.0012860808055847883 max memory_allocated 29743.89111328125 
[2025-02-07 09:01:44 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 6 loss:0.09765809029340744 norm:0.0012314709601923823 max memory_allocated 29743.89111328125 
[2025-02-07 09:02:31 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 7 loss:0.09746037423610687 norm:0.0011838267091661692 max memory_allocated 29743.89111328125 
[2025-02-07 09:03:17 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 8 loss:0.09730561077594757 norm:0.0011354780290275812 max memory_allocated 29743.89111328125 
[2025-02-07 09:04:04 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 9 loss:0.09722746163606644 norm:0.0011390954023227096 max memory_allocated 29743.89111328125 
[2025-02-07 09:04:50 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 10 loss:0.09716156125068665 norm:0.0011578096309676766 max memory_allocated 29743.89111328125 
[2025-02-07 09:05:36 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 11 loss:0.09708178043365479 norm:0.0011240519816055894 max memory_allocated 29743.89111328125 
[2025-02-07 09:06:23 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 12 loss:0.09704309701919556 norm:0.0011404494289308786 max memory_allocated 29743.89111328125 
[2025-02-07 09:07:09 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 13 loss:0.0969955176115036 norm:0.0011232533724978566 max memory_allocated 29743.89111328125 
[2025-02-07 09:07:56 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 14 loss:0.09694364666938782 norm:0.0010864132782444358 max memory_allocated 29743.89111328125 
[2025-02-07 09:08:42 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 15 loss:0.09691917151212692 norm:0.001129197422415018 max memory_allocated 29743.89111328125 
[2025-02-07 09:09:29 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 16 loss:0.09690286964178085 norm:0.0010906015522778034 max memory_allocated 29743.89111328125 
[2025-02-07 09:10:15 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 17 loss:0.09690150618553162 norm:0.0010969581780955195 max memory_allocated 29743.89111328125 
[2025-02-07 09:11:02 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 18 loss:0.09688477218151093 norm:0.0010774817783385515 max memory_allocated 29743.89111328125 
[2025-02-07 09:11:48 root] (abq_llm_calib_config.py 368): INFO layer 15 iter 19 loss:0.09687153249979019 norm:0.0011145941680297256 max memory_allocated 29743.89111328125 
[2025-02-07 09:12:02 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 16 ===
[2025-02-07 09:12:52 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 0 loss:0.11930277943611145 norm:0.0019505136879161 max memory_allocated 29745.95361328125 
[2025-02-07 09:13:38 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 1 loss:0.11257221549749374 norm:0.001350071164779365 max memory_allocated 29745.95361328125 
[2025-02-07 09:14:25 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 2 loss:0.1074397936463356 norm:0.0011699812021106482 max memory_allocated 29745.95361328125 
[2025-02-07 09:15:11 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 3 loss:0.10572218894958496 norm:0.0011102411663159728 max memory_allocated 29745.95361328125 
[2025-02-07 09:15:58 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 4 loss:0.10469400882720947 norm:0.0010653308127075434 max memory_allocated 29745.95361328125 
[2025-02-07 09:16:44 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 5 loss:0.10409107059240341 norm:0.001002762233838439 max memory_allocated 29745.95361328125 
[2025-02-07 09:17:31 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 6 loss:0.10377657413482666 norm:0.0009717255015857518 max memory_allocated 29745.95361328125 
[2025-02-07 09:18:17 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 7 loss:0.10362696647644043 norm:0.0009934380650520325 max memory_allocated 29745.95361328125 
[2025-02-07 09:19:04 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 8 loss:0.10352455824613571 norm:0.0009727076394483447 max memory_allocated 29745.95361328125 
[2025-02-07 09:19:50 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 9 loss:0.10345155000686646 norm:0.0009737707441672683 max memory_allocated 29745.95361328125 
[2025-02-07 09:20:37 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 10 loss:0.10338648408651352 norm:0.0009529856033623219 max memory_allocated 29745.95361328125 
[2025-02-07 09:21:23 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 11 loss:0.1033276692032814 norm:0.0009506181231699884 max memory_allocated 29745.95361328125 
[2025-02-07 09:22:10 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 12 loss:0.10326307266950607 norm:0.0009492452954873443 max memory_allocated 29745.95361328125 
[2025-02-07 09:22:56 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 13 loss:0.1031990572810173 norm:0.0009234881727024913 max memory_allocated 29745.95361328125 
[2025-02-07 09:23:43 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 14 loss:0.1031767874956131 norm:0.0009428763296455145 max memory_allocated 29745.95361328125 
[2025-02-07 09:24:29 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 15 loss:0.10314267128705978 norm:0.0009180073975585401 max memory_allocated 29745.95361328125 
[2025-02-07 09:25:16 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 16 loss:0.10310852527618408 norm:0.000916093064006418 max memory_allocated 29745.95361328125 
[2025-02-07 09:26:02 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 17 loss:0.10307760536670685 norm:0.0009003602899610996 max memory_allocated 29745.95361328125 
[2025-02-07 09:26:49 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 18 loss:0.10307106375694275 norm:0.0008954335353337228 max memory_allocated 29745.95361328125 
[2025-02-07 09:27:35 root] (abq_llm_calib_config.py 368): INFO layer 16 iter 19 loss:0.10306179523468018 norm:0.0008766514365561306 max memory_allocated 29745.95361328125 
[2025-02-07 09:27:49 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 17 ===
[2025-02-07 09:28:39 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 0 loss:0.12876459956169128 norm:0.0025069613475352526 max memory_allocated 29748.01611328125 
[2025-02-07 09:29:26 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 1 loss:0.12106673419475555 norm:0.0016280085546895862 max memory_allocated 29748.01611328125 
[2025-02-07 09:30:12 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 2 loss:0.11541052162647247 norm:0.001399422762915492 max memory_allocated 29748.01611328125 
[2025-02-07 09:30:58 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 3 loss:0.11378476023674011 norm:0.0012552794069051743 max memory_allocated 29748.01611328125 
[2025-02-07 09:31:45 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 4 loss:0.11270178109407425 norm:0.0011907124426215887 max memory_allocated 29748.01611328125 
[2025-02-07 09:32:31 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 5 loss:0.11206289380788803 norm:0.0011937761446461082 max memory_allocated 29748.01611328125 
[2025-02-07 09:33:18 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 6 loss:0.11173257231712341 norm:0.0011672410182654858 max memory_allocated 29748.01611328125 
[2025-02-07 09:34:04 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 7 loss:0.11151576042175293 norm:0.0011510960757732391 max memory_allocated 29748.01611328125 
[2025-02-07 09:34:51 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 8 loss:0.11139098554849625 norm:0.0011240789899602532 max memory_allocated 29748.01611328125 
[2025-02-07 09:35:37 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 9 loss:0.11127407103776932 norm:0.001103498274460435 max memory_allocated 29748.01611328125 
[2025-02-07 09:36:24 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 10 loss:0.1111605241894722 norm:0.0010656442027539015 max memory_allocated 29748.01611328125 
[2025-02-07 09:37:10 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 11 loss:0.11108709871768951 norm:0.0010564164258539677 max memory_allocated 29748.01611328125 
[2025-02-07 09:37:57 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 12 loss:0.11105936020612717 norm:0.0011101815616711974 max memory_allocated 29748.01611328125 
[2025-02-07 09:38:43 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 13 loss:0.11099953949451447 norm:0.0010632312623783946 max memory_allocated 29748.01611328125 
[2025-02-07 09:39:30 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 14 loss:0.11095419526100159 norm:0.001046974677592516 max memory_allocated 29748.01611328125 
[2025-02-07 09:40:16 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 15 loss:0.11091694980859756 norm:0.0010640328982844949 max memory_allocated 29748.01611328125 
[2025-02-07 09:41:03 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 16 loss:0.11089460551738739 norm:0.0010607463773339987 max memory_allocated 29748.01611328125 
[2025-02-07 09:41:49 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 17 loss:0.11085642874240875 norm:0.0010301502188667655 max memory_allocated 29748.01611328125 
[2025-02-07 09:42:36 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 18 loss:0.11081917583942413 norm:0.0010249435435980558 max memory_allocated 29748.01611328125 
[2025-02-07 09:43:22 root] (abq_llm_calib_config.py 368): INFO layer 17 iter 19 loss:0.11082100868225098 norm:0.0010392164113000035 max memory_allocated 29748.01611328125 
[2025-02-07 09:43:36 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 18 ===
[2025-02-07 09:44:26 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 0 loss:0.14557458460330963 norm:0.002648059045895934 max memory_allocated 29750.07861328125 
[2025-02-07 09:45:12 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 1 loss:0.1364639401435852 norm:0.0017565697198733687 max memory_allocated 29750.07861328125 
[2025-02-07 09:45:59 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 2 loss:0.129556342959404 norm:0.0015697806375101209 max memory_allocated 29750.07861328125 
[2025-02-07 09:46:45 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 3 loss:0.12715895473957062 norm:0.0013968065613880754 max memory_allocated 29750.07861328125 
[2025-02-07 09:47:32 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 4 loss:0.1258326768875122 norm:0.001378819695673883 max memory_allocated 29750.07861328125 
[2025-02-07 09:48:18 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 5 loss:0.12519477307796478 norm:0.0013032102724537253 max memory_allocated 29750.07861328125 
[2025-02-07 09:49:05 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 6 loss:0.1249023824930191 norm:0.001253235968761146 max memory_allocated 29750.07861328125 
[2025-02-07 09:49:51 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 7 loss:0.12470848858356476 norm:0.00120855204295367 max memory_allocated 29750.07861328125 
[2025-02-07 09:50:38 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 8 loss:0.12456659227609634 norm:0.0011900878744199872 max memory_allocated 29750.07861328125 
[2025-02-07 09:51:24 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 9 loss:0.12443198263645172 norm:0.0011939036194235086 max memory_allocated 29750.07861328125 
[2025-02-07 09:52:11 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 10 loss:0.1243402510881424 norm:0.001169209135696292 max memory_allocated 29750.07861328125 
[2025-02-07 09:52:57 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 11 loss:0.1242537647485733 norm:0.0011374364839866757 max memory_allocated 29750.07861328125 
[2025-02-07 09:53:44 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 12 loss:0.12418514490127563 norm:0.0011292097624391317 max memory_allocated 29750.07861328125 
[2025-02-07 09:54:30 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 13 loss:0.12412526458501816 norm:0.001136241015046835 max memory_allocated 29750.07861328125 
[2025-02-07 09:55:17 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 14 loss:0.12406791001558304 norm:0.0011474136263132095 max memory_allocated 29750.07861328125 
[2025-02-07 09:56:03 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 15 loss:0.12401625514030457 norm:0.0011230793315917253 max memory_allocated 29750.07861328125 
[2025-02-07 09:56:50 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 16 loss:0.12397721409797668 norm:0.0011475452920421958 max memory_allocated 29750.07861328125 
[2025-02-07 09:57:36 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 17 loss:0.12393569946289062 norm:0.0011445629643276334 max memory_allocated 29750.07861328125 
[2025-02-07 09:58:23 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 18 loss:0.12392757087945938 norm:0.0011450015008449554 max memory_allocated 29750.07861328125 
[2025-02-07 09:59:09 root] (abq_llm_calib_config.py 368): INFO layer 18 iter 19 loss:0.12388946861028671 norm:0.0011509384494274855 max memory_allocated 29750.07861328125 
[2025-02-07 09:59:23 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 19 ===
[2025-02-07 10:00:13 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 0 loss:0.15609435737133026 norm:0.001837054267525673 max memory_allocated 29752.14111328125 
[2025-02-07 10:01:00 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 1 loss:0.14814020693302155 norm:0.001455141231417656 max memory_allocated 29752.14111328125 
[2025-02-07 10:01:46 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 2 loss:0.1414615958929062 norm:0.0012946028728038073 max memory_allocated 29752.14111328125 
[2025-02-07 10:02:33 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 3 loss:0.13938093185424805 norm:0.0011946001322939992 max memory_allocated 29752.14111328125 
[2025-02-07 10:03:19 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 4 loss:0.13814836740493774 norm:0.0011284237261861563 max memory_allocated 29752.14111328125 
[2025-02-07 10:04:06 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 5 loss:0.13755816221237183 norm:0.0011178150307387114 max memory_allocated 29752.14111328125 
[2025-02-07 10:04:52 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 6 loss:0.13724589347839355 norm:0.0010512609733268619 max memory_allocated 29752.14111328125 
[2025-02-07 10:05:39 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 7 loss:0.13702142238616943 norm:0.0010460240300744772 max memory_allocated 29752.14111328125 
[2025-02-07 10:06:25 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 8 loss:0.13688595592975616 norm:0.001040588947944343 max memory_allocated 29752.14111328125 
[2025-02-07 10:07:12 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 9 loss:0.1367616057395935 norm:0.0009999793255701661 max memory_allocated 29752.14111328125 
[2025-02-07 10:07:58 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 10 loss:0.13667921721935272 norm:0.0009996832814067602 max memory_allocated 29752.14111328125 
[2025-02-07 10:08:45 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 11 loss:0.13663500547409058 norm:0.001011773245409131 max memory_allocated 29752.14111328125 
[2025-02-07 10:09:32 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 12 loss:0.13658159971237183 norm:0.0010027873795479536 max memory_allocated 29752.14111328125 
[2025-02-07 10:10:18 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 13 loss:0.13654790818691254 norm:0.0010150952730327845 max memory_allocated 29752.14111328125 
[2025-02-07 10:11:05 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 14 loss:0.13648948073387146 norm:0.001000374322757125 max memory_allocated 29752.14111328125 
[2025-02-07 10:11:51 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 15 loss:0.13644550740718842 norm:0.001011102576740086 max memory_allocated 29752.14111328125 
[2025-02-07 10:12:38 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 16 loss:0.1364143043756485 norm:0.0009881691075861454 max memory_allocated 29752.14111328125 
[2025-02-07 10:13:24 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 17 loss:0.1363832652568817 norm:0.0010142696555703878 max memory_allocated 29752.14111328125 
[2025-02-07 10:14:11 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 18 loss:0.1363450288772583 norm:0.001000067568384111 max memory_allocated 29752.14111328125 
[2025-02-07 10:14:57 root] (abq_llm_calib_config.py 368): INFO layer 19 iter 19 loss:0.136330708861351 norm:0.0009981285547837615 max memory_allocated 29752.14111328125 
[2025-02-07 10:15:11 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 20 ===
[2025-02-07 10:16:01 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 0 loss:0.17221105098724365 norm:0.0019718175753951073 max memory_allocated 29754.20361328125 
[2025-02-07 10:16:48 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 1 loss:0.16294580698013306 norm:0.0014024106785655022 max memory_allocated 29754.20361328125 
[2025-02-07 10:17:34 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 2 loss:0.15533368289470673 norm:0.0012963612098246813 max memory_allocated 29754.20361328125 
[2025-02-07 10:18:21 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 3 loss:0.15298475325107574 norm:0.0011887140572071075 max memory_allocated 29754.20361328125 
[2025-02-07 10:19:07 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 4 loss:0.1516520082950592 norm:0.0011341607896611094 max memory_allocated 29754.20361328125 
[2025-02-07 10:19:54 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 5 loss:0.15109555423259735 norm:0.0010944658424705267 max memory_allocated 29754.20361328125 
[2025-02-07 10:20:40 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 6 loss:0.15080101788043976 norm:0.0010751758236438036 max memory_allocated 29754.20361328125 
[2025-02-07 10:21:27 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 7 loss:0.15057781338691711 norm:0.0010366580681875348 max memory_allocated 29754.20361328125 
[2025-02-07 10:22:13 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 8 loss:0.15041467547416687 norm:0.001023898716084659 max memory_allocated 29754.20361328125 
[2025-02-07 10:23:00 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 9 loss:0.15027964115142822 norm:0.0009939164156094193 max memory_allocated 29754.20361328125 
[2025-02-07 10:23:46 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 10 loss:0.15018928050994873 norm:0.0009896744741126895 max memory_allocated 29754.20361328125 
[2025-02-07 10:24:33 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 11 loss:0.15007612109184265 norm:0.0009952111868187785 max memory_allocated 29754.20361328125 
[2025-02-07 10:25:19 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 12 loss:0.15002286434173584 norm:0.0009991079568862915 max memory_allocated 29754.20361328125 
[2025-02-07 10:26:06 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 13 loss:0.1499725580215454 norm:0.0009920891607180238 max memory_allocated 29754.20361328125 
[2025-02-07 10:26:52 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 14 loss:0.1499004364013672 norm:0.0009837232064455748 max memory_allocated 29754.20361328125 
[2025-02-07 10:27:39 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 15 loss:0.14984433352947235 norm:0.0009872692171484232 max memory_allocated 29754.20361328125 
[2025-02-07 10:28:26 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 16 loss:0.14982397854328156 norm:0.0009968281956389546 max memory_allocated 29754.20361328125 
[2025-02-07 10:29:12 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 17 loss:0.14977896213531494 norm:0.0010056516621261835 max memory_allocated 29754.20361328125 
[2025-02-07 10:29:59 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 18 loss:0.14972063899040222 norm:0.0009925924241542816 max memory_allocated 29754.20361328125 
[2025-02-07 10:30:45 root] (abq_llm_calib_config.py 368): INFO layer 20 iter 19 loss:0.14967714250087738 norm:0.0009903260506689548 max memory_allocated 29754.20361328125 
[2025-02-07 10:30:59 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 21 ===
[2025-02-07 10:31:49 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 0 loss:0.196254163980484 norm:0.00241770944558084 max memory_allocated 29756.26611328125 
[2025-02-07 10:32:36 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 1 loss:0.18501995503902435 norm:0.0016456887824460864 max memory_allocated 29756.26611328125 
[2025-02-07 10:33:22 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 2 loss:0.1760045886039734 norm:0.0013925802195444703 max memory_allocated 29756.26611328125 
[2025-02-07 10:34:09 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 3 loss:0.17318853735923767 norm:0.0012708032736554742 max memory_allocated 29756.26611328125 
[2025-02-07 10:34:55 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 4 loss:0.17176976799964905 norm:0.0012151409173384309 max memory_allocated 29756.26611328125 
[2025-02-07 10:35:42 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 5 loss:0.17120306193828583 norm:0.0011490065371617675 max memory_allocated 29756.26611328125 
[2025-02-07 10:36:28 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 6 loss:0.17090612649917603 norm:0.0011453967308625579 max memory_allocated 29756.26611328125 
[2025-02-07 10:37:15 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 7 loss:0.1706855446100235 norm:0.0010937524493783712 max memory_allocated 29756.26611328125 
[2025-02-07 10:38:01 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 8 loss:0.1705217808485031 norm:0.0010614317143335938 max memory_allocated 29756.26611328125 
[2025-02-07 10:38:48 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 9 loss:0.170356884598732 norm:0.001045833108946681 max memory_allocated 29756.26611328125 
[2025-02-07 10:39:35 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 10 loss:0.1702350229024887 norm:0.0010592773323878646 max memory_allocated 29756.26611328125 
[2025-02-07 10:40:21 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 11 loss:0.1701483428478241 norm:0.0010630954056978226 max memory_allocated 29756.26611328125 
[2025-02-07 10:41:08 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 12 loss:0.17005904018878937 norm:0.0010435325093567371 max memory_allocated 29756.26611328125 
[2025-02-07 10:41:54 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 13 loss:0.16997747123241425 norm:0.0010099641513079405 max memory_allocated 29756.26611328125 
[2025-02-07 10:42:41 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 14 loss:0.16988587379455566 norm:0.0010048466501757503 max memory_allocated 29756.26611328125 
[2025-02-07 10:43:27 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 15 loss:0.16983944177627563 norm:0.0009713477338664234 max memory_allocated 29756.26611328125 
[2025-02-07 10:44:14 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 16 loss:0.16978543996810913 norm:0.000967657077126205 max memory_allocated 29756.26611328125 
[2025-02-07 10:45:01 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 17 loss:0.16975127160549164 norm:0.0010088358540087938 max memory_allocated 29756.26611328125 
[2025-02-07 10:45:47 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 18 loss:0.1697319746017456 norm:0.00100363336969167 max memory_allocated 29756.26611328125 
[2025-02-07 10:46:34 root] (abq_llm_calib_config.py 368): INFO layer 21 iter 19 loss:0.16969621181488037 norm:0.0010098519269376993 max memory_allocated 29756.26611328125 
[2025-02-07 10:46:48 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 22 ===
[2025-02-07 10:47:38 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 0 loss:0.21964581310749054 norm:0.00267135351896286 max memory_allocated 29758.32861328125 
[2025-02-07 10:48:25 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 1 loss:0.2083289623260498 norm:0.0022595280315726995 max memory_allocated 29758.32861328125 
[2025-02-07 10:49:11 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 2 loss:0.1988793909549713 norm:0.0021308045834302902 max memory_allocated 29758.32861328125 
[2025-02-07 10:49:58 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 3 loss:0.19598892331123352 norm:0.0020312205888330936 max memory_allocated 29758.32861328125 
[2025-02-07 10:50:44 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 4 loss:0.19456131756305695 norm:0.0019073308212682605 max memory_allocated 29758.32861328125 
[2025-02-07 10:51:31 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 5 loss:0.19404208660125732 norm:0.0018882463918998837 max memory_allocated 29758.32861328125 
[2025-02-07 10:52:17 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 6 loss:0.19373038411140442 norm:0.001864887773990631 max memory_allocated 29758.32861328125 
[2025-02-07 10:53:04 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 7 loss:0.19348835945129395 norm:0.001862858422100544 max memory_allocated 29758.32861328125 
[2025-02-07 10:53:50 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 8 loss:0.19330187141895294 norm:0.0017912436742335558 max memory_allocated 29758.32861328125 
[2025-02-07 10:54:37 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 9 loss:0.19314855337142944 norm:0.001827068394050002 max memory_allocated 29758.32861328125 
[2025-02-07 10:55:23 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 10 loss:0.1930149495601654 norm:0.0017449965234845877 max memory_allocated 29758.32861328125 
[2025-02-07 10:56:10 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 11 loss:0.19292397797107697 norm:0.0017486314754933119 max memory_allocated 29758.32861328125 
[2025-02-07 10:56:56 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 12 loss:0.19281938672065735 norm:0.0017548941541463137 max memory_allocated 29758.32861328125 
[2025-02-07 10:57:43 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 13 loss:0.19273853302001953 norm:0.0017283307388424873 max memory_allocated 29758.32861328125 
[2025-02-07 10:58:29 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 14 loss:0.1926545798778534 norm:0.0016928380355238914 max memory_allocated 29758.32861328125 
[2025-02-07 10:59:16 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 15 loss:0.19260023534297943 norm:0.001728881266899407 max memory_allocated 29758.32861328125 
[2025-02-07 11:00:02 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 16 loss:0.19253160059452057 norm:0.001721375621855259 max memory_allocated 29758.32861328125 
[2025-02-07 11:00:49 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 17 loss:0.19245645403862 norm:0.00169574492610991 max memory_allocated 29758.32861328125 
[2025-02-07 11:01:36 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 18 loss:0.19241729378700256 norm:0.0016907011158764362 max memory_allocated 29758.32861328125 
[2025-02-07 11:02:22 root] (abq_llm_calib_config.py 368): INFO layer 22 iter 19 loss:0.1923530250787735 norm:0.0015994856366887689 max memory_allocated 29758.32861328125 
[2025-02-07 11:02:36 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 23 ===
[2025-02-07 11:03:26 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 0 loss:0.24620197713375092 norm:0.0023574179504066706 max memory_allocated 29760.39111328125 
[2025-02-07 11:04:13 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 1 loss:0.23427355289459229 norm:0.0018183531938120723 max memory_allocated 29760.39111328125 
[2025-02-07 11:04:59 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 2 loss:0.22460798919200897 norm:0.0016380497254431248 max memory_allocated 29760.39111328125 
[2025-02-07 11:05:46 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 3 loss:0.22184868156909943 norm:0.0015062156599014997 max memory_allocated 29760.39111328125 
[2025-02-07 11:06:32 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 4 loss:0.22035537660121918 norm:0.0014429548755288124 max memory_allocated 29760.39111328125 
[2025-02-07 11:07:19 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 5 loss:0.21976721286773682 norm:0.0013261608546599746 max memory_allocated 29760.39111328125 
[2025-02-07 11:08:05 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 6 loss:0.219415545463562 norm:0.001297647482715547 max memory_allocated 29760.39111328125 
[2025-02-07 11:08:52 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 7 loss:0.2191518396139145 norm:0.0012391123455017805 max memory_allocated 29760.39111328125 
[2025-02-07 11:09:38 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 8 loss:0.2189144641160965 norm:0.0011487737065181136 max memory_allocated 29760.39111328125 
[2025-02-07 11:10:25 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 9 loss:0.2187933623790741 norm:0.0011514810612425208 max memory_allocated 29760.39111328125 
[2025-02-07 11:11:12 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 10 loss:0.21861498057842255 norm:0.0011444749543443322 max memory_allocated 29760.39111328125 
[2025-02-07 11:11:58 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 11 loss:0.21848022937774658 norm:0.0011304474901407957 max memory_allocated 29760.39111328125 
[2025-02-07 11:12:45 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 12 loss:0.21836957335472107 norm:0.001138758147135377 max memory_allocated 29760.39111328125 
[2025-02-07 11:13:31 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 13 loss:0.2182493805885315 norm:0.0011159981368109584 max memory_allocated 29760.39111328125 
[2025-02-07 11:14:18 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 14 loss:0.21817083656787872 norm:0.0011189366923645139 max memory_allocated 29760.39111328125 
[2025-02-07 11:15:04 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 15 loss:0.21808108687400818 norm:0.001082502887584269 max memory_allocated 29760.39111328125 
[2025-02-07 11:15:51 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 16 loss:0.21800263226032257 norm:0.0010754648828878999 max memory_allocated 29760.39111328125 
[2025-02-07 11:16:37 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 17 loss:0.21794532239437103 norm:0.0010870957048609853 max memory_allocated 29760.39111328125 
[2025-02-07 11:17:24 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 18 loss:0.21789273619651794 norm:0.0011226236820220947 max memory_allocated 29760.39111328125 
[2025-02-07 11:18:10 root] (abq_llm_calib_config.py 368): INFO layer 23 iter 19 loss:0.21784579753875732 norm:0.0011305426014587283 max memory_allocated 29760.39111328125 
[2025-02-07 11:18:24 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 24 ===
[2025-02-07 11:19:14 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 0 loss:0.275910347700119 norm:0.002709090942516923 max memory_allocated 29762.45361328125 
[2025-02-07 11:20:00 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 1 loss:0.2637534737586975 norm:0.0020711692050099373 max memory_allocated 29762.45361328125 
[2025-02-07 11:20:47 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 2 loss:0.2532062530517578 norm:0.001827893895097077 max memory_allocated 29762.45361328125 
[2025-02-07 11:21:33 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 3 loss:0.24980591237545013 norm:0.0017391875153407454 max memory_allocated 29762.45361328125 
[2025-02-07 11:22:19 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 4 loss:0.24817276000976562 norm:0.0015761684626340866 max memory_allocated 29762.45361328125 
[2025-02-07 11:23:06 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 5 loss:0.2476145476102829 norm:0.0015910849906504154 max memory_allocated 29762.45361328125 
[2025-02-07 11:23:52 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 6 loss:0.24724560976028442 norm:0.0015777976950630546 max memory_allocated 29762.45361328125 
[2025-02-07 11:24:39 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 7 loss:0.24699363112449646 norm:0.0015317696379497647 max memory_allocated 29762.45361328125 
[2025-02-07 11:25:25 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 8 loss:0.24681612849235535 norm:0.0014155842363834381 max memory_allocated 29762.45361328125 
[2025-02-07 11:26:11 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 9 loss:0.24663156270980835 norm:0.0014402632368728518 max memory_allocated 29762.45361328125 
[2025-02-07 11:26:58 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 10 loss:0.24646522104740143 norm:0.0014502608682960272 max memory_allocated 29762.45361328125 
[2025-02-07 11:27:44 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 11 loss:0.24632063508033752 norm:0.0014772225404158235 max memory_allocated 29762.45361328125 
[2025-02-07 11:28:31 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 12 loss:0.24620036780834198 norm:0.0014625451294705272 max memory_allocated 29762.45361328125 
[2025-02-07 11:29:17 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 13 loss:0.24610991775989532 norm:0.0014747551176697016 max memory_allocated 29762.45361328125 
[2025-02-07 11:30:03 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 14 loss:0.24600496888160706 norm:0.001453533535823226 max memory_allocated 29762.45361328125 
[2025-02-07 11:30:50 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 15 loss:0.2459375411272049 norm:0.0014092562487348914 max memory_allocated 29762.45361328125 
[2025-02-07 11:31:36 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 16 loss:0.2458564192056656 norm:0.0014110952615737915 max memory_allocated 29762.45361328125 
[2025-02-07 11:32:23 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 17 loss:0.24578030407428741 norm:0.0013552445452660322 max memory_allocated 29762.45361328125 
[2025-02-07 11:33:09 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 18 loss:0.24570491909980774 norm:0.0013943638186901808 max memory_allocated 29762.45361328125 
[2025-02-07 11:33:56 root] (abq_llm_calib_config.py 368): INFO layer 24 iter 19 loss:0.2456676959991455 norm:0.001368407509289682 max memory_allocated 29762.45361328125 
[2025-02-07 11:34:09 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 25 ===
[2025-02-07 11:34:59 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 0 loss:0.3047185242176056 norm:0.002321662614122033 max memory_allocated 29764.51611328125 
[2025-02-07 11:35:46 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 1 loss:0.2925213575363159 norm:0.0018497367855161428 max memory_allocated 29764.51611328125 
[2025-02-07 11:36:32 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 2 loss:0.2818533480167389 norm:0.0017259538872167468 max memory_allocated 29764.51611328125 
[2025-02-07 11:37:18 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 3 loss:0.2789191007614136 norm:0.0016208237502723932 max memory_allocated 29764.51611328125 
[2025-02-07 11:38:05 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 4 loss:0.2775849401950836 norm:0.001620735740289092 max memory_allocated 29764.51611328125 
[2025-02-07 11:38:51 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 5 loss:0.2770644426345825 norm:0.0015669051790609956 max memory_allocated 29764.51611328125 
[2025-02-07 11:39:38 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 6 loss:0.2767435312271118 norm:0.00158487178850919 max memory_allocated 29764.51611328125 
[2025-02-07 11:40:24 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 7 loss:0.2764403820037842 norm:0.00153062934987247 max memory_allocated 29764.51611328125 
[2025-02-07 11:41:11 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 8 loss:0.2761811912059784 norm:0.0014989260816946626 max memory_allocated 29764.51611328125 
[2025-02-07 11:41:57 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 9 loss:0.2760070264339447 norm:0.0015054360264912248 max memory_allocated 29764.51611328125 
[2025-02-07 11:42:43 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 10 loss:0.27582141757011414 norm:0.0014500466641038656 max memory_allocated 29764.51611328125 
[2025-02-07 11:43:30 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 11 loss:0.27568191289901733 norm:0.0014516685623675585 max memory_allocated 29764.51611328125 
[2025-02-07 11:44:16 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 12 loss:0.2755308747291565 norm:0.0014230110682547092 max memory_allocated 29764.51611328125 
[2025-02-07 11:45:03 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 13 loss:0.2753962278366089 norm:0.0014554345980286598 max memory_allocated 29764.51611328125 
[2025-02-07 11:45:49 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 14 loss:0.27529001235961914 norm:0.0014404229586943984 max memory_allocated 29764.51611328125 
[2025-02-07 11:46:36 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 15 loss:0.2752213180065155 norm:0.0014178301207721233 max memory_allocated 29764.51611328125 
[2025-02-07 11:47:22 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 16 loss:0.2751431167125702 norm:0.0014211343368515372 max memory_allocated 29764.51611328125 
[2025-02-07 11:48:08 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 17 loss:0.2750703692436218 norm:0.001432316261343658 max memory_allocated 29764.51611328125 
[2025-02-07 11:48:55 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 18 loss:0.27497202157974243 norm:0.001415420789271593 max memory_allocated 29764.51611328125 
[2025-02-07 11:49:41 root] (abq_llm_calib_config.py 368): INFO layer 25 iter 19 loss:0.27492719888687134 norm:0.0014047042932361364 max memory_allocated 29764.51611328125 
[2025-02-07 11:49:55 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 26 ===
[2025-02-07 11:50:45 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 0 loss:0.34091830253601074 norm:0.0022148778662085533 max memory_allocated 29766.57861328125 
[2025-02-07 11:51:31 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 1 loss:0.32751786708831787 norm:0.0015351504553109407 max memory_allocated 29766.57861328125 
[2025-02-07 11:52:18 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 2 loss:0.3152792751789093 norm:0.0012631796998903155 max memory_allocated 29766.57861328125 
[2025-02-07 11:53:04 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 3 loss:0.31158894300460815 norm:0.001159416395239532 max memory_allocated 29766.57861328125 
[2025-02-07 11:53:51 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 4 loss:0.3100828230381012 norm:0.001082738395780325 max memory_allocated 29766.57861328125 
[2025-02-07 11:54:37 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 5 loss:0.30954188108444214 norm:0.0010101801017299294 max memory_allocated 29766.57861328125 
[2025-02-07 11:55:23 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 6 loss:0.3091924786567688 norm:0.0010015030857175589 max memory_allocated 29766.57861328125 
[2025-02-07 11:56:10 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 7 loss:0.3089348077774048 norm:0.0010052330326288939 max memory_allocated 29766.57861328125 
[2025-02-07 11:56:56 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 8 loss:0.3087364435195923 norm:0.0010124517139047384 max memory_allocated 29766.57861328125 
[2025-02-07 11:57:43 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 9 loss:0.30856946110725403 norm:0.0010076126782223582 max memory_allocated 29766.57861328125 
[2025-02-07 11:58:29 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 10 loss:0.30839067697525024 norm:0.0009883263846859336 max memory_allocated 29766.57861328125 
[2025-02-07 11:59:15 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 11 loss:0.3082289695739746 norm:0.0009630968561396003 max memory_allocated 29766.57861328125 
[2025-02-07 12:00:02 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 12 loss:0.3081212341785431 norm:0.000955008203163743 max memory_allocated 29766.57861328125 
[2025-02-07 12:00:48 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 13 loss:0.3080180883407593 norm:0.0009242098312824965 max memory_allocated 29766.57861328125 
[2025-02-07 12:01:35 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 14 loss:0.30789726972579956 norm:0.0009461357840336859 max memory_allocated 29766.57861328125 
[2025-02-07 12:02:21 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 15 loss:0.3078088164329529 norm:0.0009214526508003473 max memory_allocated 29766.57861328125 
[2025-02-07 12:03:07 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 16 loss:0.3077217638492584 norm:0.0009357748203910887 max memory_allocated 29766.57861328125 
[2025-02-07 12:03:54 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 17 loss:0.307640939950943 norm:0.000929146830458194 max memory_allocated 29766.57861328125 
[2025-02-07 12:04:40 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 18 loss:0.30758875608444214 norm:0.0009449318749830127 max memory_allocated 29766.57861328125 
[2025-02-07 12:05:27 root] (abq_llm_calib_config.py 368): INFO layer 26 iter 19 loss:0.30752837657928467 norm:0.0009489358635619283 max memory_allocated 29766.57861328125 
[2025-02-07 12:05:40 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 27 ===
[2025-02-07 12:06:30 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 0 loss:0.37983083724975586 norm:0.0021686162799596786 max memory_allocated 29768.64111328125 
[2025-02-07 12:07:17 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 1 loss:0.3649514615535736 norm:0.001729305600747466 max memory_allocated 29768.64111328125 
[2025-02-07 12:08:03 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 2 loss:0.3511698842048645 norm:0.001539001241326332 max memory_allocated 29768.64111328125 
[2025-02-07 12:08:50 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 3 loss:0.3473324179649353 norm:0.0015037213452160358 max memory_allocated 29768.64111328125 
[2025-02-07 12:09:36 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 4 loss:0.34585052728652954 norm:0.0013517156476154923 max memory_allocated 29768.64111328125 
[2025-02-07 12:10:22 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 5 loss:0.3452649414539337 norm:0.0013046507956460118 max memory_allocated 29768.64111328125 
[2025-02-07 12:11:09 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 6 loss:0.34488415718078613 norm:0.001287603983655572 max memory_allocated 29768.64111328125 
[2025-02-07 12:11:55 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 7 loss:0.3445645868778229 norm:0.0012578710447996855 max memory_allocated 29768.64111328125 
[2025-02-07 12:12:42 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 8 loss:0.34432151913642883 norm:0.0012463193852454424 max memory_allocated 29768.64111328125 
[2025-02-07 12:13:28 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 9 loss:0.34415024518966675 norm:0.0012452744413167238 max memory_allocated 29768.64111328125 
[2025-02-07 12:14:14 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 10 loss:0.3439643979072571 norm:0.001229128334671259 max memory_allocated 29768.64111328125 
[2025-02-07 12:15:01 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 11 loss:0.34376320242881775 norm:0.00121720798779279 max memory_allocated 29768.64111328125 
[2025-02-07 12:15:47 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 12 loss:0.3435770571231842 norm:0.0011759358458220959 max memory_allocated 29768.64111328125 
[2025-02-07 12:16:34 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 13 loss:0.34345459938049316 norm:0.0011887777363881469 max memory_allocated 29768.64111328125 
[2025-02-07 12:17:20 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 14 loss:0.3433213233947754 norm:0.0011633693939074874 max memory_allocated 29768.64111328125 
[2025-02-07 12:18:07 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 15 loss:0.34320467710494995 norm:0.0011729487450793386 max memory_allocated 29768.64111328125 
[2025-02-07 12:18:53 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 16 loss:0.34311285614967346 norm:0.0011653515975922346 max memory_allocated 29768.64111328125 
[2025-02-07 12:19:39 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 17 loss:0.343034952878952 norm:0.0011665979400277138 max memory_allocated 29768.64111328125 
[2025-02-07 12:20:26 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 18 loss:0.342974454164505 norm:0.0011470700846984982 max memory_allocated 29768.64111328125 
[2025-02-07 12:21:12 root] (abq_llm_calib_config.py 368): INFO layer 27 iter 19 loss:0.34289801120758057 norm:0.001138611463829875 max memory_allocated 29768.64111328125 
[2025-02-07 12:21:26 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 28 ===
[2025-02-07 12:22:16 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 0 loss:0.41908055543899536 norm:0.004099554382264614 max memory_allocated 29770.70361328125 
[2025-02-07 12:23:02 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 1 loss:0.4037562608718872 norm:0.00385543005540967 max memory_allocated 29770.70361328125 
[2025-02-07 12:23:49 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 2 loss:0.38925936818122864 norm:0.0036061634309589863 max memory_allocated 29770.70361328125 
[2025-02-07 12:24:35 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 3 loss:0.3850492238998413 norm:0.0035480952356010675 max memory_allocated 29770.70361328125 
[2025-02-07 12:25:22 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 4 loss:0.3835286498069763 norm:0.003467550268396735 max memory_allocated 29770.70361328125 
[2025-02-07 12:26:08 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 5 loss:0.3829834461212158 norm:0.0033567878417670727 max memory_allocated 29770.70361328125 
[2025-02-07 12:26:54 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 6 loss:0.38259920477867126 norm:0.0033374845515936613 max memory_allocated 29770.70361328125 
[2025-02-07 12:27:41 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 7 loss:0.38224688172340393 norm:0.002982465783134103 max memory_allocated 29770.70361328125 
[2025-02-07 12:28:27 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 8 loss:0.3820093274116516 norm:0.0029856860637664795 max memory_allocated 29770.70361328125 
[2025-02-07 12:29:14 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 9 loss:0.38178956508636475 norm:0.003110690275207162 max memory_allocated 29770.70361328125 
[2025-02-07 12:30:00 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 10 loss:0.38164106011390686 norm:0.0031365319155156612 max memory_allocated 29770.70361328125 
[2025-02-07 12:30:46 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 11 loss:0.3814960718154907 norm:0.0032265004701912403 max memory_allocated 29770.70361328125 
[2025-02-07 12:31:33 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 12 loss:0.3813685178756714 norm:0.0032113331835716963 max memory_allocated 29770.70361328125 
[2025-02-07 12:32:19 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 13 loss:0.38126251101493835 norm:0.003341870615258813 max memory_allocated 29770.70361328125 
[2025-02-07 12:33:06 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 14 loss:0.3811432421207428 norm:0.0033406256698071957 max memory_allocated 29770.70361328125 
[2025-02-07 12:33:52 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 15 loss:0.3810509741306305 norm:0.0033158641308546066 max memory_allocated 29770.70361328125 
[2025-02-07 12:34:39 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 16 loss:0.3809705376625061 norm:0.0033227279782295227 max memory_allocated 29770.70361328125 
[2025-02-07 12:35:25 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 17 loss:0.3809005320072174 norm:0.0033367653377354145 max memory_allocated 29770.70361328125 
[2025-02-07 12:36:11 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 18 loss:0.38080281019210815 norm:0.0032816894818097353 max memory_allocated 29770.70361328125 
[2025-02-07 12:36:58 root] (abq_llm_calib_config.py 368): INFO layer 28 iter 19 loss:0.3806897699832916 norm:0.003197970101609826 max memory_allocated 29770.70361328125 
[2025-02-07 12:37:11 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 29 ===
[2025-02-07 12:38:02 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 0 loss:0.457562118768692 norm:0.0026079758536070585 max memory_allocated 29772.76611328125 
[2025-02-07 12:38:48 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 1 loss:0.4414730370044708 norm:0.0019102415535598993 max memory_allocated 29772.76611328125 
[2025-02-07 12:39:34 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 2 loss:0.42636585235595703 norm:0.0017658559372648597 max memory_allocated 29772.76611328125 
[2025-02-07 12:40:21 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 3 loss:0.4220406115055084 norm:0.0016805364284664392 max memory_allocated 29772.76611328125 
[2025-02-07 12:41:07 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 4 loss:0.42060405015945435 norm:0.0015799941029399633 max memory_allocated 29772.76611328125 
[2025-02-07 12:41:54 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 5 loss:0.420044869184494 norm:0.0015180002665147185 max memory_allocated 29772.76611328125 
[2025-02-07 12:42:40 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 6 loss:0.41971927881240845 norm:0.0014764490770176053 max memory_allocated 29772.76611328125 
[2025-02-07 12:43:26 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 7 loss:0.4194289445877075 norm:0.001497988821938634 max memory_allocated 29772.76611328125 
[2025-02-07 12:44:13 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 8 loss:0.41916579008102417 norm:0.0014712526462972164 max memory_allocated 29772.76611328125 
[2025-02-07 12:44:59 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 9 loss:0.41896504163742065 norm:0.0014911651378497481 max memory_allocated 29772.76611328125 
[2025-02-07 12:45:46 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 10 loss:0.4187614321708679 norm:0.0014642395544797182 max memory_allocated 29772.76611328125 
[2025-02-07 12:46:32 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 11 loss:0.4185865819454193 norm:0.0014559364644810557 max memory_allocated 29772.76611328125 
[2025-02-07 12:47:18 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 12 loss:0.4184325933456421 norm:0.0014278751332312822 max memory_allocated 29772.76611328125 
[2025-02-07 12:48:05 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 13 loss:0.4183011054992676 norm:0.0014232199173420668 max memory_allocated 29772.76611328125 
[2025-02-07 12:48:51 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 14 loss:0.41819241642951965 norm:0.0014307776000350714 max memory_allocated 29772.76611328125 
[2025-02-07 12:49:38 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 15 loss:0.41807281970977783 norm:0.0014199843863025308 max memory_allocated 29772.76611328125 
[2025-02-07 12:50:24 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 16 loss:0.41796875 norm:0.0013889280380681157 max memory_allocated 29772.76611328125 
[2025-02-07 12:51:10 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 17 loss:0.41789284348487854 norm:0.0014061139663681388 max memory_allocated 29772.76611328125 
[2025-02-07 12:51:57 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 18 loss:0.4177978038787842 norm:0.0014068975578993559 max memory_allocated 29772.76611328125 
[2025-02-07 12:52:43 root] (abq_llm_calib_config.py 368): INFO layer 29 iter 19 loss:0.41771844029426575 norm:0.0013702772557735443 max memory_allocated 29772.76611328125 
[2025-02-07 12:52:57 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 30 ===
[2025-02-07 12:53:47 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 0 loss:0.5004196763038635 norm:0.0027791731990873814 max memory_allocated 29774.82861328125 
[2025-02-07 12:54:33 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 1 loss:0.48417598009109497 norm:0.0021511020604521036 max memory_allocated 29774.82861328125 
[2025-02-07 12:55:20 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 2 loss:0.4687669575214386 norm:0.0018495869589969516 max memory_allocated 29774.82861328125 
[2025-02-07 12:56:06 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 3 loss:0.4644310474395752 norm:0.0016552924644201994 max memory_allocated 29774.82861328125 
[2025-02-07 12:56:53 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 4 loss:0.46307066082954407 norm:0.001644195057451725 max memory_allocated 29774.82861328125 
[2025-02-07 12:57:39 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 5 loss:0.46245822310447693 norm:0.0015397294191643596 max memory_allocated 29774.82861328125 
[2025-02-07 12:58:25 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 6 loss:0.46203479170799255 norm:0.001601905096322298 max memory_allocated 29774.82861328125 
[2025-02-07 12:59:12 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 7 loss:0.46167564392089844 norm:0.001538445707410574 max memory_allocated 29774.82861328125 
[2025-02-07 12:59:58 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 8 loss:0.46137741208076477 norm:0.0015068540815263987 max memory_allocated 29774.82861328125 
[2025-02-07 13:00:45 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 9 loss:0.46111923456192017 norm:0.0015368383610621095 max memory_allocated 29774.82861328125 
[2025-02-07 13:01:31 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 10 loss:0.4609047472476959 norm:0.0015122368931770325 max memory_allocated 29774.82861328125 
[2025-02-07 13:02:17 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 11 loss:0.4607076644897461 norm:0.0014732466079294682 max memory_allocated 29774.82861328125 
[2025-02-07 13:03:04 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 12 loss:0.4605638086795807 norm:0.0014726835070177913 max memory_allocated 29774.82861328125 
[2025-02-07 13:03:50 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 13 loss:0.4603845477104187 norm:0.0014357937034219503 max memory_allocated 29774.82861328125 
[2025-02-07 13:04:37 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 14 loss:0.46024104952812195 norm:0.0014683336485177279 max memory_allocated 29774.82861328125 
[2025-02-07 13:05:23 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 15 loss:0.46012747287750244 norm:0.001469675451517105 max memory_allocated 29774.82861328125 
[2025-02-07 13:06:09 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 16 loss:0.4599960148334503 norm:0.001401917077600956 max memory_allocated 29774.82861328125 
[2025-02-07 13:06:56 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 17 loss:0.4598790109157562 norm:0.0014570323983207345 max memory_allocated 29774.82861328125 
[2025-02-07 13:07:42 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 18 loss:0.45979762077331543 norm:0.0014692040858790278 max memory_allocated 29774.82861328125 
[2025-02-07 13:08:29 root] (abq_llm_calib_config.py 368): INFO layer 30 iter 19 loss:0.45970144867897034 norm:0.0014786752872169018 max memory_allocated 29774.82861328125 
[2025-02-07 13:08:42 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 31 ===
[2025-02-07 13:09:32 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 0 loss:0.5483403205871582 norm:0.0032000469509512186 max memory_allocated 29776.89111328125 
[2025-02-07 13:10:19 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 1 loss:0.5304230451583862 norm:0.002366699744015932 max memory_allocated 29776.89111328125 
[2025-02-07 13:11:05 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 2 loss:0.5139882564544678 norm:0.00199917983263731 max memory_allocated 29776.89111328125 
[2025-02-07 13:11:52 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 3 loss:0.5091550946235657 norm:0.001922453986480832 max memory_allocated 29776.89111328125 
[2025-02-07 13:12:38 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 4 loss:0.5077082514762878 norm:0.0018298126524314284 max memory_allocated 29776.89111328125 
[2025-02-07 13:13:24 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 5 loss:0.5071004629135132 norm:0.001781080849468708 max memory_allocated 29776.89111328125 
[2025-02-07 13:14:11 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 6 loss:0.5066556930541992 norm:0.0017566841561347246 max memory_allocated 29776.89111328125 
[2025-02-07 13:14:57 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 7 loss:0.5062791705131531 norm:0.0017903817351907492 max memory_allocated 29776.89111328125 
[2025-02-07 13:15:43 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 8 loss:0.5059669017791748 norm:0.0017138957045972347 max memory_allocated 29776.89111328125 
[2025-02-07 13:16:30 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 9 loss:0.5057296752929688 norm:0.0017632008530199528 max memory_allocated 29776.89111328125 
[2025-02-07 13:17:16 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 10 loss:0.5055031776428223 norm:0.0017785639502108097 max memory_allocated 29776.89111328125 
[2025-02-07 13:18:03 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 11 loss:0.5052914023399353 norm:0.0016672593774273992 max memory_allocated 29776.89111328125 
[2025-02-07 13:18:49 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 12 loss:0.5051026344299316 norm:0.0017062206752598286 max memory_allocated 29776.89111328125 
[2025-02-07 13:19:35 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 13 loss:0.5049557089805603 norm:0.0017094553913921118 max memory_allocated 29776.89111328125 
[2025-02-07 13:20:22 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 14 loss:0.5048149824142456 norm:0.0016728027258068323 max memory_allocated 29776.89111328125 
[2025-02-07 13:21:08 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 15 loss:0.5046724081039429 norm:0.0016415747813880444 max memory_allocated 29776.89111328125 
[2025-02-07 13:21:54 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 16 loss:0.5045425891876221 norm:0.0016000097384676337 max memory_allocated 29776.89111328125 
[2025-02-07 13:22:41 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 17 loss:0.504470705986023 norm:0.001651054248213768 max memory_allocated 29776.89111328125 
[2025-02-07 13:23:27 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 18 loss:0.5043807625770569 norm:0.0016335451509803534 max memory_allocated 29776.89111328125 
[2025-02-07 13:24:14 root] (abq_llm_calib_config.py 368): INFO layer 31 iter 19 loss:0.504274308681488 norm:0.0016296064713969827 max memory_allocated 29776.89111328125 
[2025-02-07 13:24:27 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 32 ===
[2025-02-07 13:25:17 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 0 loss:0.593458890914917 norm:0.0036199060268700123 max memory_allocated 29778.95361328125 
[2025-02-07 13:26:04 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 1 loss:0.5753494501113892 norm:0.002811981597915292 max memory_allocated 29778.95361328125 
[2025-02-07 13:26:50 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 2 loss:0.5583196878433228 norm:0.0022918046452105045 max memory_allocated 29778.95361328125 
[2025-02-07 13:27:36 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 3 loss:0.5534249544143677 norm:0.002140403725206852 max memory_allocated 29778.95361328125 
[2025-02-07 13:28:23 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 4 loss:0.5521000623703003 norm:0.002098575932905078 max memory_allocated 29778.95361328125 
[2025-02-07 13:29:09 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 5 loss:0.5514439344406128 norm:0.0020800777710974216 max memory_allocated 29778.95361328125 
[2025-02-07 13:29:56 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 6 loss:0.5509839057922363 norm:0.0019617227371782064 max memory_allocated 29778.95361328125 
[2025-02-07 13:30:42 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 7 loss:0.5506280660629272 norm:0.0019404240883886814 max memory_allocated 29778.95361328125 
[2025-02-07 13:31:28 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 8 loss:0.5503247976303101 norm:0.0019304306479170918 max memory_allocated 29778.95361328125 
[2025-02-07 13:32:15 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 9 loss:0.5500833988189697 norm:0.0019504752708598971 max memory_allocated 29778.95361328125 
[2025-02-07 13:33:01 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 10 loss:0.549868106842041 norm:0.0018756635254248977 max memory_allocated 29778.95361328125 
[2025-02-07 13:33:48 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 11 loss:0.549645721912384 norm:0.0018536329735070467 max memory_allocated 29778.95361328125 
[2025-02-07 13:34:34 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 12 loss:0.5494933128356934 norm:0.0018747553694993258 max memory_allocated 29778.95361328125 
[2025-02-07 13:35:20 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 13 loss:0.5493184924125671 norm:0.0018649704288691282 max memory_allocated 29778.95361328125 
[2025-02-07 13:36:07 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 14 loss:0.5491788387298584 norm:0.0019078683108091354 max memory_allocated 29778.95361328125 
[2025-02-07 13:36:53 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 15 loss:0.5490489602088928 norm:0.001935525331646204 max memory_allocated 29778.95361328125 
[2025-02-07 13:37:39 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 16 loss:0.5489277243614197 norm:0.001901792362332344 max memory_allocated 29778.95361328125 
[2025-02-07 13:38:26 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 17 loss:0.5488191843032837 norm:0.0018690365832298994 max memory_allocated 29778.95361328125 
[2025-02-07 13:39:12 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 18 loss:0.5487099885940552 norm:0.0019319894490763545 max memory_allocated 29778.95361328125 
[2025-02-07 13:39:59 root] (abq_llm_calib_config.py 368): INFO layer 32 iter 19 loss:0.5486134886741638 norm:0.0018745593260973692 max memory_allocated 29778.95361328125 
[2025-02-07 13:40:12 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 33 ===
[2025-02-07 13:41:02 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 0 loss:0.6473367810249329 norm:0.003405807539820671 max memory_allocated 29781.01611328125 
[2025-02-07 13:41:49 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 1 loss:0.6285163164138794 norm:0.0028847185894846916 max memory_allocated 29781.01611328125 
[2025-02-07 13:42:35 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 2 loss:0.6110708117485046 norm:0.002660853788256645 max memory_allocated 29781.01611328125 
[2025-02-07 13:43:21 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 3 loss:0.6062811613082886 norm:0.0024987338110804558 max memory_allocated 29781.01611328125 
[2025-02-07 13:44:08 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 4 loss:0.6050334572792053 norm:0.0024659293703734875 max memory_allocated 29781.01611328125 
[2025-02-07 13:44:54 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 5 loss:0.6043790578842163 norm:0.0024716148618608713 max memory_allocated 29781.01611328125 
[2025-02-07 13:45:41 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 6 loss:0.6038821339607239 norm:0.0024536345154047012 max memory_allocated 29781.01611328125 
[2025-02-07 13:46:27 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 7 loss:0.603429913520813 norm:0.0023967078886926174 max memory_allocated 29781.01611328125 
[2025-02-07 13:47:13 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 8 loss:0.603055477142334 norm:0.0023637639824301004 max memory_allocated 29781.01611328125 
[2025-02-07 13:48:00 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 9 loss:0.6027817130088806 norm:0.00235185818746686 max memory_allocated 29781.01611328125 
[2025-02-07 13:48:46 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 10 loss:0.6025041341781616 norm:0.0022720820270478725 max memory_allocated 29781.01611328125 
[2025-02-07 13:49:32 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 11 loss:0.6022939085960388 norm:0.0022995476610958576 max memory_allocated 29781.01611328125 
[2025-02-07 13:50:19 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 12 loss:0.602073609828949 norm:0.0022149744909256697 max memory_allocated 29781.01611328125 
[2025-02-07 13:51:05 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 13 loss:0.6019113063812256 norm:0.0023068846203386784 max memory_allocated 29781.01611328125 
[2025-02-07 13:51:52 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 14 loss:0.6017113924026489 norm:0.0022589336149394512 max memory_allocated 29781.01611328125 
[2025-02-07 13:52:38 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 15 loss:0.601570725440979 norm:0.0022532613947987556 max memory_allocated 29781.01611328125 
[2025-02-07 13:53:24 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 16 loss:0.6014275550842285 norm:0.002277555875480175 max memory_allocated 29781.01611328125 
[2025-02-07 13:54:11 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 17 loss:0.6013103723526001 norm:0.0022230539470911026 max memory_allocated 29781.01611328125 
[2025-02-07 13:54:57 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 18 loss:0.6012033820152283 norm:0.0022324216552078724 max memory_allocated 29781.01611328125 
[2025-02-07 13:55:43 root] (abq_llm_calib_config.py 368): INFO layer 33 iter 19 loss:0.6011163592338562 norm:0.0022349206265062094 max memory_allocated 29781.01611328125 
[2025-02-07 13:55:57 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 34 ===
[2025-02-07 13:56:47 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 0 loss:0.716869056224823 norm:0.0034701479598879814 max memory_allocated 29783.07861328125 
[2025-02-07 13:57:34 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 1 loss:0.6950860023498535 norm:0.002755949506536126 max memory_allocated 29783.07861328125 
[2025-02-07 13:58:20 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 2 loss:0.674862265586853 norm:0.0023232093080878258 max memory_allocated 29783.07861328125 
[2025-02-07 13:59:06 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 3 loss:0.6696500778198242 norm:0.002286501694470644 max memory_allocated 29783.07861328125 
[2025-02-07 13:59:53 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 4 loss:0.6683602929115295 norm:0.002256853273138404 max memory_allocated 29783.07861328125 
[2025-02-07 14:00:39 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 5 loss:0.6676895022392273 norm:0.0021729799918830395 max memory_allocated 29783.07861328125 
[2025-02-07 14:01:25 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 6 loss:0.6672518849372864 norm:0.0021914804819971323 max memory_allocated 29783.07861328125 
[2025-02-07 14:02:12 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 7 loss:0.6668165326118469 norm:0.002113153925165534 max memory_allocated 29783.07861328125 
[2025-02-07 14:02:58 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 8 loss:0.6664950251579285 norm:0.0021064337342977524 max memory_allocated 29783.07861328125 
[2025-02-07 14:03:45 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 9 loss:0.6661769151687622 norm:0.0020988015457987785 max memory_allocated 29783.07861328125 
[2025-02-07 14:04:31 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 10 loss:0.6659204959869385 norm:0.0020831783767789602 max memory_allocated 29783.07861328125 
[2025-02-07 14:05:17 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 11 loss:0.6656175255775452 norm:0.0020457401406019926 max memory_allocated 29783.07861328125 
[2025-02-07 14:06:04 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 12 loss:0.6654499173164368 norm:0.0020997305400669575 max memory_allocated 29783.07861328125 
[2025-02-07 14:06:50 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 13 loss:0.6652994155883789 norm:0.002101615536957979 max memory_allocated 29783.07861328125 
[2025-02-07 14:07:36 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 14 loss:0.6651138067245483 norm:0.0020708797965198755 max memory_allocated 29783.07861328125 
[2025-02-07 14:08:23 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 15 loss:0.6649112105369568 norm:0.002008348936215043 max memory_allocated 29783.07861328125 
[2025-02-07 14:09:09 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 16 loss:0.6647511720657349 norm:0.0019756085239350796 max memory_allocated 29783.07861328125 
[2025-02-07 14:09:56 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 17 loss:0.6646130681037903 norm:0.0020043218974024057 max memory_allocated 29783.07861328125 
[2025-02-07 14:10:42 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 18 loss:0.6644948124885559 norm:0.0020216433331370354 max memory_allocated 29783.07861328125 
[2025-02-07 14:11:28 root] (abq_llm_calib_config.py 368): INFO layer 34 iter 19 loss:0.6643964648246765 norm:0.0020384504459798336 max memory_allocated 29783.07861328125 
[2025-02-07 14:11:42 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 35 ===
[2025-02-07 14:12:32 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 0 loss:0.7891738414764404 norm:0.005094144027680159 max memory_allocated 29785.14111328125 
[2025-02-07 14:13:19 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 1 loss:0.7642070055007935 norm:0.0037227999418973923 max memory_allocated 29785.14111328125 
[2025-02-07 14:14:05 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 2 loss:0.7420172095298767 norm:0.002853075973689556 max memory_allocated 29785.14111328125 
[2025-02-07 14:14:51 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 3 loss:0.7366074323654175 norm:0.0025898576714098454 max memory_allocated 29785.14111328125 
[2025-02-07 14:15:38 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 4 loss:0.7349880933761597 norm:0.0023956336081027985 max memory_allocated 29785.14111328125 
[2025-02-07 14:16:24 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 5 loss:0.7342046499252319 norm:0.0024036006070673466 max memory_allocated 29785.14111328125 
[2025-02-07 14:17:11 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 6 loss:0.7335925698280334 norm:0.002297482220456004 max memory_allocated 29785.14111328125 
[2025-02-07 14:17:57 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 7 loss:0.7330402731895447 norm:0.002267909701913595 max memory_allocated 29785.14111328125 
[2025-02-07 14:18:43 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 8 loss:0.7325257658958435 norm:0.002369645982980728 max memory_allocated 29785.14111328125 
[2025-02-07 14:19:30 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 9 loss:0.73216712474823 norm:0.0022335282992571592 max memory_allocated 29785.14111328125 
[2025-02-07 14:20:16 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 10 loss:0.731823742389679 norm:0.002226397627964616 max memory_allocated 29785.14111328125 
[2025-02-07 14:21:02 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 11 loss:0.7315435409545898 norm:0.0022343159653246403 max memory_allocated 29785.14111328125 
[2025-02-07 14:21:49 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 12 loss:0.7312145829200745 norm:0.002216850407421589 max memory_allocated 29785.14111328125 
[2025-02-07 14:22:35 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 13 loss:0.7309650182723999 norm:0.0022472920827567577 max memory_allocated 29785.14111328125 
[2025-02-07 14:23:22 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 14 loss:0.730702817440033 norm:0.0021746461279690266 max memory_allocated 29785.14111328125 
[2025-02-07 14:24:08 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 15 loss:0.7305022478103638 norm:0.0021805991418659687 max memory_allocated 29785.14111328125 
[2025-02-07 14:24:54 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 16 loss:0.7304456830024719 norm:0.0021935487166047096 max memory_allocated 29785.14111328125 
[2025-02-07 14:25:41 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 17 loss:0.7303449511528015 norm:0.0020811583381146193 max memory_allocated 29785.14111328125 
[2025-02-07 14:26:27 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 18 loss:0.730259895324707 norm:0.0021745068952441216 max memory_allocated 29785.14111328125 
[2025-02-07 14:27:14 root] (abq_llm_calib_config.py 368): INFO layer 35 iter 19 loss:0.7301068305969238 norm:0.0021112437825649977 max memory_allocated 29785.14111328125 
[2025-02-07 14:27:27 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 36 ===
[2025-02-07 14:27:31 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 14:28:18 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 0 loss:0.8685844540596008 norm:0.014998136088252068 max memory_allocated 29787.34814453125 
[2025-02-07 14:29:04 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 1 loss:0.84047931432724 norm:0.011690332554280758 max memory_allocated 29787.34814453125 
[2025-02-07 14:29:51 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 2 loss:0.815045177936554 norm:0.00888819620013237 max memory_allocated 29787.34814453125 
[2025-02-07 14:30:37 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 3 loss:0.8092195391654968 norm:0.007494802586734295 max memory_allocated 29787.34814453125 
[2025-02-07 14:31:24 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 4 loss:0.8075498342514038 norm:0.006205452606081963 max memory_allocated 29787.34814453125 
[2025-02-07 14:32:10 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 5 loss:0.806454598903656 norm:0.00540049746632576 max memory_allocated 29787.34814453125 
[2025-02-07 14:32:57 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 6 loss:0.8059015870094299 norm:0.0052076708525419235 max memory_allocated 29787.34814453125 
[2025-02-07 14:33:44 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 7 loss:0.80525803565979 norm:0.00499494094401598 max memory_allocated 29787.34814453125 
[2025-02-07 14:34:30 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 8 loss:0.804832935333252 norm:0.0048067462630569935 max memory_allocated 29787.34814453125 
[2025-02-07 14:35:17 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 9 loss:0.8044424653053284 norm:0.004688329994678497 max memory_allocated 29787.34814453125 
[2025-02-07 14:36:03 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 10 loss:0.8039114475250244 norm:0.0044200425036251545 max memory_allocated 29787.34814453125 
[2025-02-07 14:36:50 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 11 loss:0.8035266399383545 norm:0.004287333227694035 max memory_allocated 29787.34814453125 
[2025-02-07 14:37:36 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 12 loss:0.8031533360481262 norm:0.004220134112983942 max memory_allocated 29787.34814453125 
[2025-02-07 14:38:23 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 13 loss:0.802749752998352 norm:0.004035652615129948 max memory_allocated 29787.34814453125 
[2025-02-07 14:39:10 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 14 loss:0.8022274971008301 norm:0.004055818542838097 max memory_allocated 29787.34814453125 
[2025-02-07 14:39:56 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 15 loss:0.8019034266471863 norm:0.003963090479373932 max memory_allocated 29787.34814453125 
[2025-02-07 14:40:43 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 16 loss:0.8017590045928955 norm:0.003974182065576315 max memory_allocated 29787.34814453125 
[2025-02-07 14:41:29 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 17 loss:0.8016079664230347 norm:0.00387491169385612 max memory_allocated 29787.34814453125 
[2025-02-07 14:42:16 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 18 loss:0.8014183044433594 norm:0.003812333568930626 max memory_allocated 29787.34814453125 
[2025-02-07 14:43:02 root] (abq_llm_calib_config.py 368): INFO layer 36 iter 19 loss:0.8012925982475281 norm:0.0037629231810569763 max memory_allocated 29787.34814453125 
[2025-02-07 14:43:16 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 37 ===
[2025-02-07 14:43:20 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 14:44:06 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 0 loss:0.9914600849151611 norm:0.02046940289437771 max memory_allocated 29789.41064453125 
[2025-02-07 14:44:53 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 1 loss:0.9539065361022949 norm:0.012566560879349709 max memory_allocated 29789.41064453125 
[2025-02-07 14:45:39 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 2 loss:0.920093297958374 norm:0.012165202759206295 max memory_allocated 29789.41064453125 
[2025-02-07 14:46:26 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 3 loss:0.9124069809913635 norm:0.012311214581131935 max memory_allocated 29789.41064453125 
[2025-02-07 14:47:12 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 4 loss:0.9100964069366455 norm:0.011942286044359207 max memory_allocated 29789.41064453125 
[2025-02-07 14:47:59 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 5 loss:0.9085568785667419 norm:0.0106356805190444 max memory_allocated 29789.41064453125 
[2025-02-07 14:48:46 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 6 loss:0.9077783823013306 norm:0.009502608329057693 max memory_allocated 29789.41064453125 
[2025-02-07 14:49:32 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 7 loss:0.9070184826850891 norm:0.008752970024943352 max memory_allocated 29789.41064453125 
[2025-02-07 14:50:19 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 8 loss:0.9060651659965515 norm:0.008006127551198006 max memory_allocated 29789.41064453125 
[2025-02-07 14:51:05 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 9 loss:0.9055079221725464 norm:0.007366816513240337 max memory_allocated 29789.41064453125 
[2025-02-07 14:51:52 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 10 loss:0.9049721956253052 norm:0.007577040232717991 max memory_allocated 29789.41064453125 
[2025-02-07 14:52:38 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 11 loss:0.9041494131088257 norm:0.006941234692931175 max memory_allocated 29789.41064453125 
[2025-02-07 14:53:25 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 12 loss:0.9038540720939636 norm:0.006723257713019848 max memory_allocated 29789.41064453125 
[2025-02-07 14:54:11 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 13 loss:0.9035479426383972 norm:0.006812980864197016 max memory_allocated 29789.41064453125 
[2025-02-07 14:54:58 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 14 loss:0.9033992290496826 norm:0.006803683005273342 max memory_allocated 29789.41064453125 
[2025-02-07 14:55:45 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 15 loss:0.902896523475647 norm:0.0065291388891637325 max memory_allocated 29789.41064453125 
[2025-02-07 14:56:31 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 16 loss:0.9023733139038086 norm:0.00619796197861433 max memory_allocated 29789.41064453125 
[2025-02-07 14:57:18 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 17 loss:0.9020567536354065 norm:0.006034363526850939 max memory_allocated 29789.41064453125 
[2025-02-07 14:58:04 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 18 loss:0.9017027020454407 norm:0.0058083925396203995 max memory_allocated 29789.41064453125 
[2025-02-07 14:58:51 root] (abq_llm_calib_config.py 368): INFO layer 37 iter 19 loss:0.9014657139778137 norm:0.005814198404550552 max memory_allocated 29789.41064453125 
[2025-02-07 14:59:04 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 38 ===
[2025-02-07 14:59:08 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 14:59:55 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 0 loss:1.2265431880950928 norm:0.041157789528369904 max memory_allocated 29791.47314453125 
[2025-02-07 15:00:41 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 1 loss:1.1638567447662354 norm:0.027664555236697197 max memory_allocated 29791.47314453125 
[2025-02-07 15:01:28 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 2 loss:1.1206153631210327 norm:0.02055124007165432 max memory_allocated 29791.47314453125 
[2025-02-07 15:02:14 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 3 loss:1.107925534248352 norm:0.01823047362267971 max memory_allocated 29791.47314453125 
[2025-02-07 15:03:01 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 4 loss:1.102410912513733 norm:0.016082540154457092 max memory_allocated 29791.47314453125 
[2025-02-07 15:03:47 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 5 loss:1.0992592573165894 norm:0.014684433117508888 max memory_allocated 29791.47314453125 
[2025-02-07 15:04:34 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 6 loss:1.096500039100647 norm:0.013505922630429268 max memory_allocated 29791.47314453125 
[2025-02-07 15:05:21 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 7 loss:1.0943639278411865 norm:0.012183737941086292 max memory_allocated 29791.47314453125 
[2025-02-07 15:06:07 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 8 loss:1.0928678512573242 norm:0.011678787879645824 max memory_allocated 29791.47314453125 
[2025-02-07 15:06:54 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 9 loss:1.0915471315383911 norm:0.011615436524152756 max memory_allocated 29791.47314453125 
[2025-02-07 15:07:40 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 10 loss:1.0903311967849731 norm:0.011310224421322346 max memory_allocated 29791.47314453125 
[2025-02-07 15:08:27 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 11 loss:1.0897419452667236 norm:0.011168044060468674 max memory_allocated 29791.47314453125 
[2025-02-07 15:09:13 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 12 loss:1.088719129562378 norm:0.010500813834369183 max memory_allocated 29791.47314453125 
[2025-02-07 15:10:00 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 13 loss:1.0883419513702393 norm:0.011123638600111008 max memory_allocated 29791.47314453125 
[2025-02-07 15:10:47 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 14 loss:1.0879521369934082 norm:0.010889249853789806 max memory_allocated 29791.47314453125 
[2025-02-07 15:11:33 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 15 loss:1.0873008966445923 norm:0.010448603890836239 max memory_allocated 29791.47314453125 
[2025-02-07 15:12:20 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 16 loss:1.0871894359588623 norm:0.010669889859855175 max memory_allocated 29791.47314453125 
[2025-02-07 15:13:06 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 17 loss:1.0868356227874756 norm:0.010848559439182281 max memory_allocated 29791.47314453125 
[2025-02-07 15:13:53 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 18 loss:1.0865757465362549 norm:0.010463740676641464 max memory_allocated 29791.47314453125 
[2025-02-07 15:14:39 root] (abq_llm_calib_config.py 368): INFO layer 38 iter 19 loss:1.0862548351287842 norm:0.010535210371017456 max memory_allocated 29791.47314453125 
[2025-02-07 15:14:53 root] (abq_llm_calib_config.py 235): INFO === Start quantize layer 39 ===
[2025-02-07 15:14:57 root] (abq_llm_calib_config.py 308): INFO use compensation vector
[2025-02-07 15:15:43 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 0 loss:2.0840578079223633 norm:0.12195082008838654 max memory_allocated 29793.53564453125 
[2025-02-07 15:16:30 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 1 loss:1.941664218902588 norm:0.0880364328622818 max memory_allocated 29793.53564453125 
[2025-02-07 15:17:16 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 2 loss:1.8385411500930786 norm:0.05900842323899269 max memory_allocated 29793.53564453125 
[2025-02-07 15:18:03 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 3 loss:1.8086512088775635 norm:0.05846399441361427 max memory_allocated 29793.53564453125 
[2025-02-07 15:18:49 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 4 loss:1.7933614253997803 norm:0.055121634155511856 max memory_allocated 29793.53564453125 
[2025-02-07 15:19:36 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 5 loss:1.7823803424835205 norm:0.051972776651382446 max memory_allocated 29793.53564453125 
[2025-02-07 15:20:23 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 6 loss:1.7749180793762207 norm:0.05179964378476143 max memory_allocated 29793.53564453125 
[2025-02-07 15:21:09 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 7 loss:1.768489122390747 norm:0.04980205371975899 max memory_allocated 29793.53564453125 
[2025-02-07 15:21:56 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 8 loss:1.764822244644165 norm:0.05197301134467125 max memory_allocated 29793.53564453125 
[2025-02-07 15:22:42 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 9 loss:1.762540578842163 norm:0.05138370767235756 max memory_allocated 29793.53564453125 
[2025-02-07 15:23:29 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 10 loss:1.759795904159546 norm:0.050106409937143326 max memory_allocated 29793.53564453125 
[2025-02-07 15:24:15 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 11 loss:1.7560752630233765 norm:0.04808748885989189 max memory_allocated 29793.53564453125 
[2025-02-07 15:25:02 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 12 loss:1.752448320388794 norm:0.04530322551727295 max memory_allocated 29793.53564453125 
[2025-02-07 15:25:49 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 13 loss:1.7510381937026978 norm:0.04500192031264305 max memory_allocated 29793.53564453125 
[2025-02-07 15:26:35 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 14 loss:1.7518097162246704 norm:0.04662802070379257 max memory_allocated 29793.53564453125 
[2025-02-07 15:27:22 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 15 loss:1.750754952430725 norm:0.04604125767946243 max memory_allocated 29793.53564453125 
[2025-02-07 15:28:09 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 16 loss:1.7497185468673706 norm:0.046945516020059586 max memory_allocated 29793.53564453125 
[2025-02-07 15:28:55 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 17 loss:1.7475861310958862 norm:0.0450575053691864 max memory_allocated 29793.53564453125 
[2025-02-07 15:29:42 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 18 loss:1.7445350885391235 norm:0.044275060296058655 max memory_allocated 29793.53564453125 
[2025-02-07 15:30:28 root] (abq_llm_calib_config.py 368): INFO layer 39 iter 19 loss:1.7449240684509277 norm:0.04613882303237915 max memory_allocated 29793.53564453125 
[2025-02-07 15:30:42 root] (main_calib_config.py 366): INFO 37865.656918764114
[2025-02-07 15:31:53 root] (main_calib_config.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-02-07 15:33:49 root] (main_calib_config.py 159): INFO wikitext2 : 5.357367038726807
[2025-02-07 15:33:49 root] (main_calib_config.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-02-07 15:36:47 root] (main_calib_config.py 159): INFO c4 : 6.9504852294921875
[2025-02-07 17:14:52 root] (main_calib_config.py 170): INFO {'wikitext2': 5.357367038726807, 'c4': 6.9504852294921875, 'results': {'winogrande': {'acc': 0.6795580110497238, 'acc_stderr': 0.013115085457681712}, 'hellaswag': {'acc': 0.5743875721967735, 'acc_stderr': 0.00493425039087978, 'acc_norm': 0.7461661023700458, 'acc_norm_stderr': 0.004343142545094254}}, 'versions': {'winogrande': 0, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
