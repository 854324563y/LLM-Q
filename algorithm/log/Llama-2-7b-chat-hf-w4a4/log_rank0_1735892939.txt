[2025-01-03 08:28:59 root] (main_divide_blocks.py 274): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-chat-hf', cache_dir='./cache', output_dir='./log/Llama-2-7b-chat-hf-w4a4', save_dir='./quant/Llama-2-7b-chat-hf-w4a4', resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='', eval_ppl=False, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=10, let=False, lwc=False, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, error_threshold=0.1, similarity_threshold=0.8, sensitivity_threshold=0.5, max_block_size=3)
[2025-01-03 08:29:01 root] (main_divide_blocks.py 342): INFO === start quantization ===
[2025-01-03 08:29:01 root] (main_divide_blocks.py 348): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-01-03 08:29:01 root] (abq_llm_divide_blocks.py 61): INFO Starting ...
[2025-01-03 08:29:04 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 0 similarity and sensitivity ===
[2025-01-03 08:29:04 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000490830274023
[2025-01-03 08:29:04 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 1 similarity and sensitivity ===
[2025-01-03 08:29:05 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9365224923406329
[2025-01-03 08:29:06 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000876853581474
[2025-01-03 08:29:06 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 2 similarity and sensitivity ===
[2025-01-03 08:29:07 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.945068189076015
[2025-01-03 08:29:07 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5001003331313034
[2025-01-03 08:29:07 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 3 similarity and sensitivity ===
[2025-01-03 08:29:09 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.998047241142818
[2025-01-03 08:29:09 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000936197431889
[2025-01-03 08:29:09 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 4 similarity and sensitivity ===
[2025-01-03 08:29:11 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9985637324196952
[2025-01-03 08:29:11 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000983058270517
[2025-01-03 08:29:11 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 5 similarity and sensitivity ===
[2025-01-03 08:29:12 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9995886853763035
[2025-01-03 08:29:13 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5001007354179442
[2025-01-03 08:29:13 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 6 similarity and sensitivity ===
[2025-01-03 08:29:14 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9971630828721183
[2025-01-03 08:29:14 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000925191478373
[2025-01-03 08:29:14 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 7 similarity and sensitivity ===
[2025-01-03 08:29:16 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9999109166009086
[2025-01-03 08:29:16 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.500092061272256
[2025-01-03 08:29:16 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 8 similarity and sensitivity ===
[2025-01-03 08:29:18 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.999577522277832
[2025-01-03 08:29:18 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000937804594723
[2025-01-03 08:29:18 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 9 similarity and sensitivity ===
[2025-01-03 08:29:19 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9996087721415928
[2025-01-03 08:29:20 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000953864179264
[2025-01-03 08:29:20 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 10 similarity and sensitivity ===
[2025-01-03 08:29:22 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9998486042022705
[2025-01-03 08:29:22 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000956544574908
[2025-01-03 08:29:22 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 11 similarity and sensitivity ===
[2025-01-03 08:29:23 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.998076319694519
[2025-01-03 08:29:24 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.500091346161906
[2025-01-03 08:29:24 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 12 similarity and sensitivity ===
[2025-01-03 08:29:26 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9991021752357483
[2025-01-03 08:29:26 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000942837419642
[2025-01-03 08:29:26 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 13 similarity and sensitivity ===
[2025-01-03 08:29:28 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9995694586208889
[2025-01-03 08:29:28 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000943508495221
[2025-01-03 08:29:28 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 14 similarity and sensitivity ===
[2025-01-03 08:29:30 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.999871483870915
[2025-01-03 08:29:30 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000935940097908
[2025-01-03 08:29:30 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 15 similarity and sensitivity ===
[2025-01-03 08:29:32 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.999535356249128
[2025-01-03 08:29:32 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000947940224716
[2025-01-03 08:29:32 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 16 similarity and sensitivity ===
[2025-01-03 08:29:34 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.999412110873631
[2025-01-03 08:29:35 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000955214240426
[2025-01-03 08:29:35 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 17 similarity and sensitivity ===
[2025-01-03 08:29:36 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.999857519354139
[2025-01-03 08:29:37 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000947970663164
[2025-01-03 08:29:37 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 18 similarity and sensitivity ===
[2025-01-03 08:29:39 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9993765694754464
[2025-01-03 08:29:39 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000948428385326
[2025-01-03 08:29:39 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 19 similarity and sensitivity ===
[2025-01-03 08:29:41 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9998676010540554
[2025-01-03 08:29:41 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000943848607768
[2025-01-03 08:29:41 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 20 similarity and sensitivity ===
[2025-01-03 08:29:43 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9998610275132316
[2025-01-03 08:29:43 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000956644530451
[2025-01-03 08:29:43 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 21 similarity and sensitivity ===
[2025-01-03 08:29:45 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9996094107627869
[2025-01-03 08:29:45 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000950630099376
[2025-01-03 08:29:45 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 22 similarity and sensitivity ===
[2025-01-03 08:29:47 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9997915370123727
[2025-01-03 08:29:48 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000969061576352
[2025-01-03 08:29:48 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 23 similarity and sensitivity ===
[2025-01-03 08:29:49 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9992672204971313
[2025-01-03 08:29:50 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000987159477684
[2025-01-03 08:29:50 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 24 similarity and sensitivity ===
[2025-01-03 08:29:51 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9993519953319004
[2025-01-03 08:29:52 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000963136078269
[2025-01-03 08:29:52 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 25 similarity and sensitivity ===
[2025-01-03 08:29:53 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.999281815120152
[2025-01-03 08:29:53 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000990316092525
[2025-01-03 08:29:53 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 26 similarity and sensitivity ===
[2025-01-03 08:29:55 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9997429081371852
[2025-01-03 08:29:55 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5000993887073134
[2025-01-03 08:29:55 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 27 similarity and sensitivity ===
[2025-01-03 08:29:57 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.999108612537384
[2025-01-03 08:29:57 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5001025115819753
[2025-01-03 08:29:57 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 28 similarity and sensitivity ===
[2025-01-03 08:29:59 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9994618892669678
[2025-01-03 08:29:59 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5001025278984136
[2025-01-03 08:29:59 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 29 similarity and sensitivity ===
[2025-01-03 08:30:01 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9996175595692226
[2025-01-03 08:30:01 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5001015481187296
[2025-01-03 08:30:01 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 30 similarity and sensitivity ===
[2025-01-03 08:30:02 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9995589682034084
[2025-01-03 08:30:03 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5001045052855374
[2025-01-03 08:30:03 root] (abq_llm_divide_blocks.py 216): INFO === Start compute layer 31 similarity and sensitivity ===
[2025-01-03 08:30:04 quantize.utils_divide] (utils_divide.py 248): INFO Layer similarity: 0.9965078830718994
[2025-01-03 08:30:04 quantize.utils_divide] (utils_divide.py 299): INFO Hessian sensitivity: 0.5001033471263031
[2025-01-03 08:30:04 root] (abq_llm_divide_blocks.py 231): INFO === Start quantize layer 0 ===
