[2025-01-08 02:43:36 root] (main_quant_config.py 110): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-chat-hf', cache_dir='./cache', output_dir='./log/Llama-2-7b-chat-hf-w4a4', blocks_pkl='log/Llama-2-7b-chat-hf-w4a4/Llama-2-7b-chat-hf_blocks_temp.pkl', calib_dataset='wikitext2', nsamples=1, batch_size=1, seed=2, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, weight_quant_params={'per_channel_axes': [0], 'symmetric': False, 'dynamic_method': 'per_channel', 'disable_zero_point': False}, act_quant_params={'per_channel_axes': [], 'symmetric': False, 'dynamic_method': 'per_token'})
[2025-01-08 02:43:37 root] (main_quant_config.py 128): INFO load calibration from ./cache/dataloader_Llama_wikitext2_1.cache
[2025-01-08 02:43:38 root] (block_wise_quant_config_search.py 198): INFO searching quant config for block 0 from 0 to 1
