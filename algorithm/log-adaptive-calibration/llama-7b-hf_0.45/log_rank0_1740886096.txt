[2025-03-02 03:28:16 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.45', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.45.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 03:30:43 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-02 03:30:43 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.45.pkl
[2025-03-02 03:30:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 03:30:51 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.01566607505083084 norm:0.01546255499124527 max memory_allocated 22559.10693359375 
[2025-03-02 03:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.008089275099337101 norm:0.007394058164209127 max memory_allocated 22559.10693359375 
[2025-03-02 03:32:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.005638393573462963 norm:0.005097413435578346 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.004731139168143272 norm:0.003878810442984104 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.004418531898409128 norm:0.003346848301589489 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.004174042493104935 norm:0.002795068547129631 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.004032266326248646 norm:0.0024235984310507774 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.003957867156714201 norm:0.0021106929052621126 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.003872017143294215 norm:0.001918656867928803 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0038422271609306335 norm:0.0016921506030485034 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.003798640565946698 norm:0.0015536081045866013 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.003781405743211508 norm:0.0013654560316354036 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0037886309437453747 norm:0.0012594888685271144 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0037520979531109333 norm:0.0011357157491147518 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0037366850301623344 norm:0.0010142023675143719 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0036891575437039137 norm:0.000929995730984956 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0036678696051239967 norm:0.0008343902882188559 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.003680286929011345 norm:0.0008289053803309798 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.003676003310829401 norm:0.0007902025827206671 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0036663454957306385 norm:0.0007288395427167416 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 03:42:23 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:42:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.030425820499658585 norm:0.02054668590426445 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.01724608987569809 norm:0.012631464749574661 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.012534799054265022 norm:0.007317634765058756 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.011239626444876194 norm:0.005423023831099272 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.01076456718146801 norm:0.004674473777413368 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.010416341945528984 norm:0.004306318238377571 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.010169617831707 norm:0.0037719388492405415 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.009942719712853432 norm:0.0034582100342959166 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.009802112355828285 norm:0.003222075290977955 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.009688762947916985 norm:0.002987861866131425 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.009628570638597012 norm:0.0027274712920188904 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.009520270861685276 norm:0.0024679163470864296 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.009438392706215382 norm:0.002266043797135353 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.009392942301928997 norm:0.0020358830224722624 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.009359114803373814 norm:0.0018159133614972234 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.009340879507362843 norm:0.0016407829243689775 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.009307889267802238 norm:0.0014722583582624793 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.00929558277130127 norm:0.0013563033426180482 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.009313702583312988 norm:0.0013734770473092794 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.00934615172445774 norm:0.0014339085901156068 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 03:53:57 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:54:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.12865088880062103 norm:0.022191816940903664 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.08196783065795898 norm:0.020994389429688454 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.0666310116648674 norm:0.01872330904006958 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.06026456132531166 norm:0.020623285323381424 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.0572749488055706 norm:0.016434358432888985 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.05553147941827774 norm:0.013749132864177227 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.05417190492153168 norm:0.01285718847066164 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.0534290112555027 norm:0.011676938273012638 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.052861109375953674 norm:0.010936816222965717 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.052421871572732925 norm:0.010418483056128025 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.052430033683776855 norm:0.010360583662986755 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.052313532680273056 norm:0.009855428710579872 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.05221683531999588 norm:0.009624699130654335 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.05212559178471565 norm:0.009115603752434254 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.052373532205820084 norm:0.009045220911502838 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.05220671743154526 norm:0.008886126801371574 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.05197424814105034 norm:0.009037979878485203 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.05168287828564644 norm:0.008802076801657677 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.0513780415058136 norm:0.008587594144046307 max memory_allocated 22559.45068359375 
[2025-03-02 04:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.05149155482649803 norm:0.00850752554833889 max memory_allocated 22559.45068359375 
[2025-03-02 04:05:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.05709855258464813 norm:0.006659250240772963 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.04420909658074379 norm:0.0023743310011923313 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.03875422477722168 norm:0.0011727360542863607 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.0367291122674942 norm:0.0006315677892416716 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.035704728215932846 norm:0.0004131616442464292 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.035163573920726776 norm:0.0002931115450337529 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.034929823130369186 norm:0.0002476383524481207 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.03482562676072121 norm:0.00021952236420474946 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.03479402884840965 norm:0.00021154707064852118 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.0347958579659462 norm:0.00021028750052209944 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.03472945839166641 norm:0.000202521841856651 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.03471609205007553 norm:0.0002051916380878538 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.03470136225223541 norm:0.00019029331451747566 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.03469723463058472 norm:0.00018540385644882917 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.03468651324510574 norm:0.0001859514886746183 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.03467680513858795 norm:0.00018481063307262957 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.034667253494262695 norm:0.0001890702551463619 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.03466351330280304 norm:0.00018554343841969967 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.0346803292632103 norm:0.00018021299911197275 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.03467739000916481 norm:0.00018627755343914032 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 04:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.06876164674758911 norm:0.006164950784295797 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.052754685282707214 norm:0.002451490145176649 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.04526713863015175 norm:0.0012107206275686622 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:15 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.04241171106696129 norm:0.0006673592142760754 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.04107719659805298 norm:0.0004282777081243694 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.04049806296825409 norm:0.00034066743683069944 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.04026179388165474 norm:0.00031386996852234006 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.0401233434677124 norm:0.0002877184597309679 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.040023431181907654 norm:0.0002791839942801744 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.039959922432899475 norm:0.00027125520864501595 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.03994100168347359 norm:0.0002788125129882246 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.039904333651065826 norm:0.0002723527722992003 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.03992435336112976 norm:0.00025919178733602166 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.03989499807357788 norm:0.0002580984146334231 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.039851389825344086 norm:0.00025953137082979083 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.039820075035095215 norm:0.0002565092290751636 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.03980087488889694 norm:0.0002585800248198211 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.03981183096766472 norm:0.00025755821843631566 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.03980467468500137 norm:0.00026073597837239504 max memory_allocated 22559.67919921875 
[2025-03-02 04:28:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.03982912003993988 norm:0.0002551423676777631 max memory_allocated 22559.67919921875 
[2025-03-02 04:28:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 04:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.07421454787254333 norm:0.006375996395945549 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.05736279487609863 norm:0.002725460799410939 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.04939354583621025 norm:0.0014221774181351066 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.04620436206459999 norm:0.0008143620216287673 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.04461691901087761 norm:0.0004940500948578119 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.043874919414520264 norm:0.0003545361978467554 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.043589312583208084 norm:0.0003023015451617539 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.04341530799865723 norm:0.00027679908089339733 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.04326614364981651 norm:0.00025941466446965933 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.04318275302648544 norm:0.0002498893009033054 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.04308897629380226 norm:0.0002498749818187207 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.04299701377749443 norm:0.00024406742886640131 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.04294678941369057 norm:0.00023702757607679814 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.042912598699331284 norm:0.0002451393520459533 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.04291507974267006 norm:0.0002473228960298002 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.04290756955742836 norm:0.00024212052812799811 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:08 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.04290153086185455 norm:0.00024059896531980485 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.04289401322603226 norm:0.0002442602126393467 max memory_allocated 22559.85107421875 
[2025-03-02 04:39:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.04290357977151871 norm:0.00024051641230471432 max memory_allocated 22559.85107421875 
[2025-03-02 04:39:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.042913127690553665 norm:0.00023107208835426718 max memory_allocated 22559.85107421875 
[2025-03-02 04:39:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 04:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.07371755689382553 norm:0.0057869041338562965 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.0586942620575428 norm:0.0015655475435778499 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.05179945379495621 norm:0.0007296387921087444 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.04936455562710762 norm:0.000449812738224864 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.04814489185810089 norm:0.0003329683095216751 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.04755473881959915 norm:0.0002899041282944381 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.047271717339754105 norm:0.00025592889869585633 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:33 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.04712902382016182 norm:0.00025425414787605405 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.047096315771341324 norm:0.0002881641557905823 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.047032877802848816 norm:0.0002422753896098584 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.04692167788743973 norm:0.00022977837943471968 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.046847764402627945 norm:0.0002253248676424846 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.04681738093495369 norm:0.00021941662998870015 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.04679928719997406 norm:0.00021936610573902726 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.0467623695731163 norm:0.0002257185842609033 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.04676220938563347 norm:0.0002355087490286678 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.04674884304404259 norm:0.0002285233058501035 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.04674183949828148 norm:0.00023317680461332202 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.046739522367715836 norm:0.00023382862855214626 max memory_allocated 22560.02294921875 
[2025-03-02 04:51:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.046717774122953415 norm:0.00022668758174404502 max memory_allocated 22560.02294921875 
[2025-03-02 04:51:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 04:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.07931552827358246 norm:0.003879522904753685 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.06441627442836761 norm:0.0016857176087796688 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.05712032690644264 norm:0.0009289283188991249 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.05435425043106079 norm:0.0005753031000494957 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.053000833839178085 norm:0.000391996989492327 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.05239391699433327 norm:0.00032545364229008555 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.052145443856716156 norm:0.0002960984711535275 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.05196493864059448 norm:0.0002634977863635868 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.05192089453339577 norm:0.0002760869392659515 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.05179290100932121 norm:0.0002293614816153422 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.05176233872771263 norm:0.00022868806263431907 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.051750749349594116 norm:0.00022436946164816618 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.05177163705229759 norm:0.00021943729370832443 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.051691196858882904 norm:0.000217705121031031 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.051684312522411346 norm:0.0002227121585747227 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.05163533240556717 norm:0.0002168388746213168 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.05161547660827637 norm:0.00021670937712769955 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.05159781873226166 norm:0.0002121259312843904 max memory_allocated 22560.19482421875 
[2025-03-02 05:02:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.051598284393548965 norm:0.00021189198014326394 max memory_allocated 22560.19482421875 
[2025-03-02 05:02:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.05158861353993416 norm:0.00020906519785057753 max memory_allocated 22560.19482421875 
[2025-03-02 05:03:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:03:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.0839962288737297 norm:0.00307636009529233 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.0683198869228363 norm:0.001152134733274579 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.06063452363014221 norm:0.0005798903293907642 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.05790628492832184 norm:0.0003691950114443898 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.056550249457359314 norm:0.0002790360013023019 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.05592476949095726 norm:0.00023863509704824537 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.05558228865265846 norm:0.0002231523540103808 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.055406272411346436 norm:0.00020852554007433355 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.05534395948052406 norm:0.00021883462613914162 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.05525345727801323 norm:0.00020265764032956213 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.055181365460157394 norm:0.0002008576411753893 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.055114876478910446 norm:0.00019327481277287006 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.05505285784602165 norm:0.0001911620347527787 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.0550689660012722 norm:0.00021559919696301222 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.0550617016851902 norm:0.0002013412886299193 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.055054761469364166 norm:0.00020758702885359526 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.055147685110569 norm:0.00021216404275037348 max memory_allocated 22560.36669921875 
[2025-03-02 05:13:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.055083468556404114 norm:0.00019034820434171706 max memory_allocated 22560.36669921875 
[2025-03-02 05:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.05505700036883354 norm:0.00018641722272150218 max memory_allocated 22560.36669921875 
[2025-03-02 05:14:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.055090345442295074 norm:0.0001935073232743889 max memory_allocated 22560.36669921875 
[2025-03-02 05:14:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 05:15:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.09036961197853088 norm:0.00325253838673234 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.07380510121583939 norm:0.001404914422892034 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.06581983715295792 norm:0.0007451152778230608 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.06287209689617157 norm:0.00046404346358031034 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.06147090345621109 norm:0.00033521949080750346 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.06078309565782547 norm:0.000278030289337039 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.060388192534446716 norm:0.000243800095631741 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.06023363023996353 norm:0.000231294019613415 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.060100290924310684 norm:0.00021266414842102677 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.05999760702252388 norm:0.00020389108976814896 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.05989692360162735 norm:0.00019424488709773868 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.05982990935444832 norm:0.00019502466602716595 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.05984616279602051 norm:0.00021340878447517753 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.059773288667201996 norm:0.00019370847439859062 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.05974624678492546 norm:0.00019273815269116312 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.05972018092870712 norm:0.0001931688457261771 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.05968809872865677 norm:0.00019130347936879843 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.05970477685332298 norm:0.00019676097144838423 max memory_allocated 22560.53857421875 
[2025-03-02 05:25:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.059686023741960526 norm:0.00019266510207671672 max memory_allocated 22560.53857421875 
[2025-03-02 05:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.05968865752220154 norm:0.00019126501865684986 max memory_allocated 22560.53857421875 
[2025-03-02 05:26:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 05:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.08727838099002838 norm:0.002510634483769536 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.0754159614443779 norm:0.0010567144490778446 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.06836526095867157 norm:0.0005377679481171072 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.06569293141365051 norm:0.00034849485382437706 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.06453874707221985 norm:0.0002603861503303051 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.06401832401752472 norm:0.00021882551664020866 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.063730388879776 norm:0.0001894001616165042 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.06361718475818634 norm:0.00017501620459370315 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.06356793642044067 norm:0.00016692132339812815 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.06347579509019852 norm:0.0001612472115084529 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.06345245242118835 norm:0.0001640902628423646 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.06339873373508453 norm:0.00015728997823316604 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.06340570747852325 norm:0.0001579348900122568 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.06340126693248749 norm:0.00015608020476065576 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.0634172335267067 norm:0.00015820635599084198 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.06340889632701874 norm:0.000153853849042207 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.0634075477719307 norm:0.0001544952974654734 max memory_allocated 22560.71044921875 
[2025-03-02 05:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.06341110914945602 norm:0.0001546261482872069 max memory_allocated 22560.71044921875 
[2025-03-02 05:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.06341743469238281 norm:0.00015446411271113902 max memory_allocated 22560.71044921875 
[2025-03-02 05:37:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.06340474635362625 norm:0.0001572702603880316 max memory_allocated 22560.71044921875 
[2025-03-02 05:37:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 05:38:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.09216146916151047 norm:0.0032337289303541183 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.07889236509799957 norm:0.0012787508312612772 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.07121776044368744 norm:0.0006332355551421642 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.06853527575731277 norm:0.0003897697024513036 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.06734809279441833 norm:0.0002784630923997611 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.06677078455686569 norm:0.00023423184757120907 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.06648878753185272 norm:0.00020435958867892623 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.06631176173686981 norm:0.00018672648002393544 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.06621360033750534 norm:0.00018074960098601878 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.06615328043699265 norm:0.00018098346481565386 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.0660991445183754 norm:0.00016882513591554016 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.06605377793312073 norm:0.00017027162539307028 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.06604316085577011 norm:0.00016929314006119967 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.06599466502666473 norm:0.00016559970390517265 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.06598159670829773 norm:0.00016170127491932362 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.06597040593624115 norm:0.00015956703282427043 max memory_allocated 22560.88232421875 
[2025-03-02 05:47:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.06596821546554565 norm:0.0001625561562832445 max memory_allocated 22560.88232421875 
[2025-03-02 05:47:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.0659671276807785 norm:0.00016052517457865179 max memory_allocated 22560.88232421875 
[2025-03-02 05:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.0659450814127922 norm:0.00016155651246663183 max memory_allocated 22560.88232421875 
[2025-03-02 05:48:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.06592752784490585 norm:0.00016013445565477014 max memory_allocated 22560.88232421875 
[2025-03-02 05:49:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 05:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.0908237099647522 norm:0.0017251147655770183 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.08036822080612183 norm:0.0007628316525369883 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.0736641064286232 norm:0.0004218564718030393 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.07117582857608795 norm:0.0002891699259635061 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.06994829326868057 norm:0.00023110168694984168 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.06934397667646408 norm:0.0002048166934400797 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.06906285881996155 norm:0.0001891289430204779 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.06886272877454758 norm:0.00017014463082887232 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.06873977184295654 norm:0.00016533488815184683 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.06865205615758896 norm:0.00016030960250645876 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.0685969814658165 norm:0.00015971477841958404 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.06853879988193512 norm:0.0001518536446383223 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.0685332641005516 norm:0.0001520001096650958 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.06850573420524597 norm:0.0001502390659879893 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.06847354769706726 norm:0.00014939229004085064 max memory_allocated 22561.05419921875 
[2025-03-02 05:58:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.06843996793031693 norm:0.00014833138266112655 max memory_allocated 22561.05419921875 
[2025-03-02 05:58:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.06842759251594543 norm:0.0001456827303627506 max memory_allocated 22561.05419921875 
[2025-03-02 05:59:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.06843572109937668 norm:0.0001481552462792024 max memory_allocated 22561.05419921875 
[2025-03-02 05:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.06844395399093628 norm:0.00014736922457814217 max memory_allocated 22561.05419921875 
[2025-03-02 06:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.06843216717243195 norm:0.00014682431356050074 max memory_allocated 22561.05419921875 
[2025-03-02 06:00:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 06:01:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.09184318780899048 norm:0.0016992961755022407 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.08188992738723755 norm:0.0007094907923601568 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.07599446177482605 norm:0.00040560984052717686 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.07373198121786118 norm:0.00028292989009059966 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.07256791740655899 norm:0.00021799984097015113 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:05 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.07195613533258438 norm:0.00019037575111724436 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.07165423780679703 norm:0.00017212766397278756 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.0714951604604721 norm:0.00015879154670983553 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.07138046622276306 norm:0.00015506020281463861 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:21 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.07131942361593246 norm:0.00014708633534610271 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.07128186523914337 norm:0.000145043755765073 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.07124073058366776 norm:0.00014233494584914297 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.07118852436542511 norm:0.00014096792438067496 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.0711432471871376 norm:0.00014092626224737614 max memory_allocated 22561.22607421875 
[2025-03-02 06:09:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.07110586762428284 norm:0.0001388618111377582 max memory_allocated 22561.22607421875 
[2025-03-02 06:09:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.07109317928552628 norm:0.00013988146383780986 max memory_allocated 22561.22607421875 
[2025-03-02 06:10:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.07111852616071701 norm:0.00014118033868726343 max memory_allocated 22561.22607421875 
[2025-03-02 06:10:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.07108938694000244 norm:0.00013968082203064114 max memory_allocated 22561.22607421875 
[2025-03-02 06:11:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.07108192890882492 norm:0.00014401893713511527 max memory_allocated 22561.22607421875 
[2025-03-02 06:12:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.07110461592674255 norm:0.0001470831921324134 max memory_allocated 22561.22607421875 
[2025-03-02 06:12:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.10097510367631912 norm:0.0028195383492857218 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.08878887444734573 norm:0.0012413995573297143 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.08146405965089798 norm:0.0006812587380409241 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.07881029695272446 norm:0.000439528317656368 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.07752980291843414 norm:0.0003188300470355898 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:36 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.07688702642917633 norm:0.0002564572496339679 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.07659068703651428 norm:0.0002238021115772426 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.07643307000398636 norm:0.00020354631124064326 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.07629900425672531 norm:0.00018708858988247812 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.0762079507112503 norm:0.0001763097825460136 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.07617875933647156 norm:0.0001703510497463867 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.07613241672515869 norm:0.0001648667239351198 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.0760766789317131 norm:0.00016038956528063864 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.07605151832103729 norm:0.00016214445349760354 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.07603846490383148 norm:0.00016034074360504746 max memory_allocated 22561.39794921875 
[2025-03-02 06:21:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.07601001858711243 norm:0.00015795623767189682 max memory_allocated 22561.39794921875 
[2025-03-02 06:21:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.07598885148763657 norm:0.00015463160525541753 max memory_allocated 22561.39794921875 
[2025-03-02 06:22:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.0759584903717041 norm:0.00015342455299105495 max memory_allocated 22561.39794921875 
[2025-03-02 06:22:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.07595247030258179 norm:0.00015469036588910967 max memory_allocated 22561.39794921875 
[2025-03-02 06:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.07594034820795059 norm:0.00015480050933547318 max memory_allocated 22561.39794921875 
[2025-03-02 06:23:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 06:24:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.10192789882421494 norm:0.0018324254779145122 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.09221965074539185 norm:0.0008060833788476884 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.08552346378564835 norm:0.0004396362928673625 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.0831819474697113 norm:0.0003026260528713465 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.08206653594970703 norm:0.00023577173124067485 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.08155667036771774 norm:0.0001975930790649727 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.0812733918428421 norm:0.00017347831453662366 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.08108589798212051 norm:0.00016242885612882674 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.081052266061306 norm:0.00017239476437680423 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.0809757187962532 norm:0.00015812883793842047 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.08090391755104065 norm:0.00014915842621121556 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.08088479936122894 norm:0.00015436450485140085 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.08084703981876373 norm:0.0001503436069469899 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:39 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.08081043511629105 norm:0.0001500104699516669 max memory_allocated 22561.56982421875 
[2025-03-02 06:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.08074928820133209 norm:0.00014683074550703168 max memory_allocated 22561.56982421875 
[2025-03-02 06:32:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.0807267501950264 norm:0.00014581714640371501 max memory_allocated 22561.56982421875 
[2025-03-02 06:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.08071586489677429 norm:0.00014302958152256906 max memory_allocated 22561.56982421875 
[2025-03-02 06:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.08069527894258499 norm:0.00014400975487660617 max memory_allocated 22561.56982421875 
[2025-03-02 06:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.08068931847810745 norm:0.00014690369425807148 max memory_allocated 22561.56982421875 
[2025-03-02 06:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.08066807687282562 norm:0.00014596169057767838 max memory_allocated 22561.56982421875 
[2025-03-02 06:35:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 06:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.11242339015007019 norm:0.002317733597010374 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.10061662644147873 norm:0.0008791661821305752 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.09313489496707916 norm:0.00046600683708675206 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.09070413559675217 norm:0.0003334881621412933 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.08945699036121368 norm:0.00027906408649869263 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.08882007002830505 norm:0.00022988012642599642 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.08847901225090027 norm:0.0002026977454079315 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.08828577399253845 norm:0.00019283944857306778 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.08813691139221191 norm:0.0001802469341782853 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.08807015419006348 norm:0.00017608885536901653 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.08802850544452667 norm:0.000171394000062719 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.08796479552984238 norm:0.00016475583834107965 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.08789563179016113 norm:0.00016300863353535533 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.0878349170088768 norm:0.0001563421101309359 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.08779198676347733 norm:0.00015476231055799872 max memory_allocated 22561.74169921875 
[2025-03-02 06:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.0877460390329361 norm:0.00015247013652697206 max memory_allocated 22561.74169921875 
[2025-03-02 06:44:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.08768400549888611 norm:0.0001554086193209514 max memory_allocated 22561.74169921875 
[2025-03-02 06:45:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.0876593142747879 norm:0.0001508548593847081 max memory_allocated 22561.74169921875 
[2025-03-02 06:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.08768294006586075 norm:0.00015205364616122097 max memory_allocated 22561.74169921875 
[2025-03-02 06:46:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.08765120804309845 norm:0.00015114378766156733 max memory_allocated 22561.74169921875 
[2025-03-02 06:46:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 06:47:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.12491700053215027 norm:0.002870303113013506 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.11205276101827621 norm:0.0011863142717629671 max memory_allocated 22561.91357421875 
[2025-03-02 06:48:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.10362236201763153 norm:0.0006555111031048 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.10084964334964752 norm:0.0004281388537492603 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.09952428191900253 norm:0.00032153454958461225 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.09895331412553787 norm:0.0002700576442293823 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.09865635633468628 norm:0.0002338351187063381 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.09845708310604095 norm:0.00021226743410807103 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.09831207990646362 norm:0.00019531973521225154 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.0982062965631485 norm:0.00018826274026650935 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.09815187752246857 norm:0.00018380259280093014 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.0980789065361023 norm:0.0001788683293852955 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.09799536317586899 norm:0.00017052656039595604 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.09794861823320389 norm:0.00016861017502378672 max memory_allocated 22561.91357421875 
[2025-03-02 06:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.09789614379405975 norm:0.0001668447075644508 max memory_allocated 22561.91357421875 
[2025-03-02 06:55:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.09786369651556015 norm:0.000166572310263291 max memory_allocated 22561.91357421875 
[2025-03-02 06:56:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.09784682095050812 norm:0.00016694818623363972 max memory_allocated 22561.91357421875 
[2025-03-02 06:56:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.0978161096572876 norm:0.00016452823183499277 max memory_allocated 22561.91357421875 
[2025-03-02 06:57:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.097791388630867 norm:0.00016437105659861118 max memory_allocated 22561.91357421875 
[2025-03-02 06:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.09776583313941956 norm:0.00016296074318233877 max memory_allocated 22561.91357421875 
[2025-03-02 06:58:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 06:58:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.13526396453380585 norm:0.0016291877254843712 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.12424061447381973 norm:0.00071590521838516 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.11637399345636368 norm:0.00042514633969403803 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.11383496224880219 norm:0.0003134384169243276 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.11267358809709549 norm:0.0002583530149422586 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.1122259646654129 norm:0.00022953121515456587 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.11195746064186096 norm:0.00020864080579485744 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.11176379024982452 norm:0.00019928609253838658 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.11164813488721848 norm:0.00018659027409739792 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.11154352128505707 norm:0.00017940714315045625 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.11145569384098053 norm:0.0001744670735206455 max memory_allocated 22562.08544921875 
[2025-03-02 07:05:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.11134828627109528 norm:0.00016984609828796238 max memory_allocated 22562.08544921875 
[2025-03-02 07:05:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.11127853393554688 norm:0.0001670163474045694 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.11122981458902359 norm:0.0001636728848097846 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.11119654774665833 norm:0.00016189331654459238 max memory_allocated 22562.08544921875 
[2025-03-02 07:07:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.11114002764225006 norm:0.00016168745059985667 max memory_allocated 22562.08544921875 
[2025-03-02 07:07:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.11115923523902893 norm:0.00016420304018538445 max memory_allocated 22562.08544921875 
[2025-03-02 07:08:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.11114567518234253 norm:0.00016264923033304513 max memory_allocated 22562.08544921875 
[2025-03-02 07:09:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.11109073460102081 norm:0.00015899463323876262 max memory_allocated 22562.08544921875 
[2025-03-02 07:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.11105737835168839 norm:0.00015796153456903994 max memory_allocated 22562.08544921875 
[2025-03-02 07:09:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:10:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.1532624214887619 norm:0.001823124010115862 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.14222896099090576 norm:0.0008323097135871649 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.13389937579631805 norm:0.0004589514574036002 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.1312292367219925 norm:0.0003420114517211914 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.13002896308898926 norm:0.0002770649443846196 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.1295701563358307 norm:0.00024609779939055443 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.12933605909347534 norm:0.0002314936282346025 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.1290881186723709 norm:0.00020914303604513407 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.1288878619670868 norm:0.00019846523355226964 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.12879252433776855 norm:0.0001954669423867017 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.1286952942609787 norm:0.00019183935364708304 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.1286059319972992 norm:0.0001896215253509581 max memory_allocated 22562.25732421875 
[2025-03-02 07:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.12857018411159515 norm:0.00018673924205359071 max memory_allocated 22562.25732421875 
[2025-03-02 07:17:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.12850895524024963 norm:0.00018212408758699894 max memory_allocated 22562.25732421875 
[2025-03-02 07:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.12845847010612488 norm:0.00018137332517653704 max memory_allocated 22562.25732421875 
[2025-03-02 07:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.12838295102119446 norm:0.000177999580046162 max memory_allocated 22562.25732421875 
[2025-03-02 07:19:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.12832899391651154 norm:0.0001766008062986657 max memory_allocated 22562.25732421875 
[2025-03-02 07:19:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.1282867044210434 norm:0.00017556175589561462 max memory_allocated 22562.25732421875 
[2025-03-02 07:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.12829025089740753 norm:0.00017522853158880025 max memory_allocated 22562.25732421875 
[2025-03-02 07:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.128264918923378 norm:0.0001758661528583616 max memory_allocated 22562.25732421875 
[2025-03-02 07:21:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 07:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.185407817363739 norm:0.004097583703696728 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.1697983741760254 norm:0.0014961976557970047 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.1591290682554245 norm:0.0007777173304930329 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.15586239099502563 norm:0.0005795009201392531 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.1544988751411438 norm:0.0004926268011331558 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.15388257801532745 norm:0.0004014155128970742 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.15351949632167816 norm:0.00038564158603549004 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.15325552225112915 norm:0.0003220615617465228 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.15295013785362244 norm:0.00030423124553635716 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.15273532271385193 norm:0.0002801437512971461 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.15258875489234924 norm:0.00027371960459277034 max memory_allocated 22562.42919921875 
[2025-03-02 07:28:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.15245455503463745 norm:0.0002588926872704178 max memory_allocated 22562.42919921875 
[2025-03-02 07:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.15236739814281464 norm:0.0002455248904880136 max memory_allocated 22562.42919921875 
[2025-03-02 07:29:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.1522546261548996 norm:0.000243368063820526 max memory_allocated 22562.42919921875 
[2025-03-02 07:29:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.15219245851039886 norm:0.00024403995485045016 max memory_allocated 22562.42919921875 
[2025-03-02 07:30:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.15208518505096436 norm:0.00024221700732596219 max memory_allocated 22562.42919921875 
[2025-03-02 07:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.15202179551124573 norm:0.00023925914138089865 max memory_allocated 22562.42919921875 
[2025-03-02 07:31:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.15194076299667358 norm:0.0002397505595581606 max memory_allocated 22562.42919921875 
[2025-03-02 07:32:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.15198130905628204 norm:0.00024070555809885263 max memory_allocated 22562.42919921875 
[2025-03-02 07:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.15205547213554382 norm:0.00025060452753677964 max memory_allocated 22562.42919921875 
[2025-03-02 07:32:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 07:33:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.20989370346069336 norm:0.0013388716615736485 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.19727453589439392 norm:0.0006780751282349229 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.18692009150981903 norm:0.0004874425067100674 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.18392321467399597 norm:0.0004313139943405986 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.1823936253786087 norm:0.00035915334592573345 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.18192067742347717 norm:0.00032321340404450893 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.18168410658836365 norm:0.00035423520603217185 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.18133336305618286 norm:0.00029955149511806667 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.1810106784105301 norm:0.0002836694766301662 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.18083055317401886 norm:0.00027452342328615487 max memory_allocated 22562.60107421875 
[2025-03-02 07:39:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.1806684285402298 norm:0.00028770280187018216 max memory_allocated 22562.60107421875 
[2025-03-02 07:39:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.18052855134010315 norm:0.00028367829509079456 max memory_allocated 22562.60107421875 
[2025-03-02 07:40:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.18042545020580292 norm:0.00027412580675445497 max memory_allocated 22562.60107421875 
[2025-03-02 07:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.18028491735458374 norm:0.00028594795730896294 max memory_allocated 22562.60107421875 
[2025-03-02 07:41:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.18018856644630432 norm:0.00026992082712240517 max memory_allocated 22562.60107421875 
[2025-03-02 07:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.18017636239528656 norm:0.0002934671938419342 max memory_allocated 22562.60107421875 
[2025-03-02 07:42:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.1801215559244156 norm:0.0002684770443011075 max memory_allocated 22562.60107421875 
[2025-03-02 07:43:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.18002931773662567 norm:0.00027153216069564223 max memory_allocated 22562.60107421875 
[2025-03-02 07:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.179952934384346 norm:0.0003082346520386636 max memory_allocated 22562.60107421875 
[2025-03-02 07:44:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.17990481853485107 norm:0.0002734420704655349 max memory_allocated 22562.60107421875 
[2025-03-02 07:44:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 07:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.24368031322956085 norm:0.0029372586868703365 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.22895218431949615 norm:0.001445346511900425 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.21741372346878052 norm:0.0008623010944575071 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.21389833092689514 norm:0.0006077464786358178 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.21258462965488434 norm:0.0004761431773658842 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.21199214458465576 norm:0.0003958874149248004 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.21155479550361633 norm:0.00035008019767701626 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.21129775047302246 norm:0.00031308733741752803 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.21102409064769745 norm:0.00029540949617512524 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.21087144315242767 norm:0.0002934131189249456 max memory_allocated 22562.77294921875 
[2025-03-02 07:50:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.21074186265468597 norm:0.00027733948081731796 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.21055485308170319 norm:0.0002734966401476413 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.21049362421035767 norm:0.0002689574030227959 max memory_allocated 22562.77294921875 
[2025-03-02 07:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.21037137508392334 norm:0.0002640201128087938 max memory_allocated 22562.77294921875 
[2025-03-02 07:52:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.210297092795372 norm:0.0002631800016388297 max memory_allocated 22562.77294921875 
[2025-03-02 07:53:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.21020576357841492 norm:0.0002561812289059162 max memory_allocated 22562.77294921875 
[2025-03-02 07:53:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.21008163690567017 norm:0.0002634839038364589 max memory_allocated 22562.77294921875 
[2025-03-02 07:54:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.20999500155448914 norm:0.00025875208666548133 max memory_allocated 22562.77294921875 
[2025-03-02 07:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.20998884737491608 norm:0.00025769678177312016 max memory_allocated 22562.77294921875 
[2025-03-02 07:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.2099114954471588 norm:0.0002556850959081203 max memory_allocated 22562.77294921875 
[2025-03-02 07:55:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 07:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.28251728415489197 norm:0.003927616402506828 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.26702558994293213 norm:0.00201575830578804 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.25473570823669434 norm:0.0012091423850506544 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.250879168510437 norm:0.00083291030023247 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.24944907426834106 norm:0.0006286223069764674 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.24875204265117645 norm:0.0005063780699856579 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.24834759533405304 norm:0.00043749608448706567 max memory_allocated 22562.94482421875 
[2025-03-02 08:00:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.24798831343650818 norm:0.000397348718252033 max memory_allocated 22562.94482421875 
[2025-03-02 08:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.24775825440883636 norm:0.0003598564362619072 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.2475230097770691 norm:0.000336435652570799 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.24736708402633667 norm:0.0003201762738171965 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.24723966419696808 norm:0.0003095338470302522 max memory_allocated 22562.94482421875 
[2025-03-02 08:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.24708229303359985 norm:0.0002993535890709609 max memory_allocated 22562.94482421875 
[2025-03-02 08:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.24694961309432983 norm:0.000300779240205884 max memory_allocated 22562.94482421875 
[2025-03-02 08:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.2468387484550476 norm:0.00030227669049054384 max memory_allocated 22562.94482421875 
[2025-03-02 08:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.24675513803958893 norm:0.0002936838718596846 max memory_allocated 22562.94482421875 
[2025-03-02 08:05:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.24666902422904968 norm:0.0002972767106257379 max memory_allocated 22562.94482421875 
[2025-03-02 08:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.24660325050354004 norm:0.000293655350105837 max memory_allocated 22562.94482421875 
[2025-03-02 08:06:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.24653440713882446 norm:0.0002890111645683646 max memory_allocated 22562.94482421875 
[2025-03-02 08:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.24649105966091156 norm:0.0002899426908697933 max memory_allocated 22562.94482421875 
[2025-03-02 08:07:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.32112637162208557 norm:0.0025210564490407705 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.3061819076538086 norm:0.0013688639737665653 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.29207944869995117 norm:0.0007354115368798375 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.28794917464256287 norm:0.0005389630678109825 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.28671565651893616 norm:0.0004468421684578061 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.28625497221946716 norm:0.000400905089918524 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.28593143820762634 norm:0.00035417565959505737 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.28561487793922424 norm:0.0003320906253065914 max memory_allocated 22563.11669921875 
[2025-03-02 08:12:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.28539854288101196 norm:0.0003193969023413956 max memory_allocated 22563.11669921875 
[2025-03-02 08:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.2851787507534027 norm:0.0003086737706325948 max memory_allocated 22563.11669921875 
[2025-03-02 08:13:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.285007119178772 norm:0.0002953390358015895 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.28486666083335876 norm:0.0002884527202695608 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.2847161889076233 norm:0.00028507571551017463 max memory_allocated 22563.11669921875 
[2025-03-02 08:15:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.28465890884399414 norm:0.0002844481496140361 max memory_allocated 22563.11669921875 
[2025-03-02 08:15:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.28454551100730896 norm:0.000281932094367221 max memory_allocated 22563.11669921875 
[2025-03-02 08:16:25 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.2844166159629822 norm:0.0002776413457468152 max memory_allocated 22563.11669921875 
[2025-03-02 08:16:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.2843400537967682 norm:0.0002767322293948382 max memory_allocated 22563.11669921875 
[2025-03-02 08:17:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.28428980708122253 norm:0.0002756203757598996 max memory_allocated 22563.11669921875 
[2025-03-02 08:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.2842230796813965 norm:0.0002779322676360607 max memory_allocated 22563.11669921875 
[2025-03-02 08:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.2841704189777374 norm:0.00027465115999802947 max memory_allocated 22563.11669921875 
[2025-03-02 08:18:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 08:19:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.3665348291397095 norm:0.003000665456056595 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.3503548204898834 norm:0.0016309272032231092 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.3359551429748535 norm:0.0010025659576058388 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.3317407965660095 norm:0.0007160077802836895 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.3304903209209442 norm:0.0005525001906789839 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.3299958109855652 norm:0.00046661420492455363 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.3296870291233063 norm:0.00039900781121104956 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.32939568161964417 norm:0.00035717111313715577 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.3291219174861908 norm:0.0003264986153226346 max memory_allocated 22563.28857421875 
[2025-03-02 08:24:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.3289414644241333 norm:0.0003129662945866585 max memory_allocated 22563.28857421875 
[2025-03-02 08:25:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.328779399394989 norm:0.0002950328344013542 max memory_allocated 22563.28857421875 
[2025-03-02 08:25:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.328656405210495 norm:0.00028863968327641487 max memory_allocated 22563.28857421875 
[2025-03-02 08:26:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.3284560739994049 norm:0.00028142883093096316 max memory_allocated 22563.28857421875 
[2025-03-02 08:26:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.3283415734767914 norm:0.00027704989770427346 max memory_allocated 22563.28857421875 
[2025-03-02 08:27:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.32821205258369446 norm:0.0002766211691778153 max memory_allocated 22563.28857421875 
[2025-03-02 08:27:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.3280908167362213 norm:0.000276049948297441 max memory_allocated 22563.28857421875 
[2025-03-02 08:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.3280283808708191 norm:0.0002729679399635643 max memory_allocated 22563.28857421875 
[2025-03-02 08:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.32794350385665894 norm:0.0002707589592318982 max memory_allocated 22563.28857421875 
[2025-03-02 08:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.32785600423812866 norm:0.0002693524584174156 max memory_allocated 22563.28857421875 
[2025-03-02 08:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.32781246304512024 norm:0.00026849255664274096 max memory_allocated 22563.28857421875 
[2025-03-02 08:30:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 08:30:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.43020549416542053 norm:0.011974511668086052 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.4061465263366699 norm:0.0058210683055222034 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.3876316249370575 norm:0.0033958209678530693 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.3819562494754791 norm:0.002220334019511938 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.38024818897247314 norm:0.0015942665049806237 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.37931299209594727 norm:0.0012173544382676482 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.37869787216186523 norm:0.0009611999266780913 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.37824833393096924 norm:0.000789397454354912 max memory_allocated 22563.46044921875 
[2025-03-02 08:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.3778504729270935 norm:0.0006693448522128165 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.37752974033355713 norm:0.0005844077095389366 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.3772988021373749 norm:0.0005261197220534086 max memory_allocated 22563.46044921875 
[2025-03-02 08:37:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.37702593207359314 norm:0.00048257221351377666 max memory_allocated 22563.46044921875 
[2025-03-02 08:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.3768003284931183 norm:0.0004497574409469962 max memory_allocated 22563.46044921875 
[2025-03-02 08:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.3765966594219208 norm:0.0004240535490680486 max memory_allocated 22563.46044921875 
[2025-03-02 08:38:53 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.3764835298061371 norm:0.00040802391595207155 max memory_allocated 22563.46044921875 
[2025-03-02 08:39:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.3763658404350281 norm:0.0003930829116143286 max memory_allocated 22563.46044921875 
[2025-03-02 08:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.3762591481208801 norm:0.00038424876402132213 max memory_allocated 22563.46044921875 
[2025-03-02 08:40:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.3761870861053467 norm:0.0003776623634621501 max memory_allocated 22563.46044921875 
[2025-03-02 08:41:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.37612390518188477 norm:0.0003728881711140275 max memory_allocated 22563.46044921875 
[2025-03-02 08:41:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.37604472041130066 norm:0.0003694834013003856 max memory_allocated 22563.46044921875 
[2025-03-02 08:41:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 08:42:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.47077861428260803 norm:0.005915264133363962 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.45180588960647583 norm:0.0029683792963624 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.4358009099960327 norm:0.001794630428776145 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.4310106635093689 norm:0.0012299722293391824 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.42968887090682983 norm:0.000953520240727812 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.429056316614151 norm:0.000768335594329983 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.42862096428871155 norm:0.000646372267510742 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.42827650904655457 norm:0.0005633109249174595 max memory_allocated 22563.63232421875 
[2025-03-02 08:47:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.4279453456401825 norm:0.000503874383866787 max memory_allocated 22563.63232421875 
[2025-03-02 08:47:35 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.42769259214401245 norm:0.00045487130410037935 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.42746978998184204 norm:0.00042873877100646496 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.4272767901420593 norm:0.00040228787111118436 max memory_allocated 22563.63232421875 
[2025-03-02 08:49:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.4271826446056366 norm:0.00038791418774053454 max memory_allocated 22563.63232421875 
[2025-03-02 08:49:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.4270675778388977 norm:0.00037874418194405735 max memory_allocated 22563.63232421875 
[2025-03-02 08:50:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.42697200179100037 norm:0.00035986988223157823 max memory_allocated 22563.63232421875 
[2025-03-02 08:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.42686086893081665 norm:0.00035481996019370854 max memory_allocated 22563.63232421875 
[2025-03-02 08:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.42686405777931213 norm:0.00035458861384540796 max memory_allocated 22563.63232421875 
[2025-03-02 08:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.42673176527023315 norm:0.00035671345540322363 max memory_allocated 22563.63232421875 
[2025-03-02 08:52:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.4266500174999237 norm:0.00035818549804389477 max memory_allocated 22563.63232421875 
[2025-03-02 08:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.42653128504753113 norm:0.00034450882230885327 max memory_allocated 22563.63232421875 
[2025-03-02 08:53:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 08:53:26 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 08:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.544931173324585 norm:0.019815918058156967 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.5219138860702515 norm:0.014998708851635456 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.5033621788024902 norm:0.01033063791692257 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.497651606798172 norm:0.008933626115322113 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.4960252046585083 norm:0.007715927436947823 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.49515146017074585 norm:0.006647343281656504 max memory_allocated 22563.91943359375 
[2025-03-02 08:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.49441084265708923 norm:0.005829381290823221 max memory_allocated 22563.91943359375 
[2025-03-02 08:57:58 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.4939066767692566 norm:0.005348554812371731 max memory_allocated 22563.91943359375 
[2025-03-02 08:58:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.49371007084846497 norm:0.005295855924487114 max memory_allocated 22563.91943359375 
[2025-03-02 08:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.49345728754997253 norm:0.005305200815200806 max memory_allocated 22563.91943359375 
[2025-03-02 08:59:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.49328842759132385 norm:0.0049224793910980225 max memory_allocated 22563.91943359375 
[2025-03-02 09:00:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.49288561940193176 norm:0.004602787550538778 max memory_allocated 22563.91943359375 
[2025-03-02 09:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.49270153045654297 norm:0.004351518582552671 max memory_allocated 22563.91943359375 
[2025-03-02 09:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.4925902187824249 norm:0.004213683307170868 max memory_allocated 22563.91943359375 
[2025-03-02 09:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.4924754202365875 norm:0.004221550654619932 max memory_allocated 22563.91943359375 
[2025-03-02 09:02:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.4924088418483734 norm:0.004215084481984377 max memory_allocated 22563.91943359375 
[2025-03-02 09:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.49228978157043457 norm:0.004115228075534105 max memory_allocated 22563.91943359375 
[2025-03-02 09:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.4921157956123352 norm:0.0039125774055719376 max memory_allocated 22563.91943359375 
[2025-03-02 09:04:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.49208906292915344 norm:0.003918579779565334 max memory_allocated 22563.91943359375 
[2025-03-02 09:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.49201110005378723 norm:0.0038339407183229923 max memory_allocated 22563.91943359375 
[2025-03-02 09:04:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 09:04:59 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:05:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.6333835124969482 norm:0.02258862927556038 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.6060169339179993 norm:0.01566881500184536 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.5841455459594727 norm:0.010745398700237274 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.5783225893974304 norm:0.009125826880335808 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.5765196084976196 norm:0.0077371858060359955 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:24 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.5753957033157349 norm:0.0066171796061098576 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.5745567679405212 norm:0.005583388730883598 max memory_allocated 22564.09130859375 
[2025-03-02 09:09:32 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.5739797353744507 norm:0.00505833700299263 max memory_allocated 22564.09130859375 
[2025-03-02 09:10:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.5738307237625122 norm:0.005196578800678253 max memory_allocated 22564.09130859375 
[2025-03-02 09:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.5736620426177979 norm:0.0052787261083722115 max memory_allocated 22564.09130859375 
[2025-03-02 09:11:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.5732828378677368 norm:0.004917647689580917 max memory_allocated 22564.09130859375 
[2025-03-02 09:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.573091983795166 norm:0.004630882292985916 max memory_allocated 22564.09130859375 
[2025-03-02 09:12:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.5728471279144287 norm:0.004502335097640753 max memory_allocated 22564.09130859375 
[2025-03-02 09:12:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.5726892948150635 norm:0.004034869372844696 max memory_allocated 22564.09130859375 
[2025-03-02 09:13:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.5725194811820984 norm:0.004204196389764547 max memory_allocated 22564.09130859375 
[2025-03-02 09:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.572365939617157 norm:0.003973773214966059 max memory_allocated 22564.09130859375 
[2025-03-02 09:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.5723025798797607 norm:0.0040718866512179375 max memory_allocated 22564.09130859375 
[2025-03-02 09:15:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.5721666812896729 norm:0.0038313623517751694 max memory_allocated 22564.09130859375 
[2025-03-02 09:15:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.5720599889755249 norm:0.003884569276124239 max memory_allocated 22564.09130859375 
[2025-03-02 09:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.5719123482704163 norm:0.0035633533261716366 max memory_allocated 22564.09130859375 
[2025-03-02 09:16:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:16:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:17:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.8443338871002197 norm:0.03596726059913635 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.789015531539917 norm:0.024635091423988342 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.7488844394683838 norm:0.014065466821193695 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.7387523651123047 norm:0.015620206482708454 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.7349151968955994 norm:0.01774332858622074 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.7321873307228088 norm:0.01821177266538143 max memory_allocated 22564.26318359375 
[2025-03-02 09:20:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.7306753396987915 norm:0.018063509836792946 max memory_allocated 22564.26318359375 
[2025-03-02 09:21:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.7293511629104614 norm:0.018173260614275932 max memory_allocated 22564.26318359375 
[2025-03-02 09:21:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.7283312678337097 norm:0.01680508255958557 max memory_allocated 22564.26318359375 
[2025-03-02 09:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.728347897529602 norm:0.017061496153473854 max memory_allocated 22564.26318359375 
[2025-03-02 09:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.7274878621101379 norm:0.017613962292671204 max memory_allocated 22564.26318359375 
[2025-03-02 09:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.7271331548690796 norm:0.01731910929083824 max memory_allocated 22564.26318359375 
[2025-03-02 09:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.7270486354827881 norm:0.017868023365736008 max memory_allocated 22564.26318359375 
[2025-03-02 09:24:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.7269154787063599 norm:0.01806689240038395 max memory_allocated 22564.26318359375 
[2025-03-02 09:25:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.7263292074203491 norm:0.017795097082853317 max memory_allocated 22564.26318359375 
[2025-03-02 09:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.7261287569999695 norm:0.017747392877936363 max memory_allocated 22564.26318359375 
[2025-03-02 09:26:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.7261537909507751 norm:0.018157538026571274 max memory_allocated 22564.26318359375 
[2025-03-02 09:26:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.7260416150093079 norm:0.01823306828737259 max memory_allocated 22564.26318359375 
[2025-03-02 09:27:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.7255563735961914 norm:0.017655950039625168 max memory_allocated 22564.26318359375 
[2025-03-02 09:27:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.7259223461151123 norm:0.01778402365744114 max memory_allocated 22564.26318359375 
[2025-03-02 09:28:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 09:28:05 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:1.5362756252288818 norm:0.10055273771286011 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:1.3992372751235962 norm:0.06940701603889465 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:1.304965615272522 norm:0.051561903208494186 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:1.2750277519226074 norm:0.050824590027332306 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:1.259321928024292 norm:0.05083969980478287 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:1.2492562532424927 norm:0.05140131339430809 max memory_allocated 22564.43505859375 
[2025-03-02 09:32:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:1.2405564785003662 norm:0.04765874519944191 max memory_allocated 22564.43505859375 
[2025-03-02 09:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:1.234877347946167 norm:0.04526910558342934 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:1.2306792736053467 norm:0.045979030430316925 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:1.2287360429763794 norm:0.046678394079208374 max memory_allocated 22564.43505859375 
[2025-03-02 09:34:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:1.2238010168075562 norm:0.04297351837158203 max memory_allocated 22564.43505859375 
[2025-03-02 09:34:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:1.2221516370773315 norm:0.04467601329088211 max memory_allocated 22564.43505859375 
[2025-03-02 09:35:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:1.2208311557769775 norm:0.04797840863466263 max memory_allocated 22564.43505859375 
[2025-03-02 09:36:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:1.2174922227859497 norm:0.044271331280469894 max memory_allocated 22564.43505859375 
[2025-03-02 09:36:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:1.217839002609253 norm:0.04489543288946152 max memory_allocated 22564.43505859375 
[2025-03-02 09:37:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:1.2164398431777954 norm:0.04230034351348877 max memory_allocated 22564.43505859375 
[2025-03-02 09:37:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:1.2139085531234741 norm:0.04005909711122513 max memory_allocated 22564.43505859375 
[2025-03-02 09:38:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:1.2139462232589722 norm:0.04060741141438484 max memory_allocated 22564.43505859375 
[2025-03-02 09:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:1.2130956649780273 norm:0.04205883666872978 max memory_allocated 22564.43505859375 
[2025-03-02 09:39:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:1.2118048667907715 norm:0.04070788249373436 max memory_allocated 22564.43505859375 
[2025-03-02 09:39:35 root] (main_calib_config2.py 380): INFO 22132.41567850113
[2025-03-02 09:39:41 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 09:40:53 root] (main_calib_config2.py 159): INFO wikitext2 : 5.982185363769531
[2025-03-02 09:40:53 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 09:42:45 root] (main_calib_config2.py 159): INFO c4 : 7.536150932312012
[2025-03-02 11:21:03 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.982185363769531, 'c4': 7.536150932312012, 'results': {'arc_challenge': {'acc': 0.37372013651877134, 'acc_stderr': 0.014137708601759096, 'acc_norm': 0.40187713310580203, 'acc_norm_stderr': 0.01432726861457827}, 'arc_easy': {'acc': 0.6658249158249159, 'acc_stderr': 0.009679106032919061, 'acc_norm': 0.5273569023569024, 'acc_norm_stderr': 0.010244415164390534}, 'piqa': {'acc': 0.7704026115342764, 'acc_stderr': 0.009812682950815176, 'acc_norm': 0.764961915125136, 'acc_norm_stderr': 0.00989314668880531}, 'winogrande': {'acc': 0.6456195737963694, 'acc_stderr': 0.01344331436835609}, 'boolq': {'acc': 0.7079510703363915, 'acc_stderr': 0.007952834971031336}, 'hellaswag': {'acc': 0.5447122087233619, 'acc_stderr': 0.004969790407117536, 'acc_norm': 0.7042421828321052, 'acc_norm_stderr': 0.004554499409290722}}, 'versions': {'arc_challenge': 0, 'arc_easy': 0, 'piqa': 0, 'winogrande': 0, 'boolq': 1, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
