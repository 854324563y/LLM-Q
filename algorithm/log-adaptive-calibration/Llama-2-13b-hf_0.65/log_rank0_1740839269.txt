[2025-03-01 14:27:49 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.65', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.65.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-01 14:28:23 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-01 14:28:23 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.65.pkl
[2025-03-01 14:28:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-01 14:29:00 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.007094111759215593 norm:0.012462254613637924 max memory_allocated 29271.02001953125 
[2025-03-01 14:30:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.004025192465633154 norm:0.007529709488153458 max memory_allocated 29271.02001953125 
[2025-03-01 14:31:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.003360176458954811 norm:0.005527909845113754 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0031339009292423725 norm:0.004804552998393774 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0028544780798256397 norm:0.0036944032181054354 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.002717808121815324 norm:0.0029822811484336853 max memory_allocated 29271.02001953125 
[2025-03-01 14:34:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.002616901183500886 norm:0.0027019777335226536 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.002555850660428405 norm:0.0022646894212812185 max memory_allocated 29271.02001953125 
[2025-03-01 14:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0024153839331120253 norm:0.001956954365596175 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0024030394852161407 norm:0.0018419602420181036 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.002400485333055258 norm:0.0016245092265307903 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.002355657983571291 norm:0.0014224370243027806 max memory_allocated 29271.02001953125 
[2025-03-01 14:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0023932545445859432 norm:0.0014033871702849865 max memory_allocated 29271.02001953125 
[2025-03-01 14:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.002364605199545622 norm:0.0013070980785414577 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0022741651628166437 norm:0.001164354500360787 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0023270517122000456 norm:0.0011897720396518707 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0022517708130180836 norm:0.0009781024418771267 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.002277298364788294 norm:0.0009399426053278148 max memory_allocated 29271.02001953125 
[2025-03-01 14:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0022448066156357527 norm:0.0009637415641918778 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0022357141133397818 norm:0.0009070817031897604 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-01 14:45:41 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:46:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.020302584394812584 norm:0.01062099914997816 max memory_allocated 29271.02001953125 
[2025-03-01 14:47:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.012508977204561234 norm:0.006046258378773928 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.009073900990188122 norm:0.0038930284790694714 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.008215902373194695 norm:0.0030365141574293375 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.00788171961903572 norm:0.002549680881202221 max memory_allocated 29271.02001953125 
[2025-03-01 14:50:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.007663760334253311 norm:0.0022598521318286657 max memory_allocated 29271.02001953125 
[2025-03-01 14:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.007510128431022167 norm:0.0021503926254808903 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.0073843649588525295 norm:0.0019614463672041893 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.007288884837180376 norm:0.0018239778000861406 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.007195071317255497 norm:0.0016312752850353718 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.007134540937840939 norm:0.0014649645891040564 max memory_allocated 29271.02001953125 
[2025-03-01 14:55:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.007052775472402573 norm:0.001331970444880426 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.007007258012890816 norm:0.0012111958349123597 max memory_allocated 29271.02001953125 
[2025-03-01 14:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.0069630201905965805 norm:0.001126592280343175 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.0069237034767866135 norm:0.0011280475882813334 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.006910713855177164 norm:0.0010823478223755956 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.006887586321681738 norm:0.0010766023769974709 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.006873984821140766 norm:0.0009883623570203781 max memory_allocated 29271.02001953125 
[2025-03-01 15:01:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.006872053258121014 norm:0.000969569431617856 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.006843338720500469 norm:0.0009045519982464612 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-01 15:02:25 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 15:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.025152161717414856 norm:0.009428189136087894 max memory_allocated 29271.02001953125 
[2025-03-01 15:04:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.0185769684612751 norm:0.006888824049383402 max memory_allocated 29271.02001953125 
[2025-03-01 15:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.015343808569014072 norm:0.005059261806309223 max memory_allocated 29271.02001953125 
[2025-03-01 15:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.014298920519649982 norm:0.004022897686809301 max memory_allocated 29271.02001953125 
[2025-03-01 15:06:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.013790071941912174 norm:0.0033491039648652077 max memory_allocated 29271.02001953125 
[2025-03-01 15:07:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.013476373627781868 norm:0.002863264409825206 max memory_allocated 29271.02001953125 
[2025-03-01 15:08:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.013150510378181934 norm:0.002419973723590374 max memory_allocated 29271.02001953125 
[2025-03-01 15:09:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.012889566831290722 norm:0.0020684325136244297 max memory_allocated 29271.02001953125 
[2025-03-01 15:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.012726745568215847 norm:0.00191767408978194 max memory_allocated 29271.02001953125 
[2025-03-01 15:10:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.012613749131560326 norm:0.0017339179757982492 max memory_allocated 29271.02001953125 
[2025-03-01 15:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.012556977570056915 norm:0.0016506420215591788 max memory_allocated 29271.02001953125 
[2025-03-01 15:12:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.012520072981715202 norm:0.001590900355949998 max memory_allocated 29271.02001953125 
[2025-03-01 15:13:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.012567556463181973 norm:0.0015859475824981928 max memory_allocated 29271.02001953125 
[2025-03-01 15:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.012559990398585796 norm:0.0015416574897244573 max memory_allocated 29271.02001953125 
[2025-03-01 15:14:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.012544333003461361 norm:0.0015247589908540249 max memory_allocated 29271.02001953125 
[2025-03-01 15:15:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.012517894618213177 norm:0.0014670881209895015 max memory_allocated 29271.02001953125 
[2025-03-01 15:16:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.012499086558818817 norm:0.0014297575689852238 max memory_allocated 29271.02001953125 
[2025-03-01 15:17:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.012474372051656246 norm:0.0013444118667393923 max memory_allocated 29271.02001953125 
[2025-03-01 15:18:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.012454177252948284 norm:0.0012868741760030389 max memory_allocated 29271.02001953125 
[2025-03-01 15:18:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.012440687045454979 norm:0.0012143314816057682 max memory_allocated 29271.02001953125 
[2025-03-01 15:19:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-01 15:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.1127299964427948 norm:0.015747521072626114 max memory_allocated 29271.43798828125 
[2025-03-01 15:20:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.084161177277565 norm:0.009105727076530457 max memory_allocated 29271.43798828125 
[2025-03-01 15:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.06480395048856735 norm:0.0076836165972054005 max memory_allocated 29271.43798828125 
[2025-03-01 15:22:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.06288023293018341 norm:0.007916823029518127 max memory_allocated 29271.43798828125 
[2025-03-01 15:23:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.055795859545469284 norm:0.007497178390622139 max memory_allocated 29271.43798828125 
[2025-03-01 15:24:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.04604366421699524 norm:0.005746844224631786 max memory_allocated 29271.43798828125 
[2025-03-01 15:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.04153234511613846 norm:0.0049300058744847775 max memory_allocated 29271.43798828125 
[2025-03-01 15:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.03941326215863228 norm:0.004130684770643711 max memory_allocated 29271.43798828125 
[2025-03-01 15:26:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.042890358716249466 norm:0.005152846220880747 max memory_allocated 29271.43798828125 
[2025-03-01 15:27:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.04604404792189598 norm:0.00634029321372509 max memory_allocated 29271.43798828125 
[2025-03-01 15:28:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.04717545583844185 norm:0.006127747241407633 max memory_allocated 29271.43798828125 
[2025-03-01 15:29:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.04347135126590729 norm:0.0055806138552725315 max memory_allocated 29271.43798828125 
[2025-03-01 15:29:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.04525856301188469 norm:0.005979346111416817 max memory_allocated 29271.43798828125 
[2025-03-01 15:30:40 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.044961731880903244 norm:0.006224897690117359 max memory_allocated 29271.43798828125 
[2025-03-01 15:31:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.045506369322538376 norm:0.005828217603266239 max memory_allocated 29271.43798828125 
[2025-03-01 15:32:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.04820001497864723 norm:0.006686794571578503 max memory_allocated 29271.43798828125 
[2025-03-01 15:33:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.045791324228048325 norm:0.006345880683511496 max memory_allocated 29271.43798828125 
[2025-03-01 15:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.04747425764799118 norm:0.006433691829442978 max memory_allocated 29271.43798828125 
[2025-03-01 15:34:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.04685318470001221 norm:0.006180278025567532 max memory_allocated 29271.43798828125 
[2025-03-01 15:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.04605914652347565 norm:0.006109537091106176 max memory_allocated 29271.43798828125 
[2025-03-01 15:35:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-01 15:36:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.03916800022125244 norm:0.000763952499255538 max memory_allocated 29271.43798828125 
[2025-03-01 15:37:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.03460874781012535 norm:0.0003235656186006963 max memory_allocated 29271.43798828125 
[2025-03-01 15:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.032523348927497864 norm:0.0001951513986568898 max memory_allocated 29271.43798828125 
[2025-03-01 15:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.03136126324534416 norm:0.00016503920778632164 max memory_allocated 29271.43798828125 
[2025-03-01 15:40:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.030671069398522377 norm:0.00014673989790026098 max memory_allocated 29271.43798828125 
[2025-03-01 15:40:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.030198995023965836 norm:0.00013690283230971545 max memory_allocated 29271.43798828125 
[2025-03-01 15:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.029882887378335 norm:0.00013422917982097715 max memory_allocated 29271.43798828125 
[2025-03-01 15:42:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.029746713116765022 norm:0.0001306170888710767 max memory_allocated 29271.43798828125 
[2025-03-01 15:43:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.02965550683438778 norm:0.0001332991087110713 max memory_allocated 29271.43798828125 
[2025-03-01 15:44:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.02963048405945301 norm:0.0001393966085743159 max memory_allocated 29271.43798828125 
[2025-03-01 15:44:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.029607582837343216 norm:0.00013623188715428114 max memory_allocated 29271.43798828125 
[2025-03-01 15:45:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.029581671580672264 norm:0.0001292294473387301 max memory_allocated 29271.43798828125 
[2025-03-01 15:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.02955811284482479 norm:0.0001233771617989987 max memory_allocated 29271.43798828125 
[2025-03-01 15:47:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.029551273211836815 norm:0.00012667982082348317 max memory_allocated 29271.43798828125 
[2025-03-01 15:48:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.029554788023233414 norm:0.00013360337470658123 max memory_allocated 29271.43798828125 
[2025-03-01 15:49:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.02952638268470764 norm:0.00013123854296281934 max memory_allocated 29271.43798828125 
[2025-03-01 15:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.029542474076151848 norm:0.00013395256246440113 max memory_allocated 29271.43798828125 
[2025-03-01 15:50:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.029557906091213226 norm:0.00014081898552831262 max memory_allocated 29271.43798828125 
[2025-03-01 15:51:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.02955709584057331 norm:0.00013121135998517275 max memory_allocated 29271.43798828125 
[2025-03-01 15:52:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.02953668311238289 norm:0.00013739684072788805 max memory_allocated 29271.43798828125 
[2025-03-01 15:52:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-01 15:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.04246453940868378 norm:0.0011486036237329245 max memory_allocated 29271.43798828125 
[2025-03-01 15:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.03629555553197861 norm:0.0004563865950331092 max memory_allocated 29271.43798828125 
[2025-03-01 15:55:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.03402998670935631 norm:0.00024915780522860587 max memory_allocated 29271.43798828125 
[2025-03-01 15:55:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.03266633674502373 norm:0.000177839829120785 max memory_allocated 29271.43798828125 
[2025-03-01 15:56:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.03182058781385422 norm:0.00014790114073548466 max memory_allocated 29271.43798828125 
[2025-03-01 15:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.031274206936359406 norm:0.0001311388041358441 max memory_allocated 29271.43798828125 
[2025-03-01 15:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.030962694436311722 norm:0.00012834467634093016 max memory_allocated 29271.43798828125 
[2025-03-01 15:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.03080863319337368 norm:0.00011717661254806444 max memory_allocated 29271.43798828125 
[2025-03-01 16:00:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.030720986425876617 norm:0.00011102725693490356 max memory_allocated 29271.43798828125 
[2025-03-01 16:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.030671052634716034 norm:0.00010979924991261214 max memory_allocated 29271.43798828125 
[2025-03-01 16:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.03063926473259926 norm:0.00010934100282611325 max memory_allocated 29271.43798828125 
[2025-03-01 16:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.030610214918851852 norm:0.00011048861779272556 max memory_allocated 29271.43798828125 
[2025-03-01 16:03:17 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.030612535774707794 norm:0.00010669022594811395 max memory_allocated 29271.43798828125 
[2025-03-01 16:04:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.030606957152485847 norm:0.00011075454676756635 max memory_allocated 29271.43798828125 
[2025-03-01 16:04:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.030583368614315987 norm:0.00011224692570976913 max memory_allocated 29271.43798828125 
[2025-03-01 16:05:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.0305780116468668 norm:0.00011115560482721776 max memory_allocated 29271.43798828125 
[2025-03-01 16:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.03056984394788742 norm:0.0001116089551942423 max memory_allocated 29271.43798828125 
[2025-03-01 16:07:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.030559610575437546 norm:0.0001094811232178472 max memory_allocated 29271.43798828125 
[2025-03-01 16:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.03053572215139866 norm:0.00010651992488419637 max memory_allocated 29271.43798828125 
[2025-03-01 16:09:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.030542034655809402 norm:0.00011018980148946866 max memory_allocated 29271.43798828125 
[2025-03-01 16:09:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-01 16:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.04651308432221413 norm:0.001483930740505457 max memory_allocated 29272.00048828125 
[2025-03-01 16:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.039852987974882126 norm:0.0006225880933925509 max memory_allocated 29272.00048828125 
[2025-03-01 16:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.03698799014091492 norm:0.00035472874878905714 max memory_allocated 29272.00048828125 
[2025-03-01 16:12:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.03541170433163643 norm:0.0002438362716929987 max memory_allocated 29272.00048828125 
[2025-03-01 16:13:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.03439535200595856 norm:0.00019987524137832224 max memory_allocated 29272.00048828125 
[2025-03-01 16:14:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.03380800783634186 norm:0.00017626103362999856 max memory_allocated 29272.00048828125 
[2025-03-01 16:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.03346763923764229 norm:0.0001598116068635136 max memory_allocated 29272.00048828125 
[2025-03-01 16:15:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.03328564390540123 norm:0.00015316349163185805 max memory_allocated 29272.00048828125 
[2025-03-01 16:16:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.03319369629025459 norm:0.00015152079868130386 max memory_allocated 29272.00048828125 
[2025-03-01 16:17:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.03315640613436699 norm:0.0001505077088950202 max memory_allocated 29272.00048828125 
[2025-03-01 16:18:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.03310510516166687 norm:0.00014671860844828188 max memory_allocated 29272.00048828125 
[2025-03-01 16:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.033070340752601624 norm:0.0001446958485757932 max memory_allocated 29272.00048828125 
[2025-03-01 16:20:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.03304731845855713 norm:0.00013367370411287993 max memory_allocated 29272.00048828125 
[2025-03-01 16:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.03305738791823387 norm:0.00014354585437104106 max memory_allocated 29272.00048828125 
[2025-03-01 16:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.03303099423646927 norm:0.00013794279948342592 max memory_allocated 29272.00048828125 
[2025-03-01 16:22:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.033033281564712524 norm:0.00013617002696264535 max memory_allocated 29272.00048828125 
[2025-03-01 16:23:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.033038198947906494 norm:0.00014663876208942384 max memory_allocated 29272.00048828125 
[2025-03-01 16:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.033028971403837204 norm:0.00013803222100250423 max memory_allocated 29272.00048828125 
[2025-03-01 16:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.033018745481967926 norm:0.0001432124845450744 max memory_allocated 29272.00048828125 
[2025-03-01 16:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.03299545869231224 norm:0.00013483990915119648 max memory_allocated 29272.00048828125 
[2025-03-01 16:25:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-01 16:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.05672645568847656 norm:0.0016577763017266989 max memory_allocated 29272.18798828125 
[2025-03-01 16:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.04690475016832352 norm:0.0006958838785067201 max memory_allocated 29272.18798828125 
[2025-03-01 16:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.04313027113676071 norm:0.0004060727369505912 max memory_allocated 29272.18798828125 
[2025-03-01 16:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.041220374405384064 norm:0.00030513788806274533 max memory_allocated 29272.18798828125 
[2025-03-01 16:30:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.04012557119131088 norm:0.00026095932116732 max memory_allocated 29272.18798828125 
[2025-03-01 16:30:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.03941349685192108 norm:0.00023767128004692495 max memory_allocated 29272.18798828125 
[2025-03-01 16:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.03902527689933777 norm:0.00021587539231404662 max memory_allocated 29272.18798828125 
[2025-03-01 16:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.038775213062763214 norm:0.00021051843941677362 max memory_allocated 29272.18798828125 
[2025-03-01 16:33:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.038648732006549835 norm:0.00021637778263539076 max memory_allocated 29272.18798828125 
[2025-03-01 16:34:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.038579002022743225 norm:0.0002073621581075713 max memory_allocated 29272.18798828125 
[2025-03-01 16:35:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.03855808079242706 norm:0.00020593596855178475 max memory_allocated 29272.18798828125 
[2025-03-01 16:35:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.03852427378296852 norm:0.00019877569866366684 max memory_allocated 29272.18798828125 
[2025-03-01 16:36:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.03850436955690384 norm:0.00019969517597928643 max memory_allocated 29272.18798828125 
[2025-03-01 16:37:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.0384848453104496 norm:0.00018831661145668477 max memory_allocated 29272.18798828125 
[2025-03-01 16:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.038451049476861954 norm:0.00019117450574412942 max memory_allocated 29272.18798828125 
[2025-03-01 16:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.038421232253313065 norm:0.0002021085238084197 max memory_allocated 29272.18798828125 
[2025-03-01 16:40:00 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.03838319331407547 norm:0.00020164022862445563 max memory_allocated 29272.18798828125 
[2025-03-01 16:40:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.03835128992795944 norm:0.00019673307542689145 max memory_allocated 29272.18798828125 
[2025-03-01 16:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.03834241256117821 norm:0.00019380888261366636 max memory_allocated 29272.18798828125 
[2025-03-01 16:42:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.038320645689964294 norm:0.00019157402857672423 max memory_allocated 29272.18798828125 
[2025-03-01 16:42:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-01 16:43:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.05780480429530144 norm:0.0016326133627444506 max memory_allocated 29272.37548828125 
[2025-03-01 16:44:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.04919452220201492 norm:0.0007168998126871884 max memory_allocated 29272.37548828125 
[2025-03-01 16:45:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.04555505886673927 norm:0.0004096304182894528 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:03 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.04358001425862312 norm:0.0002887010050471872 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.04228193312883377 norm:0.0002265876391902566 max memory_allocated 29272.37548828125 
[2025-03-01 16:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.04158833995461464 norm:0.00019736879039555788 max memory_allocated 29272.37548828125 
[2025-03-01 16:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.04122284799814224 norm:0.0001835064758779481 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.04097527265548706 norm:0.0001680543937254697 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.04081154242157936 norm:0.0001596682268427685 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.040711659938097 norm:0.00015311846800614148 max memory_allocated 29272.37548828125 
[2025-03-01 16:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.04063992574810982 norm:0.00014909912715665996 max memory_allocated 29272.37548828125 
[2025-03-01 16:52:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.040595460683107376 norm:0.00014417478814721107 max memory_allocated 29272.37548828125 
[2025-03-01 16:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.04057273268699646 norm:0.0001475034950999543 max memory_allocated 29272.37548828125 
[2025-03-01 16:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.04054420441389084 norm:0.00014078403182793409 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.040536753833293915 norm:0.00013867444067727774 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.04052887484431267 norm:0.00013944665261078626 max memory_allocated 29272.37548828125 
[2025-03-01 16:56:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.04050096124410629 norm:0.00014135270612314343 max memory_allocated 29272.37548828125 
[2025-03-01 16:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.04049517959356308 norm:0.00014000349619891495 max memory_allocated 29272.37548828125 
[2025-03-01 16:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.04049190878868103 norm:0.00014588385238312185 max memory_allocated 29272.37548828125 
[2025-03-01 16:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.04046670347452164 norm:0.00014290209219325334 max memory_allocated 29272.37548828125 
[2025-03-01 16:59:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-01 17:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.08440151810646057 norm:0.0029420952778309584 max memory_allocated 29272.56298828125 
[2025-03-01 17:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.0632789358496666 norm:0.0013140285154804587 max memory_allocated 29272.56298828125 
[2025-03-01 17:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.05286236107349396 norm:0.0006646047113463283 max memory_allocated 29272.56298828125 
[2025-03-01 17:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.04995942860841751 norm:0.0004495479224715382 max memory_allocated 29272.56298828125 
[2025-03-01 17:03:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.04843215271830559 norm:0.0003559448814485222 max memory_allocated 29272.56298828125 
[2025-03-01 17:04:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.04756931588053703 norm:0.0003096392028965056 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.04704354330897331 norm:0.00028487941017374396 max memory_allocated 29272.56298828125 
[2025-03-01 17:06:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.04668402671813965 norm:0.0002683204656932503 max memory_allocated 29272.56298828125 
[2025-03-01 17:06:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.046476319432258606 norm:0.0002679838507901877 max memory_allocated 29272.56298828125 
[2025-03-01 17:07:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.046247974038124084 norm:0.0002446899306960404 max memory_allocated 29272.56298828125 
[2025-03-01 17:08:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.04611271619796753 norm:0.00023514963686466217 max memory_allocated 29272.56298828125 
[2025-03-01 17:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.04599134251475334 norm:0.00023694017727393657 max memory_allocated 29272.56298828125 
[2025-03-01 17:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.04586320370435715 norm:0.00023507888545282185 max memory_allocated 29272.56298828125 
[2025-03-01 17:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.04574163258075714 norm:0.00022299331612884998 max memory_allocated 29272.56298828125 
[2025-03-01 17:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.045649006962776184 norm:0.00021625778754241765 max memory_allocated 29272.56298828125 
[2025-03-01 17:12:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.04554683715105057 norm:0.00020980702538508922 max memory_allocated 29272.56298828125 
[2025-03-01 17:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.04545869678258896 norm:0.00021443735749926418 max memory_allocated 29272.56298828125 
[2025-03-01 17:14:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.045402683317661285 norm:0.00022067564714234322 max memory_allocated 29272.56298828125 
[2025-03-01 17:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.045363496989011765 norm:0.0002183473843615502 max memory_allocated 29272.56298828125 
[2025-03-01 17:15:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.04531630873680115 norm:0.00021239434136077762 max memory_allocated 29272.56298828125 
[2025-03-01 17:16:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-01 17:17:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.0708284080028534 norm:0.0015595286386087537 max memory_allocated 29272.75048828125 
[2025-03-01 17:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.05938700586557388 norm:0.0007899698684923351 max memory_allocated 29272.75048828125 
[2025-03-01 17:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.05321601405739784 norm:0.00046366406604647636 max memory_allocated 29272.75048828125 
[2025-03-01 17:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.05121929943561554 norm:0.00033026476739905775 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.050065506249666214 norm:0.0002614402037579566 max memory_allocated 29272.75048828125 
[2025-03-01 17:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.049377184361219406 norm:0.00022275753144640476 max memory_allocated 29272.75048828125 
[2025-03-01 17:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.048956602811813354 norm:0.00020546269661281258 max memory_allocated 29272.75048828125 
[2025-03-01 17:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.04870617762207985 norm:0.00018959332373924553 max memory_allocated 29272.75048828125 
[2025-03-01 17:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.04852555692195892 norm:0.00018048778292723 max memory_allocated 29272.75048828125 
[2025-03-01 17:24:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.04841764643788338 norm:0.00017069114255718887 max memory_allocated 29272.75048828125 
[2025-03-01 17:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.04832350090146065 norm:0.0001687339536147192 max memory_allocated 29272.75048828125 
[2025-03-01 17:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.04823027923703194 norm:0.0001652973733143881 max memory_allocated 29272.75048828125 
[2025-03-01 17:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.048147570341825485 norm:0.00015847010945435613 max memory_allocated 29272.75048828125 
[2025-03-01 17:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.048096664249897 norm:0.0001539550139568746 max memory_allocated 29272.75048828125 
[2025-03-01 17:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.04804736748337746 norm:0.000141334836371243 max memory_allocated 29272.75048828125 
[2025-03-01 17:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.04799941927194595 norm:0.0001389348180964589 max memory_allocated 29272.75048828125 
[2025-03-01 17:30:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.04797179996967316 norm:0.00014235377602744848 max memory_allocated 29272.75048828125 
[2025-03-01 17:30:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.047925740480422974 norm:0.0001346408243989572 max memory_allocated 29272.75048828125 
[2025-03-01 17:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.04789191484451294 norm:0.00013149323058314621 max memory_allocated 29272.75048828125 
[2025-03-01 17:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.047872234135866165 norm:0.00012938059808220714 max memory_allocated 29272.75048828125 
[2025-03-01 17:32:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-01 17:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.07127412408590317 norm:0.0011275953147560358 max memory_allocated 29272.93798828125 
[2025-03-01 17:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.06092764064669609 norm:0.0005428149597719312 max memory_allocated 29272.93798828125 
[2025-03-01 17:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.05540057644248009 norm:0.00031658506486564875 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.05365832895040512 norm:0.00023435450566466898 max memory_allocated 29272.93798828125 
[2025-03-01 17:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.05265209823846817 norm:0.00019568315474316478 max memory_allocated 29272.93798828125 
[2025-03-01 17:37:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.05210350826382637 norm:0.00018214102601632476 max memory_allocated 29272.93798828125 
[2025-03-01 17:38:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.05175451189279556 norm:0.00017096020746976137 max memory_allocated 29272.93798828125 
[2025-03-01 17:39:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.051541756838560104 norm:0.00016367959324270487 max memory_allocated 29272.93798828125 
[2025-03-01 17:40:18 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.051397256553173065 norm:0.00015247586998157203 max memory_allocated 29272.93798828125 
[2025-03-01 17:41:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.051279954612255096 norm:0.00014675655984319746 max memory_allocated 29272.93798828125 
[2025-03-01 17:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.051210466772317886 norm:0.00014687304792460054 max memory_allocated 29272.93798828125 
[2025-03-01 17:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.05114394798874855 norm:0.00014171336079016328 max memory_allocated 29272.93798828125 
[2025-03-01 17:43:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.051075778901576996 norm:0.0001390335673931986 max memory_allocated 29272.93798828125 
[2025-03-01 17:44:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.05102252960205078 norm:0.00013479824701789767 max memory_allocated 29272.93798828125 
[2025-03-01 17:45:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.050972867757081985 norm:0.00013478999608196318 max memory_allocated 29272.93798828125 
[2025-03-01 17:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.05092845857143402 norm:0.0001273574453080073 max memory_allocated 29272.93798828125 
[2025-03-01 17:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.05090471729636192 norm:0.00012373931531328708 max memory_allocated 29272.93798828125 
[2025-03-01 17:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.050865042954683304 norm:0.0001224108855240047 max memory_allocated 29272.93798828125 
[2025-03-01 17:48:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.0508437342941761 norm:0.00012126143701607361 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.05083271488547325 norm:0.00011980831186519936 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-01 17:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.07450934499502182 norm:0.0010643317364156246 max memory_allocated 29273.12548828125 
[2025-03-01 17:51:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.0632706731557846 norm:0.000528511474840343 max memory_allocated 29273.12548828125 
[2025-03-01 17:52:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.057247478514909744 norm:0.0003025619953405112 max memory_allocated 29273.12548828125 
[2025-03-01 17:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.05561106652021408 norm:0.00023569744371343404 max memory_allocated 29273.12548828125 
[2025-03-01 17:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.05465604364871979 norm:0.000199476518901065 max memory_allocated 29273.12548828125 
[2025-03-01 17:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.054028209298849106 norm:0.0001783492334652692 max memory_allocated 29273.12548828125 
[2025-03-01 17:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.05366603285074234 norm:0.00016614928608760238 max memory_allocated 29273.12548828125 
[2025-03-01 17:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.053416721522808075 norm:0.0001536889758426696 max memory_allocated 29273.12548828125 
[2025-03-01 17:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.05323672667145729 norm:0.00014778802869841456 max memory_allocated 29273.12548828125 
[2025-03-01 17:57:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.05312559753656387 norm:0.00014076815568841994 max memory_allocated 29273.12548828125 
[2025-03-01 17:58:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.05303468927741051 norm:0.00014344268129207194 max memory_allocated 29273.12548828125 
[2025-03-01 17:59:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.052950501441955566 norm:0.00013857847079634666 max memory_allocated 29273.12548828125 
[2025-03-01 18:00:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.05288252234458923 norm:0.00013905057858210057 max memory_allocated 29273.12548828125 
[2025-03-01 18:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.05281488597393036 norm:0.0001330649247393012 max memory_allocated 29273.12548828125 
[2025-03-01 18:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.0527733750641346 norm:0.0001272319641429931 max memory_allocated 29273.12548828125 
[2025-03-01 18:02:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.05272076651453972 norm:0.00011848248686874285 max memory_allocated 29273.12548828125 
[2025-03-01 18:03:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.052690573036670685 norm:0.0001174009230453521 max memory_allocated 29273.12548828125 
[2025-03-01 18:04:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.05267792195081711 norm:0.00011675828136503696 max memory_allocated 29273.12548828125 
[2025-03-01 18:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.05265425518155098 norm:0.00011351301509421319 max memory_allocated 29273.12548828125 
[2025-03-01 18:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.05261494591832161 norm:0.00011039869423257187 max memory_allocated 29273.12548828125 
[2025-03-01 18:06:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-01 18:07:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.07564336061477661 norm:0.0012120063183829188 max memory_allocated 29273.31298828125 
[2025-03-01 18:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.06529328227043152 norm:0.0006110887625254691 max memory_allocated 29273.31298828125 
[2025-03-01 18:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.05968814715743065 norm:0.00037726626032963395 max memory_allocated 29273.31298828125 
[2025-03-01 18:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.057899244129657745 norm:0.00028451389516703784 max memory_allocated 29273.31298828125 
[2025-03-01 18:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.056779175996780396 norm:0.0002333901502424851 max memory_allocated 29273.31298828125 
[2025-03-01 18:11:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.056133415549993515 norm:0.0002070223999908194 max memory_allocated 29273.31298828125 
[2025-03-01 18:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.05573160946369171 norm:0.000191637926036492 max memory_allocated 29273.31298828125 
[2025-03-01 18:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.055464163422584534 norm:0.0001832723937695846 max memory_allocated 29273.31298828125 
[2025-03-01 18:13:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.05531220883131027 norm:0.00017360824858769774 max memory_allocated 29273.31298828125 
[2025-03-01 18:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.055147435516119 norm:0.00016450045222882181 max memory_allocated 29273.31298828125 
[2025-03-01 18:15:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.05502540245652199 norm:0.00015626246749889106 max memory_allocated 29273.31298828125 
[2025-03-01 18:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.054922036826610565 norm:0.00014966583694331348 max memory_allocated 29273.31298828125 
[2025-03-01 18:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.05484271049499512 norm:0.00014923747221473604 max memory_allocated 29273.31298828125 
[2025-03-01 18:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.054780490696430206 norm:0.00014118064427748322 max memory_allocated 29273.31298828125 
[2025-03-01 18:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.05473390594124794 norm:0.00013661138655152172 max memory_allocated 29273.31298828125 
[2025-03-01 18:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.05468429625034332 norm:0.00013395668065641075 max memory_allocated 29273.31298828125 
[2025-03-01 18:20:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.05463434383273125 norm:0.00013227778254076838 max memory_allocated 29273.31298828125 
[2025-03-01 18:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.054600298404693604 norm:0.00013385122292675078 max memory_allocated 29273.31298828125 
[2025-03-01 18:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.05454464629292488 norm:0.00012203083315398544 max memory_allocated 29273.31298828125 
[2025-03-01 18:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.05453462898731232 norm:0.00012425654858816415 max memory_allocated 29273.31298828125 
[2025-03-01 18:22:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-01 18:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.075042724609375 norm:0.0010321441804990172 max memory_allocated 29273.50048828125 
[2025-03-01 18:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.06605152040719986 norm:0.0005255641881376505 max memory_allocated 29273.50048828125 
[2025-03-01 18:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.06089131534099579 norm:0.00032399181509390473 max memory_allocated 29273.50048828125 
[2025-03-01 18:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.05933235213160515 norm:0.00024630525149405 max memory_allocated 29273.50048828125 
[2025-03-01 18:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.05837312340736389 norm:0.0002065656881313771 max memory_allocated 29273.50048828125 
[2025-03-01 18:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.05775904282927513 norm:0.00018057224224321544 max memory_allocated 29273.50048828125 
[2025-03-01 18:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.057348765432834625 norm:0.00016328673518728465 max memory_allocated 29273.50048828125 
[2025-03-01 18:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.05708789825439453 norm:0.00015498805441893637 max memory_allocated 29273.50048828125 
[2025-03-01 18:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.05691465735435486 norm:0.0001479396305512637 max memory_allocated 29273.50048828125 
[2025-03-01 18:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.05679528787732124 norm:0.00014035387721378356 max memory_allocated 29273.50048828125 
[2025-03-01 18:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.056688521057367325 norm:0.00013481728092301637 max memory_allocated 29273.50048828125 
[2025-03-01 18:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.056586142629384995 norm:0.00012863932352047414 max memory_allocated 29273.50048828125 
[2025-03-01 18:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.05650518834590912 norm:0.00012163050269009545 max memory_allocated 29273.50048828125 
[2025-03-01 18:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.05644730105996132 norm:0.00011812745651695877 max memory_allocated 29273.50048828125 
[2025-03-01 18:35:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.056397974491119385 norm:0.00011433075269451365 max memory_allocated 29273.50048828125 
[2025-03-01 18:36:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.05636763200163841 norm:0.00011137579713249579 max memory_allocated 29273.50048828125 
[2025-03-01 18:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.056342218071222305 norm:0.00010992103489115834 max memory_allocated 29273.50048828125 
[2025-03-01 18:37:50 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.056315671652555466 norm:0.00010986214329022914 max memory_allocated 29273.50048828125 
[2025-03-01 18:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.056303948163986206 norm:0.00010975440818583593 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.05627730116248131 norm:0.00011304258805466816 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-01 18:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.07291176915168762 norm:0.0006887221825309098 max memory_allocated 29273.68798828125 
[2025-03-01 18:41:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.06555181741714478 norm:0.0003721872344613075 max memory_allocated 29273.68798828125 
[2025-03-01 18:42:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.06064740568399429 norm:0.0002408632863080129 max memory_allocated 29273.68798828125 
[2025-03-01 18:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.05921640247106552 norm:0.0001883351942524314 max memory_allocated 29273.68798828125 
[2025-03-01 18:43:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.05841781944036484 norm:0.00016573724860791117 max memory_allocated 29273.68798828125 
[2025-03-01 18:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.057823989540338516 norm:0.0001485942048020661 max memory_allocated 29273.68798828125 
[2025-03-01 18:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.0574401319026947 norm:0.0001392276753904298 max memory_allocated 29273.68798828125 
[2025-03-01 18:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.05721120536327362 norm:0.00012967427028343081 max memory_allocated 29273.68798828125 
[2025-03-01 18:47:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.05704096332192421 norm:0.00012242681987117976 max memory_allocated 29273.68798828125 
[2025-03-01 18:47:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.056928105652332306 norm:0.00011772837024182081 max memory_allocated 29273.68798828125 
[2025-03-01 18:48:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.05681886896491051 norm:0.00011437598004704341 max memory_allocated 29273.68798828125 
[2025-03-01 18:49:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.05675661936402321 norm:0.00011103706492576748 max memory_allocated 29273.68798828125 
[2025-03-01 18:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.05669938772916794 norm:0.00010626704897731543 max memory_allocated 29273.68798828125 
[2025-03-01 18:51:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.05663112923502922 norm:9.908528591040522e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:52:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.056576430797576904 norm:9.702347597340122e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:52:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.05654752627015114 norm:9.726665302878246e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.056520264595746994 norm:9.470898658037186e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.05649254098534584 norm:9.392801439389586e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.05646894872188568 norm:9.315733768744394e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.056439440697431564 norm:9.142856288235635e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:56:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-01 18:57:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.07894393801689148 norm:0.0011544760782271624 max memory_allocated 29273.87548828125 
[2025-03-01 18:58:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.06906279921531677 norm:0.0005679636960849166 max memory_allocated 29273.87548828125 
[2025-03-01 18:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.06319937855005264 norm:0.00035929205478169024 max memory_allocated 29273.87548828125 
[2025-03-01 18:59:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.06142207607626915 norm:0.0002576968399807811 max memory_allocated 29273.87548828125 
[2025-03-01 19:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.060444336384534836 norm:0.00021747851860709488 max memory_allocated 29273.87548828125 
[2025-03-01 19:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.05976586788892746 norm:0.00019440671894699335 max memory_allocated 29273.87548828125 
[2025-03-01 19:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.05931580439209938 norm:0.00017891502648126334 max memory_allocated 29273.87548828125 
[2025-03-01 19:03:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.05900483578443527 norm:0.00016737834084779024 max memory_allocated 29273.87548828125 
[2025-03-01 19:03:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.058799389749765396 norm:0.00015757991059217602 max memory_allocated 29273.87548828125 
[2025-03-01 19:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.05864175409078598 norm:0.00015377288218587637 max memory_allocated 29273.87548828125 
[2025-03-01 19:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.05853665992617607 norm:0.00015178062312770635 max memory_allocated 29273.87548828125 
[2025-03-01 19:06:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.05842496454715729 norm:0.00014256275608204305 max memory_allocated 29273.87548828125 
[2025-03-01 19:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.058319371193647385 norm:0.0001352749823126942 max memory_allocated 29273.87548828125 
[2025-03-01 19:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.058250002562999725 norm:0.00013537469203583896 max memory_allocated 29273.87548828125 
[2025-03-01 19:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.05818130820989609 norm:0.00013214816863182932 max memory_allocated 29273.87548828125 
[2025-03-01 19:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.05811891704797745 norm:0.0001312677195528522 max memory_allocated 29273.87548828125 
[2025-03-01 19:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.05805724859237671 norm:0.00013115415640641004 max memory_allocated 29273.87548828125 
[2025-03-01 19:11:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.057990480214357376 norm:0.0001262435398530215 max memory_allocated 29273.87548828125 
[2025-03-01 19:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.0579509511590004 norm:0.00012388125469442457 max memory_allocated 29273.87548828125 
[2025-03-01 19:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.05791935324668884 norm:0.00011664423800539225 max memory_allocated 29273.87548828125 
[2025-03-01 19:13:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-01 19:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.07497084885835648 norm:0.0010344177717342973 max memory_allocated 29274.06298828125 
[2025-03-01 19:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.06770455837249756 norm:0.0005667799850925803 max memory_allocated 29274.06298828125 
[2025-03-01 19:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.06291236728429794 norm:0.00036513034137897193 max memory_allocated 29274.06298828125 
[2025-03-01 19:16:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.061513226479291916 norm:0.00026689562946558 max memory_allocated 29274.06298828125 
[2025-03-01 19:17:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.060654185712337494 norm:0.00022437656298279762 max memory_allocated 29274.06298828125 
[2025-03-01 19:18:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.06004854291677475 norm:0.00019714920199476182 max memory_allocated 29274.06298828125 
[2025-03-01 19:18:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.05964794009923935 norm:0.00017473923799116164 max memory_allocated 29274.06298828125 
[2025-03-01 19:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.05941099300980568 norm:0.00016396641149185598 max memory_allocated 29274.06298828125 
[2025-03-01 19:20:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.05924409627914429 norm:0.0001552124449517578 max memory_allocated 29274.06298828125 
[2025-03-01 19:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.059110209345817566 norm:0.00015008222544565797 max memory_allocated 29274.06298828125 
[2025-03-01 19:22:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.0590180903673172 norm:0.0001465695386286825 max memory_allocated 29274.06298828125 
[2025-03-01 19:23:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.05893001705408096 norm:0.00013941063662059605 max memory_allocated 29274.06298828125 
[2025-03-01 19:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.05883173272013664 norm:0.0001308430073549971 max memory_allocated 29274.06298828125 
[2025-03-01 19:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.0587724931538105 norm:0.00012847117614001036 max memory_allocated 29274.06298828125 
[2025-03-01 19:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.05873877927660942 norm:0.00012966108624823391 max memory_allocated 29274.06298828125 
[2025-03-01 19:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.05869385227560997 norm:0.00012834061635658145 max memory_allocated 29274.06298828125 
[2025-03-01 19:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.058647457510232925 norm:0.0001260598364751786 max memory_allocated 29274.06298828125 
[2025-03-01 19:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.058608438819646835 norm:0.00012523039185907692 max memory_allocated 29274.06298828125 
[2025-03-01 19:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.058577172458171844 norm:0.00012180823250673711 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.0585440993309021 norm:0.00011863216059282422 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-01 19:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.069440558552742 norm:0.0008863502298481762 max memory_allocated 29274.25048828125 
[2025-03-01 19:31:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.06467409431934357 norm:0.00039283264777623117 max memory_allocated 29274.25048828125 
[2025-03-01 19:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.06262607872486115 norm:0.00025292590726166964 max memory_allocated 29274.25048828125 
[2025-03-01 19:33:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.06122436746954918 norm:0.00018896891560871154 max memory_allocated 29274.25048828125 
[2025-03-01 19:34:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.06027698144316673 norm:0.00015446578618139029 max memory_allocated 29274.25048828125 
[2025-03-01 19:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.05969984829425812 norm:0.0001358508161501959 max memory_allocated 29274.25048828125 
[2025-03-01 19:35:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.05934172868728638 norm:0.0001219306286657229 max memory_allocated 29274.25048828125 
[2025-03-01 19:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.059156741946935654 norm:0.00011399389040889218 max memory_allocated 29274.25048828125 
[2025-03-01 19:37:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.05906905233860016 norm:0.00010806982754729688 max memory_allocated 29274.25048828125 
[2025-03-01 19:38:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.05900450423359871 norm:0.00010399240272818133 max memory_allocated 29274.25048828125 
[2025-03-01 19:38:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.058952443301677704 norm:9.962434705812484e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:39:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.05891494080424309 norm:9.650566062191501e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.05887158215045929 norm:9.165899245999753e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:41:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.05883830040693283 norm:8.712177805136889e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:42:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.0588119775056839 norm:8.354068268090487e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.05878894031047821 norm:8.224260091083124e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:43:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.05876666679978371 norm:8.210628584492952e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.058756858110427856 norm:8.125108433887362e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.05875106155872345 norm:7.980453665368259e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:46:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.05874280259013176 norm:7.969645957928151e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:46:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-01 19:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.07046975195407867 norm:0.0007007756503298879 max memory_allocated 29274.43798828125 
[2025-03-01 19:48:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.0668192058801651 norm:0.00034288669121451676 max memory_allocated 29274.43798828125 
[2025-03-01 19:49:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.06488136947154999 norm:0.00022161057859193534 max memory_allocated 29274.43798828125 
[2025-03-01 19:49:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.06358686089515686 norm:0.00016353142564184964 max memory_allocated 29274.43798828125 
[2025-03-01 19:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.06268762052059174 norm:0.00013864596257917583 max memory_allocated 29274.43798828125 
[2025-03-01 19:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.06213593855500221 norm:0.0001250619679922238 max memory_allocated 29274.43798828125 
[2025-03-01 19:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.06181706115603447 norm:0.00011787316179834306 max memory_allocated 29274.43798828125 
[2025-03-01 19:53:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.06163681298494339 norm:0.00010671966447262093 max memory_allocated 29274.43798828125 
[2025-03-01 19:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.06152573600411415 norm:9.935212437994778e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.061439402401447296 norm:9.249964205082506e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.061398740857839584 norm:8.928145689424127e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:56:29 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.06135615333914757 norm:8.895235077943653e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:57:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.061323583126068115 norm:8.922414417611435e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:58:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.0612993948161602 norm:8.337384497281164e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.06128543242812157 norm:8.11577046988532e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:59:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.06126401573419571 norm:7.840071339160204e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.06125957518815994 norm:7.691890641581267e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.0612502284348011 norm:7.695133535889909e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.06122961267828941 norm:7.792703399900347e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:03:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.06122772768139839 norm:7.477138569811359e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:03:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-01 20:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.07268950343132019 norm:0.000630511378403753 max memory_allocated 29274.62548828125 
[2025-03-01 20:05:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.06941202282905579 norm:0.000306123896734789 max memory_allocated 29274.62548828125 
[2025-03-01 20:05:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.0676465854048729 norm:0.00020142956054769456 max memory_allocated 29274.62548828125 
[2025-03-01 20:06:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.06634222716093063 norm:0.00015119329327717423 max memory_allocated 29274.62548828125 
[2025-03-01 20:07:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.06548815220594406 norm:0.000125309030408971 max memory_allocated 29274.62548828125 
[2025-03-01 20:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.06494668126106262 norm:0.00011142326547997072 max memory_allocated 29274.62548828125 
[2025-03-01 20:09:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.06461293250322342 norm:0.00010317962733097374 max memory_allocated 29274.62548828125 
[2025-03-01 20:09:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.06447222828865051 norm:9.808919276110828e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:10:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.0643773227930069 norm:9.253187454305589e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:11:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.06430042535066605 norm:8.830238948576152e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.06424923986196518 norm:8.297386375488713e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.06420926004648209 norm:8.2931321230717e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.06418129801750183 norm:8.196893759304658e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.06417479366064072 norm:7.858245953684673e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.06416642665863037 norm:7.717437256360427e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:16:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.06415225565433502 norm:7.46739751775749e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:17:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.06411376595497131 norm:7.372182881226763e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:18:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.06409967690706253 norm:7.393694249913096e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:18:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.06409785151481628 norm:7.410340913338587e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.06407981365919113 norm:7.295286923181266e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:20:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-01 20:20:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.0789700374007225 norm:0.0008344508241862059 max memory_allocated 29274.81298828125 
[2025-03-01 20:21:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.07472061365842819 norm:0.0004069669230375439 max memory_allocated 29274.81298828125 
[2025-03-01 20:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.07260748744010925 norm:0.0002665465872269124 max memory_allocated 29274.81298828125 
[2025-03-01 20:23:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.07113572955131531 norm:0.00019121883087791502 max memory_allocated 29274.81298828125 
[2025-03-01 20:24:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.07021071761846542 norm:0.00015972343680914491 max memory_allocated 29274.81298828125 
[2025-03-01 20:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.06961072981357574 norm:0.00013938514166511595 max memory_allocated 29274.81298828125 
[2025-03-01 20:25:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.0692434161901474 norm:0.00012950997916050255 max memory_allocated 29274.81298828125 
[2025-03-01 20:26:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.06904959678649902 norm:0.00012038451677653939 max memory_allocated 29274.81298828125 
[2025-03-01 20:27:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.06894343346357346 norm:0.00011732719576684758 max memory_allocated 29274.81298828125 
[2025-03-01 20:28:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.06886858493089676 norm:0.00011003635154338554 max memory_allocated 29274.81298828125 
[2025-03-01 20:29:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.06882023811340332 norm:0.00010625051072565839 max memory_allocated 29274.81298828125 
[2025-03-01 20:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.06877033412456512 norm:0.00010235495574306697 max memory_allocated 29274.81298828125 
[2025-03-01 20:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.06872458755970001 norm:9.993500862037763e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:31:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.06867221742868423 norm:9.519106970401481e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.06864666938781738 norm:9.400556882610545e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.06862905621528625 norm:9.093307016883045e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:34:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.0686369240283966 norm:8.998008706839755e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.0686194896697998 norm:8.632966637378559e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:35:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.06861411780118942 norm:8.392550807911903e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:36:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.06860684603452682 norm:8.429955050814897e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:36:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-01 20:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.07944843173027039 norm:0.0005323977093212306 max memory_allocated 29275.00048828125 
[2025-03-01 20:38:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.07735881954431534 norm:0.00025592712336219847 max memory_allocated 29275.00048828125 
[2025-03-01 20:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.0762866735458374 norm:0.00016239937394857407 max memory_allocated 29275.00048828125 
[2025-03-01 20:40:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.07534356415271759 norm:0.00012717166100628674 max memory_allocated 29275.00048828125 
[2025-03-01 20:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.07447434216737747 norm:0.00010468840628163889 max memory_allocated 29275.00048828125 
[2025-03-01 20:41:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.07388795167207718 norm:9.442307782592252e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:42:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.07358668744564056 norm:8.825906843412668e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.07346199452877045 norm:8.269259706139565e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:44:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.07338796555995941 norm:8.207875362131745e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:45:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.0733487457036972 norm:8.056317165028304e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:45:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.073309525847435 norm:7.802840991644189e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:46:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.07327613234519958 norm:7.857289165258408e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.07325159013271332 norm:7.757642742944881e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:48:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.07322989404201508 norm:7.573122275061905e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.07322279363870621 norm:7.611225009895861e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.07320159673690796 norm:7.909136184025556e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:50:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.07319475710391998 norm:8.5309031419456e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:51:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.07317598909139633 norm:7.422309863613918e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:52:24 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.07318682968616486 norm:7.418680615955964e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:53:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.07317370176315308 norm:7.579005614388734e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:53:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-01 20:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.08567747473716736 norm:0.0005243775667622685 max memory_allocated 29275.18798828125 
[2025-03-01 20:55:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.08362311869859695 norm:0.00027287763077765703 max memory_allocated 29275.18798828125 
[2025-03-01 20:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.08241754025220871 norm:0.00017583077715244144 max memory_allocated 29275.18798828125 
[2025-03-01 20:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.08144276589155197 norm:0.00013334090181160718 max memory_allocated 29275.18798828125 
[2025-03-01 20:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.0805978998541832 norm:0.00011242899199714884 max memory_allocated 29275.18798828125 
[2025-03-01 20:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.07998909801244736 norm:9.992193372454494e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:59:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.07969436794519424 norm:9.321249672211707e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.07956583052873611 norm:8.572113438276574e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:00:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.07949498295783997 norm:8.19604319985956e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.07944399863481522 norm:7.895693852333352e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:02:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.07941076904535294 norm:7.824128988431767e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:03:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.07936853915452957 norm:7.514326716773212e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:04:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.07933414727449417 norm:7.334817928494886e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:05:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.0793083980679512 norm:7.283506420208141e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:05:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.07929373532533646 norm:0.00011249793897150084 max memory_allocated 29275.18798828125 
[2025-03-01 21:06:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.07928463816642761 norm:7.063768134685233e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.07927137613296509 norm:7.005254155956209e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.07925420999526978 norm:6.996378942858428e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.07923911511898041 norm:7.00710661476478e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.07922609150409698 norm:7.030690176179633e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:10:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-01 21:11:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.09169288724660873 norm:0.0005013311747461557 max memory_allocated 29275.37548828125 
[2025-03-01 21:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.08987218886613846 norm:0.00027461210265755653 max memory_allocated 29275.37548828125 
[2025-03-01 21:12:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.08883008360862732 norm:0.00017773683066479862 max memory_allocated 29275.37548828125 
[2025-03-01 21:13:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.08797786384820938 norm:0.00013445253716781735 max memory_allocated 29275.37548828125 
[2025-03-01 21:14:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.08714036643505096 norm:0.00011512144556036219 max memory_allocated 29275.37548828125 
[2025-03-01 21:15:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.08651818335056305 norm:9.922392200678587e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:16:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.08622559159994125 norm:9.276643686462194e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:16:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.08611568808555603 norm:9.173282887786627e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.08604992926120758 norm:8.850137965055183e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:18:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.08600983768701553 norm:8.408425492234528e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.08596401661634445 norm:8.254202839452773e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:20:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.08593958616256714 norm:9.475324623053893e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:20:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.0859256386756897 norm:8.783624070929363e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:21:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.08591504395008087 norm:9.895455150399357e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:22:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.08590315282344818 norm:9.397290705237538e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:23:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.08589387685060501 norm:9.373137436341494e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:24:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.08589452505111694 norm:0.00010577141802059487 max memory_allocated 29275.37548828125 
[2025-03-01 21:25:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.08588068932294846 norm:0.00010335743718314916 max memory_allocated 29275.37548828125 
[2025-03-01 21:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.08588247746229172 norm:0.00010084946552524343 max memory_allocated 29275.37548828125 
[2025-03-01 21:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.08586810529232025 norm:9.322263940703124e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:26:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-01 21:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.09940359741449356 norm:0.0004885178641416132 max memory_allocated 29275.56298828125 
[2025-03-01 21:28:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.09770829230546951 norm:0.000262696499703452 max memory_allocated 29275.56298828125 
[2025-03-01 21:29:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.09671759605407715 norm:0.00017233483958989382 max memory_allocated 29275.56298828125 
[2025-03-01 21:30:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.09580957889556885 norm:0.0001289716747123748 max memory_allocated 29275.56298828125 
[2025-03-01 21:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.09487860649824142 norm:0.00010719588317442685 max memory_allocated 29275.56298828125 
[2025-03-01 21:31:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.09423268586397171 norm:9.446122567169368e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.09396851062774658 norm:8.498549141222611e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.09387902915477753 norm:7.872252899687737e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:34:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.09381334483623505 norm:7.55351793486625e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:35:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.09377935528755188 norm:7.315106631722301e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.09374818205833435 norm:7.195740181487054e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:36:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.09372156113386154 norm:6.820872658863664e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.09370043873786926 norm:6.674074393231422e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.09368569403886795 norm:6.27934277872555e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.09367581456899643 norm:6.232080340851098e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:40:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.09366205334663391 norm:6.133088754722849e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:40:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.09364594519138336 norm:6.232057057786733e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.09363913536071777 norm:6.160933116916567e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.09363164007663727 norm:6.172052235342562e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.09363012760877609 norm:6.380855484167114e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:43:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-01 21:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.1087861880660057 norm:0.0005042364355176687 max memory_allocated 29275.75048828125 
[2025-03-01 21:45:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.10704527050256729 norm:0.000286791124381125 max memory_allocated 29275.75048828125 
[2025-03-01 21:46:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.10591231286525726 norm:0.00020346684323158115 max memory_allocated 29275.75048828125 
[2025-03-01 21:46:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.10485631227493286 norm:0.00015963209443725646 max memory_allocated 29275.75048828125 
[2025-03-01 21:47:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.10383737087249756 norm:0.00014118956460151821 max memory_allocated 29275.75048828125 
[2025-03-01 21:48:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.10316235572099686 norm:0.0001308001228608191 max memory_allocated 29275.75048828125 
[2025-03-01 21:49:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.102887824177742 norm:0.0001225885353051126 max memory_allocated 29275.75048828125 
[2025-03-01 21:50:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.10277511924505234 norm:0.00011586599430302158 max memory_allocated 29275.75048828125 
[2025-03-01 21:51:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.1027129739522934 norm:0.00011169392382726073 max memory_allocated 29275.75048828125 
[2025-03-01 21:51:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.10267004370689392 norm:0.00010057930194307119 max memory_allocated 29275.75048828125 
[2025-03-01 21:52:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.10263259708881378 norm:9.540661267237738e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.10260702669620514 norm:9.380161645822227e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.10259023308753967 norm:9.702222450869158e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:55:12 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.10255395621061325 norm:9.443779708817601e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:56:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.10253676772117615 norm:9.526408393867314e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.10252946615219116 norm:9.893733658827841e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:57:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.10252579301595688 norm:0.00010232780186925083 max memory_allocated 29275.75048828125 
[2025-03-01 21:58:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.10253380984067917 norm:0.00010174079943681136 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.10251881182193756 norm:9.672786109149456e-05 max memory_allocated 29275.75048828125 
[2025-03-01 22:00:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.10252109915018082 norm:9.532814146950841e-05 max memory_allocated 29275.75048828125 
[2025-03-01 22:00:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-01 22:01:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.11678186058998108 norm:0.0003219802747480571 max memory_allocated 29275.93798828125 
[2025-03-01 22:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.11544287949800491 norm:0.00019150505249854177 max memory_allocated 29275.93798828125 
[2025-03-01 22:02:54 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.11459875106811523 norm:0.00013967709674034268 max memory_allocated 29275.93798828125 
[2025-03-01 22:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.1136942207813263 norm:0.00011280489707132801 max memory_allocated 29275.93798828125 
[2025-03-01 22:04:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.11267238110303879 norm:0.0001252402289537713 max memory_allocated 29275.93798828125 
[2025-03-01 22:05:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.11203226447105408 norm:8.916365914046764e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:06:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.11181820929050446 norm:8.225659257732332e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.11172744631767273 norm:7.681579882046208e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:07:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.11167579144239426 norm:7.170892786234617e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:08:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.11163382232189178 norm:7.252689101733267e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:09:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.11160621047019958 norm:7.158996595535427e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.11159002780914307 norm:6.926314381416887e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:11:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.11157260835170746 norm:6.996262527536601e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:11:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.1115504652261734 norm:6.888131611049175e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.11153820157051086 norm:6.618259794777259e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.11153830587863922 norm:6.667515845037997e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:14:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.11153310537338257 norm:6.684890104224905e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.11152923852205276 norm:6.491498788818717e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.1115160807967186 norm:6.480260344687849e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.11150971800088882 norm:6.614615995204076e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:17:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-01 22:17:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.12946586310863495 norm:0.000612816191278398 max memory_allocated 29276.12548828125 
[2025-03-01 22:18:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.12740954756736755 norm:0.00037804688327014446 max memory_allocated 29276.12548828125 
[2025-03-01 22:19:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.12608648836612701 norm:0.0002729756524786353 max memory_allocated 29276.12548828125 
[2025-03-01 22:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.12497847527265549 norm:0.0002223113551735878 max memory_allocated 29276.12548828125 
[2025-03-01 22:21:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.12380892038345337 norm:0.0001907018304336816 max memory_allocated 29276.12548828125 
[2025-03-01 22:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.12316188216209412 norm:0.00017985710292123258 max memory_allocated 29276.12548828125 
[2025-03-01 22:22:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.12293528020381927 norm:0.0001584704004926607 max memory_allocated 29276.12548828125 
[2025-03-01 22:23:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.12281598895788193 norm:0.00014681446191389114 max memory_allocated 29276.12548828125 
[2025-03-01 22:24:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.12273211777210236 norm:0.00014814500173088163 max memory_allocated 29276.12548828125 
[2025-03-01 22:25:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.12269242852926254 norm:0.00014868589641992003 max memory_allocated 29276.12548828125 
[2025-03-01 22:26:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.12260828167200089 norm:0.00013594061601907015 max memory_allocated 29276.12548828125 
[2025-03-01 22:27:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.12256978452205658 norm:0.00015046383487060666 max memory_allocated 29276.12548828125 
[2025-03-01 22:27:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.12253174185752869 norm:0.00014280792674981058 max memory_allocated 29276.12548828125 
[2025-03-01 22:28:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.1225040853023529 norm:0.0001422208151780069 max memory_allocated 29276.12548828125 
[2025-03-01 22:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.1224995106458664 norm:0.00014573417138308287 max memory_allocated 29276.12548828125 
[2025-03-01 22:30:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.12249787896871567 norm:0.00013955097529105842 max memory_allocated 29276.12548828125 
[2025-03-01 22:31:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.12246179580688477 norm:0.00012063635949743912 max memory_allocated 29276.12548828125 
[2025-03-01 22:31:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.12242556363344193 norm:0.00012467203487176448 max memory_allocated 29276.12548828125 
[2025-03-01 22:32:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.12242339551448822 norm:0.00011532593634910882 max memory_allocated 29276.12548828125 
[2025-03-01 22:33:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.12243108451366425 norm:0.00011488445306895301 max memory_allocated 29276.12548828125 
[2025-03-01 22:33:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-01 22:34:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.13907523453235626 norm:0.00044886101386509836 max memory_allocated 29276.31298828125 
[2025-03-01 22:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.13773173093795776 norm:0.00025837839348241687 max memory_allocated 29276.31298828125 
[2025-03-01 22:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.13685336709022522 norm:0.00018295005429536104 max memory_allocated 29276.31298828125 
[2025-03-01 22:37:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.13581977784633636 norm:0.00014194291725289077 max memory_allocated 29276.31298828125 
[2025-03-01 22:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.13470269739627838 norm:0.00011667953367577866 max memory_allocated 29276.31298828125 
[2025-03-01 22:38:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.1341157704591751 norm:0.00011400876246625558 max memory_allocated 29276.31298828125 
[2025-03-01 22:39:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.13393062353134155 norm:9.355287329526618e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.13384512066841125 norm:8.714315481483936e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.13378582894802094 norm:8.297957538161427e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.13375338912010193 norm:7.924069359432906e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:42:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.13371542096138 norm:7.460398046532646e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.13369397819042206 norm:7.330549851758406e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.1336839497089386 norm:7.243824802571908e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:45:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.13367271423339844 norm:7.426744559779763e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:46:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.13366848230361938 norm:7.289732457138598e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:47:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.1336570531129837 norm:7.079316856106743e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:47:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.13364726305007935 norm:7.157672371249646e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:48:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.13363490998744965 norm:7.054582965793088e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:49:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.13363298773765564 norm:7.070109859341756e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:50:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.13362683355808258 norm:7.078654016368091e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:50:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-01 22:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.15337932109832764 norm:0.0005085408920422196 max memory_allocated 29276.50048828125 
[2025-03-01 22:52:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.15139004588127136 norm:0.00027863390278071165 max memory_allocated 29276.50048828125 
[2025-03-01 22:53:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.15004529058933258 norm:0.00018760176317300647 max memory_allocated 29276.50048828125 
[2025-03-01 22:53:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.14873002469539642 norm:0.0001456591853639111 max memory_allocated 29276.50048828125 
[2025-03-01 22:54:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.14748691022396088 norm:0.00012195280578453094 max memory_allocated 29276.50048828125 
[2025-03-01 22:55:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.1469665914773941 norm:0.00013627030421048403 max memory_allocated 29276.50048828125 
[2025-03-01 22:56:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.14681464433670044 norm:9.995420259656385e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.146720290184021 norm:9.280002268496901e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:58:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.14665745198726654 norm:8.832921594148502e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:58:50 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.14660689234733582 norm:8.61765947774984e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.14657998085021973 norm:8.479959069518372e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:00:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.14655491709709167 norm:8.273062121588737e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:01:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.14653164148330688 norm:8.024916314752772e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:02:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.1465180516242981 norm:7.986211858224124e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:02:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.14650365710258484 norm:7.745087350485846e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:03:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.14648693799972534 norm:7.7214659540914e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:04:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.14647172391414642 norm:7.813820411683992e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:05:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.14647039771080017 norm:8.039531530812383e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:06:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.14646461606025696 norm:7.946373079903424e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.14645414054393768 norm:7.863491919124499e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:07:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-01 23:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.166215181350708 norm:0.0004441276250872761 max memory_allocated 29276.68798828125 
[2025-03-01 23:08:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.16467879712581635 norm:0.00024177719024010003 max memory_allocated 29276.68798828125 
[2025-03-01 23:09:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.16351211071014404 norm:0.00017091345216613263 max memory_allocated 29276.68798828125 
[2025-03-01 23:10:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.16213317215442657 norm:0.00013166165444999933 max memory_allocated 29276.68798828125 
[2025-03-01 23:11:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.160933256149292 norm:0.00011084631842095405 max memory_allocated 29276.68798828125 
[2025-03-01 23:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.16054660081863403 norm:9.970355313271284e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:13:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.16043204069137573 norm:9.320639219367877e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.16035959124565125 norm:9.001762373372912e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:14:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.16031302511692047 norm:8.974314550869167e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.1602775901556015 norm:8.722858183318749e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:16:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.16025274991989136 norm:8.710010297363624e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.16023051738739014 norm:8.628296927781776e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:18:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.1602075695991516 norm:8.564131712773815e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.16018575429916382 norm:8.499121031491086e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.16018059849739075 norm:8.549635094823316e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:20:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.16017861664295197 norm:8.314329170389101e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:21:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.16018792986869812 norm:8.658586739329621e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.16018174588680267 norm:8.739916665945202e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:22:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.16016730666160583 norm:8.717863966012374e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:23:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.16015975177288055 norm:8.456168143311515e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:24:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-01 23:24:53 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.18313570320606232 norm:0.0005666540237143636 max memory_allocated 29276.87548828125 
[2025-03-01 23:25:42 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.18104074895381927 norm:0.00030683507793582976 max memory_allocated 29276.87548828125 
[2025-03-01 23:26:32 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.17955082654953003 norm:0.00021105378982611 max memory_allocated 29276.87548828125 
[2025-03-01 23:27:21 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.177888885140419 norm:0.00016012226114980876 max memory_allocated 29276.87548828125 
[2025-03-01 23:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.17656674981117249 norm:0.0001320539158768952 max memory_allocated 29276.87548828125 
[2025-03-01 23:28:59 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.17617446184158325 norm:0.00011775908205891028 max memory_allocated 29276.87548828125 
[2025-03-01 23:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.1760476976633072 norm:0.00010945291433017701 max memory_allocated 29276.87548828125 
[2025-03-01 23:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.17593234777450562 norm:0.00010544832912273705 max memory_allocated 29276.87548828125 
[2025-03-01 23:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.17586946487426758 norm:0.0001022226206259802 max memory_allocated 29276.87548828125 
[2025-03-01 23:32:16 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.1758180558681488 norm:9.523139306111261e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.1757938712835312 norm:9.017281990963966e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:55 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.1757761836051941 norm:8.85110639501363e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.175765722990036 norm:8.775035530561581e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:35:33 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.17572593688964844 norm:8.688480011187494e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:36:23 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.17570830881595612 norm:8.516886009601876e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:37:12 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.17569056153297424 norm:8.481646364089102e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:38:01 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.1756828874349594 norm:8.54889367474243e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:38:50 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.17565825581550598 norm:8.777445327723399e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:39:40 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.1756698340177536 norm:8.84963374119252e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.17566047608852386 norm:8.863667608238757e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:40:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-01 23:41:36 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.19868165254592896 norm:0.0005013902555219829 max memory_allocated 29277.06298828125 
[2025-03-01 23:42:25 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.19667141139507294 norm:0.00028089925763197243 max memory_allocated 29277.06298828125 
[2025-03-01 23:43:15 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.19518834352493286 norm:0.0001883706427179277 max memory_allocated 29277.06298828125 
[2025-03-01 23:44:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.19355329871177673 norm:0.00014211543020792305 max memory_allocated 29277.06298828125 
[2025-03-01 23:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.19227635860443115 norm:0.0001244985032826662 max memory_allocated 29277.06298828125 
[2025-03-01 23:45:42 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.1919240951538086 norm:0.00011517202074173838 max memory_allocated 29277.06298828125 
[2025-03-01 23:46:32 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.1918056160211563 norm:0.00011222008470213041 max memory_allocated 29277.06298828125 
[2025-03-01 23:47:21 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.1917051374912262 norm:0.00010246861347695813 max memory_allocated 29277.06298828125 
[2025-03-01 23:48:10 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.19167111814022064 norm:0.00010166955325985327 max memory_allocated 29277.06298828125 
[2025-03-01 23:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.1916416734457016 norm:0.00010004056093748659 max memory_allocated 29277.06298828125 
[2025-03-01 23:49:49 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.19160683453083038 norm:9.73811256699264e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:50:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.19157426059246063 norm:9.724689880385995e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.19156327843666077 norm:9.593940194463357e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:52:17 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.19153423607349396 norm:9.582965867593884e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.1915285587310791 norm:9.429599595023319e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:53:55 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.19153271615505219 norm:9.557756129652262e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:54:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.1915493905544281 norm:9.556971781421453e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.19153478741645813 norm:9.749596210895106e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.19151419401168823 norm:9.543511259835213e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:57:12 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.19151192903518677 norm:9.518404840491712e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:57:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-01 23:58:20 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.22035488486289978 norm:0.0005608162609860301 max memory_allocated 29277.25048828125 
[2025-03-01 23:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.2176508903503418 norm:0.0002953480579890311 max memory_allocated 29277.25048828125 
[2025-03-01 23:59:58 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.21567900478839874 norm:0.00020261024474166334 max memory_allocated 29277.25048828125 
[2025-03-02 00:00:47 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.21368816494941711 norm:0.00015863061707932502 max memory_allocated 29277.25048828125 
[2025-03-02 00:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.2124691903591156 norm:0.0001387101801810786 max memory_allocated 29277.25048828125 
[2025-03-02 00:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.2121700793504715 norm:0.00012958368461113423 max memory_allocated 29277.25048828125 
[2025-03-02 00:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.21199968457221985 norm:0.00011960025585722178 max memory_allocated 29277.25048828125 
[2025-03-02 00:04:04 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.21191152930259705 norm:0.00011541402636794373 max memory_allocated 29277.25048828125 
[2025-03-02 00:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.21185214817523956 norm:0.0001119251101044938 max memory_allocated 29277.25048828125 
[2025-03-02 00:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.2117859423160553 norm:0.00010704551095841452 max memory_allocated 29277.25048828125 
[2025-03-02 00:06:32 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.2117394059896469 norm:0.00010382565233157948 max memory_allocated 29277.25048828125 
[2025-03-02 00:07:21 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.21171611547470093 norm:0.00010303064482286572 max memory_allocated 29277.25048828125 
[2025-03-02 00:08:11 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.21168828010559082 norm:9.965210483642295e-05 max memory_allocated 29277.25048828125 
[2025-03-02 00:09:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.211674302816391 norm:9.821164712775499e-05 max memory_allocated 29277.25048828125 
[2025-03-02 00:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.21166235208511353 norm:9.673861495684832e-05 max memory_allocated 29277.25048828125 
[2025-03-02 00:10:39 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.21164660155773163 norm:9.222837979905307e-05 max memory_allocated 29277.25048828125 
[2025-03-02 00:11:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.21163229644298553 norm:9.195561870001256e-05 max memory_allocated 29277.25048828125 
[2025-03-02 00:12:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.21162094175815582 norm:9.184192458633333e-05 max memory_allocated 29277.25048828125 
[2025-03-02 00:13:06 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.2116186022758484 norm:9.22217222978361e-05 max memory_allocated 29277.25048828125 
[2025-03-02 00:13:56 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.21161292493343353 norm:9.180005872622132e-05 max memory_allocated 29277.25048828125 
[2025-03-02 00:14:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 00:15:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.24267926812171936 norm:0.0010010822443291545 max memory_allocated 29277.43798828125 
[2025-03-02 00:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.239695206284523 norm:0.0005331680295057595 max memory_allocated 29277.43798828125 
[2025-03-02 00:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.23739822208881378 norm:0.0003416487597860396 max memory_allocated 29277.43798828125 
[2025-03-02 00:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.23509906232357025 norm:0.00024175895669031888 max memory_allocated 29277.43798828125 
[2025-03-02 00:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.2339126616716385 norm:0.00019033749413210899 max memory_allocated 29277.43798828125 
[2025-03-02 00:19:10 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.23357565701007843 norm:0.00016058671462815255 max memory_allocated 29277.43798828125 
[2025-03-02 00:19:59 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.23343999683856964 norm:0.0001421658816980198 max memory_allocated 29277.43798828125 
[2025-03-02 00:20:48 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.23335061967372894 norm:0.0001282498997170478 max memory_allocated 29277.43798828125 
[2025-03-02 00:21:38 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.23329997062683105 norm:0.0001204565996886231 max memory_allocated 29277.43798828125 
[2025-03-02 00:22:27 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.23325884342193604 norm:0.00011572468065423891 max memory_allocated 29277.43798828125 
[2025-03-02 00:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.23322203755378723 norm:0.00011320885096210986 max memory_allocated 29277.43798828125 
[2025-03-02 00:24:05 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.23318491876125336 norm:0.0001112179525080137 max memory_allocated 29277.43798828125 
[2025-03-02 00:24:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.23315176367759705 norm:0.00010590106103336439 max memory_allocated 29277.43798828125 
[2025-03-02 00:25:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.23313771188259125 norm:0.00010555938933975995 max memory_allocated 29277.43798828125 
[2025-03-02 00:26:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.23311683535575867 norm:0.00010666580055840313 max memory_allocated 29277.43798828125 
[2025-03-02 00:27:23 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.23310400545597076 norm:0.00010695023229345679 max memory_allocated 29277.43798828125 
[2025-03-02 00:28:12 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.23309700191020966 norm:0.00010756425763247535 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:01 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.233086958527565 norm:0.00010705502063501626 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:50 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.2330785095691681 norm:0.00010654910875018686 max memory_allocated 29277.43798828125 
[2025-03-02 00:30:40 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.23307177424430847 norm:0.0001063272065948695 max memory_allocated 29277.43798828125 
[2025-03-02 00:30:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 00:30:58 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:31:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.2740730941295624 norm:0.00716821476817131 max memory_allocated 29277.77001953125 
[2025-03-02 00:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.2688472270965576 norm:0.005465616937726736 max memory_allocated 29277.77001953125 
[2025-03-02 00:33:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.2653062343597412 norm:0.004329374060034752 max memory_allocated 29277.77001953125 
[2025-03-02 00:34:16 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.26227283477783203 norm:0.0034564801026135683 max memory_allocated 29277.77001953125 
[2025-03-02 00:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.2609250247478485 norm:0.0028407215140759945 max memory_allocated 29277.77001953125 
[2025-03-02 00:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.26045334339141846 norm:0.0023722017649561167 max memory_allocated 29277.77001953125 
[2025-03-02 00:36:44 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.2601906657218933 norm:0.002107208361849189 max memory_allocated 29277.77001953125 
[2025-03-02 00:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.25999313592910767 norm:0.0020484421402215958 max memory_allocated 29277.77001953125 
[2025-03-02 00:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.2598988115787506 norm:0.0020443478133529425 max memory_allocated 29277.77001953125 
[2025-03-02 00:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.25979602336883545 norm:0.002049555303528905 max memory_allocated 29277.77001953125 
[2025-03-02 00:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.2596886157989502 norm:0.0018711942248046398 max memory_allocated 29277.77001953125 
[2025-03-02 00:40:51 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.25967374444007874 norm:0.001896667294204235 max memory_allocated 29277.77001953125 
[2025-03-02 00:41:40 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.2596125602722168 norm:0.0018609969411045313 max memory_allocated 29277.77001953125 
[2025-03-02 00:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.25963136553764343 norm:0.0016906507080420852 max memory_allocated 29277.77001953125 
[2025-03-02 00:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.2595251500606537 norm:0.001775495707988739 max memory_allocated 29277.77001953125 
[2025-03-02 00:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.25960105657577515 norm:0.001603099051862955 max memory_allocated 29277.77001953125 
[2025-03-02 00:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.25946077704429626 norm:0.0017206385964527726 max memory_allocated 29277.77001953125 
[2025-03-02 00:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.25945529341697693 norm:0.001548188622109592 max memory_allocated 29277.77001953125 
[2025-03-02 00:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.25939738750457764 norm:0.0016740817809477448 max memory_allocated 29277.77001953125 
[2025-03-02 00:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.2595096826553345 norm:0.0014909105375409126 max memory_allocated 29277.77001953125 
[2025-03-02 00:47:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 00:47:44 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:48:34 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.3080788552761078 norm:0.007850253954529762 max memory_allocated 29277.95751953125 
[2025-03-02 00:49:23 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.30147528648376465 norm:0.0061960648745298386 max memory_allocated 29277.95751953125 
[2025-03-02 00:50:13 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.29615092277526855 norm:0.004765101708471775 max memory_allocated 29277.95751953125 
[2025-03-02 00:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.29245078563690186 norm:0.003798578167334199 max memory_allocated 29277.95751953125 
[2025-03-02 00:51:51 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.29100432991981506 norm:0.003218677593395114 max memory_allocated 29277.95751953125 
[2025-03-02 00:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.2904335558414459 norm:0.00278096622787416 max memory_allocated 29277.95751953125 
[2025-03-02 00:53:30 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.2900223135948181 norm:0.002459182869642973 max memory_allocated 29277.95751953125 
[2025-03-02 00:54:20 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.28982222080230713 norm:0.002362721599638462 max memory_allocated 29277.95751953125 
[2025-03-02 00:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.28968900442123413 norm:0.002287506125867367 max memory_allocated 29277.95751953125 
[2025-03-02 00:55:58 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.28961417078971863 norm:0.0022784294560551643 max memory_allocated 29277.95751953125 
[2025-03-02 00:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.2895078957080841 norm:0.002225393196567893 max memory_allocated 29277.95751953125 
[2025-03-02 00:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.289442777633667 norm:0.002201753668487072 max memory_allocated 29277.95751953125 
[2025-03-02 00:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.28937581181526184 norm:0.0021570560056716204 max memory_allocated 29277.95751953125 
[2025-03-02 00:59:16 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.2893107533454895 norm:0.0021462596487253904 max memory_allocated 29277.95751953125 
[2025-03-02 01:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.28926584124565125 norm:0.0020808710251003504 max memory_allocated 29277.95751953125 
[2025-03-02 01:00:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.2892165184020996 norm:0.0020968103781342506 max memory_allocated 29277.95751953125 
[2025-03-02 01:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.2891387939453125 norm:0.001981819048523903 max memory_allocated 29277.95751953125 
[2025-03-02 01:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.2891070544719696 norm:0.001956891966983676 max memory_allocated 29277.95751953125 
[2025-03-02 01:03:23 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.2890331447124481 norm:0.0019275719532743096 max memory_allocated 29277.95751953125 
[2025-03-02 01:04:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.28899022936820984 norm:0.0018557594157755375 max memory_allocated 29277.95751953125 
[2025-03-02 01:04:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 01:04:31 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.3682498633861542 norm:0.010743857361376286 max memory_allocated 29278.14501953125 
[2025-03-02 01:06:09 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.3561271131038666 norm:0.005299283657222986 max memory_allocated 29278.14501953125 
[2025-03-02 01:06:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.3451175093650818 norm:0.004293298348784447 max memory_allocated 29278.14501953125 
[2025-03-02 01:07:48 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.34034931659698486 norm:0.0042540524154901505 max memory_allocated 29278.14501953125 
[2025-03-02 01:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.3387877643108368 norm:0.004093505907803774 max memory_allocated 29278.14501953125 
[2025-03-02 01:09:27 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.3378666341304779 norm:0.0038704201579093933 max memory_allocated 29278.14501953125 
[2025-03-02 01:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.33732807636260986 norm:0.0037899056915193796 max memory_allocated 29278.14501953125 
[2025-03-02 01:11:06 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.33688884973526 norm:0.003622491145506501 max memory_allocated 29278.14501953125 
[2025-03-02 01:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.3365851640701294 norm:0.0034664764534682035 max memory_allocated 29278.14501953125 
[2025-03-02 01:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.3364102840423584 norm:0.0033926344476640224 max memory_allocated 29278.14501953125 
[2025-03-02 01:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.33623436093330383 norm:0.003396830754354596 max memory_allocated 29278.14501953125 
[2025-03-02 01:14:23 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.33611369132995605 norm:0.003313962835818529 max memory_allocated 29278.14501953125 
[2025-03-02 01:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.33595162630081177 norm:0.003136171493679285 max memory_allocated 29278.14501953125 
[2025-03-02 01:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.33578377962112427 norm:0.003041689284145832 max memory_allocated 29278.14501953125 
[2025-03-02 01:16:52 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.3357793688774109 norm:0.003009053645655513 max memory_allocated 29278.14501953125 
[2025-03-02 01:17:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.3357003629207611 norm:0.0029962295666337013 max memory_allocated 29278.14501953125 
[2025-03-02 01:18:30 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.3356727063655853 norm:0.0030081584118306637 max memory_allocated 29278.14501953125 
[2025-03-02 01:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.33560624718666077 norm:0.0029760359320789576 max memory_allocated 29278.14501953125 
[2025-03-02 01:20:09 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.3355746865272522 norm:0.0030404645949602127 max memory_allocated 29278.14501953125 
[2025-03-02 01:20:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.3355276584625244 norm:0.003013808513060212 max memory_allocated 29278.14501953125 
[2025-03-02 01:21:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 01:21:17 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:22:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.5439229607582092 norm:0.03981628268957138 max memory_allocated 29278.33251953125 
[2025-03-02 01:22:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.49771133065223694 norm:0.021863367408514023 max memory_allocated 29278.33251953125 
[2025-03-02 01:23:45 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.4774983823299408 norm:0.015170307829976082 max memory_allocated 29278.33251953125 
[2025-03-02 01:24:35 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.46586349606513977 norm:0.012951442040503025 max memory_allocated 29278.33251953125 
[2025-03-02 01:25:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.459310382604599 norm:0.012109809555113316 max memory_allocated 29278.33251953125 
[2025-03-02 01:26:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.45533138513565063 norm:0.011045766063034534 max memory_allocated 29278.33251953125 
[2025-03-02 01:27:03 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.45281267166137695 norm:0.010573501698672771 max memory_allocated 29278.33251953125 
[2025-03-02 01:27:53 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.4508903920650482 norm:0.010221663862466812 max memory_allocated 29278.33251953125 
[2025-03-02 01:28:42 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.4492985010147095 norm:0.010053238831460476 max memory_allocated 29278.33251953125 
[2025-03-02 01:29:31 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.4482225775718689 norm:0.010183691047132015 max memory_allocated 29278.33251953125 
[2025-03-02 01:30:21 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.4474638104438782 norm:0.009859553538262844 max memory_allocated 29278.33251953125 
[2025-03-02 01:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.44682440161705017 norm:0.00954452808946371 max memory_allocated 29278.33251953125 
[2025-03-02 01:31:59 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.4462379217147827 norm:0.009166650474071503 max memory_allocated 29278.33251953125 
[2025-03-02 01:32:49 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.4457431733608246 norm:0.008909638971090317 max memory_allocated 29278.33251953125 
[2025-03-02 01:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.4450142979621887 norm:0.0086520966142416 max memory_allocated 29278.33251953125 
[2025-03-02 01:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.4447820484638214 norm:0.00865190476179123 max memory_allocated 29278.33251953125 
[2025-03-02 01:35:17 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.4441012740135193 norm:0.008322822861373425 max memory_allocated 29278.33251953125 
[2025-03-02 01:36:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.44379931688308716 norm:0.00820525735616684 max memory_allocated 29278.33251953125 
[2025-03-02 01:36:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.44363462924957275 norm:0.008244180120527744 max memory_allocated 29278.33251953125 
[2025-03-02 01:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.44305896759033203 norm:0.007607797626405954 max memory_allocated 29278.33251953125 
[2025-03-02 01:38:00 root] (main_calib_config2.py 380): INFO 40177.193470954895
[2025-03-02 01:38:09 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-02 01:40:05 root] (main_calib_config2.py 159): INFO wikitext2 : 5.059929847717285
[2025-03-02 01:40:05 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-02 01:43:04 root] (main_calib_config2.py 159): INFO c4 : 6.7044148445129395
[2025-03-02 03:50:01 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.059929847717285, 'c4': 6.7044148445129395, 'results': {'arc_challenge': {'acc': 0.42406143344709896, 'acc_stderr': 0.014441889627464396, 'acc_norm': 0.4232081911262799, 'acc_norm_stderr': 0.014438036220848029}, 'piqa': {'acc': 0.780739934711643, 'acc_stderr': 0.009653357463605301, 'acc_norm': 0.7840043525571273, 'acc_norm_stderr': 0.009601236303553546}, 'boolq': {'acc': 0.6703363914373088, 'acc_stderr': 0.008221942635482617}, 'arc_easy': {'acc': 0.7041245791245792, 'acc_stderr': 0.009365854134140065, 'acc_norm': 0.5534511784511784, 'acc_norm_stderr': 0.0102009900762453}, 'winogrande': {'acc': 0.6795580110497238, 'acc_stderr': 0.01311508545768171}, 'hellaswag': {'acc': 0.5877315275841466, 'acc_stderr': 0.004912370023913013, 'acc_norm': 0.7533359888468433, 'acc_norm_stderr': 0.004301884727122817}}, 'versions': {'arc_challenge': 0, 'piqa': 0, 'boolq': 1, 'arc_easy': 0, 'winogrande': 0, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
