[2025-03-02 03:28:16 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.3', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.3.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 03:30:43 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-02 03:30:43 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.3.pkl
[2025-03-02 03:30:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 03:30:51 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.05954686924815178 norm:0.03540673851966858 max memory_allocated 22559.10693359375 
[2025-03-02 03:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0410173274576664 norm:0.020310603082180023 max memory_allocated 22559.10693359375 
[2025-03-02 03:32:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.033123213797807693 norm:0.014151222072541714 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.030312763527035713 norm:0.012403255328536034 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.029034847393631935 norm:0.01086744386702776 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.028157439082860947 norm:0.009304835461080074 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.027572838589549065 norm:0.008088380098342896 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.027102487161755562 norm:0.00696822814643383 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.026754580438137054 norm:0.006080687511712313 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.026495622470974922 norm:0.005361254792660475 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0264247115701437 norm:0.004855012521147728 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.026342591270804405 norm:0.004328075796365738 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.02622682973742485 norm:0.003995741717517376 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.02620571479201317 norm:0.003807544242590666 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.02610022947192192 norm:0.0036140703596174717 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.026060106232762337 norm:0.003462765133008361 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.02602769434452057 norm:0.003362619783729315 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.026019304990768433 norm:0.0032446456607431173 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.026035774499177933 norm:0.0031227858271449804 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.026001600548624992 norm:0.0030993237160146236 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 03:42:15 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.19452539086341858 norm:0.07692903280258179 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.12153342366218567 norm:0.035801757127046585 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:56 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.09584517776966095 norm:0.021806340664625168 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.08565966039896011 norm:0.01679050922393799 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.08069678395986557 norm:0.014415254816412926 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.077586330473423 norm:0.012519657611846924 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.07553520053625107 norm:0.010995205491781235 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.07417985796928406 norm:0.009912046603858471 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.0732998326420784 norm:0.008867685683071613 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.07254412770271301 norm:0.007736231200397015 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.0720512643456459 norm:0.007062582764774561 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.0717010423541069 norm:0.0063741556368768215 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.0712512657046318 norm:0.005764438305050135 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.07096078991889954 norm:0.00536759477108717 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.07075853645801544 norm:0.005120243411511183 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.07055306434631348 norm:0.004866546485573053 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.07040007412433624 norm:0.004683406557887793 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.07024344056844711 norm:0.004564009606838226 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.07013446092605591 norm:0.0045263259671628475 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.07004767656326294 norm:0.004528669640421867 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 03:53:41 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:54:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.2346855103969574 norm:0.036503907293081284 max memory_allocated 22559.45068359375 
[2025-03-02 03:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.19232957065105438 norm:0.03554757684469223 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.17468690872192383 norm:0.02009725570678711 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.16495411098003387 norm:0.016376247629523277 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.1603439748287201 norm:0.01610940881073475 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.1559792011976242 norm:0.014993870630860329 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.15345437824726105 norm:0.014843398705124855 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.15313725173473358 norm:0.015647022053599358 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.14731408655643463 norm:0.015298010781407356 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.14835581183433533 norm:0.014142507687211037 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.14914920926094055 norm:0.013704616576433182 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.14370857179164886 norm:0.01339960191398859 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:59 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.14542189240455627 norm:0.01382969319820404 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.14424365758895874 norm:0.01288628950715065 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.14458969235420227 norm:0.01260748878121376 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.1425887495279312 norm:0.013423718512058258 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.13700056076049805 norm:0.010625011287629604 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.13669836521148682 norm:0.010283189825713634 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.14099885523319244 norm:0.01168146077543497 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.13943344354629517 norm:0.010050078853964806 max memory_allocated 22559.45068359375 
[2025-03-02 04:05:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.23138611018657684 norm:0.040988557040691376 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.18793068826198578 norm:0.011792846955358982 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.16103631258010864 norm:0.004830252844840288 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.15181313455104828 norm:0.002918781479820609 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.1477702558040619 norm:0.0021696866024285555 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.14533816277980804 norm:0.0018010638887062669 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.14367827773094177 norm:0.0016438938910141587 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.14252616465091705 norm:0.0015179823385551572 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.14148414134979248 norm:0.0013739867135882378 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.14068777859210968 norm:0.0013340895529836416 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.1401914358139038 norm:0.0012973096454516053 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.13980212807655334 norm:0.0012892424128949642 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.1395483762025833 norm:0.0012278694193810225 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.13937649130821228 norm:0.001219071913510561 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.13923996686935425 norm:0.0012005441822111607 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.13911888003349304 norm:0.0011833161115646362 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.13906872272491455 norm:0.001187009271234274 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.13906696438789368 norm:0.0011783936060965061 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.1390913873910904 norm:0.001183719257824123 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.1391412317752838 norm:0.0011873348848894238 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 04:17:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.27388471364974976 norm:0.03854016959667206 max memory_allocated 22559.67919921875 
[2025-03-02 04:17:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.22855380177497864 norm:0.015345551073551178 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.19788864254951477 norm:0.005723265465348959 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.1859479546546936 norm:0.002616311190649867 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.18084511160850525 norm:0.001887691905722022 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.17802970111370087 norm:0.0016304508317261934 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.17618031799793243 norm:0.0014640555018559098 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.1749914586544037 norm:0.0013702383730560541 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.1743169128894806 norm:0.001351109822280705 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.17386655509471893 norm:0.001318112714216113 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.17388667166233063 norm:0.0014192935777828097 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:15 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.17373749613761902 norm:0.0013515938771888614 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.17325177788734436 norm:0.00129508669488132 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.17317980527877808 norm:0.0013525128597393632 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.17262640595436096 norm:0.0013207318261265755 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.17256224155426025 norm:0.0013208267046138644 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.17251238226890564 norm:0.0013267867034301162 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.1722312867641449 norm:0.0012771927285939455 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.17228159308433533 norm:0.001255410141311586 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.17227718234062195 norm:0.0012345038121566176 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 04:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.33322083950042725 norm:0.06854096055030823 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.27067944407463074 norm:0.02109544165432453 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.22657547891139984 norm:0.006704696454107761 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.21380583941936493 norm:0.00378994969651103 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.20892781019210815 norm:0.0030831077601760626 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.20563805103302002 norm:0.002648737747222185 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.2032630443572998 norm:0.0024003260768949986 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.201570525765419 norm:0.002268004696816206 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.2002388834953308 norm:0.0020135603845119476 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.1993618607521057 norm:0.0019101256038993597 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.19900666177272797 norm:0.0018730852752923965 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.19863294064998627 norm:0.001700356719084084 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.19844453036785126 norm:0.0017220330191776156 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.1979328691959381 norm:0.0016076641622930765 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.19729678332805634 norm:0.0015126329381018877 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.19715489447116852 norm:0.0014464715495705605 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:29 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.1971498429775238 norm:0.0013893700670450926 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.1967398226261139 norm:0.001363742514513433 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.19668936729431152 norm:0.001336081069894135 max memory_allocated 22559.85107421875 
[2025-03-02 04:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.19687716662883759 norm:0.0013514962047338486 max memory_allocated 22559.85107421875 
[2025-03-02 04:39:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 04:39:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.34211739897727966 norm:0.060166891664266586 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.30016613006591797 norm:0.026068761944770813 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.25312554836273193 norm:0.007378328125923872 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.2379617989063263 norm:0.0036100028082728386 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.23236757516860962 norm:0.002769412938505411 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.2289428412914276 norm:0.0022774976678192616 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.2267102152109146 norm:0.002073299139738083 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.22525277733802795 norm:0.002002641325816512 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.2242327630519867 norm:0.001816558069549501 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.2232004851102829 norm:0.0016642238479107618 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:33 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.2227286398410797 norm:0.0016070244600996375 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.2223181277513504 norm:0.001584368059411645 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.22176863253116608 norm:0.0014350025448948145 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.22154031693935394 norm:0.0014122913125902414 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.22145773470401764 norm:0.0014113095821812749 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.2213439643383026 norm:0.0014439243823289871 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.22137777507305145 norm:0.0014416034100577235 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.22120417654514313 norm:0.0014328896068036556 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.2212739884853363 norm:0.001406903495080769 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.2211543172597885 norm:0.0013469926780089736 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 04:51:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.3815365135669708 norm:0.043528035283088684 max memory_allocated 22560.19482421875 
[2025-03-02 04:51:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.32977086305618286 norm:0.018780265003442764 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.27752330899238586 norm:0.005886074621230364 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.2614825963973999 norm:0.0029345876537263393 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.25529688596725464 norm:0.002262596972286701 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.2516394257545471 norm:0.0019692762289196253 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.24922385811805725 norm:0.0017741841729730368 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:17 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.24760349094867706 norm:0.0015820362605154514 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.24667365849018097 norm:0.001450145267881453 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.2461821436882019 norm:0.0013890337431803346 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.24594371020793915 norm:0.0014172923984006047 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.24536971747875214 norm:0.0013820782769471407 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.24491170048713684 norm:0.0012846620520576835 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.24470025300979614 norm:0.0012845163000747561 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.244636669754982 norm:0.0012808114988729358 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:47 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.24470502138137817 norm:0.0012230025604367256 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.2446402907371521 norm:0.0012028783094137907 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.24490898847579956 norm:0.0011975668603554368 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.24494487047195435 norm:0.0012147014494985342 max memory_allocated 22560.19482421875 
[2025-03-02 05:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.24461542069911957 norm:0.0011826766422018409 max memory_allocated 22560.19482421875 
[2025-03-02 05:02:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:02:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.33584749698638916 norm:0.010935472324490547 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.3026905357837677 norm:0.0036346011329442263 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.28126147389411926 norm:0.0018615474691614509 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.273214727640152 norm:0.0012808358296751976 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.2689247131347656 norm:0.0010361564345657825 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.26613691449165344 norm:0.000931943824980408 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.26431089639663696 norm:0.0008803280652500689 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.2630244791507721 norm:0.0008392658783122897 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.262227863073349 norm:0.0008217823342420161 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.2617240250110626 norm:0.0008200978045351803 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.26129311323165894 norm:0.0008143104496411979 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.26100027561187744 norm:0.0008133071241900325 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.26078367233276367 norm:0.0008125148015096784 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.26055291295051575 norm:0.0008161322912201285 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.2603737711906433 norm:0.0007999552180990577 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.2601854205131531 norm:0.0008060418767854571 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.2600977420806885 norm:0.0008021896937862039 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.2600226402282715 norm:0.0007923335651867092 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.25997477769851685 norm:0.0007841986371204257 max memory_allocated 22560.36669921875 
[2025-03-02 05:13:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.25998684763908386 norm:0.0007902344223111868 max memory_allocated 22560.36669921875 
[2025-03-02 05:13:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 05:14:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.3649786710739136 norm:0.015999434515833855 max memory_allocated 22560.53857421875 
[2025-03-02 05:14:47 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.32890573143959045 norm:0.005865291692316532 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.30269163846969604 norm:0.0026637990958988667 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.2937166392803192 norm:0.00179629388730973 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.2894553244113922 norm:0.0014229274820536375 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.2865435481071472 norm:0.0012237426126375794 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.28456538915634155 norm:0.0010995373595505953 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.2831061780452728 norm:0.001021308358758688 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.28220874071121216 norm:0.0009813179494813085 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.2814961075782776 norm:0.0009541732724756002 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.28100964426994324 norm:0.0009052034001797438 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.2805511951446533 norm:0.0008817187044769526 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.28024789690971375 norm:0.000876613543368876 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.2799356281757355 norm:0.0008301702328026295 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.27975234389305115 norm:0.0008195926202461123 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.27952855825424194 norm:0.0007993608014658093 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.279331237077713 norm:0.0007849144749343395 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.27920785546302795 norm:0.000790574005804956 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.2791213393211365 norm:0.0007884276565164328 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.27901923656463623 norm:0.0007760848966427147 max memory_allocated 22560.53857421875 
[2025-03-02 05:25:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 05:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.3580172657966614 norm:0.008882738649845123 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.33311137557029724 norm:0.003702644258737564 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.3141040503978729 norm:0.0018156174337491393 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.3063567280769348 norm:0.0012196701718494296 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.30254504084587097 norm:0.0009879878489300609 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.3000510036945343 norm:0.0008874101913534105 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.29837143421173096 norm:0.0008328665280714631 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.29718345403671265 norm:0.0007948991842567921 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.2962592542171478 norm:0.0007599961245432496 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.2957111597061157 norm:0.0007446763338521123 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.29532894492149353 norm:0.0007256825338117778 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.29511532187461853 norm:0.000726166763342917 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.29476553201675415 norm:0.0007182729314081371 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.2945201098918915 norm:0.0007103460957296193 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.29440122842788696 norm:0.000711024971678853 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.2942560613155365 norm:0.0007035332964733243 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.29414814710617065 norm:0.0006924521876499057 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.29403185844421387 norm:0.0006886710762046278 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.2939566969871521 norm:0.0006864045280963182 max memory_allocated 22560.71044921875 
[2025-03-02 05:36:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.2937861979007721 norm:0.0006774747162126005 max memory_allocated 22560.71044921875 
[2025-03-02 05:36:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 05:37:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.4077753722667694 norm:0.025853538885712624 max memory_allocated 22560.88232421875 
[2025-03-02 05:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.3764743506908417 norm:0.013202616013586521 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.3394814431667328 norm:0.0045744432136416435 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.3239777088165283 norm:0.002016672631725669 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.3185097873210907 norm:0.001533963717520237 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.31518372893333435 norm:0.0013832729309797287 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.3129424452781677 norm:0.0012802525889128447 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.31150633096694946 norm:0.0012511775130406022 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.31039056181907654 norm:0.001208548666909337 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.30941393971443176 norm:0.0011848917929455638 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.3087034523487091 norm:0.0011545460438355803 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.30828094482421875 norm:0.0011260188184678555 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.3078942596912384 norm:0.0010495230089873075 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.30763623118400574 norm:0.0010400700848549604 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.30737340450286865 norm:0.001027810969389975 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.3071346879005432 norm:0.0009877876145765185 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.30692240595817566 norm:0.0009788587922230363 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.3066348731517792 norm:0.0009284780826419592 max memory_allocated 22560.88232421875 
[2025-03-02 05:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.3064863085746765 norm:0.000914574193302542 max memory_allocated 22560.88232421875 
[2025-03-02 05:47:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.30638110637664795 norm:0.0009241255465894938 max memory_allocated 22560.88232421875 
[2025-03-02 05:47:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 05:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.3828769028186798 norm:0.016882775351405144 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.3619161546230316 norm:0.007912936620414257 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.34509262442588806 norm:0.004614748060703278 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.3373379111289978 norm:0.003281739540398121 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.33261770009994507 norm:0.002473349217325449 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.3294171392917633 norm:0.002043035114184022 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.32719796895980835 norm:0.0018165430519729853 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.32547110319137573 norm:0.00156866863835603 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.3242148458957672 norm:0.0014478274388238788 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.3233537971973419 norm:0.0013302401639521122 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.32260897755622864 norm:0.0011934167705476284 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.32198774814605713 norm:0.0011119102127850056 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.3215203583240509 norm:0.0010571960592642426 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.32113954424858093 norm:0.001006215694360435 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.3208756148815155 norm:0.0009907007915899158 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.32074791193008423 norm:0.0009743822738528252 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.32054993510246277 norm:0.0009355700458399951 max memory_allocated 22561.05419921875 
[2025-03-02 05:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.32034075260162354 norm:0.0009129142272286117 max memory_allocated 22561.05419921875 
[2025-03-02 05:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.32019907236099243 norm:0.0008788482518866658 max memory_allocated 22561.05419921875 
[2025-03-02 05:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.3200927674770355 norm:0.0008577085682190955 max memory_allocated 22561.05419921875 
[2025-03-02 05:59:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 05:59:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.3921138048171997 norm:0.0074365343898534775 max memory_allocated 22561.22607421875 
[2025-03-02 06:00:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.3707340657711029 norm:0.003082005539909005 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:05 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.353725790977478 norm:0.0016509821871295571 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.347173273563385 norm:0.001192952855490148 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.34371840953826904 norm:0.0010552550666034222 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.34132176637649536 norm:0.0009876752737909555 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.339519202709198 norm:0.0009344764403067529 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.33825013041496277 norm:0.0008996621472761035 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.3372385501861572 norm:0.0008847690769471228 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.33640941977500916 norm:0.0008658617152832448 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.3356727659702301 norm:0.0008502022246830165 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.3352039158344269 norm:0.0008308643009513617 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.3350007236003876 norm:0.0008317403844557703 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.3347199857234955 norm:0.0008217592258006334 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.33456340432167053 norm:0.0008199938456527889 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.33434993028640747 norm:0.0008123672450892627 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.33415505290031433 norm:0.0008112053037621081 max memory_allocated 22561.22607421875 
[2025-03-02 06:09:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.3339550495147705 norm:0.0008059474639594555 max memory_allocated 22561.22607421875 
[2025-03-02 06:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.33382415771484375 norm:0.0008029068703763187 max memory_allocated 22561.22607421875 
[2025-03-02 06:10:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.3337361514568329 norm:0.0007994290208443999 max memory_allocated 22561.22607421875 
[2025-03-02 06:10:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:11:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.42440518736839294 norm:0.024433059617877007 max memory_allocated 22561.39794921875 
[2025-03-02 06:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.40151745080947876 norm:0.012043560855090618 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.3833828568458557 norm:0.007352784276008606 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.37466269731521606 norm:0.004917182493954897 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.3699111044406891 norm:0.003780194791033864 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.3663036525249481 norm:0.0028359449934214354 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.3636842966079712 norm:0.00231368001550436 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.3615679144859314 norm:0.0019135428592562675 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.3601227402687073 norm:0.0016184786800295115 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.3590279817581177 norm:0.0014040105743333697 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.3582009971141815 norm:0.0012584640644490719 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.357529878616333 norm:0.0010835530702024698 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.35705554485321045 norm:0.0009975621942430735 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.3567260801792145 norm:0.00093032605946064 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.3562828600406647 norm:0.0008239718154072762 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.35602882504463196 norm:0.000805665971711278 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.35583868622779846 norm:0.0008066592854447663 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.3557235598564148 norm:0.000806537689641118 max memory_allocated 22561.39794921875 
[2025-03-02 06:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.3555828928947449 norm:0.000802328868303448 max memory_allocated 22561.39794921875 
[2025-03-02 06:22:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.35553133487701416 norm:0.0007969937287271023 max memory_allocated 22561.39794921875 
[2025-03-02 06:22:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 06:22:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.4373018443584442 norm:0.01217546034604311 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.41947197914123535 norm:0.005864564795047045 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.40396928787231445 norm:0.003218018915504217 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.3968942165374756 norm:0.001867535524070263 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.3929174542427063 norm:0.0012678210623562336 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.39009711146354675 norm:0.0009996050503104925 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.3880617618560791 norm:0.000949339009821415 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.3865092396736145 norm:0.0009214530582539737 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.3854062557220459 norm:0.0008931224001571536 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.38460302352905273 norm:0.0008872285252436996 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.3839857578277588 norm:0.0008807905251160264 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.3833901286125183 norm:0.0008726443629711866 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.38308626413345337 norm:0.0008707178058102727 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.38285037875175476 norm:0.0008646294591017067 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.3825843632221222 norm:0.0008646143251098692 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.38234883546829224 norm:0.000864629924762994 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.3822256326675415 norm:0.0008593485690653324 max memory_allocated 22561.56982421875 
[2025-03-02 06:32:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.3820341229438782 norm:0.0008607432246208191 max memory_allocated 22561.56982421875 
[2025-03-02 06:32:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.38181936740875244 norm:0.0008618738502264023 max memory_allocated 22561.56982421875 
[2025-03-02 06:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.38168299198150635 norm:0.0008619817090220749 max memory_allocated 22561.56982421875 
[2025-03-02 06:33:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 06:34:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.48579469323158264 norm:0.017219295725226402 max memory_allocated 22561.74169921875 
[2025-03-02 06:34:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.4647727310657501 norm:0.009049576707184315 max memory_allocated 22561.74169921875 
[2025-03-02 06:35:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.4457525610923767 norm:0.005176160484552383 max memory_allocated 22561.74169921875 
[2025-03-02 06:35:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.43651077151298523 norm:0.002619012026116252 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.4320535361766815 norm:0.0019588663708418608 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.42893511056900024 norm:0.0017852180171757936 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.4264591634273529 norm:0.00163899059407413 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.4247381091117859 norm:0.0015261875232681632 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.4230062961578369 norm:0.001088488381356001 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.42187172174453735 norm:0.0010394590208306909 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.4210348129272461 norm:0.0010138251818716526 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.4203231930732727 norm:0.0009903910104185343 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.4196739196777344 norm:0.0009727724245749414 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.419328510761261 norm:0.0009655635221861303 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.4189505875110626 norm:0.0009527980000711977 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.41866445541381836 norm:0.0009453834500163794 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.41839075088500977 norm:0.0009395607048645616 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.4181366264820099 norm:0.0009278034558519721 max memory_allocated 22561.74169921875 
[2025-03-02 06:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.41789010167121887 norm:0.0009194654412567616 max memory_allocated 22561.74169921875 
[2025-03-02 06:44:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.41765451431274414 norm:0.0009180750348605216 max memory_allocated 22561.74169921875 
[2025-03-02 06:45:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 06:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.5351959466934204 norm:0.01609739661216736 max memory_allocated 22561.91357421875 
[2025-03-02 06:46:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.5130289793014526 norm:0.008060413412749767 max memory_allocated 22561.91357421875 
[2025-03-02 06:46:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.4936470091342926 norm:0.004255066625773907 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.4855891466140747 norm:0.0025433446280658245 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.48058125376701355 norm:0.0018128551309928298 max memory_allocated 22561.91357421875 
[2025-03-02 06:48:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.4776977598667145 norm:0.0015915192198008299 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.47536903619766235 norm:0.0014582485891878605 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.47357556223869324 norm:0.0013626082800328732 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.4721640944480896 norm:0.0012999592581763864 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.471039742231369 norm:0.0012459664139896631 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.470220685005188 norm:0.0012213016161695123 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.4695572555065155 norm:0.0011995298555120826 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.46898770332336426 norm:0.0011677982984110713 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:58 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.4685105085372925 norm:0.0011587515473365784 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.4681869149208069 norm:0.0011453997576609254 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.46785569190979004 norm:0.0011227823561057448 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.4675673246383667 norm:0.0011214055120944977 max memory_allocated 22561.91357421875 
[2025-03-02 06:55:13 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.4673258662223816 norm:0.0011114274384453893 max memory_allocated 22561.91357421875 
[2025-03-02 06:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.4670466482639313 norm:0.0010977868223562837 max memory_allocated 22561.91357421875 
[2025-03-02 06:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.4668770134449005 norm:0.001084744231775403 max memory_allocated 22561.91357421875 
[2025-03-02 06:56:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 06:57:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.5975661277770996 norm:0.01992611028254032 max memory_allocated 22562.08544921875 
[2025-03-02 06:57:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.5767456889152527 norm:0.010706959292292595 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.5572023391723633 norm:0.005755146499723196 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.5495166778564453 norm:0.0041565606370568275 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.5450635552406311 norm:0.0031771943904459476 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.5416948199272156 norm:0.0026177167892456055 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.5392051339149475 norm:0.0022919687908142805 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.5372334122657776 norm:0.00198994018137455 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.5355050563812256 norm:0.0010946029797196388 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.5345175862312317 norm:0.0010795547859743237 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.5337665677070618 norm:0.0010652141645550728 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.5331869721412659 norm:0.0010671152267605066 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.5325488448143005 norm:0.0010591413592919707 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.5321184396743774 norm:0.0010529848514124751 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.5318232178688049 norm:0.0010499455966055393 max memory_allocated 22562.08544921875 
[2025-03-02 07:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.5314944982528687 norm:0.0010505762184038758 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.5312610268592834 norm:0.0010467295069247484 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.5309769511222839 norm:0.0010462086647748947 max memory_allocated 22562.08544921875 
[2025-03-02 07:07:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.5308042764663696 norm:0.0010359634179621935 max memory_allocated 22562.08544921875 
[2025-03-02 07:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.5306285619735718 norm:0.0010347471106797457 max memory_allocated 22562.08544921875 
[2025-03-02 07:07:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:08:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.673760712146759 norm:0.02037755958735943 max memory_allocated 22562.25732421875 
[2025-03-02 07:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.6557605862617493 norm:0.01153314858675003 max memory_allocated 22562.25732421875 
[2025-03-02 07:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.6386390328407288 norm:0.006997294258326292 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.631232738494873 norm:0.0049882810562849045 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.6269727945327759 norm:0.003939240239560604 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.6237402558326721 norm:0.0032206205651164055 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.6213527917861938 norm:0.0027209578547626734 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.6192927360534668 norm:0.002267735078930855 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.6176756620407104 norm:0.0019817561842501163 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:35 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.6163321733474731 norm:0.0017611973453313112 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.6154134273529053 norm:0.0016927713295444846 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.6139758229255676 norm:0.001152512151747942 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.6132506728172302 norm:0.0010353256948292255 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:49 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.6128751039505005 norm:0.0010297078406438231 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.6124950647354126 norm:0.001026837038807571 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.6122924089431763 norm:0.0010249594924971461 max memory_allocated 22562.25732421875 
[2025-03-02 07:17:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.6119916439056396 norm:0.0010256916284561157 max memory_allocated 22562.25732421875 
[2025-03-02 07:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.611699104309082 norm:0.0010262781288474798 max memory_allocated 22562.25732421875 
[2025-03-02 07:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.6113818287849426 norm:0.0010269774356856942 max memory_allocated 22562.25732421875 
[2025-03-02 07:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.6111631393432617 norm:0.0010262778960168362 max memory_allocated 22562.25732421875 
[2025-03-02 07:19:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 07:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.7947602272033691 norm:0.02237704023718834 max memory_allocated 22562.42919921875 
[2025-03-02 07:20:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.773813784122467 norm:0.012950083240866661 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.7533285021781921 norm:0.0076025500893592834 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.7440557479858398 norm:0.005325544159859419 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.7393476963043213 norm:0.004145806655287743 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.7358588576316833 norm:0.0034533466678112745 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.7332713603973389 norm:0.0029924348928034306 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.730985164642334 norm:0.0023941434919834137 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.7288899421691895 norm:0.001355188898742199 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.7279178500175476 norm:0.0013265018351376057 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.7270694971084595 norm:0.0013077296316623688 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.7262526154518127 norm:0.0012771113542839885 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.7256133556365967 norm:0.0012606540694832802 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.72512286901474 norm:0.0012493575923144817 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.7247295379638672 norm:0.0012475978583097458 max memory_allocated 22562.42919921875 
[2025-03-02 07:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.7244275808334351 norm:0.0012475693365558982 max memory_allocated 22562.42919921875 
[2025-03-02 07:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.7241271138191223 norm:0.0012446345062926412 max memory_allocated 22562.42919921875 
[2025-03-02 07:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.7237871885299683 norm:0.0012435911921784282 max memory_allocated 22562.42919921875 
[2025-03-02 07:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.723522961139679 norm:0.0012385775335133076 max memory_allocated 22562.42919921875 
[2025-03-02 07:30:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.7233133912086487 norm:0.0012405083980411291 max memory_allocated 22562.42919921875 
[2025-03-02 07:30:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 07:31:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.9080224633216858 norm:0.008571897633373737 max memory_allocated 22562.60107421875 
[2025-03-02 07:31:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.8929096460342407 norm:0.004528196528553963 max memory_allocated 22562.60107421875 
[2025-03-02 07:32:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.8778173327445984 norm:0.002724604681134224 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.8717281818389893 norm:0.0020675889682024717 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.867684006690979 norm:0.0015025524189695716 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.8647263646125793 norm:0.0014191213995218277 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.8626449704170227 norm:0.001393776503391564 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.8610594272613525 norm:0.0013841933105140924 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.8596512079238892 norm:0.0013698716647922993 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.8588944673538208 norm:0.0013686582678928971 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.858177125453949 norm:0.0013604507548734546 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.8576595783233643 norm:0.001366867683827877 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.8571646213531494 norm:0.0013728687772527337 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.8567808866500854 norm:0.001372854458168149 max memory_allocated 22562.60107421875 
[2025-03-02 07:39:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.8563556671142578 norm:0.0013612861512228847 max memory_allocated 22562.60107421875 
[2025-03-02 07:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.8560004830360413 norm:0.001371782156638801 max memory_allocated 22562.60107421875 
[2025-03-02 07:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.8557388186454773 norm:0.0013767096679657698 max memory_allocated 22562.60107421875 
[2025-03-02 07:40:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.8556442856788635 norm:0.0013851657276973128 max memory_allocated 22562.60107421875 
[2025-03-02 07:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.8553922772407532 norm:0.0013852271949872375 max memory_allocated 22562.60107421875 
[2025-03-02 07:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.8551357984542847 norm:0.0013743326999247074 max memory_allocated 22562.60107421875 
[2025-03-02 07:42:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 07:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:1.050740122795105 norm:0.011108951643109322 max memory_allocated 22562.77294921875 
[2025-03-02 07:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:1.031551480293274 norm:0.006406997796148062 max memory_allocated 22562.77294921875 
[2025-03-02 07:43:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:1.012548804283142 norm:0.003570619272068143 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:29 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:1.0051586627960205 norm:0.00257222936488688 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:1.000524640083313 norm:0.0018870627973228693 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.9973827600479126 norm:0.0016596837667748332 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.9950011968612671 norm:0.0014853242319077253 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.9930710792541504 norm:0.0013047782704234123 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.9918667674064636 norm:0.001252132118679583 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.9908902645111084 norm:0.001229412155225873 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.9902189373970032 norm:0.0012180194025859237 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.9895795583724976 norm:0.001206947141326964 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.9891082644462585 norm:0.0012060917215421796 max memory_allocated 22562.77294921875 
[2025-03-02 07:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.9886994361877441 norm:0.0011916800867766142 max memory_allocated 22562.77294921875 
[2025-03-02 07:50:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.9883870482444763 norm:0.0011862897081300616 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.9881228804588318 norm:0.0011771006975322962 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.9878478050231934 norm:0.0011701838811859488 max memory_allocated 22562.77294921875 
[2025-03-02 07:52:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.9875549077987671 norm:0.0011632563546299934 max memory_allocated 22562.77294921875 
[2025-03-02 07:52:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.9873542785644531 norm:0.001167210517451167 max memory_allocated 22562.77294921875 
[2025-03-02 07:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.9871832132339478 norm:0.0011632442474365234 max memory_allocated 22562.77294921875 
[2025-03-02 07:53:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 07:54:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:1.2312023639678955 norm:0.019911162555217743 max memory_allocated 22562.94482421875 
[2025-03-02 07:54:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:1.207646369934082 norm:0.012746509164571762 max memory_allocated 22562.94482421875 
[2025-03-02 07:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:1.1821008920669556 norm:0.00670181680470705 max memory_allocated 22562.94482421875 
[2025-03-02 07:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:1.1692813634872437 norm:0.0032064944971352816 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:1.1634221076965332 norm:0.0025644665583968163 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:1.1583571434020996 norm:0.0016109795542433858 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:1.1554665565490723 norm:0.00148091372102499 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:1.1534677743911743 norm:0.0014289499958977103 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:1.1520801782608032 norm:0.0013852458214387298 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:1.1511670351028442 norm:0.0013674332294613123 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:1.1502532958984375 norm:0.0013479705667123199 max memory_allocated 22562.94482421875 
[2025-03-02 08:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:1.149585485458374 norm:0.0013498851330950856 max memory_allocated 22562.94482421875 
[2025-03-02 08:00:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:1.1490730047225952 norm:0.0013406670186668634 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:1.1487683057785034 norm:0.001341380295343697 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:1.1483817100524902 norm:0.0013359873555600643 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:1.1481900215148926 norm:0.0013305417960509658 max memory_allocated 22562.94482421875 
[2025-03-02 08:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:1.1479763984680176 norm:0.00132595538161695 max memory_allocated 22562.94482421875 
[2025-03-02 08:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:1.147789716720581 norm:0.001331483363173902 max memory_allocated 22562.94482421875 
[2025-03-02 08:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:1.1475872993469238 norm:0.0013165216660127044 max memory_allocated 22562.94482421875 
[2025-03-02 08:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:1.147339940071106 norm:0.001308780163526535 max memory_allocated 22562.94482421875 
[2025-03-02 08:05:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:05:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:1.3919907808303833 norm:0.032900575548410416 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:1.3716388940811157 norm:0.022373966872692108 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:1.3471345901489258 norm:0.014144157990813255 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:1.3365874290466309 norm:0.010664324276149273 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:54 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:1.3289796113967896 norm:0.008104904554784298 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:1.3229172229766846 norm:0.006424821447581053 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:1.318260669708252 norm:0.005257071927189827 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:1.3155853748321533 norm:0.0046415808610618114 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:1.313591718673706 norm:0.0041445475071668625 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:1.3121049404144287 norm:0.0037441798485815525 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:1.3109320402145386 norm:0.003386765718460083 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:1.3098857402801514 norm:0.003093040781095624 max memory_allocated 22563.11669921875 
[2025-03-02 08:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:1.308915615081787 norm:0.0028655484784394503 max memory_allocated 22563.11669921875 
[2025-03-02 08:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:1.308203935623169 norm:0.002659805351868272 max memory_allocated 22563.11669921875 
[2025-03-02 08:13:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:1.3074510097503662 norm:0.002485316712409258 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:1.3068920373916626 norm:0.0023180549032986164 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:1.3063616752624512 norm:0.00217485916800797 max memory_allocated 22563.11669921875 
[2025-03-02 08:15:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:1.305809736251831 norm:0.0020545569714158773 max memory_allocated 22563.11669921875 
[2025-03-02 08:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:1.3053901195526123 norm:0.001946035074070096 max memory_allocated 22563.11669921875 
[2025-03-02 08:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:1.3050944805145264 norm:0.0018685095710679889 max memory_allocated 22563.11669921875 
[2025-03-02 08:16:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 08:17:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:1.5550488233566284 norm:0.006646773777902126 max memory_allocated 22563.28857421875 
[2025-03-02 08:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:1.5367403030395508 norm:0.003891881089657545 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:1.5152044296264648 norm:0.002325296401977539 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:1.5068359375 norm:0.0016970033757388592 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:1.5017839670181274 norm:0.0014439038932323456 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:1.4977964162826538 norm:0.0013290031347423792 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:1.4948856830596924 norm:0.0012605874799191952 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:1.4928845167160034 norm:0.001233396353200078 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:1.4913817644119263 norm:0.0012160168262198567 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:1.4903807640075684 norm:0.0012061421293765306 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:1.4895381927490234 norm:0.0011955791851505637 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:1.4889200925827026 norm:0.0011809741845354438 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:1.488275170326233 norm:0.0011744879884645343 max memory_allocated 22563.28857421875 
[2025-03-02 08:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:1.4878311157226562 norm:0.0011742901988327503 max memory_allocated 22563.28857421875 
[2025-03-02 08:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:1.487491250038147 norm:0.001174850738607347 max memory_allocated 22563.28857421875 
[2025-03-02 08:25:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:1.487128734588623 norm:0.0011716471053659916 max memory_allocated 22563.28857421875 
[2025-03-02 08:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:1.4868102073669434 norm:0.001164435874670744 max memory_allocated 22563.28857421875 
[2025-03-02 08:26:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:1.486563801765442 norm:0.0011586874024942517 max memory_allocated 22563.28857421875 
[2025-03-02 08:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:1.4863368272781372 norm:0.001159808598458767 max memory_allocated 22563.28857421875 
[2025-03-02 08:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:1.486151099205017 norm:0.0011614307295531034 max memory_allocated 22563.28857421875 
[2025-03-02 08:27:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 08:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:1.7750499248504639 norm:0.026131857186555862 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:1.745546579360962 norm:0.013438397087156773 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:1.7165026664733887 norm:0.006597277708351612 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:1.7037668228149414 norm:0.003620515577495098 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:1.696746587753296 norm:0.0027997037395834923 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:1.6913872957229614 norm:0.0022640242241322994 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:1.6876310110092163 norm:0.0019156564958393574 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:1.685166358947754 norm:0.0016941896174103022 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:1.68341064453125 norm:0.001545288017950952 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:1.682152509689331 norm:0.0014426481211557984 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:1.6812009811401367 norm:0.0013747363118454814 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:1.6804437637329102 norm:0.001322384923696518 max memory_allocated 22563.46044921875 
[2025-03-02 08:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:1.67988121509552 norm:0.0012911565136164427 max memory_allocated 22563.46044921875 
[2025-03-02 08:35:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:1.6792347431182861 norm:0.001268156454898417 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:1.6787629127502441 norm:0.0012429453199729323 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:1.6784316301345825 norm:0.001227087457664311 max memory_allocated 22563.46044921875 
[2025-03-02 08:37:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:1.6781005859375 norm:0.001213752431795001 max memory_allocated 22563.46044921875 
[2025-03-02 08:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:1.6777701377868652 norm:0.0012103843037039042 max memory_allocated 22563.46044921875 
[2025-03-02 08:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:1.677506923675537 norm:0.0012092808028683066 max memory_allocated 22563.46044921875 
[2025-03-02 08:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:1.677223801612854 norm:0.0012017427943646908 max memory_allocated 22563.46044921875 
[2025-03-02 08:39:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 08:39:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:1.9726221561431885 norm:0.020808523520827293 max memory_allocated 22563.63232421875 
[2025-03-02 08:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:1.9425544738769531 norm:0.009548073634505272 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:1.9143036603927612 norm:0.006081894971430302 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:1.8992527723312378 norm:0.0026141025591641665 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:1.892637014389038 norm:0.0019698545802384615 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:1.8875761032104492 norm:0.001741618849337101 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:1.8841317892074585 norm:0.0015273909084498882 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:1.881835699081421 norm:0.0014283983036875725 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:1.879968285560608 norm:0.0013683191500604153 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:1.8788574934005737 norm:0.0013383290497586131 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:1.877907395362854 norm:0.0013062985381111503 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:1.877220869064331 norm:0.0012870174832642078 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:1.8765264749526978 norm:0.001264904160052538 max memory_allocated 22563.63232421875 
[2025-03-02 08:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:1.875964879989624 norm:0.001252857968211174 max memory_allocated 22563.63232421875 
[2025-03-02 08:47:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:1.8754370212554932 norm:0.0012508784420788288 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:1.8750218152999878 norm:0.0012473120586946607 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:1.874680757522583 norm:0.0012381816050037742 max memory_allocated 22563.63232421875 
[2025-03-02 08:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:1.8741846084594727 norm:0.0012410436756908894 max memory_allocated 22563.63232421875 
[2025-03-02 08:50:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:1.8737233877182007 norm:0.0012396061792969704 max memory_allocated 22563.63232421875 
[2025-03-02 08:50:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:1.873603105545044 norm:0.0012273549800738692 max memory_allocated 22563.63232421875 
[2025-03-02 08:50:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 08:50:48 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 08:51:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:2.268099546432495 norm:0.05109482258558273 max memory_allocated 22563.91943359375 
[2025-03-02 08:51:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:2.2372312545776367 norm:0.045064982026815414 max memory_allocated 22563.91943359375 
[2025-03-02 08:52:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:2.204817056655884 norm:0.03619096428155899 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:2.1865785121917725 norm:0.030515342950820923 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:2.175513744354248 norm:0.025826020166277885 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:2.1669962406158447 norm:0.022709431126713753 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:2.160518169403076 norm:0.01994888111948967 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:2.155489206314087 norm:0.01827399991452694 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:2.151655912399292 norm:0.01722012832760811 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:2.1479687690734863 norm:0.016516050323843956 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:2.144733428955078 norm:0.015752140432596207 max memory_allocated 22563.91943359375 
[2025-03-02 08:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:2.142092227935791 norm:0.015626631677150726 max memory_allocated 22563.91943359375 
[2025-03-02 08:58:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:2.139779567718506 norm:0.015482841059565544 max memory_allocated 22563.91943359375 
[2025-03-02 08:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:2.137584686279297 norm:0.0154076823964715 max memory_allocated 22563.91943359375 
[2025-03-02 08:59:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:2.135669231414795 norm:0.014837666414678097 max memory_allocated 22563.91943359375 
[2025-03-02 08:59:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:2.1336779594421387 norm:0.014442178420722485 max memory_allocated 22563.91943359375 
[2025-03-02 09:00:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:2.132354736328125 norm:0.014030521735548973 max memory_allocated 22563.91943359375 
[2025-03-02 09:00:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:2.1306777000427246 norm:0.013643131591379642 max memory_allocated 22563.91943359375 
[2025-03-02 09:01:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:2.1293575763702393 norm:0.01334370393306017 max memory_allocated 22563.91943359375 
[2025-03-02 09:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:2.128140926361084 norm:0.013158239424228668 max memory_allocated 22563.91943359375 
[2025-03-02 09:02:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 09:02:15 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:02:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:2.572760820388794 norm:0.05295196920633316 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:2.5296785831451416 norm:0.043971456587314606 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:2.4830451011657715 norm:0.033130235970020294 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:2.4591963291168213 norm:0.027239687740802765 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:2.4469995498657227 norm:0.022651810199022293 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:2.438337802886963 norm:0.019167616963386536 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:2.43243408203125 norm:0.01673520915210247 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:2.4284887313842773 norm:0.014998527243733406 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:2.425710678100586 norm:0.014156430959701538 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:2.423412322998047 norm:0.013629534281790257 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:2.421851634979248 norm:0.01308226678520441 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:2.4206583499908447 norm:0.013506319373846054 max memory_allocated 22564.09130859375 
[2025-03-02 09:09:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:2.4194700717926025 norm:0.01276486273854971 max memory_allocated 22564.09130859375 
[2025-03-02 09:10:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:2.4181532859802246 norm:0.012818342074751854 max memory_allocated 22564.09130859375 
[2025-03-02 09:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:2.41697359085083 norm:0.011776406317949295 max memory_allocated 22564.09130859375 
[2025-03-02 09:11:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:2.4161128997802734 norm:0.011934283189475536 max memory_allocated 22564.09130859375 
[2025-03-02 09:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:2.4155116081237793 norm:0.011665163561701775 max memory_allocated 22564.09130859375 
[2025-03-02 09:12:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:2.414398670196533 norm:0.011219247244298458 max memory_allocated 22564.09130859375 
[2025-03-02 09:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:2.413930892944336 norm:0.011061126366257668 max memory_allocated 22564.09130859375 
[2025-03-02 09:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:2.41337513923645 norm:0.010991961695253849 max memory_allocated 22564.09130859375 
[2025-03-02 09:13:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:13:41 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:14:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:3.4062793254852295 norm:0.10152527689933777 max memory_allocated 22564.26318359375 
[2025-03-02 09:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:3.3075778484344482 norm:0.07440876960754395 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:3.160499095916748 norm:0.04338416829705238 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:3.0961992740631104 norm:0.03604113683104515 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:3.0700347423553467 norm:0.034548912197351456 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:3.0510659217834473 norm:0.035378944128751755 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:3.034226894378662 norm:0.03460481017827988 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:3.021860122680664 norm:0.0364222526550293 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:3.0140299797058105 norm:0.03545478358864784 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:3.0056588649749756 norm:0.034004755318164825 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:52 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:3.0016651153564453 norm:0.034472864121198654 max memory_allocated 22564.26318359375 
[2025-03-02 09:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:2.994994640350342 norm:0.03623506799340248 max memory_allocated 22564.26318359375 
[2025-03-02 09:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:2.9907586574554443 norm:0.03668675944209099 max memory_allocated 22564.26318359375 
[2025-03-02 09:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:2.9872894287109375 norm:0.036570947617292404 max memory_allocated 22564.26318359375 
[2025-03-02 09:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:2.990623950958252 norm:0.037902265787124634 max memory_allocated 22564.26318359375 
[2025-03-02 09:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:2.9846081733703613 norm:0.038127973675727844 max memory_allocated 22564.26318359375 
[2025-03-02 09:23:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:2.9837069511413574 norm:0.03745775669813156 max memory_allocated 22564.26318359375 
[2025-03-02 09:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:2.9836699962615967 norm:0.038879748433828354 max memory_allocated 22564.26318359375 
[2025-03-02 09:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:2.984708070755005 norm:0.03882235661149025 max memory_allocated 22564.26318359375 
[2025-03-02 09:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:2.9763565063476562 norm:0.03773093223571777 max memory_allocated 22564.26318359375 
[2025-03-02 09:25:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 09:25:08 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:25:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:6.26462459564209 norm:0.4165821075439453 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:5.810530185699463 norm:0.32329636812210083 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:5.502019882202148 norm:0.27829429507255554 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:5.315549850463867 norm:0.2761273980140686 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:5.223929405212402 norm:0.25998470187187195 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:5.156628608703613 norm:0.24382534623146057 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:5.104358673095703 norm:0.2292952686548233 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:5.062046051025391 norm:0.21155016124248505 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:5.0197649002075195 norm:0.2035921961069107 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:4.990718841552734 norm:0.20058850944042206 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:4.96881103515625 norm:0.19100582599639893 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:4.950355529785156 norm:0.187399759888649 max memory_allocated 22564.43505859375 
[2025-03-02 09:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:4.931544780731201 norm:0.18075399100780487 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:4.91734504699707 norm:0.1750512421131134 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:4.9071044921875 norm:0.1720471978187561 max memory_allocated 22564.43505859375 
[2025-03-02 09:34:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:4.896800518035889 norm:0.16669899225234985 max memory_allocated 22564.43505859375 
[2025-03-02 09:34:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:4.885781764984131 norm:0.15882691740989685 max memory_allocated 22564.43505859375 
[2025-03-02 09:35:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:4.876511573791504 norm:0.1595655381679535 max memory_allocated 22564.43505859375 
[2025-03-02 09:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:4.871109962463379 norm:0.15036079287528992 max memory_allocated 22564.43505859375 
[2025-03-02 09:36:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:4.866775989532471 norm:0.15064653754234314 max memory_allocated 22564.43505859375 
[2025-03-02 09:36:33 root] (main_calib_config2.py 380): INFO 21949.601565122604
[2025-03-02 09:36:37 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 09:37:49 root] (main_calib_config2.py 159): INFO wikitext2 : 8.184426307678223
[2025-03-02 09:37:49 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 09:39:38 root] (main_calib_config2.py 159): INFO c4 : 11.916845321655273
