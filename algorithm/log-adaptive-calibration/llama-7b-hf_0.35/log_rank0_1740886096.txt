[2025-03-02 03:28:16 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.35', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.35.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 03:30:43 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-02 03:30:43 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.35.pkl
[2025-03-02 03:30:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 03:30:51 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.05083244666457176 norm:0.026850037276744843 max memory_allocated 22559.10693359375 
[2025-03-02 03:31:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.03601563721895218 norm:0.014800374396145344 max memory_allocated 22559.10693359375 
[2025-03-02 03:32:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.029950648546218872 norm:0.011136223562061787 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.02765621431171894 norm:0.009187749586999416 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.026539668440818787 norm:0.007509135641157627 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.025891993194818497 norm:0.00616239570081234 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.025489743798971176 norm:0.005187714006751776 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.025232886895537376 norm:0.004219613038003445 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:50 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.024988148361444473 norm:0.0036639540921896696 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.024851111695170403 norm:0.0034328224137425423 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.024771301075816154 norm:0.003289611777290702 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.024720536544919014 norm:0.0031862789765000343 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.024633917957544327 norm:0.002989517292007804 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.02463543601334095 norm:0.002989816013723612 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.02464360184967518 norm:0.0028822459280490875 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.024642644450068474 norm:0.002898434642702341 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.024646185338497162 norm:0.0028628455474972725 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.024624250829219818 norm:0.0027755689807236195 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.02457462064921856 norm:0.0026524323038756847 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.024577807635068893 norm:0.002689998596906662 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 03:42:09 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.10491281747817993 norm:0.034894730895757675 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.08079240471124649 norm:0.02110437862575054 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.0705525279045105 norm:0.01285235770046711 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.0667150691151619 norm:0.010166934691369534 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:56 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.06463485956192017 norm:0.008647887967526913 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.06357467174530029 norm:0.007396555505692959 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.06269945949316025 norm:0.006270608864724636 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.06208879500627518 norm:0.00539582222700119 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.061598118394613266 norm:0.004560688976198435 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.061257533729076385 norm:0.003880079835653305 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.060971688479185104 norm:0.003447613911703229 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.060749445110559464 norm:0.0032238676212728024 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.060579296201467514 norm:0.003135896986350417 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.06047037988901138 norm:0.0030998806469142437 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.06026909500360489 norm:0.0030134315602481365 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.060230109840631485 norm:0.0030978417489677668 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.060118693858385086 norm:0.0030821673572063446 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.060005053877830505 norm:0.0030286447145044804 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.0600077286362648 norm:0.002998937387019396 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.05996047332882881 norm:0.0030169193632900715 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 03:53:29 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.20456063747406006 norm:0.0346464067697525 max memory_allocated 22559.45068359375 
[2025-03-02 03:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.17473338544368744 norm:0.028855273500084877 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.1593683511018753 norm:0.017387937754392624 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.15186631679534912 norm:0.01492978073656559 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.14778956770896912 norm:0.013789891265332699 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.14480842649936676 norm:0.013604197651147842 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.14216026663780212 norm:0.013751608319580555 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.140744149684906 norm:0.012826522812247276 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.13655909895896912 norm:0.0130743607878685 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.1397472620010376 norm:0.012679963372647762 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.1333373636007309 norm:0.01251333486288786 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.13212800025939941 norm:0.013051032088696957 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.13519784808158875 norm:0.012579575181007385 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.1390601098537445 norm:0.012844947166740894 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.13566529750823975 norm:0.011857416480779648 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.13324567675590515 norm:0.01131734810769558 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.1346147358417511 norm:0.011012389324605465 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.13355185091495514 norm:0.011244263499975204 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.13364684581756592 norm:0.01043994352221489 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.1336400806903839 norm:0.010564419440925121 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:05:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.18558624386787415 norm:0.015634585171937943 max memory_allocated 22559.50732421875 
[2025-03-02 04:05:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.1590590476989746 norm:0.0057297456078231335 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.14418448507785797 norm:0.0032889905851334333 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.138926699757576 norm:0.002072014845907688 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.13610324263572693 norm:0.0015527401119470596 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.13437023758888245 norm:0.0012458664132282138 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.1331450641155243 norm:0.0010633053025230765 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.13232886791229248 norm:0.0009770238539204001 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.1318526417016983 norm:0.0009290642919950187 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.13151481747627258 norm:0.0008902677218429744 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.13121317327022552 norm:0.000857215840369463 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.13101254403591156 norm:0.0008376748883165419 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.1308169960975647 norm:0.0008268168894574046 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.1306648999452591 norm:0.0008234783308580518 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.1305745244026184 norm:0.0008246686775237322 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.13048675656318665 norm:0.0008195044938474894 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.13042494654655457 norm:0.0008159009157679975 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.1303677260875702 norm:0.0008154879324138165 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.13028202950954437 norm:0.0008188839419744909 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.13022831082344055 norm:0.0008140564896166325 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 04:16:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.23066724836826324 norm:0.036577168852090836 max memory_allocated 22559.67919921875 
[2025-03-02 04:17:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.19843021035194397 norm:0.01496368832886219 max memory_allocated 22559.67919921875 
[2025-03-02 04:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.17745843529701233 norm:0.005043488927185535 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.16967061161994934 norm:0.0019239102257415652 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.16574996709823608 norm:0.0014257564907893538 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.16344889998435974 norm:0.001178449485450983 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.16196587681770325 norm:0.001035215682350099 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.1611325740814209 norm:0.0009678543428890407 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.16059260070323944 norm:0.0009210079442709684 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.16016733646392822 norm:0.0008977322722785175 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.15993574261665344 norm:0.0008714903378859162 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.15970087051391602 norm:0.0008636467391625047 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.159530907869339 norm:0.0008602635934948921 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.1593928188085556 norm:0.0008489251486025751 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.15931271016597748 norm:0.0008462838013656437 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.15920215845108032 norm:0.0008581390138715506 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.15914012491703033 norm:0.0008498381357640028 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.15906304121017456 norm:0.0008522127172909677 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.15899363160133362 norm:0.0008460490498691797 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.15892641246318817 norm:0.0008486809674650431 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 04:27:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.27190884947776794 norm:0.053447507321834564 max memory_allocated 22559.85107421875 
[2025-03-02 04:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.210419163107872 norm:0.018779996782541275 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.16849258542060852 norm:0.0058382293209433556 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.15619169175624847 norm:0.0031050643883645535 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.15179109573364258 norm:0.002232103142887354 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.14944592118263245 norm:0.0019376890268176794 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.14797309041023254 norm:0.0016051058191806078 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.1472761631011963 norm:0.0016199338715523481 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.14723917841911316 norm:0.001659577013924718 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.14675340056419373 norm:0.0014942700508981943 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.1460687518119812 norm:0.0013294341042637825 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.14552925527095795 norm:0.0011650440283119678 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.14519119262695312 norm:0.0011429785517975688 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.14508438110351562 norm:0.00109854806214571 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.14512872695922852 norm:0.0010182170663028955 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.14517201483249664 norm:0.0010446450905874372 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.14523059129714966 norm:0.0010149761801585555 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.1459834724664688 norm:0.0010752896778285503 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.1460414081811905 norm:0.000996692106127739 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.14626067876815796 norm:0.001005626400001347 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 04:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.26317307353019714 norm:0.054503463208675385 max memory_allocated 22560.02294921875 
[2025-03-02 04:39:52 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.22508786618709564 norm:0.026379158720374107 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.18023857474327087 norm:0.008300545625388622 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.1646982729434967 norm:0.0033601243048906326 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.16030187904834747 norm:0.0024845735169947147 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.15752069652080536 norm:0.0019298072438687086 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.15597134828567505 norm:0.0017223620088770986 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.15517202019691467 norm:0.0016087150434032083 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.1547612100839615 norm:0.001503900857642293 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.15455172955989838 norm:0.0014316719025373459 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.15429121255874634 norm:0.001326254801824689 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.1540851593017578 norm:0.0013173060724511743 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.1543903350830078 norm:0.0013320731231942773 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:33 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.15457475185394287 norm:0.0013227351009845734 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.15432137250900269 norm:0.001250333501957357 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.15404073894023895 norm:0.0011118781985715032 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.15380382537841797 norm:0.001083059818483889 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.15368708968162537 norm:0.0010423220228403807 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.1536608636379242 norm:0.0009983986383304 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.15380048751831055 norm:0.0009987243684008718 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 04:50:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.2504279911518097 norm:0.008990884758532047 max memory_allocated 22560.19482421875 
[2025-03-02 04:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.2253868579864502 norm:0.003711927682161331 max memory_allocated 22560.19482421875 
[2025-03-02 04:51:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.20938560366630554 norm:0.0020466959103941917 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.20329277217388153 norm:0.0013391125248745084 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.20017996430397034 norm:0.001030178740620613 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.19806711375713348 norm:0.0008923719287849963 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.19672510027885437 norm:0.0008312891586683691 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.19586750864982605 norm:0.0007996349595487118 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.1953151524066925 norm:0.0007818127050995827 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.19495084881782532 norm:0.0007735742256045341 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.19466066360473633 norm:0.0007706087199039757 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.19442760944366455 norm:0.0007701992290094495 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.19419680535793304 norm:0.0007804331253282726 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.19402550160884857 norm:0.0007720028515905142 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.19386538863182068 norm:0.0007704266463406384 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.19378086924552917 norm:0.0007731494843028486 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.193687304854393 norm:0.0007772567914798856 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.1936008781194687 norm:0.0007705710595473647 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.19354036450386047 norm:0.000770760583691299 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.19345176219940186 norm:0.0007764481124468148 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.2318953573703766 norm:0.007121026515960693 max memory_allocated 22560.36669921875 
[2025-03-02 05:02:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.20448899269104004 norm:0.0023059381637722254 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.18864887952804565 norm:0.001085832016542554 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.18309985101222992 norm:0.0007667113677598536 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.18023674190044403 norm:0.000618480087723583 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.17866143584251404 norm:0.0005274339346215129 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.17779229581356049 norm:0.0004897640901617706 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.1773124784231186 norm:0.0004708653432317078 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.1769879311323166 norm:0.0004640666302293539 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.1768190711736679 norm:0.00045589174260385334 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.17673712968826294 norm:0.0004501061048358679 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.17654457688331604 norm:0.00046425143955275416 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.17647385597229004 norm:0.0004578305233735591 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.1764371395111084 norm:0.00044430390698835254 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.17638429999351501 norm:0.0004405385407153517 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.1763187050819397 norm:0.00043562226346693933 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.17628176510334015 norm:0.00042876327643170953 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.17625820636749268 norm:0.00043463872862048447 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.17620792984962463 norm:0.0004449830739758909 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.176169291138649 norm:0.000444452918600291 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 05:13:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.24180345237255096 norm:0.009151200763881207 max memory_allocated 22560.53857421875 
[2025-03-02 05:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.21310770511627197 norm:0.003162149339914322 max memory_allocated 22560.53857421875 
[2025-03-02 05:14:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.19449105858802795 norm:0.0013610293390229344 max memory_allocated 22560.53857421875 
[2025-03-02 05:14:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.18857833743095398 norm:0.0009228029521182179 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:32 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.18597698211669922 norm:0.0007255309028550982 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.1843617558479309 norm:0.0006157280295155942 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.18334539234638214 norm:0.0005871265893802047 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.18270936608314514 norm:0.0005467820446938276 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.1824265718460083 norm:0.000530095596332103 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.18229471147060394 norm:0.0005145131144672632 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.18212807178497314 norm:0.0005027658771723509 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.18200638890266418 norm:0.0004999936791136861 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.1819400191307068 norm:0.00048668839735910296 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.1819247007369995 norm:0.00047340025776065886 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.18177783489227295 norm:0.00046082944027148187 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.1817125827074051 norm:0.0004590026510413736 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.18167155981063843 norm:0.0004500235663726926 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.18163970112800598 norm:0.0004488026024773717 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.1816205233335495 norm:0.0004469825071282685 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.1816750466823578 norm:0.00044917676132172346 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 05:24:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.22676128149032593 norm:0.005300935357809067 max memory_allocated 22560.71044921875 
[2025-03-02 05:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.20827427506446838 norm:0.002073592273518443 max memory_allocated 22560.71044921875 
[2025-03-02 05:25:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.19564464688301086 norm:0.0009428826160728931 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.19068753719329834 norm:0.0006384550360962749 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.18841390311717987 norm:0.0005128547200001776 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.187223419547081 norm:0.00047254201490432024 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.1865941435098648 norm:0.00044079229701310396 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.18621835112571716 norm:0.0004213134234305471 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.1859910488128662 norm:0.00040830590296536684 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.18581393361091614 norm:0.00040175236063078046 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.18578509986400604 norm:0.00040094455471262336 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.1856999397277832 norm:0.0003883453900925815 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.18568888306617737 norm:0.0003828062326647341 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.18566982448101044 norm:0.0003801663115154952 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.18559542298316956 norm:0.0003780903934966773 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.18563340604305267 norm:0.0003779680992010981 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.18561197817325592 norm:0.0003745456342585385 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.18549522757530212 norm:0.000368017063010484 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.18550166487693787 norm:0.00036783472751267254 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.18551598489284515 norm:0.0003678800421766937 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 05:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.2588111162185669 norm:0.01612114906311035 max memory_allocated 22560.88232421875 
[2025-03-02 05:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.23654749989509583 norm:0.010100793093442917 max memory_allocated 22560.88232421875 
[2025-03-02 05:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.20651191473007202 norm:0.0035448367707431316 max memory_allocated 22560.88232421875 
[2025-03-02 05:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.19562500715255737 norm:0.0017012495081871748 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.1916855126619339 norm:0.0011734715662896633 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.18963046371936798 norm:0.0010211425833404064 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.18859127163887024 norm:0.0009580281912349164 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.187691792845726 norm:0.000837506668176502 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.18707424402236938 norm:0.0007842151098884642 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.18670013546943665 norm:0.0007800549501553178 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.18643958866596222 norm:0.0007138264481909573 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.18617989122867584 norm:0.0006914259865880013 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.18596144020557404 norm:0.0006494076224043965 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.1858026683330536 norm:0.0006311014294624329 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.18569552898406982 norm:0.000635233533103019 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.18549641966819763 norm:0.0006294111954048276 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.18553203344345093 norm:0.0006068719667382538 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.18562786281108856 norm:0.0005748973344452679 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.18555553257465363 norm:0.0005512521020136774 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.18556460738182068 norm:0.0005353382439352572 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 05:47:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.22132277488708496 norm:0.003830092493444681 max memory_allocated 22561.05419921875 
[2025-03-02 05:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.20651894807815552 norm:0.0017022088868543506 max memory_allocated 22561.05419921875 
[2025-03-02 05:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.19597101211547852 norm:0.0009715522755868733 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.19138427078723907 norm:0.000674201175570488 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.18907853960990906 norm:0.0005500246188603342 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.18794076144695282 norm:0.0004890118725597858 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.1872881054878235 norm:0.0004493615124374628 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.18693265318870544 norm:0.00041748903458938 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.18666517734527588 norm:0.0003972036065533757 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.18655307590961456 norm:0.00038654383388347924 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.18638083338737488 norm:0.0003710757882799953 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.18626847863197327 norm:0.0003624990058597177 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.18620631098747253 norm:0.0003543331695254892 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.18611720204353333 norm:0.0003464024921413511 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.18612845242023468 norm:0.0003464882029220462 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.18611538410186768 norm:0.00034167265403084457 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.18606938421726227 norm:0.00033918279223144054 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.18604034185409546 norm:0.00033604662166908383 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.1860254406929016 norm:0.00033585148048587143 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.1860930472612381 norm:0.0003401670546736568 max memory_allocated 22561.05419921875 
[2025-03-02 05:58:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 05:58:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.22436842322349548 norm:0.0051347240805625916 max memory_allocated 22561.22607421875 
[2025-03-02 05:59:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.20879694819450378 norm:0.002085751388221979 max memory_allocated 22561.22607421875 
[2025-03-02 05:59:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.19722311198711395 norm:0.0007970749866217375 max memory_allocated 22561.22607421875 
[2025-03-02 06:00:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.19323264062404633 norm:0.0005451130564324558 max memory_allocated 22561.22607421875 
[2025-03-02 06:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.19112151861190796 norm:0.00047979928785935044 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.189870223402977 norm:0.0004356239805929363 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.1891002655029297 norm:0.000402331497753039 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.1887151449918747 norm:0.00039572082459926605 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.18845058977603912 norm:0.00038163672434166074 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.18835338950157166 norm:0.0003788759931921959 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.1882467120885849 norm:0.00037647414137609303 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.18816588819026947 norm:0.0003686386626213789 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.18823744356632233 norm:0.000373503309674561 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.1881941705942154 norm:0.00036797637585550547 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.18817493319511414 norm:0.0003775088698603213 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.18805637955665588 norm:0.00038070528535172343 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.1880783885717392 norm:0.0003769354661926627 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.18807663023471832 norm:0.0003829294291790575 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.1880202442407608 norm:0.00037390770739875734 max memory_allocated 22561.22607421875 
[2025-03-02 06:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.18796423077583313 norm:0.0003719780361279845 max memory_allocated 22561.22607421875 
[2025-03-02 06:09:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.23188774287700653 norm:0.004351195879280567 max memory_allocated 22561.39794921875 
[2025-03-02 06:10:36 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.2155955284833908 norm:0.0018669981509447098 max memory_allocated 22561.39794921875 
[2025-03-02 06:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.204745814204216 norm:0.0010152270551770926 max memory_allocated 22561.39794921875 
[2025-03-02 06:11:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.2003047913312912 norm:0.0007124816183932126 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.19824115931987762 norm:0.0005694081191904843 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:50 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.1972554475069046 norm:0.0004994365735910833 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.19671747088432312 norm:0.0004588161827996373 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.19637717306613922 norm:0.00043325568549335003 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.19630944728851318 norm:0.0004192329361103475 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.19625303149223328 norm:0.00040728974272497 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.1961783766746521 norm:0.0003943215706385672 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.19611170887947083 norm:0.0003833991941064596 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.19603277742862701 norm:0.0003742138796951622 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.19599378108978271 norm:0.00037098920438438654 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.1959453821182251 norm:0.00036955525865778327 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.19586047530174255 norm:0.0003604596422519535 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.19589786231517792 norm:0.00036386048304848373 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.19585123658180237 norm:0.0003546770312823355 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.1958329975605011 norm:0.00035464329994283617 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.195789635181427 norm:0.00034993261215277016 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 06:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.23335742950439453 norm:0.003021488431841135 max memory_allocated 22561.56982421875 
[2025-03-02 06:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.22028584778308868 norm:0.0012500635348260403 max memory_allocated 22561.56982421875 
[2025-03-02 06:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.21085061132907867 norm:0.0006871485966257751 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.2071380317211151 norm:0.0005108949262648821 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.20529568195343018 norm:0.00043797653052024543 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.20439063012599945 norm:0.0004053663578815758 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.20389628410339355 norm:0.0003896397538483143 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.20359919965267181 norm:0.00037460552994161844 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.20343367755413055 norm:0.00036865490255877376 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.20333331823349 norm:0.00036891878698952496 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.20325006544589996 norm:0.0003611576394177973 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.20320509374141693 norm:0.0003649000427685678 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.20320424437522888 norm:0.00035292672691866755 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.2031453251838684 norm:0.0003457420680206269 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.20314066112041473 norm:0.0003415647952351719 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.20311151444911957 norm:0.00033831261680461466 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.20314471423625946 norm:0.00034755791421048343 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.20312398672103882 norm:0.00034440873423591256 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.2031131535768509 norm:0.000343684630934149 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.20309209823608398 norm:0.0003447099297773093 max memory_allocated 22561.56982421875 
[2025-03-02 06:32:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 06:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.2511548399925232 norm:0.00497328070923686 max memory_allocated 22561.74169921875 
[2025-03-02 06:33:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.23539581894874573 norm:0.0019730532076209784 max memory_allocated 22561.74169921875 
[2025-03-02 06:33:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.22293612360954285 norm:0.0007782976608723402 max memory_allocated 22561.74169921875 
[2025-03-02 06:34:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.2185458242893219 norm:0.0005622718017548323 max memory_allocated 22561.74169921875 
[2025-03-02 06:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.21670883893966675 norm:0.0005064387223683298 max memory_allocated 22561.74169921875 
[2025-03-02 06:35:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.2156391739845276 norm:0.00045816239435225725 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.2151098996400833 norm:0.000431463064160198 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.21479129791259766 norm:0.00041254243114963174 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.21457022428512573 norm:0.00039464887231588364 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.2143024206161499 norm:0.0003794643853325397 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.2141694873571396 norm:0.00036451336927711964 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.21404671669006348 norm:0.0003565828956197947 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.21403977274894714 norm:0.00035221403231844306 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.21399973332881927 norm:0.0003462732129264623 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.21395491063594818 norm:0.0003434760728850961 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.21383467316627502 norm:0.0003447920025791973 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.21383699774742126 norm:0.00034207093995064497 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.21387887001037598 norm:0.0003401955182198435 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.21385763585567474 norm:0.00033889018232002854 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.213934987783432 norm:0.00034123315708711743 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 06:44:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.2661730945110321 norm:0.004488094709813595 max memory_allocated 22561.91357421875 
[2025-03-02 06:44:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.25127485394477844 norm:0.0018417981918901205 max memory_allocated 22561.91357421875 
[2025-03-02 06:45:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.23996447026729584 norm:0.0008929059840738773 max memory_allocated 22561.91357421875 
[2025-03-02 06:45:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.23590199649333954 norm:0.0006454239482991397 max memory_allocated 22561.91357421875 
[2025-03-02 06:46:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.23395228385925293 norm:0.0005336624453775585 max memory_allocated 22561.91357421875 
[2025-03-02 06:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.2330814152956009 norm:0.00047554110642522573 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.23262590169906616 norm:0.00043960142647847533 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.23244529962539673 norm:0.0004149904125370085 max memory_allocated 22561.91357421875 
[2025-03-02 06:48:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.2322588413953781 norm:0.0003927489451598376 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.23207631707191467 norm:0.00037452985998243093 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.2319560945034027 norm:0.0003577274619601667 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.2318006455898285 norm:0.00035006762482225895 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.23178339004516602 norm:0.0003507484798319638 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.2317042499780655 norm:0.00034095870796591043 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.23169828951358795 norm:0.00034170824801549315 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.2316836416721344 norm:0.00033509847708046436 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.23163257539272308 norm:0.00033320439979434013 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.2315843552350998 norm:0.0003287286381237209 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.23150676488876343 norm:0.00032808829564601183 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.23152443766593933 norm:0.00032631956855766475 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 06:55:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.2915750741958618 norm:0.0038881783839315176 max memory_allocated 22562.08544921875 
[2025-03-02 06:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.2769388258457184 norm:0.0015277304919436574 max memory_allocated 22562.08544921875 
[2025-03-02 06:56:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.2653062045574188 norm:0.0007415685686282814 max memory_allocated 22562.08544921875 
[2025-03-02 06:57:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.26152336597442627 norm:0.0005576977273449302 max memory_allocated 22562.08544921875 
[2025-03-02 06:57:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.2597183883190155 norm:0.00046921393368393183 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.2589702010154724 norm:0.00042075058445334435 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.2585723400115967 norm:0.00038927572313696146 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.258319616317749 norm:0.0003702810499817133 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.25816747546195984 norm:0.00035693467361852527 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.25804221630096436 norm:0.0003483645850792527 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.25799521803855896 norm:0.0003435467660892755 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.25794556736946106 norm:0.00033889937913045287 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.25782960653305054 norm:0.0003344678261782974 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.2577008605003357 norm:0.0003306094731669873 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.25762683153152466 norm:0.00033239711774513125 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.2575431764125824 norm:0.00032811472192406654 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.2575099766254425 norm:0.00033156207064166665 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.25745946168899536 norm:0.0003332854248583317 max memory_allocated 22562.08544921875 
[2025-03-02 07:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.25741878151893616 norm:0.000324197462759912 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.2573387324810028 norm:0.0003265730629209429 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.3216956555843353 norm:0.0031550475396215916 max memory_allocated 22562.25732421875 
[2025-03-02 07:07:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.30864575505256653 norm:0.0014209933578968048 max memory_allocated 22562.25732421875 
[2025-03-02 07:07:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.2984963059425354 norm:0.0008037562947720289 max memory_allocated 22562.25732421875 
[2025-03-02 07:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.29494455456733704 norm:0.0006023652385920286 max memory_allocated 22562.25732421875 
[2025-03-02 07:08:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.2933207154273987 norm:0.0005346012185327709 max memory_allocated 22562.25732421875 
[2025-03-02 07:09:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.2926501929759979 norm:0.0004841280751861632 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.29217928647994995 norm:0.0004427207459229976 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.2919440269470215 norm:0.0004246185708325356 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.29182183742523193 norm:0.0004057619662489742 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.2915385067462921 norm:0.00037894092383794487 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.29134994745254517 norm:0.00037208100548014045 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.2912929654121399 norm:0.00036666958476416767 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.2911145091056824 norm:0.00034951523412019014 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.2910018563270569 norm:0.0003456543490756303 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.2909121811389923 norm:0.00033839402021840215 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.29087236523628235 norm:0.0003372199716977775 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.2908259928226471 norm:0.00033786497078835964 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.2907666265964508 norm:0.00033531783265061677 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.2907547950744629 norm:0.0003376537642907351 max memory_allocated 22562.25732421875 
[2025-03-02 07:17:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.29069650173187256 norm:0.0003345358418300748 max memory_allocated 22562.25732421875 
[2025-03-02 07:17:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 07:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.37639349699020386 norm:0.006734918337315321 max memory_allocated 22562.42919921875 
[2025-03-02 07:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.3596154451370239 norm:0.0027054217644035816 max memory_allocated 22562.42919921875 
[2025-03-02 07:19:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.34618717432022095 norm:0.001086693606339395 max memory_allocated 22562.42919921875 
[2025-03-02 07:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.3414898216724396 norm:0.000781513808760792 max memory_allocated 22562.42919921875 
[2025-03-02 07:20:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.3395349383354187 norm:0.0007016844465397298 max memory_allocated 22562.42919921875 
[2025-03-02 07:20:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.3388425409793854 norm:0.000637872377410531 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.3384597897529602 norm:0.0005786769324913621 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.3380962312221527 norm:0.0005313373985700309 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.33782705664634705 norm:0.0004994315677322447 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.3375266492366791 norm:0.0004780386807397008 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.3374488949775696 norm:0.0004563428810797632 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.33726370334625244 norm:0.00045065704034641385 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.3371674120426178 norm:0.00043326523154973984 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.33709990978240967 norm:0.0004326293710619211 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.33704474568367004 norm:0.0004210599872749299 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.3370559811592102 norm:0.00041452833102084696 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.3369569778442383 norm:0.0004061589716002345 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.3369258642196655 norm:0.0004054224700666964 max memory_allocated 22562.42919921875 
[2025-03-02 07:28:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.3368961215019226 norm:0.0004058421473018825 max memory_allocated 22562.42919921875 
[2025-03-02 07:28:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.33687692880630493 norm:0.00039983054739423096 max memory_allocated 22562.42919921875 
[2025-03-02 07:28:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 07:29:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.42449527978897095 norm:0.001833934336900711 max memory_allocated 22562.60107421875 
[2025-03-02 07:30:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.4117359220981598 norm:0.0009225240792147815 max memory_allocated 22562.60107421875 
[2025-03-02 07:30:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.39991486072540283 norm:0.000796028645709157 max memory_allocated 22562.60107421875 
[2025-03-02 07:31:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.39587149024009705 norm:0.000631155795417726 max memory_allocated 22562.60107421875 
[2025-03-02 07:31:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.3941826820373535 norm:0.0006349325412884355 max memory_allocated 22562.60107421875 
[2025-03-02 07:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.39357608556747437 norm:0.0006159119657240808 max memory_allocated 22562.60107421875 
[2025-03-02 07:32:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.3932444155216217 norm:0.0005733853904530406 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.3928762674331665 norm:0.0006115130963735282 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.3925085961818695 norm:0.0006116828881204128 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.3923497498035431 norm:0.0005824824911542237 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.3920731246471405 norm:0.0005918440874665976 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.3919554650783539 norm:0.0005932903150096536 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.39175787568092346 norm:0.0005862825782969594 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.39168691635131836 norm:0.0005830383743159473 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.3916623890399933 norm:0.000581681146286428 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.3916366696357727 norm:0.0005894467467442155 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.3914961516857147 norm:0.0005817962810397148 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.39151012897491455 norm:0.0005846073618158698 max memory_allocated 22562.60107421875 
[2025-03-02 07:39:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.3914104104042053 norm:0.0005655070999637246 max memory_allocated 22562.60107421875 
[2025-03-02 07:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.3916638493537903 norm:0.0005878056399524212 max memory_allocated 22562.60107421875 
[2025-03-02 07:40:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 07:40:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.4857988953590393 norm:0.0045123472809791565 max memory_allocated 22562.77294921875 
[2025-03-02 07:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.4697687029838562 norm:0.002224845578894019 max memory_allocated 22562.77294921875 
[2025-03-02 07:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.4563739597797394 norm:0.001221442362293601 max memory_allocated 22562.77294921875 
[2025-03-02 07:42:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.45168614387512207 norm:0.0008779235649853945 max memory_allocated 22562.77294921875 
[2025-03-02 07:43:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.4498181939125061 norm:0.0007270805654115975 max memory_allocated 22562.77294921875 
[2025-03-02 07:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.44916725158691406 norm:0.0006430423818528652 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.44883912801742554 norm:0.0005716863088309765 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.4484408497810364 norm:0.0005183385219424963 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.4482136070728302 norm:0.0004997936775907874 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.4480181038379669 norm:0.000482136441860348 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.447775661945343 norm:0.00046795839443802834 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.44769972562789917 norm:0.0004589900781866163 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.44781339168548584 norm:0.0004719770513474941 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.44779741764068604 norm:0.0004592380137182772 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.4476492404937744 norm:0.00045384943950921297 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.447614461183548 norm:0.00044626352610066533 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.4476315379142761 norm:0.00044309982331469655 max memory_allocated 22562.77294921875 
[2025-03-02 07:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.44731372594833374 norm:0.00043276845826767385 max memory_allocated 22562.77294921875 
[2025-03-02 07:50:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.44747889041900635 norm:0.00043735915096476674 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.4474344253540039 norm:0.0004285797767806798 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 07:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.5707642436027527 norm:0.011765185743570328 max memory_allocated 22562.94482421875 
[2025-03-02 07:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.5508342385292053 norm:0.006555443629622459 max memory_allocated 22562.94482421875 
[2025-03-02 07:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.5348163843154907 norm:0.004169185180217028 max memory_allocated 22562.94482421875 
[2025-03-02 07:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.5282430648803711 norm:0.0027516873087733984 max memory_allocated 22562.94482421875 
[2025-03-02 07:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.5254138708114624 norm:0.0020035579800605774 max memory_allocated 22562.94482421875 
[2025-03-02 07:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.5241266489028931 norm:0.0015586569206789136 max memory_allocated 22562.94482421875 
[2025-03-02 07:55:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.5235157608985901 norm:0.0012660217471420765 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.5227949619293213 norm:0.0010764178587123752 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.5222511887550354 norm:0.0009529017261229455 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.5218574404716492 norm:0.0008387197740375996 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.5214734077453613 norm:0.0007889955304563046 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.5209504961967468 norm:0.0006121102487668395 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.5207724571228027 norm:0.0006059670704416931 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.5206223130226135 norm:0.0006067968788556755 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.5204651355743408 norm:0.0006067947833798826 max memory_allocated 22562.94482421875 
[2025-03-02 08:00:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.5203462243080139 norm:0.0006132596754468977 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.5203582644462585 norm:0.0006111174589022994 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.5204010009765625 norm:0.0006134103750810027 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.5202476382255554 norm:0.0006034568650647998 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.5201902389526367 norm:0.0006119842291809618 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.6282973289489746 norm:0.0038178307004272938 max memory_allocated 22563.11669921875 
[2025-03-02 08:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.6131975650787354 norm:0.0019992333836853504 max memory_allocated 22563.11669921875 
[2025-03-02 08:04:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.5975743532180786 norm:0.0009909956716001034 max memory_allocated 22563.11669921875 
[2025-03-02 08:05:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.5925849080085754 norm:0.0007451900746673346 max memory_allocated 22563.11669921875 
[2025-03-02 08:05:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.5905985236167908 norm:0.0006465916521847248 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.5899031758308411 norm:0.0005899441312067211 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.589430570602417 norm:0.0005431724712252617 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.5891684293746948 norm:0.0005104062147438526 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.5888705253601074 norm:0.0004855297156609595 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.5886605978012085 norm:0.00047162885311990976 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.5884947180747986 norm:0.0004621359403245151 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.5883349180221558 norm:0.00045184374903328717 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.5882161855697632 norm:0.00044320779852569103 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.5880533456802368 norm:0.00043970465776510537 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.5879179239273071 norm:0.0004340434679761529 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.587840735912323 norm:0.0004272272053640336 max memory_allocated 22563.11669921875 
[2025-03-02 08:12:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.587762176990509 norm:0.000430482643423602 max memory_allocated 22563.11669921875 
[2025-03-02 08:12:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.5877686738967896 norm:0.0004278538981452584 max memory_allocated 22563.11669921875 
[2025-03-02 08:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.5877349376678467 norm:0.0004222117713652551 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.5876498818397522 norm:0.00042517000110819936 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 08:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.7117674946784973 norm:0.004284051712602377 max memory_allocated 22563.28857421875 
[2025-03-02 08:15:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.6959412693977356 norm:0.0023993216454982758 max memory_allocated 22563.28857421875 
[2025-03-02 08:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.6791608333587646 norm:0.00121667783241719 max memory_allocated 22563.28857421875 
[2025-03-02 08:16:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.6733642220497131 norm:0.000904395361430943 max memory_allocated 22563.28857421875 
[2025-03-02 08:17:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.6714150905609131 norm:0.0007518662605434656 max memory_allocated 22563.28857421875 
[2025-03-02 08:17:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.670748770236969 norm:0.0006546330987475812 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.6703343987464905 norm:0.0005983776063658297 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.6700367331504822 norm:0.000553322839550674 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.6697300672531128 norm:0.000525491836015135 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.6695507764816284 norm:0.0004981589736416936 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.6694541573524475 norm:0.0004932228475809097 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.6693153381347656 norm:0.00048517610412091017 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.6691376566886902 norm:0.00048427507863380015 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.6689351797103882 norm:0.00047719397116452456 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.6687144637107849 norm:0.0004730938235297799 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.6686501502990723 norm:0.00046912935795262456 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.6685949563980103 norm:0.00046378455590456724 max memory_allocated 22563.28857421875 
[2025-03-02 08:24:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.6684876680374146 norm:0.00046107536763884127 max memory_allocated 22563.28857421875 
[2025-03-02 08:24:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.6684719324111938 norm:0.00046272724284790456 max memory_allocated 22563.28857421875 
[2025-03-02 08:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.6683285236358643 norm:0.0004592110344674438 max memory_allocated 22563.28857421875 
[2025-03-02 08:25:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 08:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.8126541376113892 norm:0.012729145586490631 max memory_allocated 22563.46044921875 
[2025-03-02 08:26:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.7893497347831726 norm:0.006319704465568066 max memory_allocated 22563.46044921875 
[2025-03-02 08:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.769623339176178 norm:0.003580585354939103 max memory_allocated 22563.46044921875 
[2025-03-02 08:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.7618143558502197 norm:0.0023466087877750397 max memory_allocated 22563.46044921875 
[2025-03-02 08:28:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.759009599685669 norm:0.0017209001816809177 max memory_allocated 22563.46044921875 
[2025-03-02 08:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.7577155828475952 norm:0.00135140516795218 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.7569757699966431 norm:0.0011009128065779805 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.7564236521720886 norm:0.0009408326004631817 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.7560094594955444 norm:0.0008266268996521831 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.755656361579895 norm:0.0007432966376654804 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.7554281949996948 norm:0.0006794281071051955 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.7552748322486877 norm:0.0006428614724427462 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.7551711797714233 norm:0.0006119465106166899 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.7549901008605957 norm:0.0005956378299742937 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.7548662424087524 norm:0.0005794859607703984 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.7548134326934814 norm:0.0005667773075401783 max memory_allocated 22563.46044921875 
[2025-03-02 08:35:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.7546695470809937 norm:0.0005549128982238472 max memory_allocated 22563.46044921875 
[2025-03-02 08:35:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.7545899748802185 norm:0.000548161449842155 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.7544925808906555 norm:0.0005403113318607211 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.7544088363647461 norm:0.0005352814914658666 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 08:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.8917883634567261 norm:0.006861379835754633 max memory_allocated 22563.63232421875 
[2025-03-02 08:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.8712790608406067 norm:0.0034175137989223003 max memory_allocated 22563.63232421875 
[2025-03-02 08:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.8533790111541748 norm:0.002050914103165269 max memory_allocated 22563.63232421875 
[2025-03-02 08:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.847146213054657 norm:0.0014339468907564878 max memory_allocated 22563.63232421875 
[2025-03-02 08:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.8452235460281372 norm:0.0011553217191249132 max memory_allocated 22563.63232421875 
[2025-03-02 08:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.8448181748390198 norm:0.0009807087481021881 max memory_allocated 22563.63232421875 
[2025-03-02 08:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.8444778323173523 norm:0.000868414412252605 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.8442316651344299 norm:0.0007856368320062757 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.8440396785736084 norm:0.0007488115224987268 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.8439777493476868 norm:0.0007066972320899367 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.8438127040863037 norm:0.0006649445276707411 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.8438108563423157 norm:0.0006577413878403604 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.8439684510231018 norm:0.0006472640670835972 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.8444082140922546 norm:0.0006871948135085404 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.8440801501274109 norm:0.0006746069993823767 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.843468964099884 norm:0.000650052388664335 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.8439192771911621 norm:0.0006421805592253804 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.843522846698761 norm:0.0006716522620990872 max memory_allocated 22563.63232421875 
[2025-03-02 08:47:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.8432385921478271 norm:0.000603267049882561 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.8429852724075317 norm:0.000611091498285532 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 08:48:17 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 08:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:1.0213819742202759 norm:0.023246631026268005 max memory_allocated 22563.91943359375 
[2025-03-02 08:49:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.9965518116950989 norm:0.020906468853354454 max memory_allocated 22563.91943359375 
[2025-03-02 08:49:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.9753793478012085 norm:0.014266528189182281 max memory_allocated 22563.91943359375 
[2025-03-02 08:50:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.9673174619674683 norm:0.01272373553365469 max memory_allocated 22563.91943359375 
[2025-03-02 08:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.9644383788108826 norm:0.011559410952031612 max memory_allocated 22563.91943359375 
[2025-03-02 08:51:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.9629729986190796 norm:0.010608387179672718 max memory_allocated 22563.91943359375 
[2025-03-02 08:52:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.9619219899177551 norm:0.009876254945993423 max memory_allocated 22563.91943359375 
[2025-03-02 08:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.9611989855766296 norm:0.009160827845335007 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.9605792760848999 norm:0.008589430712163448 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.9600551128387451 norm:0.008375353179872036 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.9596759080886841 norm:0.008081198669970036 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.9595385193824768 norm:0.007937343791127205 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.9591944217681885 norm:0.00781330931931734 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.9590904116630554 norm:0.007845722138881683 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.9588541984558105 norm:0.007578712888062 max memory_allocated 22563.91943359375 
[2025-03-02 08:57:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.9586430788040161 norm:0.007467153947800398 max memory_allocated 22563.91943359375 
[2025-03-02 08:57:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.9584485292434692 norm:0.0071972948499023914 max memory_allocated 22563.91943359375 
[2025-03-02 08:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.9584137201309204 norm:0.007111795246601105 max memory_allocated 22563.91943359375 
[2025-03-02 08:58:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.9582585096359253 norm:0.007101807277649641 max memory_allocated 22563.91943359375 
[2025-03-02 08:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.9582065939903259 norm:0.007067961618304253 max memory_allocated 22563.91943359375 
[2025-03-02 08:59:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 08:59:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:00:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:1.1711318492889404 norm:0.03411193564534187 max memory_allocated 22564.09130859375 
[2025-03-02 09:00:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:1.1416692733764648 norm:0.026760512962937355 max memory_allocated 22564.09130859375 
[2025-03-02 09:01:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:1.115057110786438 norm:0.019005103036761284 max memory_allocated 22564.09130859375 
[2025-03-02 09:01:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:1.1054883003234863 norm:0.01573997735977173 max memory_allocated 22564.09130859375 
[2025-03-02 09:02:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:1.1021214723587036 norm:0.013730300590395927 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:01 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:1.100313663482666 norm:0.01200713962316513 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:1.099090814590454 norm:0.010625595226883888 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:1.0982074737548828 norm:0.009809848852455616 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:1.0974692106246948 norm:0.009060999378561974 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:1.0969789028167725 norm:0.008575571700930595 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:1.0965731143951416 norm:0.008278828114271164 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:1.096258521080017 norm:0.007830974645912647 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:1.095967411994934 norm:0.007524467073380947 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:1.095679759979248 norm:0.007148456759750843 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:1.0954638719558716 norm:0.0072599234990775585 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:1.0952659845352173 norm:0.006865513976663351 max memory_allocated 22564.09130859375 
[2025-03-02 09:09:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:1.0952050685882568 norm:0.007100831251591444 max memory_allocated 22564.09130859375 
[2025-03-02 09:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:1.0949859619140625 norm:0.006864132359623909 max memory_allocated 22564.09130859375 
[2025-03-02 09:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:1.0949451923370361 norm:0.0067848809994757175 max memory_allocated 22564.09130859375 
[2025-03-02 09:10:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:1.0948622226715088 norm:0.006526948884129524 max memory_allocated 22564.09130859375 
[2025-03-02 09:11:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:11:03 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:11:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.5318409204483032 norm:0.04771459475159645 max memory_allocated 22564.26318359375 
[2025-03-02 09:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:1.44965398311615 norm:0.028898002579808235 max memory_allocated 22564.26318359375 
[2025-03-02 09:12:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:1.3979946374893188 norm:0.03374188765883446 max memory_allocated 22564.26318359375 
[2025-03-02 09:13:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:1.3818649053573608 norm:0.033672258257865906 max memory_allocated 22564.26318359375 
[2025-03-02 09:13:50 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:1.3763662576675415 norm:0.035481929779052734 max memory_allocated 22564.26318359375 
[2025-03-02 09:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:1.3744046688079834 norm:0.039604708552360535 max memory_allocated 22564.26318359375 
[2025-03-02 09:14:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:1.3716390132904053 norm:0.0389990359544754 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:1.3706368207931519 norm:0.03926600143313408 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:1.3691117763519287 norm:0.04002514109015465 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:1.3684202432632446 norm:0.04005353897809982 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:1.3679111003875732 norm:0.03857063874602318 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:1.3671929836273193 norm:0.03890743479132652 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:1.3653430938720703 norm:0.03696855157613754 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:1.3635822534561157 norm:0.035629838705062866 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:1.3614791631698608 norm:0.03365777060389519 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:1.361708164215088 norm:0.033557645976543427 max memory_allocated 22564.26318359375 
[2025-03-02 09:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:1.3588824272155762 norm:0.03319643437862396 max memory_allocated 22564.26318359375 
[2025-03-02 09:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:1.3596553802490234 norm:0.03428955376148224 max memory_allocated 22564.26318359375 
[2025-03-02 09:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:1.3615553379058838 norm:0.034572020173072815 max memory_allocated 22564.26318359375 
[2025-03-02 09:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:1.361576795578003 norm:0.03381764516234398 max memory_allocated 22564.26318359375 
[2025-03-02 09:22:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 09:22:25 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:2.8311243057250977 norm:0.14691467583179474 max memory_allocated 22564.43505859375 
[2025-03-02 09:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:2.6178176403045654 norm:0.09323353320360184 max memory_allocated 22564.43505859375 
[2025-03-02 09:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:2.467283010482788 norm:0.06801479309797287 max memory_allocated 22564.43505859375 
[2025-03-02 09:24:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:2.411219835281372 norm:0.06628091633319855 max memory_allocated 22564.43505859375 
[2025-03-02 09:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:2.3754239082336426 norm:0.05916792154312134 max memory_allocated 22564.43505859375 
[2025-03-02 09:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:2.3527121543884277 norm:0.055050645023584366 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:2.3377597332000732 norm:0.054476384073495865 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:2.328050374984741 norm:0.054571546614170074 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:2.3189656734466553 norm:0.05416296422481537 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:2.3126449584960938 norm:0.054727230221033096 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:2.305664539337158 norm:0.05183941498398781 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:2.3023910522460938 norm:0.05531958490610123 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:2.299457311630249 norm:0.057207804173231125 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:2.296546220779419 norm:0.054409854114055634 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:2.2923927307128906 norm:0.05325895920395851 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:2.288688898086548 norm:0.05406993627548218 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:2.286466121673584 norm:0.05426797270774841 max memory_allocated 22564.43505859375 
[2025-03-02 09:32:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:2.2826173305511475 norm:0.049456361681222916 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:2.2823121547698975 norm:0.051660265773534775 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:2.281602621078491 norm:0.05357760190963745 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:45 root] (main_calib_config2.py 380): INFO 21782.47443461418
[2025-03-02 09:33:50 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 09:35:01 root] (main_calib_config2.py 159): INFO wikitext2 : 6.517213821411133
[2025-03-02 09:35:01 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 09:36:50 root] (main_calib_config2.py 159): INFO c4 : 8.460856437683105
[2025-03-02 11:16:17 root] (main_calib_config2.py 170): INFO {'wikitext2': 6.517213821411133, 'c4': 8.460856437683105, 'results': {'arc_easy': {'acc': 0.6245791245791246, 'acc_stderr': 0.0099362185271143, 'acc_norm': 0.49873737373737376, 'acc_norm_stderr': 0.010259750807991156}, 'arc_challenge': {'acc': 0.3430034129692833, 'acc_stderr': 0.013872423223718167, 'acc_norm': 0.36689419795221845, 'acc_norm_stderr': 0.014084133118104298}, 'winogrande': {'acc': 0.595895816890292, 'acc_stderr': 0.013791610664670856}, 'piqa': {'acc': 0.7404787812840044, 'acc_stderr': 0.010227939888173923, 'acc_norm': 0.7399347116430903, 'acc_norm_stderr': 0.010234893249061293}, 'boolq': {'acc': 0.6639143730886851, 'acc_stderr': 0.008261778456573672}, 'hellaswag': {'acc': 0.5177255526787492, 'acc_stderr': 0.004986644894743123, 'acc_norm': 0.678550089623581, 'acc_norm_stderr': 0.004660785616933771}}, 'versions': {'arc_easy': 0, 'arc_challenge': 0, 'winogrande': 0, 'piqa': 0, 'boolq': 1, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
