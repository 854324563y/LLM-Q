[2025-03-02 03:28:16 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.55', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.55.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 03:30:43 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-02 03:30:43 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.55.pkl
[2025-03-02 03:30:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 03:30:52 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:31:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.01106248702853918 norm:0.0069234734401106834 max memory_allocated 22559.10693359375 
[2025-03-02 03:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.006071471143513918 norm:0.00394328823313117 max memory_allocated 22559.10693359375 
[2025-03-02 03:32:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.004288258031010628 norm:0.002861948683857918 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0037248488515615463 norm:0.00220234552398324 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.003555143252015114 norm:0.0018803870771080256 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0034526370000094175 norm:0.0015743952244520187 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0034048985689878464 norm:0.0013604073319584131 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.003335984656587243 norm:0.001209345180541277 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.003290152410045266 norm:0.0010736559052020311 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0032554389908909798 norm:0.0009396846289746463 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.003226235508918762 norm:0.0007953879539854825 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0031942829955369234 norm:0.000738362199626863 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.00318386172875762 norm:0.0006711538881063461 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.00314968335442245 norm:0.0006164051592350006 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0031445578206330538 norm:0.0005797506892122328 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0031273127533495426 norm:0.0005525958840735257 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0031223706901073456 norm:0.0005375543260015547 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0031212051399052143 norm:0.0005299095064401627 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0031130220741033554 norm:0.0005038316012360156 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0031031128019094467 norm:0.0004884888767264783 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 03:42:19 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:42:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.025741921737790108 norm:0.01970033161342144 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.015015748329460621 norm:0.012051218189299107 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.010855548083782196 norm:0.007258587516844273 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.00971823651343584 norm:0.00523456372320652 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.009259114973247051 norm:0.0045021092519164085 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.008977772668004036 norm:0.003998253028839827 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.008771155029535294 norm:0.0036963005550205708 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.0085908193141222 norm:0.003357695182785392 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.008441334590315819 norm:0.0030719712376594543 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.008321425877511501 norm:0.0027847664896398783 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.00823329109698534 norm:0.002577860141173005 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.008205779828131199 norm:0.00237985048443079 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.00816536694765091 norm:0.0021696225740015507 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.008116547018289566 norm:0.0019550754223018885 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.008039053529500961 norm:0.0017532643396407366 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.00802094116806984 norm:0.0015836837701499462 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.007992931641638279 norm:0.0014416787307709455 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.007995844818651676 norm:0.0013241121778264642 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.008001353591680527 norm:0.001326009165495634 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.008054881356656551 norm:0.0012629935517907143 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 03:53:47 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.08556606620550156 norm:0.02728279121220112 max memory_allocated 22559.45068359375 
[2025-03-02 03:54:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.0430324412882328 norm:0.014460612088441849 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.028735069558024406 norm:0.011009219102561474 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.02346562035381794 norm:0.010795824229717255 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.021783892065286636 norm:0.008941756561398506 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.0204431414604187 norm:0.008015252649784088 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.019860537722706795 norm:0.007356966380029917 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.01961655542254448 norm:0.006877253297716379 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.019486911594867706 norm:0.006398587021976709 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.019202962517738342 norm:0.006184086203575134 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:59 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.01897175796329975 norm:0.005987231153994799 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:33 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.01904459111392498 norm:0.006040732376277447 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.018702266737818718 norm:0.005823933053761721 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.01884455792605877 norm:0.00567803205922246 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.018574468791484833 norm:0.005402574315667152 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.018425993621349335 norm:0.005100186448544264 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.01882263645529747 norm:0.005327813792973757 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.01852254569530487 norm:0.005024816375225782 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.01848388835787773 norm:0.004966248758137226 max memory_allocated 22559.45068359375 
[2025-03-02 04:05:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.018444383516907692 norm:0.004811685066670179 max memory_allocated 22559.45068359375 
[2025-03-02 04:05:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:05:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.03546811267733574 norm:0.003991629928350449 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.02625173144042492 norm:0.0012226109392940998 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.02206460013985634 norm:0.0006329231546260417 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.020600713789463043 norm:0.0003690606390591711 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.01977936550974846 norm:0.00026749627431854606 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.01931440457701683 norm:0.00019623087428044528 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.019126802682876587 norm:0.00017229844524990767 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.019034262746572495 norm:0.00016530236462131143 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.018999043852090836 norm:0.000147208062116988 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.01895282231271267 norm:0.00012914391118101776 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.01891784369945526 norm:0.00012310243619140238 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.018914610147476196 norm:0.00012057246203767136 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.018909825012087822 norm:0.00012060550216119736 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.018906211480498314 norm:0.00011526695743668824 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.01892876625061035 norm:0.00012558005983009934 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.018905622884631157 norm:0.00011173139500897378 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.01890452764928341 norm:0.00011130359780509025 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.018903249874711037 norm:0.00011116254609078169 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.018906258046627045 norm:0.0001183080457849428 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.018911059945821762 norm:0.00011531626660143957 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 04:17:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.043712224811315536 norm:0.0030073923990130424 max memory_allocated 22559.67919921875 
[2025-03-02 04:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.03303025662899017 norm:0.001105444971472025 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.02733411267399788 norm:0.0005732717690989375 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.025220131501555443 norm:0.00034162335214205086 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.024304015561938286 norm:0.00025943893706426024 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.023852888494729996 norm:0.00023271437385119498 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.023678014054894447 norm:0.0002022490807576105 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.02354889176785946 norm:0.0001960914087248966 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.023473627865314484 norm:0.00018113003170583397 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.0234385933727026 norm:0.00019253531354479492 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.0233998391777277 norm:0.0001835720322560519 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.023411424830555916 norm:0.00018112239195033908 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.023395080119371414 norm:0.0001777908328222111 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.023374535143375397 norm:0.000172674423083663 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.023368563503026962 norm:0.0001747507049003616 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.02335706353187561 norm:0.00016996447811834514 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.023353273048996925 norm:0.00017518318782094866 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.023335181176662445 norm:0.00017523803398944438 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.02333647571504116 norm:0.0001764761982485652 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.02340189926326275 norm:0.00018645080854184926 max memory_allocated 22559.67919921875 
[2025-03-02 04:28:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 04:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.04741436243057251 norm:0.0029011708684265614 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.036716341972351074 norm:0.0011236394057050347 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.031114865094423294 norm:0.000589755829423666 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.02901950106024742 norm:0.000368201028322801 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.02796214446425438 norm:0.0002457938389852643 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.02747461386024952 norm:0.00020759666222147644 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.027274364605545998 norm:0.00020142293942626566 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.02713741734623909 norm:0.0001839454344008118 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.027007494121789932 norm:0.00016786743071861565 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.02692977339029312 norm:0.0001667500619078055 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.026916779577732086 norm:0.00017694162670522928 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.026853127405047417 norm:0.00017574506637174636 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.026829633861780167 norm:0.0001772628165781498 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.026819616556167603 norm:0.00017340494378004223 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.026820659637451172 norm:0.0001794428244465962 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.026870042085647583 norm:0.00016561801021452993 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.02682618238031864 norm:0.00015931829693727195 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.02677447348833084 norm:0.0001600963732926175 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.02682218700647354 norm:0.0001640414702706039 max memory_allocated 22559.85107421875 
[2025-03-02 04:39:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.026821572333574295 norm:0.0001605149154784158 max memory_allocated 22559.85107421875 
[2025-03-02 04:39:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 04:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.05118151754140854 norm:0.004321382846683264 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.040197137743234634 norm:0.0009769108146429062 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.03476930037140846 norm:0.00048626025090925395 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.03291403129696846 norm:0.00032424996607005596 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:27 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.03197524696588516 norm:0.00024072157975751907 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.03140116482973099 norm:0.00021036440739408135 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.031183116137981415 norm:0.0001979762892005965 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.031124327331781387 norm:0.00021083324099890888 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.03104349598288536 norm:0.00019245658768340945 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.03096085973083973 norm:0.000179611291969195 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.03091268241405487 norm:0.00016684641013853252 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.030854741111397743 norm:0.00016455833974760026 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.03084261529147625 norm:0.00016494691953994334 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.030801430344581604 norm:0.00015735489432699978 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.030762670561671257 norm:0.00015356049698311836 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.03073945641517639 norm:0.00015822930436115712 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.03074401244521141 norm:0.00016497231263201684 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.030748602002859116 norm:0.00016197770310100168 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.030736051499843597 norm:0.0001646060700295493 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.0307124275714159 norm:0.00015183599316515028 max memory_allocated 22560.02294921875 
[2025-03-02 04:51:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 04:51:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.054723870009183884 norm:0.0018945580814033747 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.04464642331004143 norm:0.0007510661380365491 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.03916461765766144 norm:0.00046356217353604734 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.03716852888464928 norm:0.0002796194748952985 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.03614211454987526 norm:0.00021989802189636976 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.03569137305021286 norm:0.0002076146483886987 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.0355326272547245 norm:0.00018907268531620502 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.03544597327709198 norm:0.0001913903106469661 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.035311512649059296 norm:0.00016329725622199476 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.03523530066013336 norm:0.0001789072557585314 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.03521972894668579 norm:0.00016442779451608658 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.03523683175444603 norm:0.00015263792010955513 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.035195086151361465 norm:0.00014965509762987494 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.03519445285201073 norm:0.00015919354336801916 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.03516392409801483 norm:0.00016308289195876569 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.03515872359275818 norm:0.00016011568368412554 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.035172052681446075 norm:0.00016018774476833642 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.035135913640260696 norm:0.0001601956901140511 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.03510550409555435 norm:0.0001549500011606142 max memory_allocated 22560.19482421875 
[2025-03-02 05:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.03515506908297539 norm:0.00016472680727019906 max memory_allocated 22560.19482421875 
[2025-03-02 05:02:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:03:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.06052505224943161 norm:0.001615866320207715 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.049097735434770584 norm:0.0006097386358305812 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.0428294911980629 norm:0.0003278304939158261 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.040700845420360565 norm:0.00023746283841319382 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.03958810120820999 norm:0.00019162861281074584 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.039059873670339584 norm:0.00016447348752990365 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.03884759172797203 norm:0.00015816694940440357 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.03871818259358406 norm:0.0001563787809573114 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.038668978959321976 norm:0.00015487958444282413 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.038579706102609634 norm:0.00014664302580058575 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.038489606231451035 norm:0.00014568198821507394 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.03845810890197754 norm:0.00014477447257377207 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.03844854235649109 norm:0.0001621872215764597 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.03847847506403923 norm:0.0001555404014652595 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.03844832628965378 norm:0.000141166674438864 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.038439881056547165 norm:0.00014574243687093258 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.03845065459609032 norm:0.00014767763786949217 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.03842423856258392 norm:0.00014312972780317068 max memory_allocated 22560.36669921875 
[2025-03-02 05:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.03840649873018265 norm:0.0001402628404321149 max memory_allocated 22560.36669921875 
[2025-03-02 05:13:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.038384635001420975 norm:0.00013811701501253992 max memory_allocated 22560.36669921875 
[2025-03-02 05:13:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 05:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.06612899154424667 norm:0.001756628043949604 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.05373922735452652 norm:0.0007099391659721732 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.04733969271183014 norm:0.00041072003659792244 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.04507315158843994 norm:0.0002757680194918066 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.043962497264146805 norm:0.00022234555217437446 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.04341328516602516 norm:0.00019644727581180632 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.04312319681048393 norm:0.00017544152797199786 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.04297718033194542 norm:0.00016014104767236859 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.04284586012363434 norm:0.00015251210425049067 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.042731866240501404 norm:0.00014479373930953443 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.042731914669275284 norm:0.00014875386841595173 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.04265362024307251 norm:0.00014387773990165442 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.042665719985961914 norm:0.0001491467992309481 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.04263854771852493 norm:0.00014738846221007407 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.042584098875522614 norm:0.00013789255172014236 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.042563457041978836 norm:0.00013694258814211935 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.042525794357061386 norm:0.00013840373139828444 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.04249962791800499 norm:0.00013320618018042296 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.04250374436378479 norm:0.0001316022826358676 max memory_allocated 22560.53857421875 
[2025-03-02 05:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.042483095079660416 norm:0.00013364363985601813 max memory_allocated 22560.53857421875 
[2025-03-02 05:25:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 05:26:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.06447605788707733 norm:0.00134367891587317 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.055665235966444016 norm:0.0005841655656695366 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.0498502254486084 norm:0.00030354002956300974 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.047674354165792465 norm:0.00021427434694487602 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.04674630984663963 norm:0.00017411661974620074 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.046329014003276825 norm:0.00015025062020868063 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.046154990792274475 norm:0.00013101442891638726 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.04604673013091087 norm:0.00012039343710057437 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.045988284051418304 norm:0.00011732320854207501 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.0459500290453434 norm:0.00011908282613148913 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.04591651260852814 norm:0.00011356861796230078 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.04586758837103844 norm:0.00010966601985273883 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.04584304615855217 norm:0.00010599193774396554 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.04581941291689873 norm:0.00010645592556102201 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.04582873359322548 norm:0.00011267569789197296 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.045813895761966705 norm:0.00011114630615338683 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.04580902308225632 norm:0.00011028037260985002 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.045796215534210205 norm:0.00010711098730098456 max memory_allocated 22560.71044921875 
[2025-03-02 05:36:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.045775316655635834 norm:0.00010824429773492739 max memory_allocated 22560.71044921875 
[2025-03-02 05:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.0458032451570034 norm:0.00011459264351287857 max memory_allocated 22560.71044921875 
[2025-03-02 05:36:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 05:37:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.06841698288917542 norm:0.00215961248613894 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.05868976563215256 norm:0.0007948933634907007 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.052389971911907196 norm:0.0003657619236037135 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.05029118061065674 norm:0.0002190981904277578 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.04939625412225723 norm:0.00017360942729283124 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.04895049333572388 norm:0.00015271297888830304 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.048748213797807693 norm:0.0001430801348760724 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.04860861971974373 norm:0.00012704232358373702 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.04850556701421738 norm:0.0001296353293582797 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.048448387533426285 norm:0.00012372966739349067 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.04841601848602295 norm:0.00011966565216425806 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.048397500067949295 norm:0.00011809914576588199 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.04835626855492592 norm:0.00011818460188806057 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.04832230135798454 norm:0.00011973115033470094 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.04831841215491295 norm:0.00011576696124393493 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.04828672483563423 norm:0.00011285937944194302 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.048279374837875366 norm:0.00011067862214986235 max memory_allocated 22560.88232421875 
[2025-03-02 05:47:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.04825952649116516 norm:0.00011042530968552455 max memory_allocated 22560.88232421875 
[2025-03-02 05:47:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.04825457185506821 norm:0.00010638477397151291 max memory_allocated 22560.88232421875 
[2025-03-02 05:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.04824599251151085 norm:0.00010726961045293137 max memory_allocated 22560.88232421875 
[2025-03-02 05:48:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 05:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.06920190900564194 norm:0.0010676259407773614 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.06082324683666229 norm:0.0004928518319502473 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.054964594542980194 norm:0.00027593254344537854 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.05284279212355614 norm:0.00019663308921735734 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.05181458592414856 norm:0.00016670863260515034 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.05129687115550041 norm:0.0001516651245765388 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.05104734003543854 norm:0.00013952917652204633 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.05088815838098526 norm:0.00012881014845333993 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.05077746510505676 norm:0.00012494174006860703 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.05071236193180084 norm:0.00011903401173185557 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.05065447464585304 norm:0.00011642373283393681 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.05061819404363632 norm:0.00010913031292147934 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.05060163140296936 norm:0.00010844236385310069 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.05056612193584442 norm:0.00010824131459230557 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.05056110396981239 norm:0.00010718585690483451 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.050540484488010406 norm:0.0001027716207318008 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.050523992627859116 norm:0.00010278764966642484 max memory_allocated 22561.05419921875 
[2025-03-02 05:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.05051642283797264 norm:0.00010470637062098831 max memory_allocated 22561.05419921875 
[2025-03-02 05:59:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.05052506923675537 norm:0.00010780317097669467 max memory_allocated 22561.05419921875 
[2025-03-02 05:59:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.05050757899880409 norm:0.00010523437231313437 max memory_allocated 22561.05419921875 
[2025-03-02 05:59:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 06:00:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.07056770473718643 norm:0.0010404271306470037 max memory_allocated 22561.22607421875 
[2025-03-02 06:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.06248730421066284 norm:0.00044600243563763797 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.057197827845811844 norm:0.0002789277641568333 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.055203624069690704 norm:0.00019945688836742193 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.05422888696193695 norm:0.00015920573787298054 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.05370458960533142 norm:0.00013984103861730546 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.05343693122267723 norm:0.00012770594912581146 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.05331910401582718 norm:0.00011988517508143559 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.053205542266368866 norm:0.00011350057320669293 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.05315376818180084 norm:0.00010909654520219192 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.05309775844216347 norm:0.00010656701488187537 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.05307653546333313 norm:0.00010632388875819743 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.05302092432975769 norm:0.00010446926899021491 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.05298169329762459 norm:9.976996807381511e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.052967339754104614 norm:0.00010137080971617252 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.05296779423952103 norm:0.00010200122778769583 max memory_allocated 22561.22607421875 
[2025-03-02 06:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.05300296097993851 norm:0.00010726891923695803 max memory_allocated 22561.22607421875 
[2025-03-02 06:09:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.0529760979115963 norm:0.00010089932038681582 max memory_allocated 22561.22607421875 
[2025-03-02 06:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.052959248423576355 norm:9.81892881100066e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:11:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.052944302558898926 norm:9.944268822437152e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:11:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.07736512273550034 norm:0.0014155254466459155 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.06788700819015503 norm:0.0006365696317516267 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.06164117902517319 norm:0.0003649164573289454 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.05944797769188881 norm:0.0002510636404622346 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.05839146301150322 norm:0.00019820540910586715 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.05788436904549599 norm:0.0001723418099572882 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.05765916407108307 norm:0.0001572299952385947 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.05748758465051651 norm:0.00014043824921827763 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.05734642595052719 norm:0.00013252907956484705 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.05729099363088608 norm:0.00012785887520294636 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.057235050946474075 norm:0.00011839851504191756 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.05719012767076492 norm:0.00011550105409696698 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.057117924094200134 norm:0.00011159045970998704 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.05709623917937279 norm:0.00011838095815619454 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.05706192925572395 norm:0.00011151478247484192 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.05704778805375099 norm:0.0001116880594054237 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.057036589831113815 norm:0.00010753850801847875 max memory_allocated 22561.39794921875 
[2025-03-02 06:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.05701129138469696 norm:0.0001067042030626908 max memory_allocated 22561.39794921875 
[2025-03-02 06:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.056997448205947876 norm:0.00010752686648629606 max memory_allocated 22561.39794921875 
[2025-03-02 06:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.056983862072229385 norm:0.00010670616029528901 max memory_allocated 22561.39794921875 
[2025-03-02 06:22:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 06:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.07922350615262985 norm:0.0009633307345211506 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.07123247534036636 norm:0.0004485582176130265 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.06521736085414886 norm:0.0002529588236939162 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.0631750300526619 norm:0.00019629354937933385 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.06223506107926369 norm:0.00016602160758338869 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.061782434582710266 norm:0.00014027365250512958 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:39 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.06155050918459892 norm:0.00012639582564588636 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.06139674410223961 norm:0.00012019269342999905 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.0613429993391037 norm:0.00012537081784103066 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.06129363924264908 norm:0.0001212005372508429 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.06121004745364189 norm:0.00011039382661692798 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.06117139384150505 norm:0.00010749047942226753 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.061161939054727554 norm:0.00011828191054519266 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.06111098825931549 norm:0.0001080484944395721 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.06108300760388374 norm:0.00010927882976830006 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.061055853962898254 norm:0.00010821971955010667 max memory_allocated 22561.56982421875 
[2025-03-02 06:32:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.0610232949256897 norm:0.00010730397480074316 max memory_allocated 22561.56982421875 
[2025-03-02 06:32:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.06100936979055405 norm:0.00010566983110038564 max memory_allocated 22561.56982421875 
[2025-03-02 06:33:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.06101103872060776 norm:0.0001084328832803294 max memory_allocated 22561.56982421875 
[2025-03-02 06:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.06101034954190254 norm:0.00011146746692247689 max memory_allocated 22561.56982421875 
[2025-03-02 06:34:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 06:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.08808013051748276 norm:0.0015292282914742827 max memory_allocated 22561.74169921875 
[2025-03-02 06:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.07808047533035278 norm:0.0005494317738339305 max memory_allocated 22561.74169921875 
[2025-03-02 06:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.07142098993062973 norm:0.00029932643519714475 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.06926310062408447 norm:0.0002283311478095129 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.0681738629937172 norm:0.0002005902206292376 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.0676189437508583 norm:0.00016637652879580855 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.06737197935581207 norm:0.00015339997480623424 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.067191481590271 norm:0.0001378499873680994 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.06706617772579193 norm:0.0001374246785417199 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.06701726466417313 norm:0.0001437219907529652 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.06691128760576248 norm:0.00012299629452172667 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.06683982908725739 norm:0.00011737226304830983 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.06681951880455017 norm:0.00012170178524684161 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.06674226373434067 norm:0.00011693423584802076 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.06671377271413803 norm:0.00011534729856066406 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.06666684150695801 norm:0.00010978554200846702 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.06662468612194061 norm:0.00011134892702102661 max memory_allocated 22561.74169921875 
[2025-03-02 06:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.06659911572933197 norm:0.00011118940892629325 max memory_allocated 22561.74169921875 
[2025-03-02 06:44:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.06657999753952026 norm:0.00011169914796482772 max memory_allocated 22561.74169921875 
[2025-03-02 06:45:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.06656232476234436 norm:0.00011262246698606759 max memory_allocated 22561.74169921875 
[2025-03-02 06:45:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 06:46:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.09770075231790543 norm:0.0017403177917003632 max memory_allocated 22561.91357421875 
[2025-03-02 06:46:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.0872369334101677 norm:0.0007078432245180011 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.07974600046873093 norm:0.000397902651457116 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.07734661549329758 norm:0.00027761084493249655 max memory_allocated 22561.91357421875 
[2025-03-02 06:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.07623902708292007 norm:0.0002168997161788866 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.07575689256191254 norm:0.00019517158216331154 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.07550922781229019 norm:0.00017204506730195135 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.07537414878606796 norm:0.00015636396710760891 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.07520312070846558 norm:0.00014573600492440164 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.07512133568525314 norm:0.0001412441924912855 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.07506400346755981 norm:0.0001320265728281811 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.0749753788113594 norm:0.0001279791904380545 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.07489068806171417 norm:0.00012198573676869273 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.074839286506176 norm:0.00012120792962377891 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.074800044298172 norm:0.00011974121298408136 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.07474568486213684 norm:0.00011963188444497064 max memory_allocated 22561.91357421875 
[2025-03-02 06:55:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.07472173124551773 norm:0.00011972155334660783 max memory_allocated 22561.91357421875 
[2025-03-02 06:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.07469812035560608 norm:0.00012183256330899894 max memory_allocated 22561.91357421875 
[2025-03-02 06:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.07468453794717789 norm:0.00011933314090128988 max memory_allocated 22561.91357421875 
[2025-03-02 06:56:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.07466000318527222 norm:0.00011928388994419947 max memory_allocated 22561.91357421875 
[2025-03-02 06:57:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 06:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.10727047920227051 norm:0.0012658840278163552 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.09729375690221786 norm:0.0005283576902002096 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.08994034677743912 norm:0.0003129123942926526 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.0876617431640625 norm:0.00024012854555621743 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.08662254363298416 norm:0.00020144300651736557 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.08623121678829193 norm:0.0001866944949142635 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.08597604930400848 norm:0.00016949212295003235 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.08581498265266418 norm:0.00015861856809351593 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.08570948243141174 norm:0.000147181999636814 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.08559882640838623 norm:0.0001424824440618977 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.08551421016454697 norm:0.00013865926302969456 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.08540963381528854 norm:0.00013247645983938128 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.08533675968647003 norm:0.0001296125556109473 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.08529072999954224 norm:0.00012564132339321077 max memory_allocated 22562.08544921875 
[2025-03-02 07:05:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.08527463674545288 norm:0.0001257445983355865 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.08523723483085632 norm:0.00012512282410170883 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.0851970911026001 norm:0.00012452418741304427 max memory_allocated 22562.08544921875 
[2025-03-02 07:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.08515824377536774 norm:0.00012108012015232816 max memory_allocated 22562.08544921875 
[2025-03-02 07:07:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.08512389659881592 norm:0.0001231484056916088 max memory_allocated 22562.08544921875 
[2025-03-02 07:08:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.08512778580188751 norm:0.00012212496949359775 max memory_allocated 22562.08544921875 
[2025-03-02 07:08:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.12165962904691696 norm:0.0013100113719701767 max memory_allocated 22562.25732421875 
[2025-03-02 07:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.11155432462692261 norm:0.0006031142547726631 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.10371273010969162 norm:0.0003373846993781626 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.10130143910646439 norm:0.0002592944074422121 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.10021872073411942 norm:0.000214495332329534 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.09983465075492859 norm:0.00020617659902200103 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.09961830824613571 norm:0.00018483545864000916 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.09937811642885208 norm:0.00017271938850171864 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:35 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.09919802099466324 norm:0.00015904668543953449 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.09908968210220337 norm:0.00015512658865191042 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.09900055825710297 norm:0.0001524369727121666 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.09889621287584305 norm:0.00014646686031483114 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.09881545603275299 norm:0.00014308271056506783 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.09878237545490265 norm:0.00014597788685932755 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.09871213138103485 norm:0.0001389480021316558 max memory_allocated 22562.25732421875 
[2025-03-02 07:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.09865113347768784 norm:0.00013599492376670241 max memory_allocated 22562.25732421875 
[2025-03-02 07:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.09859222173690796 norm:0.00013526696420740336 max memory_allocated 22562.25732421875 
[2025-03-02 07:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.09856468439102173 norm:0.00013599336671177298 max memory_allocated 22562.25732421875 
[2025-03-02 07:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.09852388501167297 norm:0.00013382991892285645 max memory_allocated 22562.25732421875 
[2025-03-02 07:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.09849446266889572 norm:0.00013373936235439032 max memory_allocated 22562.25732421875 
[2025-03-02 07:19:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 07:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.14751626551151276 norm:0.003458684775978327 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.13335654139518738 norm:0.0011088538449257612 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.12357699126005173 norm:0.0005498165264725685 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.12067299336194992 norm:0.00044637612882070243 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.11955402791500092 norm:0.0004043931548949331 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.11899470537900925 norm:0.0003343127609696239 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.11868272721767426 norm:0.00031250249594449997 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.1183692142367363 norm:0.00028362427838146687 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.11812837421894073 norm:0.00025256999651901424 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.11793474853038788 norm:0.00023158543626777828 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.11774884164333344 norm:0.00022629296290688217 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.11761143058538437 norm:0.0002112802758347243 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.11753807961940765 norm:0.00020239377045072615 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.1174122616648674 norm:0.00019811431411653757 max memory_allocated 22562.42919921875 
[2025-03-02 07:28:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.11734643578529358 norm:0.00019948685076087713 max memory_allocated 22562.42919921875 
[2025-03-02 07:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.11726370453834534 norm:0.0001913301821332425 max memory_allocated 22562.42919921875 
[2025-03-02 07:29:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.11721847951412201 norm:0.00019071287533733994 max memory_allocated 22562.42919921875 
[2025-03-02 07:30:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.11716591566801071 norm:0.00019388490181881934 max memory_allocated 22562.42919921875 
[2025-03-02 07:30:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.11712751537561417 norm:0.00019501251517795026 max memory_allocated 22562.42919921875 
[2025-03-02 07:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.11710583418607712 norm:0.00018702654051594436 max memory_allocated 22562.42919921875 
[2025-03-02 07:31:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 07:31:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.16723288595676422 norm:0.0010317047126591206 max memory_allocated 22562.60107421875 
[2025-03-02 07:32:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.1554081290960312 norm:0.0005029710009694099 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.14555147290229797 norm:0.0003726135182660073 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.1427398920059204 norm:0.000337381090503186 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.14143219590187073 norm:0.00032314163399860263 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.1410379260778427 norm:0.0003360636765137315 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.1407351940870285 norm:0.00030046459869481623 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.1403491199016571 norm:0.0002668000233825296 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.14010481536388397 norm:0.0002579559513833374 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.13993868231773376 norm:0.000255560502409935 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.13978134095668793 norm:0.00024898562696762383 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.1396304816007614 norm:0.00025623635156080127 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.1395273357629776 norm:0.00023542600683867931 max memory_allocated 22562.60107421875 
[2025-03-02 07:39:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.13941185176372528 norm:0.0002627519133966416 max memory_allocated 22562.60107421875 
[2025-03-02 07:39:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.1393345445394516 norm:0.00025207846192643046 max memory_allocated 22562.60107421875 
[2025-03-02 07:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.13931646943092346 norm:0.0002780466165859252 max memory_allocated 22562.60107421875 
[2025-03-02 07:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.13925719261169434 norm:0.0002601288724690676 max memory_allocated 22562.60107421875 
[2025-03-02 07:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.1391630470752716 norm:0.00027798148221336305 max memory_allocated 22562.60107421875 
[2025-03-02 07:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.13921979069709778 norm:0.0002472486230544746 max memory_allocated 22562.60107421875 
[2025-03-02 07:42:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.13944607973098755 norm:0.00033382404944859445 max memory_allocated 22562.60107421875 
[2025-03-02 07:42:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 07:43:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.19357909262180328 norm:0.0018464300082996488 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.1801292598247528 norm:0.000869082345161587 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.16922475397586823 norm:0.0004982466925866902 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.16607075929641724 norm:0.00037119450280442834 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.16496765613555908 norm:0.00030372972832992673 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.16441954672336578 norm:0.0002659427700564265 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.16406755149364471 norm:0.0002416687784716487 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.1638144552707672 norm:0.00022532333969138563 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.1636054515838623 norm:0.0002156529517378658 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.1634407639503479 norm:0.0002157329290639609 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.16333401203155518 norm:0.00022092097788117826 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.16316008567810059 norm:0.00020873299217782915 max memory_allocated 22562.77294921875 
[2025-03-02 07:50:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.16308817267417908 norm:0.00021009804913774133 max memory_allocated 22562.77294921875 
[2025-03-02 07:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.16296043992042542 norm:0.00020817162294406444 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.1628369390964508 norm:0.0002054823562502861 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.1626867651939392 norm:0.00020397861953824759 max memory_allocated 22562.77294921875 
[2025-03-02 07:52:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.16264361143112183 norm:0.00020100311667192727 max memory_allocated 22562.77294921875 
[2025-03-02 07:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.16252736747264862 norm:0.0001982974645216018 max memory_allocated 22562.77294921875 
[2025-03-02 07:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.16250067949295044 norm:0.00019605117267929018 max memory_allocated 22562.77294921875 
[2025-03-02 07:54:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.16251881420612335 norm:0.0001982211833819747 max memory_allocated 22562.77294921875 
[2025-03-02 07:54:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 07:54:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.2242109477519989 norm:0.002048538764938712 max memory_allocated 22562.94482421875 
[2025-03-02 07:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.21020983159542084 norm:0.001079436857253313 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.19865484535694122 norm:0.0006643482483923435 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.19519661366939545 norm:0.0004911322612315416 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.19402474164962769 norm:0.000410752953030169 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.19347703456878662 norm:0.00033825243008323014 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.19313985109329224 norm:0.000309901952277869 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.19285470247268677 norm:0.0002940623671747744 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.19259484112262726 norm:0.0002679319295566529 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.19240526854991913 norm:0.0002589371579233557 max memory_allocated 22562.94482421875 
[2025-03-02 08:00:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.19225086271762848 norm:0.0002576372935436666 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.19205015897750854 norm:0.00024150415265467018 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.19188378751277924 norm:0.00023802954819984734 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.19179171323776245 norm:0.0002407911524642259 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.19168688356876373 norm:0.00024259858764708042 max memory_allocated 22562.94482421875 
[2025-03-02 08:03:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.19155386090278625 norm:0.00024277801276184618 max memory_allocated 22562.94482421875 
[2025-03-02 08:03:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.19146957993507385 norm:0.0002370105794398114 max memory_allocated 22562.94482421875 
[2025-03-02 08:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.19141514599323273 norm:0.00023291951220016927 max memory_allocated 22562.94482421875 
[2025-03-02 08:05:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.19132843613624573 norm:0.0002338455233257264 max memory_allocated 22562.94482421875 
[2025-03-02 08:05:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.19123031198978424 norm:0.00022937673202250153 max memory_allocated 22562.94482421875 
[2025-03-02 08:05:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:06:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.2557150721549988 norm:0.002090086229145527 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:54 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.2414344996213913 norm:0.001122214482165873 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.22786036133766174 norm:0.0005464680143631995 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.22411075234413147 norm:0.00042125905747525394 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.22304725646972656 norm:0.0003493286785669625 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.22261150181293488 norm:0.0003262610116507858 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.22231408953666687 norm:0.0002905700239352882 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.221976175904274 norm:0.0002718225587159395 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.22174370288848877 norm:0.000257921899901703 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.22156035900115967 norm:0.00024680045316927135 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.2213718742132187 norm:0.00023587918258272111 max memory_allocated 22563.11669921875 
[2025-03-02 08:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.221249058842659 norm:0.00022777206322643906 max memory_allocated 22563.11669921875 
[2025-03-02 08:13:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.22113054990768433 norm:0.00022273855574894696 max memory_allocated 22563.11669921875 
[2025-03-02 08:13:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.22101542353630066 norm:0.0002210330858360976 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.22089438140392303 norm:0.0002207919314969331 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.22079098224639893 norm:0.00021631657727994025 max memory_allocated 22563.11669921875 
[2025-03-02 08:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.22075508534908295 norm:0.0002229490492027253 max memory_allocated 22563.11669921875 
[2025-03-02 08:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.2207004278898239 norm:0.00021502957679331303 max memory_allocated 22563.11669921875 
[2025-03-02 08:16:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.2206304371356964 norm:0.00021667469991371036 max memory_allocated 22563.11669921875 
[2025-03-02 08:17:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.22057674825191498 norm:0.00021590809046756476 max memory_allocated 22563.11669921875 
[2025-03-02 08:17:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 08:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.2907264530658722 norm:0.0018227791879326105 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.2756204307079315 norm:0.0009598088217899203 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.2620229423046112 norm:0.0005732722929678857 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.2583243250846863 norm:0.0004363544285297394 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.2572852671146393 norm:0.0003521660983096808 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.25681272149086 norm:0.00031193860922940075 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.2564767003059387 norm:0.00026891299057751894 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.2561931908130646 norm:0.0002549438504502177 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.2559448480606079 norm:0.00022803019965067506 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.25578072667121887 norm:0.0002230862301075831 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.2556113302707672 norm:0.0002135403046850115 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.25543856620788574 norm:0.00021101969468872994 max memory_allocated 22563.28857421875 
[2025-03-02 08:24:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.2552841305732727 norm:0.00020677711290773004 max memory_allocated 22563.28857421875 
[2025-03-02 08:25:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.2551622986793518 norm:0.0002016481594182551 max memory_allocated 22563.28857421875 
[2025-03-02 08:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.2550591230392456 norm:0.0002024047280428931 max memory_allocated 22563.28857421875 
[2025-03-02 08:26:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.25499963760375977 norm:0.00020503824634943157 max memory_allocated 22563.28857421875 
[2025-03-02 08:26:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.25491732358932495 norm:0.00020499498350545764 max memory_allocated 22563.28857421875 
[2025-03-02 08:27:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.2548448443412781 norm:0.00020296371076256037 max memory_allocated 22563.28857421875 
[2025-03-02 08:27:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.2547916769981384 norm:0.0002006963040912524 max memory_allocated 22563.28857421875 
[2025-03-02 08:28:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.25471869111061096 norm:0.00019903072097804397 max memory_allocated 22563.28857421875 
[2025-03-02 08:28:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 08:29:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.33413445949554443 norm:0.005736473947763443 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.31679767370224 norm:0.0028987573459744453 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.3023320138454437 norm:0.001720231375657022 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.298076868057251 norm:0.0011485485592857003 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.29695096611976624 norm:0.000839304004330188 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.2962909936904907 norm:0.0006527708610519767 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.2958153486251831 norm:0.000528730743099004 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.2954466938972473 norm:0.0004473077424336225 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.2951049208641052 norm:0.0003953563573304564 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.294825941324234 norm:0.0003530519315972924 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.29461613297462463 norm:0.000330795330228284 max memory_allocated 22563.46044921875 
[2025-03-02 08:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.29444780945777893 norm:0.0003105033829342574 max memory_allocated 22563.46044921875 
[2025-03-02 08:35:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.2942499816417694 norm:0.0002948827750515193 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.2941228151321411 norm:0.0002820499357767403 max memory_allocated 22563.46044921875 
[2025-03-02 08:37:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.2939852178096771 norm:0.00027400036924518645 max memory_allocated 22563.46044921875 
[2025-03-02 08:37:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.29387229681015015 norm:0.00026806702953763306 max memory_allocated 22563.46044921875 
[2025-03-02 08:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.2937588393688202 norm:0.00026391312712803483 max memory_allocated 22563.46044921875 
[2025-03-02 08:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.29367712140083313 norm:0.00026500626699998975 max memory_allocated 22563.46044921875 
[2025-03-02 08:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.293599396944046 norm:0.0002575626131147146 max memory_allocated 22563.46044921875 
[2025-03-02 08:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.2935437560081482 norm:0.0002544304879847914 max memory_allocated 22563.46044921875 
[2025-03-02 08:40:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 08:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.37253639101982117 norm:0.0030403542332351208 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.3555615246295929 norm:0.0016001356998458505 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.34066423773765564 norm:0.0009846125030890107 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.3365703821182251 norm:0.0006958090234547853 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.3354741334915161 norm:0.0005577567499130964 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.3349595069885254 norm:0.00045599922304973006 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.33457842469215393 norm:0.0003882710007019341 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.33429116010665894 norm:0.00034848664654418826 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.33399248123168945 norm:0.0003170334384776652 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.333805114030838 norm:0.0002992595254909247 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.3335798680782318 norm:0.00028801950975321233 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.3334377110004425 norm:0.00027587381191551685 max memory_allocated 22563.63232421875 
[2025-03-02 08:47:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.3333050608634949 norm:0.000265304435743019 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.33316701650619507 norm:0.00026485417038202286 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.3330687880516052 norm:0.000256496190559119 max memory_allocated 22563.63232421875 
[2025-03-02 08:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.33295971155166626 norm:0.0002624399203341454 max memory_allocated 22563.63232421875 
[2025-03-02 08:49:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.33292707800865173 norm:0.00026185691240243614 max memory_allocated 22563.63232421875 
[2025-03-02 08:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.33281299471855164 norm:0.0002583058085292578 max memory_allocated 22563.63232421875 
[2025-03-02 08:50:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.33273980021476746 norm:0.00026033163885585964 max memory_allocated 22563.63232421875 
[2025-03-02 08:51:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.3326761722564697 norm:0.00024994666455313563 max memory_allocated 22563.63232421875 
[2025-03-02 08:51:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 08:51:35 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 08:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.4336005449295044 norm:0.012673135846853256 max memory_allocated 22563.91943359375 
[2025-03-02 08:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.41433072090148926 norm:0.010809920728206635 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.39786139130592346 norm:0.007948040030896664 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.3935104012489319 norm:0.007140906527638435 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.3922971785068512 norm:0.006173347122967243 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:58 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.39143106341362 norm:0.005303025245666504 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.3908531665802002 norm:0.004786892794072628 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.39051035046577454 norm:0.004599639680236578 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.3901384174823761 norm:0.004341908264905214 max memory_allocated 22563.91943359375 
[2025-03-02 08:57:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.38984015583992004 norm:0.004090048838406801 max memory_allocated 22563.91943359375 
[2025-03-02 08:57:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.3897923231124878 norm:0.004159773699939251 max memory_allocated 22563.91943359375 
[2025-03-02 08:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.3895021080970764 norm:0.004008080810308456 max memory_allocated 22563.91943359375 
[2025-03-02 08:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.38933172821998596 norm:0.0038838256150484085 max memory_allocated 22563.91943359375 
[2025-03-02 08:59:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.3892083764076233 norm:0.0037954235449433327 max memory_allocated 22563.91943359375 
[2025-03-02 09:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.3890601694583893 norm:0.0037516809534281492 max memory_allocated 22563.91943359375 
[2025-03-02 09:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.38898009061813354 norm:0.0036484254524111748 max memory_allocated 22563.91943359375 
[2025-03-02 09:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.38889193534851074 norm:0.003647130448371172 max memory_allocated 22563.91943359375 
[2025-03-02 09:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.3888401389122009 norm:0.0036175409331917763 max memory_allocated 22563.91943359375 
[2025-03-02 09:02:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.3886706531047821 norm:0.0034392850939184427 max memory_allocated 22563.91943359375 
[2025-03-02 09:02:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.38864487409591675 norm:0.003476520301774144 max memory_allocated 22563.91943359375 
[2025-03-02 09:03:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 09:03:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:03:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.5017560124397278 norm:0.014912737533450127 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.47985756397247314 norm:0.01074958872050047 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.46152597665786743 norm:0.007951038889586926 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.4571398198604584 norm:0.006714566145092249 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:53 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.45577818155288696 norm:0.005677824839949608 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.4549555778503418 norm:0.00476894062012434 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.4543837606906891 norm:0.004304405767470598 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.45417144894599915 norm:0.004317911807447672 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.4537762999534607 norm:0.00431929063051939 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.4534434974193573 norm:0.0039615631103515625 max memory_allocated 22564.09130859375 
[2025-03-02 09:09:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.45318901538848877 norm:0.0037824916653335094 max memory_allocated 22564.09130859375 
[2025-03-02 09:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.4529222846031189 norm:0.0035226137842983007 max memory_allocated 22564.09130859375 
[2025-03-02 09:10:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.45283934473991394 norm:0.0036415120121091604 max memory_allocated 22564.09130859375 
[2025-03-02 09:10:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.4526587724685669 norm:0.0034618712961673737 max memory_allocated 22564.09130859375 
[2025-03-02 09:11:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.4524989724159241 norm:0.003423489397391677 max memory_allocated 22564.09130859375 
[2025-03-02 09:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.4522773027420044 norm:0.0032009535934776068 max memory_allocated 22564.09130859375 
[2025-03-02 09:12:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.4522079825401306 norm:0.003282802179455757 max memory_allocated 22564.09130859375 
[2025-03-02 09:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.4521580636501312 norm:0.0031734774820506573 max memory_allocated 22564.09130859375 
[2025-03-02 09:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.4520277678966522 norm:0.003198895836248994 max memory_allocated 22564.09130859375 
[2025-03-02 09:14:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.45199456810951233 norm:0.0030510511714965105 max memory_allocated 22564.09130859375 
[2025-03-02 09:14:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:14:32 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.6929894089698792 norm:0.033111754804849625 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.6371012926101685 norm:0.022348739206790924 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.5985755324363708 norm:0.015374260023236275 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.5894140005111694 norm:0.01707954704761505 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.5852985382080078 norm:0.018949752673506737 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.5825479030609131 norm:0.019211921840906143 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.580721378326416 norm:0.017801016569137573 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.5798765420913696 norm:0.016864918172359467 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.5795581936836243 norm:0.016805678606033325 max memory_allocated 22564.26318359375 
[2025-03-02 09:20:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.5791844129562378 norm:0.016662446781992912 max memory_allocated 22564.26318359375 
[2025-03-02 09:20:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.5786811113357544 norm:0.017002709209918976 max memory_allocated 22564.26318359375 
[2025-03-02 09:21:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.5789529085159302 norm:0.017780954018235207 max memory_allocated 22564.26318359375 
[2025-03-02 09:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.5783571004867554 norm:0.018092459067702293 max memory_allocated 22564.26318359375 
[2025-03-02 09:22:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.5775193572044373 norm:0.017212308943271637 max memory_allocated 22564.26318359375 
[2025-03-02 09:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.5774388909339905 norm:0.017180267721414566 max memory_allocated 22564.26318359375 
[2025-03-02 09:23:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.5769270658493042 norm:0.016683757305145264 max memory_allocated 22564.26318359375 
[2025-03-02 09:24:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.577534556388855 norm:0.017196208238601685 max memory_allocated 22564.26318359375 
[2025-03-02 09:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.577382504940033 norm:0.018138065934181213 max memory_allocated 22564.26318359375 
[2025-03-02 09:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.5764325261116028 norm:0.017845697700977325 max memory_allocated 22564.26318359375 
[2025-03-02 09:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.5768069624900818 norm:0.017691059038043022 max memory_allocated 22564.26318359375 
[2025-03-02 09:25:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 09:26:01 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:1.2219382524490356 norm:0.08962250500917435 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:1.120711326599121 norm:0.05742710456252098 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:1.0634520053863525 norm:0.0448584258556366 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:1.0339293479919434 norm:0.03909702226519585 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:1.014926552772522 norm:0.03631165996193886 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:1.0040125846862793 norm:0.03500719368457794 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.9956813454627991 norm:0.03606093302369118 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.9894649386405945 norm:0.034890513867139816 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.9856556057929993 norm:0.037507638335227966 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.9816620349884033 norm:0.03454631567001343 max memory_allocated 22564.43505859375 
[2025-03-02 09:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.9792148470878601 norm:0.03535695746541023 max memory_allocated 22564.43505859375 
[2025-03-02 09:32:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.976867139339447 norm:0.035893239080905914 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.9765959978103638 norm:0.03959183022379875 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.9746647477149963 norm:0.03588460758328438 max memory_allocated 22564.43505859375 
[2025-03-02 09:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.973348081111908 norm:0.037648674100637436 max memory_allocated 22564.43505859375 
[2025-03-02 09:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.9703186750411987 norm:0.032608360052108765 max memory_allocated 22564.43505859375 
[2025-03-02 09:35:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.9693855047225952 norm:0.03302514925599098 max memory_allocated 22564.43505859375 
[2025-03-02 09:36:09 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.9681392908096313 norm:0.032289162278175354 max memory_allocated 22564.43505859375 
[2025-03-02 09:36:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.9686940312385559 norm:0.03540728986263275 max memory_allocated 22564.43505859375 
[2025-03-02 09:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.9677544832229614 norm:0.03291101008653641 max memory_allocated 22564.43505859375 
[2025-03-02 09:37:27 root] (main_calib_config2.py 380): INFO 22003.687718153
[2025-03-02 09:37:32 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 09:38:44 root] (main_calib_config2.py 159): INFO wikitext2 : 5.9124908447265625
[2025-03-02 09:38:44 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 09:40:34 root] (main_calib_config2.py 159): INFO c4 : 7.422329902648926
[2025-03-02 11:23:20 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.9124908447265625, 'c4': 7.422329902648926, 'results': {'boolq': {'acc': 0.7201834862385321, 'acc_stderr': 0.007851466641001337}, 'arc_challenge': {'acc': 0.3728668941979522, 'acc_stderr': 0.014131176760131163, 'acc_norm': 0.3873720136518771, 'acc_norm_stderr': 0.014235872487909872}, 'piqa': {'acc': 0.778563656147987, 'acc_stderr': 0.00968761645684027, 'acc_norm': 0.7736670293797606, 'acc_norm_stderr': 0.00976329424687942}, 'arc_easy': {'acc': 0.6595117845117845, 'acc_stderr': 0.009723676813825868, 'acc_norm': 0.5223063973063973, 'acc_norm_stderr': 0.010249568404555653}, 'winogrande': {'acc': 0.6393054459352802, 'acc_stderr': 0.013496064394234009}, 'hellaswag': {'acc': 0.5502887870942044, 'acc_stderr': 0.004964479324552531, 'acc_norm': 0.7132045409281019, 'acc_norm_stderr': 0.004513409114983842}}, 'versions': {'boolq': 1, 'arc_challenge': 0, 'piqa': 0, 'arc_easy': 0, 'winogrande': 0, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
