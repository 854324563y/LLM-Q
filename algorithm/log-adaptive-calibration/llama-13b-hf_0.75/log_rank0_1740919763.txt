[2025-03-02 12:49:23 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.75', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.75.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.75.pkl
[2025-03-02 12:52:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.007206388749182224 norm:0.00952675100415945 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0037940465845167637 norm:0.003951892256736755 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0031129021663218737 norm:0.003109193639829755 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0027610519900918007 norm:0.0027041740249842405 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0025531412102282047 norm:0.0022903860080987215 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0024443005677312613 norm:0.0019691968336701393 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.002314987825229764 norm:0.0016999649815261364 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.002263743430376053 norm:0.0015674738679081202 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.002163158031180501 norm:0.0014034751802682877 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.002163731725886464 norm:0.0013288147747516632 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0020954017527401447 norm:0.0012097982689738274 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.002086241729557514 norm:0.001162022235803306 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.002058804966509342 norm:0.0010591794271022081 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0020534279756247997 norm:0.001050432212650776 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0020320359617471695 norm:0.0009446909534744918 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.001981245819479227 norm:0.0008537778630852699 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0020174956880509853 norm:0.0008649852825328708 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.002005240647122264 norm:0.0008515699300915003 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.002040640916675329 norm:0.0008695450378581882 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0019864363130182028 norm:0.0007771439268253744 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:28 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.016790544614195824 norm:0.01438076514750719 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.009208681993186474 norm:0.008291198872029781 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.007149835117161274 norm:0.005383031442761421 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.0063903434202075005 norm:0.00454286765307188 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.006100645288825035 norm:0.004093875177204609 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.005913115106523037 norm:0.003675102721899748 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.005757802631705999 norm:0.0034616971388459206 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.005595679860562086 norm:0.0031247904989868402 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.005453727673739195 norm:0.0029119914397597313 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.005341320298612118 norm:0.0026907080318778753 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.005217421799898148 norm:0.00245701614767313 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.0051380665972828865 norm:0.002308377530425787 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.0050689117051661015 norm:0.0021383329294621944 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.004989395383745432 norm:0.00191393680870533 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.004936574026942253 norm:0.0017595796380192041 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.0048935022205114365 norm:0.0015736425993964076 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.004860944580286741 norm:0.0014195770490914583 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.00484091741964221 norm:0.0012975342106074095 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004829127341508865 norm:0.0012243790552020073 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.004811338614672422 norm:0.0012815388618037105 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:18 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.027980417013168335 norm:0.01139005459845066 max memory_allocated 29268.39501953125 
[2025-03-02 13:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.019419686868786812 norm:0.007476605474948883 max memory_allocated 29268.39501953125 
[2025-03-02 13:28:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.016876932233572006 norm:0.006849074736237526 max memory_allocated 29268.39501953125 
[2025-03-02 13:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.015290886163711548 norm:0.006054271943867207 max memory_allocated 29268.39501953125 
[2025-03-02 13:30:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.014347604475915432 norm:0.005875838920474052 max memory_allocated 29268.39501953125 
[2025-03-02 13:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.013505439274013042 norm:0.005149376578629017 max memory_allocated 29268.39501953125 
[2025-03-02 13:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.012561975978314877 norm:0.004006667993962765 max memory_allocated 29268.39501953125 
[2025-03-02 13:32:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.0121438167989254 norm:0.003789217211306095 max memory_allocated 29268.39501953125 
[2025-03-02 13:33:45 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.011780154891312122 norm:0.0035921167582273483 max memory_allocated 29268.39501953125 
[2025-03-02 13:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.01158724632114172 norm:0.0033475763630121946 max memory_allocated 29268.39501953125 
[2025-03-02 13:35:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.011661131866276264 norm:0.003739428473636508 max memory_allocated 29268.39501953125 
[2025-03-02 13:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.011458300985395908 norm:0.003300595795735717 max memory_allocated 29268.39501953125 
[2025-03-02 13:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.011305910535156727 norm:0.00269431178458035 max memory_allocated 29268.39501953125 
[2025-03-02 13:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.011287568137049675 norm:0.002944136504083872 max memory_allocated 29268.39501953125 
[2025-03-02 13:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.011125730350613594 norm:0.0027853345964103937 max memory_allocated 29268.39501953125 
[2025-03-02 13:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.011128791607916355 norm:0.0027162942569702864 max memory_allocated 29268.39501953125 
[2025-03-02 13:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.01115792989730835 norm:0.002849014475941658 max memory_allocated 29268.39501953125 
[2025-03-02 13:41:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.011054877191781998 norm:0.002777746645733714 max memory_allocated 29268.39501953125 
[2025-03-02 13:42:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.010953735560178757 norm:0.0025476242881268263 max memory_allocated 29268.39501953125 
[2025-03-02 13:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.010894568637013435 norm:0.0023009045980870724 max memory_allocated 29268.39501953125 
[2025-03-02 13:43:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:43:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.02059098705649376 norm:0.0016145455883815885 max memory_allocated 29268.43798828125 
[2025-03-02 13:44:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.01644546166062355 norm:0.0006647617556154728 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:37 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.014980306848883629 norm:0.0003394261875655502 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.014174140989780426 norm:0.000243156508076936 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.013687320984899998 norm:0.00014521008415613323 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.013291386887431145 norm:0.00012957716535311192 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.013046790845692158 norm:0.0001424117072019726 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.012893685139715672 norm:0.00012892702943645418 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.012848109006881714 norm:0.00014285063662100583 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.01280337292701006 norm:0.00012157546734670177 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.01281802635639906 norm:0.0001542173995403573 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.012810511514544487 norm:0.00012712868920061737 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.012761653400957584 norm:0.00010811544780153781 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.012744623236358166 norm:0.00011039125820389017 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.012768634594976902 norm:0.00012328290904406458 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.01273844949901104 norm:0.00012170287664048374 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.012722901999950409 norm:0.00012789668107870966 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:59 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.012715445831418037 norm:0.00014301906048785895 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.012715373188257217 norm:0.00012375014193821698 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.012703176587820053 norm:0.00013278490223456174 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:00:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.02808704599738121 norm:0.0032734840642660856 max memory_allocated 29268.43798828125 
[2025-03-02 14:01:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.02186242677271366 norm:0.0009498565923422575 max memory_allocated 29268.43798828125 
[2025-03-02 14:02:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.019653428345918655 norm:0.0005833827890455723 max memory_allocated 29268.43798828125 
[2025-03-02 14:03:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.01849704422056675 norm:0.000453696382464841 max memory_allocated 29268.43798828125 
[2025-03-02 14:04:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.017763974145054817 norm:0.000338544137775898 max memory_allocated 29268.43798828125 
[2025-03-02 14:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.017267853021621704 norm:0.00028225232381373644 max memory_allocated 29268.43798828125 
[2025-03-02 14:05:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.017040487378835678 norm:0.0002373507886659354 max memory_allocated 29268.43798828125 
[2025-03-02 14:06:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.016941023990511894 norm:0.00021922617452219129 max memory_allocated 29268.43798828125 
[2025-03-02 14:07:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.016889333724975586 norm:0.00019362667808309197 max memory_allocated 29268.43798828125 
[2025-03-02 14:08:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.01685425080358982 norm:0.0001778464502422139 max memory_allocated 29268.43798828125 
[2025-03-02 14:09:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.01684367097914219 norm:0.0001472898293286562 max memory_allocated 29268.43798828125 
[2025-03-02 14:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.01678127981722355 norm:0.00013648608000949025 max memory_allocated 29268.43798828125 
[2025-03-02 14:10:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.01681693084537983 norm:0.0002116973337251693 max memory_allocated 29268.43798828125 
[2025-03-02 14:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.016727421432733536 norm:0.0001410125696565956 max memory_allocated 29268.43798828125 
[2025-03-02 14:12:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.01671459525823593 norm:0.00012734814663417637 max memory_allocated 29268.43798828125 
[2025-03-02 14:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.016689026728272438 norm:0.00011744260700652376 max memory_allocated 29268.43798828125 
[2025-03-02 14:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.01668516732752323 norm:0.00011946571612497792 max memory_allocated 29268.43798828125 
[2025-03-02 14:14:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.016679568216204643 norm:0.00012757138756569475 max memory_allocated 29268.43798828125 
[2025-03-02 14:15:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.016744162887334824 norm:0.00014887977158650756 max memory_allocated 29268.43798828125 
[2025-03-02 14:16:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.016730187460780144 norm:0.00013328433851711452 max memory_allocated 29268.43798828125 
[2025-03-02 14:16:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.03525182604789734 norm:0.0033994291443377733 max memory_allocated 29268.43798828125 
[2025-03-02 14:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.026132073253393173 norm:0.0010688849724829197 max memory_allocated 29268.43798828125 
[2025-03-02 14:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.023342613130807877 norm:0.0006010598735883832 max memory_allocated 29268.43798828125 
[2025-03-02 14:20:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.021915137767791748 norm:0.0003994263825006783 max memory_allocated 29268.43798828125 
[2025-03-02 14:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.021028202027082443 norm:0.0003097960143350065 max memory_allocated 29268.43798828125 
[2025-03-02 14:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.02049240656197071 norm:0.00026386507670395076 max memory_allocated 29268.43798828125 
[2025-03-02 14:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.02023981511592865 norm:0.00024461111752316356 max memory_allocated 29268.43798828125 
[2025-03-02 14:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.020105455070734024 norm:0.00020325594232417643 max memory_allocated 29268.43798828125 
[2025-03-02 14:24:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.020021148025989532 norm:0.00019994573085568845 max memory_allocated 29268.43798828125 
[2025-03-02 14:24:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.01995950937271118 norm:0.0001784894848242402 max memory_allocated 29268.43798828125 
[2025-03-02 14:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.019914554432034492 norm:0.00017545235459692776 max memory_allocated 29268.43798828125 
[2025-03-02 14:26:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.019902193918824196 norm:0.0002000193198909983 max memory_allocated 29268.43798828125 
[2025-03-02 14:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.019852029159665108 norm:0.00016475564916618168 max memory_allocated 29268.43798828125 
[2025-03-02 14:28:17 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.01983567886054516 norm:0.00015525688650086522 max memory_allocated 29268.43798828125 
[2025-03-02 14:29:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.019786009564995766 norm:0.0001566902210470289 max memory_allocated 29268.43798828125 
[2025-03-02 14:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.01978648640215397 norm:0.00015818377141840756 max memory_allocated 29268.43798828125 
[2025-03-02 14:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.019772643223404884 norm:0.0001642515999265015 max memory_allocated 29268.43798828125 
[2025-03-02 14:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.01973254606127739 norm:0.0001545492559671402 max memory_allocated 29268.43798828125 
[2025-03-02 14:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.019741741940379143 norm:0.00015174235159065574 max memory_allocated 29268.43798828125 
[2025-03-02 14:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.0197155699133873 norm:0.000145423982758075 max memory_allocated 29268.43798828125 
[2025-03-02 14:33:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:34:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.040717337280511856 norm:0.0021268429700285196 max memory_allocated 29268.43798828125 
[2025-03-02 14:35:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.03312418982386589 norm:0.0012540745083242655 max memory_allocated 29268.43798828125 
[2025-03-02 14:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.029731279239058495 norm:0.0008562793955206871 max memory_allocated 29268.43798828125 
[2025-03-02 14:36:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.027472781017422676 norm:0.000707854051142931 max memory_allocated 29268.43798828125 
[2025-03-02 14:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.02618943341076374 norm:0.0006246660486795008 max memory_allocated 29268.43798828125 
[2025-03-02 14:38:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.025480452924966812 norm:0.0005413647159002721 max memory_allocated 29268.43798828125 
[2025-03-02 14:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.025051238015294075 norm:0.0004623371351044625 max memory_allocated 29268.43798828125 
[2025-03-02 14:40:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.024828683584928513 norm:0.0004289515782147646 max memory_allocated 29268.43798828125 
[2025-03-02 14:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.024693990126252174 norm:0.0003959560126531869 max memory_allocated 29268.43798828125 
[2025-03-02 14:41:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.02473430708050728 norm:0.00047452657599933445 max memory_allocated 29268.43798828125 
[2025-03-02 14:42:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.024583034217357635 norm:0.0004051628930028528 max memory_allocated 29268.43798828125 
[2025-03-02 14:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.024545416235923767 norm:0.0003886499034706503 max memory_allocated 29268.43798828125 
[2025-03-02 14:44:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.024494709447026253 norm:0.0003837125259451568 max memory_allocated 29268.43798828125 
[2025-03-02 14:45:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.024456288665533066 norm:0.00036785894189961255 max memory_allocated 29268.43798828125 
[2025-03-02 14:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.02440047264099121 norm:0.00036601556348614395 max memory_allocated 29268.43798828125 
[2025-03-02 14:46:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.02439669333398342 norm:0.0003627105033956468 max memory_allocated 29268.43798828125 
[2025-03-02 14:47:33 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.0243674386292696 norm:0.0003500167513266206 max memory_allocated 29268.43798828125 
[2025-03-02 14:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.02436051145195961 norm:0.00035328156081959605 max memory_allocated 29268.43798828125 
[2025-03-02 14:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.024356933310627937 norm:0.00036969452048651874 max memory_allocated 29268.43798828125 
[2025-03-02 14:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.02435927465558052 norm:0.00035087051219306886 max memory_allocated 29268.43798828125 
[2025-03-02 14:50:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:51:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.03824456036090851 norm:0.0013695370871573687 max memory_allocated 29269.18798828125 
[2025-03-02 14:51:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.03244250640273094 norm:0.0006336353253573179 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.0300751905888319 norm:0.0003384039446245879 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.028725311160087585 norm:0.00022262003039941192 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.027964452281594276 norm:0.00017881588428281248 max memory_allocated 29269.18798828125 
[2025-03-02 14:55:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.027524953708052635 norm:0.0001606241858098656 max memory_allocated 29269.18798828125 
[2025-03-02 14:56:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.027292290702462196 norm:0.000154160923557356 max memory_allocated 29269.18798828125 
[2025-03-02 14:56:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.027178505435585976 norm:0.00014296626613941044 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.02712075598537922 norm:0.00014178593119140714 max memory_allocated 29269.18798828125 
[2025-03-02 14:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.02708328887820244 norm:0.0001427493552910164 max memory_allocated 29269.18798828125 
[2025-03-02 14:59:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.027058830484747887 norm:0.000165337638463825 max memory_allocated 29269.18798828125 
[2025-03-02 15:00:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.027012381702661514 norm:0.0001441447384422645 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.026973240077495575 norm:0.00014584990276489407 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.026949787512421608 norm:0.00014331402780953795 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.026943877339363098 norm:0.00014059318345971406 max memory_allocated 29269.18798828125 
[2025-03-02 15:03:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.026951279491186142 norm:0.00014459851081483066 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.0269677322357893 norm:0.0001511521404609084 max memory_allocated 29269.18798828125 
[2025-03-02 15:05:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.026956036686897278 norm:0.00014791794819757342 max memory_allocated 29269.18798828125 
[2025-03-02 15:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.026949061080813408 norm:0.00014503028069157153 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.026944614946842194 norm:0.00014276467845775187 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:07:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.042779289186000824 norm:0.001491889706812799 max memory_allocated 29269.18798828125 
[2025-03-02 15:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.03646751865744591 norm:0.0005836760392412543 max memory_allocated 29269.18798828125 
[2025-03-02 15:09:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.03266614302992821 norm:0.00027525259065441787 max memory_allocated 29269.18798828125 
[2025-03-02 15:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.03168316185474396 norm:0.00016812479589134455 max memory_allocated 29269.18798828125 
[2025-03-02 15:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.03108225017786026 norm:0.00013147217396181077 max memory_allocated 29269.18798828125 
[2025-03-02 15:12:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.030732449144124985 norm:0.00011542094580363482 max memory_allocated 29269.18798828125 
[2025-03-02 15:12:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.030539263039827347 norm:0.00010598744120215997 max memory_allocated 29269.18798828125 
[2025-03-02 15:13:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.03043624386191368 norm:0.00010049100092146546 max memory_allocated 29269.18798828125 
[2025-03-02 15:14:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.03038994036614895 norm:9.723543917061761e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:15:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.030353721231222153 norm:9.556155418977141e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.030328230932354927 norm:9.363525168737397e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:17:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.030310053378343582 norm:9.342132398160174e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.030292758718132973 norm:9.27781147765927e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.03027658723294735 norm:9.206255344906822e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.030260849744081497 norm:9.122722258325666e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.030250046402215958 norm:9.219676576321945e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.030234673991799355 norm:9.108207450481132e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:21:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.030226076021790504 norm:9.086959471460432e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:22:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.030217526480555534 norm:9.162818605545908e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:23:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.030213192105293274 norm:9.082247561309487e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:23:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.04350462555885315 norm:0.0012385908048599958 max memory_allocated 29269.18798828125 
[2025-03-02 15:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.03828338533639908 norm:0.0005380546790547669 max memory_allocated 29269.18798828125 
[2025-03-02 15:26:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.036004070192575455 norm:0.00028919728356413543 max memory_allocated 29269.18798828125 
[2025-03-02 15:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.03472769632935524 norm:0.00019996764604002237 max memory_allocated 29269.18798828125 
[2025-03-02 15:28:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.034030329436063766 norm:0.00016503440565429628 max memory_allocated 29269.18798828125 
[2025-03-02 15:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.03359093517065048 norm:0.000146175516420044 max memory_allocated 29269.18798828125 
[2025-03-02 15:29:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.03334984555840492 norm:0.00013848116213921458 max memory_allocated 29269.18798828125 
[2025-03-02 15:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.03323594108223915 norm:0.00013542993110604584 max memory_allocated 29269.18798828125 
[2025-03-02 15:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.03317596763372421 norm:0.00012978668382856995 max memory_allocated 29269.18798828125 
[2025-03-02 15:32:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.0331350639462471 norm:0.00012878901907242835 max memory_allocated 29269.18798828125 
[2025-03-02 15:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.03311418369412422 norm:0.00012882481678389013 max memory_allocated 29269.18798828125 
[2025-03-02 15:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.033088840544223785 norm:0.00012849070481024683 max memory_allocated 29269.18798828125 
[2025-03-02 15:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.03305353224277496 norm:0.00013042330101598054 max memory_allocated 29269.18798828125 
[2025-03-02 15:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.03304111957550049 norm:0.00012843162403441966 max memory_allocated 29269.18798828125 
[2025-03-02 15:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.03301769867539406 norm:0.00013070240675006062 max memory_allocated 29269.18798828125 
[2025-03-02 15:37:06 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.03300900757312775 norm:0.00012944678019266576 max memory_allocated 29269.18798828125 
[2025-03-02 15:37:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.03301246464252472 norm:0.00013099063653498888 max memory_allocated 29269.18798828125 
[2025-03-02 15:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.03300316259264946 norm:0.00013277135440148413 max memory_allocated 29269.18798828125 
[2025-03-02 15:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.03300570696592331 norm:0.00012737425277009606 max memory_allocated 29269.18798828125 
[2025-03-02 15:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.03300769254565239 norm:0.00013376650167629123 max memory_allocated 29269.18798828125 
[2025-03-02 15:40:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.04702349752187729 norm:0.0010638287058100104 max memory_allocated 29269.18798828125 
[2025-03-02 15:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.04143984615802765 norm:0.0004037483886349946 max memory_allocated 29269.18798828125 
[2025-03-02 15:43:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.037920400500297546 norm:0.00019670845358632505 max memory_allocated 29269.18798828125 
[2025-03-02 15:44:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.03699951991438866 norm:0.00012786436127498746 max memory_allocated 29269.18798828125 
[2025-03-02 15:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.03644729405641556 norm:0.00010248689068248495 max memory_allocated 29269.18798828125 
[2025-03-02 15:45:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.036089230328798294 norm:9.08525544218719e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.035896312445402145 norm:8.459090895485133e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:47:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.03581548109650612 norm:8.174680988304317e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:48:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.035768598318099976 norm:7.929271669127047e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:48:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.035736534744501114 norm:7.83636060077697e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:49:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.035706777125597 norm:7.838261080905795e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:50:36 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.03568940982222557 norm:7.663165160920471e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.03566621616482735 norm:7.659340190002695e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:52:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.03565290942788124 norm:7.606738654430956e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:53:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.03564588353037834 norm:7.602805271744728e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:53:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.03563835099339485 norm:7.596863724756986e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:54:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.03563082218170166 norm:7.586695573991165e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.03562425822019577 norm:7.631517655681819e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.035618655383586884 norm:7.544543768744916e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:57:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.03561446815729141 norm:7.528431160608307e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:57:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:58:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.0509614497423172 norm:0.001116679748520255 max memory_allocated 29269.18798828125 
[2025-03-02 15:59:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.044978685677051544 norm:0.00045886056614108384 max memory_allocated 29269.18798828125 
[2025-03-02 15:59:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.04105372726917267 norm:0.0002219954621978104 max memory_allocated 29269.18798828125 
[2025-03-02 16:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.04007905721664429 norm:0.00013494750601239502 max memory_allocated 29269.18798828125 
[2025-03-02 16:01:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.03951200097799301 norm:0.00010338846186641604 max memory_allocated 29269.18798828125 
[2025-03-02 16:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.03915846720337868 norm:9.043692261911929e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:03:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.03897444158792496 norm:8.455757051706314e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:04:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.038883715867996216 norm:8.061197149800137e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.03883485496044159 norm:7.836587610654533e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:05:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.038798145949840546 norm:7.738475687801838e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.03877423703670502 norm:7.669707702007145e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:07:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.03875486180186272 norm:7.606201688759029e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:08:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.03873680159449577 norm:7.648454629816115e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:09:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.03872397541999817 norm:7.591636676806957e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:09:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.038712434470653534 norm:7.578484655823559e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:10:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.0387042760848999 norm:7.550998270744458e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:11:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.038696110248565674 norm:7.541500963270664e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.038685042411088943 norm:7.529185677412897e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.03867572173476219 norm:7.521938096033409e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:14:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.03867147117853165 norm:7.543860556324944e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:14:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:15:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.053022708743810654 norm:0.000914132222533226 max memory_allocated 29269.18798828125 
[2025-03-02 16:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.047467149794101715 norm:0.00038690638029947877 max memory_allocated 29269.18798828125 
[2025-03-02 16:16:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.04347767308354378 norm:0.0002110148052452132 max memory_allocated 29269.18798828125 
[2025-03-02 16:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.04252566024661064 norm:0.00014698422455694526 max memory_allocated 29269.18798828125 
[2025-03-02 16:18:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.04194233566522598 norm:0.00011695973807945848 max memory_allocated 29269.18798828125 
[2025-03-02 16:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.04157251864671707 norm:0.00010116737394127995 max memory_allocated 29269.18798828125 
[2025-03-02 16:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.041377514600753784 norm:9.210473217535764e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:20:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.041277237236499786 norm:8.844874537317082e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:21:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.04121389240026474 norm:8.675221033627167e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:22:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.041166409850120544 norm:8.493931090924889e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:23:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.04113347455859184 norm:8.357193291885778e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.041101038455963135 norm:8.234412234742194e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:25:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.04107782617211342 norm:8.188001811504364e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:25:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.0410589873790741 norm:8.070456533459947e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:26:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.04104486107826233 norm:8.100042032310739e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:27:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.041026536375284195 norm:8.017897926038131e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:28:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.04101530835032463 norm:7.99691624706611e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.04100673273205757 norm:7.937689952086657e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:30:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.04099513590335846 norm:7.892529538366944e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:30:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.04098864272236824 norm:7.873289723647758e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:31:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.051485635340213776 norm:0.0006928525981493294 max memory_allocated 29269.18798828125 
[2025-03-02 16:32:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.048272501677274704 norm:0.0003558595781214535 max memory_allocated 29269.18798828125 
[2025-03-02 16:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.04632792994379997 norm:0.0002272968558827415 max memory_allocated 29269.18798828125 
[2025-03-02 16:34:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.04500274360179901 norm:0.00017114491492975503 max memory_allocated 29269.18798828125 
[2025-03-02 16:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.04414069280028343 norm:0.00014293794811237603 max memory_allocated 29269.18798828125 
[2025-03-02 16:36:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.043648265302181244 norm:0.00012411581701599061 max memory_allocated 29269.18798828125 
[2025-03-02 16:36:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.04340655356645584 norm:0.00011601228470681235 max memory_allocated 29269.18798828125 
[2025-03-02 16:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.04328487813472748 norm:0.00011197906860616058 max memory_allocated 29269.18798828125 
[2025-03-02 16:38:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.04321371018886566 norm:0.00010890189878409728 max memory_allocated 29269.18798828125 
[2025-03-02 16:39:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.04315163940191269 norm:0.00010558035864960402 max memory_allocated 29269.18798828125 
[2025-03-02 16:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.04312191903591156 norm:0.00010386882058810443 max memory_allocated 29269.18798828125 
[2025-03-02 16:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.0430973656475544 norm:0.00010522383672650903 max memory_allocated 29269.18798828125 
[2025-03-02 16:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.043084774166345596 norm:0.000100538476544898 max memory_allocated 29269.18798828125 
[2025-03-02 16:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.04307365044951439 norm:9.651415894040838e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:43:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.043075479567050934 norm:9.704153490019962e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.043065670877695084 norm:9.761971887201071e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:45:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.04305052384734154 norm:9.750473691383377e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.043065331876277924 norm:9.764981223270297e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.04305334389209747 norm:9.765107824932784e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.04304703325033188 norm:9.747976582730189e-05 max memory_allocated 29269.18798828125 
[2025-03-02 16:47:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.05572475120425224 norm:0.0010331316152587533 max memory_allocated 29269.50048828125 
[2025-03-02 16:49:36 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.05154835060238838 norm:0.0005113823572173715 max memory_allocated 29269.50048828125 
[2025-03-02 16:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.049191996455192566 norm:0.0003130933619104326 max memory_allocated 29269.50048828125 
[2025-03-02 16:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.04781261831521988 norm:0.00022584271209780127 max memory_allocated 29269.50048828125 
[2025-03-02 16:52:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.04701479151844978 norm:0.00017687567742541432 max memory_allocated 29269.50048828125 
[2025-03-02 16:52:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.04651438072323799 norm:0.00014936891966499388 max memory_allocated 29269.50048828125 
[2025-03-02 16:53:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.04627861827611923 norm:0.000137805356644094 max memory_allocated 29269.50048828125 
[2025-03-02 16:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.04614513739943504 norm:0.00012761344260070473 max memory_allocated 29269.50048828125 
[2025-03-02 16:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.04604301601648331 norm:0.00012116086145397276 max memory_allocated 29269.50048828125 
[2025-03-02 16:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.04598531126976013 norm:0.000119818389066495 max memory_allocated 29269.50048828125 
[2025-03-02 16:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.04598382115364075 norm:0.0001154724886873737 max memory_allocated 29269.50048828125 
[2025-03-02 16:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.0459640771150589 norm:0.00011464639101177454 max memory_allocated 29269.50048828125 
[2025-03-02 16:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.04592620208859444 norm:0.00011088460450991988 max memory_allocated 29269.50048828125 
[2025-03-02 16:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.04591015353798866 norm:0.00011283842468401417 max memory_allocated 29269.50048828125 
[2025-03-02 17:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.04589550197124481 norm:0.00011413720494601876 max memory_allocated 29269.50048828125 
[2025-03-02 17:01:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.04587823897600174 norm:0.00011483547859825194 max memory_allocated 29269.50048828125 
[2025-03-02 17:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.04587087780237198 norm:0.00011452285980340093 max memory_allocated 29269.50048828125 
[2025-03-02 17:02:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.045862529426813126 norm:0.00011729836842278019 max memory_allocated 29269.50048828125 
[2025-03-02 17:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.04586398974061012 norm:0.00011646483471849933 max memory_allocated 29269.50048828125 
[2025-03-02 17:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.04586959257721901 norm:0.00011956263188039884 max memory_allocated 29269.50048828125 
[2025-03-02 17:04:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.057982031255960464 norm:0.0009269423317164183 max memory_allocated 29269.50048828125 
[2025-03-02 17:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.05425715446472168 norm:0.0003698195796459913 max memory_allocated 29269.50048828125 
[2025-03-02 17:07:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.05254005640745163 norm:0.00025078788166865706 max memory_allocated 29269.50048828125 
[2025-03-02 17:08:03 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.051177747547626495 norm:0.00019329859060235322 max memory_allocated 29269.50048828125 
[2025-03-02 17:08:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.05024167522788048 norm:0.00015881494618952274 max memory_allocated 29269.50048828125 
[2025-03-02 17:09:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.049669940024614334 norm:0.0001407807576470077 max memory_allocated 29269.50048828125 
[2025-03-02 17:10:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.04942041262984276 norm:0.0001290344080189243 max memory_allocated 29269.50048828125 
[2025-03-02 17:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.04927912726998329 norm:0.00011794242891483009 max memory_allocated 29269.50048828125 
[2025-03-02 17:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.04919739440083504 norm:0.0001101805828511715 max memory_allocated 29269.50048828125 
[2025-03-02 17:13:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.049156948924064636 norm:0.00010370169911766425 max memory_allocated 29269.50048828125 
[2025-03-02 17:13:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.04912704601883888 norm:9.881777077680454e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:14:39 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.04909633472561836 norm:9.399105329066515e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.049086570739746094 norm:9.105070785153657e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:16:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.049059122800827026 norm:9.19701560633257e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.04903094843029976 norm:9.038599819177762e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:17:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.04902276396751404 norm:8.967865142039955e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.049026843160390854 norm:9.098873852053657e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:19:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.0490274652838707 norm:8.868931763572618e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.04900957643985748 norm:8.717089076526463e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:21:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.049016669392585754 norm:8.749843982513994e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:21:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:22:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.060323067009449005 norm:0.0010741730220615864 max memory_allocated 29269.87548828125 
[2025-03-02 17:23:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.05756894871592522 norm:0.0005264636711217463 max memory_allocated 29269.87548828125 
[2025-03-02 17:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.05602864921092987 norm:0.0003277202195022255 max memory_allocated 29269.87548828125 
[2025-03-02 17:24:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.054737892001867294 norm:0.0002296692255185917 max memory_allocated 29269.87548828125 
[2025-03-02 17:25:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.05389022082090378 norm:0.0001768158981576562 max memory_allocated 29269.87548828125 
[2025-03-02 17:26:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.05342162400484085 norm:0.00014535707305185497 max memory_allocated 29269.87548828125 
[2025-03-02 17:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.05325310304760933 norm:0.0001284466707147658 max memory_allocated 29269.87548828125 
[2025-03-02 17:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.053166888654232025 norm:0.00011919745884370059 max memory_allocated 29269.87548828125 
[2025-03-02 17:28:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.0531286858022213 norm:0.00011451840691734105 max memory_allocated 29269.87548828125 
[2025-03-02 17:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.053080908954143524 norm:0.00010787453356897458 max memory_allocated 29269.87548828125 
[2025-03-02 17:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.05305400863289833 norm:0.00010667073365766555 max memory_allocated 29269.87548828125 
[2025-03-02 17:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.05304160714149475 norm:0.00010485106031410396 max memory_allocated 29269.87548828125 
[2025-03-02 17:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.05300481989979744 norm:0.00010147270222660154 max memory_allocated 29269.87548828125 
[2025-03-02 17:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.05299386382102966 norm:0.00010299706627847627 max memory_allocated 29269.87548828125 
[2025-03-02 17:33:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.052971210330724716 norm:0.00010213113273493946 max memory_allocated 29269.87548828125 
[2025-03-02 17:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.05296481028199196 norm:0.00010154502524528652 max memory_allocated 29269.87548828125 
[2025-03-02 17:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.05295145884156227 norm:0.00010159663361264393 max memory_allocated 29269.87548828125 
[2025-03-02 17:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.05295567214488983 norm:0.00010426143853692338 max memory_allocated 29269.87548828125 
[2025-03-02 17:37:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.05294346064329147 norm:0.00010390721581643447 max memory_allocated 29269.87548828125 
[2025-03-02 17:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.05293205380439758 norm:0.0001029846171149984 max memory_allocated 29269.87548828125 
[2025-03-02 17:38:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.0656273141503334 norm:0.0014367643743753433 max memory_allocated 29269.87548828125 
[2025-03-02 17:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.06245321407914162 norm:0.0006538754678331316 max memory_allocated 29269.87548828125 
[2025-03-02 17:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.06059275567531586 norm:0.00039295063470490277 max memory_allocated 29269.87548828125 
[2025-03-02 17:41:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.059159643948078156 norm:0.00026887201238423586 max memory_allocated 29269.87548828125 
[2025-03-02 17:42:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.05814878270030022 norm:0.0001988355361390859 max memory_allocated 29269.87548828125 
[2025-03-02 17:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.057661667466163635 norm:0.00015966122737154365 max memory_allocated 29269.87548828125 
[2025-03-02 17:44:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.05745488777756691 norm:0.00013578488142229617 max memory_allocated 29269.87548828125 
[2025-03-02 17:44:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.05736514925956726 norm:0.00011978838301729411 max memory_allocated 29269.87548828125 
[2025-03-02 17:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.057304248213768005 norm:0.00010755871335277334 max memory_allocated 29269.87548828125 
[2025-03-02 17:46:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.05725735425949097 norm:9.962605690816417e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.05724429339170456 norm:9.693414176581427e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.05722414702177048 norm:9.374555520480499e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.05720241367816925 norm:9.02833417057991e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.057184264063835144 norm:8.941686246544123e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.05717179551720619 norm:8.91441450221464e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:51:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.057167377322912216 norm:8.86431589606218e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.057160913944244385 norm:8.774973684921861e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:53:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.05715369060635567 norm:8.705131767783314e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.05717264488339424 norm:8.966212772065774e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.057165373116731644 norm:8.977950346888974e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:55:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.0723215863108635 norm:0.0013248128816485405 max memory_allocated 29270.25048828125 
[2025-03-02 17:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.06891638040542603 norm:0.0005611202213913202 max memory_allocated 29270.25048828125 
[2025-03-02 17:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.06698480248451233 norm:0.00032959537929855287 max memory_allocated 29270.25048828125 
[2025-03-02 17:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.06547131389379501 norm:0.00023054522171150893 max memory_allocated 29270.25048828125 
[2025-03-02 17:59:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.0644451230764389 norm:0.00017629828653298318 max memory_allocated 29270.25048828125 
[2025-03-02 18:00:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.06397862732410431 norm:0.00014780418132431805 max memory_allocated 29270.25048828125 
[2025-03-02 18:00:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.0637810230255127 norm:0.00013243785360828042 max memory_allocated 29270.25048828125 
[2025-03-02 18:01:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.06368201971054077 norm:0.00012143149069743231 max memory_allocated 29270.25048828125 
[2025-03-02 18:02:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.06361058354377747 norm:0.00011324544175295159 max memory_allocated 29270.25048828125 
[2025-03-02 18:03:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.06357113271951675 norm:0.0001094393155653961 max memory_allocated 29270.25048828125 
[2025-03-02 18:04:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.06353101134300232 norm:0.00010348897194489837 max memory_allocated 29270.25048828125 
[2025-03-02 18:05:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.06350613385438919 norm:0.0001017977119772695 max memory_allocated 29270.25048828125 
[2025-03-02 18:05:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.06347765773534775 norm:0.00010131789895240217 max memory_allocated 29270.25048828125 
[2025-03-02 18:06:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.06345243006944656 norm:9.842519648373127e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.06344146281480789 norm:9.784213762031868e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:08:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.06343650072813034 norm:9.595734445611015e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:09:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.06344836950302124 norm:9.920389857143164e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:10:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.06343099474906921 norm:9.948357910616323e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:10:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.06341995298862457 norm:9.914094698615372e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:11:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.06342357397079468 norm:9.974261047318578e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:11:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.07806219905614853 norm:0.0008948322501964867 max memory_allocated 29270.43798828125 
[2025-03-02 18:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.07571281492710114 norm:0.00041306173079647124 max memory_allocated 29270.43798828125 
[2025-03-02 18:14:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.0738973617553711 norm:0.0002611367090139538 max memory_allocated 29270.43798828125 
[2025-03-02 18:15:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.07232915610074997 norm:0.00018708696006797254 max memory_allocated 29270.43798828125 
[2025-03-02 18:16:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.07133190333843231 norm:0.0001493586751166731 max memory_allocated 29270.43798828125 
[2025-03-02 18:16:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.07094573974609375 norm:0.000126362094306387 max memory_allocated 29270.43798828125 
[2025-03-02 18:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.07080471515655518 norm:0.00011220912710996345 max memory_allocated 29270.43798828125 
[2025-03-02 18:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.07071039080619812 norm:0.0001093122991733253 max memory_allocated 29270.43798828125 
[2025-03-02 18:19:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.07067568600177765 norm:0.0001068407145794481 max memory_allocated 29270.43798828125 
[2025-03-02 18:20:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.07064808905124664 norm:0.00010346100316382945 max memory_allocated 29270.43798828125 
[2025-03-02 18:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.07061798870563507 norm:0.00010129420115845278 max memory_allocated 29270.43798828125 
[2025-03-02 18:21:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.0706028863787651 norm:9.659081842983142e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.07056781649589539 norm:9.530861279927194e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.07055175304412842 norm:9.48681918089278e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:24:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.07055525481700897 norm:9.426601172890514e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:25:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.07054422050714493 norm:9.439852874493226e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:25:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.07053636014461517 norm:9.510684321867302e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:26:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.07053844630718231 norm:9.7132426162716e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:27:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.07053303718566895 norm:9.479492291575298e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:28:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.0705195814371109 norm:9.592407150194049e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:28:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:29:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.08664677292108536 norm:0.000856328580994159 max memory_allocated 29270.43798828125 
[2025-03-02 18:30:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.08355271816253662 norm:0.0003912776883225888 max memory_allocated 29270.43798828125 
[2025-03-02 18:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.0814943015575409 norm:0.0002591572410892695 max memory_allocated 29270.43798828125 
[2025-03-02 18:32:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.0797414481639862 norm:0.00019114059978164732 max memory_allocated 29270.43798828125 
[2025-03-02 18:32:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.07869410514831543 norm:0.00015904454630799592 max memory_allocated 29270.43798828125 
[2025-03-02 18:33:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.0783320739865303 norm:0.00013670636690221727 max memory_allocated 29270.43798828125 
[2025-03-02 18:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.07816461473703384 norm:0.00012314537889324129 max memory_allocated 29270.43798828125 
[2025-03-02 18:35:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.07810105383396149 norm:0.0001159746534540318 max memory_allocated 29270.43798828125 
[2025-03-02 18:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.07802406698465347 norm:0.00011134603118989617 max memory_allocated 29270.43798828125 
[2025-03-02 18:37:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.077958844602108 norm:0.00010648159513948485 max memory_allocated 29270.43798828125 
[2025-03-02 18:37:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.07790471613407135 norm:0.0001042230287566781 max memory_allocated 29270.43798828125 
[2025-03-02 18:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.07787369191646576 norm:9.942706674337387e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:39:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.07786453515291214 norm:9.500375745119527e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:40:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.07784848660230637 norm:9.493366087554023e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:41:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.07783473283052444 norm:9.412076906301081e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.07781095057725906 norm:9.302849503001198e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.07782049477100372 norm:9.632213914301246e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.07780800014734268 norm:9.320821845903993e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.07780341058969498 norm:9.394130756845698e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.07779819518327713 norm:9.307658910984173e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:45:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.09815338253974915 norm:0.0011642404133453965 max memory_allocated 29270.81298828125 
[2025-03-02 18:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.09445945173501968 norm:0.0005737687461078167 max memory_allocated 29270.81298828125 
[2025-03-02 18:48:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.09210595488548279 norm:0.0003784698492381722 max memory_allocated 29270.81298828125 
[2025-03-02 18:48:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.09018613398075104 norm:0.0002731878194026649 max memory_allocated 29270.81298828125 
[2025-03-02 18:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.08903135359287262 norm:0.0002138147538062185 max memory_allocated 29270.81298828125 
[2025-03-02 18:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.08864238113164902 norm:0.00017661220044828951 max memory_allocated 29270.81298828125 
[2025-03-02 18:51:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.08848173916339874 norm:0.00015809034812264144 max memory_allocated 29270.81298828125 
[2025-03-02 18:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.08838146179914474 norm:0.0001456460595363751 max memory_allocated 29270.81298828125 
[2025-03-02 18:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.08831041306257248 norm:0.00013810014934279025 max memory_allocated 29270.81298828125 
[2025-03-02 18:53:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.08824131637811661 norm:0.0001299947762163356 max memory_allocated 29270.81298828125 
[2025-03-02 18:54:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.08820757269859314 norm:0.0001229352637892589 max memory_allocated 29270.81298828125 
[2025-03-02 18:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.08817709982395172 norm:0.00012047882046317682 max memory_allocated 29270.81298828125 
[2025-03-02 18:56:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.08815973997116089 norm:0.00011849340808112174 max memory_allocated 29270.81298828125 
[2025-03-02 18:57:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.08814641088247299 norm:0.00011617494601523504 max memory_allocated 29270.81298828125 
[2025-03-02 18:57:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.08813190460205078 norm:0.0001159458261099644 max memory_allocated 29270.81298828125 
[2025-03-02 18:58:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.08811858296394348 norm:0.00011383208038751036 max memory_allocated 29270.81298828125 
[2025-03-02 18:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.08810557425022125 norm:0.00011059481767006218 max memory_allocated 29270.81298828125 
[2025-03-02 19:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.08809159696102142 norm:0.00011234129488002509 max memory_allocated 29270.81298828125 
[2025-03-02 19:01:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.08808699250221252 norm:0.00011032794282073155 max memory_allocated 29270.81298828125 
[2025-03-02 19:02:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.08808594197034836 norm:0.00011386230471543968 max memory_allocated 29270.81298828125 
[2025-03-02 19:02:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.10864508897066116 norm:0.000945034553296864 max memory_allocated 29271.00048828125 
[2025-03-02 19:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.10597875714302063 norm:0.0004966272972524166 max memory_allocated 29271.00048828125 
[2025-03-02 19:04:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.10376273095607758 norm:0.00031832867534831166 max memory_allocated 29271.00048828125 
[2025-03-02 19:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.10183684527873993 norm:0.00022599950898438692 max memory_allocated 29271.00048828125 
[2025-03-02 19:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.10080284625291824 norm:0.00018232739239465445 max memory_allocated 29271.00048828125 
[2025-03-02 19:07:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.10047931969165802 norm:0.0001558390213176608 max memory_allocated 29271.00048828125 
[2025-03-02 19:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.10033825784921646 norm:0.00014146321336738765 max memory_allocated 29271.00048828125 
[2025-03-02 19:08:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.1002444177865982 norm:0.00013405839854385704 max memory_allocated 29271.00048828125 
[2025-03-02 19:09:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.10017998516559601 norm:0.0001284111203858629 max memory_allocated 29271.00048828125 
[2025-03-02 19:10:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.10017256438732147 norm:0.00012499283184297383 max memory_allocated 29271.00048828125 
[2025-03-02 19:11:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.1001284047961235 norm:0.00012397584214340895 max memory_allocated 29271.00048828125 
[2025-03-02 19:12:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.10009163618087769 norm:0.00012107322254450992 max memory_allocated 29271.00048828125 
[2025-03-02 19:13:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.10008643567562103 norm:0.00011848741269204766 max memory_allocated 29271.00048828125 
[2025-03-02 19:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.10006813704967499 norm:0.00011889446614077315 max memory_allocated 29271.00048828125 
[2025-03-02 19:14:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.10004143416881561 norm:0.0001217901153722778 max memory_allocated 29271.00048828125 
[2025-03-02 19:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.10004881024360657 norm:0.0001177147205453366 max memory_allocated 29271.00048828125 
[2025-03-02 19:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.10003973543643951 norm:0.00011687906226143241 max memory_allocated 29271.00048828125 
[2025-03-02 19:17:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.10001441836357117 norm:0.00011818366328952834 max memory_allocated 29271.00048828125 
[2025-03-02 19:18:02 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.10000494867563248 norm:0.00011851309682242572 max memory_allocated 29271.00048828125 
[2025-03-02 19:18:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.09999308735132217 norm:0.00011897712101927027 max memory_allocated 29271.00048828125 
[2025-03-02 19:19:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:19:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.12442556023597717 norm:0.0011935781221836805 max memory_allocated 29271.00048828125 
[2025-03-02 19:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.12123806029558182 norm:0.0006089939270168543 max memory_allocated 29271.00048828125 
[2025-03-02 19:21:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.11876717209815979 norm:0.00038040700019337237 max memory_allocated 29271.00048828125 
[2025-03-02 19:22:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.11647961288690567 norm:0.00027042097644880414 max memory_allocated 29271.00048828125 
[2025-03-02 19:23:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.1154155284166336 norm:0.00021194398868829012 max memory_allocated 29271.00048828125 
[2025-03-02 19:24:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.11516112089157104 norm:0.00018254067981615663 max memory_allocated 29271.00048828125 
[2025-03-02 19:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.11501605063676834 norm:0.0001652073988225311 max memory_allocated 29271.00048828125 
[2025-03-02 19:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.11493466794490814 norm:0.00015354731294792145 max memory_allocated 29271.00048828125 
[2025-03-02 19:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.11484897881746292 norm:0.0001447123649995774 max memory_allocated 29271.00048828125 
[2025-03-02 19:27:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.11479176580905914 norm:0.00013832816330250353 max memory_allocated 29271.00048828125 
[2025-03-02 19:28:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.1147797629237175 norm:0.0001358094741590321 max memory_allocated 29271.00048828125 
[2025-03-02 19:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.11474819481372833 norm:0.00013219572429079562 max memory_allocated 29271.00048828125 
[2025-03-02 19:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.11470910906791687 norm:0.00013001292245462537 max memory_allocated 29271.00048828125 
[2025-03-02 19:30:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.11469706892967224 norm:0.00012764727580361068 max memory_allocated 29271.00048828125 
[2025-03-02 19:31:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.11469240486621857 norm:0.00012585028889589012 max memory_allocated 29271.00048828125 
[2025-03-02 19:32:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.11467161029577255 norm:0.00012630931450985372 max memory_allocated 29271.00048828125 
[2025-03-02 19:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.11464995890855789 norm:0.00012627328396774828 max memory_allocated 29271.00048828125 
[2025-03-02 19:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.11467331647872925 norm:0.0001272280205739662 max memory_allocated 29271.00048828125 
[2025-03-02 19:34:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.11464649438858032 norm:0.00012707528367172927 max memory_allocated 29271.00048828125 
[2025-03-02 19:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.11462915688753128 norm:0.0001261856668861583 max memory_allocated 29271.00048828125 
[2025-03-02 19:35:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:36:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.13794510066509247 norm:0.001347678597085178 max memory_allocated 29271.37548828125 
[2025-03-02 19:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.13547064363956451 norm:0.0007020691409707069 max memory_allocated 29271.37548828125 
[2025-03-02 19:38:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.1332339644432068 norm:0.0004474791348911822 max memory_allocated 29271.37548828125 
[2025-03-02 19:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.13096307218074799 norm:0.00031236890936270356 max memory_allocated 29271.37548828125 
[2025-03-02 19:40:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.12995336949825287 norm:0.0002376764314249158 max memory_allocated 29271.37548828125 
[2025-03-02 19:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.1296693980693817 norm:0.0001923103118315339 max memory_allocated 29271.37548828125 
[2025-03-02 19:41:44 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.12956300377845764 norm:0.00016681134002283216 max memory_allocated 29271.37548828125 
[2025-03-02 19:42:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.1295180320739746 norm:0.0001574027701281011 max memory_allocated 29271.37548828125 
[2025-03-02 19:43:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.12946605682373047 norm:0.0001448577386327088 max memory_allocated 29271.37548828125 
[2025-03-02 19:44:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.12939919531345367 norm:0.0001395343424519524 max memory_allocated 29271.37548828125 
[2025-03-02 19:45:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.12936396896839142 norm:0.00013354442489799112 max memory_allocated 29271.37548828125 
[2025-03-02 19:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.1293357014656067 norm:0.0001333266554865986 max memory_allocated 29271.37548828125 
[2025-03-02 19:46:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.12931568920612335 norm:0.00012884581519756466 max memory_allocated 29271.37548828125 
[2025-03-02 19:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.1293068677186966 norm:0.0001287135819438845 max memory_allocated 29271.37548828125 
[2025-03-02 19:48:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.12928931415081024 norm:0.00012683872773777694 max memory_allocated 29271.37548828125 
[2025-03-02 19:49:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.12928035855293274 norm:0.00012753141345456243 max memory_allocated 29271.37548828125 
[2025-03-02 19:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.12927119433879852 norm:0.00012611337297130376 max memory_allocated 29271.37548828125 
[2025-03-02 19:50:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.12926463782787323 norm:0.00012473700917325914 max memory_allocated 29271.37548828125 
[2025-03-02 19:51:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.12926188111305237 norm:0.00012418528785929084 max memory_allocated 29271.37548828125 
[2025-03-02 19:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.12927329540252686 norm:0.00012374519428703934 max memory_allocated 29271.37548828125 
[2025-03-02 19:52:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:53:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.154847651720047 norm:0.0009249962167814374 max memory_allocated 29271.37548828125 
[2025-03-02 19:54:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.15240933001041412 norm:0.0004987081047147512 max memory_allocated 29271.37548828125 
[2025-03-02 19:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.15002207458019257 norm:0.0003341357223689556 max memory_allocated 29271.37548828125 
[2025-03-02 19:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.1476677805185318 norm:0.000245511531829834 max memory_allocated 29271.37548828125 
[2025-03-02 19:56:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.1467338502407074 norm:0.00019863262423314154 max memory_allocated 29271.37548828125 
[2025-03-02 19:57:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.1464775949716568 norm:0.00017316268349532038 max memory_allocated 29271.37548828125 
[2025-03-02 19:58:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.1463444083929062 norm:0.00015977706061676145 max memory_allocated 29271.37548828125 
[2025-03-02 19:59:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.14624935388565063 norm:0.00014939169341232628 max memory_allocated 29271.37548828125 
[2025-03-02 20:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.14621472358703613 norm:0.00014177121920511127 max memory_allocated 29271.37548828125 
[2025-03-02 20:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.14614887535572052 norm:0.00013667541497852653 max memory_allocated 29271.37548828125 
[2025-03-02 20:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.1461016684770584 norm:0.00013201517867855728 max memory_allocated 29271.37548828125 
[2025-03-02 20:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.14606685936450958 norm:0.00013185238640289754 max memory_allocated 29271.37548828125 
[2025-03-02 20:03:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.14603391289710999 norm:0.00013078941265121102 max memory_allocated 29271.37548828125 
[2025-03-02 20:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.14601337909698486 norm:0.00012810807675123215 max memory_allocated 29271.37548828125 
[2025-03-02 20:05:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.1459856927394867 norm:0.00012809058534912765 max memory_allocated 29271.37548828125 
[2025-03-02 20:05:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.1459943801164627 norm:0.00012922259338665754 max memory_allocated 29271.37548828125 
[2025-03-02 20:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.1459985077381134 norm:0.00012925697956234217 max memory_allocated 29271.37548828125 
[2025-03-02 20:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.14599791169166565 norm:0.0001291102234972641 max memory_allocated 29271.37548828125 
[2025-03-02 20:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.14599502086639404 norm:0.0001300973235629499 max memory_allocated 29271.37548828125 
[2025-03-02 20:09:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.14597900211811066 norm:0.00013060073251836002 max memory_allocated 29271.37548828125 
[2025-03-02 20:09:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:10:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.17240087687969208 norm:0.0010877733584493399 max memory_allocated 29271.37548828125 
[2025-03-02 20:11:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.1699007749557495 norm:0.0004781799507327378 max memory_allocated 29271.37548828125 
[2025-03-02 20:12:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.16744787991046906 norm:0.0003000347933266312 max memory_allocated 29271.37548828125 
[2025-03-02 20:12:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.16499951481819153 norm:0.00022154355247039348 max memory_allocated 29271.37548828125 
[2025-03-02 20:13:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.16412357985973358 norm:0.00017681719327811152 max memory_allocated 29271.37548828125 
[2025-03-02 20:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.1639156937599182 norm:0.00015797605738043785 max memory_allocated 29271.37548828125 
[2025-03-02 20:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.16379976272583008 norm:0.0001434267614968121 max memory_allocated 29271.37548828125 
[2025-03-02 20:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.16373348236083984 norm:0.00013637611118610948 max memory_allocated 29271.37548828125 
[2025-03-02 20:16:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.16366620361804962 norm:0.0001304746838286519 max memory_allocated 29271.37548828125 
[2025-03-02 20:17:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.16362355649471283 norm:0.00012817134847864509 max memory_allocated 29271.37548828125 
[2025-03-02 20:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.16360439360141754 norm:0.00012563855852931738 max memory_allocated 29271.37548828125 
[2025-03-02 20:19:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.16358590126037598 norm:0.00012453601812012494 max memory_allocated 29271.37548828125 
[2025-03-02 20:20:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.1635950654745102 norm:0.00012293057807255536 max memory_allocated 29271.37548828125 
[2025-03-02 20:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.16357503831386566 norm:0.00012350716860964894 max memory_allocated 29271.37548828125 
[2025-03-02 20:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.16355721652507782 norm:0.00012358010280877352 max memory_allocated 29271.37548828125 
[2025-03-02 20:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.16353586316108704 norm:0.00012252853775862604 max memory_allocated 29271.37548828125 
[2025-03-02 20:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.16353647410869598 norm:0.00012444703315850347 max memory_allocated 29271.37548828125 
[2025-03-02 20:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.16353267431259155 norm:0.00012349913595244288 max memory_allocated 29271.37548828125 
[2025-03-02 20:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.16353440284729004 norm:0.00012440986756701022 max memory_allocated 29271.37548828125 
[2025-03-02 20:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.16354864835739136 norm:0.00012425656314007938 max memory_allocated 29271.37548828125 
[2025-03-02 20:26:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.19326025247573853 norm:0.0008737244643270969 max memory_allocated 29271.37548828125 
[2025-03-02 20:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.19067591428756714 norm:0.00045099033741280437 max memory_allocated 29271.37548828125 
[2025-03-02 20:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.18801982700824738 norm:0.0003085811622440815 max memory_allocated 29271.37548828125 
[2025-03-02 20:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.18533584475517273 norm:0.0002347837871639058 max memory_allocated 29271.37548828125 
[2025-03-02 20:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.18445903062820435 norm:0.00019906596571672708 max memory_allocated 29271.37548828125 
[2025-03-02 20:31:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.18418534100055695 norm:0.00017599263810552657 max memory_allocated 29271.37548828125 
[2025-03-02 20:32:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.18403378129005432 norm:0.0001657911780057475 max memory_allocated 29271.37548828125 
[2025-03-02 20:32:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.1839205026626587 norm:0.0001553535694256425 max memory_allocated 29271.37548828125 
[2025-03-02 20:33:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.18386031687259674 norm:0.00015125921345315874 max memory_allocated 29271.37548828125 
[2025-03-02 20:34:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.1838160902261734 norm:0.00014638359425589442 max memory_allocated 29271.37548828125 
[2025-03-02 20:35:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.183762788772583 norm:0.00014449050650000572 max memory_allocated 29271.37548828125 
[2025-03-02 20:36:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.18372279405593872 norm:0.000143333338201046 max memory_allocated 29271.37548828125 
[2025-03-02 20:37:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.18370996415615082 norm:0.0001417786697857082 max memory_allocated 29271.37548828125 
[2025-03-02 20:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.18369217216968536 norm:0.00014184287283569574 max memory_allocated 29271.37548828125 
[2025-03-02 20:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.1836971789598465 norm:0.00014325129450298846 max memory_allocated 29271.37548828125 
[2025-03-02 20:39:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.18368081748485565 norm:0.00014208629727363586 max memory_allocated 29271.37548828125 
[2025-03-02 20:40:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.1836748570203781 norm:0.00014322383503895253 max memory_allocated 29271.37548828125 
[2025-03-02 20:41:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.18365800380706787 norm:0.00014369862037710845 max memory_allocated 29271.37548828125 
[2025-03-02 20:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.18364951014518738 norm:0.00014316439046524465 max memory_allocated 29271.37548828125 
[2025-03-02 20:42:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.1836530715227127 norm:0.00014357517648022622 max memory_allocated 29271.37548828125 
[2025-03-02 20:43:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.21518902480602264 norm:0.0011462264228612185 max memory_allocated 29271.37548828125 
[2025-03-02 20:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.21235291659832 norm:0.0005895390640944242 max memory_allocated 29271.37548828125 
[2025-03-02 20:45:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.20938679575920105 norm:0.00042137978016398847 max memory_allocated 29271.37548828125 
[2025-03-02 20:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.20649610459804535 norm:0.0003628089325502515 max memory_allocated 29271.37548828125 
[2025-03-02 20:47:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.20570895075798035 norm:0.0003006027836818248 max memory_allocated 29271.37548828125 
[2025-03-02 20:48:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.20549122989177704 norm:0.00026194745441898704 max memory_allocated 29271.37548828125 
[2025-03-02 20:48:58 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.20535016059875488 norm:0.00025428287335671484 max memory_allocated 29271.37548828125 
[2025-03-02 20:49:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.20526841282844543 norm:0.0002424968988634646 max memory_allocated 29271.37548828125 
[2025-03-02 20:50:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.20521676540374756 norm:0.00024211218988057226 max memory_allocated 29271.37548828125 
[2025-03-02 20:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.2051842212677002 norm:0.00023807537218090147 max memory_allocated 29271.37548828125 
[2025-03-02 20:52:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.2051624357700348 norm:0.00023234722902998328 max memory_allocated 29271.37548828125 
[2025-03-02 20:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.20513495802879333 norm:0.00023194056120701134 max memory_allocated 29271.37548828125 
[2025-03-02 20:53:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.2051088809967041 norm:0.00023704917111899704 max memory_allocated 29271.37548828125 
[2025-03-02 20:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.2050936371088028 norm:0.00023306453658733517 max memory_allocated 29271.37548828125 
[2025-03-02 20:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.20510491728782654 norm:0.0002469900355208665 max memory_allocated 29271.37548828125 
[2025-03-02 20:56:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.20509004592895508 norm:0.00020733292330987751 max memory_allocated 29271.37548828125 
[2025-03-02 20:57:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.2050684243440628 norm:0.00021101508173160255 max memory_allocated 29271.37548828125 
[2025-03-02 20:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.20506559312343597 norm:0.0002170440275222063 max memory_allocated 29271.37548828125 
[2025-03-02 20:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.20506764948368073 norm:0.00020163301087450236 max memory_allocated 29271.37548828125 
[2025-03-02 20:59:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.20506367087364197 norm:0.00019778948626480997 max memory_allocated 29271.37548828125 
[2025-03-02 20:59:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 21:00:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.2371574342250824 norm:0.0016663193237036467 max memory_allocated 29272.31298828125 
[2025-03-02 21:01:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.2340819537639618 norm:0.0008662027539685369 max memory_allocated 29272.31298828125 
[2025-03-02 21:02:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.2308332920074463 norm:0.0005340756615623832 max memory_allocated 29272.31298828125 
[2025-03-02 21:03:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.22781336307525635 norm:0.00036017000093124807 max memory_allocated 29272.31298828125 
[2025-03-02 21:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.22704792022705078 norm:0.00027245006640441716 max memory_allocated 29272.31298828125 
[2025-03-02 21:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.22683793306350708 norm:0.00022296197130344808 max memory_allocated 29272.31298828125 
[2025-03-02 21:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.22674144804477692 norm:0.00019240421534050256 max memory_allocated 29272.31298828125 
[2025-03-02 21:06:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.22664977610111237 norm:0.00017156556714326143 max memory_allocated 29272.31298828125 
[2025-03-02 21:07:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.22661258280277252 norm:0.00015943078324198723 max memory_allocated 29272.31298828125 
[2025-03-02 21:08:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.22659125924110413 norm:0.0001516354241175577 max memory_allocated 29272.31298828125 
[2025-03-02 21:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.22656109929084778 norm:0.00014638205175288022 max memory_allocated 29272.31298828125 
[2025-03-02 21:09:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.22653864324092865 norm:0.00014247398939915001 max memory_allocated 29272.31298828125 
[2025-03-02 21:10:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.22652481496334076 norm:0.00013855959696229547 max memory_allocated 29272.31298828125 
[2025-03-02 21:11:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.226507768034935 norm:0.00013704958837479353 max memory_allocated 29272.31298828125 
[2025-03-02 21:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.22650206089019775 norm:0.00013526479597203434 max memory_allocated 29272.31298828125 
[2025-03-02 21:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.22648541629314423 norm:0.00013451497943606228 max memory_allocated 29272.31298828125 
[2025-03-02 21:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.2264752835035324 norm:0.00013332927483133972 max memory_allocated 29272.31298828125 
[2025-03-02 21:14:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.22647584974765778 norm:0.00013438169844448566 max memory_allocated 29272.31298828125 
[2025-03-02 21:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.2264738231897354 norm:0.00013405081699602306 max memory_allocated 29272.31298828125 
[2025-03-02 21:16:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.2264726161956787 norm:0.0001334620756097138 max memory_allocated 29272.31298828125 
[2025-03-02 21:16:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:17:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.26167768239974976 norm:0.0015618717297911644 max memory_allocated 29272.31298828125 
[2025-03-02 21:18:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.2586050033569336 norm:0.0007896024035289884 max memory_allocated 29272.31298828125 
[2025-03-02 21:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.2551392614841461 norm:0.0004922665539197624 max memory_allocated 29272.31298828125 
[2025-03-02 21:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.2521679997444153 norm:0.00034506310475990176 max memory_allocated 29272.31298828125 
[2025-03-02 21:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.2514680325984955 norm:0.00027065505855716765 max memory_allocated 29272.31298828125 
[2025-03-02 21:21:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.25120243430137634 norm:0.0002307834947714582 max memory_allocated 29272.31298828125 
[2025-03-02 21:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.25105971097946167 norm:0.0002085553132928908 max memory_allocated 29272.31298828125 
[2025-03-02 21:23:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.2509349584579468 norm:0.0001980915985768661 max memory_allocated 29272.31298828125 
[2025-03-02 21:24:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.25087207555770874 norm:0.000182461051736027 max memory_allocated 29272.31298828125 
[2025-03-02 21:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.2508009970188141 norm:0.00017730589024722576 max memory_allocated 29272.31298828125 
[2025-03-02 21:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.250737726688385 norm:0.0001700675638858229 max memory_allocated 29272.31298828125 
[2025-03-02 21:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.2507118284702301 norm:0.0001653877698117867 max memory_allocated 29272.31298828125 
[2025-03-02 21:27:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.25069937109947205 norm:0.00016475236043334007 max memory_allocated 29272.31298828125 
[2025-03-02 21:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.25066784024238586 norm:0.00016463903011754155 max memory_allocated 29272.31298828125 
[2025-03-02 21:29:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.25065240263938904 norm:0.00016576328198425472 max memory_allocated 29272.31298828125 
[2025-03-02 21:30:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.2506456971168518 norm:0.0001697409024927765 max memory_allocated 29272.31298828125 
[2025-03-02 21:30:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.25063031911849976 norm:0.00016848604718688875 max memory_allocated 29272.31298828125 
[2025-03-02 21:31:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.25061824917793274 norm:0.00016866727673914284 max memory_allocated 29272.31298828125 
[2025-03-02 21:32:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.2505936920642853 norm:0.00016698277613613755 max memory_allocated 29272.31298828125 
[2025-03-02 21:33:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.2505888044834137 norm:0.00016696276725269854 max memory_allocated 29272.31298828125 
[2025-03-02 21:33:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:34:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.2891208529472351 norm:0.0018803616985678673 max memory_allocated 29273.68798828125 
[2025-03-02 21:35:17 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.28526705503463745 norm:0.0009153307182714343 max memory_allocated 29273.68798828125 
[2025-03-02 21:36:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.28118425607681274 norm:0.0005537773249670863 max memory_allocated 29273.68798828125 
[2025-03-02 21:36:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.27793100476264954 norm:0.00037291215267032385 max memory_allocated 29273.68798828125 
[2025-03-02 21:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.2772662043571472 norm:0.00028743018629029393 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.27705442905426025 norm:0.00024072839005384594 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.2769175171852112 norm:0.00020998936088290066 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.27684059739112854 norm:0.00019321340369060636 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.2767952084541321 norm:0.00018376966181676835 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.2767646014690399 norm:0.00017112681234721094 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.2767482399940491 norm:0.0001677859399933368 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.2766832113265991 norm:0.00016792617680039257 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.27666547894477844 norm:0.00016035688167903572 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.2766367197036743 norm:0.00016238012176472694 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.27663174271583557 norm:0.00016088224947452545 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.27661481499671936 norm:0.00016505936218891293 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.27659380435943604 norm:0.0001638245739741251 max memory_allocated 29273.68798828125 
[2025-03-02 21:48:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.27660566568374634 norm:0.0001665471208980307 max memory_allocated 29273.68798828125 
[2025-03-02 21:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.27658766508102417 norm:0.00016521925863344222 max memory_allocated 29273.68798828125 
[2025-03-02 21:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.2765910029411316 norm:0.00016564229736104608 max memory_allocated 29273.68798828125 
[2025-03-02 21:50:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.3146863579750061 norm:0.0022811335511505604 max memory_allocated 29273.68798828125 
[2025-03-02 21:52:05 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.3112803101539612 norm:0.001153895747847855 max memory_allocated 29273.68798828125 
[2025-03-02 21:52:54 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.3073173761367798 norm:0.0007027980173006654 max memory_allocated 29273.68798828125 
[2025-03-02 21:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.3042108416557312 norm:0.0004687777254730463 max memory_allocated 29273.68798828125 
[2025-03-02 21:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.3035236597061157 norm:0.0003537748707458377 max memory_allocated 29273.68798828125 
[2025-03-02 21:55:23 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.30327361822128296 norm:0.00028625220875255764 max memory_allocated 29273.68798828125 
[2025-03-02 21:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.30315515398979187 norm:0.00024613054119981825 max memory_allocated 29273.68798828125 
[2025-03-02 21:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.3030582070350647 norm:0.00021884409943595529 max memory_allocated 29273.68798828125 
[2025-03-02 21:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.3029825985431671 norm:0.00019971303117927164 max memory_allocated 29273.68798828125 
[2025-03-02 21:58:41 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.30293720960617065 norm:0.0001874318695627153 max memory_allocated 29273.68798828125 
[2025-03-02 21:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.30290213227272034 norm:0.00018018617993220687 max memory_allocated 29273.68798828125 
[2025-03-02 22:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.30287742614746094 norm:0.00017317227320745587 max memory_allocated 29273.68798828125 
[2025-03-02 22:01:09 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.3028465807437897 norm:0.000168660277267918 max memory_allocated 29273.68798828125 
[2025-03-02 22:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.30282944440841675 norm:0.00016512678121216595 max memory_allocated 29273.68798828125 
[2025-03-02 22:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.30282095074653625 norm:0.00016299576964229345 max memory_allocated 29273.68798828125 
[2025-03-02 22:03:38 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.3028072416782379 norm:0.00016335949476342648 max memory_allocated 29273.68798828125 
[2025-03-02 22:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.30279088020324707 norm:0.00016063118528109044 max memory_allocated 29273.68798828125 
[2025-03-02 22:05:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.30277881026268005 norm:0.0001587472652317956 max memory_allocated 29273.68798828125 
[2025-03-02 22:06:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.30277377367019653 norm:0.0001596353540662676 max memory_allocated 29273.68798828125 
[2025-03-02 22:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.30276867747306824 norm:0.00015940130106173456 max memory_allocated 29273.68798828125 
[2025-03-02 22:07:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:08:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.3467904031276703 norm:0.0012665665708482265 max memory_allocated 29273.68798828125 
[2025-03-02 22:08:53 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.3429364562034607 norm:0.0006868238560855389 max memory_allocated 29273.68798828125 
[2025-03-02 22:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.33831578493118286 norm:0.0004581146640703082 max memory_allocated 29273.68798828125 
[2025-03-02 22:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.33524665236473083 norm:0.0003342445706948638 max memory_allocated 29273.68798828125 
[2025-03-02 22:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.3346068561077118 norm:0.0002729162806645036 max memory_allocated 29273.68798828125 
[2025-03-02 22:12:11 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.3343403935432434 norm:0.0002467883168719709 max memory_allocated 29273.68798828125 
[2025-03-02 22:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.33416134119033813 norm:0.00022554186580237 max memory_allocated 29273.68798828125 
[2025-03-02 22:13:51 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.33403778076171875 norm:0.0002144895406672731 max memory_allocated 29273.68798828125 
[2025-03-02 22:14:40 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.33395329117774963 norm:0.00020643674361053854 max memory_allocated 29273.68798828125 
[2025-03-02 22:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.33388465642929077 norm:0.00020148341718595475 max memory_allocated 29273.68798828125 
[2025-03-02 22:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.33381497859954834 norm:0.00019736368267331272 max memory_allocated 29273.68798828125 
[2025-03-02 22:17:09 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.33375993371009827 norm:0.00019297157996334136 max memory_allocated 29273.68798828125 
[2025-03-02 22:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.3337450623512268 norm:0.0001929439458763227 max memory_allocated 29273.68798828125 
[2025-03-02 22:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.33373337984085083 norm:0.0001924022362800315 max memory_allocated 29273.68798828125 
[2025-03-02 22:19:37 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.33372312784194946 norm:0.00019429078383836895 max memory_allocated 29273.68798828125 
[2025-03-02 22:20:27 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.333696186542511 norm:0.00019420871103648096 max memory_allocated 29273.68798828125 
[2025-03-02 22:21:16 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.3336856961250305 norm:0.00019340886501595378 max memory_allocated 29273.68798828125 
[2025-03-02 22:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.333682119846344 norm:0.00019676216470543295 max memory_allocated 29273.68798828125 
[2025-03-02 22:22:55 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.3336772620677948 norm:0.00019519681518431753 max memory_allocated 29273.68798828125 
[2025-03-02 22:23:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.33366286754608154 norm:0.00019415697897784412 max memory_allocated 29273.68798828125 
[2025-03-02 22:23:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:24:53 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.3850913941860199 norm:0.0016588905127719045 max memory_allocated 29273.68798828125 
[2025-03-02 22:25:42 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.38037416338920593 norm:0.0008386330446228385 max memory_allocated 29273.68798828125 
[2025-03-02 22:26:31 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.37496188282966614 norm:0.0005318725598044693 max memory_allocated 29273.68798828125 
[2025-03-02 22:27:21 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.37176910042762756 norm:0.00038024873356334865 max memory_allocated 29273.68798828125 
[2025-03-02 22:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.3712155520915985 norm:0.0003084612835664302 max memory_allocated 29273.68798828125 
[2025-03-02 22:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.37099388241767883 norm:0.0002670580870471895 max memory_allocated 29273.68798828125 
[2025-03-02 22:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.370840847492218 norm:0.0002443392004352063 max memory_allocated 29273.68798828125 
[2025-03-02 22:30:39 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.37073105573654175 norm:0.0002308935218024999 max memory_allocated 29273.68798828125 
[2025-03-02 22:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.37061160802841187 norm:0.00022035004803910851 max memory_allocated 29273.68798828125 
[2025-03-02 22:32:18 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.3705344796180725 norm:0.0002140010183211416 max memory_allocated 29273.68798828125 
[2025-03-02 22:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.3704698085784912 norm:0.0002064432919723913 max memory_allocated 29273.68798828125 
[2025-03-02 22:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.370443731546402 norm:0.00020402666996233165 max memory_allocated 29273.68798828125 
[2025-03-02 22:34:47 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.3704242706298828 norm:0.0002046040608547628 max memory_allocated 29273.68798828125 
[2025-03-02 22:35:36 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.37037742137908936 norm:0.00020073297491762787 max memory_allocated 29273.68798828125 
[2025-03-02 22:36:25 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.37033385038375854 norm:0.00020192765805404633 max memory_allocated 29273.68798828125 
[2025-03-02 22:37:15 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.3703170418739319 norm:0.00019945170788560063 max memory_allocated 29273.68798828125 
[2025-03-02 22:38:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.37029334902763367 norm:0.00020093149214517325 max memory_allocated 29273.68798828125 
[2025-03-02 22:38:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.3702915906906128 norm:0.00020362019131425768 max memory_allocated 29273.68798828125 
[2025-03-02 22:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.3702884316444397 norm:0.00020469618903007358 max memory_allocated 29273.68798828125 
[2025-03-02 22:40:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.3702937364578247 norm:0.00020462913380470127 max memory_allocated 29273.68798828125 
[2025-03-02 22:40:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:41:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.4261837899684906 norm:0.0031380190048366785 max memory_allocated 29273.68798828125 
[2025-03-02 22:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.4202853739261627 norm:0.0016723007429391146 max memory_allocated 29273.68798828125 
[2025-03-02 22:43:20 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.41408535838127136 norm:0.0010423330822959542 max memory_allocated 29273.68798828125 
[2025-03-02 22:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.41083332896232605 norm:0.0007119811489246786 max memory_allocated 29273.68798828125 
[2025-03-02 22:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.4100192189216614 norm:0.000538801250513643 max memory_allocated 29273.68798828125 
[2025-03-02 22:45:49 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.40950915217399597 norm:0.00044403981883078814 max memory_allocated 29273.68798828125 
[2025-03-02 22:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.40915098786354065 norm:0.00038069451693445444 max memory_allocated 29273.68798828125 
[2025-03-02 22:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.4089311361312866 norm:0.0003385840682312846 max memory_allocated 29273.68798828125 
[2025-03-02 22:48:17 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.40875640511512756 norm:0.0003137750900350511 max memory_allocated 29273.68798828125 
[2025-03-02 22:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.4088326096534729 norm:0.0002899871615227312 max memory_allocated 29273.68798828125 
[2025-03-02 22:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.40878891944885254 norm:0.000280860549537465 max memory_allocated 29273.68798828125 
[2025-03-02 22:50:46 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.4087024927139282 norm:0.0002706579689402133 max memory_allocated 29273.68798828125 
[2025-03-02 22:51:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.4086117744445801 norm:0.00026233436074107885 max memory_allocated 29273.68798828125 
[2025-03-02 22:52:25 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.40859121084213257 norm:0.00025832458049990237 max memory_allocated 29273.68798828125 
[2025-03-02 22:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.4085806906223297 norm:0.0002562081499490887 max memory_allocated 29273.68798828125 
[2025-03-02 22:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.40855950117111206 norm:0.0002539462293498218 max memory_allocated 29273.68798828125 
[2025-03-02 22:54:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.4085129499435425 norm:0.0002529631310608238 max memory_allocated 29273.68798828125 
[2025-03-02 22:55:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.40848278999328613 norm:0.00024980548187159 max memory_allocated 29273.68798828125 
[2025-03-02 22:56:32 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.4084745943546295 norm:0.00025155249750241637 max memory_allocated 29273.68798828125 
[2025-03-02 22:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.40845805406570435 norm:0.0002506165183149278 max memory_allocated 29273.68798828125 
[2025-03-02 22:57:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 22:57:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 22:58:30 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.47074538469314575 norm:0.0076858592219650745 max memory_allocated 29273.77001953125 
[2025-03-02 22:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.4646188020706177 norm:0.0063428147695958614 max memory_allocated 29273.77001953125 
[2025-03-02 23:00:09 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.45779794454574585 norm:0.005132986698299646 max memory_allocated 29273.77001953125 
[2025-03-02 23:00:59 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.45454078912734985 norm:0.004198676906526089 max memory_allocated 29273.77001953125 
[2025-03-02 23:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.45367324352264404 norm:0.003445643000304699 max memory_allocated 29273.77001953125 
[2025-03-02 23:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.4531383216381073 norm:0.0029932463075965643 max memory_allocated 29273.77001953125 
[2025-03-02 23:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.45292535424232483 norm:0.0028442691545933485 max memory_allocated 29273.77001953125 
[2025-03-02 23:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.45277827978134155 norm:0.002674751216545701 max memory_allocated 29273.77001953125 
[2025-03-02 23:05:08 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.45264628529548645 norm:0.002571354154497385 max memory_allocated 29273.77001953125 
[2025-03-02 23:05:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.45243924856185913 norm:0.0025259354151785374 max memory_allocated 29273.77001953125 
[2025-03-02 23:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.45221054553985596 norm:0.0024093464016914368 max memory_allocated 29273.77001953125 
[2025-03-02 23:07:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.45211923122406006 norm:0.0024317996576428413 max memory_allocated 29273.77001953125 
[2025-03-02 23:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.4519733488559723 norm:0.002373548923060298 max memory_allocated 29273.77001953125 
[2025-03-02 23:09:16 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.45182734727859497 norm:0.0023032831959426403 max memory_allocated 29273.77001953125 
[2025-03-02 23:10:06 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.4517976939678192 norm:0.0022473346907645464 max memory_allocated 29273.77001953125 
[2025-03-02 23:10:55 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.4516977369785309 norm:0.0021770386956632137 max memory_allocated 29273.77001953125 
[2025-03-02 23:11:45 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.4517480432987213 norm:0.002198250265792012 max memory_allocated 29273.77001953125 
[2025-03-02 23:12:35 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.45167702436447144 norm:0.0021463073790073395 max memory_allocated 29273.77001953125 
[2025-03-02 23:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.45166638493537903 norm:0.002127725863829255 max memory_allocated 29273.77001953125 
[2025-03-02 23:14:14 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.451575368642807 norm:0.0020686716306954622 max memory_allocated 29273.77001953125 
[2025-03-02 23:14:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:14:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:15:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.5356046557426453 norm:0.009346556849777699 max memory_allocated 29273.77001953125 
[2025-03-02 23:16:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.5254294872283936 norm:0.006104885600507259 max memory_allocated 29273.77001953125 
[2025-03-02 23:17:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.5165139436721802 norm:0.007209019735455513 max memory_allocated 29273.77001953125 
[2025-03-02 23:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.5123701691627502 norm:0.006524759344756603 max memory_allocated 29273.77001953125 
[2025-03-02 23:18:41 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.5113062262535095 norm:0.006347375921905041 max memory_allocated 29273.77001953125 
[2025-03-02 23:19:31 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.5108190774917603 norm:0.006147637963294983 max memory_allocated 29273.77001953125 
[2025-03-02 23:20:20 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.51039719581604 norm:0.005823655053973198 max memory_allocated 29273.77001953125 
[2025-03-02 23:21:10 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.5098962783813477 norm:0.005174772813916206 max memory_allocated 29273.77001953125 
[2025-03-02 23:22:00 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.5097551345825195 norm:0.0051289997063577175 max memory_allocated 29273.77001953125 
[2025-03-02 23:22:49 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.5095418691635132 norm:0.005120145156979561 max memory_allocated 29273.77001953125 
[2025-03-02 23:23:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.5094068050384521 norm:0.0047960844822227955 max memory_allocated 29273.77001953125 
[2025-03-02 23:24:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.5093386173248291 norm:0.004550290293991566 max memory_allocated 29273.77001953125 
[2025-03-02 23:25:18 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.5094812512397766 norm:0.004555378574877977 max memory_allocated 29273.77001953125 
[2025-03-02 23:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.5096796154975891 norm:0.00441771000623703 max memory_allocated 29273.77001953125 
[2025-03-02 23:26:58 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.5096931457519531 norm:0.004330974072217941 max memory_allocated 29273.77001953125 
[2025-03-02 23:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.509549617767334 norm:0.004190288484096527 max memory_allocated 29273.77001953125 
[2025-03-02 23:28:37 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.5095548033714294 norm:0.004285483621060848 max memory_allocated 29273.77001953125 
[2025-03-02 23:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.5095389485359192 norm:0.0041082464158535 max memory_allocated 29273.77001953125 
[2025-03-02 23:30:17 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.5094262361526489 norm:0.003961601294577122 max memory_allocated 29273.77001953125 
[2025-03-02 23:31:06 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.5094180107116699 norm:0.0038341020699590445 max memory_allocated 29273.77001953125 
[2025-03-02 23:31:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:31:25 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:32:14 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.7489816546440125 norm:0.03984198719263077 max memory_allocated 29274.14501953125 
[2025-03-02 23:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.7061241269111633 norm:0.028755830600857735 max memory_allocated 29274.14501953125 
[2025-03-02 23:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.6762517690658569 norm:0.021251481026411057 max memory_allocated 29274.14501953125 
[2025-03-02 23:34:43 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.6612969040870667 norm:0.018444541841745377 max memory_allocated 29274.14501953125 
[2025-03-02 23:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.6529842615127563 norm:0.016477642580866814 max memory_allocated 29274.14501953125 
[2025-03-02 23:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.6463984847068787 norm:0.013890065252780914 max memory_allocated 29274.14501953125 
[2025-03-02 23:37:12 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.6419852375984192 norm:0.011521664448082447 max memory_allocated 29274.14501953125 
[2025-03-02 23:38:01 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.6396321654319763 norm:0.011375470086932182 max memory_allocated 29274.14501953125 
[2025-03-02 23:38:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.6382386088371277 norm:0.010779671370983124 max memory_allocated 29274.14501953125 
[2025-03-02 23:39:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.6369341015815735 norm:0.010219392366707325 max memory_allocated 29274.14501953125 
[2025-03-02 23:40:30 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.6360116004943848 norm:0.009847115725278854 max memory_allocated 29274.14501953125 
[2025-03-02 23:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.6354354023933411 norm:0.009629100561141968 max memory_allocated 29274.14501953125 
[2025-03-02 23:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.6350632905960083 norm:0.009407487697899342 max memory_allocated 29274.14501953125 
[2025-03-02 23:42:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.6342202425003052 norm:0.00864530447870493 max memory_allocated 29274.14501953125 
[2025-03-02 23:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.6336844563484192 norm:0.00821293331682682 max memory_allocated 29274.14501953125 
[2025-03-02 23:44:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.6333276033401489 norm:0.008007070049643517 max memory_allocated 29274.14501953125 
[2025-03-02 23:45:28 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.6333110332489014 norm:0.008154508657753468 max memory_allocated 29274.14501953125 
[2025-03-02 23:46:18 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.6330066919326782 norm:0.008091630414128304 max memory_allocated 29274.14501953125 
[2025-03-02 23:47:07 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.6333070993423462 norm:0.008340736851096153 max memory_allocated 29274.14501953125 
[2025-03-02 23:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.6330123543739319 norm:0.008482053875923157 max memory_allocated 29274.14501953125 
[2025-03-02 23:48:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:48:16 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:1.1865215301513672 norm:0.06109726056456566 max memory_allocated 29274.14501953125 
[2025-03-02 23:49:55 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:1.12284255027771 norm:0.041631050407886505 max memory_allocated 29274.14501953125 
[2025-03-02 23:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:1.0897136926651 norm:0.03261367604136467 max memory_allocated 29274.14501953125 
[2025-03-02 23:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:1.068678855895996 norm:0.029156070202589035 max memory_allocated 29274.14501953125 
[2025-03-02 23:52:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:1.0565611124038696 norm:0.029207682237029076 max memory_allocated 29274.14501953125 
[2025-03-02 23:53:13 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:1.0512738227844238 norm:0.03138088807463646 max memory_allocated 29274.14501953125 
[2025-03-02 23:54:03 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:1.0466632843017578 norm:0.03032626397907734 max memory_allocated 29274.14501953125 
[2025-03-02 23:54:53 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:1.0432521104812622 norm:0.02919004298746586 max memory_allocated 29274.14501953125 
[2025-03-02 23:55:43 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:1.0385903120040894 norm:0.027459420263767242 max memory_allocated 29274.14501953125 
[2025-03-02 23:56:32 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:1.035509705543518 norm:0.025592558085918427 max memory_allocated 29274.14501953125 
[2025-03-02 23:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:1.0335134267807007 norm:0.02787862718105316 max memory_allocated 29274.14501953125 
[2025-03-02 23:58:11 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:1.0309162139892578 norm:0.02419610321521759 max memory_allocated 29274.14501953125 
[2025-03-02 23:59:01 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:1.0295785665512085 norm:0.02683122642338276 max memory_allocated 29274.14501953125 
[2025-03-02 23:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:1.0283879041671753 norm:0.02527092583477497 max memory_allocated 29274.14501953125 
[2025-03-03 00:00:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:1.0276165008544922 norm:0.026820991188287735 max memory_allocated 29274.14501953125 
[2025-03-03 00:01:30 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:1.0263800621032715 norm:0.024312684312462807 max memory_allocated 29274.14501953125 
[2025-03-03 00:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:1.0241260528564453 norm:0.023288093507289886 max memory_allocated 29274.14501953125 
[2025-03-03 00:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:1.0235289335250854 norm:0.024369152262806892 max memory_allocated 29274.14501953125 
[2025-03-03 00:03:59 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:1.0215940475463867 norm:0.022622287273406982 max memory_allocated 29274.14501953125 
[2025-03-03 00:04:49 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:1.0218626260757446 norm:0.022319627925753593 max memory_allocated 29274.14501953125 
[2025-03-03 00:05:03 root] (main_calib_config2.py 372): INFO 40353.128145217896
[2025-03-03 00:05:14 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:07:11 root] (main_calib_config2.py 159): INFO wikitext2 : 5.238716125488281
[2025-03-03 00:07:11 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:10:11 root] (main_calib_config2.py 159): INFO c4 : 6.787557125091553
[2025-03-03 02:12:25 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.238716125488281, 'c4': 6.787557125091553, 'results': {'piqa': {'acc': 0.7867247007616975, 'acc_stderr': 0.009557121225861335, 'acc_norm': 0.7845484221980413, 'acc_norm_stderr': 0.009592463115658114}, 'arc_challenge': {'acc': 0.41638225255972694, 'acc_stderr': 0.014405618279436176, 'acc_norm': 0.4283276450511945, 'acc_norm_stderr': 0.014460496367599017}, 'boolq': {'acc': 0.6807339449541284, 'acc_stderr': 0.008153754221520464}, 'winogrande': {'acc': 0.691397000789266, 'acc_stderr': 0.01298216020092657}, 'arc_easy': {'acc': 0.7306397306397306, 'acc_stderr': 0.009103043207756996, 'acc_norm': 0.5833333333333334, 'acc_norm_stderr': 0.010116282977781258}, 'hellaswag': {'acc': 0.5833499302927704, 'acc_stderr': 0.004919962822208309, 'acc_norm': 0.7543318064130651, 'acc_norm_stderr': 0.004296028885089461}}, 'versions': {'piqa': 0, 'arc_challenge': 0, 'boolq': 1, 'winogrande': 0, 'arc_easy': 0, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
