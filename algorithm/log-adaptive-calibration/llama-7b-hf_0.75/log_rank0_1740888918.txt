[2025-03-02 04:15:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.75', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.75.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 04:16:52 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 04:16:52 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.75.pkl
[2025-03-02 04:16:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 04:16:57 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:17:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.005116019397974014 norm:0.003695231396704912 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.002663968363776803 norm:0.0018621217459440231 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0021160400938242674 norm:0.00164989719633013 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.001961346482858062 norm:0.0017272644909098744 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0018452625954523683 norm:0.0014875403139740229 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0017917922232300043 norm:0.0013624619459733367 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.001734590856358409 norm:0.0012111363466829062 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0017022452084347606 norm:0.0011209303047508001 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0016725711757317185 norm:0.0010087681002914906 max memory_allocated 22559.10693359375 
[2025-03-02 04:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0016587227582931519 norm:0.0009381825220771134 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0016341875307261944 norm:0.0008567642653360963 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0016064434312283993 norm:0.0007670239428989589 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0015977248549461365 norm:0.0007209687028080225 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0015843254514038563 norm:0.0006861289730295539 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0015768017619848251 norm:0.0006396787939593196 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0015709878643974662 norm:0.0006060287705622613 max memory_allocated 22559.10693359375 
[2025-03-02 04:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0015589185059070587 norm:0.0005503038410097361 max memory_allocated 22559.10693359375 
[2025-03-02 04:27:01 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.001551565364934504 norm:0.000534108083229512 max memory_allocated 22559.10693359375 
[2025-03-02 04:27:35 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0015427239704877138 norm:0.0005031324690207839 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0015386344166472554 norm:0.00048726474051363766 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 04:28:20 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:28:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.014719871804118156 norm:0.016576049849390984 max memory_allocated 22559.27880859375 
[2025-03-02 04:29:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.008353225886821747 norm:0.011962667107582092 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.00657624751329422 norm:0.007146827876567841 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.005983167327940464 norm:0.005032898858189583 max memory_allocated 22559.27880859375 
[2025-03-02 04:31:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.005658344365656376 norm:0.0043785725720226765 max memory_allocated 22559.27880859375 
[2025-03-02 04:31:42 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.005429724231362343 norm:0.0039383117109537125 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.005257456097751856 norm:0.0034983402583748102 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.005158164072781801 norm:0.003221026621758938 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.005047119688242674 norm:0.0029621049761772156 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.00493185268715024 norm:0.0027021453715860844 max memory_allocated 22559.27880859375 
[2025-03-02 04:34:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.004820789210498333 norm:0.0024824710562825203 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.004786354023963213 norm:0.0023199780844151974 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.004749867133796215 norm:0.0020986278541386127 max memory_allocated 22559.27880859375 
[2025-03-02 04:36:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.004726231563836336 norm:0.0019263016292825341 max memory_allocated 22559.27880859375 
[2025-03-02 04:36:45 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.004685957916080952 norm:0.0017421721713617444 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.004650226328521967 norm:0.0015598160680383444 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.004629801958799362 norm:0.0013917277101427317 max memory_allocated 22559.27880859375 
[2025-03-02 04:38:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.004614281002432108 norm:0.0012349830940365791 max memory_allocated 22559.27880859375 
[2025-03-02 04:38:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004588166251778603 norm:0.0010671928757801652 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.004586930386722088 norm:0.0010232416680082679 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 04:39:45 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.12769444286823273 norm:0.03437314182519913 max memory_allocated 22559.45068359375 
[2025-03-02 04:40:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.051317207515239716 norm:0.023787060752511024 max memory_allocated 22559.45068359375 
[2025-03-02 04:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.026624102145433426 norm:0.017552919685840607 max memory_allocated 22559.45068359375 
[2025-03-02 04:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.018211498856544495 norm:0.00956906657665968 max memory_allocated 22559.45068359375 
[2025-03-02 04:42:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.015707384794950485 norm:0.00707333255559206 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.013619760982692242 norm:0.005489017348736525 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.012832279317080975 norm:0.004408860579133034 max memory_allocated 22559.45068359375 
[2025-03-02 04:44:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.012126529589295387 norm:0.004149054642766714 max memory_allocated 22559.45068359375 
[2025-03-02 04:44:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.011620108038187027 norm:0.0034579383209347725 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.011243827641010284 norm:0.0031744225416332483 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.011113462969660759 norm:0.003287019906565547 max memory_allocated 22559.45068359375 
[2025-03-02 04:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.010983334854245186 norm:0.003362241666764021 max memory_allocated 22559.45068359375 
[2025-03-02 04:47:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.010991811752319336 norm:0.0035451767034828663 max memory_allocated 22559.45068359375 
[2025-03-02 04:47:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.01085282489657402 norm:0.003284332575276494 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.010710612870752811 norm:0.0032265703193843365 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.010501989163458347 norm:0.0027314634062349796 max memory_allocated 22559.45068359375 
[2025-03-02 04:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.010365732945501804 norm:0.002585370559245348 max memory_allocated 22559.45068359375 
[2025-03-02 04:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.01032896339893341 norm:0.002830047393217683 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.010282118804752827 norm:0.002522651804611087 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.010220459662377834 norm:0.002507836325094104 max memory_allocated 22559.45068359375 
[2025-03-02 04:51:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.0180109441280365 norm:0.0020698632579296827 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.014500330202281475 norm:0.0008546578465029597 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.013190679252147675 norm:0.0004213472129777074 max memory_allocated 22559.50732421875 
[2025-03-02 04:53:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.01239837147295475 norm:0.0002355301403440535 max memory_allocated 22559.50732421875 
[2025-03-02 04:53:59 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.01187402568757534 norm:0.00015342200640589 max memory_allocated 22559.50732421875 
[2025-03-02 04:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.0115380072966218 norm:0.00011724227806553245 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.011404849588871002 norm:0.00010551876039244235 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.011374201625585556 norm:9.52047121245414e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.011349432170391083 norm:9.252644667867571e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.011331592686474323 norm:8.954746590461582e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.011319986544549465 norm:8.712481940165162e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.011330172419548035 norm:9.978180605685338e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.011310887522995472 norm:0.00010062991350423545 max memory_allocated 22559.50732421875 
[2025-03-02 04:59:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.011325662024319172 norm:0.00010101158113684505 max memory_allocated 22559.50732421875 
[2025-03-02 04:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.01131247729063034 norm:9.838490950642154e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.01130976527929306 norm:9.770825272426009e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.011307400651276112 norm:0.0001003638535621576 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.011287924833595753 norm:9.426494216313586e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.011292417533695698 norm:9.872294322121888e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:02:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.011292116716504097 norm:0.00010017190652433783 max memory_allocated 22559.50732421875 
[2025-03-02 05:02:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 05:03:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.027935510501265526 norm:0.0020955512300133705 max memory_allocated 22559.67919921875 
[2025-03-02 05:03:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.021218495443463326 norm:0.0009011017973534763 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:15 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.01767270267009735 norm:0.000438223680248484 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.016646668314933777 norm:0.0002578731218818575 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.016043690964579582 norm:0.00018367513257544488 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.0157388336956501 norm:0.0001596824440639466 max memory_allocated 22559.67919921875 
[2025-03-02 05:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.01563410274684429 norm:0.00012923908070661128 max memory_allocated 22559.67919921875 
[2025-03-02 05:07:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.015584909357130527 norm:0.00013255415251478553 max memory_allocated 22559.67919921875 
[2025-03-02 05:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.015542340464890003 norm:0.00012471742229536176 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.015507904812693596 norm:0.00013784454495180398 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.015483402647078037 norm:0.00012019668065477163 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.015467733144760132 norm:0.00012130793038522825 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.015449530445039272 norm:0.00013119560026098043 max memory_allocated 22559.67919921875 
[2025-03-02 05:10:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.015428945422172546 norm:0.00012094886915292591 max memory_allocated 22559.67919921875 
[2025-03-02 05:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.015415349043905735 norm:0.00011832830205094069 max memory_allocated 22559.67919921875 
[2025-03-02 05:11:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.015407567843794823 norm:0.00011438604997238144 max memory_allocated 22559.67919921875 
[2025-03-02 05:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.015406419523060322 norm:0.00011202743917237967 max memory_allocated 22559.67919921875 
[2025-03-02 05:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.01539843250066042 norm:0.00011004160478478298 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.015392575412988663 norm:0.00011141478171339259 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.015390205197036266 norm:0.00011102536518592387 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 05:14:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.02680934965610504 norm:0.001920504029840231 max memory_allocated 22559.85107421875 
[2025-03-02 05:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.02241101861000061 norm:0.0009018571581691504 max memory_allocated 22559.85107421875 
[2025-03-02 05:15:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.02027137391269207 norm:0.0004664435691665858 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.01908608339726925 norm:0.0002620037121232599 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.018352489918470383 norm:0.00016974483150988817 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.018084868788719177 norm:0.00013928597036283463 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.01793670281767845 norm:0.00012645911192521453 max memory_allocated 22559.85107421875 
[2025-03-02 05:18:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.017895124852657318 norm:0.00013092362496536225 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.017846738919615746 norm:0.00012688781134784222 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.017799943685531616 norm:0.00013795825361739844 max memory_allocated 22559.85107421875 
[2025-03-02 05:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.017753567546606064 norm:0.0001341767783742398 max memory_allocated 22559.85107421875 
[2025-03-02 05:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.017722953110933304 norm:0.00013439834583550692 max memory_allocated 22559.85107421875 
[2025-03-02 05:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.017691608518362045 norm:0.00014511830522678792 max memory_allocated 22559.85107421875 
[2025-03-02 05:21:47 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.0176823940128088 norm:0.00012782725389115512 max memory_allocated 22559.85107421875 
[2025-03-02 05:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.01766389235854149 norm:0.0001216617165482603 max memory_allocated 22559.85107421875 
[2025-03-02 05:22:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.017635870724916458 norm:0.00011683834600262344 max memory_allocated 22559.85107421875 
[2025-03-02 05:23:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.017641864717006683 norm:0.0001266764011234045 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.017629090696573257 norm:0.00012745638377964497 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.017640531063079834 norm:0.00013108830899000168 max memory_allocated 22559.85107421875 
[2025-03-02 05:25:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.017641283571720123 norm:0.00013172814215067774 max memory_allocated 22559.85107421875 
[2025-03-02 05:25:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 05:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.032361261546611786 norm:0.0012126077199354768 max memory_allocated 22560.02294921875 
[2025-03-02 05:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.0264169629663229 norm:0.00042835710337385535 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.02299177087843418 norm:0.00022238348901737481 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.022043025121092796 norm:0.00015613078721798956 max memory_allocated 22560.02294921875 
[2025-03-02 05:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.021483270451426506 norm:0.00012074811093043536 max memory_allocated 22560.02294921875 
[2025-03-02 05:28:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.0212114118039608 norm:0.00010223827848676592 max memory_allocated 22560.02294921875 
[2025-03-02 05:29:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.021095994859933853 norm:9.359026444144547e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:29:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.021030353382229805 norm:8.329573756782338e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:30:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.020992837846279144 norm:8.296603482449427e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:30:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.02095988765358925 norm:7.917801121948287e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:31:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.020938822999596596 norm:7.639569230377674e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.020917968824505806 norm:7.552084571216255e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.020898491144180298 norm:7.256666867760941e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.020885847508907318 norm:7.246393215609714e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.020872440189123154 norm:7.090713188517839e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:34:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.02086445689201355 norm:7.070305582601577e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.02085464634001255 norm:7.051909051369876e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.020845739170908928 norm:6.981455953791738e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:35:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.02084079571068287 norm:7.09139640093781e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.02083355188369751 norm:7.036530587356538e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:36:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 05:37:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.0342974029481411 norm:0.001244718674570322 max memory_allocated 22560.19482421875 
[2025-03-02 05:37:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.02925224043428898 norm:0.0006139427423477173 max memory_allocated 22560.19482421875 
[2025-03-02 05:38:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.026835912838578224 norm:0.0003614477172959596 max memory_allocated 22560.19482421875 
[2025-03-02 05:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.025495877489447594 norm:0.00024415476946160197 max memory_allocated 22560.19482421875 
[2025-03-02 05:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.024804336950182915 norm:0.0002318390179425478 max memory_allocated 22560.19482421875 
[2025-03-02 05:40:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.02438351698219776 norm:0.000173619351699017 max memory_allocated 22560.19482421875 
[2025-03-02 05:40:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.02424030378460884 norm:0.0001733713288558647 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.024183500558137894 norm:0.0001593632041476667 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.02417764626443386 norm:0.00017359804769512266 max memory_allocated 22560.19482421875 
[2025-03-02 05:42:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.02408284693956375 norm:0.00015142645861487836 max memory_allocated 22560.19482421875 
[2025-03-02 05:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.024021964520215988 norm:0.0001474488090025261 max memory_allocated 22560.19482421875 
[2025-03-02 05:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.023993484675884247 norm:0.0001473014272050932 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.02402232028543949 norm:0.00014624043251387775 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.02401479333639145 norm:0.00015148967213463038 max memory_allocated 22560.19482421875 
[2025-03-02 05:45:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.024025995284318924 norm:0.00014488848682958633 max memory_allocated 22560.19482421875 
[2025-03-02 05:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.024014722555875778 norm:0.00015139809693209827 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.023992883041501045 norm:0.00014822185039520264 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.023955941200256348 norm:0.0001441269414499402 max memory_allocated 22560.19482421875 
[2025-03-02 05:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.023959964513778687 norm:0.0001417210733052343 max memory_allocated 22560.19482421875 
[2025-03-02 05:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.02397468499839306 norm:0.00014708912931382656 max memory_allocated 22560.19482421875 
[2025-03-02 05:48:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:48:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.036599915474653244 norm:0.0010045585222542286 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.031272273510694504 norm:0.00036595764686353505 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.027986792847514153 norm:0.00019586272537708282 max memory_allocated 22560.36669921875 
[2025-03-02 05:50:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.02709759585559368 norm:0.00012836561654694378 max memory_allocated 22560.36669921875 
[2025-03-02 05:50:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.026590975001454353 norm:0.00010152717004530132 max memory_allocated 22560.36669921875 
[2025-03-02 05:51:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.02632918395102024 norm:9.09468435565941e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:52:03 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.026195500046014786 norm:8.393196912948042e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.026131317019462585 norm:8.309476834256202e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:53:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.026082288473844528 norm:8.424426050623879e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:53:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.026054155081510544 norm:8.326979877892882e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.0260245893150568 norm:7.897901377873495e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:54:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.025997014716267586 norm:7.858124445192516e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:55:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.02597362920641899 norm:7.705317693762481e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:55:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.025956563651561737 norm:7.663468568352982e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:56:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.02594773843884468 norm:7.960305083543062e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:57:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.02593361958861351 norm:7.7023112680763e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.02592463418841362 norm:7.904745143605396e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:58:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.025921309366822243 norm:7.572137837996706e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:58:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.02591570094227791 norm:7.718164124526083e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:59:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.025906110182404518 norm:7.589573942823336e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:59:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 06:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.0412210077047348 norm:0.0012145499931648374 max memory_allocated 22560.53857421875 
[2025-03-02 06:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.034877579659223557 norm:0.0004966084379702806 max memory_allocated 22560.53857421875 
[2025-03-02 06:01:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.031122306361794472 norm:0.0002632589021231979 max memory_allocated 22560.53857421875 
[2025-03-02 06:01:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.030116640031337738 norm:0.00015713500033598393 max memory_allocated 22560.53857421875 
[2025-03-02 06:02:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.029570339247584343 norm:0.0001120266824727878 max memory_allocated 22560.53857421875 
[2025-03-02 06:02:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.029281992465257645 norm:9.962801414076239e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:03:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.029139814898371696 norm:9.275106276618317e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.029074883088469505 norm:8.77911297720857e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.02902568131685257 norm:8.5369661974255e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:05:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.02899274230003357 norm:8.327624527737498e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.028955623507499695 norm:8.154749230016023e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:06:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.028928425163030624 norm:7.965906843310222e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.02890520542860031 norm:8.024163980735466e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:07:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.028890984132885933 norm:7.885397644713521e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:07:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.028874658048152924 norm:7.705976167926565e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:08:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.028860056772828102 norm:7.760197331663221e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.028849083930253983 norm:7.983487012097612e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.0288412943482399 norm:7.848119275877252e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.028834214434027672 norm:7.772376557113603e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.028825867921113968 norm:7.517600897699594e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:10:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 06:11:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.041102610528469086 norm:0.0009028077474795282 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.03597554937005043 norm:0.00036539745633490384 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.03272704407572746 norm:0.0001925848046084866 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.0318259671330452 norm:0.0001251426147064194 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.03130248188972473 norm:9.4278555479832e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:14:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.03104155696928501 norm:8.059154060902074e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.030924344435334206 norm:7.453389116562903e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:15:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.03086891770362854 norm:7.132587779778987e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:15:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.030832812190055847 norm:7.016988092800602e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:16:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.03079666756093502 norm:6.884735921630636e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.030772648751735687 norm:6.751800538040698e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.030764687806367874 norm:6.782118725823238e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.030747415497899055 norm:6.563639180967584e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:18:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.03073330596089363 norm:6.563613715115935e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.0307305995374918 norm:6.46831831545569e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:19:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.030720632523298264 norm:6.364331056829542e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.03071373887360096 norm:6.390656199073419e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.030706996098160744 norm:6.259867222979665e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:21:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.030701829120516777 norm:6.243051757337525e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.030700914561748505 norm:6.256959750317037e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:22:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 06:22:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.04436832666397095 norm:0.0011522131972014904 max memory_allocated 22560.88232421875 
[2025-03-02 06:23:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.038221124559640884 norm:0.00040617474587634206 max memory_allocated 22560.88232421875 
[2025-03-02 06:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.03460617735981941 norm:0.0002173221728298813 max memory_allocated 22560.88232421875 
[2025-03-02 06:24:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.03366084769368172 norm:0.00013889915135223418 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.033140283077955246 norm:0.00010195272625423968 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.03285875543951988 norm:8.728517423151061e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:26:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.032711949199438095 norm:8.056825026869774e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:26:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.03263767436146736 norm:7.829628884792328e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.032588373869657516 norm:7.745979382889345e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:27:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.032540928572416306 norm:7.601945981150493e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:28:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.032511353492736816 norm:7.436152372974902e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.03248903527855873 norm:7.475817983504385e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.032467156648635864 norm:7.40560790291056e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.03245259076356888 norm:7.384461787296459e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.032440945506095886 norm:7.28871746105142e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.03242964297533035 norm:7.290709618246183e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.032422635704278946 norm:7.324181933654472e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:32:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.032413460314273834 norm:7.156049832701683e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:32:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.03240509703755379 norm:7.118099892977625e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.032399751245975494 norm:6.996063893893734e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:33:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 06:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.04498884826898575 norm:0.0006953325937502086 max memory_allocated 22561.05419921875 
[2025-03-02 06:34:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.03979635611176491 norm:0.00029490774613805115 max memory_allocated 22561.05419921875 
[2025-03-02 06:35:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.03621838614344597 norm:0.00016416958533227444 max memory_allocated 22561.05419921875 
[2025-03-02 06:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.035325437784194946 norm:0.00011461740359663963 max memory_allocated 22561.05419921875 
[2025-03-02 06:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.03477496653795242 norm:9.281731036026031e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.03446388617157936 norm:8.142891601892188e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:37:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.03430343419313431 norm:7.546949927927926e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.03421701863408089 norm:6.996044976403937e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.034161847084760666 norm:6.697438220726326e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.03411657363176346 norm:6.65708867018111e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:39:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.03407728299498558 norm:6.47478736937046e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:40:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.03405073285102844 norm:6.360542465699837e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.03402549400925636 norm:6.287605356192216e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:41:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.033998437225818634 norm:6.173398287501186e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.03398313373327255 norm:6.060325540602207e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:42:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.03397337719798088 norm:6.0015026974724606e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:43:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.03396996483206749 norm:6.0170616052346304e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:43:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.03396524861454964 norm:6.011884397594258e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:44:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.033960532397031784 norm:5.989776400383562e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.03395308926701546 norm:5.98016704316251e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:45:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 06:45:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.04316505417227745 norm:0.0005751913413405418 max memory_allocated 22561.22607421875 
[2025-03-02 06:46:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.040251873433589935 norm:0.0002948787878267467 max memory_allocated 22561.22607421875 
[2025-03-02 06:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.03840493783354759 norm:0.0001944193063536659 max memory_allocated 22561.22607421875 
[2025-03-02 06:47:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.037222057580947876 norm:0.00015450749197043478 max memory_allocated 22561.22607421875 
[2025-03-02 06:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.03657834976911545 norm:0.00013511773431673646 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.03622153773903847 norm:0.00012119543680455536 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.0360473096370697 norm:0.00011154815729241818 max memory_allocated 22561.22607421875 
[2025-03-02 06:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.03597657009959221 norm:0.000101832440122962 max memory_allocated 22561.22607421875 
[2025-03-02 06:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.03592570871114731 norm:9.55801151576452e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:50:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.03588680177927017 norm:9.324388520326465e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.03585364669561386 norm:9.259164653485641e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.03582213446497917 norm:9.544369822833687e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:52:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.03580353036522865 norm:8.66819464135915e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:52:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.0358034148812294 norm:8.499000978190452e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.035815563052892685 norm:8.311337296618149e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.035814423114061356 norm:8.363989763893187e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.03580271825194359 norm:8.497048111166805e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.035768911242485046 norm:8.581647125538439e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:55:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.035761509090662 norm:8.312232967000455e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:56:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.035742588341236115 norm:8.245534991146997e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:56:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:57:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.04822775721549988 norm:0.0010678294347599149 max memory_allocated 22561.39794921875 
[2025-03-02 06:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.04395456984639168 norm:0.0005020973039790988 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.04158634692430496 norm:0.00031088796094991267 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.04026835784316063 norm:0.00022559688659384847 max memory_allocated 22561.39794921875 
[2025-03-02 06:59:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.03955226019024849 norm:0.00018083855684380978 max memory_allocated 22561.39794921875 
[2025-03-02 06:59:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.039174120873212814 norm:0.00015477664419449866 max memory_allocated 22561.39794921875 
[2025-03-02 07:00:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.03901372849941254 norm:0.00013661944831255823 max memory_allocated 22561.39794921875 
[2025-03-02 07:00:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.03888911381363869 norm:0.00012658812920562923 max memory_allocated 22561.39794921875 
[2025-03-02 07:01:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.03880869969725609 norm:0.00012132029951317236 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.03871947526931763 norm:0.00011408136924728751 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:36 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.03870195522904396 norm:0.00011532247299328446 max memory_allocated 22561.39794921875 
[2025-03-02 07:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.03867282718420029 norm:0.00010577262582955882 max memory_allocated 22561.39794921875 
[2025-03-02 07:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.03865773603320122 norm:0.00010144116095034406 max memory_allocated 22561.39794921875 
[2025-03-02 07:04:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.03864835575222969 norm:0.00010118621139554307 max memory_allocated 22561.39794921875 
[2025-03-02 07:04:50 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.03866267204284668 norm:0.00010099747305503115 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.03866451978683472 norm:0.00010456301970407367 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.03861059248447418 norm:9.916811541188508e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:06:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.03860153630375862 norm:9.847954788710922e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:07:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.038595050573349 norm:9.38663215492852e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:07:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.03859114646911621 norm:9.789448813535273e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:07:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 07:08:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.0488504134118557 norm:0.0007288942579180002 max memory_allocated 22561.56982421875 
[2025-03-02 07:08:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.0460137277841568 norm:0.0003631849540397525 max memory_allocated 22561.56982421875 
[2025-03-02 07:09:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.04403951019048691 norm:0.00023083804990164936 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.04275216534733772 norm:0.00016690458869561553 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.04206180199980736 norm:0.0001447480171918869 max memory_allocated 22561.56982421875 
[2025-03-02 07:11:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.04174916446208954 norm:0.00012634330778382719 max memory_allocated 22561.56982421875 
[2025-03-02 07:11:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.04159490019083023 norm:0.00011419013026170433 max memory_allocated 22561.56982421875 
[2025-03-02 07:12:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.04149765148758888 norm:0.00010093978198710829 max memory_allocated 22561.56982421875 
[2025-03-02 07:12:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.04145793989300728 norm:9.426019823877141e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.04142677038908005 norm:0.00010155806376133114 max memory_allocated 22561.56982421875 
[2025-03-02 07:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.04140152037143707 norm:9.740161476656795e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.04135214164853096 norm:9.119800961343572e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.041342008858919144 norm:8.636160055175424e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.04131251573562622 norm:8.40415304992348e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.041304610669612885 norm:8.6667321738787e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.04130654036998749 norm:8.818484639050439e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.04130207747220993 norm:8.885813440429047e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:17:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.041337527334690094 norm:0.00011119550617877394 max memory_allocated 22561.56982421875 
[2025-03-02 07:18:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.04131300002336502 norm:8.536522364011034e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.04132920503616333 norm:0.00011449892917880788 max memory_allocated 22561.56982421875 
[2025-03-02 07:19:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 07:19:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.05474676936864853 norm:0.0010456172749400139 max memory_allocated 22561.74169921875 
[2025-03-02 07:20:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.050468090921640396 norm:0.0003874438116326928 max memory_allocated 22561.74169921875 
[2025-03-02 07:20:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.04823494330048561 norm:0.00023844929819460958 max memory_allocated 22561.74169921875 
[2025-03-02 07:21:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.04676256701350212 norm:0.00018707032722886652 max memory_allocated 22561.74169921875 
[2025-03-02 07:22:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.04602771997451782 norm:0.00016488766414113343 max memory_allocated 22561.74169921875 
[2025-03-02 07:22:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.045697394758462906 norm:0.00014617067063227296 max memory_allocated 22561.74169921875 
[2025-03-02 07:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.04556477069854736 norm:0.00013705494347959757 max memory_allocated 22561.74169921875 
[2025-03-02 07:23:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.04547617584466934 norm:0.00012059088476235047 max memory_allocated 22561.74169921875 
[2025-03-02 07:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.045368049293756485 norm:0.00011525586160132661 max memory_allocated 22561.74169921875 
[2025-03-02 07:24:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.045299023389816284 norm:0.00011134924716316164 max memory_allocated 22561.74169921875 
[2025-03-02 07:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.045275043696165085 norm:0.00011008622823283076 max memory_allocated 22561.74169921875 
[2025-03-02 07:25:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.04526819661259651 norm:0.00011001156235579401 max memory_allocated 22561.74169921875 
[2025-03-02 07:26:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.04524296522140503 norm:0.0001088558929041028 max memory_allocated 22561.74169921875 
[2025-03-02 07:27:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.045215241611003876 norm:0.00010327728523407131 max memory_allocated 22561.74169921875 
[2025-03-02 07:27:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.04517769068479538 norm:0.00010201827535638586 max memory_allocated 22561.74169921875 
[2025-03-02 07:28:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.04515081271529198 norm:9.949965897249058e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.04515065252780914 norm:9.833921649260446e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:29:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.04516006261110306 norm:9.653091547079384e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:29:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.045132678002119064 norm:0.00010107763955602422 max memory_allocated 22561.74169921875 
[2025-03-02 07:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.04513154178857803 norm:9.866397886071354e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:30:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 07:31:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.06046748533844948 norm:0.001240014680661261 max memory_allocated 22561.91357421875 
[2025-03-02 07:31:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.05636030435562134 norm:0.0005076457746326923 max memory_allocated 22561.91357421875 
[2025-03-02 07:32:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.053745076060295105 norm:0.0002981451107189059 max memory_allocated 22561.91357421875 
[2025-03-02 07:32:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.05214198678731918 norm:0.00021703512175008655 max memory_allocated 22561.91357421875 
[2025-03-02 07:33:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.05136782303452492 norm:0.00017031391325872391 max memory_allocated 22561.91357421875 
[2025-03-02 07:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.05104811489582062 norm:0.00014609824575018138 max memory_allocated 22561.91357421875 
[2025-03-02 07:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.05090710148215294 norm:0.00013334088725969195 max memory_allocated 22561.91357421875 
[2025-03-02 07:35:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.050845418125391006 norm:0.00012931192759424448 max memory_allocated 22561.91357421875 
[2025-03-02 07:35:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.0507793053984642 norm:0.00011665809870464727 max memory_allocated 22561.91357421875 
[2025-03-02 07:36:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.05070837214589119 norm:0.00010887431562878191 max memory_allocated 22561.91357421875 
[2025-03-02 07:36:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.050672102719545364 norm:0.0001082500530174002 max memory_allocated 22561.91357421875 
[2025-03-02 07:37:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.05064740777015686 norm:0.00010203695273958147 max memory_allocated 22561.91357421875 
[2025-03-02 07:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.05062779411673546 norm:9.978600428439677e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.05060470849275589 norm:9.869813220575452e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.05059774965047836 norm:9.915768896462396e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.05060866102576256 norm:9.873278759187087e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:40:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.050595518201589584 norm:9.827900066738948e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.050588078796863556 norm:9.684691030997783e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.050577543675899506 norm:9.833279909798875e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.05055833235383034 norm:9.930280793923885e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:41:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 07:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.06552523374557495 norm:0.0006097131408751011 max memory_allocated 22562.08544921875 
[2025-03-02 07:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.06240277364850044 norm:0.0002803789684548974 max memory_allocated 22562.08544921875 
[2025-03-02 07:43:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.060405176132917404 norm:0.00020209679496474564 max memory_allocated 22562.08544921875 
[2025-03-02 07:44:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.05891807749867439 norm:0.00017186814511660486 max memory_allocated 22562.08544921875 
[2025-03-02 07:44:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.0582224503159523 norm:0.00013754965038970113 max memory_allocated 22562.08544921875 
[2025-03-02 07:45:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.05798674002289772 norm:0.00012704276014119387 max memory_allocated 22562.08544921875 
[2025-03-02 07:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.05788048356771469 norm:0.0001171550975413993 max memory_allocated 22562.08544921875 
[2025-03-02 07:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.0578078031539917 norm:0.00010808833758346736 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.057746563106775284 norm:0.00010007276432588696 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.057685721665620804 norm:9.535303252050653e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:48:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.057684995234012604 norm:9.290250454796478e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:48:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.057649530470371246 norm:9.277746721636504e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.05761905014514923 norm:9.115447755903006e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.05760178342461586 norm:8.677724690642208e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.05760195106267929 norm:8.801474905340001e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.057602427899837494 norm:8.817933121463284e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.057594265788793564 norm:8.802400407148525e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.05758832395076752 norm:8.697854354977608e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:52:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.05757322907447815 norm:8.620466542197391e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:53:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.05758036673069 norm:8.798441558610648e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:53:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:53:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.07557351887226105 norm:0.000938295153900981 max memory_allocated 22562.25732421875 
[2025-03-02 07:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.07207465916872025 norm:0.0003732649201992899 max memory_allocated 22562.25732421875 
[2025-03-02 07:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.06974498927593231 norm:0.0002354213793296367 max memory_allocated 22562.25732421875 
[2025-03-02 07:55:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.0680604800581932 norm:0.00019010022515431046 max memory_allocated 22562.25732421875 
[2025-03-02 07:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.06733009219169617 norm:0.00016074193990789354 max memory_allocated 22562.25732421875 
[2025-03-02 07:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.06710638105869293 norm:0.0001413102145306766 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.06696507334709167 norm:0.000125250342534855 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.06690837442874908 norm:0.00013123234384693205 max memory_allocated 22562.25732421875 
[2025-03-02 07:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.06684974581003189 norm:0.00012261918163858354 max memory_allocated 22562.25732421875 
[2025-03-02 07:59:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.06677071005105972 norm:0.0001091157246264629 max memory_allocated 22562.25732421875 
[2025-03-02 07:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.0667349323630333 norm:0.00010853051935555413 max memory_allocated 22562.25732421875 
[2025-03-02 08:00:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.06671871989965439 norm:0.00010782040772028267 max memory_allocated 22562.25732421875 
[2025-03-02 08:00:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.06673918664455414 norm:0.00010761847079265863 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.06669340282678604 norm:0.00010641350672813132 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.06666364520788193 norm:0.00010639341053320095 max memory_allocated 22562.25732421875 
[2025-03-02 08:02:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.0666571855545044 norm:0.00010372815449954942 max memory_allocated 22562.25732421875 
[2025-03-02 08:02:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.06665841490030289 norm:0.0001066079712472856 max memory_allocated 22562.25732421875 
[2025-03-02 08:03:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.06665422022342682 norm:0.00010472079156897962 max memory_allocated 22562.25732421875 
[2025-03-02 08:04:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.0666576623916626 norm:0.00010717828263295814 max memory_allocated 22562.25732421875 
[2025-03-02 08:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.06665153801441193 norm:0.00010713043593568727 max memory_allocated 22562.25732421875 
[2025-03-02 08:04:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 08:05:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.09128046035766602 norm:0.0022681611590087414 max memory_allocated 22562.42919921875 
[2025-03-02 08:05:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.0859246775507927 norm:0.0006777848466299474 max memory_allocated 22562.42919921875 
[2025-03-02 08:06:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.08279415220022202 norm:0.000390639208490029 max memory_allocated 22562.42919921875 
[2025-03-02 08:07:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.08073647320270538 norm:0.00029313532286323607 max memory_allocated 22562.42919921875 
[2025-03-02 08:07:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.08003874868154526 norm:0.0002765373501460999 max memory_allocated 22562.42919921875 
[2025-03-02 08:08:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.07974731922149658 norm:0.0002112794463755563 max memory_allocated 22562.42919921875 
[2025-03-02 08:08:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.07959304749965668 norm:0.00019646581495180726 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.07949164509773254 norm:0.000179767856025137 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.07937012612819672 norm:0.00016825154307298362 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.07926516979932785 norm:0.00015597794845234603 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.0792047455906868 norm:0.00015346157306339592 max memory_allocated 22562.42919921875 
[2025-03-02 08:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.07914908975362778 norm:0.0001384162314934656 max memory_allocated 22562.42919921875 
[2025-03-02 08:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.07913151383399963 norm:0.0001314254041062668 max memory_allocated 22562.42919921875 
[2025-03-02 08:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.07909566164016724 norm:0.00013427036174107343 max memory_allocated 22562.42919921875 
[2025-03-02 08:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.07907524704933167 norm:0.0001332982792519033 max memory_allocated 22562.42919921875 
[2025-03-02 08:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.07904908061027527 norm:0.00013658133684657514 max memory_allocated 22562.42919921875 
[2025-03-02 08:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.07901066541671753 norm:0.00013557181227952242 max memory_allocated 22562.42919921875 
[2025-03-02 08:14:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.07905440777540207 norm:0.00014094379730522633 max memory_allocated 22562.42919921875 
[2025-03-02 08:15:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.07905575633049011 norm:0.0001340774178970605 max memory_allocated 22562.42919921875 
[2025-03-02 08:16:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.07906046509742737 norm:0.00014329652185551822 max memory_allocated 22562.42919921875 
[2025-03-02 08:16:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 08:16:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.10407985746860504 norm:0.0022895357105880976 max memory_allocated 22562.60107421875 
[2025-03-02 08:17:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.10025222599506378 norm:0.0008177963318303227 max memory_allocated 22562.60107421875 
[2025-03-02 08:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.09749254584312439 norm:0.00044044628157280385 max memory_allocated 22562.60107421875 
[2025-03-02 08:18:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.0953657329082489 norm:0.00034838877036236227 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.09466539323329926 norm:0.00031561116338707507 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.0944410040974617 norm:0.0002731493441388011 max memory_allocated 22562.60107421875 
[2025-03-02 08:20:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.09430699050426483 norm:0.00025894062127918005 max memory_allocated 22562.60107421875 
[2025-03-02 08:20:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.09416791051626205 norm:0.0002242350747110322 max memory_allocated 22562.60107421875 
[2025-03-02 08:21:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.09406989067792892 norm:0.0002113064838340506 max memory_allocated 22562.60107421875 
[2025-03-02 08:21:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.09401783347129822 norm:0.00019908117246814072 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.09396621584892273 norm:0.00018627228564582765 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.09392113983631134 norm:0.0001682004367467016 max memory_allocated 22562.60107421875 
[2025-03-02 08:23:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.09387245029211044 norm:0.00016188320296350867 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.0938454270362854 norm:0.0001502553786849603 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.09380931407213211 norm:0.00014412100426852703 max memory_allocated 22562.60107421875 
[2025-03-02 08:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.09378445148468018 norm:0.00013780419249087572 max memory_allocated 22562.60107421875 
[2025-03-02 08:25:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.0937679186463356 norm:0.00013291285722516477 max memory_allocated 22562.60107421875 
[2025-03-02 08:26:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.09375905990600586 norm:0.00013753457460552454 max memory_allocated 22562.60107421875 
[2025-03-02 08:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.09375868737697601 norm:0.00013911678979638964 max memory_allocated 22562.60107421875 
[2025-03-02 08:27:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.09375549852848053 norm:0.00015191578131634742 max memory_allocated 22562.60107421875 
[2025-03-02 08:27:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 08:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.11871715635061264 norm:0.001197967678308487 max memory_allocated 22562.77294921875 
[2025-03-02 08:28:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.11542218923568726 norm:0.000612684350926429 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.11278993636369705 norm:0.00040516251465305686 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.11067109555006027 norm:0.00030390534084290266 max memory_allocated 22562.77294921875 
[2025-03-02 08:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.11019831895828247 norm:0.00024028759798966348 max memory_allocated 22562.77294921875 
[2025-03-02 08:30:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.10998842865228653 norm:0.00020157528342679143 max memory_allocated 22562.77294921875 
[2025-03-02 08:31:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.10982006788253784 norm:0.00017578445840626955 max memory_allocated 22562.77294921875 
[2025-03-02 08:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.10966208577156067 norm:0.00016383487673010677 max memory_allocated 22562.77294921875 
[2025-03-02 08:32:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.10964683443307877 norm:0.0001611463085282594 max memory_allocated 22562.77294921875 
[2025-03-02 08:33:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.1095995381474495 norm:0.00015739473747089505 max memory_allocated 22562.77294921875 
[2025-03-02 08:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.10954520851373672 norm:0.00015423260629177094 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.10950284451246262 norm:0.00015641307982150465 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.10949656367301941 norm:0.00015103293117135763 max memory_allocated 22562.77294921875 
[2025-03-02 08:35:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.10949638485908508 norm:0.00015304688713513315 max memory_allocated 22562.77294921875 
[2025-03-02 08:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.10949451476335526 norm:0.00015539246669504791 max memory_allocated 22562.77294921875 
[2025-03-02 08:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.10948267579078674 norm:0.00014820077922195196 max memory_allocated 22562.77294921875 
[2025-03-02 08:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.10950393974781036 norm:0.00015056415577419102 max memory_allocated 22562.77294921875 
[2025-03-02 08:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.10947816073894501 norm:0.0001569819141877815 max memory_allocated 22562.77294921875 
[2025-03-02 08:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.10950024425983429 norm:0.00016590391169302166 max memory_allocated 22562.77294921875 
[2025-03-02 08:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.1094951331615448 norm:0.0001538288634037599 max memory_allocated 22562.77294921875 
[2025-03-02 08:38:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 08:39:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.14002938568592072 norm:0.0018906198674812913 max memory_allocated 22562.94482421875 
[2025-03-02 08:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.13635678589344025 norm:0.000984605634585023 max memory_allocated 22562.94482421875 
[2025-03-02 08:40:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.1332889050245285 norm:0.000625721993856132 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.13088414072990417 norm:0.0004439949698280543 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.130234494805336 norm:0.00035936577478423715 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.12991780042648315 norm:0.00027683223015628755 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.1297287940979004 norm:0.00025246842415072024 max memory_allocated 22562.94482421875 
[2025-03-02 08:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.1296456903219223 norm:0.00022855374845676124 max memory_allocated 22562.94482421875 
[2025-03-02 08:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.12954986095428467 norm:0.00020280266471672803 max memory_allocated 22562.94482421875 
[2025-03-02 08:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.12945100665092468 norm:0.00019526761025190353 max memory_allocated 22562.94482421875 
[2025-03-02 08:45:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.1294151246547699 norm:0.00019360710575710982 max memory_allocated 22562.94482421875 
[2025-03-02 08:45:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.12940162420272827 norm:0.00018124078633263707 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.12939366698265076 norm:0.00018025045574177057 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.12940292060375214 norm:0.0001864483638200909 max memory_allocated 22562.94482421875 
[2025-03-02 08:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.12937003374099731 norm:0.00018437385733705014 max memory_allocated 22562.94482421875 
[2025-03-02 08:47:58 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.129357248544693 norm:0.00018107332289218903 max memory_allocated 22562.94482421875 
[2025-03-02 08:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.12935450673103333 norm:0.00018312422616872936 max memory_allocated 22562.94482421875 
[2025-03-02 08:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.12932857871055603 norm:0.00018031554645858705 max memory_allocated 22562.94482421875 
[2025-03-02 08:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.12930259108543396 norm:0.00018161244224756956 max memory_allocated 22562.94482421875 
[2025-03-02 08:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.1293012648820877 norm:0.0001819687895476818 max memory_allocated 22562.94482421875 
[2025-03-02 08:50:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.1592356562614441 norm:0.0009079299052245915 max memory_allocated 22563.11669921875 
[2025-03-02 08:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.15610191226005554 norm:0.0005090196500532329 max memory_allocated 22563.11669921875 
[2025-03-02 08:52:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.15289202332496643 norm:0.0003668058488983661 max memory_allocated 22563.11669921875 
[2025-03-02 08:52:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.15051652491092682 norm:0.0002900263643823564 max memory_allocated 22563.11669921875 
[2025-03-02 08:53:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.1500505805015564 norm:0.0002445694408379495 max memory_allocated 22563.11669921875 
[2025-03-02 08:53:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.14976881444454193 norm:0.00021954580734018236 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.14965790510177612 norm:0.0002025564608629793 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.14954635500907898 norm:0.0001873563160188496 max memory_allocated 22563.11669921875 
[2025-03-02 08:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.1494762897491455 norm:0.00018334199558012187 max memory_allocated 22563.11669921875 
[2025-03-02 08:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.14937762916088104 norm:0.0001742483291309327 max memory_allocated 22563.11669921875 
[2025-03-02 08:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.14931312203407288 norm:0.00016963118105195463 max memory_allocated 22563.11669921875 
[2025-03-02 08:57:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.14926153421401978 norm:0.00016809570661280304 max memory_allocated 22563.11669921875 
[2025-03-02 08:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.1492459923028946 norm:0.00016589523875154555 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.14923954010009766 norm:0.00016588301514275372 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.14918044209480286 norm:0.0001648689794819802 max memory_allocated 22563.11669921875 
[2025-03-02 08:59:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.1491665244102478 norm:0.00016601123206783086 max memory_allocated 22563.11669921875 
[2025-03-02 08:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.1491539478302002 norm:0.00016240691184066236 max memory_allocated 22563.11669921875 
[2025-03-02 09:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.14915145933628082 norm:0.0001621657283976674 max memory_allocated 22563.11669921875 
[2025-03-02 09:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.14914940297603607 norm:0.00016234077338594943 max memory_allocated 22563.11669921875 
[2025-03-02 09:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.14915907382965088 norm:0.0001606785081094131 max memory_allocated 22563.11669921875 
[2025-03-02 09:01:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 09:02:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.1839107871055603 norm:0.0013172547332942486 max memory_allocated 22563.28857421875 
[2025-03-02 09:02:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.18025794625282288 norm:0.0007575814379379153 max memory_allocated 22563.28857421875 
[2025-03-02 09:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.1765461564064026 norm:0.0005166168557479978 max memory_allocated 22563.28857421875 
[2025-03-02 09:04:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.17409226298332214 norm:0.00038109274464659393 max memory_allocated 22563.28857421875 
[2025-03-02 09:04:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.1735956221818924 norm:0.000306768313748762 max memory_allocated 22563.28857421875 
[2025-03-02 09:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.1733534038066864 norm:0.00025154592003673315 max memory_allocated 22563.28857421875 
[2025-03-02 09:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.17323285341262817 norm:0.00022324122255668044 max memory_allocated 22563.28857421875 
[2025-03-02 09:06:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.17310184240341187 norm:0.00019817714928649366 max memory_allocated 22563.28857421875 
[2025-03-02 09:06:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.17298701405525208 norm:0.00018175956211052835 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.17292743921279907 norm:0.00017460524395573884 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.1728774905204773 norm:0.0001681686844676733 max memory_allocated 22563.28857421875 
[2025-03-02 09:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.17286430299282074 norm:0.00016662933921907097 max memory_allocated 22563.28857421875 
[2025-03-02 09:09:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.1728449910879135 norm:0.00016633023915346712 max memory_allocated 22563.28857421875 
[2025-03-02 09:09:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.17279182374477386 norm:0.00016457642777822912 max memory_allocated 22563.28857421875 
[2025-03-02 09:10:12 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.1727946400642395 norm:0.00016105538816191256 max memory_allocated 22563.28857421875 
[2025-03-02 09:10:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.1727927029132843 norm:0.00016109587159007788 max memory_allocated 22563.28857421875 
[2025-03-02 09:11:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.17276303470134735 norm:0.00015674591122660786 max memory_allocated 22563.28857421875 
[2025-03-02 09:11:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.17275939881801605 norm:0.000157783244503662 max memory_allocated 22563.28857421875 
[2025-03-02 09:12:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.17274530231952667 norm:0.00015887929475866258 max memory_allocated 22563.28857421875 
[2025-03-02 09:12:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.17273269593715668 norm:0.0001584374695084989 max memory_allocated 22563.28857421875 
[2025-03-02 09:13:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 09:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.21544249355793 norm:0.005316249560564756 max memory_allocated 22563.46044921875 
[2025-03-02 09:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.20914235711097717 norm:0.002728957450017333 max memory_allocated 22563.46044921875 
[2025-03-02 09:14:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.20404180884361267 norm:0.0016571850283071399 max memory_allocated 22563.46044921875 
[2025-03-02 09:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.20103558897972107 norm:0.0011010344605892897 max memory_allocated 22563.46044921875 
[2025-03-02 09:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.2002723515033722 norm:0.0007936539477668703 max memory_allocated 22563.46044921875 
[2025-03-02 09:16:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.19993150234222412 norm:0.0006102070328779519 max memory_allocated 22563.46044921875 
[2025-03-02 09:17:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.19971469044685364 norm:0.00048201967729255557 max memory_allocated 22563.46044921875 
[2025-03-02 09:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.1995343416929245 norm:0.00039982068119570613 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.19941352307796478 norm:0.00034383981255814433 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.19929543137550354 norm:0.0003060207818634808 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.19922271370887756 norm:0.00027747248532250524 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:54 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.19916263222694397 norm:0.00025597790954634547 max memory_allocated 22563.46044921875 
[2025-03-02 09:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.1991034597158432 norm:0.00024123374896589667 max memory_allocated 22563.46044921875 
[2025-03-02 09:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.19906051456928253 norm:0.00023372798750642687 max memory_allocated 22563.46044921875 
[2025-03-02 09:21:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.19902072846889496 norm:0.00022596836788579822 max memory_allocated 22563.46044921875 
[2025-03-02 09:22:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.19902849197387695 norm:0.00022551910660695285 max memory_allocated 22563.46044921875 
[2025-03-02 09:22:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.19902725517749786 norm:0.00021613307762891054 max memory_allocated 22563.46044921875 
[2025-03-02 09:23:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.19896212220191956 norm:0.00021076771372463554 max memory_allocated 22563.46044921875 
[2025-03-02 09:23:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.198917955160141 norm:0.0002062627172563225 max memory_allocated 22563.46044921875 
[2025-03-02 09:24:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.19889789819717407 norm:0.00020682437752839178 max memory_allocated 22563.46044921875 
[2025-03-02 09:24:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 09:25:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.24119755625724792 norm:0.003036963054910302 max memory_allocated 22563.63232421875 
[2025-03-02 09:25:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.23611658811569214 norm:0.0015757111832499504 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.2311868667602539 norm:0.0010027524549514055 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.2284007966518402 norm:0.0006950298557057977 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.22780457139015198 norm:0.0005491669871844351 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.2275913655757904 norm:0.000458122871350497 max memory_allocated 22563.63232421875 
[2025-03-02 09:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.227418452501297 norm:0.0003830547211691737 max memory_allocated 22563.63232421875 
[2025-03-02 09:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.22722752392292023 norm:0.00032397996983490884 max memory_allocated 22563.63232421875 
[2025-03-02 09:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.22713826596736908 norm:0.00029061283566989005 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.22705577313899994 norm:0.0002645131025929004 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.22697517275810242 norm:0.00025377163547091186 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.22689107060432434 norm:0.0002374066098127514 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.22686737775802612 norm:0.0002246444346383214 max memory_allocated 22563.63232421875 
[2025-03-02 09:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.22686904668807983 norm:0.00021174969151616096 max memory_allocated 22563.63232421875 
[2025-03-02 09:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.22684070467948914 norm:0.00021017547987867147 max memory_allocated 22563.63232421875 
[2025-03-02 09:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.22677454352378845 norm:0.00019626419816631824 max memory_allocated 22563.63232421875 
[2025-03-02 09:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.22675465047359467 norm:0.0001976747444132343 max memory_allocated 22563.63232421875 
[2025-03-02 09:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.22673636674880981 norm:0.0001944159303093329 max memory_allocated 22563.63232421875 
[2025-03-02 09:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.22671763598918915 norm:0.00019014941062778234 max memory_allocated 22563.63232421875 
[2025-03-02 09:35:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.22669970989227295 norm:0.00018681856454350054 max memory_allocated 22563.63232421875 
[2025-03-02 09:35:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 09:36:00 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.2796579897403717 norm:0.00816630944609642 max memory_allocated 22563.91943359375 
[2025-03-02 09:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.27374905347824097 norm:0.006905430927872658 max memory_allocated 22563.91943359375 
[2025-03-02 09:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.26784369349479675 norm:0.00536715891212225 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.26497042179107666 norm:0.004706607665866613 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.2643113136291504 norm:0.0041497983038425446 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.2638806402683258 norm:0.0036440046969801188 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.26359570026397705 norm:0.0033295152243226767 max memory_allocated 22563.91943359375 
[2025-03-02 09:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.2634449005126953 norm:0.0031456139404326677 max memory_allocated 22563.91943359375 
[2025-03-02 09:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.2633916139602661 norm:0.003204700304195285 max memory_allocated 22563.91943359375 
[2025-03-02 09:41:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.2633100152015686 norm:0.00279100495390594 max memory_allocated 22563.91943359375 
[2025-03-02 09:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.2631392776966095 norm:0.0028766533359885216 max memory_allocated 22563.91943359375 
[2025-03-02 09:42:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.26307791471481323 norm:0.0026287198998034 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.2630666494369507 norm:0.002729442436248064 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.2630307376384735 norm:0.002515846863389015 max memory_allocated 22563.91943359375 
[2025-03-02 09:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.26297372579574585 norm:0.0025880644097924232 max memory_allocated 22563.91943359375 
[2025-03-02 09:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.2629287540912628 norm:0.002406009007245302 max memory_allocated 22563.91943359375 
[2025-03-02 09:45:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.2628490626811981 norm:0.002444653073325753 max memory_allocated 22563.91943359375 
[2025-03-02 09:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.2628273069858551 norm:0.0023547164164483547 max memory_allocated 22563.91943359375 
[2025-03-02 09:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.2628047466278076 norm:0.0023660871665924788 max memory_allocated 22563.91943359375 
[2025-03-02 09:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.2627647817134857 norm:0.002297072671353817 max memory_allocated 22563.91943359375 
[2025-03-02 09:47:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 09:47:26 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.3262764811515808 norm:0.008587422780692577 max memory_allocated 22564.09130859375 
[2025-03-02 09:48:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.319260835647583 norm:0.006584641057997942 max memory_allocated 22564.09130859375 
[2025-03-02 09:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.3127364218235016 norm:0.005280022509396076 max memory_allocated 22564.09130859375 
[2025-03-02 09:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.3097885549068451 norm:0.004373885691165924 max memory_allocated 22564.09130859375 
[2025-03-02 09:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.3090992867946625 norm:0.003716922365128994 max memory_allocated 22564.09130859375 
[2025-03-02 09:50:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.3086846172809601 norm:0.0032939654774963856 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.30846482515335083 norm:0.0030184988863766193 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.30831071734428406 norm:0.0030753114260733128 max memory_allocated 22564.09130859375 
[2025-03-02 09:52:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.3084567189216614 norm:0.00271993363276124 max memory_allocated 22564.09130859375 
[2025-03-02 09:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.3080425560474396 norm:0.0028237290680408478 max memory_allocated 22564.09130859375 
[2025-03-02 09:53:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.30789056420326233 norm:0.0025448650121688843 max memory_allocated 22564.09130859375 
[2025-03-02 09:54:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.30774450302124023 norm:0.002632182789966464 max memory_allocated 22564.09130859375 
[2025-03-02 09:54:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.30767038464546204 norm:0.00252043129876256 max memory_allocated 22564.09130859375 
[2025-03-02 09:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.3076207935810089 norm:0.002557233674451709 max memory_allocated 22564.09130859375 
[2025-03-02 09:55:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.3075801432132721 norm:0.0024880997370928526 max memory_allocated 22564.09130859375 
[2025-03-02 09:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.3075827956199646 norm:0.0024273437447845936 max memory_allocated 22564.09130859375 
[2025-03-02 09:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.3075251877307892 norm:0.0024030364584177732 max memory_allocated 22564.09130859375 
[2025-03-02 09:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.3075840175151825 norm:0.0023639898281544447 max memory_allocated 22564.09130859375 
[2025-03-02 09:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.30750811100006104 norm:0.0023657504934817553 max memory_allocated 22564.09130859375 
[2025-03-02 09:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.30746960639953613 norm:0.0023079747334122658 max memory_allocated 22564.09130859375 
[2025-03-02 09:58:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:58:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:59:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.43519511818885803 norm:0.01748570241034031 max memory_allocated 22564.26318359375 
[2025-03-02 10:00:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.4144495725631714 norm:0.018178757280111313 max memory_allocated 22564.26318359375 
[2025-03-02 10:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.4032260775566101 norm:0.01844053715467453 max memory_allocated 22564.26318359375 
[2025-03-02 10:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.398578405380249 norm:0.018852826207876205 max memory_allocated 22564.26318359375 
[2025-03-02 10:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.396281361579895 norm:0.019454576075077057 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.3946991562843323 norm:0.01969176158308983 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.3935268223285675 norm:0.01822667010128498 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.39282432198524475 norm:0.01750284992158413 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.39240771532058716 norm:0.017034512013196945 max memory_allocated 22564.26318359375 
[2025-03-02 10:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.391865074634552 norm:0.01633388176560402 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.39178210496902466 norm:0.016398336738348007 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.3913903534412384 norm:0.015245139598846436 max memory_allocated 22564.26318359375 
[2025-03-02 10:06:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.39104464650154114 norm:0.014805851504206657 max memory_allocated 22564.26318359375 
[2025-03-02 10:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.3907927870750427 norm:0.014648012816905975 max memory_allocated 22564.26318359375 
[2025-03-02 10:07:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.3905176818370819 norm:0.01416772324591875 max memory_allocated 22564.26318359375 
[2025-03-02 10:07:52 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.3904658854007721 norm:0.013981198891997337 max memory_allocated 22564.26318359375 
[2025-03-02 10:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.3905556797981262 norm:0.013631477952003479 max memory_allocated 22564.26318359375 
[2025-03-02 10:09:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.39056792855262756 norm:0.013435246422886848 max memory_allocated 22564.26318359375 
[2025-03-02 10:09:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.3903472423553467 norm:0.01313506718724966 max memory_allocated 22564.26318359375 
[2025-03-02 10:10:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.390271931886673 norm:0.013054756447672844 max memory_allocated 22564.26318359375 
[2025-03-02 10:10:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 10:10:20 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 10:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.7799525260925293 norm:0.0470166951417923 max memory_allocated 22564.43505859375 
[2025-03-02 10:11:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.7334839105606079 norm:0.03427416458725929 max memory_allocated 22564.43505859375 
[2025-03-02 10:12:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.7062948346138 norm:0.0290478877723217 max memory_allocated 22564.43505859375 
[2025-03-02 10:12:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.6907779574394226 norm:0.028192849829792976 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.6835025548934937 norm:0.029682204127311707 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.6782665252685547 norm:0.029542477801442146 max memory_allocated 22564.43505859375 
[2025-03-02 10:14:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.6737881302833557 norm:0.028049346059560776 max memory_allocated 22564.43505859375 
[2025-03-02 10:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.670861542224884 norm:0.02728934958577156 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.6694949865341187 norm:0.028988687321543694 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.6671468019485474 norm:0.028109807521104813 max memory_allocated 22564.43505859375 
[2025-03-02 10:16:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.6657137274742126 norm:0.027272971346974373 max memory_allocated 22564.43505859375 
[2025-03-02 10:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.6646189093589783 norm:0.027035972103476524 max memory_allocated 22564.43505859375 
[2025-03-02 10:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.6639218330383301 norm:0.026553193107247353 max memory_allocated 22564.43505859375 
[2025-03-02 10:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.6626635193824768 norm:0.026181388646364212 max memory_allocated 22564.43505859375 
[2025-03-02 10:18:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.6614797711372375 norm:0.024367835372686386 max memory_allocated 22564.43505859375 
[2025-03-02 10:19:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.6601064205169678 norm:0.023546753451228142 max memory_allocated 22564.43505859375 
[2025-03-02 10:19:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.6599209904670715 norm:0.023536473512649536 max memory_allocated 22564.43505859375 
[2025-03-02 10:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.6595755815505981 norm:0.0236936267465353 max memory_allocated 22564.43505859375 
[2025-03-02 10:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.6594226360321045 norm:0.024817585945129395 max memory_allocated 22564.43505859375 
[2025-03-02 10:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.6585654616355896 norm:0.02272881753742695 max memory_allocated 22564.43505859375 
[2025-03-02 10:21:43 root] (main_calib_config2.py 372): INFO 21891.439522981644
[2025-03-02 10:21:48 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 10:23:00 root] (main_calib_config2.py 159): INFO wikitext2 : 5.8259992599487305
[2025-03-02 10:23:00 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 10:24:50 root] (main_calib_config2.py 159): INFO c4 : 7.30157995223999
[2025-03-02 12:03:31 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.8259992599487305, 'c4': 7.30157995223999, 'results': {'boolq': {'acc': 0.7207951070336391, 'acc_stderr': 0.007846210712706131}, 'winogrande': {'acc': 0.6661404893449092, 'acc_stderr': 0.013254029695143358}, 'arc_challenge': {'acc': 0.37627986348122866, 'acc_stderr': 0.014157022555407165, 'acc_norm': 0.3993174061433447, 'acc_norm_stderr': 0.014312094557946704}, 'hellaswag': {'acc': 0.5535749850627365, 'acc_stderr': 0.004961054589573466, 'acc_norm': 0.7178848834893448, 'acc_norm_stderr': 0.004491093528113422}, 'piqa': {'acc': 0.7758433079434167, 'acc_stderr': 0.009729897956410057, 'acc_norm': 0.7698585418933623, 'acc_norm_stderr': 0.009820832826839798}, 'arc_easy': {'acc': 0.6620370370370371, 'acc_stderr': 0.009706080538632861, 'acc_norm': 0.5151515151515151, 'acc_norm_stderr': 0.010255071794531506}}, 'versions': {'boolq': 1, 'winogrande': 0, 'arc_challenge': 0, 'hellaswag': 0, 'piqa': 0, 'arc_easy': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
