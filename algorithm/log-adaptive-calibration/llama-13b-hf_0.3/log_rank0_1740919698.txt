[2025-03-02 12:48:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.3', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.3.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.3.pkl
[2025-03-02 12:52:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.07382093369960785 norm:0.04706533998250961 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.04732828587293625 norm:0.02581613138318062 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.03760632872581482 norm:0.015862273052334785 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.03386865183711052 norm:0.013546709902584553 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.03241103142499924 norm:0.012123688124120235 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.031513314694166183 norm:0.010835597291588783 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.03074812889099121 norm:0.009438127279281616 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.030326280742883682 norm:0.008630344644188881 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.03007977455854416 norm:0.007801693398505449 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.029664786532521248 norm:0.006761795841157436 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.029590753838419914 norm:0.00635911338031292 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.029289374127984047 norm:0.005625772289931774 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.029256600886583328 norm:0.005304331891238689 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.029193999245762825 norm:0.004888896364718676 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.029109563678503036 norm:0.004511295817792416 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.029068347066640854 norm:0.004285351373255253 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.029012508690357208 norm:0.0040329755283892155 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.02899215742945671 norm:0.00390634685754776 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.029070476070046425 norm:0.0038151037879288197 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.028943980112671852 norm:0.003566955216228962 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:25 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.22326305508613586 norm:0.0754493921995163 max memory_allocated 29268.20751953125 
[2025-03-02 13:11:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.1435331404209137 norm:0.03232031688094139 max memory_allocated 29268.20751953125 
[2025-03-02 13:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.10956133902072906 norm:0.018501698970794678 max memory_allocated 29268.20751953125 
[2025-03-02 13:12:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.09482390433549881 norm:0.014108611270785332 max memory_allocated 29268.20751953125 
[2025-03-02 13:13:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.08798455446958542 norm:0.012024507857859135 max memory_allocated 29268.20751953125 
[2025-03-02 13:14:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.08430510759353638 norm:0.01064461749047041 max memory_allocated 29268.20751953125 
[2025-03-02 13:15:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.08173929154872894 norm:0.009334294125437737 max memory_allocated 29268.20751953125 
[2025-03-02 13:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.0800396054983139 norm:0.00824500247836113 max memory_allocated 29268.20751953125 
[2025-03-02 13:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.07874475419521332 norm:0.007446109317243099 max memory_allocated 29268.20751953125 
[2025-03-02 13:17:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.07786392420530319 norm:0.006735645700246096 max memory_allocated 29268.20751953125 
[2025-03-02 13:18:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.0771525502204895 norm:0.006034304853528738 max memory_allocated 29268.20751953125 
[2025-03-02 13:19:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.07667399942874908 norm:0.00545360054820776 max memory_allocated 29268.20751953125 
[2025-03-02 13:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.076237753033638 norm:0.005027693696320057 max memory_allocated 29268.20751953125 
[2025-03-02 13:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.07591748982667923 norm:0.004709357395768166 max memory_allocated 29268.20751953125 
[2025-03-02 13:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.07566457241773605 norm:0.0047529940493404865 max memory_allocated 29268.20751953125 
[2025-03-02 13:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.07554823160171509 norm:0.004892281256616116 max memory_allocated 29268.20751953125 
[2025-03-02 13:23:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.07552487403154373 norm:0.00466999551281333 max memory_allocated 29268.20751953125 
[2025-03-02 13:24:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.07527397572994232 norm:0.004535767715424299 max memory_allocated 29268.20751953125 
[2025-03-02 13:25:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.07529976963996887 norm:0.0043959119357168674 max memory_allocated 29268.20751953125 
[2025-03-02 13:25:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.07511907070875168 norm:0.004288501106202602 max memory_allocated 29268.20751953125 
[2025-03-02 13:26:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:17 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.23254770040512085 norm:0.038420334458351135 max memory_allocated 29268.20751953125 
[2025-03-02 13:27:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.19239649176597595 norm:0.026603277772665024 max memory_allocated 29268.20751953125 
[2025-03-02 13:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.1711714267730713 norm:0.018749436363577843 max memory_allocated 29268.20751953125 
[2025-03-02 13:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.1600790023803711 norm:0.014821844175457954 max memory_allocated 29268.20751953125 
[2025-03-02 13:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.15448243916034698 norm:0.014211959205567837 max memory_allocated 29268.20751953125 
[2025-03-02 13:31:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.1508888304233551 norm:0.014274726621806622 max memory_allocated 29268.20751953125 
[2025-03-02 13:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.1473902314901352 norm:0.014307618141174316 max memory_allocated 29268.20751953125 
[2025-03-02 13:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.14526093006134033 norm:0.014761754311621189 max memory_allocated 29268.20751953125 
[2025-03-02 13:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.14302246272563934 norm:0.0147238215431571 max memory_allocated 29268.20751953125 
[2025-03-02 13:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.14134462177753448 norm:0.014346852898597717 max memory_allocated 29268.20751953125 
[2025-03-02 13:35:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.14037813246250153 norm:0.01435994915664196 max memory_allocated 29268.20751953125 
[2025-03-02 13:36:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.13824008405208588 norm:0.014276528730988503 max memory_allocated 29268.20751953125 
[2025-03-02 13:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.13684725761413574 norm:0.013718864880502224 max memory_allocated 29268.20751953125 
[2025-03-02 13:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.13646331429481506 norm:0.013682909309864044 max memory_allocated 29268.20751953125 
[2025-03-02 13:38:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.13495756685733795 norm:0.013532211072742939 max memory_allocated 29268.20751953125 
[2025-03-02 13:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.13614678382873535 norm:0.015218665823340416 max memory_allocated 29268.20751953125 
[2025-03-02 13:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.1334562748670578 norm:0.01381644420325756 max memory_allocated 29268.20751953125 
[2025-03-02 13:41:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.13376426696777344 norm:0.014406537637114525 max memory_allocated 29268.20751953125 
[2025-03-02 13:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.13370099663734436 norm:0.013174358755350113 max memory_allocated 29268.20751953125 
[2025-03-02 13:42:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.13291485607624054 norm:0.013455214910209179 max memory_allocated 29268.20751953125 
[2025-03-02 13:43:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.23341090977191925 norm:0.02894970029592514 max memory_allocated 29268.43798828125 
[2025-03-02 13:44:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.2045016586780548 norm:0.012528260238468647 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.1791139841079712 norm:0.005659996531903744 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.17065748572349548 norm:0.00403040274977684 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.1673477590084076 norm:0.003425170900300145 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.16430899500846863 norm:0.002835993655025959 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.1628955602645874 norm:0.0026763668283820152 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.16197672486305237 norm:0.0024964148178696632 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.16014038026332855 norm:0.0019892966374754906 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.1593473106622696 norm:0.0018538202857598662 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.1591373085975647 norm:0.0018571083201095462 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.158436119556427 norm:0.0017248888034373522 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.1583460569381714 norm:0.0017120845150202513 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.1578994244337082 norm:0.0015619683545082808 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.15738150477409363 norm:0.0014764948282390833 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.15722109377384186 norm:0.0014993580989539623 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.15725134313106537 norm:0.0014957021921873093 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.15745726227760315 norm:0.0014897040091454983 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.15765562653541565 norm:0.001471622847020626 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.15768292546272278 norm:0.0014614707324653864 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:00:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.27361273765563965 norm:0.0265335813164711 max memory_allocated 29268.62548828125 
[2025-03-02 14:01:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.2407614290714264 norm:0.007264268584549427 max memory_allocated 29268.62548828125 
[2025-03-02 14:02:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.21858198940753937 norm:0.00391634926199913 max memory_allocated 29268.62548828125 
[2025-03-02 14:03:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.21075031161308289 norm:0.0029960856772959232 max memory_allocated 29268.62548828125 
[2025-03-02 14:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.20645594596862793 norm:0.002259623259305954 max memory_allocated 29268.62548828125 
[2025-03-02 14:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.20334187150001526 norm:0.0018515067640691996 max memory_allocated 29268.62548828125 
[2025-03-02 14:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.2012554556131363 norm:0.0016703124856576324 max memory_allocated 29268.62548828125 
[2025-03-02 14:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.19982682168483734 norm:0.0015724438708275557 max memory_allocated 29268.62548828125 
[2025-03-02 14:07:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.19876715540885925 norm:0.0015106422360986471 max memory_allocated 29268.62548828125 
[2025-03-02 14:08:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.19813957810401917 norm:0.0014326238306239247 max memory_allocated 29268.62548828125 
[2025-03-02 14:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.19768087565898895 norm:0.0013918537879362702 max memory_allocated 29268.62548828125 
[2025-03-02 14:09:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.19732727110385895 norm:0.0013989462750032544 max memory_allocated 29268.62548828125 
[2025-03-02 14:10:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.1969912052154541 norm:0.0014037761138752103 max memory_allocated 29268.62548828125 
[2025-03-02 14:11:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.19688427448272705 norm:0.0014419053914025426 max memory_allocated 29268.62548828125 
[2025-03-02 14:12:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.19666212797164917 norm:0.0014450213639065623 max memory_allocated 29268.62548828125 
[2025-03-02 14:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.1965051293373108 norm:0.0014742347411811352 max memory_allocated 29268.62548828125 
[2025-03-02 14:14:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.1964959055185318 norm:0.0014864972326904535 max memory_allocated 29268.62548828125 
[2025-03-02 14:14:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.19630633294582367 norm:0.0014715479919686913 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.196049764752388 norm:0.0014290324179455638 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.19588249921798706 norm:0.001389328041113913 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.33524778485298157 norm:0.05939975008368492 max memory_allocated 29268.81298828125 
[2025-03-02 14:18:29 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.28926748037338257 norm:0.02051539719104767 max memory_allocated 29268.81298828125 
[2025-03-02 14:19:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.2524562478065491 norm:0.006539149209856987 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.24164383113384247 norm:0.004517873749136925 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.2365819811820984 norm:0.0037122173234820366 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.23319615423679352 norm:0.003253011964261532 max memory_allocated 29268.81298828125 
[2025-03-02 14:22:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.23092147707939148 norm:0.002956325886771083 max memory_allocated 29268.81298828125 
[2025-03-02 14:23:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.22945433855056763 norm:0.0027272459119558334 max memory_allocated 29268.81298828125 
[2025-03-02 14:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.22842934727668762 norm:0.0025564529933035374 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.2275473028421402 norm:0.0023187994956970215 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.2266249656677246 norm:0.0021037920378148556 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.22641852498054504 norm:0.002080959267914295 max memory_allocated 29268.81298828125 
[2025-03-02 14:27:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.22634366154670715 norm:0.0020921817049384117 max memory_allocated 29268.81298828125 
[2025-03-02 14:28:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.22571100294589996 norm:0.0019362568855285645 max memory_allocated 29268.81298828125 
[2025-03-02 14:29:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.22512784600257874 norm:0.0017670325469225645 max memory_allocated 29268.81298828125 
[2025-03-02 14:30:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.22480836510658264 norm:0.0017219710862264037 max memory_allocated 29268.81298828125 
[2025-03-02 14:30:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.224709615111351 norm:0.0016175745986402035 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.2246054708957672 norm:0.0015690141590312123 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.22431841492652893 norm:0.0015417487593367696 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.224299356341362 norm:0.0015030915383249521 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:34:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.3840753138065338 norm:0.015142648480832577 max memory_allocated 29269.00048828125 
[2025-03-02 14:35:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.3489144742488861 norm:0.008099477738142014 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.3180842995643616 norm:0.004990164190530777 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.30854934453964233 norm:0.003513374598696828 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.30321091413497925 norm:0.002905020723119378 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.29591330885887146 norm:0.003303470555692911 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:27 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.2953028976917267 norm:0.004005619790405035 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.2898429036140442 norm:0.0030378454830497503 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.28780388832092285 norm:0.0028903360944241285 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.2869432270526886 norm:0.002857613144442439 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.2863490879535675 norm:0.0028756994288414717 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.28556472063064575 norm:0.002951506758108735 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.28471365571022034 norm:0.002957915421575308 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.28403350710868835 norm:0.0029865149408578873 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.28393107652664185 norm:0.0031058411113917828 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.2835516929626465 norm:0.0033727632835507393 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.28460782766342163 norm:0.00319181801751256 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:33 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.2841648459434509 norm:0.0029808434192091227 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.2835419774055481 norm:0.002979051787406206 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.28293904662132263 norm:0.0032586464658379555 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:51:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.4004603922367096 norm:0.019571151584386826 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.3688090443611145 norm:0.009563005529344082 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.3315443694591522 norm:0.0038960364181548357 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.31690654158592224 norm:0.002245340496301651 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.31096819043159485 norm:0.0017161552095785737 max memory_allocated 29269.18798828125 
[2025-03-02 14:55:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.3072688579559326 norm:0.001450278447009623 max memory_allocated 29269.18798828125 
[2025-03-02 14:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.30464714765548706 norm:0.001296916976571083 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.30258065462112427 norm:0.0011912619229406118 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.30094456672668457 norm:0.0011044653365388513 max memory_allocated 29269.18798828125 
[2025-03-02 14:58:47 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.29984140396118164 norm:0.0010542848613113165 max memory_allocated 29269.18798828125 
[2025-03-02 14:59:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.2989667057991028 norm:0.0010130940936505795 max memory_allocated 29269.18798828125 
[2025-03-02 15:00:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.2983027398586273 norm:0.0009838484693318605 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.2978825569152832 norm:0.0009758648811839521 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.29751837253570557 norm:0.0009722627582959831 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.297156423330307 norm:0.0009596076561138034 max memory_allocated 29269.18798828125 
[2025-03-02 15:03:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.296889990568161 norm:0.0009496306302025914 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.2965863347053528 norm:0.000972368405200541 max memory_allocated 29269.18798828125 
[2025-03-02 15:05:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.2964226007461548 norm:0.0009403930744156241 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.29628726840019226 norm:0.0009398417314514518 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.29627925157546997 norm:0.0009271177113987505 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:08:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.42142072319984436 norm:0.018233876675367355 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.38759756088256836 norm:0.009457342326641083 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.3513493537902832 norm:0.0039344672113657 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.33547890186309814 norm:0.002168315928429365 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.3297894299030304 norm:0.001678184955380857 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.3258342146873474 norm:0.001303254859521985 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.32301193475723267 norm:0.0011417325586080551 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.32107406854629517 norm:0.0010385230416432023 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.31969380378723145 norm:0.0009828831534832716 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.31859612464904785 norm:0.0009463129681535065 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.3179003894329071 norm:0.0009517034632153809 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.3173310458660126 norm:0.0009295142954215407 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.31699103116989136 norm:0.0009202956571243703 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.31662172079086304 norm:0.0009263415122404695 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.31631404161453247 norm:0.0009231087169609964 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.31604519486427307 norm:0.0009108360391110182 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.3158559203147888 norm:0.0009045399492606521 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:14 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.3157369792461395 norm:0.0008984077721834183 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.31567394733428955 norm:0.0008965931483544409 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.31555381417274475 norm:0.0008884893613867462 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:25:01 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.4524180293083191 norm:0.01822168193757534 max memory_allocated 29269.56298828125 
[2025-03-02 15:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.4103359878063202 norm:0.008538427762687206 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.3680550158023834 norm:0.0033564071636646986 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.35359489917755127 norm:0.0017385318642482162 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.34853994846343994 norm:0.0013704242883250117 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.34510403871536255 norm:0.0011381354415789247 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.3426537811756134 norm:0.001034286106005311 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.34072721004486084 norm:0.00099118088837713 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.33948108553886414 norm:0.0009558891179040074 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.33862772583961487 norm:0.0009533488191664219 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.33792737126350403 norm:0.0009242040105164051 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.3373986780643463 norm:0.0009198049665428698 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.33690187335014343 norm:0.0008976645185612142 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.3365984261035919 norm:0.0008889644523151219 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.3363291919231415 norm:0.0008900159737095237 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.33600595593452454 norm:0.0008911108016036451 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.3356841206550598 norm:0.0008654666016809642 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.33550697565078735 norm:0.0008482707780785859 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.3353317379951477 norm:0.0008368100970983505 max memory_allocated 29269.56298828125 
[2025-03-02 15:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.3351486623287201 norm:0.0008399522630497813 max memory_allocated 29269.56298828125 
[2025-03-02 15:40:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.45279207825660706 norm:0.027073100209236145 max memory_allocated 29269.75048828125 
[2025-03-02 15:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.4241579473018646 norm:0.011812319979071617 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.38675838708877563 norm:0.003879762487486005 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.37253159284591675 norm:0.001859573065303266 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.3674355149269104 norm:0.0014490422327071428 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.36436814069747925 norm:0.0012694306205958128 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.3619503378868103 norm:0.0011257755104452372 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.36023300886154175 norm:0.0010458211181685328 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.3590331971645355 norm:0.0010369594674557447 max memory_allocated 29269.75048828125 
[2025-03-02 15:49:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.35783255100250244 norm:0.0009529401431791484 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.3569178581237793 norm:0.0009246131521649659 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.3562096059322357 norm:0.0008960302220657468 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.3557334840297699 norm:0.0008506187587045133 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.35534003376960754 norm:0.0008261461043730378 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.3549928665161133 norm:0.0008141002035699785 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.3546757698059082 norm:0.0007974979816935956 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.3544486463069916 norm:0.0007934054592624307 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.35423383116722107 norm:0.0007805805653333664 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.3541330099105835 norm:0.0007689754129387438 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.3540162444114685 norm:0.0007703647715970874 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.4836153984069824 norm:0.020592838525772095 max memory_allocated 29269.93798828125 
[2025-03-02 15:59:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.44827917218208313 norm:0.008903613314032555 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.409294068813324 norm:0.003563546808436513 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.3942215144634247 norm:0.0017396496841683984 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.3891316056251526 norm:0.0013084311503916979 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.3858134150505066 norm:0.0011270835530012846 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.383461058139801 norm:0.001055653439834714 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.381633996963501 norm:0.0009771037148311734 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.3802785575389862 norm:0.0009211569558829069 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.37945088744163513 norm:0.0009025487233884633 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.3786586821079254 norm:0.0008638779981993139 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.3780463635921478 norm:0.0008270010002888739 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.3776259422302246 norm:0.0008139387355186045 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.3772675096988678 norm:0.000808802607934922 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.37696734070777893 norm:0.0007996464846655726 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.37674006819725037 norm:0.0007786412024870515 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.3765026926994324 norm:0.0007730962242931128 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.3763066530227661 norm:0.0007691944483667612 max memory_allocated 29269.93798828125 
[2025-03-02 16:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.3761604428291321 norm:0.0007662754505872726 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.37601810693740845 norm:0.000765172007959336 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.4951498806476593 norm:0.022899804636836052 max memory_allocated 29270.12548828125 
[2025-03-02 16:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.4633597731590271 norm:0.0087171895429492 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.43220648169517517 norm:0.0038781079929322004 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.41795632243156433 norm:0.0018214908195659518 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.41221189498901367 norm:0.0013268000911921263 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.4085680842399597 norm:0.0011414028704166412 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.4058229327201843 norm:0.0010396335273981094 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.40395644307136536 norm:0.0009902797173708677 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.4023568332195282 norm:0.0009364550351165235 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.401330828666687 norm:0.000919658225029707 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.400593101978302 norm:0.0009123662021011114 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.3998667597770691 norm:0.0009018455748446286 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.3992960751056671 norm:0.0008815720211714506 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.3987792730331421 norm:0.0008813018212094903 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.39829444885253906 norm:0.0008869229350239038 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.3978702425956726 norm:0.000886880443431437 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.39757826924324036 norm:0.0008624918991699815 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.3974778354167938 norm:0.0008470761822536588 max memory_allocated 29270.12548828125 
[2025-03-02 16:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.3973122239112854 norm:0.0008374993340112269 max memory_allocated 29270.12548828125 
[2025-03-02 16:31:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.3971806466579437 norm:0.0008442730759270489 max memory_allocated 29270.12548828125 
[2025-03-02 16:31:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.5035337209701538 norm:0.008564765565097332 max memory_allocated 29270.31298828125 
[2025-03-02 16:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.4775870144367218 norm:0.00468079000711441 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.4510882496833801 norm:0.0024277193006128073 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.43972641229629517 norm:0.0015255945036187768 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.4346538782119751 norm:0.0012407320318743587 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.4313231110572815 norm:0.0011186384363099933 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.42889639735221863 norm:0.0010489235864952207 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.4270451068878174 norm:0.0010254952358081937 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.4256327748298645 norm:0.0009973691776394844 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.4244435131549835 norm:0.0009757358347997069 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.42346280813217163 norm:0.0009534029522910714 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.42265743017196655 norm:0.0009450771030969918 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:21 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.42196401953697205 norm:0.0009501418098807335 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.4214375615119934 norm:0.000943566148635 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.4210491478443146 norm:0.000928821973502636 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.42068803310394287 norm:0.0009067205828614533 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:40 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.42041733860969543 norm:0.0008977491525001824 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.4202771484851837 norm:0.0008921811240725219 max memory_allocated 29270.31298828125 
[2025-03-02 16:47:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.4201914072036743 norm:0.0008926204754970968 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.4200834333896637 norm:0.0008923305431380868 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.5112176537513733 norm:0.018334131687879562 max memory_allocated 29270.50048828125 
[2025-03-02 16:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.49064409732818604 norm:0.009340542368590832 max memory_allocated 29270.50048828125 
[2025-03-02 16:50:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.47245514392852783 norm:0.0055434624664485455 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.4632987082004547 norm:0.0029511298052966595 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.45815905928611755 norm:0.0018898025155067444 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.4545634388923645 norm:0.0015034526586532593 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.4518660604953766 norm:0.001306857680901885 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.4496399164199829 norm:0.0010217273375019431 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.4480774700641632 norm:0.0009786055888980627 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.4468633830547333 norm:0.0009478472638875246 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.44597575068473816 norm:0.0009299808880314231 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.4452422261238098 norm:0.0009111568797379732 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.44466689229011536 norm:0.000904740416444838 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.44422560930252075 norm:0.0008967971662059426 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.44387930631637573 norm:0.0008897734223864973 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.44357210397720337 norm:0.0008890162571333349 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.44329163432121277 norm:0.0008897106745280325 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.44302821159362793 norm:0.000888482725713402 max memory_allocated 29270.50048828125 
[2025-03-02 17:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.44287770986557007 norm:0.000887734058778733 max memory_allocated 29270.50048828125 
[2025-03-02 17:05:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.4427134692668915 norm:0.0008881819667294621 max memory_allocated 29270.50048828125 
[2025-03-02 17:05:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.5771304965019226 norm:0.06833088397979736 max memory_allocated 29270.68798828125 
[2025-03-02 17:06:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.5587533712387085 norm:0.038351282477378845 max memory_allocated 29270.68798828125 
[2025-03-02 17:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.5202580094337463 norm:0.012599615380167961 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.5043632388114929 norm:0.006171239539980888 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.49769896268844604 norm:0.004077418707311153 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.4936062693595886 norm:0.0029264779295772314 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.4908049404621124 norm:0.002637479454278946 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.4879556894302368 norm:0.0016508626285940409 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.4859541356563568 norm:0.001491742441430688 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.484485924243927 norm:0.0014227270148694515 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.48342788219451904 norm:0.0013930096756666899 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.4825361967086792 norm:0.0013574424665421247 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:03 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.48174816370010376 norm:0.0013098107883706689 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.4811308979988098 norm:0.0012680678628385067 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.480697363615036 norm:0.0012538679875433445 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:32 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.48037490248680115 norm:0.0012246714904904366 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.47986024618148804 norm:0.0011951786000281572 max memory_allocated 29270.68798828125 
[2025-03-02 17:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.4795052707195282 norm:0.0011972228530794382 max memory_allocated 29270.68798828125 
[2025-03-02 17:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.4793069660663605 norm:0.0011994491796940565 max memory_allocated 29270.68798828125 
[2025-03-02 17:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.4790971279144287 norm:0.0011893295450136065 max memory_allocated 29270.68798828125 
[2025-03-02 17:22:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:22:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.5576547980308533 norm:0.008415021002292633 max memory_allocated 29270.87548828125 
[2025-03-02 17:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.5439813137054443 norm:0.004188799764961004 max memory_allocated 29270.87548828125 
[2025-03-02 17:24:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.5310009717941284 norm:0.002459742594510317 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.5252751708030701 norm:0.0015991386026144028 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.522148609161377 norm:0.0012097933795303106 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.5198560357093811 norm:0.0010673095239326358 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.5178170800209045 norm:0.0009919739095494151 max memory_allocated 29270.87548828125 
[2025-03-02 17:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.5161596536636353 norm:0.0009491347009316087 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.5147178173065186 norm:0.000904516433365643 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.5136463046073914 norm:0.0008857769425958395 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.5127491354942322 norm:0.0008728830143809319 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.5119970440864563 norm:0.0008585218456573784 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.5113826394081116 norm:0.0008531586499884725 max memory_allocated 29270.87548828125 
[2025-03-02 17:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.5109739303588867 norm:0.000850310199894011 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.5105072855949402 norm:0.0008424253319390118 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.5101423263549805 norm:0.0008431934984400868 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.5098491907119751 norm:0.0008428730070590973 max memory_allocated 29270.87548828125 
[2025-03-02 17:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.5096040368080139 norm:0.0008369520073756576 max memory_allocated 29270.87548828125 
[2025-03-02 17:37:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.5093969702720642 norm:0.0008355457684956491 max memory_allocated 29270.87548828125 
[2025-03-02 17:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.5092486143112183 norm:0.0008375174948014319 max memory_allocated 29270.87548828125 
[2025-03-02 17:38:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:39:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.6301091909408569 norm:0.013280984945595264 max memory_allocated 29271.06298828125 
[2025-03-02 17:40:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.6070130467414856 norm:0.00709587661549449 max memory_allocated 29271.06298828125 
[2025-03-02 17:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.5810354948043823 norm:0.003694334998726845 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.5705137848854065 norm:0.0023777487222105265 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.5660645961761475 norm:0.0018653239822015166 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.5629841685295105 norm:0.0015466839540749788 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.5606229305267334 norm:0.0013762767193838954 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.5587968826293945 norm:0.0012651364086195827 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.5572015047073364 norm:0.0011984495213255286 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.5560151934623718 norm:0.0011507475282996893 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.5548520684242249 norm:0.0011009579757228494 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.5539930462837219 norm:0.00107486208435148 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.553232729434967 norm:0.0010529226856306195 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.5526401400566101 norm:0.0010329344077035785 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.5521731376647949 norm:0.0010094617027789354 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.5518635511398315 norm:0.0009981445036828518 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.5515002012252808 norm:0.0009799896506592631 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.5511725544929504 norm:0.0009576035081408918 max memory_allocated 29271.06298828125 
[2025-03-02 17:54:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.5509185791015625 norm:0.0009536333964206278 max memory_allocated 29271.06298828125 
[2025-03-02 17:55:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.5507304668426514 norm:0.0009516454883851111 max memory_allocated 29271.06298828125 
[2025-03-02 17:55:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:56:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.6732826232910156 norm:0.029667479917407036 max memory_allocated 29271.25048828125 
[2025-03-02 17:57:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.6561222672462463 norm:0.016252676025032997 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.6396438479423523 norm:0.009616471827030182 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.6317827105522156 norm:0.005846830550581217 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.6270628571510315 norm:0.004214913118630648 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.623839259147644 norm:0.0035342290066182613 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.6210737228393555 norm:0.002953900024294853 max memory_allocated 29271.25048828125 
[2025-03-02 18:02:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.6185392141342163 norm:0.002196162473410368 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.6169362664222717 norm:0.0021136547438800335 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.6155930757522583 norm:0.0019803422037512064 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.6142110824584961 norm:0.00160102522931993 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.6129317879676819 norm:0.00108653015922755 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.6121401786804199 norm:0.0010743916500359774 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.6115601062774658 norm:0.0010658601531758904 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.6111269593238831 norm:0.0010510253487154841 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.6108489632606506 norm:0.0010478193871676922 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.6105809807777405 norm:0.0010393296834081411 max memory_allocated 29271.25048828125 
[2025-03-02 18:10:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.6102503538131714 norm:0.0010366665665060282 max memory_allocated 29271.25048828125 
[2025-03-02 18:11:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.609973132610321 norm:0.001029147650115192 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.6096786856651306 norm:0.0010211628396064043 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:13:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.732947587966919 norm:0.013786029070615768 max memory_allocated 29271.43798828125 
[2025-03-02 18:14:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.7179372906684875 norm:0.007119398098438978 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.7035138010978699 norm:0.004011305049061775 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.6971885561943054 norm:0.0027186681982129812 max memory_allocated 29271.43798828125 
[2025-03-02 18:16:49 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.6936445832252502 norm:0.002304660389199853 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.6904994249343872 norm:0.0012722332030534744 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.6883718371391296 norm:0.0011948347091674805 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.6865810751914978 norm:0.001166434376500547 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.685193657875061 norm:0.001147278817370534 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.6840989589691162 norm:0.0011275253491476178 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.6831414699554443 norm:0.0011166755575686693 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.6824816465377808 norm:0.001110686338506639 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.681924045085907 norm:0.0010937061160802841 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.6814191341400146 norm:0.0010896275052800775 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.6809921264648438 norm:0.001086117816157639 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.6805455684661865 norm:0.0010780394077301025 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.6801685094833374 norm:0.0010736840777099133 max memory_allocated 29271.43798828125 
[2025-03-02 18:27:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.6799184679985046 norm:0.0010719459969550371 max memory_allocated 29271.43798828125 
[2025-03-02 18:28:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.679661750793457 norm:0.0010671040508896112 max memory_allocated 29271.43798828125 
[2025-03-02 18:29:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.6794047951698303 norm:0.0010626958683133125 max memory_allocated 29271.43798828125 
[2025-03-02 18:29:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:30:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.8139152526855469 norm:0.023525603115558624 max memory_allocated 29271.62548828125 
[2025-03-02 18:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.7972553372383118 norm:0.014102541841566563 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.7805510759353638 norm:0.008498990908265114 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.772651731967926 norm:0.004924973472952843 max memory_allocated 29271.62548828125 
[2025-03-02 18:33:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.7683212757110596 norm:0.0038267544005066156 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.765038788318634 norm:0.0031694683711975813 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.76263028383255 norm:0.002857399173080921 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.7606549859046936 norm:0.002436529379338026 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.7590635418891907 norm:0.002189906546846032 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.7578979134559631 norm:0.002112970920279622 max memory_allocated 29271.62548828125 
[2025-03-02 18:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.7560267448425293 norm:0.0012044472387060523 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.7554185390472412 norm:0.0011011608876287937 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.7548990845680237 norm:0.0010944324312731624 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.7543507814407349 norm:0.0010965196415781975 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.7538529634475708 norm:0.0010798497823998332 max memory_allocated 29271.62548828125 
[2025-03-02 18:42:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.7534578442573547 norm:0.0010809237137436867 max memory_allocated 29271.62548828125 
[2025-03-02 18:43:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.7531149983406067 norm:0.0010772871319204569 max memory_allocated 29271.62548828125 
[2025-03-02 18:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.7528024911880493 norm:0.0010753560345619917 max memory_allocated 29271.62548828125 
[2025-03-02 18:45:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.752565860748291 norm:0.0010686999885365367 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.7523907423019409 norm:0.0010679980041459203 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.9076639413833618 norm:0.0062231565825641155 max memory_allocated 29271.81298828125 
[2025-03-02 18:48:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.8915416598320007 norm:0.003656937275081873 max memory_allocated 29271.81298828125 
[2025-03-02 18:48:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.8749152421951294 norm:0.0023427007254213095 max memory_allocated 29271.81298828125 
[2025-03-02 18:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.8681403994560242 norm:0.0015528034418821335 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.8648085594177246 norm:0.0013743173331022263 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.8622493147850037 norm:0.0013048268156126142 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.8599402904510498 norm:0.0012525365455076098 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.858005940914154 norm:0.0012192117283120751 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.8566845655441284 norm:0.001209014211781323 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.8556312918663025 norm:0.0012043964816257358 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.8547030091285706 norm:0.0012004140298813581 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.8539220690727234 norm:0.0011929998872801661 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.8534046411514282 norm:0.00118256697896868 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.8528543710708618 norm:0.001182425650767982 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.8524815440177917 norm:0.0011895957868546247 max memory_allocated 29271.81298828125 
[2025-03-02 18:59:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.8520263433456421 norm:0.0011899643577635288 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.851700484752655 norm:0.0011838539503514767 max memory_allocated 29271.81298828125 
[2025-03-02 19:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.851380467414856 norm:0.0011740075424313545 max memory_allocated 29271.81298828125 
[2025-03-02 19:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.851088285446167 norm:0.0011678170412778854 max memory_allocated 29271.81298828125 
[2025-03-02 19:02:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.8508738279342651 norm:0.0011641549644991755 max memory_allocated 29271.81298828125 
[2025-03-02 19:03:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:04:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:1.0325992107391357 norm:0.016832318156957626 max memory_allocated 29272.00048828125 
[2025-03-02 19:04:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:1.0136871337890625 norm:0.008369687013328075 max memory_allocated 29272.00048828125 
[2025-03-02 19:05:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.9948221445083618 norm:0.004624567925930023 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.9865771532058716 norm:0.002411361550912261 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.9822565913200378 norm:0.0016368846409022808 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.9793790578842163 norm:0.0015344824641942978 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.9769477844238281 norm:0.001485629822127521 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.9750829935073853 norm:0.0014449600130319595 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.9737937450408936 norm:0.0014203621540218592 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.9725615382194519 norm:0.0013913277070969343 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.9716476202011108 norm:0.00137295201420784 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.9709310531616211 norm:0.0013666019076481462 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.9704035520553589 norm:0.0013544140383601189 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.9699893593788147 norm:0.0013448679819703102 max memory_allocated 29272.00048828125 
[2025-03-02 19:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.9695587754249573 norm:0.0013380872551351786 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.9691747426986694 norm:0.0013337924610823393 max memory_allocated 29272.00048828125 
[2025-03-02 19:17:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.9687966704368591 norm:0.0013282682048156857 max memory_allocated 29272.00048828125 
[2025-03-02 19:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.9684281945228577 norm:0.0013223346322774887 max memory_allocated 29272.00048828125 
[2025-03-02 19:18:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.9681533575057983 norm:0.0013188101584091783 max memory_allocated 29272.00048828125 
[2025-03-02 19:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.9678909778594971 norm:0.0013163699768483639 max memory_allocated 29272.00048828125 
[2025-03-02 19:20:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:20:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:1.1721471548080444 norm:0.01968885213136673 max memory_allocated 29272.18798828125 
[2025-03-02 19:21:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:1.1555061340332031 norm:0.011589692905545235 max memory_allocated 29272.18798828125 
[2025-03-02 19:22:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:1.1371843814849854 norm:0.006162323988974094 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:1.129379391670227 norm:0.002271378645673394 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:1.1254647970199585 norm:0.0018882020376622677 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:1.122438669204712 norm:0.001789068803191185 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:1.1199711561203003 norm:0.0017281360924243927 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:1.1180064678192139 norm:0.001682713977061212 max memory_allocated 29272.18798828125 
[2025-03-02 19:27:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:1.1165460348129272 norm:0.0016490680864080787 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:1.1153571605682373 norm:0.0016425923677161336 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:1.1144407987594604 norm:0.0016278558177873492 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:1.1136994361877441 norm:0.0016165808774530888 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:1.1130914688110352 norm:0.0016144472174346447 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:1.1125292778015137 norm:0.0016120582586154342 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:1.1120188236236572 norm:0.0016025196528062224 max memory_allocated 29272.18798828125 
[2025-03-02 19:33:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:1.111549973487854 norm:0.0015897173434495926 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:1.111129879951477 norm:0.0015793729107826948 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:1.110752820968628 norm:0.0015702922828495502 max memory_allocated 29272.18798828125 
[2025-03-02 19:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:1.110406517982483 norm:0.0015562830958515406 max memory_allocated 29272.18798828125 
[2025-03-02 19:36:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:1.1100102663040161 norm:0.0015375385992228985 max memory_allocated 29272.18798828125 
[2025-03-02 19:36:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:37:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:1.309868335723877 norm:0.013191466219723225 max memory_allocated 29272.37548828125 
[2025-03-02 19:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:1.2928967475891113 norm:0.0074689192697405815 max memory_allocated 29272.37548828125 
[2025-03-02 19:39:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:1.276114821434021 norm:0.004874605685472488 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:1.269438624382019 norm:0.003577033057808876 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:1.265336275100708 norm:0.0030335127376019955 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:1.2623205184936523 norm:0.0027004992589354515 max memory_allocated 29272.37548828125 
[2025-03-02 19:42:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:1.259507179260254 norm:0.002386988839134574 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:1.2574865818023682 norm:0.002154187997803092 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:1.256008505821228 norm:0.0019975414033979177 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:1.2547990083694458 norm:0.0018577687442302704 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:1.2538036108016968 norm:0.0017652601236477494 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:1.2529140710830688 norm:0.0016896071610972285 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:1.2521599531173706 norm:0.001629528938792646 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:1.2514199018478394 norm:0.001582335215061903 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:1.2508488893508911 norm:0.0015461230650544167 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:1.2504832744598389 norm:0.0015174783766269684 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:1.2500971555709839 norm:0.0014886269345879555 max memory_allocated 29272.37548828125 
[2025-03-02 19:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:1.2497142553329468 norm:0.0014754192670807242 max memory_allocated 29272.37548828125 
[2025-03-02 19:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:1.249393343925476 norm:0.001459389110095799 max memory_allocated 29272.37548828125 
[2025-03-02 19:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:1.2491580247879028 norm:0.001447986694984138 max memory_allocated 29272.37548828125 
[2025-03-02 19:53:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:1.471440076828003 norm:0.01825627312064171 max memory_allocated 29272.56298828125 
[2025-03-02 19:55:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:1.452286720275879 norm:0.010473069734871387 max memory_allocated 29272.56298828125 
[2025-03-02 19:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:1.4325271844863892 norm:0.006144724320620298 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:1.4244334697723389 norm:0.0037106196396052837 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:1.4193148612976074 norm:0.0015765891876071692 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:1.4160622358322144 norm:0.0014687794027850032 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:1.4134632349014282 norm:0.0014248694060370326 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:1.4115300178527832 norm:0.0014016071800142527 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:1.4101448059082031 norm:0.0013972168089821935 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:1.4089891910552979 norm:0.0013937688199803233 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:1.4081952571868896 norm:0.0013922069920226932 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:1.4073588848114014 norm:0.0013855014694854617 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:1.406489610671997 norm:0.0013752756640315056 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:1.4056929349899292 norm:0.0013728251215070486 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:1.4053152799606323 norm:0.0013725240714848042 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:1.405001163482666 norm:0.0013713224325329065 max memory_allocated 29272.56298828125 
[2025-03-02 20:07:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:1.4046564102172852 norm:0.001368479453958571 max memory_allocated 29272.56298828125 
[2025-03-02 20:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:1.4044619798660278 norm:0.0013628869783133268 max memory_allocated 29272.56298828125 
[2025-03-02 20:09:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:1.4041532278060913 norm:0.0013629508903250098 max memory_allocated 29272.56298828125 
[2025-03-02 20:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:1.4038952589035034 norm:0.0013651743065565825 max memory_allocated 29272.56298828125 
[2025-03-02 20:10:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:11:25 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:1.629149317741394 norm:0.0141085684299469 max memory_allocated 29272.75048828125 
[2025-03-02 20:12:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:1.6096638441085815 norm:0.007689655292779207 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:1.5891776084899902 norm:0.004690122790634632 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:1.5809564590454102 norm:0.0023255906999111176 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:1.5769085884094238 norm:0.0016588756116107106 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:1.5735743045806885 norm:0.001460572239011526 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:1.5708158016204834 norm:0.0013507389230653644 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:1.5687288045883179 norm:0.001327094971202314 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:1.5673073530197144 norm:0.0013268990442156792 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:1.5661325454711914 norm:0.0013138354988768697 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:1.5652449131011963 norm:0.0013095902977511287 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:1.5645880699157715 norm:0.0013066136743873358 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:1.564131259918213 norm:0.001308880397118628 max memory_allocated 29272.75048828125 
[2025-03-02 20:22:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:1.5637001991271973 norm:0.0013014021096751094 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:00 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:1.563269853591919 norm:0.0012986280489712954 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:1.5628352165222168 norm:0.0012999383034184575 max memory_allocated 29272.75048828125 
[2025-03-02 20:24:39 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:1.5625327825546265 norm:0.0013014641590416431 max memory_allocated 29272.75048828125 
[2025-03-02 20:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:1.5622550249099731 norm:0.0012993609998375177 max memory_allocated 29272.75048828125 
[2025-03-02 20:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:1.5619854927062988 norm:0.0013007073430344462 max memory_allocated 29272.75048828125 
[2025-03-02 20:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:1.5617625713348389 norm:0.0013030519476160407 max memory_allocated 29272.75048828125 
[2025-03-02 20:27:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:28:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:1.813576340675354 norm:0.00610552029684186 max memory_allocated 29272.93798828125 
[2025-03-02 20:29:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:1.7949013710021973 norm:0.0036088433116674423 max memory_allocated 29272.93798828125 
[2025-03-02 20:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:1.7728867530822754 norm:0.0025042009074240923 max memory_allocated 29272.93798828125 
[2025-03-02 20:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:1.7644662857055664 norm:0.0016232948983088136 max memory_allocated 29272.93798828125 
[2025-03-02 20:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:1.7601382732391357 norm:0.0014252230757847428 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:1.7566956281661987 norm:0.0013763353927060962 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:1.7538422346115112 norm:0.0013593655312433839 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:1.7517058849334717 norm:0.0013537784107029438 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:1.7500888109207153 norm:0.001350322854705155 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:1.748872995376587 norm:0.00134681211784482 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:1.7478771209716797 norm:0.0013468435499817133 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:1.7469209432601929 norm:0.0013370693195611238 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:1.7463326454162598 norm:0.001347907935269177 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:1.7457226514816284 norm:0.0013574862387031317 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:1.7451955080032349 norm:0.0013589602895081043 max memory_allocated 29272.93798828125 
[2025-03-02 20:40:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:1.744802713394165 norm:0.0013559452490881085 max memory_allocated 29272.93798828125 
[2025-03-02 20:41:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:1.7446036338806152 norm:0.0013608720619231462 max memory_allocated 29272.93798828125 
[2025-03-02 20:42:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:1.7442353963851929 norm:0.0013590732123702765 max memory_allocated 29272.93798828125 
[2025-03-02 20:43:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:1.7438668012619019 norm:0.0013620044337585568 max memory_allocated 29272.93798828125 
[2025-03-02 20:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:1.7436192035675049 norm:0.0013593686744570732 max memory_allocated 29272.93798828125 
[2025-03-02 20:44:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:1.9983160495758057 norm:0.005464306101202965 max memory_allocated 29273.12548828125 
[2025-03-02 20:45:58 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:1.9792360067367554 norm:0.0030542444437742233 max memory_allocated 29273.12548828125 
[2025-03-02 20:46:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:1.9583323001861572 norm:0.0023376811295747757 max memory_allocated 29273.12548828125 
[2025-03-02 20:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:1.9511743783950806 norm:0.001967162825167179 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:1.9468635320663452 norm:0.0017306902445852757 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:1.9433313608169556 norm:0.0016480152262374759 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:1.9403715133666992 norm:0.0016070152632892132 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:1.937943935394287 norm:0.0015586388763040304 max memory_allocated 29273.12548828125 
[2025-03-02 20:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:1.9361598491668701 norm:0.0016011274419724941 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:1.9347704648971558 norm:0.0015832403441891074 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:1.9338387250900269 norm:0.0015561615582555532 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:1.9330847263336182 norm:0.0015718837967142463 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:1.932248592376709 norm:0.0015424347948282957 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:1.9314669370651245 norm:0.0015430902130901814 max memory_allocated 29273.12548828125 
[2025-03-02 20:56:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:1.9309117794036865 norm:0.001531932270154357 max memory_allocated 29273.12548828125 
[2025-03-02 20:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:1.9306440353393555 norm:0.0015258240746334195 max memory_allocated 29273.12548828125 
[2025-03-02 20:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:1.930307149887085 norm:0.0015449465718120337 max memory_allocated 29273.12548828125 
[2025-03-02 20:59:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:1.9300464391708374 norm:0.001522638602182269 max memory_allocated 29273.12548828125 
[2025-03-02 21:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:1.92987060546875 norm:0.0015350322937592864 max memory_allocated 29273.12548828125 
[2025-03-02 21:00:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:1.9295306205749512 norm:0.001511058071628213 max memory_allocated 29273.12548828125 
[2025-03-02 21:01:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 21:02:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:2.1772499084472656 norm:0.010673212818801403 max memory_allocated 29273.31298828125 
[2025-03-02 21:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:2.157853126525879 norm:0.005805312190204859 max memory_allocated 29273.31298828125 
[2025-03-02 21:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:2.135451555252075 norm:0.00347421457991004 max memory_allocated 29273.31298828125 
[2025-03-02 21:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:2.127277374267578 norm:0.0022272812202572823 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:2.1225130558013916 norm:0.0014677869621664286 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:2.118826150894165 norm:0.0013549686409533024 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:2.115718364715576 norm:0.0013262906577438116 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:2.113220691680908 norm:0.0012999887112528086 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:2.111572027206421 norm:0.0012816041707992554 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:2.1103274822235107 norm:0.0012779542012140155 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:2.109327554702759 norm:0.0012683907989412546 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:2.1086013317108154 norm:0.0012695409823209047 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:2.108020305633545 norm:0.001267588115297258 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:2.1075406074523926 norm:0.0012711100280284882 max memory_allocated 29273.31298828125 
[2025-03-02 21:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:2.1070964336395264 norm:0.001277840230613947 max memory_allocated 29273.31298828125 
[2025-03-02 21:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:2.106762409210205 norm:0.0012783922720700502 max memory_allocated 29273.31298828125 
[2025-03-02 21:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:2.1064529418945312 norm:0.0012718969956040382 max memory_allocated 29273.31298828125 
[2025-03-02 21:16:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:2.1061952114105225 norm:0.0012653417652472854 max memory_allocated 29273.31298828125 
[2025-03-02 21:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:2.1058907508850098 norm:0.0012749568559229374 max memory_allocated 29273.31298828125 
[2025-03-02 21:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:2.1056294441223145 norm:0.0012757440563291311 max memory_allocated 29273.31298828125 
[2025-03-02 21:17:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:18:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:2.3941054344177246 norm:0.015539580956101418 max memory_allocated 29273.50048828125 
[2025-03-02 21:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:2.374173164367676 norm:0.011052110232412815 max memory_allocated 29273.50048828125 
[2025-03-02 21:20:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:2.3483009338378906 norm:0.007890469394624233 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:2.338637351989746 norm:0.006058882921934128 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:2.3314685821533203 norm:0.00454062782227993 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:2.3251731395721436 norm:0.0037763228174299 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:2.321441650390625 norm:0.0036873044446110725 max memory_allocated 29273.50048828125 
[2025-03-02 21:24:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:2.318484306335449 norm:0.0033787284046411514 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:2.3162083625793457 norm:0.003070086007937789 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:2.3145861625671387 norm:0.0028720065020024776 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:2.3131656646728516 norm:0.0026967243757098913 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:2.3120319843292236 norm:0.0025558117777109146 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:2.3109586238861084 norm:0.0024118064902722836 max memory_allocated 29273.50048828125 
[2025-03-02 21:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:2.3101465702056885 norm:0.002280318643897772 max memory_allocated 29273.50048828125 
[2025-03-02 21:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:2.3094067573547363 norm:0.0021752624306827784 max memory_allocated 29273.50048828125 
[2025-03-02 21:31:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:2.308744430541992 norm:0.002067373599857092 max memory_allocated 29273.50048828125 
[2025-03-02 21:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:2.3080618381500244 norm:0.0019735279493033886 max memory_allocated 29273.50048828125 
[2025-03-02 21:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:2.3075778484344482 norm:0.0019587120041251183 max memory_allocated 29273.50048828125 
[2025-03-02 21:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:2.3071141242980957 norm:0.0018874439410865307 max memory_allocated 29273.50048828125 
[2025-03-02 21:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:2.3066866397857666 norm:0.0018274751491844654 max memory_allocated 29273.50048828125 
[2025-03-02 21:34:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:35:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:2.59114146232605 norm:0.006304600741714239 max memory_allocated 29273.68798828125 
[2025-03-02 21:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:2.569303035736084 norm:0.0036148116923868656 max memory_allocated 29273.68798828125 
[2025-03-02 21:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:2.5444600582122803 norm:0.00250232289545238 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:2.534644365310669 norm:0.0019758723210543394 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:2.529082775115967 norm:0.0017524033319205046 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:2.52424693107605 norm:0.001643893774598837 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:2.520566701889038 norm:0.0015969118103384972 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:2.5176048278808594 norm:0.0015108577208593488 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:2.515373945236206 norm:0.0015078673604875803 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:2.513726234436035 norm:0.0015061453450471163 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:57 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:2.512484312057495 norm:0.0015100480522960424 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:2.5115809440612793 norm:0.0014935825020074844 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:2.5107548236846924 norm:0.0014990235213190317 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:2.509955406188965 norm:0.0014795437455177307 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:2.509265661239624 norm:0.0014787475811317563 max memory_allocated 29273.68798828125 
[2025-03-02 21:48:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:2.508791208267212 norm:0.001477970159612596 max memory_allocated 29273.68798828125 
[2025-03-02 21:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:2.50836443901062 norm:0.0014613136881962419 max memory_allocated 29273.68798828125 
[2025-03-02 21:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:2.5079612731933594 norm:0.0014670122181996703 max memory_allocated 29273.68798828125 
[2025-03-02 21:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:2.507629156112671 norm:0.0014674130361527205 max memory_allocated 29273.68798828125 
[2025-03-02 21:51:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:2.5074164867401123 norm:0.001462668413296342 max memory_allocated 29273.68798828125 
[2025-03-02 21:51:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:52:32 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:2.7956488132476807 norm:0.010872429236769676 max memory_allocated 29273.87548828125 
[2025-03-02 21:53:21 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:2.7728233337402344 norm:0.006169954314827919 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:11 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:2.746140718460083 norm:0.003856134368106723 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:00 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:2.734829902648926 norm:0.0025213139597326517 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:2.728908061981201 norm:0.0018566618673503399 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:2.7241547107696533 norm:0.0016611164901405573 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:29 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:2.7198121547698975 norm:0.0014935331419110298 max memory_allocated 29273.87548828125 
[2025-03-02 21:58:19 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:2.7169010639190674 norm:0.0014395288890227675 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:08 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:2.71464204788208 norm:0.0013919728808104992 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:58 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:2.7129592895507812 norm:0.0013698783004656434 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:48 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:2.7118425369262695 norm:0.0013489355333149433 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:2.7109780311584473 norm:0.001337374676950276 max memory_allocated 29273.87548828125 
[2025-03-02 22:02:27 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:2.710087299346924 norm:0.00132169877178967 max memory_allocated 29273.87548828125 
[2025-03-02 22:03:16 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:2.7093307971954346 norm:0.0013228273019194603 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:2.7087695598602295 norm:0.0013119092909619212 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:56 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:2.7082526683807373 norm:0.0013035588199272752 max memory_allocated 29273.87548828125 
[2025-03-02 22:05:45 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:2.707742214202881 norm:0.0012947316281497478 max memory_allocated 29273.87548828125 
[2025-03-02 22:06:35 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:2.707394599914551 norm:0.0012906224001199007 max memory_allocated 29273.87548828125 
[2025-03-02 22:07:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:2.7070133686065674 norm:0.0012958593433722854 max memory_allocated 29273.87548828125 
[2025-03-02 22:08:14 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:2.706599712371826 norm:0.0012882392620667815 max memory_allocated 29273.87548828125 
[2025-03-02 22:08:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:3.0358150005340576 norm:0.01078852266073227 max memory_allocated 29274.06298828125 
[2025-03-02 22:10:12 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:3.0105843544006348 norm:0.005974479019641876 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:01 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:2.9806008338928223 norm:0.003931690473109484 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:51 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:2.968135118484497 norm:0.0027756397612392902 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:2.961103916168213 norm:0.0021516941487789154 max memory_allocated 29274.06298828125 
[2025-03-02 22:13:30 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:2.9551923274993896 norm:0.0017848494462668896 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:20 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:2.950371265411377 norm:0.0016954434104263783 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:09 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:2.947096347808838 norm:0.0016665809089317918 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:2.9446587562561035 norm:0.0016145923873409629 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:48 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:2.9426708221435547 norm:0.0015749512240290642 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:2.9412076473236084 norm:0.0015409637708216906 max memory_allocated 29274.06298828125 
[2025-03-02 22:18:28 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:2.9401776790618896 norm:0.001513187075033784 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:2.939396381378174 norm:0.001481416984461248 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:2.9385693073272705 norm:0.0014741556951776147 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:56 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:2.9379448890686035 norm:0.00149258179590106 max memory_allocated 29274.06298828125 
[2025-03-02 22:21:46 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:2.93721866607666 norm:0.001483690575696528 max memory_allocated 29274.06298828125 
[2025-03-02 22:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:2.936577081680298 norm:0.001466367393732071 max memory_allocated 29274.06298828125 
[2025-03-02 22:23:25 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:2.9360501766204834 norm:0.0014610113576054573 max memory_allocated 29274.06298828125 
[2025-03-02 22:24:15 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:2.9357094764709473 norm:0.0014608402270823717 max memory_allocated 29274.06298828125 
[2025-03-02 22:25:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:2.935359001159668 norm:0.0014714330900460482 max memory_allocated 29274.06298828125 
[2025-03-02 22:25:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:26:13 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:3.3478963375091553 norm:0.034062355756759644 max memory_allocated 29274.25048828125 
[2025-03-02 22:27:03 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:3.3143138885498047 norm:0.022575289011001587 max memory_allocated 29274.25048828125 
[2025-03-02 22:27:52 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:3.2742228507995605 norm:0.014795714057981968 max memory_allocated 29274.25048828125 
[2025-03-02 22:28:42 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:3.2528977394104004 norm:0.009842431172728539 max memory_allocated 29274.25048828125 
[2025-03-02 22:29:32 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:3.2407522201538086 norm:0.007419104687869549 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:21 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:3.2326762676239014 norm:0.006280910689383745 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:11 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:3.2269082069396973 norm:0.005488707218319178 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:01 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:3.2221012115478516 norm:0.004689294844865799 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:51 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:3.2173995971679688 norm:0.0038606920279562473 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:40 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:3.2128682136535645 norm:0.0017706523649394512 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:30 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:3.2104971408843994 norm:0.001778137288056314 max memory_allocated 29274.25048828125 
[2025-03-02 22:35:20 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:3.2092223167419434 norm:0.0017508864402770996 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:09 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:3.2076845169067383 norm:0.0017330244882032275 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:3.2062268257141113 norm:0.0017109160544350743 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:3.205402135848999 norm:0.0017126391176134348 max memory_allocated 29274.25048828125 
[2025-03-02 22:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:3.204688787460327 norm:0.0017102141864597797 max memory_allocated 29274.25048828125 
[2025-03-02 22:39:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:3.2041237354278564 norm:0.0017122253775596619 max memory_allocated 29274.25048828125 
[2025-03-02 22:40:18 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:3.2034666538238525 norm:0.001702347886748612 max memory_allocated 29274.25048828125 
[2025-03-02 22:41:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:3.2030386924743652 norm:0.0017024923581629992 max memory_allocated 29274.25048828125 
[2025-03-02 22:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:3.2026734352111816 norm:0.001697137369774282 max memory_allocated 29274.25048828125 
[2025-03-02 22:42:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:43:05 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:3.6363165378570557 norm:0.02139267325401306 max memory_allocated 29274.43798828125 
[2025-03-02 22:43:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:3.597654342651367 norm:0.01428271271288395 max memory_allocated 29274.43798828125 
[2025-03-02 22:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:3.553476333618164 norm:0.009422346018254757 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:34 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:3.531529426574707 norm:0.006643453147262335 max memory_allocated 29274.43798828125 
[2025-03-02 22:46:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:3.519265651702881 norm:0.005333114415407181 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:3.5101027488708496 norm:0.00453593535348773 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:3.502998113632202 norm:0.00395754212513566 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:3.4976353645324707 norm:0.0036883270367980003 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:3.493466854095459 norm:0.0033521903678774834 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:3.4904587268829346 norm:0.0030521780718117952 max memory_allocated 29274.43798828125 
[2025-03-02 22:51:22 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:3.488110065460205 norm:0.0029151844792068005 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:12 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:3.48669695854187 norm:0.0029559226240962744 max memory_allocated 29274.43798828125 
[2025-03-02 22:53:02 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:3.484990119934082 norm:0.002773625310510397 max memory_allocated 29274.43798828125 
[2025-03-02 22:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:3.4829261302948 norm:0.002494602231308818 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:3.481079339981079 norm:0.0025936837773770094 max memory_allocated 29274.43798828125 
[2025-03-02 22:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:3.479952096939087 norm:0.0026240930892527103 max memory_allocated 29274.43798828125 
[2025-03-02 22:56:21 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:3.478766679763794 norm:0.0026387860998511314 max memory_allocated 29274.43798828125 
[2025-03-02 22:57:10 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:3.477630615234375 norm:0.002627510577440262 max memory_allocated 29274.43798828125 
[2025-03-02 22:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:3.476518154144287 norm:0.0026397809851914644 max memory_allocated 29274.43798828125 
[2025-03-02 22:58:50 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:3.4755117893218994 norm:0.0025935552548617125 max memory_allocated 29274.43798828125 
[2025-03-02 22:59:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 22:59:08 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 22:59:58 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:3.937285900115967 norm:0.04403838887810707 max memory_allocated 29274.77001953125 
[2025-03-02 23:00:48 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:3.8899824619293213 norm:0.04096902161836624 max memory_allocated 29274.77001953125 
[2025-03-02 23:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:3.8388986587524414 norm:0.03367586061358452 max memory_allocated 29274.77001953125 
[2025-03-02 23:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:3.8163790702819824 norm:0.02924577333033085 max memory_allocated 29274.77001953125 
[2025-03-02 23:03:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:3.8031246662139893 norm:0.02607981115579605 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:3.791353702545166 norm:0.023272596299648285 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:3.78218150138855 norm:0.02068497985601425 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:3.775899648666382 norm:0.01934085041284561 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:3.7709975242614746 norm:0.018941449001431465 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:27 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:3.7674689292907715 norm:0.018109219148755074 max memory_allocated 29274.77001953125 
[2025-03-02 23:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:3.764568328857422 norm:0.01740572229027748 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:3.762366533279419 norm:0.01703539863228798 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:3.7602663040161133 norm:0.016819261014461517 max memory_allocated 29274.77001953125 
[2025-03-02 23:10:46 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:3.75819993019104 norm:0.016526471823453903 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:36 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:3.7569262981414795 norm:0.016229594126343727 max memory_allocated 29274.77001953125 
[2025-03-02 23:12:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:3.755643367767334 norm:0.016229216009378433 max memory_allocated 29274.77001953125 
[2025-03-02 23:13:16 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:3.7544615268707275 norm:0.01639554649591446 max memory_allocated 29274.77001953125 
[2025-03-02 23:14:06 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:3.7534995079040527 norm:0.016365930438041687 max memory_allocated 29274.77001953125 
[2025-03-02 23:14:56 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:3.7525925636291504 norm:0.016364529728889465 max memory_allocated 29274.77001953125 
[2025-03-02 23:15:46 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:3.7519452571868896 norm:0.01657775044441223 max memory_allocated 29274.77001953125 
[2025-03-02 23:16:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:16:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:16:54 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:4.396524906158447 norm:0.0616227425634861 max memory_allocated 29274.95751953125 
[2025-03-02 23:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:4.327496528625488 norm:0.05229596793651581 max memory_allocated 29274.95751953125 
[2025-03-02 23:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:4.2551984786987305 norm:0.04032597318291664 max memory_allocated 29274.95751953125 
[2025-03-02 23:19:23 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:4.222513675689697 norm:0.03174006566405296 max memory_allocated 29274.95751953125 
[2025-03-02 23:20:13 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:4.203608989715576 norm:0.02531544864177704 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:03 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:4.1907267570495605 norm:0.021245909854769707 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:53 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:4.181375026702881 norm:0.019266648218035698 max memory_allocated 29274.95751953125 
[2025-03-02 23:22:42 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:4.174356937408447 norm:0.018722139298915863 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:4.169106960296631 norm:0.018190521746873856 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:4.164976119995117 norm:0.017405321821570396 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:4.161926746368408 norm:0.017812542617321014 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:4.157900810241699 norm:0.017919490113854408 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:4.1561760902404785 norm:0.018193837255239487 max memory_allocated 29274.95751953125 
[2025-03-02 23:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:4.153032302856445 norm:0.017860300838947296 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:4.151690483093262 norm:0.017997857183218002 max memory_allocated 29274.95751953125 
[2025-03-02 23:29:21 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:4.1500372886657715 norm:0.018150320276618004 max memory_allocated 29274.95751953125 
[2025-03-02 23:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:4.148687362670898 norm:0.018114816397428513 max memory_allocated 29274.95751953125 
[2025-03-02 23:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:4.147094249725342 norm:0.017899537459015846 max memory_allocated 29274.95751953125 
[2025-03-02 23:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:4.145328521728516 norm:0.01755486987531185 max memory_allocated 29274.95751953125 
[2025-03-02 23:32:41 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:4.144488334655762 norm:0.017170626670122147 max memory_allocated 29274.95751953125 
[2025-03-02 23:32:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:32:59 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:5.570768356323242 norm:0.21042519807815552 max memory_allocated 29275.14501953125 
[2025-03-02 23:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:5.370774269104004 norm:0.1468077152967453 max memory_allocated 29275.14501953125 
[2025-03-02 23:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:5.238033771514893 norm:0.1114659458398819 max memory_allocated 29275.14501953125 
[2025-03-02 23:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:5.16502571105957 norm:0.09797508269548416 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:08 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:5.1230998039245605 norm:0.08746152371168137 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:58 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:5.081926345825195 norm:0.07503793388605118 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:47 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:5.060678005218506 norm:0.07092209905385971 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:37 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:5.0375800132751465 norm:0.06584128737449646 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:5.019099712371826 norm:0.06297378242015839 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:5.003792762756348 norm:0.05948007106781006 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:07 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:4.993368148803711 norm:0.05745876953005791 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:56 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:4.984960556030273 norm:0.05596861615777016 max memory_allocated 29275.14501953125 
[2025-03-02 23:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:4.977938175201416 norm:0.05309038981795311 max memory_allocated 29275.14501953125 
[2025-03-02 23:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:4.972825527191162 norm:0.04832015931606293 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:4.967041015625 norm:0.04533327370882034 max memory_allocated 29275.14501953125 
[2025-03-02 23:46:16 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:4.961061477661133 norm:0.04691047593951225 max memory_allocated 29275.14501953125 
[2025-03-02 23:47:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:4.956610679626465 norm:0.047201965004205704 max memory_allocated 29275.14501953125 
[2025-03-02 23:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:4.953572750091553 norm:0.04615632817149162 max memory_allocated 29275.14501953125 
[2025-03-02 23:48:45 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:4.950606346130371 norm:0.04494023323059082 max memory_allocated 29275.14501953125 
[2025-03-02 23:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:4.948609828948975 norm:0.04337824508547783 max memory_allocated 29275.14501953125 
[2025-03-02 23:49:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:49:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:9.559396743774414 norm:0.4439694285392761 max memory_allocated 29275.33251953125 
[2025-03-02 23:51:33 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:9.114815711975098 norm:0.36270415782928467 max memory_allocated 29275.33251953125 
[2025-03-02 23:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:8.721426963806152 norm:0.3075690269470215 max memory_allocated 29275.33251953125 
[2025-03-02 23:53:12 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:8.477679252624512 norm:0.32525092363357544 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:8.344447135925293 norm:0.3120350241661072 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:52 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:8.271324157714844 norm:0.29542824625968933 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:8.198702812194824 norm:0.2796693444252014 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:31 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:8.127591133117676 norm:0.26627588272094727 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:8.054009437561035 norm:0.26221176981925964 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:11 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:7.996087551116943 norm:0.25841107964515686 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:01 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:7.960572719573975 norm:0.250232458114624 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:50 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:7.93963098526001 norm:0.24135304987430573 max memory_allocated 29275.33251953125 
[2025-03-03 00:00:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:7.915301322937012 norm:0.23715588450431824 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:30 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:7.898664951324463 norm:0.23675699532032013 max memory_allocated 29275.33251953125 
[2025-03-03 00:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:7.877772331237793 norm:0.23335841298103333 max memory_allocated 29275.33251953125 
[2025-03-03 00:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:7.866581916809082 norm:0.22698350250720978 max memory_allocated 29275.33251953125 
[2025-03-03 00:03:59 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:7.855541229248047 norm:0.22558841109275818 max memory_allocated 29275.33251953125 
[2025-03-03 00:04:49 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:7.853694915771484 norm:0.2293311059474945 max memory_allocated 29275.33251953125 
[2025-03-03 00:05:39 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:7.8383941650390625 norm:0.2283666431903839 max memory_allocated 29275.33251953125 
[2025-03-03 00:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:7.826603889465332 norm:0.22084940969944 max memory_allocated 29275.33251953125 
[2025-03-03 00:06:43 root] (main_calib_config2.py 372): INFO 40453.06989312172
[2025-03-03 00:06:53 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:08:50 root] (main_calib_config2.py 159): INFO wikitext2 : 7.41226053237915
[2025-03-03 00:08:50 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:11:48 root] (main_calib_config2.py 159): INFO c4 : 10.366556167602539
[2025-03-03 02:13:35 root] (main_calib_config2.py 170): INFO {'wikitext2': 7.41226053237915, 'c4': 10.366556167602539, 'results': {'piqa': {'acc': 0.6996735582154516, 'acc_stderr': 0.01069522530818314, 'acc_norm': 0.7029379760609358, 'acc_norm_stderr': 0.01066172540481478}, 'arc_easy': {'acc': 0.5795454545454546, 'acc_stderr': 0.010129114278546528, 'acc_norm': 0.4675925925925926, 'acc_norm_stderr': 0.01023821036880189}, 'winogrande': {'acc': 0.5816890292028414, 'acc_stderr': 0.013863669961195918}, 'arc_challenge': {'acc': 0.3097269624573379, 'acc_stderr': 0.013512058415238361, 'acc_norm': 0.33447098976109213, 'acc_norm_stderr': 0.013787460322441377}, 'boolq': {'acc': 0.6412844036697247, 'acc_stderr': 0.008388668034059417}, 'hellaswag': {'acc': 0.49512049392551283, 'acc_stderr': 0.004989543796593283, 'acc_norm': 0.658832901812388, 'acc_norm_stderr': 0.0047313244091332606}}, 'versions': {'piqa': 0, 'arc_easy': 0, 'winogrande': 0, 'arc_challenge': 0, 'boolq': 1, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
