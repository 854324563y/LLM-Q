[2025-02-28 13:28:37 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.7', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.7.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:28:46 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:28:46 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:28:47 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:28:47 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.7.pkl
[2025-02-28 13:28:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:29:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.006719864904880524 norm:0.011737397871911526 max memory_allocated 29271.02001953125 
[2025-02-28 13:30:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0037381844595074654 norm:0.006882166489958763 max memory_allocated 29271.02001953125 
[2025-02-28 13:31:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.003172470023855567 norm:0.005392225459218025 max memory_allocated 29271.02001953125 
[2025-02-28 13:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0028912248089909554 norm:0.004437804222106934 max memory_allocated 29271.02001953125 
[2025-02-28 13:32:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0026439845096319914 norm:0.0034606135450303555 max memory_allocated 29271.02001953125 
[2025-02-28 13:33:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.00243490026332438 norm:0.0027642783243209124 max memory_allocated 29271.02001953125 
[2025-02-28 13:34:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.002337272046133876 norm:0.002347674686461687 max memory_allocated 29271.02001953125 
[2025-02-28 13:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0023308689706027508 norm:0.002190499333664775 max memory_allocated 29271.02001953125 
[2025-02-28 13:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.00234104017727077 norm:0.0019631909672170877 max memory_allocated 29271.02001953125 
[2025-02-28 13:36:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.002305649220943451 norm:0.001647288678213954 max memory_allocated 29271.02001953125 
[2025-02-28 13:37:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0021788938902318478 norm:0.001565809128805995 max memory_allocated 29271.02001953125 
[2025-02-28 13:38:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.002160473493859172 norm:0.0013407141668722034 max memory_allocated 29271.02001953125 
[2025-02-28 13:38:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.00214828341268003 norm:0.0012894038809463382 max memory_allocated 29271.02001953125 
[2025-02-28 13:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.002198288217186928 norm:0.0012202714569866657 max memory_allocated 29271.02001953125 
[2025-02-28 13:40:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.002118276432156563 norm:0.001123432768508792 max memory_allocated 29271.02001953125 
[2025-02-28 13:41:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0020716991275548935 norm:0.0010376516729593277 max memory_allocated 29271.02001953125 
[2025-02-28 13:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0020776784513145685 norm:0.0009972242405638099 max memory_allocated 29271.02001953125 
[2025-02-28 13:42:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.002092581009492278 norm:0.0009645596146583557 max memory_allocated 29271.02001953125 
[2025-02-28 13:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0020974737126380205 norm:0.001019984600134194 max memory_allocated 29271.02001953125 
[2025-02-28 13:44:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0021289123687893152 norm:0.0009991961997002363 max memory_allocated 29271.02001953125 
[2025-02-28 13:44:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:44:35 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.013426173478364944 norm:0.010062411427497864 max memory_allocated 29271.02001953125 
[2025-02-28 13:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.009021101519465446 norm:0.006484918296337128 max memory_allocated 29271.02001953125 
[2025-02-28 13:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.007763777859508991 norm:0.004610050469636917 max memory_allocated 29271.02001953125 
[2025-02-28 13:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.007156441919505596 norm:0.003523800754919648 max memory_allocated 29271.02001953125 
[2025-02-28 13:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.006811362691223621 norm:0.002959863282740116 max memory_allocated 29271.02001953125 
[2025-02-28 13:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.006626534275710583 norm:0.00258744228631258 max memory_allocated 29271.02001953125 
[2025-02-28 13:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.006494077853858471 norm:0.002329680137336254 max memory_allocated 29271.02001953125 
[2025-02-28 13:50:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.006393440533429384 norm:0.002093852497637272 max memory_allocated 29271.02001953125 
[2025-02-28 13:51:24 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.006307942792773247 norm:0.00188293750397861 max memory_allocated 29271.02001953125 
[2025-02-28 13:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.006221328396350145 norm:0.0016649237368255854 max memory_allocated 29271.02001953125 
[2025-02-28 13:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.006126610096544027 norm:0.0014777830801904202 max memory_allocated 29271.02001953125 
[2025-02-28 13:53:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.006048896815627813 norm:0.0013263835571706295 max memory_allocated 29271.02001953125 
[2025-02-28 13:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.006013583391904831 norm:0.0012165377847850323 max memory_allocated 29271.02001953125 
[2025-02-28 13:55:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.005989494733512402 norm:0.001161367865279317 max memory_allocated 29271.02001953125 
[2025-02-28 13:55:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.0059331669472157955 norm:0.0010846006916835904 max memory_allocated 29271.02001953125 
[2025-02-28 13:56:42 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.005902464035898447 norm:0.0010731398360803723 max memory_allocated 29271.02001953125 
[2025-02-28 13:57:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.0058822487480938435 norm:0.0010698124533519149 max memory_allocated 29271.02001953125 
[2025-02-28 13:58:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.005899007897824049 norm:0.0011174409883096814 max memory_allocated 29271.02001953125 
[2025-02-28 13:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.005962751340121031 norm:0.0011952172499150038 max memory_allocated 29271.02001953125 
[2025-02-28 13:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.005980281159281731 norm:0.0011954826768487692 max memory_allocated 29271.02001953125 
[2025-02-28 13:59:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 14:00:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 14:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.018753034994006157 norm:0.004700974095612764 max memory_allocated 29271.02001953125 
[2025-02-28 14:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.01384920347481966 norm:0.0035498940851539373 max memory_allocated 29271.02001953125 
[2025-02-28 14:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.011272422038018703 norm:0.0025673944037407637 max memory_allocated 29271.02001953125 
[2025-02-28 14:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.010655172169208527 norm:0.002092295326292515 max memory_allocated 29271.02001953125 
[2025-02-28 14:03:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.01037938054651022 norm:0.001816476578824222 max memory_allocated 29271.02001953125 
[2025-02-28 14:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.010127874091267586 norm:0.0015979957534000278 max memory_allocated 29271.02001953125 
[2025-02-28 14:05:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.00985869113355875 norm:0.0013746654149144888 max memory_allocated 29271.02001953125 
[2025-02-28 14:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.009651566855609417 norm:0.0012173332506790757 max memory_allocated 29271.02001953125 
[2025-02-28 14:06:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.009490501135587692 norm:0.0010666931048035622 max memory_allocated 29271.02001953125 
[2025-02-28 14:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.009380434639751911 norm:0.0009104937198571861 max memory_allocated 29271.02001953125 
[2025-02-28 14:08:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.009351927787065506 norm:0.0008649434894323349 max memory_allocated 29271.02001953125 
[2025-02-28 14:09:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.009328428655862808 norm:0.0007998684304766357 max memory_allocated 29271.02001953125 
[2025-02-28 14:09:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.009259690530598164 norm:0.0007590569439344108 max memory_allocated 29271.02001953125 
[2025-02-28 14:10:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.009289072826504707 norm:0.0007749352371320128 max memory_allocated 29271.02001953125 
[2025-02-28 14:11:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.009322893805801868 norm:0.0007157381041906774 max memory_allocated 29271.02001953125 
[2025-02-28 14:12:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.009284041821956635 norm:0.0005886888829991221 max memory_allocated 29271.02001953125 
[2025-02-28 14:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.009272303432226181 norm:0.0006513195112347603 max memory_allocated 29271.02001953125 
[2025-02-28 14:13:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.009257799945771694 norm:0.0006415200768969953 max memory_allocated 29271.02001953125 
[2025-02-28 14:14:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.009241080842912197 norm:0.0006363437278196216 max memory_allocated 29271.02001953125 
[2025-02-28 14:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.009323733858764172 norm:0.00046072894474491477 max memory_allocated 29271.02001953125 
[2025-02-28 14:15:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 14:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.13314290344715118 norm:0.017254671081900597 max memory_allocated 29271.02001953125 
[2025-02-28 14:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.09542472660541534 norm:0.01095714420080185 max memory_allocated 29271.02001953125 
[2025-02-28 14:17:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.06526876240968704 norm:0.008393775671720505 max memory_allocated 29271.02001953125 
[2025-02-28 14:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.05823405832052231 norm:0.010452616959810257 max memory_allocated 29271.02001953125 
[2025-02-28 14:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.04204182326793671 norm:0.0066191162914037704 max memory_allocated 29271.02001953125 
[2025-02-28 14:20:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.03920990601181984 norm:0.005850509740412235 max memory_allocated 29271.02001953125 
[2025-02-28 14:20:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.03821288049221039 norm:0.0054759313352406025 max memory_allocated 29271.02001953125 
[2025-02-28 14:21:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.03722134977579117 norm:0.004935905337333679 max memory_allocated 29271.02001953125 
[2025-02-28 14:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.036469630897045135 norm:0.004607334267348051 max memory_allocated 29271.02001953125 
[2025-02-28 14:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.03628089651465416 norm:0.005171466153115034 max memory_allocated 29271.02001953125 
[2025-02-28 14:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.036906711757183075 norm:0.00555037334561348 max memory_allocated 29271.02001953125 
[2025-02-28 14:24:37 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.03608915954828262 norm:0.005151902325451374 max memory_allocated 29271.02001953125 
[2025-02-28 14:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.03521600738167763 norm:0.004806517157703638 max memory_allocated 29271.02001953125 
[2025-02-28 14:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.035097237676382065 norm:0.005495316814631224 max memory_allocated 29271.02001953125 
[2025-02-28 14:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.03453923016786575 norm:0.004443843849003315 max memory_allocated 29271.02001953125 
[2025-02-28 14:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.03568071126937866 norm:0.00455594714730978 max memory_allocated 29271.02001953125 
[2025-02-28 14:28:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.03489148989319801 norm:0.004477129317820072 max memory_allocated 29271.02001953125 
[2025-02-28 14:29:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.03427303582429886 norm:0.004165585618466139 max memory_allocated 29271.02001953125 
[2025-02-28 14:29:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.03227953612804413 norm:0.003656191285699606 max memory_allocated 29271.02001953125 
[2025-02-28 14:30:40 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.03331231698393822 norm:0.004152744077146053 max memory_allocated 29271.02001953125 
[2025-02-28 14:30:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.033147722482681274 norm:0.0008426638669334352 max memory_allocated 29271.62548828125 
[2025-02-28 14:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.028135858476161957 norm:0.00033811433240771294 max memory_allocated 29271.62548828125 
[2025-02-28 14:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.02617817558348179 norm:0.00020393433806020766 max memory_allocated 29271.62548828125 
[2025-02-28 14:34:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.02519959956407547 norm:0.00015989987878128886 max memory_allocated 29271.62548828125 
[2025-02-28 14:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.024641167372465134 norm:0.00014382657536771148 max memory_allocated 29271.62548828125 
[2025-02-28 14:35:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.0242321714758873 norm:0.0001343115873169154 max memory_allocated 29271.62548828125 
[2025-02-28 14:36:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.02391398325562477 norm:0.00013355012924876064 max memory_allocated 29271.62548828125 
[2025-02-28 14:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.023722104728221893 norm:0.00012262360542081296 max memory_allocated 29271.62548828125 
[2025-02-28 14:37:52 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.0236151572316885 norm:0.00011415906919864938 max memory_allocated 29271.62548828125 
[2025-02-28 14:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.023571915924549103 norm:0.00012332532787695527 max memory_allocated 29271.62548828125 
[2025-02-28 14:39:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.02352740988135338 norm:0.00010704297892516479 max memory_allocated 29271.62548828125 
[2025-02-28 14:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.02350209280848503 norm:0.00010374721750849858 max memory_allocated 29271.62548828125 
[2025-02-28 14:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.023481041193008423 norm:0.00010394080891273916 max memory_allocated 29271.62548828125 
[2025-02-28 14:41:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.02346472628414631 norm:0.0001072151935659349 max memory_allocated 29271.62548828125 
[2025-02-28 14:42:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.02342222072184086 norm:0.00010327816562494263 max memory_allocated 29271.62548828125 
[2025-02-28 14:43:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.02339550293982029 norm:0.00010342933819629252 max memory_allocated 29271.62548828125 
[2025-02-28 14:43:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.023401565849781036 norm:0.00010571703023742884 max memory_allocated 29271.62548828125 
[2025-02-28 14:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.023386772722005844 norm:0.00010697803372750059 max memory_allocated 29271.62548828125 
[2025-02-28 14:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.023378655314445496 norm:0.00010299331188434735 max memory_allocated 29271.62548828125 
[2025-02-28 14:46:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.023378288373351097 norm:0.00010928041592705995 max memory_allocated 29271.62548828125 
[2025-02-28 14:46:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:47:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.0361575223505497 norm:0.0011028209701180458 max memory_allocated 29271.62548828125 
[2025-02-28 14:48:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.03007134050130844 norm:0.0004552609461825341 max memory_allocated 29271.62548828125 
[2025-02-28 14:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.027991047129034996 norm:0.0002429810556350276 max memory_allocated 29271.62548828125 
[2025-02-28 14:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.026899609714746475 norm:0.00018518668366596103 max memory_allocated 29271.62548828125 
[2025-02-28 14:50:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.026187796145677567 norm:0.00015377096133306623 max memory_allocated 29271.62548828125 
[2025-02-28 14:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.025676799938082695 norm:0.00014089600881561637 max memory_allocated 29271.62548828125 
[2025-02-28 14:51:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.025388086214661598 norm:0.00012454565148800611 max memory_allocated 29271.62548828125 
[2025-02-28 14:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.025243420153856277 norm:0.00011812517186626792 max memory_allocated 29271.62548828125 
[2025-02-28 14:53:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.02515299618244171 norm:0.00011222204921068624 max memory_allocated 29271.62548828125 
[2025-02-28 14:54:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.025088535621762276 norm:0.00011120927956653759 max memory_allocated 29271.62548828125 
[2025-02-28 14:54:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.025048241019248962 norm:0.00010793819092214108 max memory_allocated 29271.62548828125 
[2025-02-28 14:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.02502279356122017 norm:0.0001068186538759619 max memory_allocated 29271.62548828125 
[2025-02-28 14:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.02499299682676792 norm:0.00010498874326003715 max memory_allocated 29271.62548828125 
[2025-02-28 14:57:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.02496500499546528 norm:0.00010991349699907005 max memory_allocated 29271.62548828125 
[2025-02-28 14:57:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.0249447263777256 norm:0.00010667131573427469 max memory_allocated 29271.62548828125 
[2025-02-28 14:58:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.02492375671863556 norm:0.0001005065641948022 max memory_allocated 29271.62548828125 
[2025-02-28 14:59:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.02491435781121254 norm:0.00010395358549430966 max memory_allocated 29271.62548828125 
[2025-02-28 15:00:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.024919185787439346 norm:0.00010644377471180633 max memory_allocated 29271.62548828125 
[2025-02-28 15:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.024921145290136337 norm:0.00010719871352193877 max memory_allocated 29271.62548828125 
[2025-02-28 15:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.024899126961827278 norm:0.00010146434942726046 max memory_allocated 29271.62548828125 
[2025-02-28 15:01:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 15:02:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.03896300122141838 norm:0.0013203610433265567 max memory_allocated 29271.62548828125 
[2025-02-28 15:03:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.032956041395664215 norm:0.0005584416794590652 max memory_allocated 29271.62548828125 
[2025-02-28 15:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.03060632012784481 norm:0.0003249700821470469 max memory_allocated 29271.62548828125 
[2025-02-28 15:05:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.02926946058869362 norm:0.00023182005679700524 max memory_allocated 29271.62548828125 
[2025-02-28 15:05:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.02843470312654972 norm:0.00018850635387934744 max memory_allocated 29271.62548828125 
[2025-02-28 15:06:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.027890710160136223 norm:0.0001615076034795493 max memory_allocated 29271.62548828125 
[2025-02-28 15:07:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.027614828199148178 norm:0.00014742845087312162 max memory_allocated 29271.62548828125 
[2025-02-28 15:08:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.027462733909487724 norm:0.00014047724835108966 max memory_allocated 29271.62548828125 
[2025-02-28 15:08:52 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.027381645515561104 norm:0.00013317959383130074 max memory_allocated 29271.62548828125 
[2025-02-28 15:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.027331838384270668 norm:0.00013117151684127748 max memory_allocated 29271.62548828125 
[2025-02-28 15:10:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.02731478586792946 norm:0.00014063206617720425 max memory_allocated 29271.62548828125 
[2025-02-28 15:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.027270041406154633 norm:0.00013780132576357573 max memory_allocated 29271.62548828125 
[2025-02-28 15:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.027234870940446854 norm:0.00013578923244494945 max memory_allocated 29271.62548828125 
[2025-02-28 15:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.027218837291002274 norm:0.00012578074529301375 max memory_allocated 29271.62548828125 
[2025-02-28 15:13:24 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.02719428762793541 norm:0.00012848724145442247 max memory_allocated 29271.62548828125 
[2025-02-28 15:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.02717491425573826 norm:0.00012613742728717625 max memory_allocated 29271.62548828125 
[2025-02-28 15:14:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.02714628353714943 norm:0.0001282979646930471 max memory_allocated 29271.62548828125 
[2025-02-28 15:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.027159102261066437 norm:0.00012948663788847625 max memory_allocated 29271.62548828125 
[2025-02-28 15:16:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.02717403881251812 norm:0.00013721376308239996 max memory_allocated 29271.62548828125 
[2025-02-28 15:17:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.02716245874762535 norm:0.00013508700067177415 max memory_allocated 29271.62548828125 
[2025-02-28 15:17:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 15:18:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.04786493629217148 norm:0.0013755387626588345 max memory_allocated 29271.62548828125 
[2025-02-28 15:19:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.03903217613697052 norm:0.0006076846038922668 max memory_allocated 29271.62548828125 
[2025-02-28 15:19:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.035686563700437546 norm:0.0003601134812925011 max memory_allocated 29271.62548828125 
[2025-02-28 15:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.034152064472436905 norm:0.0002737985923886299 max memory_allocated 29271.62548828125 
[2025-02-28 15:21:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.03318635746836662 norm:0.00023567272000946105 max memory_allocated 29271.62548828125 
[2025-02-28 15:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.032671716064214706 norm:0.00021248801203910261 max memory_allocated 29271.62548828125 
[2025-02-28 15:22:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.03229130432009697 norm:0.0001975846680579707 max memory_allocated 29271.62548828125 
[2025-02-28 15:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.032075341790914536 norm:0.0001899169583339244 max memory_allocated 29271.62548828125 
[2025-02-28 15:24:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.03189929947257042 norm:0.00018421061395201832 max memory_allocated 29271.62548828125 
[2025-02-28 15:25:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.03178025037050247 norm:0.0001760129671311006 max memory_allocated 29271.62548828125 
[2025-02-28 15:25:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.03174421191215515 norm:0.00017884012777358294 max memory_allocated 29271.62548828125 
[2025-02-28 15:26:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.03168579563498497 norm:0.00017027975991368294 max memory_allocated 29271.62548828125 
[2025-02-28 15:27:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.031658660620450974 norm:0.0001679854467511177 max memory_allocated 29271.62548828125 
[2025-02-28 15:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.03161225840449333 norm:0.00016353424871340394 max memory_allocated 29271.62548828125 
[2025-02-28 15:28:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.03157792612910271 norm:0.00016623198462184519 max memory_allocated 29271.62548828125 
[2025-02-28 15:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.03156387805938721 norm:0.0001758127036737278 max memory_allocated 29271.62548828125 
[2025-02-28 15:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.031557124108076096 norm:0.00016327273624483496 max memory_allocated 29271.62548828125 
[2025-02-28 15:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.03154173865914345 norm:0.00015557384176645428 max memory_allocated 29271.62548828125 
[2025-02-28 15:31:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.031500194221735 norm:0.00015415283269248903 max memory_allocated 29271.62548828125 
[2025-02-28 15:32:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.03148161247372627 norm:0.00015303122927434742 max memory_allocated 29271.62548828125 
[2025-02-28 15:32:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 15:33:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.04786449298262596 norm:0.0012806807644665241 max memory_allocated 29271.62548828125 
[2025-02-28 15:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.041005223989486694 norm:0.0006087316432967782 max memory_allocated 29271.62548828125 
[2025-02-28 15:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.03809750825166702 norm:0.0003666868433356285 max memory_allocated 29271.62548828125 
[2025-02-28 15:36:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.03642440214753151 norm:0.00025390679365955293 max memory_allocated 29271.62548828125 
[2025-02-28 15:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.03541999310255051 norm:0.00020085775759071112 max memory_allocated 29271.62548828125 
[2025-02-28 15:37:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.03488742560148239 norm:0.00017796560132410377 max memory_allocated 29271.62548828125 
[2025-02-28 15:38:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.03457016497850418 norm:0.00015958207950461656 max memory_allocated 29271.62548828125 
[2025-02-28 15:39:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.034391894936561584 norm:0.0001545855775475502 max memory_allocated 29271.62548828125 
[2025-02-28 15:39:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.034257952123880386 norm:0.00014222314348444343 max memory_allocated 29271.62548828125 
[2025-02-28 15:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.03419820964336395 norm:0.00014294302673079073 max memory_allocated 29271.62548828125 
[2025-02-28 15:41:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.034142542630434036 norm:0.00014038504741620272 max memory_allocated 29271.62548828125 
[2025-02-28 15:42:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.0340828113257885 norm:0.00013777610729448497 max memory_allocated 29271.62548828125 
[2025-02-28 15:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.03404320776462555 norm:0.00013525468239095062 max memory_allocated 29271.62548828125 
[2025-02-28 15:43:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.03401702269911766 norm:0.00013153765758033842 max memory_allocated 29271.62548828125 
[2025-02-28 15:44:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.03401096165180206 norm:0.0001346821809420362 max memory_allocated 29271.62548828125 
[2025-02-28 15:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.03398045152425766 norm:0.00013325079635251313 max memory_allocated 29271.62548828125 
[2025-02-28 15:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.03395016863942146 norm:0.00013085207319818437 max memory_allocated 29271.62548828125 
[2025-02-28 15:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.033919062465429306 norm:0.00012932911340612918 max memory_allocated 29271.62548828125 
[2025-02-28 15:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.03390902653336525 norm:0.0001333715918008238 max memory_allocated 29271.62548828125 
[2025-02-28 15:48:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.03390108048915863 norm:0.0001286696788156405 max memory_allocated 29271.62548828125 
[2025-02-28 15:48:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 15:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.06873905658721924 norm:0.002717076102271676 max memory_allocated 29271.62548828125 
[2025-02-28 15:50:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.052183229476213455 norm:0.001221065642312169 max memory_allocated 29271.62548828125 
[2025-02-28 15:50:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.045142121613025665 norm:0.0006407620967365801 max memory_allocated 29271.62548828125 
[2025-02-28 15:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.042413778603076935 norm:0.0004352520336396992 max memory_allocated 29271.62548828125 
[2025-02-28 15:52:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.0408686026930809 norm:0.0003405052120797336 max memory_allocated 29271.62548828125 
[2025-02-28 15:53:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.040013089776039124 norm:0.00029023224487900734 max memory_allocated 29271.62548828125 
[2025-02-28 15:53:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.03952019661664963 norm:0.00026650200015865266 max memory_allocated 29271.62548828125 
[2025-02-28 15:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.03918980807065964 norm:0.0002557021798565984 max memory_allocated 29271.62548828125 
[2025-02-28 15:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.03897777944803238 norm:0.0002410094311926514 max memory_allocated 29271.62548828125 
[2025-02-28 15:56:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.03885715827345848 norm:0.0002347111003473401 max memory_allocated 29271.62548828125 
[2025-02-28 15:56:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.03867427259683609 norm:0.00022281108249444515 max memory_allocated 29271.62548828125 
[2025-02-28 15:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.038586102426052094 norm:0.00022624827397521585 max memory_allocated 29271.62548828125 
[2025-02-28 15:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.03850936517119408 norm:0.00021311988530214876 max memory_allocated 29271.62548828125 
[2025-02-28 15:59:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.03839215263724327 norm:0.00020679681620094925 max memory_allocated 29271.62548828125 
[2025-02-28 15:59:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.038343727588653564 norm:0.00020559236872941256 max memory_allocated 29271.62548828125 
[2025-02-28 16:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.03826465457677841 norm:0.00020506839791778475 max memory_allocated 29271.62548828125 
[2025-02-28 16:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.038208458572626114 norm:0.00020010172738693655 max memory_allocated 29271.62548828125 
[2025-02-28 16:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.038150276988744736 norm:0.00018653423467185348 max memory_allocated 29271.62548828125 
[2025-02-28 16:02:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.03810877352952957 norm:0.00019663097918964922 max memory_allocated 29271.62548828125 
[2025-02-28 16:03:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.038087133318185806 norm:0.00018461344006936997 max memory_allocated 29271.62548828125 
[2025-02-28 16:03:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 16:04:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.05831815302371979 norm:0.0014926893636584282 max memory_allocated 29271.75048828125 
[2025-02-28 16:05:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.049658238887786865 norm:0.0007516003679484129 max memory_allocated 29271.75048828125 
[2025-02-28 16:06:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.045836880803108215 norm:0.0004517268971540034 max memory_allocated 29271.75048828125 
[2025-02-28 16:07:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.04390011727809906 norm:0.0003227189590688795 max memory_allocated 29271.75048828125 
[2025-02-28 16:07:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.04274311661720276 norm:0.0002558696432970464 max memory_allocated 29271.75048828125 
[2025-02-28 16:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.042066045105457306 norm:0.00021928970818407834 max memory_allocated 29271.75048828125 
[2025-02-28 16:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.0416906401515007 norm:0.00019497089670039713 max memory_allocated 29271.75048828125 
[2025-02-28 16:10:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.04145524650812149 norm:0.00018109324446413666 max memory_allocated 29271.75048828125 
[2025-02-28 16:10:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.041305091232061386 norm:0.00016789583605714142 max memory_allocated 29271.75048828125 
[2025-02-28 16:11:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.041206277906894684 norm:0.0001629256148589775 max memory_allocated 29271.75048828125 
[2025-02-28 16:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.04113921895623207 norm:0.00015735870692878962 max memory_allocated 29271.75048828125 
[2025-02-28 16:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.041073236614465714 norm:0.00014962854038458318 max memory_allocated 29271.75048828125 
[2025-02-28 16:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.041013650596141815 norm:0.00014765541709493846 max memory_allocated 29271.75048828125 
[2025-02-28 16:14:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.04098379611968994 norm:0.00014971689961384982 max memory_allocated 29271.75048828125 
[2025-02-28 16:15:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.04092460498213768 norm:0.00014143197040539235 max memory_allocated 29271.75048828125 
[2025-02-28 16:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.04089022055268288 norm:0.0001423983194399625 max memory_allocated 29271.75048828125 
[2025-02-28 16:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.04086342826485634 norm:0.000140201736940071 max memory_allocated 29271.75048828125 
[2025-02-28 16:17:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.040839746594429016 norm:0.00014218356227502227 max memory_allocated 29271.75048828125 
[2025-02-28 16:18:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.04083886742591858 norm:0.00014223788457456976 max memory_allocated 29271.75048828125 
[2025-02-28 16:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.04083890840411186 norm:0.00013576775381807238 max memory_allocated 29271.75048828125 
[2025-02-28 16:19:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 16:20:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.059127625077962875 norm:0.00106579321436584 max memory_allocated 29271.93798828125 
[2025-02-28 16:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.05156318470835686 norm:0.0005191679811105132 max memory_allocated 29271.93798828125 
[2025-02-28 16:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.048126623034477234 norm:0.00031098525505512953 max memory_allocated 29271.93798828125 
[2025-02-28 16:22:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.04645230993628502 norm:0.00023110117763280869 max memory_allocated 29271.93798828125 
[2025-02-28 16:23:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.045491740107536316 norm:0.00019256325322203338 max memory_allocated 29271.93798828125 
[2025-02-28 16:24:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.044947270303964615 norm:0.0001751793606672436 max memory_allocated 29271.93798828125 
[2025-02-28 16:24:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.044625066220760345 norm:0.00016249102191068232 max memory_allocated 29271.93798828125 
[2025-02-28 16:25:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.04444190114736557 norm:0.00015340822574216872 max memory_allocated 29271.93798828125 
[2025-02-28 16:26:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.044317133724689484 norm:0.00014279715833254158 max memory_allocated 29271.93798828125 
[2025-02-28 16:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.044219013303518295 norm:0.00014273289707489312 max memory_allocated 29271.93798828125 
[2025-02-28 16:27:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.04415849223732948 norm:0.00013905703963246197 max memory_allocated 29271.93798828125 
[2025-02-28 16:28:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.04409943148493767 norm:0.00013545798719860613 max memory_allocated 29271.93798828125 
[2025-02-28 16:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.04405726492404938 norm:0.00013462419155985117 max memory_allocated 29271.93798828125 
[2025-02-28 16:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.04403935745358467 norm:0.0001317898859269917 max memory_allocated 29271.93798828125 
[2025-02-28 16:30:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.044019270688295364 norm:0.00013086936087347567 max memory_allocated 29271.93798828125 
[2025-02-28 16:31:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.04397881403565407 norm:0.00012606807285919785 max memory_allocated 29271.93798828125 
[2025-02-28 16:32:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.043950870633125305 norm:0.00012581712508108467 max memory_allocated 29271.93798828125 
[2025-02-28 16:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.04393575340509415 norm:0.00012617306492757052 max memory_allocated 29271.93798828125 
[2025-02-28 16:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.043906763195991516 norm:0.0001256517571164295 max memory_allocated 29271.93798828125 
[2025-02-28 16:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.043879393488168716 norm:0.0001239396951859817 max memory_allocated 29271.93798828125 
[2025-02-28 16:34:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 16:35:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.06258076429367065 norm:0.001023717224597931 max memory_allocated 29272.12548828125 
[2025-02-28 16:36:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.05390540137887001 norm:0.0005138351116329432 max memory_allocated 29272.12548828125 
[2025-02-28 16:37:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.050175804644823074 norm:0.0003007705381605774 max memory_allocated 29272.12548828125 
[2025-02-28 16:38:07 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.04853469133377075 norm:0.00023280519235413522 max memory_allocated 29272.12548828125 
[2025-02-28 16:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.047593340277671814 norm:0.00019839177548419684 max memory_allocated 29272.12548828125 
[2025-02-28 16:39:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.047022104263305664 norm:0.00017875293269753456 max memory_allocated 29272.12548828125 
[2025-02-28 16:40:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.0466730035841465 norm:0.0001660287962295115 max memory_allocated 29272.12548828125 
[2025-02-28 16:41:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.04644104093313217 norm:0.0001565319689689204 max memory_allocated 29272.12548828125 
[2025-02-28 16:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.04629918560385704 norm:0.00014713467680849135 max memory_allocated 29272.12548828125 
[2025-02-28 16:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.04620785266160965 norm:0.0001414896105416119 max memory_allocated 29272.12548828125 
[2025-02-28 16:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.04612479358911514 norm:0.00013983718235976994 max memory_allocated 29272.12548828125 
[2025-02-28 16:44:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.04606078192591667 norm:0.00013484293594956398 max memory_allocated 29272.12548828125 
[2025-02-28 16:44:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.04600130766630173 norm:0.00013134360779076815 max memory_allocated 29272.12548828125 
[2025-02-28 16:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.04594597965478897 norm:0.00012686090485658497 max memory_allocated 29272.12548828125 
[2025-02-28 16:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.04591521620750427 norm:0.00012656388571485877 max memory_allocated 29272.12548828125 
[2025-02-28 16:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.04589168727397919 norm:0.00012227917613927275 max memory_allocated 29272.12548828125 
[2025-02-28 16:47:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.04585247486829758 norm:0.00011594915122259408 max memory_allocated 29272.12548828125 
[2025-02-28 16:48:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.045822590589523315 norm:0.00011389428982511163 max memory_allocated 29272.12548828125 
[2025-02-28 16:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.04580247402191162 norm:0.00011320387420710176 max memory_allocated 29272.12548828125 
[2025-02-28 16:50:14 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.04579134285449982 norm:0.00011049042223021388 max memory_allocated 29272.12548828125 
[2025-02-28 16:50:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 16:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.06259735673666 norm:0.0011299592442810535 max memory_allocated 29272.31298828125 
[2025-02-28 16:52:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.05553722754120827 norm:0.0005718788015656173 max memory_allocated 29272.31298828125 
[2025-02-28 16:52:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.052481863647699356 norm:0.00036831293255090714 max memory_allocated 29272.31298828125 
[2025-02-28 16:53:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.05068899318575859 norm:0.000274831400020048 max memory_allocated 29272.31298828125 
[2025-02-28 16:54:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.0495971217751503 norm:0.00022672262275591493 max memory_allocated 29272.31298828125 
[2025-02-28 16:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.04897458851337433 norm:0.0001992970210267231 max memory_allocated 29272.31298828125 
[2025-02-28 16:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.048591453582048416 norm:0.00018480594735592604 max memory_allocated 29272.31298828125 
[2025-02-28 16:56:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.048378340899944305 norm:0.00017505117284599692 max memory_allocated 29272.31298828125 
[2025-02-28 16:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.04822149500250816 norm:0.00016677264648023993 max memory_allocated 29272.31298828125 
[2025-02-28 16:58:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.04810767248272896 norm:0.00016209203749895096 max memory_allocated 29272.31298828125 
[2025-02-28 16:58:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.04800177365541458 norm:0.00015390862245112658 max memory_allocated 29272.31298828125 
[2025-02-28 16:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.04792889580130577 norm:0.0001437765604350716 max memory_allocated 29272.31298828125 
[2025-02-28 17:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.047869328409433365 norm:0.00014455607743002474 max memory_allocated 29272.31298828125 
[2025-02-28 17:01:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.04781587794423103 norm:0.00013765180483460426 max memory_allocated 29272.31298828125 
[2025-02-28 17:01:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.04779089242219925 norm:0.00013706486788578331 max memory_allocated 29272.31298828125 
[2025-02-28 17:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.047748807817697525 norm:0.0001324304030276835 max memory_allocated 29272.31298828125 
[2025-02-28 17:03:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.047711584717035294 norm:0.00013121156371198595 max memory_allocated 29272.31298828125 
[2025-02-28 17:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.04769420623779297 norm:0.00012282462557777762 max memory_allocated 29272.31298828125 
[2025-02-28 17:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.047654248774051666 norm:0.0001170534233096987 max memory_allocated 29272.31298828125 
[2025-02-28 17:05:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.047616563737392426 norm:0.00011829403229057789 max memory_allocated 29272.31298828125 
[2025-02-28 17:05:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 17:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.06313835084438324 norm:0.0009762354893609881 max memory_allocated 29272.50048828125 
[2025-02-28 17:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.05679159611463547 norm:0.0004984252154827118 max memory_allocated 29272.50048828125 
[2025-02-28 17:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.05383823812007904 norm:0.0003171452844981104 max memory_allocated 29272.50048828125 
[2025-02-28 17:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.0522937998175621 norm:0.00023868370044510812 max memory_allocated 29272.50048828125 
[2025-02-28 17:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.051423609256744385 norm:0.00020066520664840937 max memory_allocated 29272.50048828125 
[2025-02-28 17:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.05084364116191864 norm:0.00017686671344563365 max memory_allocated 29272.50048828125 
[2025-02-28 17:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.05047021806240082 norm:0.0001595017092768103 max memory_allocated 29272.50048828125 
[2025-02-28 17:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.05023815855383873 norm:0.0001497482298873365 max memory_allocated 29272.50048828125 
[2025-02-28 17:12:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.05007823556661606 norm:0.00014343077782541513 max memory_allocated 29272.50048828125 
[2025-02-28 17:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.04998175799846649 norm:0.00013586677960120142 max memory_allocated 29272.50048828125 
[2025-02-28 17:14:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.04990754276514053 norm:0.00013198053056839854 max memory_allocated 29272.50048828125 
[2025-02-28 17:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.04985459893941879 norm:0.0001281413424294442 max memory_allocated 29272.50048828125 
[2025-02-28 17:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.0497744157910347 norm:0.00011930014443350956 max memory_allocated 29272.50048828125 
[2025-02-28 17:16:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.04971781000494957 norm:0.00011775410530390218 max memory_allocated 29272.50048828125 
[2025-02-28 17:17:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.04969201609492302 norm:0.00011350728163961321 max memory_allocated 29272.50048828125 
[2025-02-28 17:18:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.04968378320336342 norm:0.00011037586955353618 max memory_allocated 29272.50048828125 
[2025-02-28 17:18:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.04965351149439812 norm:0.00011136943066958338 max memory_allocated 29272.50048828125 
[2025-02-28 17:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.04963881894946098 norm:0.00011179153807461262 max memory_allocated 29272.50048828125 
[2025-02-28 17:20:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.04960809275507927 norm:0.00011032262409571558 max memory_allocated 29272.50048828125 
[2025-02-28 17:21:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.049584902822971344 norm:0.00010968348942697048 max memory_allocated 29272.50048828125 
[2025-02-28 17:21:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 17:22:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.060513827949762344 norm:0.0006616311147809029 max memory_allocated 29272.68798828125 
[2025-02-28 17:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.05597035586833954 norm:0.0003574491129256785 max memory_allocated 29272.68798828125 
[2025-02-28 17:23:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.053497206419706345 norm:0.00023565316223539412 max memory_allocated 29272.68798828125 
[2025-02-28 17:24:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.05210736021399498 norm:0.00018438817642163485 max memory_allocated 29272.68798828125 
[2025-02-28 17:25:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.05137025564908981 norm:0.00016056859749369323 max memory_allocated 29272.68798828125 
[2025-02-28 17:26:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.05084095522761345 norm:0.00014489622844848782 max memory_allocated 29272.68798828125 
[2025-02-28 17:26:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.05050050467252731 norm:0.00013478654727805406 max memory_allocated 29272.68798828125 
[2025-02-28 17:27:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.05029894411563873 norm:0.00012643203081097454 max memory_allocated 29272.68798828125 
[2025-02-28 17:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.050169333815574646 norm:0.00011970977357123047 max memory_allocated 29272.68798828125 
[2025-02-28 17:29:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.0500820130109787 norm:0.00011741933121811599 max memory_allocated 29272.68798828125 
[2025-02-28 17:29:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.05002404749393463 norm:0.00010970359289785847 max memory_allocated 29272.68798828125 
[2025-02-28 17:30:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.04995950683951378 norm:0.0001039994676830247 max memory_allocated 29272.68798828125 
[2025-02-28 17:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.04992281645536423 norm:0.00010014563304139301 max memory_allocated 29272.68798828125 
[2025-02-28 17:32:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.049892377108335495 norm:9.961555042536929e-05 max memory_allocated 29272.68798828125 
[2025-02-28 17:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.04986266791820526 norm:9.827338362811133e-05 max memory_allocated 29272.68798828125 
[2025-02-28 17:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.049842070788145065 norm:9.647184197092429e-05 max memory_allocated 29272.68798828125 
[2025-02-28 17:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.04981992393732071 norm:9.32164111873135e-05 max memory_allocated 29272.68798828125 
[2025-02-28 17:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.04978581890463829 norm:9.210556891048327e-05 max memory_allocated 29272.68798828125 
[2025-02-28 17:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.049776364117860794 norm:9.185190720018e-05 max memory_allocated 29272.68798828125 
[2025-02-28 17:36:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.04976363852620125 norm:9.090151434065774e-05 max memory_allocated 29272.68798828125 
[2025-02-28 17:36:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 17:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.06485634297132492 norm:0.0010883656796067953 max memory_allocated 29272.87548828125 
[2025-02-28 17:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.05844445154070854 norm:0.0005379706854000688 max memory_allocated 29272.87548828125 
[2025-02-28 17:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.05549561232328415 norm:0.00034617396886460483 max memory_allocated 29272.87548828125 
[2025-02-28 17:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.053730558604002 norm:0.00024769766605459154 max memory_allocated 29272.87548828125 
[2025-02-28 17:40:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.052796799689531326 norm:0.0002077357639791444 max memory_allocated 29272.87548828125 
[2025-02-28 17:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.052172139286994934 norm:0.0001871797430794686 max memory_allocated 29272.87548828125 
[2025-02-28 17:42:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.051772281527519226 norm:0.00017017254140228033 max memory_allocated 29272.87548828125 
[2025-02-28 17:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.05152337998151779 norm:0.0001585534046171233 max memory_allocated 29272.87548828125 
[2025-02-28 17:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.05134979262948036 norm:0.00015022473235148937 max memory_allocated 29272.87548828125 
[2025-02-28 17:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.05124535784125328 norm:0.00014633391401730478 max memory_allocated 29272.87548828125 
[2025-02-28 17:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.051179222762584686 norm:0.00014423970424104482 max memory_allocated 29272.87548828125 
[2025-02-28 17:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.05108604580163956 norm:0.00013505836250260472 max memory_allocated 29272.87548828125 
[2025-02-28 17:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.051002442836761475 norm:0.00012997029989492148 max memory_allocated 29272.87548828125 
[2025-02-28 17:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.05093933269381523 norm:0.00012836589303333312 max memory_allocated 29272.87548828125 
[2025-02-28 17:48:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.05088849738240242 norm:0.00012621800124179572 max memory_allocated 29272.87548828125 
[2025-02-28 17:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.05083684250712395 norm:0.00012287819117773324 max memory_allocated 29272.87548828125 
[2025-02-28 17:49:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.05077372491359711 norm:0.00012027832417516038 max memory_allocated 29272.87548828125 
[2025-02-28 17:50:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.050728511065244675 norm:0.00011715387518052012 max memory_allocated 29272.87548828125 
[2025-02-28 17:51:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.050710342824459076 norm:0.00011493409692775458 max memory_allocated 29272.87548828125 
[2025-02-28 17:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.0506826676428318 norm:0.00010786516941152513 max memory_allocated 29272.87548828125 
[2025-02-28 17:52:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 17:53:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.06132437288761139 norm:0.0010164756095036864 max memory_allocated 29274.06298828125 
[2025-02-28 17:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.05709872767329216 norm:0.0005443098489195108 max memory_allocated 29274.06298828125 
[2025-02-28 17:54:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.05503144860267639 norm:0.00035747571382671595 max memory_allocated 29274.06298828125 
[2025-02-28 17:55:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.05360697582364082 norm:0.00025816913694143295 max memory_allocated 29274.06298828125 
[2025-02-28 17:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.05279019847512245 norm:0.00021394281066022813 max memory_allocated 29274.06298828125 
[2025-02-28 17:57:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.05225753411650658 norm:0.00018805928993970156 max memory_allocated 29274.06298828125 
[2025-02-28 17:57:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.051887694746255875 norm:0.00016586891433689743 max memory_allocated 29274.06298828125 
[2025-02-28 17:58:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.05169671028852463 norm:0.0001549778535263613 max memory_allocated 29274.06298828125 
[2025-02-28 17:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.05157528072595596 norm:0.00014677036961074919 max memory_allocated 29274.06298828125 
[2025-02-28 18:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.05148545652627945 norm:0.00014395802281796932 max memory_allocated 29274.06298828125 
[2025-02-28 18:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.05141939967870712 norm:0.00013775475963484496 max memory_allocated 29274.06298828125 
[2025-02-28 18:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.05136709287762642 norm:0.00013610333553515375 max memory_allocated 29274.06298828125 
[2025-02-28 18:02:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.0513266921043396 norm:0.00012881477596238256 max memory_allocated 29274.06298828125 
[2025-02-28 18:03:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.05127649009227753 norm:0.0001261696161236614 max memory_allocated 29274.06298828125 
[2025-02-28 18:03:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.051248688250780106 norm:0.00012617318134289235 max memory_allocated 29274.06298828125 
[2025-02-28 18:04:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.051210321485996246 norm:0.00012304216215852648 max memory_allocated 29274.06298828125 
[2025-02-28 18:05:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.051185786724090576 norm:0.0001210226328112185 max memory_allocated 29274.06298828125 
[2025-02-28 18:06:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.05117964744567871 norm:0.00012035465624649078 max memory_allocated 29274.06298828125 
[2025-02-28 18:06:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.051152464002370834 norm:0.00011823615204775706 max memory_allocated 29274.06298828125 
[2025-02-28 18:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.051137540489435196 norm:0.00011684207856887951 max memory_allocated 29274.06298828125 
[2025-02-28 18:07:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 18:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.06085330992937088 norm:0.0007435476290993392 max memory_allocated 29274.25048828125 
[2025-02-28 18:09:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.056900639086961746 norm:0.0003545955696608871 max memory_allocated 29274.25048828125 
[2025-02-28 18:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.05528264492750168 norm:0.00023711564426776022 max memory_allocated 29274.25048828125 
[2025-02-28 18:11:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.05414228141307831 norm:0.0001809300301829353 max memory_allocated 29274.25048828125 
[2025-02-28 18:11:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.05336279794573784 norm:0.00015019123384263366 max memory_allocated 29274.25048828125 
[2025-02-28 18:12:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.05280500277876854 norm:0.00012988668459001929 max memory_allocated 29274.25048828125 
[2025-02-28 18:13:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.052473220974206924 norm:0.00011825008550658822 max memory_allocated 29274.25048828125 
[2025-02-28 18:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.05230050906538963 norm:0.00011012895993189886 max memory_allocated 29274.25048828125 
[2025-02-28 18:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.05221369490027428 norm:0.0001044812670443207 max memory_allocated 29274.25048828125 
[2025-02-28 18:15:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.05215967819094658 norm:0.00010012745769927278 max memory_allocated 29274.25048828125 
[2025-02-28 18:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.052093811333179474 norm:9.731992759043351e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:17:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.05204198509454727 norm:9.413021325599402e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.05199626088142395 norm:9.04948465176858e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:18:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.05195005238056183 norm:8.814017928671092e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:19:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.05191902071237564 norm:8.367748523596674e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.05190156772732735 norm:8.199678995879367e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:20:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.051879145205020905 norm:7.95841624494642e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:21:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.051865026354789734 norm:7.884754450060427e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:22:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.05185319855809212 norm:7.738517888356e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.05182584375143051 norm:7.583684055134654e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:23:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 18:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.062166478484869 norm:0.0005950390477664769 max memory_allocated 29274.43798828125 
[2025-02-28 18:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.05902590975165367 norm:0.0003095415886491537 max memory_allocated 29274.43798828125 
[2025-02-28 18:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.05747175216674805 norm:0.00020651478553190827 max memory_allocated 29274.43798828125 
[2025-02-28 18:26:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.05640789866447449 norm:0.00015749661542940885 max memory_allocated 29274.43798828125 
[2025-02-28 18:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.05567740648984909 norm:0.00013323317398317158 max memory_allocated 29274.43798828125 
[2025-02-28 18:28:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.0551728792488575 norm:0.00011994767555734143 max memory_allocated 29274.43798828125 
[2025-02-28 18:28:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.05487467348575592 norm:0.0001129701267927885 max memory_allocated 29274.43798828125 
[2025-02-28 18:29:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.05469706654548645 norm:0.00010615560313453898 max memory_allocated 29274.43798828125 
[2025-02-28 18:30:18 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.05459677055478096 norm:9.906592458719388e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.05450994521379471 norm:9.350926120532677e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.0544554740190506 norm:9.05198830878362e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.05441698431968689 norm:8.868194709066302e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.054386500269174576 norm:8.678574522491544e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:34:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.05435943603515625 norm:8.338264160556719e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.054322317242622375 norm:8.021562825888395e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:35:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.054295863956213 norm:8.01940550445579e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.054263584315776825 norm:7.72747298469767e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.054257363080978394 norm:7.654847286175936e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.054244354367256165 norm:7.61283008614555e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.05423644930124283 norm:7.645441655768082e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:38:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 18:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.0642409473657608 norm:0.0005997460102662444 max memory_allocated 29274.62548828125 
[2025-02-28 18:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.06149892508983612 norm:0.00029515716596506536 max memory_allocated 29274.62548828125 
[2025-02-28 18:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.06004861742258072 norm:0.0001955884654307738 max memory_allocated 29274.62548828125 
[2025-02-28 18:41:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.05901286005973816 norm:0.00014583660231437534 max memory_allocated 29274.62548828125 
[2025-02-28 18:42:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.0582830086350441 norm:0.00012514792615547776 max memory_allocated 29274.62548828125 
[2025-02-28 18:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.057727813720703125 norm:0.00010660841508070007 max memory_allocated 29274.62548828125 
[2025-02-28 18:44:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.05742044374346733 norm:9.918666182784364e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:45:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.05725995823740959 norm:9.46883374126628e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.057182665914297104 norm:8.798197814030573e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:46:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.057122521102428436 norm:8.395282202400267e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:47:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.05707903206348419 norm:8.214841363951564e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:48:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.05704513564705849 norm:7.847634697100148e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:48:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.057002533227205276 norm:7.786008791299537e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:49:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.05700941011309624 norm:7.763445319142193e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:50:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.05698033422231674 norm:7.708719203947112e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.056954558938741684 norm:7.395493594231084e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:51:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.05693082511425018 norm:7.418093446176499e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.05693574994802475 norm:7.420207839459181e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:53:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.056919824331998825 norm:7.34220739104785e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:54:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.056917861104011536 norm:7.273769733728841e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:54:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 18:55:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.06968668848276138 norm:0.0007978041539900005 max memory_allocated 29274.81298828125 
[2025-02-28 18:55:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.06614922732114792 norm:0.0003969268873333931 max memory_allocated 29274.81298828125 
[2025-02-28 18:56:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.0644623190164566 norm:0.00025965250097215176 max memory_allocated 29274.81298828125 
[2025-02-28 18:57:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.0633108913898468 norm:0.00018882482254412025 max memory_allocated 29274.81298828125 
[2025-02-28 18:58:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.0624953918159008 norm:0.0001576688082423061 max memory_allocated 29274.81298828125 
[2025-02-28 18:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.06186559423804283 norm:0.0001365833741147071 max memory_allocated 29274.81298828125 
[2025-02-28 18:59:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.06152541935443878 norm:0.00012673248420469463 max memory_allocated 29274.81298828125 
[2025-02-28 19:00:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.061342719942331314 norm:0.00011502231791382656 max memory_allocated 29274.81298828125 
[2025-02-28 19:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.06123083084821701 norm:0.00010912620928138494 max memory_allocated 29274.81298828125 
[2025-02-28 19:02:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.06116713210940361 norm:0.00010528344137128443 max memory_allocated 29274.81298828125 
[2025-02-28 19:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.06110859289765358 norm:0.00010098960774485022 max memory_allocated 29274.81298828125 
[2025-02-28 19:03:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.06107151508331299 norm:9.710976155474782e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.06103305518627167 norm:9.434769162908196e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:05:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.06099789962172508 norm:9.061157470569015e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:05:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.060969915241003036 norm:8.960520062828436e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.06093793734908104 norm:8.386878471355885e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:07:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.0609181672334671 norm:8.253193664131686e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:08:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.060914576053619385 norm:8.460645767627284e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.0609060600399971 norm:8.051584882196039e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:09:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.060899317264556885 norm:7.989919686224312e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:09:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 19:10:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.07095709443092346 norm:0.0005188942304812372 max memory_allocated 29275.00048828125 
[2025-02-28 19:11:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.0690816342830658 norm:0.00025467254454270005 max memory_allocated 29275.00048828125 
[2025-02-28 19:12:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.06814995408058167 norm:0.0001648779580136761 max memory_allocated 29275.00048828125 
[2025-02-28 19:12:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.0673542469739914 norm:0.00012550526298582554 max memory_allocated 29275.00048828125 
[2025-02-28 19:13:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.06663139164447784 norm:0.00010283238952979445 max memory_allocated 29275.00048828125 
[2025-02-28 19:14:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.06609003990888596 norm:9.429298370378092e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.0657900795340538 norm:8.855503256199881e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.06566627323627472 norm:8.595515100751072e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.0655767172574997 norm:8.120357233565301e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:17:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.06554855406284332 norm:7.914932939456776e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.06550275534391403 norm:7.542766979895532e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.06548204272985458 norm:7.443673530360684e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:19:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.06545316427946091 norm:7.400951290037483e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.06543733179569244 norm:7.310952787520364e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:21:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.06541894376277924 norm:7.416494190692902e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:22:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.06540731340646744 norm:7.368614024017006e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.06539494544267654 norm:7.464326336048543e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:23:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.06537874042987823 norm:7.532129529863596e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:24:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.06536947190761566 norm:7.303793972823769e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:25:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.06536247581243515 norm:7.422487396979704e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:25:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 19:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.07637354731559753 norm:0.0005059334798716009 max memory_allocated 29275.18798828125 
[2025-02-28 19:26:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.07469026744365692 norm:0.00026431758305989206 max memory_allocated 29275.18798828125 
[2025-02-28 19:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.07374726235866547 norm:0.0001717003178782761 max memory_allocated 29275.18798828125 
[2025-02-28 19:28:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.07297638058662415 norm:0.0001308643550146371 max memory_allocated 29275.18798828125 
[2025-02-28 19:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.07224895805120468 norm:0.00010916207975242287 max memory_allocated 29275.18798828125 
[2025-02-28 19:29:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.07164823263883591 norm:9.752105688676238e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:30:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.07136665284633636 norm:8.947972673922777e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.07124750316143036 norm:0.00015796035586390644 max memory_allocated 29275.18798828125 
[2025-02-28 19:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.07118450105190277 norm:7.925237878225744e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:32:58 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.07112111896276474 norm:7.602722325827926e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.0710849016904831 norm:7.406144868582487e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:34:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.07104560732841492 norm:7.245355664053932e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:35:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.07102440297603607 norm:7.129676669137552e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.0710127130150795 norm:7.0356392825488e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:36:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.07098789513111115 norm:6.842094444436952e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.0709826648235321 norm:6.829159974586219e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:38:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.07096964120864868 norm:6.881843000883237e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:39:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.07095831632614136 norm:7.116913911886513e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.070950947701931 norm:6.9668676587753e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:40:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.07093609124422073 norm:7.052499131532386e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:40:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 19:41:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.08260863274335861 norm:0.0005042898701503873 max memory_allocated 29275.37548828125 
[2025-02-28 19:42:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.08102737367153168 norm:0.0002596236881799996 max memory_allocated 29275.37548828125 
[2025-02-28 19:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.08008819818496704 norm:0.00017353937437292188 max memory_allocated 29275.37548828125 
[2025-02-28 19:43:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.07928551733493805 norm:0.00012638316547963768 max memory_allocated 29275.37548828125 
[2025-02-28 19:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.07847802340984344 norm:0.00010245770681649446 max memory_allocated 29275.37548828125 
[2025-02-28 19:45:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.07790394127368927 norm:8.991340291686356e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:46:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.07763580977916718 norm:8.563568553654477e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:46:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.07754040509462357 norm:8.4979175881017e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:47:44 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.07749851047992706 norm:8.205699850805104e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:48:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.0774526447057724 norm:7.816716970410198e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:49:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.07742537558078766 norm:7.494298188248649e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.07740665227174759 norm:7.539973012171686e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:50:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.07740414142608643 norm:7.456559978891164e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:51:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.07738812267780304 norm:7.2465292760171e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:52:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.07738230377435684 norm:7.431478297803551e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:53:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.0773792415857315 norm:7.67357341828756e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:53:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.07738113403320312 norm:7.130066660465673e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.07737031579017639 norm:6.919853331055492e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:55:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.07736919820308685 norm:6.8310895585455e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.07736791670322418 norm:6.913709512446076e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:56:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 19:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.08922448754310608 norm:0.00046420079888775945 max memory_allocated 29275.56298828125 
[2025-02-28 19:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.08785908669233322 norm:0.0002517811954021454 max memory_allocated 29275.56298828125 
[2025-02-28 19:58:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.08706898987293243 norm:0.00017113445210270584 max memory_allocated 29275.56298828125 
[2025-02-28 19:59:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.08630155026912689 norm:0.00012743266415782273 max memory_allocated 29275.56298828125 
[2025-02-28 20:00:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.08546603471040726 norm:0.0001135815546149388 max memory_allocated 29275.56298828125 
[2025-02-28 20:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.08486160635948181 norm:9.310226596426219e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.0846126452088356 norm:8.342303772224113e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:02:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.08450856804847717 norm:7.604005804751068e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.08445882797241211 norm:7.15665373718366e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:04:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.08442195504903793 norm:6.961019244045019e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.08439052104949951 norm:6.812513311160728e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.08437095582485199 norm:6.635831232415512e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:06:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.08434721827507019 norm:6.263218529056758e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.0843331590294838 norm:6.227576523087919e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.08431488275527954 norm:6.253372703213245e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:08:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.08429951965808868 norm:6.298198422882706e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:09:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.08428652584552765 norm:6.212366133695468e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.08427827805280685 norm:6.14851014688611e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:10:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.08426961302757263 norm:6.165457307361066e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:11:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.08426904678344727 norm:6.264167313929647e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:11:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 20:12:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.09834370017051697 norm:0.0004898119950667024 max memory_allocated 29275.75048828125 
[2025-02-28 20:13:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.0968112051486969 norm:0.0002849593583960086 max memory_allocated 29275.75048828125 
[2025-02-28 20:14:12 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.09578173607587814 norm:0.00019690203771460801 max memory_allocated 29275.75048828125 
[2025-02-28 20:14:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.09477826952934265 norm:0.00014505797298625112 max memory_allocated 29275.75048828125 
[2025-02-28 20:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.09379762411117554 norm:0.00012001878349110484 max memory_allocated 29275.75048828125 
[2025-02-28 20:16:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.09316536784172058 norm:0.00010982691310346127 max memory_allocated 29275.75048828125 
[2025-02-28 20:17:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.09293796867132187 norm:9.865129686659202e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:17:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.09284812957048416 norm:9.265038534067571e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:18:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.09278441965579987 norm:8.721873018657789e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:19:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.092735156416893 norm:8.68650313350372e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:20:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.09271438419818878 norm:8.407628047280014e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.09269505739212036 norm:8.154936949722469e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:21:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.0926731526851654 norm:7.910028944024816e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.0926644578576088 norm:8.400287333643064e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:23:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.09265342354774475 norm:8.035780774662271e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:24:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.09265124052762985 norm:7.986775017343462e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.09264108538627625 norm:8.048950257943943e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.09263096749782562 norm:7.79693727963604e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.0926327109336853 norm:7.868411194067448e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:27:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.09263022243976593 norm:7.877809548517689e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:27:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 20:28:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.1055728867650032 norm:0.0003173179575242102 max memory_allocated 29275.93798828125 
[2025-02-28 20:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.10441797971725464 norm:0.00019006067304871976 max memory_allocated 29275.93798828125 
[2025-02-28 20:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.10367044806480408 norm:0.0001397287123836577 max memory_allocated 29275.93798828125 
[2025-02-28 20:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.10284606367349625 norm:0.00011278491729171947 max memory_allocated 29275.93798828125 
[2025-02-28 20:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.10192210972309113 norm:9.841098653851077e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.10134714841842651 norm:8.75057012308389e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.1011514812707901 norm:8.005507697816938e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.10104850679636002 norm:7.385286153294146e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.10098865628242493 norm:7.271880167536438e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.10095559805631638 norm:0.00010313413804396987 max memory_allocated 29275.93798828125 
[2025-02-28 20:35:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.10092931240797043 norm:6.977806333452463e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.10090617090463638 norm:6.752998888259754e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:37:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.10088590532541275 norm:6.743171252310276e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.10087020695209503 norm:6.663173553533852e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:38:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.10085861384868622 norm:6.52353628538549e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.10084956139326096 norm:6.605587986996397e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:40:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.10083883255720139 norm:6.614196172449738e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:41:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.10082598775625229 norm:6.590078555746004e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.1008257046341896 norm:6.680248043267056e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:42:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.1008184626698494 norm:6.519799353554845e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:42:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 20:43:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.1173315942287445 norm:0.0005785281537100673 max memory_allocated 29276.12548828125 
[2025-02-28 20:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.11554260551929474 norm:0.00034344728919677436 max memory_allocated 29276.12548828125 
[2025-02-28 20:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.11438505351543427 norm:0.00024050923821050674 max memory_allocated 29276.12548828125 
[2025-02-28 20:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.11334612965583801 norm:0.00018329908198211342 max memory_allocated 29276.12548828125 
[2025-02-28 20:46:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.11224562674760818 norm:0.00014815179747529328 max memory_allocated 29276.12548828125 
[2025-02-28 20:47:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.11163834482431412 norm:0.0001345089403912425 max memory_allocated 29276.12548828125 
[2025-02-28 20:48:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.11145283281803131 norm:0.00012714526383206248 max memory_allocated 29276.12548828125 
[2025-02-28 20:48:58 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.1113559752702713 norm:0.00011470397294033319 max memory_allocated 29276.12548828125 
[2025-02-28 20:49:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.11130807548761368 norm:0.00011167951743118465 max memory_allocated 29276.12548828125 
[2025-02-28 20:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.11125943064689636 norm:0.0001103048343793489 max memory_allocated 29276.12548828125 
[2025-02-28 20:51:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.11122598499059677 norm:0.00011252460535615683 max memory_allocated 29276.12548828125 
[2025-02-28 20:52:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.11119270324707031 norm:0.00010346625640522689 max memory_allocated 29276.12548828125 
[2025-02-28 20:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.11116974800825119 norm:0.00010062302317237481 max memory_allocated 29276.12548828125 
[2025-02-28 20:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.11115481704473495 norm:9.799788676900789e-05 max memory_allocated 29276.12548828125 
[2025-02-28 20:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.11114147305488586 norm:0.00010477159230504185 max memory_allocated 29276.12548828125 
[2025-02-28 20:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.11114654690027237 norm:0.00010590437159407884 max memory_allocated 29276.12548828125 
[2025-02-28 20:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.1111297756433487 norm:0.00010533027671044692 max memory_allocated 29276.12548828125 
[2025-02-28 20:56:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.11113005131483078 norm:0.00010547409328864887 max memory_allocated 29276.12548828125 
[2025-02-28 20:57:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.11112682521343231 norm:9.840120037551969e-05 max memory_allocated 29276.12548828125 
[2025-02-28 20:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.11111240833997726 norm:9.042275632964447e-05 max memory_allocated 29276.12548828125 
[2025-02-28 20:58:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 20:59:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.1263561248779297 norm:0.0004453767614904791 max memory_allocated 29276.31298828125 
[2025-02-28 20:59:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.12515129148960114 norm:0.0002576480037532747 max memory_allocated 29276.31298828125 
[2025-02-28 21:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.12433824688196182 norm:0.0001824464270612225 max memory_allocated 29276.31298828125 
[2025-02-28 21:01:24 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.12339156866073608 norm:0.00014063285198062658 max memory_allocated 29276.31298828125 
[2025-02-28 21:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.12235993891954422 norm:0.0001186100416816771 max memory_allocated 29276.31298828125 
[2025-02-28 21:02:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.1218310222029686 norm:0.00010227962775388733 max memory_allocated 29276.31298828125 
[2025-02-28 21:03:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.12168645113706589 norm:9.634689922677353e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.12159527093172073 norm:8.733812865102664e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:05:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.12153501063585281 norm:8.255192369688302e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:05:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.12149924784898758 norm:8.74135221238248e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:06:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.12148202955722809 norm:7.702426955802366e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:07:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.12147438526153564 norm:7.674654625589028e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.12145496159791946 norm:7.622411067131907e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:08:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.12143237888813019 norm:7.581173122162e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:09:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.12141493707895279 norm:7.475481106666848e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:10:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.12140367925167084 norm:7.485243258997798e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.12139575183391571 norm:7.573609764222056e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:12:01 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.12138039618730545 norm:7.288388587767258e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.12136858701705933 norm:7.377142901532352e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.12137287855148315 norm:7.221994019346312e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:13:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 21:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.13946811854839325 norm:0.0005011064931750298 max memory_allocated 29276.50048828125 
[2025-02-28 21:15:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.1376899778842926 norm:0.0002766936377156526 max memory_allocated 29276.50048828125 
[2025-02-28 21:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.13648056983947754 norm:0.00018728197028394789 max memory_allocated 29276.50048828125 
[2025-02-28 21:16:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.1353035271167755 norm:0.00014549678598996252 max memory_allocated 29276.50048828125 
[2025-02-28 21:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.1341809630393982 norm:0.00012240486103110015 max memory_allocated 29276.50048828125 
[2025-02-28 21:18:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.13371510803699493 norm:0.000107477797428146 max memory_allocated 29276.50048828125 
[2025-02-28 21:19:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.133560910820961 norm:9.83517529675737e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:20:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.13348309695720673 norm:9.34223280637525e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:20:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.13341760635375977 norm:8.772294677328318e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:21:31 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.13336721062660217 norm:8.434598566964269e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.13332882523536682 norm:8.087149763014168e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.1333065927028656 norm:7.974547770572826e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:23:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.1332966685295105 norm:7.941463991301134e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:24:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.13327623903751373 norm:7.681066927034408e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:25:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.13327188789844513 norm:7.7391232480295e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:26:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.1332544982433319 norm:7.684569573029876e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:26:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.13324160873889923 norm:7.580837700515985e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:27:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.13322478532791138 norm:7.519667997257784e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.13322651386260986 norm:7.58793976274319e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.13321135938167572 norm:7.565740088466555e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:29:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 21:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.15115678310394287 norm:0.00044248418998904526 max memory_allocated 29276.68798828125 
[2025-02-28 21:30:57 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.1498732566833496 norm:0.00024077514535747468 max memory_allocated 29276.68798828125 
[2025-02-28 21:31:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.148886039853096 norm:0.00016960789798758924 max memory_allocated 29276.68798828125 
[2025-02-28 21:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.1476762294769287 norm:0.0001345241180388257 max memory_allocated 29276.68798828125 
[2025-02-28 21:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.1465812474489212 norm:0.00011350377462804317 max memory_allocated 29276.68798828125 
[2025-02-28 21:33:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.14620909094810486 norm:0.00010118188220076263 max memory_allocated 29276.68798828125 
[2025-02-28 21:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.1460976004600525 norm:9.163252252619714e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.146040678024292 norm:8.709947724128142e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:36:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.14600764214992523 norm:8.6582062067464e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:37:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.14597132802009583 norm:8.690628601470962e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.14593642950057983 norm:8.459390664938837e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.1459055244922638 norm:8.32122823339887e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.14589107036590576 norm:8.483079727739096e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.14588084816932678 norm:8.281618647743016e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:40:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.1458650529384613 norm:8.246395009336993e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:41:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.14584921300411224 norm:8.235676068579778e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:42:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.14583441615104675 norm:8.483439887640998e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.14582952857017517 norm:8.416148921241984e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.14581412076950073 norm:8.421309757977724e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.14581361413002014 norm:8.51457443786785e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:44:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-02-28 21:45:43 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.16687320172786713 norm:0.0005589791107922792 max memory_allocated 29276.87548828125 
[2025-02-28 21:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.1650649458169937 norm:0.00030507834162563086 max memory_allocated 29276.87548828125 
[2025-02-28 21:47:14 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.1637296974658966 norm:0.00021054786338936538 max memory_allocated 29276.87548828125 
[2025-02-28 21:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.1622380167245865 norm:0.00016063069051597267 max memory_allocated 29276.87548828125 
[2025-02-28 21:48:45 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.16105994582176208 norm:0.00013195103383623064 max memory_allocated 29276.87548828125 
[2025-02-28 21:49:30 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.16070687770843506 norm:0.00012018329289276153 max memory_allocated 29276.87548828125 
[2025-02-28 21:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.16054968535900116 norm:0.00011017203360097483 max memory_allocated 29276.87548828125 
[2025-02-28 21:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.16046229004859924 norm:0.00010413322888780385 max memory_allocated 29276.87548828125 
[2025-02-28 21:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.1603996902704239 norm:9.930409578373656e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:52:32 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.16034509241580963 norm:9.477009734837338e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:53:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.16031306982040405 norm:9.073624823940918e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:54:03 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.16028659045696259 norm:8.93086616997607e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.16026054322719574 norm:8.669716044096276e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.16023893654346466 norm:8.513400098308921e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:56:19 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.16022425889968872 norm:0.00012532543041743338 max memory_allocated 29276.87548828125 
[2025-02-28 21:57:05 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.16021186113357544 norm:8.433528273599222e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:57:50 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.16021007299423218 norm:8.422300015809014e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:58:35 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.1601884961128235 norm:8.512238855473697e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:59:21 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.16017964482307434 norm:8.445605635643005e-05 max memory_allocated 29276.87548828125 
[2025-02-28 22:00:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.1601639837026596 norm:8.400084334425628e-05 max memory_allocated 29276.87548828125 
[2025-02-28 22:00:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-02-28 22:01:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.181470587849617 norm:0.000498675974085927 max memory_allocated 29277.06298828125 
[2025-02-28 22:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.17969049513339996 norm:0.0002813859027810395 max memory_allocated 29277.06298828125 
[2025-02-28 22:02:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.17832554876804352 norm:0.00019071504357270896 max memory_allocated 29277.06298828125 
[2025-02-28 22:03:29 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.1768123209476471 norm:0.0001427842944394797 max memory_allocated 29277.06298828125 
[2025-02-28 22:04:15 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.17568059265613556 norm:0.00012351723853498697 max memory_allocated 29277.06298828125 
[2025-02-28 22:05:00 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.17539402842521667 norm:0.0001157484803115949 max memory_allocated 29277.06298828125 
[2025-02-28 22:05:46 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.17525246739387512 norm:0.00010952827869914472 max memory_allocated 29277.06298828125 
[2025-02-28 22:06:31 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.1751812845468521 norm:0.00010381029278505594 max memory_allocated 29277.06298828125 
[2025-02-28 22:07:17 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.17514574527740479 norm:0.00010185635619563982 max memory_allocated 29277.06298828125 
[2025-02-28 22:08:02 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.17511846125125885 norm:9.749231685418636e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.17507986724376678 norm:9.713116742204875e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:09:33 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.17505113780498505 norm:9.602936188457534e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:10:18 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.17502881586551666 norm:9.744463750394061e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:11:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.1750117689371109 norm:9.37824443099089e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.17499780654907227 norm:9.64655919233337e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.1749740093946457 norm:9.430819045519456e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.17496149241924286 norm:9.430490172235295e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:14:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.174959197640419 norm:9.319778473582119e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.1749657541513443 norm:9.398462134413421e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:15:36 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.1749369204044342 norm:9.421975119039416e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:15:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-02-28 22:16:41 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.20135436952114105 norm:0.0005483106942847371 max memory_allocated 29277.25048828125 
[2025-02-28 22:17:27 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.19892391562461853 norm:0.0002912324562203139 max memory_allocated 29277.25048828125 
[2025-02-28 22:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.19712644815444946 norm:0.00020011834567412734 max memory_allocated 29277.25048828125 
[2025-02-28 22:18:58 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.1953125 norm:0.00015493991668336093 max memory_allocated 29277.25048828125 
[2025-02-28 22:19:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.19421958923339844 norm:0.00013712568033952266 max memory_allocated 29277.25048828125 
[2025-02-28 22:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.19391408562660217 norm:0.00012406970199663192 max memory_allocated 29277.25048828125 
[2025-02-28 22:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.19375944137573242 norm:0.00011579065176192671 max memory_allocated 29277.25048828125 
[2025-02-28 22:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.19366836547851562 norm:0.00011110256309621036 max memory_allocated 29277.25048828125 
[2025-02-28 22:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.19358006119728088 norm:0.00010570529411779717 max memory_allocated 29277.25048828125 
[2025-02-28 22:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.19352909922599792 norm:0.00010198797099292278 max memory_allocated 29277.25048828125 
[2025-02-28 22:24:15 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.1934892237186432 norm:0.00010149405716219917 max memory_allocated 29277.25048828125 
[2025-02-28 22:25:01 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.19347316026687622 norm:9.91880806395784e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.193446084856987 norm:9.844664600677788e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:26:32 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.19341963529586792 norm:9.346254955744371e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:27:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.1934039443731308 norm:9.554334974382073e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:28:03 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.19339923560619354 norm:9.683943062555045e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.19338802993297577 norm:9.589760156814009e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:29:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.19337648153305054 norm:8.972037176135927e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:30:19 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.19337156414985657 norm:9.04785847524181e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:31:04 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.19336055219173431 norm:9.0215471573174e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:31:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-02-28 22:32:10 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.22201931476593018 norm:0.0010052744764834642 max memory_allocated 29277.43798828125 
[2025-02-28 22:32:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.21938909590244293 norm:0.0005374387837946415 max memory_allocated 29277.43798828125 
[2025-02-28 22:33:40 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.21728962659835815 norm:0.0003439128340687603 max memory_allocated 29277.43798828125 
[2025-02-28 22:34:26 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.2151862382888794 norm:0.00024350291641894728 max memory_allocated 29277.43798828125 
[2025-02-28 22:35:11 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.21415117383003235 norm:0.00019020074978470802 max memory_allocated 29277.43798828125 
[2025-02-28 22:35:57 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.21387344598770142 norm:0.00015953209367580712 max memory_allocated 29277.43798828125 
[2025-02-28 22:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.21370859444141388 norm:0.0001397639134665951 max memory_allocated 29277.43798828125 
[2025-02-28 22:37:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.21360249817371368 norm:0.00012758858792949468 max memory_allocated 29277.43798828125 
[2025-02-28 22:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.21355313062667847 norm:0.00012090263771824539 max memory_allocated 29277.43798828125 
[2025-02-28 22:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.2135079801082611 norm:0.00011523602734087035 max memory_allocated 29277.43798828125 
[2025-02-28 22:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.21345941722393036 norm:0.00011165304749738425 max memory_allocated 29277.43798828125 
[2025-02-28 22:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.2134290337562561 norm:0.00010778181604109704 max memory_allocated 29277.43798828125 
[2025-02-28 22:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.21340101957321167 norm:0.00010580624075373635 max memory_allocated 29277.43798828125 
[2025-02-28 22:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.21338044106960297 norm:0.00010495679453015327 max memory_allocated 29277.43798828125 
[2025-02-28 22:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.21336960792541504 norm:0.00010524207027629018 max memory_allocated 29277.43798828125 
[2025-02-28 22:43:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.21334213018417358 norm:0.00010381959145888686 max memory_allocated 29277.43798828125 
[2025-02-28 22:44:16 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.21333786845207214 norm:0.00010390604438725859 max memory_allocated 29277.43798828125 
[2025-02-28 22:45:02 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.21332791447639465 norm:0.0001029197737807408 max memory_allocated 29277.43798828125 
[2025-02-28 22:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.21331572532653809 norm:0.00010255505912937224 max memory_allocated 29277.43798828125 
[2025-02-28 22:46:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.2133009135723114 norm:0.00010133921750821173 max memory_allocated 29277.43798828125 
[2025-02-28 22:46:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-02-28 22:46:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 22:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.25031039118766785 norm:0.006341326981782913 max memory_allocated 29277.77001953125 
[2025-02-28 22:48:24 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.24578750133514404 norm:0.005137796513736248 max memory_allocated 29277.77001953125 
[2025-02-28 22:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.24275615811347961 norm:0.00419399281963706 max memory_allocated 29277.77001953125 
[2025-02-28 22:49:55 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.24009549617767334 norm:0.0033983655739575624 max memory_allocated 29277.77001953125 
[2025-02-28 22:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.23882223665714264 norm:0.002802689094096422 max memory_allocated 29277.77001953125 
[2025-02-28 22:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.23836928606033325 norm:0.002373222727328539 max memory_allocated 29277.77001953125 
[2025-02-28 22:52:12 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.23809358477592468 norm:0.0021138819865882397 max memory_allocated 29277.77001953125 
[2025-02-28 22:52:58 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.23796512186527252 norm:0.0020494156051427126 max memory_allocated 29277.77001953125 
[2025-02-28 22:53:43 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.23791028559207916 norm:0.002033718628808856 max memory_allocated 29277.77001953125 
[2025-02-28 22:54:29 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.23778586089611053 norm:0.0020085370633751154 max memory_allocated 29277.77001953125 
[2025-02-28 22:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.2377038151025772 norm:0.0019368223147466779 max memory_allocated 29277.77001953125 
[2025-02-28 22:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.23771624267101288 norm:0.0016961904475465417 max memory_allocated 29277.77001953125 
[2025-02-28 22:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.23756152391433716 norm:0.001781425904482603 max memory_allocated 29277.77001953125 
[2025-02-28 22:57:31 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.23764026165008545 norm:0.0016010889085009694 max memory_allocated 29277.77001953125 
[2025-02-28 22:58:17 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.23750707507133484 norm:0.0017788682598620653 max memory_allocated 29277.77001953125 
[2025-02-28 22:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.23754528164863586 norm:0.0015649815322831273 max memory_allocated 29277.77001953125 
[2025-02-28 22:59:48 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.2374035120010376 norm:0.001706219045445323 max memory_allocated 29277.77001953125 
[2025-02-28 23:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.2374609261751175 norm:0.0015518568689003587 max memory_allocated 29277.77001953125 
[2025-02-28 23:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.2373848557472229 norm:0.0016494804294779897 max memory_allocated 29277.77001953125 
[2025-02-28 23:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.23739558458328247 norm:0.0015734905609861016 max memory_allocated 29277.77001953125 
[2025-02-28 23:02:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-02-28 23:02:25 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 23:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.28168347477912903 norm:0.006438027136027813 max memory_allocated 29277.95751953125 
[2025-02-28 23:03:56 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.2758820652961731 norm:0.005327604711055756 max memory_allocated 29277.95751953125 
[2025-02-28 23:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.27120262384414673 norm:0.004149062093347311 max memory_allocated 29277.95751953125 
[2025-02-28 23:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.26799365878105164 norm:0.003399645211175084 max memory_allocated 29277.95751953125 
[2025-02-28 23:06:13 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.2667311429977417 norm:0.0028889980167150497 max memory_allocated 29277.95751953125 
[2025-02-28 23:06:59 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.26617440581321716 norm:0.002466899575665593 max memory_allocated 29277.95751953125 
[2025-02-28 23:07:44 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.26579219102859497 norm:0.0022284281440079212 max memory_allocated 29277.95751953125 
[2025-02-28 23:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.2655286490917206 norm:0.0020596617832779884 max memory_allocated 29277.95751953125 
[2025-02-28 23:09:15 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.26540032029151917 norm:0.002060965169221163 max memory_allocated 29277.95751953125 
[2025-02-28 23:10:01 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.2653447687625885 norm:0.00209830398671329 max memory_allocated 29277.95751953125 
[2025-02-28 23:10:47 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.2652314305305481 norm:0.0020075428765267134 max memory_allocated 29277.95751953125 
[2025-02-28 23:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.26510488986968994 norm:0.0019094693707302213 max memory_allocated 29277.95751953125 
[2025-02-28 23:12:18 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.26506590843200684 norm:0.0019198908703401685 max memory_allocated 29277.95751953125 
[2025-02-28 23:13:03 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.26498404145240784 norm:0.001870906911790371 max memory_allocated 29277.95751953125 
[2025-02-28 23:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.26495224237442017 norm:0.0018853333313018084 max memory_allocated 29277.95751953125 
[2025-02-28 23:14:35 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.26493826508522034 norm:0.0018415726954117417 max memory_allocated 29277.95751953125 
[2025-02-28 23:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.2649421989917755 norm:0.001880347030237317 max memory_allocated 29277.95751953125 
[2025-02-28 23:16:06 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.2649468183517456 norm:0.0017749902326613665 max memory_allocated 29277.95751953125 
[2025-02-28 23:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.2648448646068573 norm:0.0017483476549386978 max memory_allocated 29277.95751953125 
[2025-02-28 23:17:37 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.2647782266139984 norm:0.0017063484992831945 max memory_allocated 29277.95751953125 
[2025-02-28 23:17:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-02-28 23:17:58 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 23:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.33785533905029297 norm:0.00823906622827053 max memory_allocated 29278.14501953125 
[2025-02-28 23:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.3259499967098236 norm:0.0039045114535838366 max memory_allocated 29278.14501953125 
[2025-02-28 23:20:14 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.3163037896156311 norm:0.003928236197680235 max memory_allocated 29278.14501953125 
[2025-02-28 23:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.3124718964099884 norm:0.003873244160786271 max memory_allocated 29278.14501953125 
[2025-02-28 23:21:46 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.31084808707237244 norm:0.0037546236999332905 max memory_allocated 29278.14501953125 
[2025-02-28 23:22:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.3102421164512634 norm:0.0036800222005695105 max memory_allocated 29278.14501953125 
[2025-02-28 23:23:17 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.30974504351615906 norm:0.0035347414668649435 max memory_allocated 29278.14501953125 
[2025-02-28 23:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.3094138205051422 norm:0.0035113925114274025 max memory_allocated 29278.14501953125 
[2025-02-28 23:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.30897292494773865 norm:0.0034644566476345062 max memory_allocated 29278.14501953125 
[2025-02-28 23:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.3087567985057831 norm:0.003320221323519945 max memory_allocated 29278.14501953125 
[2025-02-28 23:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.30853667855262756 norm:0.0032448768615722656 max memory_allocated 29278.14501953125 
[2025-02-28 23:27:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.3084656298160553 norm:0.0033941520377993584 max memory_allocated 29278.14501953125 
[2025-02-28 23:27:50 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.30825066566467285 norm:0.0032510042656213045 max memory_allocated 29278.14501953125 
[2025-02-28 23:28:36 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.3081566095352173 norm:0.0032801590859889984 max memory_allocated 29278.14501953125 
[2025-02-28 23:29:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.30806535482406616 norm:0.003257656004279852 max memory_allocated 29278.14501953125 
[2025-02-28 23:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.3079415559768677 norm:0.0032042739912867546 max memory_allocated 29278.14501953125 
[2025-02-28 23:30:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.30782198905944824 norm:0.0031003113836050034 max memory_allocated 29278.14501953125 
[2025-02-28 23:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.30781787633895874 norm:0.0031234221532940865 max memory_allocated 29278.14501953125 
[2025-02-28 23:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.30766794085502625 norm:0.0030238586477935314 max memory_allocated 29278.14501953125 
[2025-02-28 23:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.3077227473258972 norm:0.00310219032689929 max memory_allocated 29278.14501953125 
[2025-02-28 23:33:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-02-28 23:33:31 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 23:34:17 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.488867849111557 norm:0.05044566094875336 max memory_allocated 29278.33251953125 
[2025-02-28 23:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.4448285400867462 norm:0.03041265904903412 max memory_allocated 29278.33251953125 
[2025-02-28 23:35:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.4307893216609955 norm:0.02045503631234169 max memory_allocated 29278.33251953125 
[2025-02-28 23:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.42201289534568787 norm:0.014517214149236679 max memory_allocated 29278.33251953125 
[2025-02-28 23:37:19 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.416688472032547 norm:0.011142310686409473 max memory_allocated 29278.33251953125 
[2025-02-28 23:38:05 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.41345858573913574 norm:0.009314902126789093 max memory_allocated 29278.33251953125 
[2025-02-28 23:38:50 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.4115223288536072 norm:0.009292456321418285 max memory_allocated 29278.33251953125 
[2025-02-28 23:39:36 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.41035196185112 norm:0.009375442750751972 max memory_allocated 29278.33251953125 
[2025-02-28 23:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.4092446267604828 norm:0.009226847440004349 max memory_allocated 29278.33251953125 
[2025-02-28 23:41:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.4087013006210327 norm:0.009312928654253483 max memory_allocated 29278.33251953125 
[2025-02-28 23:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.4079838991165161 norm:0.009189989417791367 max memory_allocated 29278.33251953125 
[2025-02-28 23:42:38 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.4072430729866028 norm:0.00929947104305029 max memory_allocated 29278.33251953125 
[2025-02-28 23:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.4067884087562561 norm:0.008846689015626907 max memory_allocated 29278.33251953125 
[2025-02-28 23:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.40625667572021484 norm:0.00867764838039875 max memory_allocated 29278.33251953125 
[2025-02-28 23:44:55 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.4059317409992218 norm:0.008328220807015896 max memory_allocated 29278.33251953125 
[2025-02-28 23:45:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.40546756982803345 norm:0.008275488391518593 max memory_allocated 29278.33251953125 
[2025-02-28 23:46:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.40537676215171814 norm:0.008331339806318283 max memory_allocated 29278.33251953125 
[2025-02-28 23:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.40512222051620483 norm:0.008337777107954025 max memory_allocated 29278.33251953125 
[2025-02-28 23:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.4047725796699524 norm:0.007847572676837444 max memory_allocated 29278.33251953125 
[2025-02-28 23:48:43 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.4044416844844818 norm:0.007799115497618914 max memory_allocated 29278.33251953125 
[2025-02-28 23:48:56 root] (main_calib_config2.py 380): INFO 37210.07077431679
[2025-02-28 23:49:09 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 23:50:56 root] (main_calib_config2.py 159): INFO wikitext2 : 5.044058322906494
[2025-02-28 23:50:56 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 23:53:40 root] (main_calib_config2.py 159): INFO c4 : 6.6805500984191895
[2025-03-01 01:54:51 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.044058322906494, 'c4': 6.6805500984191895, 'results': {'winogrande': {'acc': 0.6882399368587214, 'acc_stderr': 0.013018571197638551}, 'piqa': {'acc': 0.7840043525571273, 'acc_stderr': 0.00960123630355355, 'acc_norm': 0.7856365614798694, 'acc_norm_stderr': 0.00957484213605097}, 'boolq': {'acc': 0.690519877675841, 'acc_stderr': 0.008085316258869088}, 'arc_easy': {'acc': 0.7175925925925926, 'acc_stderr': 0.009237303403479339, 'acc_norm': 0.5652356902356902, 'acc_norm_stderr': 0.010172083670402786}, 'hellaswag': {'acc': 0.5889265086636128, 'acc_stderr': 0.004910229643262741, 'acc_norm': 0.7531368253335989, 'acc_norm_stderr': 0.004303052185107719}, 'arc_challenge': {'acc': 0.4402730375426621, 'acc_stderr': 0.014506769524804243, 'acc_norm': 0.4325938566552901, 'acc_norm_stderr': 0.014478005694182535}}, 'versions': {'winogrande': 0, 'piqa': 0, 'boolq': 1, 'arc_easy': 0, 'hellaswag': 0, 'arc_challenge': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
