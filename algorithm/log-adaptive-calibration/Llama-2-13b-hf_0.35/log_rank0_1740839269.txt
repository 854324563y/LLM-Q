[2025-03-01 14:27:49 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.35', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.35.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-01 14:28:23 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-01 14:28:23 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.35.pkl
[2025-03-01 14:28:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-01 14:29:00 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.0429898165166378 norm:0.030937159433960915 max memory_allocated 29271.02001953125 
[2025-03-01 14:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.028667375445365906 norm:0.018673527985811234 max memory_allocated 29271.02001953125 
[2025-03-01 14:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.02289346419274807 norm:0.01438816636800766 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.020919861271977425 norm:0.013105201534926891 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.02000998705625534 norm:0.012545900419354439 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0194625835865736 norm:0.008456734009087086 max memory_allocated 29271.02001953125 
[2025-03-01 14:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.019200798124074936 norm:0.010193951427936554 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.018968040123581886 norm:0.008418659679591656 max memory_allocated 29271.02001953125 
[2025-03-01 14:36:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.018855290487408638 norm:0.007630540989339352 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.01877683959901333 norm:0.00505485525354743 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.01869361288845539 norm:0.005844205152243376 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.01878967694938183 norm:0.005736203398555517 max memory_allocated 29271.02001953125 
[2025-03-01 14:39:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.018697241321206093 norm:0.004417389165610075 max memory_allocated 29271.02001953125 
[2025-03-01 14:40:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.018781233578920364 norm:0.0060865129344165325 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.018785540014505386 norm:0.004218827933073044 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.01856074295938015 norm:0.0050168284215033054 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.018529102206230164 norm:0.004281496629118919 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.018563445657491684 norm:0.0036168061196804047 max memory_allocated 29271.02001953125 
[2025-03-01 14:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.018466128036379814 norm:0.00339347030967474 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.01860000565648079 norm:0.0052087437361478806 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-01 14:45:44 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.09752096235752106 norm:0.024250026792287827 max memory_allocated 29271.02001953125 
[2025-03-01 14:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.0807584673166275 norm:0.01651572808623314 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.07209315896034241 norm:0.011967919766902924 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.06911863386631012 norm:0.009490962140262127 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.067348413169384 norm:0.007489064242690802 max memory_allocated 29271.02001953125 
[2025-03-01 14:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.06615076214075089 norm:0.00609203428030014 max memory_allocated 29271.02001953125 
[2025-03-01 14:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.06538963317871094 norm:0.005101343151181936 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.06491246819496155 norm:0.004502202849835157 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.06459259241819382 norm:0.0042456998489797115 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.06427180022001266 norm:0.004216885194182396 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.06413755565881729 norm:0.004171011969447136 max memory_allocated 29271.02001953125 
[2025-03-01 14:55:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.06399524956941605 norm:0.004089644644409418 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.0638812705874443 norm:0.004067305475473404 max memory_allocated 29271.02001953125 
[2025-03-01 14:57:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.06370846927165985 norm:0.00398182962089777 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.06369908154010773 norm:0.003925706259906292 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.06356760114431381 norm:0.003786670044064522 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.06354811787605286 norm:0.0037478692829608917 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.06341560184955597 norm:0.003601351287215948 max memory_allocated 29271.02001953125 
[2025-03-01 15:01:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.06350133568048477 norm:0.003591313026845455 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.06336173415184021 norm:0.00352601520717144 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-01 15:02:35 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 15:03:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.13469162583351135 norm:0.024241801351308823 max memory_allocated 29271.39501953125 
[2025-03-01 15:04:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.11790662258863449 norm:0.01660780794918537 max memory_allocated 29271.39501953125 
[2025-03-01 15:05:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.1072416752576828 norm:0.011580713093280792 max memory_allocated 29271.39501953125 
[2025-03-01 15:05:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.10313749313354492 norm:0.008763273246586323 max memory_allocated 29271.39501953125 
[2025-03-01 15:06:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.10052318871021271 norm:0.006618315353989601 max memory_allocated 29271.39501953125 
[2025-03-01 15:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.0989295169711113 norm:0.004895718768239021 max memory_allocated 29271.39501953125 
[2025-03-01 15:08:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.09799472242593765 norm:0.004598319064825773 max memory_allocated 29271.39501953125 
[2025-03-01 15:09:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.09732498228549957 norm:0.004472263623028994 max memory_allocated 29271.39501953125 
[2025-03-01 15:10:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.09677955508232117 norm:0.004297242965549231 max memory_allocated 29271.39501953125 
[2025-03-01 15:10:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.09641805291175842 norm:0.004108359105885029 max memory_allocated 29271.39501953125 
[2025-03-01 15:11:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.09607568383216858 norm:0.003875993425026536 max memory_allocated 29271.39501953125 
[2025-03-01 15:12:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.095832459628582 norm:0.003686723066493869 max memory_allocated 29271.39501953125 
[2025-03-01 15:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.09567008167505264 norm:0.003660790389403701 max memory_allocated 29271.39501953125 
[2025-03-01 15:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.09553087502717972 norm:0.003684843424707651 max memory_allocated 29271.39501953125 
[2025-03-01 15:15:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.09535659849643707 norm:0.0036279521882534027 max memory_allocated 29271.39501953125 
[2025-03-01 15:15:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.09521890431642532 norm:0.003548617707565427 max memory_allocated 29271.39501953125 
[2025-03-01 15:16:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.09513695538043976 norm:0.0035696581471711397 max memory_allocated 29271.39501953125 
[2025-03-01 15:17:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.0950259119272232 norm:0.0034808379132300615 max memory_allocated 29271.39501953125 
[2025-03-01 15:18:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.0949212983250618 norm:0.0034425121266394854 max memory_allocated 29271.39501953125 
[2025-03-01 15:19:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.09487030655145645 norm:0.0033714063465595245 max memory_allocated 29271.39501953125 
[2025-03-01 15:19:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-01 15:20:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.2798500657081604 norm:0.020389437675476074 max memory_allocated 29271.39501953125 
[2025-03-01 15:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.2416502833366394 norm:0.012643299996852875 max memory_allocated 29271.39501953125 
[2025-03-01 15:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.1976478397846222 norm:0.011144043877720833 max memory_allocated 29271.39501953125 
[2025-03-01 15:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.1824370175600052 norm:0.010226566344499588 max memory_allocated 29271.39501953125 
[2025-03-01 15:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.1742965131998062 norm:0.009121106937527657 max memory_allocated 29271.39501953125 
[2025-03-01 15:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.16874049603939056 norm:0.008158378303050995 max memory_allocated 29271.39501953125 
[2025-03-01 15:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.16562075912952423 norm:0.008596873842179775 max memory_allocated 29271.39501953125 
[2025-03-01 15:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.16173143684864044 norm:0.007982129231095314 max memory_allocated 29271.39501953125 
[2025-03-01 15:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.15914160013198853 norm:0.007130162324756384 max memory_allocated 29271.39501953125 
[2025-03-01 15:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.15750892460346222 norm:0.006738185882568359 max memory_allocated 29271.39501953125 
[2025-03-01 15:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.1557367593050003 norm:0.005577867850661278 max memory_allocated 29271.39501953125 
[2025-03-01 15:29:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.15496127307415009 norm:0.005559596233069897 max memory_allocated 29271.39501953125 
[2025-03-01 15:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.15268263220787048 norm:0.005616889335215092 max memory_allocated 29271.39501953125 
[2025-03-01 15:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.1520032435655594 norm:0.004986975342035294 max memory_allocated 29271.39501953125 
[2025-03-01 15:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.15454697608947754 norm:0.006019931752234697 max memory_allocated 29271.39501953125 
[2025-03-01 15:32:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.15355579555034637 norm:0.006157496944069862 max memory_allocated 29271.39501953125 
[2025-03-01 15:33:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.15128661692142487 norm:0.0054655191488564014 max memory_allocated 29271.39501953125 
[2025-03-01 15:34:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.15063585340976715 norm:0.004816310480237007 max memory_allocated 29271.39501953125 
[2025-03-01 15:35:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.1554737240076065 norm:0.006383218336850405 max memory_allocated 29271.39501953125 
[2025-03-01 15:35:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.15584605932235718 norm:0.006970272399485111 max memory_allocated 29271.39501953125 
[2025-03-01 15:36:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-01 15:37:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.19579757750034332 norm:0.006315126549452543 max memory_allocated 29271.39501953125 
[2025-03-01 15:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.17942067980766296 norm:0.0027092492673546076 max memory_allocated 29271.39501953125 
[2025-03-01 15:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.16869664192199707 norm:0.0015797687228769064 max memory_allocated 29271.39501953125 
[2025-03-01 15:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.16445818543434143 norm:0.0011450720485299826 max memory_allocated 29271.39501953125 
[2025-03-01 15:40:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.16221670806407928 norm:0.0010038496693596244 max memory_allocated 29271.39501953125 
[2025-03-01 15:41:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.1607188880443573 norm:0.0009497390128672123 max memory_allocated 29271.39501953125 
[2025-03-01 15:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.15964022278785706 norm:0.0009134422289207578 max memory_allocated 29271.39501953125 
[2025-03-01 15:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.1587035059928894 norm:0.0008880320237949491 max memory_allocated 29271.39501953125 
[2025-03-01 15:43:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.1579800248146057 norm:0.0008687350782565773 max memory_allocated 29271.39501953125 
[2025-03-01 15:44:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.1574276089668274 norm:0.0008623519679531455 max memory_allocated 29271.39501953125 
[2025-03-01 15:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.15699438750743866 norm:0.000850704382173717 max memory_allocated 29271.39501953125 
[2025-03-01 15:46:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.15670987963676453 norm:0.000848907046020031 max memory_allocated 29271.39501953125 
[2025-03-01 15:46:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.1565295308828354 norm:0.0008669777889735997 max memory_allocated 29271.39501953125 
[2025-03-01 15:47:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.15630096197128296 norm:0.000864303729031235 max memory_allocated 29271.39501953125 
[2025-03-01 15:48:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.15613165497779846 norm:0.0008492277120240033 max memory_allocated 29271.39501953125 
[2025-03-01 15:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.15598039329051971 norm:0.0008564228191971779 max memory_allocated 29271.39501953125 
[2025-03-01 15:50:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.15589167177677155 norm:0.0008533156360499561 max memory_allocated 29271.39501953125 
[2025-03-01 15:51:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.155790776014328 norm:0.0008397817146033049 max memory_allocated 29271.39501953125 
[2025-03-01 15:51:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.15571297705173492 norm:0.0008545175660401583 max memory_allocated 29271.39501953125 
[2025-03-01 15:52:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.15566948056221008 norm:0.0008502589189447463 max memory_allocated 29271.39501953125 
[2025-03-01 15:53:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-01 15:53:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.17849388718605042 norm:0.009812865406274796 max memory_allocated 29271.81298828125 
[2025-03-01 15:54:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.1581549048423767 norm:0.004694171249866486 max memory_allocated 29271.81298828125 
[2025-03-01 15:55:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.14764800667762756 norm:0.002967158565297723 max memory_allocated 29271.81298828125 
[2025-03-01 15:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.14357228577136993 norm:0.002032593823969364 max memory_allocated 29271.81298828125 
[2025-03-01 15:57:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.14131595194339752 norm:0.0016418818850070238 max memory_allocated 29271.81298828125 
[2025-03-01 15:58:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.13986803591251373 norm:0.0013304383028298616 max memory_allocated 29271.81298828125 
[2025-03-01 15:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.13900284469127655 norm:0.0011235976126044989 max memory_allocated 29271.81298828125 
[2025-03-01 15:59:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.1385648548603058 norm:0.0009913204703480005 max memory_allocated 29271.81298828125 
[2025-03-01 16:00:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.13823753595352173 norm:0.0009213539306074381 max memory_allocated 29271.81298828125 
[2025-03-01 16:01:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.13783997297286987 norm:0.0007555358461104333 max memory_allocated 29271.81298828125 
[2025-03-01 16:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.1376531571149826 norm:0.0007173878839239478 max memory_allocated 29271.81298828125 
[2025-03-01 16:03:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.137836754322052 norm:0.0007815838325768709 max memory_allocated 29271.81298828125 
[2025-03-01 16:03:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.13729627430438995 norm:0.0005801187944598496 max memory_allocated 29271.81298828125 
[2025-03-01 16:04:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.13727791607379913 norm:0.0005993037484586239 max memory_allocated 29271.81298828125 
[2025-03-01 16:05:29 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.13744555413722992 norm:0.0006490027299150825 max memory_allocated 29271.81298828125 
[2025-03-01 16:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.1372273862361908 norm:0.0005905209109187126 max memory_allocated 29271.81298828125 
[2025-03-01 16:07:08 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.13738083839416504 norm:0.0006172752473503351 max memory_allocated 29271.81298828125 
[2025-03-01 16:07:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.13693861663341522 norm:0.0004990266752429307 max memory_allocated 29271.81298828125 
[2025-03-01 16:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.1369081735610962 norm:0.0004885008675046265 max memory_allocated 29271.81298828125 
[2025-03-01 16:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.13686034083366394 norm:0.0004751698288600892 max memory_allocated 29271.81298828125 
[2025-03-01 16:09:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-01 16:10:45 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.18495570123195648 norm:0.006924791727215052 max memory_allocated 29271.81298828125 
[2025-03-01 16:11:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.16324248909950256 norm:0.0032266045454889536 max memory_allocated 29271.81298828125 
[2025-03-01 16:12:24 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.1499592661857605 norm:0.0016535278409719467 max memory_allocated 29271.81298828125 
[2025-03-01 16:13:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.1453036069869995 norm:0.0011203826870769262 max memory_allocated 29271.81298828125 
[2025-03-01 16:14:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.14294572174549103 norm:0.0009340575197711587 max memory_allocated 29271.81298828125 
[2025-03-01 16:14:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.14137999713420868 norm:0.0008111307397484779 max memory_allocated 29271.81298828125 
[2025-03-01 16:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.14035038650035858 norm:0.0006930311792530119 max memory_allocated 29271.81298828125 
[2025-03-01 16:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.13974635303020477 norm:0.000655217794701457 max memory_allocated 29271.81298828125 
[2025-03-01 16:17:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.13945984840393066 norm:0.0006361867417581379 max memory_allocated 29271.81298828125 
[2025-03-01 16:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.13942983746528625 norm:0.0006459299474954605 max memory_allocated 29271.81298828125 
[2025-03-01 16:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.1392168253660202 norm:0.0006036216509528458 max memory_allocated 29271.81298828125 
[2025-03-01 16:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.13904981315135956 norm:0.0005773765733465552 max memory_allocated 29271.81298828125 
[2025-03-01 16:20:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.13891664147377014 norm:0.0005548156332224607 max memory_allocated 29271.81298828125 
[2025-03-01 16:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.1387890875339508 norm:0.0005454731872305274 max memory_allocated 29271.81298828125 
[2025-03-01 16:22:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.1386861652135849 norm:0.0005248229717835784 max memory_allocated 29271.81298828125 
[2025-03-01 16:23:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.13867135345935822 norm:0.0005229485686868429 max memory_allocated 29271.81298828125 
[2025-03-01 16:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.1385539472103119 norm:0.0005145028699189425 max memory_allocated 29271.81298828125 
[2025-03-01 16:24:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.1385004222393036 norm:0.0005017518997192383 max memory_allocated 29271.81298828125 
[2025-03-01 16:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.13849182426929474 norm:0.0004951718728989363 max memory_allocated 29271.81298828125 
[2025-03-01 16:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.13838991522789001 norm:0.00048770676949061453 max memory_allocated 29271.81298828125 
[2025-03-01 16:26:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-01 16:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.20917320251464844 norm:0.008888323791325092 max memory_allocated 29271.81298828125 
[2025-03-01 16:28:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.17686514556407928 norm:0.0031758383847773075 max memory_allocated 29271.81298828125 
[2025-03-01 16:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.15862803161144257 norm:0.0014635191764682531 max memory_allocated 29271.81298828125 
[2025-03-01 16:30:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.15295681357383728 norm:0.0009484878974035382 max memory_allocated 29271.81298828125 
[2025-03-01 16:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.15044166147708893 norm:0.0007623980054631829 max memory_allocated 29271.81298828125 
[2025-03-01 16:31:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.14888787269592285 norm:0.0006989276153035462 max memory_allocated 29271.81298828125 
[2025-03-01 16:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.147883340716362 norm:0.0006496861460618675 max memory_allocated 29271.81298828125 
[2025-03-01 16:33:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.14724323153495789 norm:0.0006195175228640437 max memory_allocated 29271.81298828125 
[2025-03-01 16:34:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.14679710566997528 norm:0.0005966800381429493 max memory_allocated 29271.81298828125 
[2025-03-01 16:35:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.14650246500968933 norm:0.0005829613655805588 max memory_allocated 29271.81298828125 
[2025-03-01 16:35:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.1462288498878479 norm:0.000560497457627207 max memory_allocated 29271.81298828125 
[2025-03-01 16:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.14604692161083221 norm:0.000560634711291641 max memory_allocated 29271.81298828125 
[2025-03-01 16:37:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.14592903852462769 norm:0.0005425121635198593 max memory_allocated 29271.81298828125 
[2025-03-01 16:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.14580464363098145 norm:0.0005381840746849775 max memory_allocated 29271.81298828125 
[2025-03-01 16:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.14567606151103973 norm:0.0005368130514398217 max memory_allocated 29271.81298828125 
[2025-03-01 16:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.14559373259544373 norm:0.0005253491108305752 max memory_allocated 29271.81298828125 
[2025-03-01 16:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.14559970796108246 norm:0.0005079698166809976 max memory_allocated 29271.81298828125 
[2025-03-01 16:41:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.14552946388721466 norm:0.0005191321251913905 max memory_allocated 29271.81298828125 
[2025-03-01 16:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.14549508690834045 norm:0.000511247431859374 max memory_allocated 29271.81298828125 
[2025-03-01 16:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.14549590647220612 norm:0.0005182971945032477 max memory_allocated 29271.81298828125 
[2025-03-01 16:43:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-01 16:44:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.21811723709106445 norm:0.012933412566781044 max memory_allocated 29272.37548828125 
[2025-03-01 16:45:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.18475697934627533 norm:0.005341498181223869 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.16498848795890808 norm:0.002505487995222211 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.15851721167564392 norm:0.0016673427307978272 max memory_allocated 29272.37548828125 
[2025-03-01 16:47:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.15519380569458008 norm:0.0013038681354373693 max memory_allocated 29272.37548828125 
[2025-03-01 16:48:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.1532284915447235 norm:0.0011084515135735273 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.15205320715904236 norm:0.000996764749288559 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.15123729407787323 norm:0.0008848141878843307 max memory_allocated 29272.37548828125 
[2025-03-01 16:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.1506677269935608 norm:0.0007975253975018859 max memory_allocated 29272.37548828125 
[2025-03-01 16:51:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.150181382894516 norm:0.0007129043224267662 max memory_allocated 29272.37548828125 
[2025-03-01 16:52:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.1499149352312088 norm:0.0007183962152339518 max memory_allocated 29272.37548828125 
[2025-03-01 16:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.1496656835079193 norm:0.0006939371232874691 max memory_allocated 29272.37548828125 
[2025-03-01 16:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.1494683027267456 norm:0.0006579977343790233 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.14945662021636963 norm:0.0006419159471988678 max memory_allocated 29272.37548828125 
[2025-03-01 16:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.1493244469165802 norm:0.0006095353164710104 max memory_allocated 29272.37548828125 
[2025-03-01 16:56:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.14924411475658417 norm:0.0006048782379366457 max memory_allocated 29272.37548828125 
[2025-03-01 16:57:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.14917892217636108 norm:0.0005897232331335545 max memory_allocated 29272.37548828125 
[2025-03-01 16:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.1491297334432602 norm:0.0005778400227427483 max memory_allocated 29272.37548828125 
[2025-03-01 16:59:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.14907430112361908 norm:0.0005760361673310399 max memory_allocated 29272.37548828125 
[2025-03-01 17:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.1489611566066742 norm:0.0005512796342372894 max memory_allocated 29272.37548828125 
[2025-03-01 17:00:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-01 17:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.26073411107063293 norm:0.014683568850159645 max memory_allocated 29272.37548828125 
[2025-03-01 17:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.21869757771492004 norm:0.008125915192067623 max memory_allocated 29272.37548828125 
[2025-03-01 17:02:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.18538974225521088 norm:0.003905568504706025 max memory_allocated 29272.37548828125 
[2025-03-01 17:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.17319703102111816 norm:0.002116363262757659 max memory_allocated 29272.37548828125 
[2025-03-01 17:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.16883420944213867 norm:0.0016140230000019073 max memory_allocated 29272.37548828125 
[2025-03-01 17:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.16637533903121948 norm:0.0013878978788852692 max memory_allocated 29272.37548828125 
[2025-03-01 17:06:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.16486409306526184 norm:0.001218046760186553 max memory_allocated 29272.37548828125 
[2025-03-01 17:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.16382572054862976 norm:0.0011168245691806078 max memory_allocated 29272.37548828125 
[2025-03-01 17:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.16315852105617523 norm:0.0010558353969827294 max memory_allocated 29272.37548828125 
[2025-03-01 17:08:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.16256192326545715 norm:0.0009979384485632181 max memory_allocated 29272.37548828125 
[2025-03-01 17:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.16212663054466248 norm:0.0009180136257782578 max memory_allocated 29272.37548828125 
[2025-03-01 17:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.16177283227443695 norm:0.0008832800667732954 max memory_allocated 29272.37548828125 
[2025-03-01 17:11:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.1612958163022995 norm:0.0008159814169630408 max memory_allocated 29272.37548828125 
[2025-03-01 17:12:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.1610579490661621 norm:0.0007815264980308712 max memory_allocated 29272.37548828125 
[2025-03-01 17:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.16095753014087677 norm:0.0007504047825932503 max memory_allocated 29272.37548828125 
[2025-03-01 17:13:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.16100157797336578 norm:0.0007558385841548443 max memory_allocated 29272.37548828125 
[2025-03-01 17:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.16107559204101562 norm:0.0007518333732150495 max memory_allocated 29272.37548828125 
[2025-03-01 17:15:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.1610250174999237 norm:0.0007108270074240863 max memory_allocated 29272.37548828125 
[2025-03-01 17:16:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.1610163003206253 norm:0.0007222946733236313 max memory_allocated 29272.37548828125 
[2025-03-01 17:17:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.16095945239067078 norm:0.0007103976095095277 max memory_allocated 29272.37548828125 
[2025-03-01 17:17:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-01 17:18:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.2442624270915985 norm:0.012667985633015633 max memory_allocated 29272.37548828125 
[2025-03-01 17:19:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.2076445072889328 norm:0.005341808777302504 max memory_allocated 29272.37548828125 
[2025-03-01 17:19:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.1859312206506729 norm:0.0025201463140547276 max memory_allocated 29272.37548828125 
[2025-03-01 17:20:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.17803826928138733 norm:0.0016012871637940407 max memory_allocated 29272.37548828125 
[2025-03-01 17:21:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.17454296350479126 norm:0.0013156167697161436 max memory_allocated 29272.37548828125 
[2025-03-01 17:22:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.17239269614219666 norm:0.001091836835257709 max memory_allocated 29272.37548828125 
[2025-03-01 17:23:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.17112229764461517 norm:0.000978289172053337 max memory_allocated 29272.37548828125 
[2025-03-01 17:23:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.17025329172611237 norm:0.0008754328591749072 max memory_allocated 29272.37548828125 
[2025-03-01 17:24:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.16970673203468323 norm:0.0008318699547089636 max memory_allocated 29272.37548828125 
[2025-03-01 17:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.16928371787071228 norm:0.0007531715091317892 max memory_allocated 29272.37548828125 
[2025-03-01 17:26:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.16908471286296844 norm:0.0007107625715434551 max memory_allocated 29272.37548828125 
[2025-03-01 17:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.16894131898880005 norm:0.0006733351037837565 max memory_allocated 29272.37548828125 
[2025-03-01 17:28:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.16884317994117737 norm:0.0006439456483349204 max memory_allocated 29272.37548828125 
[2025-03-01 17:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.16881299018859863 norm:0.0006331398035399616 max memory_allocated 29272.37548828125 
[2025-03-01 17:29:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.16871772706508636 norm:0.0006177735049277544 max memory_allocated 29272.37548828125 
[2025-03-01 17:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.16853444278240204 norm:0.0006027320632711053 max memory_allocated 29272.37548828125 
[2025-03-01 17:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.168341264128685 norm:0.0005744495429098606 max memory_allocated 29272.37548828125 
[2025-03-01 17:32:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.16829010844230652 norm:0.0005690103862434626 max memory_allocated 29272.37548828125 
[2025-03-01 17:33:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.1682407557964325 norm:0.0005622454918920994 max memory_allocated 29272.37548828125 
[2025-03-01 17:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.16813860833644867 norm:0.0005573885282501578 max memory_allocated 29272.37548828125 
[2025-03-01 17:34:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-01 17:35:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.2760736048221588 norm:0.019290942698717117 max memory_allocated 29272.93798828125 
[2025-03-01 17:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.2485358864068985 norm:0.005992722697556019 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.2306218445301056 norm:0.002480195602402091 max memory_allocated 29272.93798828125 
[2025-03-01 17:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.22312769293785095 norm:0.0010215139482170343 max memory_allocated 29272.93798828125 
[2025-03-01 17:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.21945853531360626 norm:0.0008261558832600713 max memory_allocated 29272.93798828125 
[2025-03-01 17:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.21694126725196838 norm:0.000733821711037308 max memory_allocated 29272.93798828125 
[2025-03-01 17:39:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.21521255373954773 norm:0.0006748684681952 max memory_allocated 29272.93798828125 
[2025-03-01 17:40:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.21402139961719513 norm:0.0006529865204356611 max memory_allocated 29272.93798828125 
[2025-03-01 17:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.21313335001468658 norm:0.0006463853642344475 max memory_allocated 29272.93798828125 
[2025-03-01 17:42:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.2125173807144165 norm:0.0006400326965376735 max memory_allocated 29272.93798828125 
[2025-03-01 17:43:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.2120772898197174 norm:0.0006403820007108152 max memory_allocated 29272.93798828125 
[2025-03-01 17:44:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.21170474588871002 norm:0.0006402070866897702 max memory_allocated 29272.93798828125 
[2025-03-01 17:44:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.21139010787010193 norm:0.0006352782947942615 max memory_allocated 29272.93798828125 
[2025-03-01 17:45:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.21116486191749573 norm:0.0006365680601447821 max memory_allocated 29272.93798828125 
[2025-03-01 17:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.2110186219215393 norm:0.0006371436174958944 max memory_allocated 29272.93798828125 
[2025-03-01 17:47:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.2108873575925827 norm:0.0006392559735104442 max memory_allocated 29272.93798828125 
[2025-03-01 17:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.21076104044914246 norm:0.0006422219448722899 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.21066196262836456 norm:0.0006423773593269289 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.21055281162261963 norm:0.0006379783153533936 max memory_allocated 29272.93798828125 
[2025-03-01 17:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.2104688584804535 norm:0.0006399184931069613 max memory_allocated 29272.93798828125 
[2025-03-01 17:50:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-01 17:51:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.2895301878452301 norm:0.009507901966571808 max memory_allocated 29272.93798828125 
[2025-03-01 17:52:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.26074692606925964 norm:0.0034218125510960817 max memory_allocated 29272.93798828125 
[2025-03-01 17:53:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.24338661134243011 norm:0.0016330713406205177 max memory_allocated 29272.93798828125 
[2025-03-01 17:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.23638685047626495 norm:0.0010117253987118602 max memory_allocated 29272.93798828125 
[2025-03-01 17:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.23297317326068878 norm:0.0007673954823985696 max memory_allocated 29272.93798828125 
[2025-03-01 17:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.23080606758594513 norm:0.0006872704834677279 max memory_allocated 29272.93798828125 
[2025-03-01 17:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.22930654883384705 norm:0.0006418604752980173 max memory_allocated 29272.93798828125 
[2025-03-01 17:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.22816026210784912 norm:0.0006196993635967374 max memory_allocated 29272.93798828125 
[2025-03-01 17:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.22739392518997192 norm:0.0006094658165238798 max memory_allocated 29272.93798828125 
[2025-03-01 17:59:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.22683370113372803 norm:0.0006089042872190475 max memory_allocated 29272.93798828125 
[2025-03-01 18:00:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.22641275823116302 norm:0.0006072600372135639 max memory_allocated 29272.93798828125 
[2025-03-01 18:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.22608347237110138 norm:0.0006053916877135634 max memory_allocated 29272.93798828125 
[2025-03-01 18:01:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.2258470505475998 norm:0.0006040532025508583 max memory_allocated 29272.93798828125 
[2025-03-01 18:02:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.2256622165441513 norm:0.000611094175837934 max memory_allocated 29272.93798828125 
[2025-03-01 18:03:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.22545330226421356 norm:0.0006070872768759727 max memory_allocated 29272.93798828125 
[2025-03-01 18:04:14 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.2253086417913437 norm:0.0006100908503867686 max memory_allocated 29272.93798828125 
[2025-03-01 18:05:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.225180983543396 norm:0.0006119131576269865 max memory_allocated 29272.93798828125 
[2025-03-01 18:05:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.22508074343204498 norm:0.0006191927241161466 max memory_allocated 29272.93798828125 
[2025-03-01 18:06:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.22498399019241333 norm:0.0006176786264404655 max memory_allocated 29272.93798828125 
[2025-03-01 18:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.2249137908220291 norm:0.0006209746934473515 max memory_allocated 29272.93798828125 
[2025-03-01 18:07:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-01 18:08:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.2656841278076172 norm:0.008956999517977238 max memory_allocated 29272.93798828125 
[2025-03-01 18:09:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.23806670308113098 norm:0.0041753011755645275 max memory_allocated 29272.93798828125 
[2025-03-01 18:10:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.21955974400043488 norm:0.0019134469330310822 max memory_allocated 29272.93798828125 
[2025-03-01 18:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.21283425390720367 norm:0.001188725116662681 max memory_allocated 29272.93798828125 
[2025-03-01 18:11:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.20952825248241425 norm:0.0009161328198388219 max memory_allocated 29272.93798828125 
[2025-03-01 18:12:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.2076704055070877 norm:0.0007803812623023987 max memory_allocated 29272.93798828125 
[2025-03-01 18:13:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.20662082731723785 norm:0.0006928563816472888 max memory_allocated 29272.93798828125 
[2025-03-01 18:14:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.20592093467712402 norm:0.0006588370888493955 max memory_allocated 29272.93798828125 
[2025-03-01 18:15:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.20552407205104828 norm:0.0006312739569693804 max memory_allocated 29272.93798828125 
[2025-03-01 18:16:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.20525747537612915 norm:0.0005992971709929407 max memory_allocated 29272.93798828125 
[2025-03-01 18:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.205142542719841 norm:0.0005917544476687908 max memory_allocated 29272.93798828125 
[2025-03-01 18:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.20495139062404633 norm:0.0005484478315338492 max memory_allocated 29272.93798828125 
[2025-03-01 18:18:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.20476897060871124 norm:0.0005177308921702206 max memory_allocated 29272.93798828125 
[2025-03-01 18:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.2045126110315323 norm:0.0004950807197019458 max memory_allocated 29272.93798828125 
[2025-03-01 18:20:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.2043122798204422 norm:0.0004524616524577141 max memory_allocated 29272.93798828125 
[2025-03-01 18:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.20425599813461304 norm:0.00044839392649009824 max memory_allocated 29272.93798828125 
[2025-03-01 18:21:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.20422184467315674 norm:0.00045296503230929375 max memory_allocated 29272.93798828125 
[2025-03-01 18:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.20418104529380798 norm:0.0004497875343076885 max memory_allocated 29272.93798828125 
[2025-03-01 18:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.20410983264446259 norm:0.0004480434872675687 max memory_allocated 29272.93798828125 
[2025-03-01 18:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.20405378937721252 norm:0.00043276732321828604 max memory_allocated 29272.93798828125 
[2025-03-01 18:24:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-01 18:25:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.27128228545188904 norm:0.01039529126137495 max memory_allocated 29273.50048828125 
[2025-03-01 18:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.23911213874816895 norm:0.004058318678289652 max memory_allocated 29273.50048828125 
[2025-03-01 18:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.22024397552013397 norm:0.0018376566004008055 max memory_allocated 29273.50048828125 
[2025-03-01 18:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.21329179406166077 norm:0.0011531062191352248 max memory_allocated 29273.50048828125 
[2025-03-01 18:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.21018916368484497 norm:0.0009224764071404934 max memory_allocated 29273.50048828125 
[2025-03-01 18:29:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.20833377540111542 norm:0.0008206525817513466 max memory_allocated 29273.50048828125 
[2025-03-01 18:30:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.2071543037891388 norm:0.00074915518052876 max memory_allocated 29273.50048828125 
[2025-03-01 18:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.2064943164587021 norm:0.0007049749838188291 max memory_allocated 29273.50048828125 
[2025-03-01 18:32:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.20607072114944458 norm:0.0006510189268738031 max memory_allocated 29273.50048828125 
[2025-03-01 18:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.20584550499916077 norm:0.0006358767277561128 max memory_allocated 29273.50048828125 
[2025-03-01 18:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.20568424463272095 norm:0.0006131097325123847 max memory_allocated 29273.50048828125 
[2025-03-01 18:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.2055722028017044 norm:0.000593113130889833 max memory_allocated 29273.50048828125 
[2025-03-01 18:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.2054746299982071 norm:0.0005677822045981884 max memory_allocated 29273.50048828125 
[2025-03-01 18:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.20521456003189087 norm:0.0005375696928240359 max memory_allocated 29273.50048828125 
[2025-03-01 18:37:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.20506331324577332 norm:0.0005260258913040161 max memory_allocated 29273.50048828125 
[2025-03-01 18:37:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.20504029095172882 norm:0.0005142695154063404 max memory_allocated 29273.50048828125 
[2025-03-01 18:38:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.204933762550354 norm:0.0005080081755295396 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.20481204986572266 norm:0.0005208824877627194 max memory_allocated 29273.50048828125 
[2025-03-01 18:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.2048119157552719 norm:0.0004937311168760061 max memory_allocated 29273.50048828125 
[2025-03-01 18:41:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.2048276662826538 norm:0.0004790298407897353 max memory_allocated 29273.50048828125 
[2025-03-01 18:41:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-01 18:42:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.2396584153175354 norm:0.0031117405742406845 max memory_allocated 29273.50048828125 
[2025-03-01 18:43:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.22278639674186707 norm:0.0014244642807170749 max memory_allocated 29273.50048828125 
[2025-03-01 18:44:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.21091538667678833 norm:0.0007592187612317502 max memory_allocated 29273.50048828125 
[2025-03-01 18:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.20629096031188965 norm:0.0005423962720669806 max memory_allocated 29273.50048828125 
[2025-03-01 18:45:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.2040567547082901 norm:0.0004631107149180025 max memory_allocated 29273.50048828125 
[2025-03-01 18:46:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.20257410407066345 norm:0.00042332257726229727 max memory_allocated 29273.50048828125 
[2025-03-01 18:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.20177584886550903 norm:0.00040337140671908855 max memory_allocated 29273.50048828125 
[2025-03-01 18:48:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.20124977827072144 norm:0.000392692512832582 max memory_allocated 29273.50048828125 
[2025-03-01 18:49:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.20097196102142334 norm:0.00038800304173491895 max memory_allocated 29273.50048828125 
[2025-03-01 18:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.2007669359445572 norm:0.00037763197906315327 max memory_allocated 29273.50048828125 
[2025-03-01 18:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.20062538981437683 norm:0.0003725052811205387 max memory_allocated 29273.50048828125 
[2025-03-01 18:51:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.20050807297229767 norm:0.00037156761391088367 max memory_allocated 29273.50048828125 
[2025-03-01 18:52:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.20043009519577026 norm:0.00036592024844139814 max memory_allocated 29273.50048828125 
[2025-03-01 18:53:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.20031389594078064 norm:0.00035782335908152163 max memory_allocated 29273.50048828125 
[2025-03-01 18:53:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.20025061070919037 norm:0.00035509513691067696 max memory_allocated 29273.50048828125 
[2025-03-01 18:54:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.2001836597919464 norm:0.00035292073152959347 max memory_allocated 29273.50048828125 
[2025-03-01 18:55:39 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.20012696087360382 norm:0.0003519546880852431 max memory_allocated 29273.50048828125 
[2025-03-01 18:56:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.20007014274597168 norm:0.000348288711393252 max memory_allocated 29273.50048828125 
[2025-03-01 18:57:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.20002874732017517 norm:0.0003434260142967105 max memory_allocated 29273.50048828125 
[2025-03-01 18:58:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.20002707839012146 norm:0.000343983992934227 max memory_allocated 29273.50048828125 
[2025-03-01 18:58:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-01 18:59:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.2603297829627991 norm:0.01745676063001156 max memory_allocated 29273.50048828125 
[2025-03-01 19:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.2381400167942047 norm:0.009796375408768654 max memory_allocated 29273.50048828125 
[2025-03-01 19:00:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.21416577696800232 norm:0.003367945086210966 max memory_allocated 29273.50048828125 
[2025-03-01 19:01:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.2058854103088379 norm:0.0015444805612787604 max memory_allocated 29273.50048828125 
[2025-03-01 19:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.203202486038208 norm:0.0013109614374116063 max memory_allocated 29273.50048828125 
[2025-03-01 19:03:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.20146486163139343 norm:0.0011032926850020885 max memory_allocated 29273.50048828125 
[2025-03-01 19:04:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.20039162039756775 norm:0.0010011342819780111 max memory_allocated 29273.50048828125 
[2025-03-01 19:05:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.1997050642967224 norm:0.0009392965584993362 max memory_allocated 29273.50048828125 
[2025-03-01 19:05:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.19915373623371124 norm:0.0008474939968436956 max memory_allocated 29273.50048828125 
[2025-03-01 19:06:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.19881421327590942 norm:0.0008321226923726499 max memory_allocated 29273.50048828125 
[2025-03-01 19:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.19857269525527954 norm:0.0008174017420969903 max memory_allocated 29273.50048828125 
[2025-03-01 19:08:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.19850629568099976 norm:0.0007998198852874339 max memory_allocated 29273.50048828125 
[2025-03-01 19:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.1983495056629181 norm:0.000771996914409101 max memory_allocated 29273.50048828125 
[2025-03-01 19:10:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.1982186883687973 norm:0.0007323911413550377 max memory_allocated 29273.50048828125 
[2025-03-01 19:10:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.1980697214603424 norm:0.0006953245028853416 max memory_allocated 29273.50048828125 
[2025-03-01 19:11:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.19806601107120514 norm:0.0006702039972878993 max memory_allocated 29273.50048828125 
[2025-03-01 19:12:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.1980104148387909 norm:0.000636619923170656 max memory_allocated 29273.50048828125 
[2025-03-01 19:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.19778667390346527 norm:0.0006126732332631946 max memory_allocated 29273.50048828125 
[2025-03-01 19:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.19771255552768707 norm:0.0006035144906491041 max memory_allocated 29273.50048828125 
[2025-03-01 19:14:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.19764240086078644 norm:0.0005938226240687072 max memory_allocated 29273.50048828125 
[2025-03-01 19:15:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-01 19:16:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.22879566252231598 norm:0.0047122882679104805 max memory_allocated 29274.06298828125 
[2025-03-01 19:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.21587522327899933 norm:0.002388716209679842 max memory_allocated 29274.06298828125 
[2025-03-01 19:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.20601637661457062 norm:0.00134173221886158 max memory_allocated 29274.06298828125 
[2025-03-01 19:18:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.20209990441799164 norm:0.0009257291094399989 max memory_allocated 29274.06298828125 
[2025-03-01 19:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.19996149837970734 norm:0.000728249317035079 max memory_allocated 29274.06298828125 
[2025-03-01 19:20:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.19869615137577057 norm:0.0006286490242928267 max memory_allocated 29274.06298828125 
[2025-03-01 19:21:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.19793638586997986 norm:0.0005607517086900771 max memory_allocated 29274.06298828125 
[2025-03-01 19:21:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.1974024623632431 norm:0.0005082153948023915 max memory_allocated 29274.06298828125 
[2025-03-01 19:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.19708482921123505 norm:0.0004791647370439023 max memory_allocated 29274.06298828125 
[2025-03-01 19:23:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.19688889384269714 norm:0.0004538280190899968 max memory_allocated 29274.06298828125 
[2025-03-01 19:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.1967519074678421 norm:0.0004371120303403586 max memory_allocated 29274.06298828125 
[2025-03-01 19:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.19660605490207672 norm:0.0004216805682517588 max memory_allocated 29274.06298828125 
[2025-03-01 19:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.19646701216697693 norm:0.00041231236536987126 max memory_allocated 29274.06298828125 
[2025-03-01 19:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.19627639651298523 norm:0.0003983099013566971 max memory_allocated 29274.06298828125 
[2025-03-01 19:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.19621220231056213 norm:0.00039719248889014125 max memory_allocated 29274.06298828125 
[2025-03-01 19:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.19620320200920105 norm:0.000392950139939785 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.19619007408618927 norm:0.0003889608196914196 max memory_allocated 29274.06298828125 
[2025-03-01 19:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.19618012011051178 norm:0.00038948317524045706 max memory_allocated 29274.06298828125 
[2025-03-01 19:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.19615961611270905 norm:0.00038850295823067427 max memory_allocated 29274.06298828125 
[2025-03-01 19:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.1961708664894104 norm:0.0003885743790306151 max memory_allocated 29274.06298828125 
[2025-03-01 19:32:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-01 19:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.22386308014392853 norm:0.004577001556754112 max memory_allocated 29274.06298828125 
[2025-03-01 19:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.21208789944648743 norm:0.002353834453970194 max memory_allocated 29274.06298828125 
[2025-03-01 19:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.20388735830783844 norm:0.0012192998547106981 max memory_allocated 29274.06298828125 
[2025-03-01 19:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.20055386424064636 norm:0.0008058539242483675 max memory_allocated 29274.06298828125 
[2025-03-01 19:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.1987953782081604 norm:0.0006762491539120674 max memory_allocated 29274.06298828125 
[2025-03-01 19:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.1975274235010147 norm:0.000565382419154048 max memory_allocated 29274.06298828125 
[2025-03-01 19:37:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.1968088001012802 norm:0.0005384458345361054 max memory_allocated 29274.06298828125 
[2025-03-01 19:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.19640852510929108 norm:0.0005040295654907823 max memory_allocated 29274.06298828125 
[2025-03-01 19:39:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.19619466364383698 norm:0.0004743061726912856 max memory_allocated 29274.06298828125 
[2025-03-01 19:40:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.19594883918762207 norm:0.0004417358140926808 max memory_allocated 29274.06298828125 
[2025-03-01 19:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.19583077728748322 norm:0.00042728937114588916 max memory_allocated 29274.06298828125 
[2025-03-01 19:42:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.19574254751205444 norm:0.0004101966042071581 max memory_allocated 29274.06298828125 
[2025-03-01 19:42:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.19563201069831848 norm:0.00039053408545441926 max memory_allocated 29274.06298828125 
[2025-03-01 19:43:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.19558042287826538 norm:0.00038038071943446994 max memory_allocated 29274.06298828125 
[2025-03-01 19:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.19557581841945648 norm:0.0003767378511838615 max memory_allocated 29274.06298828125 
[2025-03-01 19:45:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.1955345720052719 norm:0.0003675005864351988 max memory_allocated 29274.06298828125 
[2025-03-01 19:46:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.19544848799705505 norm:0.00035306179779581726 max memory_allocated 29274.06298828125 
[2025-03-01 19:47:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.19538356363773346 norm:0.0003458057180978358 max memory_allocated 29274.06298828125 
[2025-03-01 19:47:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.1953061819076538 norm:0.0003381352871656418 max memory_allocated 29274.06298828125 
[2025-03-01 19:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.19532442092895508 norm:0.0003324136487208307 max memory_allocated 29274.06298828125 
[2025-03-01 19:48:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-01 19:49:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.22645406424999237 norm:0.003642122494056821 max memory_allocated 29274.06298828125 
[2025-03-01 19:50:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.21643643081188202 norm:0.0017067411681637168 max memory_allocated 29274.06298828125 
[2025-03-01 19:51:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.2089417427778244 norm:0.0010206159204244614 max memory_allocated 29274.06298828125 
[2025-03-01 19:52:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.20597288012504578 norm:0.0007262241560965776 max memory_allocated 29274.06298828125 
[2025-03-01 19:53:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.20447276532649994 norm:0.0006385864689946175 max memory_allocated 29274.06298828125 
[2025-03-01 19:53:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.20339466631412506 norm:0.0005543828592635691 max memory_allocated 29274.06298828125 
[2025-03-01 19:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.20279128849506378 norm:0.0005085342563688755 max memory_allocated 29274.06298828125 
[2025-03-01 19:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.2023877501487732 norm:0.0004674770752899349 max memory_allocated 29274.06298828125 
[2025-03-01 19:56:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.20211900770664215 norm:0.0004340084851719439 max memory_allocated 29274.06298828125 
[2025-03-01 19:57:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.20189175009727478 norm:0.000413066940382123 max memory_allocated 29274.06298828125 
[2025-03-01 19:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.20177625119686127 norm:0.0003966927179135382 max memory_allocated 29274.06298828125 
[2025-03-01 19:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.20174631476402283 norm:0.0003931498504243791 max memory_allocated 29274.06298828125 
[2025-03-01 19:59:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.2016882747411728 norm:0.0003867179621011019 max memory_allocated 29274.06298828125 
[2025-03-01 20:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.2016453742980957 norm:0.0003768299939110875 max memory_allocated 29274.06298828125 
[2025-03-01 20:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.20155540108680725 norm:0.00036214961437508464 max memory_allocated 29274.06298828125 
[2025-03-01 20:02:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.2014925181865692 norm:0.0003531139809638262 max memory_allocated 29274.06298828125 
[2025-03-01 20:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.20148485898971558 norm:0.0003486095229163766 max memory_allocated 29274.06298828125 
[2025-03-01 20:03:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.2014414668083191 norm:0.00034495428553782403 max memory_allocated 29274.06298828125 
[2025-03-01 20:04:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.201433002948761 norm:0.00034074560971930623 max memory_allocated 29274.06298828125 
[2025-03-01 20:05:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.20145443081855774 norm:0.0003394210943952203 max memory_allocated 29274.06298828125 
[2025-03-01 20:05:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-01 20:06:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.2323930561542511 norm:0.002821684814989567 max memory_allocated 29274.62548828125 
[2025-03-01 20:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.22355081140995026 norm:0.0013401992619037628 max memory_allocated 29274.62548828125 
[2025-03-01 20:08:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.21651028096675873 norm:0.0008620900916866958 max memory_allocated 29274.62548828125 
[2025-03-01 20:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.2136227935552597 norm:0.000667353393509984 max memory_allocated 29274.62548828125 
[2025-03-01 20:10:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.21213340759277344 norm:0.0005881458637304604 max memory_allocated 29274.62548828125 
[2025-03-01 20:10:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.2113131284713745 norm:0.0005410501617006958 max memory_allocated 29274.62548828125 
[2025-03-01 20:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.21076491475105286 norm:0.0005154592799954116 max memory_allocated 29274.62548828125 
[2025-03-01 20:12:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.21043533086776733 norm:0.0004850881814491004 max memory_allocated 29274.62548828125 
[2025-03-01 20:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.21018390357494354 norm:0.00044491278822533786 max memory_allocated 29274.62548828125 
[2025-03-01 20:14:09 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.20998141169548035 norm:0.00041776627767831087 max memory_allocated 29274.62548828125 
[2025-03-01 20:14:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.2098085880279541 norm:0.00039539224235340953 max memory_allocated 29274.62548828125 
[2025-03-01 20:15:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.20977957546710968 norm:0.00039244259824045 max memory_allocated 29274.62548828125 
[2025-03-01 20:16:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.20978944003582 norm:0.00039125754847191274 max memory_allocated 29274.62548828125 
[2025-03-01 20:17:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.20978203415870667 norm:0.0003897655406035483 max memory_allocated 29274.62548828125 
[2025-03-01 20:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.20975500345230103 norm:0.00037668299046345055 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.20972205698490143 norm:0.0003685987030621618 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.20965898036956787 norm:0.000357578945113346 max memory_allocated 29274.62548828125 
[2025-03-01 20:20:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.20963811874389648 norm:0.00034898071317002177 max memory_allocated 29274.62548828125 
[2025-03-01 20:21:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.2095804065465927 norm:0.00033969295327551663 max memory_allocated 29274.62548828125 
[2025-03-01 20:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.2095337212085724 norm:0.0003332342894282192 max memory_allocated 29274.62548828125 
[2025-03-01 20:22:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-01 20:23:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.24874721467494965 norm:0.0023364583030343056 max memory_allocated 29274.62548828125 
[2025-03-01 20:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.23953919112682343 norm:0.001426150556653738 max memory_allocated 29274.62548828125 
[2025-03-01 20:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.23192676901817322 norm:0.0009569957619532943 max memory_allocated 29274.62548828125 
[2025-03-01 20:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.22860462963581085 norm:0.000727516773622483 max memory_allocated 29274.62548828125 
[2025-03-01 20:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.22702641785144806 norm:0.0006312745972536504 max memory_allocated 29274.62548828125 
[2025-03-01 20:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.22593125700950623 norm:0.0005645882920362055 max memory_allocated 29274.62548828125 
[2025-03-01 20:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.2252504676580429 norm:0.000521769979968667 max memory_allocated 29274.62548828125 
[2025-03-01 20:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.22479106485843658 norm:0.00048491201596334577 max memory_allocated 29274.62548828125 
[2025-03-01 20:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.22450470924377441 norm:0.0004604763234965503 max memory_allocated 29274.62548828125 
[2025-03-01 20:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.22432492673397064 norm:0.0004443144134711474 max memory_allocated 29274.62548828125 
[2025-03-01 20:31:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.2241639494895935 norm:0.000429388543125242 max memory_allocated 29274.62548828125 
[2025-03-01 20:32:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.2241223156452179 norm:0.0004211650521028787 max memory_allocated 29274.62548828125 
[2025-03-01 20:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.2240341752767563 norm:0.0004090815782546997 max memory_allocated 29274.62548828125 
[2025-03-01 20:34:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.2239215075969696 norm:0.0003975041618105024 max memory_allocated 29274.62548828125 
[2025-03-01 20:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.22384068369865417 norm:0.0003847145417239517 max memory_allocated 29274.62548828125 
[2025-03-01 20:35:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.223801389336586 norm:0.0003772995842155069 max memory_allocated 29274.62548828125 
[2025-03-01 20:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.22372552752494812 norm:0.0003688072320073843 max memory_allocated 29274.62548828125 
[2025-03-01 20:37:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.22369375824928284 norm:0.00036067210021428764 max memory_allocated 29274.62548828125 
[2025-03-01 20:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.22369639575481415 norm:0.00036002430715598166 max memory_allocated 29274.62548828125 
[2025-03-01 20:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.22366434335708618 norm:0.00035650894278660417 max memory_allocated 29274.62548828125 
[2025-03-01 20:39:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-01 20:40:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.2574695646762848 norm:0.002975817769765854 max memory_allocated 29274.62548828125 
[2025-03-01 20:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.24979247152805328 norm:0.00136406603269279 max memory_allocated 29274.62548828125 
[2025-03-01 20:42:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.24368791282176971 norm:0.0009299019002355635 max memory_allocated 29274.62548828125 
[2025-03-01 20:42:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.24155744910240173 norm:0.0007029168191365898 max memory_allocated 29274.62548828125 
[2025-03-01 20:43:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.2402246743440628 norm:0.0006103760097175837 max memory_allocated 29274.62548828125 
[2025-03-01 20:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.239406019449234 norm:0.0005757378530688584 max memory_allocated 29274.62548828125 
[2025-03-01 20:45:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.23872798681259155 norm:0.0005235123680904508 max memory_allocated 29274.62548828125 
[2025-03-01 20:46:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.23834246397018433 norm:0.00048165276530198753 max memory_allocated 29274.62548828125 
[2025-03-01 20:47:02 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.23812595009803772 norm:0.0004982054233551025 max memory_allocated 29274.62548828125 
[2025-03-01 20:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.23787319660186768 norm:0.0004272965306881815 max memory_allocated 29274.62548828125 
[2025-03-01 20:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.23758462071418762 norm:0.0003832465154118836 max memory_allocated 29274.62548828125 
[2025-03-01 20:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.2374650090932846 norm:0.00037570440326817334 max memory_allocated 29274.62548828125 
[2025-03-01 20:50:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.23738691210746765 norm:0.00039686638046987355 max memory_allocated 29274.62548828125 
[2025-03-01 20:51:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.23729465901851654 norm:0.00037378285196609795 max memory_allocated 29274.62548828125 
[2025-03-01 20:52:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.23716427385807037 norm:0.00035368683165870607 max memory_allocated 29274.62548828125 
[2025-03-01 20:52:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.23707713186740875 norm:0.0003591611166484654 max memory_allocated 29274.62548828125 
[2025-03-01 20:53:40 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.23702794313430786 norm:0.0003766241716220975 max memory_allocated 29274.62548828125 
[2025-03-01 20:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.2370063066482544 norm:0.0003856552648358047 max memory_allocated 29274.62548828125 
[2025-03-01 20:55:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.23700520396232605 norm:0.00035767772351391613 max memory_allocated 29274.62548828125 
[2025-03-01 20:56:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.23692357540130615 norm:0.0003602090000640601 max memory_allocated 29274.62548828125 
[2025-03-01 20:56:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-01 20:57:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.27762049436569214 norm:0.0021364064887166023 max memory_allocated 29275.18798828125 
[2025-03-01 20:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.2698253393173218 norm:0.0012803905410692096 max memory_allocated 29275.18798828125 
[2025-03-01 20:58:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.26355108618736267 norm:0.0009068718063645065 max memory_allocated 29275.18798828125 
[2025-03-01 20:59:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.26122230291366577 norm:0.0006663489621132612 max memory_allocated 29275.18798828125 
[2025-03-01 21:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.25979873538017273 norm:0.0005436040228232741 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.2587243616580963 norm:0.0004799762100446969 max memory_allocated 29275.18798828125 
[2025-03-01 21:02:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.2580612897872925 norm:0.0004481314099393785 max memory_allocated 29275.18798828125 
[2025-03-01 21:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.25763416290283203 norm:0.0004170142055954784 max memory_allocated 29275.18798828125 
[2025-03-01 21:03:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.25735142827033997 norm:0.0003853726957459003 max memory_allocated 29275.18798828125 
[2025-03-01 21:04:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.2571825683116913 norm:0.0003677009081002325 max memory_allocated 29275.18798828125 
[2025-03-01 21:05:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.25706350803375244 norm:0.00036004421417601407 max memory_allocated 29275.18798828125 
[2025-03-01 21:06:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.25691401958465576 norm:0.00033656926825642586 max memory_allocated 29275.18798828125 
[2025-03-01 21:07:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.2567473351955414 norm:0.00032143847784027457 max memory_allocated 29275.18798828125 
[2025-03-01 21:08:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.25659576058387756 norm:0.0003073053667321801 max memory_allocated 29275.18798828125 
[2025-03-01 21:08:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.2565218210220337 norm:0.0003028515784535557 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.25645944476127625 norm:0.0002995368267875165 max memory_allocated 29275.18798828125 
[2025-03-01 21:10:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.2564111053943634 norm:0.000300977990264073 max memory_allocated 29275.18798828125 
[2025-03-01 21:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.25632667541503906 norm:0.000299094885122031 max memory_allocated 29275.18798828125 
[2025-03-01 21:12:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.2562929689884186 norm:0.0002991844667121768 max memory_allocated 29275.18798828125 
[2025-03-01 21:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.25631827116012573 norm:0.0003001105214934796 max memory_allocated 29275.18798828125 
[2025-03-01 21:13:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-01 21:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.2968190908432007 norm:0.002805121010169387 max memory_allocated 29275.18798828125 
[2025-03-01 21:14:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.2902933955192566 norm:0.0021132961846888065 max memory_allocated 29275.18798828125 
[2025-03-01 21:15:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.284099280834198 norm:0.0014197214040905237 max memory_allocated 29275.18798828125 
[2025-03-01 21:16:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.2819814085960388 norm:0.0010801823809742928 max memory_allocated 29275.18798828125 
[2025-03-01 21:17:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.28042757511138916 norm:0.0008830376318655908 max memory_allocated 29275.18798828125 
[2025-03-01 21:18:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.2793388366699219 norm:0.0007770759984850883 max memory_allocated 29275.18798828125 
[2025-03-01 21:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.27868589758872986 norm:0.0007172732730396092 max memory_allocated 29275.18798828125 
[2025-03-01 21:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.2783224284648895 norm:0.000674944487400353 max memory_allocated 29275.18798828125 
[2025-03-01 21:20:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.27814754843711853 norm:0.0006422502920031548 max memory_allocated 29275.18798828125 
[2025-03-01 21:21:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.27805599570274353 norm:0.0006163393845781684 max memory_allocated 29275.18798828125 
[2025-03-01 21:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.27791842818260193 norm:0.000566962466109544 max memory_allocated 29275.18798828125 
[2025-03-01 21:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.27783554792404175 norm:0.0005494651268236339 max memory_allocated 29275.18798828125 
[2025-03-01 21:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.27771854400634766 norm:0.0005176796112209558 max memory_allocated 29275.18798828125 
[2025-03-01 21:24:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.2776421904563904 norm:0.0004971628659404814 max memory_allocated 29275.18798828125 
[2025-03-01 21:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.2775726914405823 norm:0.00047247827751562 max memory_allocated 29275.18798828125 
[2025-03-01 21:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.27742254734039307 norm:0.00043764489237219095 max memory_allocated 29275.18798828125 
[2025-03-01 21:27:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.27732500433921814 norm:0.0004237799730617553 max memory_allocated 29275.18798828125 
[2025-03-01 21:28:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.2771962881088257 norm:0.00041053001768887043 max memory_allocated 29275.18798828125 
[2025-03-01 21:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.27713543176651 norm:0.0004036568570882082 max memory_allocated 29275.18798828125 
[2025-03-01 21:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.27706530690193176 norm:0.000389394088415429 max memory_allocated 29275.18798828125 
[2025-03-01 21:30:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-01 21:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.32017093896865845 norm:0.0025161197409033775 max memory_allocated 29275.18798828125 
[2025-03-01 21:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.31341028213500977 norm:0.0014622926246374846 max memory_allocated 29275.18798828125 
[2025-03-01 21:32:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.307239830493927 norm:0.0010156783973798156 max memory_allocated 29275.18798828125 
[2025-03-01 21:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.3051924705505371 norm:0.0007670464692637324 max memory_allocated 29275.18798828125 
[2025-03-01 21:34:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.30382898449897766 norm:0.0006083303014747798 max memory_allocated 29275.18798828125 
[2025-03-01 21:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.3027637004852295 norm:0.0005434795166365802 max memory_allocated 29275.18798828125 
[2025-03-01 21:35:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.3021196722984314 norm:0.0005047640297561884 max memory_allocated 29275.18798828125 
[2025-03-01 21:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.3017769157886505 norm:0.00048353304737247527 max memory_allocated 29275.18798828125 
[2025-03-01 21:37:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.3015694320201874 norm:0.0004572505713440478 max memory_allocated 29275.18798828125 
[2025-03-01 21:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.3014747202396393 norm:0.00041283073369413614 max memory_allocated 29275.18798828125 
[2025-03-01 21:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.3013210892677307 norm:0.00037987640826031566 max memory_allocated 29275.18798828125 
[2025-03-01 21:40:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.3012074828147888 norm:0.00035880954237654805 max memory_allocated 29275.18798828125 
[2025-03-01 21:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.3011135160923004 norm:0.00034422954195179045 max memory_allocated 29275.18798828125 
[2025-03-01 21:41:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.3010117709636688 norm:0.00032568443566560745 max memory_allocated 29275.18798828125 
[2025-03-01 21:42:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.30090850591659546 norm:0.00030734576284885406 max memory_allocated 29275.18798828125 
[2025-03-01 21:43:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.3008233606815338 norm:0.00030755583429709077 max memory_allocated 29275.18798828125 
[2025-03-01 21:44:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.300798237323761 norm:0.00029725272906944156 max memory_allocated 29275.18798828125 
[2025-03-01 21:45:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.3007320761680603 norm:0.0002904815773945302 max memory_allocated 29275.18798828125 
[2025-03-01 21:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.30069220066070557 norm:0.00028976702014915645 max memory_allocated 29275.18798828125 
[2025-03-01 21:46:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.3006913959980011 norm:0.00028405291959643364 max memory_allocated 29275.18798828125 
[2025-03-01 21:46:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-01 21:47:53 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.34960344433784485 norm:0.001803079852834344 max memory_allocated 29275.75048828125 
[2025-03-01 21:48:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.3425220847129822 norm:0.0011511498596519232 max memory_allocated 29275.75048828125 
[2025-03-01 21:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.33593931794166565 norm:0.0008460636017844081 max memory_allocated 29275.75048828125 
[2025-03-01 21:50:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.33389246463775635 norm:0.0006801257841289043 max memory_allocated 29275.75048828125 
[2025-03-01 21:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.33247026801109314 norm:0.0006258181529119611 max memory_allocated 29275.75048828125 
[2025-03-01 21:52:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.331279456615448 norm:0.0005703430506400764 max memory_allocated 29275.75048828125 
[2025-03-01 21:52:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.33058789372444153 norm:0.0005156075349077582 max memory_allocated 29275.75048828125 
[2025-03-01 21:53:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.33022332191467285 norm:0.0004907800466753542 max memory_allocated 29275.75048828125 
[2025-03-01 21:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.33000314235687256 norm:0.0004950708243995905 max memory_allocated 29275.75048828125 
[2025-03-01 21:55:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.32980623841285706 norm:0.000499330519232899 max memory_allocated 29275.75048828125 
[2025-03-01 21:56:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.329589307308197 norm:0.00047125029959715903 max memory_allocated 29275.75048828125 
[2025-03-01 21:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.32947033643722534 norm:0.00046384328743442893 max memory_allocated 29275.75048828125 
[2025-03-01 21:57:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.32941222190856934 norm:0.00045925044105388224 max memory_allocated 29275.75048828125 
[2025-03-01 21:58:39 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.3293004035949707 norm:0.0004581380635499954 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.3292434513568878 norm:0.0004559565568342805 max memory_allocated 29275.75048828125 
[2025-03-01 22:00:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.3291536271572113 norm:0.00044351621181704104 max memory_allocated 29275.75048828125 
[2025-03-01 22:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.32901284098625183 norm:0.00042968482011929154 max memory_allocated 29275.75048828125 
[2025-03-01 22:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.32895928621292114 norm:0.0004259255947545171 max memory_allocated 29275.75048828125 
[2025-03-01 22:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.3288569450378418 norm:0.0004228478646837175 max memory_allocated 29275.75048828125 
[2025-03-01 22:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.32882851362228394 norm:0.00042072663200087845 max memory_allocated 29275.75048828125 
[2025-03-01 22:03:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-01 22:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.37445175647735596 norm:0.0010082940571010113 max memory_allocated 29275.75048828125 
[2025-03-01 22:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.3678884506225586 norm:0.0006555825239047408 max memory_allocated 29275.75048828125 
[2025-03-01 22:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.36148983240127563 norm:0.0004998790100216866 max memory_allocated 29275.75048828125 
[2025-03-01 22:07:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.3596595525741577 norm:0.0004157818912062794 max memory_allocated 29275.75048828125 
[2025-03-01 22:08:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.3583717942237854 norm:0.00036162257310934365 max memory_allocated 29275.75048828125 
[2025-03-01 22:08:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.357284277677536 norm:0.00032909458968788385 max memory_allocated 29275.75048828125 
[2025-03-01 22:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.3566858470439911 norm:0.00030860595870763063 max memory_allocated 29275.75048828125 
[2025-03-01 22:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.3563724160194397 norm:0.00029360398184508085 max memory_allocated 29275.75048828125 
[2025-03-01 22:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.3560693562030792 norm:0.0002841108071152121 max memory_allocated 29275.75048828125 
[2025-03-01 22:12:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.35588929057121277 norm:0.00027859379770234227 max memory_allocated 29275.75048828125 
[2025-03-01 22:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.35575059056282043 norm:0.00027351707103662193 max memory_allocated 29275.75048828125 
[2025-03-01 22:13:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.3556056618690491 norm:0.0002662407932803035 max memory_allocated 29275.75048828125 
[2025-03-01 22:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.35549402236938477 norm:0.0002614744589664042 max memory_allocated 29275.75048828125 
[2025-03-01 22:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.35539859533309937 norm:0.00026173493824899197 max memory_allocated 29275.75048828125 
[2025-03-01 22:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.35529881715774536 norm:0.00025940415798686445 max memory_allocated 29275.75048828125 
[2025-03-01 22:17:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.3552454113960266 norm:0.0002572763478383422 max memory_allocated 29275.75048828125 
[2025-03-01 22:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.355194091796875 norm:0.0002559334971010685 max memory_allocated 29275.75048828125 
[2025-03-01 22:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.3551492989063263 norm:0.00025612354511395097 max memory_allocated 29275.75048828125 
[2025-03-01 22:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.3550674319267273 norm:0.00025927371461875737 max memory_allocated 29275.75048828125 
[2025-03-01 22:20:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.3550025224685669 norm:0.00026107538724318147 max memory_allocated 29275.75048828125 
[2025-03-01 22:20:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-01 22:21:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.4125366806983948 norm:0.001662542810663581 max memory_allocated 29275.75048828125 
[2025-03-01 22:22:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.4051018953323364 norm:0.0011124901939183474 max memory_allocated 29275.75048828125 
[2025-03-01 22:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.39822790026664734 norm:0.0010482830693945289 max memory_allocated 29275.75048828125 
[2025-03-01 22:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.3960876166820526 norm:0.0010244803270325065 max memory_allocated 29275.75048828125 
[2025-03-01 22:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.3945164084434509 norm:0.0009881656151264906 max memory_allocated 29275.75048828125 
[2025-03-01 22:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.3933872878551483 norm:0.0010316214757040143 max memory_allocated 29275.75048828125 
[2025-03-01 22:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.39263010025024414 norm:0.0009158478933386505 max memory_allocated 29275.75048828125 
[2025-03-01 22:27:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.3922249972820282 norm:0.0008118361001834273 max memory_allocated 29275.75048828125 
[2025-03-01 22:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.3918568789958954 norm:0.0007212850614450872 max memory_allocated 29275.75048828125 
[2025-03-01 22:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.39167994260787964 norm:0.0007612964254803956 max memory_allocated 29275.75048828125 
[2025-03-01 22:29:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.3914420008659363 norm:0.0006349516334012151 max memory_allocated 29275.75048828125 
[2025-03-01 22:30:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.39127206802368164 norm:0.0006438818527385592 max memory_allocated 29275.75048828125 
[2025-03-01 22:31:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.3912668228149414 norm:0.0006011854275129735 max memory_allocated 29275.75048828125 
[2025-03-01 22:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.3910341262817383 norm:0.0005619017756544054 max memory_allocated 29275.75048828125 
[2025-03-01 22:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.3908543586730957 norm:0.0005424664122983813 max memory_allocated 29275.75048828125 
[2025-03-01 22:34:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.3908102810382843 norm:0.0006754054920747876 max memory_allocated 29275.75048828125 
[2025-03-01 22:34:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.39049863815307617 norm:0.0006062271422706544 max memory_allocated 29275.75048828125 
[2025-03-01 22:35:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.3908277153968811 norm:0.0005895023932680488 max memory_allocated 29275.75048828125 
[2025-03-01 22:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.39047712087631226 norm:0.0005641818861477077 max memory_allocated 29275.75048828125 
[2025-03-01 22:37:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.3907155990600586 norm:0.0005624238983727992 max memory_allocated 29275.75048828125 
[2025-03-01 22:37:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-01 22:38:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.4451727569103241 norm:0.0016110308934003115 max memory_allocated 29276.31298828125 
[2025-03-01 22:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.4377050995826721 norm:0.0010786724742501974 max memory_allocated 29276.31298828125 
[2025-03-01 22:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.4307488203048706 norm:0.0008185969782061875 max memory_allocated 29276.31298828125 
[2025-03-01 22:40:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.4286300241947174 norm:0.000672437425237149 max memory_allocated 29276.31298828125 
[2025-03-01 22:41:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.42704230546951294 norm:0.000574406934902072 max memory_allocated 29276.31298828125 
[2025-03-01 22:42:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.4258245825767517 norm:0.0005112200160510838 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.4251626431941986 norm:0.00045539590064436197 max memory_allocated 29276.31298828125 
[2025-03-01 22:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.4247927665710449 norm:0.00042551764636300504 max memory_allocated 29276.31298828125 
[2025-03-01 22:45:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.4245084226131439 norm:0.0004017441242467612 max memory_allocated 29276.31298828125 
[2025-03-01 22:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.4243370294570923 norm:0.0003813875373452902 max memory_allocated 29276.31298828125 
[2025-03-01 22:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.4241662323474884 norm:0.00036386563442647457 max memory_allocated 29276.31298828125 
[2025-03-01 22:47:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.4239598512649536 norm:0.000344469997799024 max memory_allocated 29276.31298828125 
[2025-03-01 22:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.4238106608390808 norm:0.0003291226748842746 max memory_allocated 29276.31298828125 
[2025-03-01 22:49:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.42367175221443176 norm:0.0003303168632555753 max memory_allocated 29276.31298828125 
[2025-03-01 22:50:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.4235581159591675 norm:0.0003173023578710854 max memory_allocated 29276.31298828125 
[2025-03-01 22:50:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.4234590530395508 norm:0.00031078103347681463 max memory_allocated 29276.31298828125 
[2025-03-01 22:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.42338261008262634 norm:0.0003075246640946716 max memory_allocated 29276.31298828125 
[2025-03-01 22:52:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.423321932554245 norm:0.00030624656938016415 max memory_allocated 29276.31298828125 
[2025-03-01 22:53:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.42324918508529663 norm:0.000300310377497226 max memory_allocated 29276.31298828125 
[2025-03-01 22:54:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.42318135499954224 norm:0.00029898376669734716 max memory_allocated 29276.31298828125 
[2025-03-01 22:54:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-01 22:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.48650020360946655 norm:0.0018539892043918371 max memory_allocated 29276.31298828125 
[2025-03-01 22:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.4774209260940552 norm:0.001221745740622282 max memory_allocated 29276.31298828125 
[2025-03-01 22:57:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.46902769804000854 norm:0.0009129748796112835 max memory_allocated 29276.31298828125 
[2025-03-01 22:57:50 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.466464102268219 norm:0.0007477929466404021 max memory_allocated 29276.31298828125 
[2025-03-01 22:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.46461939811706543 norm:0.0006260547670535743 max memory_allocated 29276.31298828125 
[2025-03-01 22:59:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.4633840322494507 norm:0.0005616724956780672 max memory_allocated 29276.31298828125 
[2025-03-01 23:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.4627186059951782 norm:0.0005113335209898651 max memory_allocated 29276.31298828125 
[2025-03-01 23:01:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.4623492956161499 norm:0.0004751833330374211 max memory_allocated 29276.31298828125 
[2025-03-01 23:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.46205440163612366 norm:0.00045157517888583243 max memory_allocated 29276.31298828125 
[2025-03-01 23:02:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.4618460237979889 norm:0.00043369783088564873 max memory_allocated 29276.31298828125 
[2025-03-01 23:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.46165287494659424 norm:0.00041320768650621176 max memory_allocated 29276.31298828125 
[2025-03-01 23:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.4615115523338318 norm:0.00039880393887870014 max memory_allocated 29276.31298828125 
[2025-03-01 23:05:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.46140632033348083 norm:0.00039513062802143395 max memory_allocated 29276.31298828125 
[2025-03-01 23:06:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.46126827597618103 norm:0.000387683161534369 max memory_allocated 29276.31298828125 
[2025-03-01 23:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.46119630336761475 norm:0.0003840797580778599 max memory_allocated 29276.31298828125 
[2025-03-01 23:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.46111154556274414 norm:0.000378148426534608 max memory_allocated 29276.31298828125 
[2025-03-01 23:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.4610608220100403 norm:0.0003688315046019852 max memory_allocated 29276.31298828125 
[2025-03-01 23:09:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.46096277236938477 norm:0.0003627072728704661 max memory_allocated 29276.31298828125 
[2025-03-01 23:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.46086883544921875 norm:0.0003556867886800319 max memory_allocated 29276.31298828125 
[2025-03-01 23:11:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.46079307794570923 norm:0.0003501193132251501 max memory_allocated 29276.31298828125 
[2025-03-01 23:11:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-01 23:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.5253640413284302 norm:0.0013502745423465967 max memory_allocated 29276.31298828125 
[2025-03-01 23:13:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.5168522000312805 norm:0.0008394008036702871 max memory_allocated 29276.31298828125 
[2025-03-01 23:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.5082522630691528 norm:0.0006131103727966547 max memory_allocated 29276.31298828125 
[2025-03-01 23:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.5053562521934509 norm:0.0005162765737622976 max memory_allocated 29276.31298828125 
[2025-03-01 23:15:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.5034652352333069 norm:0.00045859417878091335 max memory_allocated 29276.31298828125 
[2025-03-01 23:16:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.5022150874137878 norm:0.0004157241783104837 max memory_allocated 29276.31298828125 
[2025-03-01 23:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.5016725063323975 norm:0.0003985098155681044 max memory_allocated 29276.31298828125 
[2025-03-01 23:18:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.5013986825942993 norm:0.0003903900214936584 max memory_allocated 29276.31298828125 
[2025-03-01 23:18:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.5011240839958191 norm:0.00037662425893358886 max memory_allocated 29276.31298828125 
[2025-03-01 23:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.5009468793869019 norm:0.0003682708484120667 max memory_allocated 29276.31298828125 
[2025-03-01 23:20:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.5007936954498291 norm:0.00037245487328618765 max memory_allocated 29276.31298828125 
[2025-03-01 23:21:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.500645101070404 norm:0.00036344496766105294 max memory_allocated 29276.31298828125 
[2025-03-01 23:22:09 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.5004578232765198 norm:0.0003570791450329125 max memory_allocated 29276.31298828125 
[2025-03-01 23:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.5003794431686401 norm:0.00036369237932376564 max memory_allocated 29276.31298828125 
[2025-03-01 23:23:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.50026935338974 norm:0.00036609763628803194 max memory_allocated 29276.31298828125 
[2025-03-01 23:24:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.5001429319381714 norm:0.00036355218617245555 max memory_allocated 29276.31298828125 
[2025-03-01 23:25:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.5000418424606323 norm:0.00036241099587641656 max memory_allocated 29276.31298828125 
[2025-03-01 23:26:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.4999755024909973 norm:0.0003537707088980824 max memory_allocated 29276.31298828125 
[2025-03-01 23:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.49989819526672363 norm:0.0003560473269317299 max memory_allocated 29276.31298828125 
[2025-03-01 23:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.4998704195022583 norm:0.0003658777568489313 max memory_allocated 29276.31298828125 
[2025-03-01 23:28:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-01 23:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.5735651254653931 norm:0.0017130858032032847 max memory_allocated 29276.87548828125 
[2025-03-01 23:29:55 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.563845157623291 norm:0.00104892672970891 max memory_allocated 29276.87548828125 
[2025-03-01 23:30:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.5546596050262451 norm:0.0007674644002690911 max memory_allocated 29276.87548828125 
[2025-03-01 23:31:34 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.5514074563980103 norm:0.0006369426264427602 max memory_allocated 29276.87548828125 
[2025-03-01 23:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.5492516756057739 norm:0.0005744301015511155 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.5478801727294922 norm:0.0005184492329135537 max memory_allocated 29276.87548828125 
[2025-03-01 23:34:03 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.5471846461296082 norm:0.0004744512843899429 max memory_allocated 29276.87548828125 
[2025-03-01 23:34:53 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.5467540621757507 norm:0.00045706331729888916 max memory_allocated 29276.87548828125 
[2025-03-01 23:35:42 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.5464053153991699 norm:0.00043332873610779643 max memory_allocated 29276.87548828125 
[2025-03-01 23:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.5461863875389099 norm:0.0004233740037307143 max memory_allocated 29276.87548828125 
[2025-03-01 23:37:22 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.5459743738174438 norm:0.00041185118607245386 max memory_allocated 29276.87548828125 
[2025-03-01 23:38:11 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.5457812547683716 norm:0.0003957024891860783 max memory_allocated 29276.87548828125 
[2025-03-01 23:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.5456643104553223 norm:0.0003849873610306531 max memory_allocated 29276.87548828125 
[2025-03-01 23:39:51 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.5455355048179626 norm:0.00038766994839534163 max memory_allocated 29276.87548828125 
[2025-03-01 23:40:40 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.5454564094543457 norm:0.00037991703720763326 max memory_allocated 29276.87548828125 
[2025-03-01 23:41:30 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.5453858971595764 norm:0.000379483331926167 max memory_allocated 29276.87548828125 
[2025-03-01 23:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.5452747941017151 norm:0.0003839884593617171 max memory_allocated 29276.87548828125 
[2025-03-01 23:43:09 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.5452167391777039 norm:0.00037067674566060305 max memory_allocated 29276.87548828125 
[2025-03-01 23:43:59 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.5450947284698486 norm:0.0003684825205709785 max memory_allocated 29276.87548828125 
[2025-03-01 23:44:49 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.5450072884559631 norm:0.00036898895632475615 max memory_allocated 29276.87548828125 
[2025-03-01 23:45:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-01 23:45:57 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.6200466752052307 norm:0.002025837544351816 max memory_allocated 29276.87548828125 
[2025-03-01 23:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.6093314290046692 norm:0.00134727219119668 max memory_allocated 29276.87548828125 
[2025-03-01 23:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.5993985533714294 norm:0.0009523751796223223 max memory_allocated 29276.87548828125 
[2025-03-01 23:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.5963578820228577 norm:0.0007709828205406666 max memory_allocated 29276.87548828125 
[2025-03-01 23:49:15 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.5944116115570068 norm:0.0006754014175385237 max memory_allocated 29276.87548828125 
[2025-03-01 23:50:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.5932842493057251 norm:0.0006045001209713519 max memory_allocated 29276.87548828125 
[2025-03-01 23:50:55 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.5927025079727173 norm:0.0005595788825303316 max memory_allocated 29276.87548828125 
[2025-03-01 23:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.5923163294792175 norm:0.0005294177681207657 max memory_allocated 29276.87548828125 
[2025-03-01 23:52:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.5920124053955078 norm:0.0004926428664475679 max memory_allocated 29276.87548828125 
[2025-03-01 23:53:24 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.5917080640792847 norm:0.00046070272219367325 max memory_allocated 29276.87548828125 
[2025-03-01 23:54:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.5915202498435974 norm:0.0004463057848624885 max memory_allocated 29276.87548828125 
[2025-03-01 23:55:03 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.5913729667663574 norm:0.00043732323683798313 max memory_allocated 29276.87548828125 
[2025-03-01 23:55:53 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.5912229418754578 norm:0.00042354577453806996 max memory_allocated 29276.87548828125 
[2025-03-01 23:56:42 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.5911502838134766 norm:0.0004153999616391957 max memory_allocated 29276.87548828125 
[2025-03-01 23:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.5909835696220398 norm:0.0003956850850954652 max memory_allocated 29276.87548828125 
[2025-03-01 23:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.5907876491546631 norm:0.00038289144868031144 max memory_allocated 29276.87548828125 
[2025-03-01 23:59:12 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.5906461477279663 norm:0.0003749516326934099 max memory_allocated 29276.87548828125 
[2025-03-02 00:00:01 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.5905874371528625 norm:0.00037487150984816253 max memory_allocated 29276.87548828125 
[2025-03-02 00:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.5905455350875854 norm:0.0003716147621162236 max memory_allocated 29276.87548828125 
[2025-03-02 00:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.5905265212059021 norm:0.00036568602081388235 max memory_allocated 29276.87548828125 
[2025-03-02 00:01:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 00:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.6800511479377747 norm:0.0014253311092033982 max memory_allocated 29276.87548828125 
[2025-03-02 00:03:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.6685516834259033 norm:0.0008915766957215965 max memory_allocated 29276.87548828125 
[2025-03-02 00:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.6581662893295288 norm:0.0007983030518516898 max memory_allocated 29276.87548828125 
[2025-03-02 00:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.6544179320335388 norm:0.0005695635918527842 max memory_allocated 29276.87548828125 
[2025-03-02 00:06:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.6519128084182739 norm:0.0005217684083618224 max memory_allocated 29276.87548828125 
[2025-03-02 00:06:57 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.6507141590118408 norm:0.0004788230871781707 max memory_allocated 29276.87548828125 
[2025-03-02 00:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.6501226425170898 norm:0.0004607724549714476 max memory_allocated 29276.87548828125 
[2025-03-02 00:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.6497032642364502 norm:0.0004433210124261677 max memory_allocated 29276.87548828125 
[2025-03-02 00:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.6493005752563477 norm:0.0004343219334259629 max memory_allocated 29276.87548828125 
[2025-03-02 00:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.649018406867981 norm:0.00042768451385200024 max memory_allocated 29276.87548828125 
[2025-03-02 00:11:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.6487951278686523 norm:0.0004113822360523045 max memory_allocated 29276.87548828125 
[2025-03-02 00:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.6485859155654907 norm:0.00040623528184369206 max memory_allocated 29276.87548828125 
[2025-03-02 00:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.6483437418937683 norm:0.00039569076034240425 max memory_allocated 29276.87548828125 
[2025-03-02 00:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.6481913328170776 norm:0.0004013139405287802 max memory_allocated 29276.87548828125 
[2025-03-02 00:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.6479433178901672 norm:0.00039324493263848126 max memory_allocated 29276.87548828125 
[2025-03-02 00:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.6478433012962341 norm:0.0003909216611646116 max memory_allocated 29276.87548828125 
[2025-03-02 00:16:03 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.6477318406105042 norm:0.00038282148307189345 max memory_allocated 29276.87548828125 
[2025-03-02 00:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.647609293460846 norm:0.00037829633220098913 max memory_allocated 29276.87548828125 
[2025-03-02 00:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.6475003957748413 norm:0.0003712441539391875 max memory_allocated 29276.87548828125 
[2025-03-02 00:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.6474639773368835 norm:0.00036610267125070095 max memory_allocated 29276.87548828125 
[2025-03-02 00:18:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 00:19:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.7445322871208191 norm:0.002719633746892214 max memory_allocated 29277.43798828125 
[2025-03-02 00:20:30 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.7311748266220093 norm:0.0016033394495025277 max memory_allocated 29277.43798828125 
[2025-03-02 00:21:20 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.7193698883056641 norm:0.0011219483567401767 max memory_allocated 29277.43798828125 
[2025-03-02 00:22:10 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.7152513265609741 norm:0.0008667228394187987 max memory_allocated 29277.43798828125 
[2025-03-02 00:23:00 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.7125557065010071 norm:0.0007292217924259603 max memory_allocated 29277.43798828125 
[2025-03-02 00:23:49 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.7111029028892517 norm:0.0006334791542030871 max memory_allocated 29277.43798828125 
[2025-03-02 00:24:39 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.7104332447052002 norm:0.0005857656360603869 max memory_allocated 29277.43798828125 
[2025-03-02 00:25:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.7099081873893738 norm:0.0005459845997393131 max memory_allocated 29277.43798828125 
[2025-03-02 00:26:18 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.7095446586608887 norm:0.0005145707400515676 max memory_allocated 29277.43798828125 
[2025-03-02 00:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.7092628479003906 norm:0.0005036677466705441 max memory_allocated 29277.43798828125 
[2025-03-02 00:27:58 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.7089352011680603 norm:0.00047931657172739506 max memory_allocated 29277.43798828125 
[2025-03-02 00:28:47 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.7086504101753235 norm:0.0004634865326806903 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.7084953784942627 norm:0.00045148778008297086 max memory_allocated 29277.43798828125 
[2025-03-02 00:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.7082583904266357 norm:0.00044417392928153276 max memory_allocated 29277.43798828125 
[2025-03-02 00:31:17 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.7081007361412048 norm:0.00043485796777531505 max memory_allocated 29277.43798828125 
[2025-03-02 00:32:06 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.7079451084136963 norm:0.00042388716246932745 max memory_allocated 29277.43798828125 
[2025-03-02 00:32:56 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.7078073024749756 norm:0.00042065948946401477 max memory_allocated 29277.43798828125 
[2025-03-02 00:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.7076910734176636 norm:0.0004238216788507998 max memory_allocated 29277.43798828125 
[2025-03-02 00:34:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.7075790166854858 norm:0.00041433415026403964 max memory_allocated 29277.43798828125 
[2025-03-02 00:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.7074670791625977 norm:0.0004098133067600429 max memory_allocated 29277.43798828125 
[2025-03-02 00:35:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 00:35:44 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.8323379755020142 norm:0.017836114391684532 max memory_allocated 29277.43798828125 
[2025-03-02 00:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.8152018785476685 norm:0.014774950221180916 max memory_allocated 29277.43798828125 
[2025-03-02 00:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.8002224564552307 norm:0.01100138295441866 max memory_allocated 29277.43798828125 
[2025-03-02 00:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.7936565279960632 norm:0.008785588666796684 max memory_allocated 29277.43798828125 
[2025-03-02 00:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.7898438572883606 norm:0.007560845464468002 max memory_allocated 29277.43798828125 
[2025-03-02 00:40:43 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.7875235080718994 norm:0.0068915486335754395 max memory_allocated 29277.43798828125 
[2025-03-02 00:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.7861475348472595 norm:0.006224432028830051 max memory_allocated 29277.43798828125 
[2025-03-02 00:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.7852134704589844 norm:0.0057739694602787495 max memory_allocated 29277.43798828125 
[2025-03-02 00:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.7844184041023254 norm:0.005383663345128298 max memory_allocated 29277.43798828125 
[2025-03-02 00:44:02 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.7838037014007568 norm:0.005189018789678812 max memory_allocated 29277.43798828125 
[2025-03-02 00:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.7833265662193298 norm:0.004919892642647028 max memory_allocated 29277.43798828125 
[2025-03-02 00:45:42 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.782860517501831 norm:0.004829758312553167 max memory_allocated 29277.43798828125 
[2025-03-02 00:46:32 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.7825846076011658 norm:0.004648818634450436 max memory_allocated 29277.43798828125 
[2025-03-02 00:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.7823152542114258 norm:0.004526395350694656 max memory_allocated 29277.43798828125 
[2025-03-02 00:48:12 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.7820397615432739 norm:0.004385970067232847 max memory_allocated 29277.43798828125 
[2025-03-02 00:49:01 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.78182053565979 norm:0.004291093442589045 max memory_allocated 29277.43798828125 
[2025-03-02 00:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.7816108465194702 norm:0.004230796825140715 max memory_allocated 29277.43798828125 
[2025-03-02 00:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.7814603447914124 norm:0.004180325660854578 max memory_allocated 29277.43798828125 
[2025-03-02 00:51:31 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.781312882900238 norm:0.00408727303147316 max memory_allocated 29277.43798828125 
[2025-03-02 00:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.7811889052391052 norm:0.00398385850712657 max memory_allocated 29277.43798828125 
[2025-03-02 00:52:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 00:52:39 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.9242082238197327 norm:0.020296018570661545 max memory_allocated 29277.43798828125 
[2025-03-02 00:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.9030061960220337 norm:0.01604728028178215 max memory_allocated 29277.43798828125 
[2025-03-02 00:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.8857115507125854 norm:0.012046070769429207 max memory_allocated 29277.43798828125 
[2025-03-02 00:55:58 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.8784869313240051 norm:0.00937085971236229 max memory_allocated 29277.43798828125 
[2025-03-02 00:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.8740943670272827 norm:0.00772991543635726 max memory_allocated 29277.43798828125 
[2025-03-02 00:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.8715978860855103 norm:0.007108418736606836 max memory_allocated 29277.43798828125 
[2025-03-02 00:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.8702383041381836 norm:0.006423161365091801 max memory_allocated 29277.43798828125 
[2025-03-02 00:59:18 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.8690733313560486 norm:0.006229627411812544 max memory_allocated 29277.43798828125 
[2025-03-02 01:00:08 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.8682769536972046 norm:0.006123563274741173 max memory_allocated 29277.43798828125 
[2025-03-02 01:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.8677476048469543 norm:0.00569720845669508 max memory_allocated 29277.43798828125 
[2025-03-02 01:01:48 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.8673593401908875 norm:0.005653277039527893 max memory_allocated 29277.43798828125 
[2025-03-02 01:02:37 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.8669982552528381 norm:0.005537320859730244 max memory_allocated 29277.43798828125 
[2025-03-02 01:03:27 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.8666760325431824 norm:0.0053530242294073105 max memory_allocated 29277.43798828125 
[2025-03-02 01:04:17 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.8663886785507202 norm:0.005439685191959143 max memory_allocated 29277.43798828125 
[2025-03-02 01:05:07 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.8663554787635803 norm:0.005343026481568813 max memory_allocated 29277.43798828125 
[2025-03-02 01:05:57 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.8660438060760498 norm:0.00520267803221941 max memory_allocated 29277.43798828125 
[2025-03-02 01:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.8656989932060242 norm:0.004947345238178968 max memory_allocated 29277.43798828125 
[2025-03-02 01:07:37 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.8656170964241028 norm:0.004844172857701778 max memory_allocated 29277.43798828125 
[2025-03-02 01:08:27 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.8654018640518188 norm:0.004853037651628256 max memory_allocated 29277.43798828125 
[2025-03-02 01:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.8655088543891907 norm:0.00485489796847105 max memory_allocated 29277.43798828125 
[2025-03-02 01:09:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 01:09:35 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:1.086343765258789 norm:0.024424776434898376 max memory_allocated 29277.43798828125 
[2025-03-02 01:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:1.061827301979065 norm:0.014513365924358368 max memory_allocated 29277.43798828125 
[2025-03-02 01:12:04 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:1.0376430749893188 norm:0.008226003497838974 max memory_allocated 29277.43798828125 
[2025-03-02 01:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:1.024435043334961 norm:0.007914526388049126 max memory_allocated 29277.43798828125 
[2025-03-02 01:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:1.0177693367004395 norm:0.007428167387843132 max memory_allocated 29277.43798828125 
[2025-03-02 01:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:1.0145975351333618 norm:0.007211507763713598 max memory_allocated 29277.43798828125 
[2025-03-02 01:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:1.0121649503707886 norm:0.007838630117475986 max memory_allocated 29277.43798828125 
[2025-03-02 01:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:1.0104589462280273 norm:0.009081566706299782 max memory_allocated 29277.43798828125 
[2025-03-02 01:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:1.009251356124878 norm:0.009106823243200779 max memory_allocated 29277.43798828125 
[2025-03-02 01:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:1.0085090398788452 norm:0.009025591425597668 max memory_allocated 29277.43798828125 
[2025-03-02 01:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:1.0077764987945557 norm:0.00855962373316288 max memory_allocated 29277.43798828125 
[2025-03-02 01:19:33 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:1.007493019104004 norm:0.008422189392149448 max memory_allocated 29277.43798828125 
[2025-03-02 01:20:23 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:1.0067901611328125 norm:0.008422255516052246 max memory_allocated 29277.43798828125 
[2025-03-02 01:21:13 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:1.006731629371643 norm:0.008514230139553547 max memory_allocated 29277.43798828125 
[2025-03-02 01:22:03 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:1.006995677947998 norm:0.008489301428198814 max memory_allocated 29277.43798828125 
[2025-03-02 01:22:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:1.0060694217681885 norm:0.007779480889439583 max memory_allocated 29277.43798828125 
[2025-03-02 01:23:42 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:1.0047240257263184 norm:0.006349243223667145 max memory_allocated 29277.43798828125 
[2025-03-02 01:24:32 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:1.0044224262237549 norm:0.00658000772818923 max memory_allocated 29277.43798828125 
[2025-03-02 01:25:22 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:1.0038690567016602 norm:0.006441849749535322 max memory_allocated 29277.43798828125 
[2025-03-02 01:26:12 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:1.0032120943069458 norm:0.005953207612037659 max memory_allocated 29277.43798828125 
[2025-03-02 01:26:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 01:26:31 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:27:21 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:1.528460144996643 norm:0.11209514737129211 max memory_allocated 29277.43798828125 
[2025-03-02 01:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:1.427338719367981 norm:0.06610552966594696 max memory_allocated 29277.43798828125 
[2025-03-02 01:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:1.3666775226593018 norm:0.03924340754747391 max memory_allocated 29277.43798828125 
[2025-03-02 01:29:50 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:1.3366575241088867 norm:0.02806921675801277 max memory_allocated 29277.43798828125 
[2025-03-02 01:30:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:1.3228791952133179 norm:0.025491924956440926 max memory_allocated 29277.43798828125 
[2025-03-02 01:31:30 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:1.3131016492843628 norm:0.022322431206703186 max memory_allocated 29277.43798828125 
[2025-03-02 01:32:19 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:1.3058016300201416 norm:0.020388644188642502 max memory_allocated 29277.43798828125 
[2025-03-02 01:33:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:1.301006555557251 norm:0.01950359344482422 max memory_allocated 29277.43798828125 
[2025-03-02 01:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:1.2972919940948486 norm:0.018583154305815697 max memory_allocated 29277.43798828125 
[2025-03-02 01:34:49 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:1.2941639423370361 norm:0.018002351745963097 max memory_allocated 29277.43798828125 
[2025-03-02 01:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:1.2921792268753052 norm:0.01747966557741165 max memory_allocated 29277.43798828125 
[2025-03-02 01:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:1.290121078491211 norm:0.017724165692925453 max memory_allocated 29277.43798828125 
[2025-03-02 01:37:19 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:1.2879389524459839 norm:0.017018720507621765 max memory_allocated 29277.43798828125 
[2025-03-02 01:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:1.2859407663345337 norm:0.016112195327878 max memory_allocated 29277.43798828125 
[2025-03-02 01:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:1.2841589450836182 norm:0.01538095623254776 max memory_allocated 29277.43798828125 
[2025-03-02 01:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:1.2828869819641113 norm:0.01546479668468237 max memory_allocated 29277.43798828125 
[2025-03-02 01:40:38 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:1.2817915678024292 norm:0.0157149750739336 max memory_allocated 29277.43798828125 
[2025-03-02 01:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:1.2805746793746948 norm:0.015560346655547619 max memory_allocated 29277.43798828125 
[2025-03-02 01:42:18 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:1.2801904678344727 norm:0.01573110558092594 max memory_allocated 29277.43798828125 
[2025-03-02 01:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:1.278829574584961 norm:0.015313321724534035 max memory_allocated 29277.43798828125 
[2025-03-02 01:43:22 root] (main_calib_config2.py 380): INFO 40499.75825834274
[2025-03-02 01:43:32 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-02 01:45:29 root] (main_calib_config2.py 159): INFO wikitext2 : 5.644891738891602
[2025-03-02 01:45:29 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-02 01:48:29 root] (main_calib_config2.py 159): INFO c4 : 7.633296966552734
[2025-03-02 03:52:27 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.644891738891602, 'c4': 7.633296966552734, 'results': {'arc_challenge': {'acc': 0.40102389078498296, 'acc_stderr': 0.014322255790719867, 'acc_norm': 0.4274744027303754, 'acc_norm_stderr': 0.014456862944650647}, 'boolq': {'acc': 0.6446483180428134, 'acc_stderr': 0.00837111203475938}, 'hellaswag': {'acc': 0.5583549093806015, 'acc_stderr': 0.004955681533284334, 'acc_norm': 0.7170882294363673, 'acc_norm_stderr': 0.00449493402546234}, 'winogrande': {'acc': 0.6219415943172849, 'acc_stderr': 0.013628165460523242}, 'arc_easy': {'acc': 0.6952861952861953, 'acc_stderr': 0.009444871667360211, 'acc_norm': 0.5488215488215489, 'acc_norm_stderr': 0.010210757101073468}, 'piqa': {'acc': 0.764961915125136, 'acc_stderr': 0.00989314668880531, 'acc_norm': 0.7714907508161044, 'acc_norm_stderr': 0.009796313511829509}}, 'versions': {'arc_challenge': 0, 'boolq': 1, 'hellaswag': 0, 'winogrande': 0, 'arc_easy': 0, 'piqa': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
