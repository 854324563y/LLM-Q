[2025-02-28 13:17:24 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-7b-hf_0.35', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.35.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:20:27 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:20:27 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.35.pkl
[2025-02-28 13:20:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:20:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.0323345810174942 norm:0.023945508524775505 max memory_allocated 22562.10693359375 
[2025-02-28 13:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.023342980071902275 norm:0.016278695315122604 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.019097857177257538 norm:0.012798598036170006 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.017625894397497177 norm:0.010239762254059315 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.017060259357094765 norm:0.008269143290817738 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.016753969714045525 norm:0.006632400676608086 max memory_allocated 22562.10693359375 
[2025-02-28 13:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.01652584969997406 norm:0.005558262579143047 max memory_allocated 22562.10693359375 
[2025-02-28 13:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.01629861444234848 norm:0.004669016692787409 max memory_allocated 22562.10693359375 
[2025-02-28 13:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.01627703383564949 norm:0.004520924296230078 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.01608767919242382 norm:0.004115676507353783 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.01616288535296917 norm:0.004429856315255165 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.016171298921108246 norm:0.004288281314074993 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.01617117039859295 norm:0.004064041189849377 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.01603059284389019 norm:0.003783909138292074 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.016113141551613808 norm:0.003846041625365615 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.016013093292713165 norm:0.0036331561859697104 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:01 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.016088195145130157 norm:0.003720426931977272 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.01596750132739544 norm:0.0032575454097241163 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.01594257913529873 norm:0.0030785200651735067 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.015914198011159897 norm:0.0029105909634381533 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:31:54 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.16427813470363617 norm:0.06197815388441086 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.12633439898490906 norm:0.04450840875506401 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.11028844863176346 norm:0.03479159623384476 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.10294108837842941 norm:0.032958660274744034 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:42 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.10016694664955139 norm:0.030634259805083275 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.0986381471157074 norm:0.029513895511627197 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.09748505055904388 norm:0.027202878147363663 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.09560705721378326 norm:0.026948831975460052 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.0944310799241066 norm:0.024985523894429207 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.094362273812294 norm:0.024886492639780045 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.09537214785814285 norm:0.02485673874616623 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.09401627629995346 norm:0.02445540949702263 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.0938747450709343 norm:0.023691784590482712 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.09353978931903839 norm:0.022763844579458237 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.09492063522338867 norm:0.02327561005949974 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.09430913627147675 norm:0.021908720955252647 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.09374424070119858 norm:0.022025365382432938 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.09493087232112885 norm:0.022417623549699783 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.09524213522672653 norm:0.021248407661914825 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.09467267245054245 norm:0.02217778190970421 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 13:43:19 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:43:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.14005611836910248 norm:0.02312416397035122 max memory_allocated 22562.45068359375 
[2025-02-28 13:44:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.12009403854608536 norm:0.015712328255176544 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.1108255460858345 norm:0.011597281321883202 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.10704466700553894 norm:0.009469165466725826 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.10473760217428207 norm:0.00767933763563633 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.10321672260761261 norm:0.006058377679437399 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.10219404846429825 norm:0.004992633126676083 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.10162903368473053 norm:0.004600629676133394 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.10128192603588104 norm:0.004385799169540405 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.10091184079647064 norm:0.0041191005147993565 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.1007016971707344 norm:0.0038216481916606426 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.100541852414608 norm:0.0036794920451939106 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:38 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.10042405128479004 norm:0.003518930170685053 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.10032884776592255 norm:0.0034053181298077106 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:45 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.10021866858005524 norm:0.003360274713486433 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.10012474656105042 norm:0.003310509491711855 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.10011520981788635 norm:0.0032413117587566376 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.10010778903961182 norm:0.0032545654103159904 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.10003551840782166 norm:0.003140874905511737 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.09998880326747894 norm:0.0031013484112918377 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 13:55:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.1386951208114624 norm:0.015738729387521744 max memory_allocated 22562.50732421875 
[2025-02-28 13:55:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.11755010485649109 norm:0.005579780787229538 max memory_allocated 22562.50732421875 
[2025-02-28 13:56:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.10258801281452179 norm:0.002077545505017042 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.09794162213802338 norm:0.0014439778169617057 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.09584659337997437 norm:0.0012258109636604786 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.09498059749603271 norm:0.0013276831014081836 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.09446205198764801 norm:0.001181424711830914 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.09417862445116043 norm:0.0010454622097313404 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.09398366510868073 norm:0.0009729131706990302 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.09385298937559128 norm:0.0009682655800133944 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.0938306376338005 norm:0.0009898747084662318 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.09374181181192398 norm:0.0009096041321754456 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.09359418600797653 norm:0.0008337507024407387 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.0935184508562088 norm:0.0007657665410079062 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.0935339704155922 norm:0.0007676029345020652 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.09352199733257294 norm:0.0007555701304227114 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.09339770674705505 norm:0.0007218348328024149 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.09339884668588638 norm:0.0006800323608331382 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.09343532472848892 norm:0.0006562806665897369 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.09340673685073853 norm:0.0006500785239040852 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.15651755034923553 norm:0.01634838618338108 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.12904372811317444 norm:0.005849980283528566 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.11052253097295761 norm:0.003353594336658716 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.10536306351423264 norm:0.0019998776260763407 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.10290659964084625 norm:0.0013771579833701253 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.10168072581291199 norm:0.0010565724223852158 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.10102150589227676 norm:0.000876915524713695 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.10061933845281601 norm:0.0008489322499372065 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.10031913965940475 norm:0.0007509720744565129 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.10010802745819092 norm:0.0007307084160856903 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.09997761249542236 norm:0.0006875148974359035 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.09984225034713745 norm:0.0006447203923016787 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.0997270941734314 norm:0.0006501441821455956 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.099660724401474 norm:0.0006427152547985315 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.0996427983045578 norm:0.0006549911922775209 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.09956488013267517 norm:0.0006306834984570742 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.09950831532478333 norm:0.0006287841824814677 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.09947772324085236 norm:0.000617021054495126 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.09940066933631897 norm:0.0006186431273818016 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.09938318282365799 norm:0.0006134971627034247 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:18:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.16387826204299927 norm:0.01928209513425827 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.14109085500240326 norm:0.0065599665977060795 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.118677519261837 norm:0.0025861039757728577 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:50 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.11211100220680237 norm:0.0015240551438182592 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.10928144305944443 norm:0.0011652603279799223 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.10784736275672913 norm:0.0009790295735001564 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.10710359364748001 norm:0.0008612524252384901 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.1066131517291069 norm:0.0008428976871073246 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.10626018047332764 norm:0.0007538518984802067 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.10607153177261353 norm:0.000719153496902436 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.10601098090410233 norm:0.0006916392594575882 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.10588712245225906 norm:0.0006719402736052871 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.10579532384872437 norm:0.0006538947345688939 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.1057034283876419 norm:0.0006270369049161673 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.10565716028213501 norm:0.0006332004559226334 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.10558848828077316 norm:0.0006239997455850244 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.10561787337064743 norm:0.000637587858363986 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.10563360154628754 norm:0.0006388375186361372 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.10560110211372375 norm:0.0006031511584296823 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.10553129762411118 norm:0.0005710113327950239 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 14:29:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.1750752180814743 norm:0.01582677662372589 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.14793460071086884 norm:0.00697022769600153 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.13256822526454926 norm:0.004197513218969107 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.12579962611198425 norm:0.0027026827447116375 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.1224374771118164 norm:0.002009668154641986 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.12066494673490524 norm:0.0017392055597156286 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.11964990943670273 norm:0.001439768704585731 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.1190764307975769 norm:0.0012724085245281458 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.11860337853431702 norm:0.0010715925600379705 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.11864469945430756 norm:0.0010063662193715572 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.11841088533401489 norm:0.00094313092995435 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.11831307411193848 norm:0.000875750498380512 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.1181308776140213 norm:0.0008547902689315379 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.11798228323459625 norm:0.0008060230757109821 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.11786974966526031 norm:0.0008070961339399219 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.11781634390354156 norm:0.0007837764569558203 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.1177837997674942 norm:0.0007616845541633666 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.11776120960712433 norm:0.0007556884083896875 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.11781854182481766 norm:0.0007688527111895382 max memory_allocated 22563.02294921875 
[2025-02-28 14:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.11794640123844147 norm:0.0007517186459153891 max memory_allocated 22563.02294921875 
[2025-02-28 14:40:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 14:40:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.1832079291343689 norm:0.01116340421140194 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.15280885994434357 norm:0.012419593520462513 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.13795697689056396 norm:0.002387409331277013 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.13267171382904053 norm:0.0018720682710409164 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.1300186961889267 norm:0.0014734421856701374 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.12836965918540955 norm:0.0012425872264429927 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.12747466564178467 norm:0.0011148946359753609 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.12681511044502258 norm:0.0009699949296191335 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.126450315117836 norm:0.0008959725964814425 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.12611691653728485 norm:0.0008344873785972595 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.1259426772594452 norm:0.0007968347636051476 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.12581206858158112 norm:0.0007416684529744089 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.12578631937503815 norm:0.0007207548478618264 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.1257207691669464 norm:0.0007082277443259954 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.12563517689704895 norm:0.0006787547026760876 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.12560877203941345 norm:0.0006772351916879416 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.12567958235740662 norm:0.0006562988855876029 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.1255476176738739 norm:0.000622356019448489 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.1256040781736374 norm:0.0006432323134504259 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.12559764087200165 norm:0.000611069961450994 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 14:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.20772770047187805 norm:0.012923057191073895 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.17410103976726532 norm:0.005387857556343079 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.1497381031513214 norm:0.002086012391373515 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.14273414015769958 norm:0.0013650235487148166 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.13939344882965088 norm:0.0011381476651877165 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.13754040002822876 norm:0.00104147766251117 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.13659535348415375 norm:0.0009544097119942307 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.13594679534435272 norm:0.0008972859941422939 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.13559000194072723 norm:0.0008834358304738998 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.1354028880596161 norm:0.0008411266608163714 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.13523510098457336 norm:0.0008115095552057028 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.1351810097694397 norm:0.0007997940992936492 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.13520392775535583 norm:0.0007357384893111885 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.13514111936092377 norm:0.0007191472686827183 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.13516002893447876 norm:0.0006985294166952372 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.13511045277118683 norm:0.0006759668467566371 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.13511274755001068 norm:0.0006566576194018126 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.13509142398834229 norm:0.0006313144112937152 max memory_allocated 22563.36669921875 
[2025-02-28 15:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.13503950834274292 norm:0.0006202586810104549 max memory_allocated 22563.36669921875 
[2025-02-28 15:03:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.135101318359375 norm:0.0006056802230887115 max memory_allocated 22563.36669921875 
[2025-02-28 15:03:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 15:03:47 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.19522537291049957 norm:0.008937057107686996 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.1706213653087616 norm:0.003412867896258831 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.15491944551467896 norm:0.001721125328913331 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.14941035211086273 norm:0.0012604333460330963 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.1468297839164734 norm:0.0010668596951290965 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.14532534778118134 norm:0.0009086591308005154 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.14451827108860016 norm:0.0008324903319589794 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.1440179944038391 norm:0.0007781560416333377 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.1437341272830963 norm:0.0007412448758259416 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.14346568286418915 norm:0.0007029810803942382 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.1432570219039917 norm:0.0006726290448568761 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.1430780291557312 norm:0.0006360301631502807 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.14300808310508728 norm:0.0006179995252750814 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.14291979372501373 norm:0.0005919242976233363 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.14281751215457916 norm:0.0005704630166292191 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.1427001655101776 norm:0.000562150205951184 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.14256805181503296 norm:0.000543242204003036 max memory_allocated 22563.53857421875 
[2025-02-28 15:13:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.1424686312675476 norm:0.0005335003370419145 max memory_allocated 22563.53857421875 
[2025-02-28 15:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.14248335361480713 norm:0.000528032542206347 max memory_allocated 22563.53857421875 
[2025-02-28 15:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.14240634441375732 norm:0.0005224025226198137 max memory_allocated 22563.53857421875 
[2025-02-28 15:14:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 15:15:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.19353780150413513 norm:0.003516034223139286 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.1732996106147766 norm:0.0018301747040823102 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.1594616025686264 norm:0.0010705143213272095 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.15378756821155548 norm:0.0007574449991807342 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.1512012481689453 norm:0.000641734164673835 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.14993171393871307 norm:0.0005772709264419973 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.1492534875869751 norm:0.0005419344524852931 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.14881041646003723 norm:0.0005113424267619848 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.1485309600830078 norm:0.0005012640031054616 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.14832887053489685 norm:0.00048634351696819067 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.1481795310974121 norm:0.00048061416600830853 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.1480151116847992 norm:0.00046890712110325694 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.14789380133152008 norm:0.00045660408795811236 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.14782178401947021 norm:0.0004547445278149098 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.14775319397449493 norm:0.0004511384468059987 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.14768241345882416 norm:0.00044899998465552926 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.14760822057724 norm:0.00044592941412702203 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.14756730198860168 norm:0.00044640517444349825 max memory_allocated 22563.71044921875 
[2025-02-28 15:25:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.14752712845802307 norm:0.0004404285573400557 max memory_allocated 22563.71044921875 
[2025-02-28 15:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.14747336506843567 norm:0.0004393841663841158 max memory_allocated 22563.71044921875 
[2025-02-28 15:26:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 15:26:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.19695298373699188 norm:0.009179908782243729 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.17408360540866852 norm:0.0043215458281338215 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.1612640917301178 norm:0.0026454704347997904 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:18 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.15587374567985535 norm:0.001828874577768147 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.15296515822410583 norm:0.0013029063120484352 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.15135900676250458 norm:0.000991830020211637 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.15050576627254486 norm:0.0008166222251020372 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.1500888168811798 norm:0.0007218035752885044 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.149788498878479 norm:0.0006574077997356653 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.14963890612125397 norm:0.0006586478557437658 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.14940479397773743 norm:0.0005871045868843794 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.14924728870391846 norm:0.0005407402059063315 max memory_allocated 22563.88232421875 
[2025-02-28 15:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.14914849400520325 norm:0.0005117034306749701 max memory_allocated 22563.88232421875 
[2025-02-28 15:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.14909391105175018 norm:0.0004959049401804805 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.1490221470594406 norm:0.00047819793689996004 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.14892518520355225 norm:0.00046774587826803327 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.14888274669647217 norm:0.0004572172474581748 max memory_allocated 22563.88232421875 
[2025-02-28 15:36:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.14888112246990204 norm:0.0004489776911213994 max memory_allocated 22563.88232421875 
[2025-02-28 15:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.1488906443119049 norm:0.0004471741267479956 max memory_allocated 22563.88232421875 
[2025-02-28 15:37:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.1488262414932251 norm:0.0004362378967925906 max memory_allocated 22563.88232421875 
[2025-02-28 15:37:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 15:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.19149766862392426 norm:0.003334238426759839 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.17368532717227936 norm:0.0017166630132123828 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.16198457777500153 norm:0.0010593121405690908 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.15702712535858154 norm:0.0007418402237817645 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.1547054946422577 norm:0.0005906149744987488 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.15337036550045013 norm:0.0005207693320699036 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.15267056226730347 norm:0.00048319934285245836 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.15233010053634644 norm:0.00045992128434590995 max memory_allocated 22564.05419921875 
[2025-02-28 15:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.1521148681640625 norm:0.00044120129314251244 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.15194696187973022 norm:0.0004235210071783513 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.15179534256458282 norm:0.0004200615221634507 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.15170562267303467 norm:0.00040077182347886264 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.151621013879776 norm:0.00039401056710630655 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.1515294909477234 norm:0.000395238574128598 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.15146273374557495 norm:0.00039359749644063413 max memory_allocated 22564.05419921875 
[2025-02-28 15:46:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.1514269858598709 norm:0.00039114977698773146 max memory_allocated 22564.05419921875 
[2025-02-28 15:47:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.15137600898742676 norm:0.00039168805233202875 max memory_allocated 22564.05419921875 
[2025-02-28 15:47:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.1513814777135849 norm:0.00039245825610123575 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:07 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.1513485163450241 norm:0.0003966293588746339 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.15132977068424225 norm:0.0003916184068657458 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 15:49:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.1864633858203888 norm:0.006134107708930969 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.1677151769399643 norm:0.0022425504866987467 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.1566638946533203 norm:0.0011684657074511051 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.15246497094631195 norm:0.0008626034250482917 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.15027505159378052 norm:0.0006763698766008019 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.14896829426288605 norm:0.0005748675321228802 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.14812862873077393 norm:0.0005300720222294331 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.14764225482940674 norm:0.0004906092071905732 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.14736804366111755 norm:0.0004667015455197543 max memory_allocated 22564.22607421875 
[2025-02-28 15:54:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.14714638888835907 norm:0.0004394986608531326 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.14700578153133392 norm:0.0004212910425849259 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.1469028741121292 norm:0.0004157933872193098 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.14679910242557526 norm:0.0004049140843562782 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.1467515230178833 norm:0.00039817404467612505 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.14674095809459686 norm:0.0003966577351093292 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.14672571420669556 norm:0.0003845309838652611 max memory_allocated 22564.22607421875 
[2025-02-28 15:58:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.1466459482908249 norm:0.0003771878546103835 max memory_allocated 22564.22607421875 
[2025-02-28 15:58:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.14660508930683136 norm:0.0003724982379935682 max memory_allocated 22564.22607421875 
[2025-02-28 15:59:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.14660581946372986 norm:0.0003701964160427451 max memory_allocated 22564.22607421875 
[2025-02-28 16:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.146621435880661 norm:0.0003743276174645871 max memory_allocated 22564.22607421875 
[2025-02-28 16:00:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 16:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.17733491957187653 norm:0.0026949597522616386 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.16320237517356873 norm:0.0012048068456351757 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.15418492257595062 norm:0.0007020702469162643 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.15044398605823517 norm:0.0005133987287990749 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.1486542969942093 norm:0.000432700093369931 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.14772668480873108 norm:0.0003892892273142934 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.14715923368930817 norm:0.00035921871312893927 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.14686739444732666 norm:0.00034373532980680466 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.1466565579175949 norm:0.00033777483622543514 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.14653435349464417 norm:0.0003364338190294802 max memory_allocated 22564.39794921875 
[2025-02-28 16:06:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.1464282125234604 norm:0.0003293142654001713 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.14632746577262878 norm:0.00032604060834273696 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.14623786509037018 norm:0.00032267411006614566 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.146197110414505 norm:0.00032230879878625274 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.14618359506130219 norm:0.00032159441616386175 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.14615553617477417 norm:0.000322613661410287 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.14612245559692383 norm:0.0003189365961588919 max memory_allocated 22564.39794921875 
[2025-02-28 16:10:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.14610563218593597 norm:0.00032026434200815856 max memory_allocated 22564.39794921875 
[2025-02-28 16:10:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.14608187973499298 norm:0.000321558938594535 max memory_allocated 22564.39794921875 
[2025-02-28 16:11:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.14607630670070648 norm:0.00031777124968357384 max memory_allocated 22564.39794921875 
[2025-02-28 16:11:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 16:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.1812807023525238 norm:0.004581731744110584 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.16310200095176697 norm:0.0016815938288345933 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.15168647468090057 norm:0.0008477407391183078 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.14766119420528412 norm:0.0005885029677301645 max memory_allocated 22564.56982421875 
[2025-02-28 16:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.1457427591085434 norm:0.00047915102913975716 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.14474044740200043 norm:0.0004236610548105091 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.14419828355312347 norm:0.0003870546934194863 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.14381545782089233 norm:0.00036980374716222286 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.14357388019561768 norm:0.0003505962959025055 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.1434277892112732 norm:0.00033812428591772914 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.14330542087554932 norm:0.0003390614874660969 max memory_allocated 22564.56982421875 
[2025-02-28 16:18:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.14321069419384003 norm:0.00033384794369339943 max memory_allocated 22564.56982421875 
[2025-02-28 16:18:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.14313988387584686 norm:0.00032988909515552223 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.1430533230304718 norm:0.00032057228963822126 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.14300906658172607 norm:0.0003167477552779019 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.14299729466438293 norm:0.0003141136548947543 max memory_allocated 22564.56982421875 
[2025-02-28 16:21:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.14295421540737152 norm:0.0003092663537245244 max memory_allocated 22564.56982421875 
[2025-02-28 16:21:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.1429480016231537 norm:0.0003119255125056952 max memory_allocated 22564.56982421875 
[2025-02-28 16:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.14289337396621704 norm:0.0003116207371931523 max memory_allocated 22564.56982421875 
[2025-02-28 16:22:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.14290200173854828 norm:0.0003146863600704819 max memory_allocated 22564.56982421875 
[2025-02-28 16:23:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 16:23:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.21981310844421387 norm:0.025307275354862213 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.18597403168678284 norm:0.010719369165599346 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.1596640646457672 norm:0.0038512253668159246 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.15039649605751038 norm:0.001535345334559679 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.14755338430404663 norm:0.0010984594700857997 max memory_allocated 22564.74169921875 
[2025-02-28 16:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.14593163132667542 norm:0.00092631223378703 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.14490079879760742 norm:0.0008324081427417696 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.14423926174640656 norm:0.0007838942692615092 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.1437918096780777 norm:0.0007536578923463821 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.14350847899913788 norm:0.0007356797577813268 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.14321573078632355 norm:0.0006592454155907035 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.14298106729984283 norm:0.0006149320979602635 max memory_allocated 22564.74169921875 
[2025-02-28 16:30:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.14274682104587555 norm:0.000578763079829514 max memory_allocated 22564.74169921875 
[2025-02-28 16:30:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.14259247481822968 norm:0.0005558992270380259 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.14245639741420746 norm:0.0005421754904091358 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.14234773814678192 norm:0.0005190489464439452 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.14222154021263123 norm:0.0004831041151192039 max memory_allocated 22564.74169921875 
[2025-02-28 16:33:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.1421811580657959 norm:0.00046873564133420587 max memory_allocated 22564.74169921875 
[2025-02-28 16:33:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.14213570952415466 norm:0.000458813039585948 max memory_allocated 22564.74169921875 
[2025-02-28 16:34:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.14204727113246918 norm:0.0004312364908400923 max memory_allocated 22564.74169921875 
[2025-02-28 16:34:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 16:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.1707465499639511 norm:0.005992854945361614 max memory_allocated 22564.91357421875 
[2025-02-28 16:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.15863290429115295 norm:0.0022485991939902306 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.14935703575611115 norm:0.0008303020149469376 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.14642849564552307 norm:0.0005156488041393459 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.1449941098690033 norm:0.00047293779789470136 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.14407603442668915 norm:0.0004284661845304072 max memory_allocated 22564.91357421875 
[2025-02-28 16:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.14352752268314362 norm:0.00038561687688343227 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.14315764605998993 norm:0.00035103046684525907 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.1429789662361145 norm:0.00033522385638207197 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.14283592998981476 norm:0.0003253890899941325 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.1426699161529541 norm:0.000309283088427037 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.14254121482372284 norm:0.0002950167690869421 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.14243322610855103 norm:0.00027860034606419504 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.14241889119148254 norm:0.0002798174391500652 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.14239385724067688 norm:0.00027210349799133837 max memory_allocated 22564.91357421875 
[2025-02-28 16:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.1423541009426117 norm:0.00027268618578091264 max memory_allocated 22564.91357421875 
[2025-02-28 16:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.14231276512145996 norm:0.00026642673765309155 max memory_allocated 22564.91357421875 
[2025-02-28 16:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.14231249690055847 norm:0.00026095713838003576 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.14228907227516174 norm:0.0002593408280517906 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.14224344491958618 norm:0.0002631423412822187 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 16:46:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.18352754414081573 norm:0.008293043822050095 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.16966524720191956 norm:0.003457257989794016 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.15777310729026794 norm:0.0013515152968466282 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.15417788922786713 norm:0.0007959838840179145 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.15249867737293243 norm:0.0006219246424734592 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.15150801837444305 norm:0.0005558004486374557 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.15091100335121155 norm:0.0005274114082567394 max memory_allocated 22565.08544921875 
[2025-02-28 16:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.15059641003608704 norm:0.00048400022205896676 max memory_allocated 22565.08544921875 
[2025-02-28 16:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.15045984089374542 norm:0.00044994341442361474 max memory_allocated 22565.08544921875 
[2025-02-28 16:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.15034054219722748 norm:0.0004244785523042083 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.1502002477645874 norm:0.00040534595609642565 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.15013054013252258 norm:0.00039886755985207856 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.1500401347875595 norm:0.0003773337812162936 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.15004011988639832 norm:0.00037103297654539347 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.15008677542209625 norm:0.00033548843930475414 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.15005767345428467 norm:0.00031135143944993615 max memory_allocated 22565.08544921875 
[2025-02-28 16:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.14997811615467072 norm:0.00031005527125671506 max memory_allocated 22565.08544921875 
[2025-02-28 16:56:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.1498742699623108 norm:0.00031018260051496327 max memory_allocated 22565.08544921875 
[2025-02-28 16:56:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.14986519515514374 norm:0.0003036397392861545 max memory_allocated 22565.08544921875 
[2025-02-28 16:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.14981961250305176 norm:0.00029958257800899446 max memory_allocated 22565.08544921875 
[2025-02-28 16:57:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 16:57:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.18777358531951904 norm:0.005285977385938168 max memory_allocated 22565.25732421875 
[2025-02-28 16:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.17711029946804047 norm:0.002381236059591174 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.1664380580186844 norm:0.0009150463156402111 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.16355523467063904 norm:0.0005583122838288546 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.1621362417936325 norm:0.00046643606037832797 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.161277636885643 norm:0.00041537711513228714 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.1608498990535736 norm:0.00038160322583280504 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.1606321930885315 norm:0.000334192649461329 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.16050267219543457 norm:0.0003061588213313371 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.16031815111637115 norm:0.0003112168051302433 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.16019539535045624 norm:0.0003016532282344997 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.16016104817390442 norm:0.0002974426024593413 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.16003954410552979 norm:0.00027990457601845264 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.15992218255996704 norm:0.00026854476891458035 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.1598690152168274 norm:0.00026456607156433165 max memory_allocated 22565.25732421875 
[2025-02-28 17:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.15983586013317108 norm:0.000261374021647498 max memory_allocated 22565.25732421875 
[2025-02-28 17:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.1598404347896576 norm:0.00025413857656531036 max memory_allocated 22565.25732421875 
[2025-02-28 17:07:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.15980862081050873 norm:0.00024289707653224468 max memory_allocated 22565.25732421875 
[2025-02-28 17:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.15971088409423828 norm:0.0002400483499513939 max memory_allocated 22565.25732421875 
[2025-02-28 17:08:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.15971463918685913 norm:0.0002390642766840756 max memory_allocated 22565.25732421875 
[2025-02-28 17:08:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 17:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.2015131115913391 norm:0.006073448807001114 max memory_allocated 22565.42919921875 
[2025-02-28 17:09:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.19069434702396393 norm:0.002866156864911318 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.18118424713611603 norm:0.001052522799000144 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.1780320107936859 norm:0.0006267870776355267 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.17657405138015747 norm:0.000550777418538928 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.1756579875946045 norm:0.0004928245907649398 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.17514826357364655 norm:0.00044979830272495747 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.17477181553840637 norm:0.0004167926963418722 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.17448347806930542 norm:0.00038144434802234173 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.17427471280097961 norm:0.0003654808097053319 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.17403222620487213 norm:0.00034473123378120363 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.17386838793754578 norm:0.00032794784056022763 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.1738261878490448 norm:0.00032197008840739727 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.17366044223308563 norm:0.0003055429842788726 max memory_allocated 22565.42919921875 
[2025-02-28 17:17:09 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.1736118346452713 norm:0.00029896406340412796 max memory_allocated 22565.42919921875 
[2025-02-28 17:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.17355291545391083 norm:0.0002958378754556179 max memory_allocated 22565.42919921875 
[2025-02-28 17:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.17351460456848145 norm:0.00028811939409933984 max memory_allocated 22565.42919921875 
[2025-02-28 17:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.1735149621963501 norm:0.00029312228434719145 max memory_allocated 22565.42919921875 
[2025-02-28 17:19:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.17343828082084656 norm:0.0002855816564988345 max memory_allocated 22565.42919921875 
[2025-02-28 17:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.17342545092105865 norm:0.0002834032929968089 max memory_allocated 22565.42919921875 
[2025-02-28 17:20:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 17:20:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.21354234218597412 norm:0.0049706073477864265 max memory_allocated 22565.60107421875 
[2025-02-28 17:21:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.20305323600769043 norm:0.0017762737115845084 max memory_allocated 22565.60107421875 
[2025-02-28 17:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.19517919421195984 norm:0.0006902466411702335 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.19284048676490784 norm:0.000457815476693213 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.19153183698654175 norm:0.0004102826351299882 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.19068922102451324 norm:0.0003954323474317789 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.1902811974287033 norm:0.0003816534881480038 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.19012504816055298 norm:0.0003527129883877933 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.18998709321022034 norm:0.00033253207220695913 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.18988025188446045 norm:0.0003102914779447019 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.1898401975631714 norm:0.00028762585134245455 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.189753919839859 norm:0.0002857593062799424 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.18971092998981476 norm:0.0002642924664542079 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.18961501121520996 norm:0.00025232761981897056 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.18954983353614807 norm:0.00023804299416951835 max memory_allocated 22565.60107421875 
[2025-02-28 17:29:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.18953144550323486 norm:0.0002380051591899246 max memory_allocated 22565.60107421875 
[2025-02-28 17:29:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.1895090788602829 norm:0.00023006349510978907 max memory_allocated 22565.60107421875 
[2025-02-28 17:30:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.18948043882846832 norm:0.00023034802870824933 max memory_allocated 22565.60107421875 
[2025-02-28 17:30:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.1894838809967041 norm:0.00022308288316708058 max memory_allocated 22565.60107421875 
[2025-02-28 17:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.18950998783111572 norm:0.0002206104836659506 max memory_allocated 22565.60107421875 
[2025-02-28 17:31:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 17:32:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.2387835532426834 norm:0.00333414226770401 max memory_allocated 22565.77294921875 
[2025-02-28 17:32:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.22865967452526093 norm:0.0011090525658801198 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.22089962661266327 norm:0.0005880716489627957 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.21815072000026703 norm:0.00047840047045610845 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.2167419046163559 norm:0.0004276334075257182 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.2159353792667389 norm:0.000409449334256351 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.2155512571334839 norm:0.00043154245940968394 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.21529620885849 norm:0.0003815564850810915 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.21507999300956726 norm:0.0003973703715018928 max memory_allocated 22565.77294921875 
[2025-02-28 17:37:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.21499216556549072 norm:0.0004120881203562021 max memory_allocated 22565.77294921875 
[2025-02-28 17:37:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.21486949920654297 norm:0.00036987740895710886 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.21467752754688263 norm:0.0003536980366334319 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.2146129459142685 norm:0.0003618638147599995 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:24 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.2145364135503769 norm:0.00037797188269905746 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.21452626585960388 norm:0.0003475459525361657 max memory_allocated 22565.77294921875 
[2025-02-28 17:40:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.21447110176086426 norm:0.00037434848491102457 max memory_allocated 22565.77294921875 
[2025-02-28 17:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.21445518732070923 norm:0.0003823808510787785 max memory_allocated 22565.77294921875 
[2025-02-28 17:41:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.2143120914697647 norm:0.00037100428016856313 max memory_allocated 22565.77294921875 
[2025-02-28 17:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.21432392299175262 norm:0.00036904396256431937 max memory_allocated 22565.77294921875 
[2025-02-28 17:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.21432101726531982 norm:0.00039823443512432277 max memory_allocated 22565.77294921875 
[2025-02-28 17:42:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 17:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.2612780034542084 norm:0.0029103606939315796 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.2522939443588257 norm:0.0014681699685752392 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.24451394379138947 norm:0.0007834946736693382 max memory_allocated 22565.94482421875 
[2025-02-28 17:45:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.2419944405555725 norm:0.0005543410661630332 max memory_allocated 22565.94482421875 
[2025-02-28 17:45:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.24048283696174622 norm:0.0004550432786345482 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.23973381519317627 norm:0.0003882948658429086 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.23940248787403107 norm:0.0003442481975071132 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.23926526308059692 norm:0.00031255773501470685 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.23910574615001678 norm:0.0002889801689889282 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.2389909327030182 norm:0.0002682058257050812 max memory_allocated 22565.94482421875 
[2025-02-28 17:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.23886454105377197 norm:0.000258804764598608 max memory_allocated 22565.94482421875 
[2025-02-28 17:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.2387869656085968 norm:0.000244928669417277 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.23871809244155884 norm:0.0002376596676185727 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.23865199089050293 norm:0.00022627608268521726 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.23857823014259338 norm:0.00022720771085005254 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.2384985089302063 norm:0.0002262390189571306 max memory_allocated 22565.94482421875 
[2025-02-28 17:52:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.23845940828323364 norm:0.00022454795544035733 max memory_allocated 22565.94482421875 
[2025-02-28 17:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.238388791680336 norm:0.00022448480012826622 max memory_allocated 22565.94482421875 
[2025-02-28 17:53:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.2383383959531784 norm:0.00022606132552027702 max memory_allocated 22565.94482421875 
[2025-02-28 17:54:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.23837383091449738 norm:0.0002232477709185332 max memory_allocated 22565.94482421875 
[2025-02-28 17:54:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 17:54:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.29480645060539246 norm:0.004452903755009174 max memory_allocated 22566.11669921875 
[2025-02-28 17:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.28302931785583496 norm:0.0013951591681689024 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.27418217062950134 norm:0.0006979599129408598 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.2711697220802307 norm:0.0004722638404928148 max memory_allocated 22566.11669921875 
[2025-02-28 17:57:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.2695558965206146 norm:0.00041105004493147135 max memory_allocated 22566.11669921875 
[2025-02-28 17:57:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.26877203583717346 norm:0.00040417263517156243 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.268362820148468 norm:0.00036410463508218527 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.26808077096939087 norm:0.00033972476376220584 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.2679150104522705 norm:0.000327808695146814 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.26777705550193787 norm:0.0003365584125276655 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.26764652132987976 norm:0.000332791794789955 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.26754045486450195 norm:0.0003353410284034908 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.2674857974052429 norm:0.000338489975547418 max memory_allocated 22566.11669921875 
[2025-02-28 18:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.2674276828765869 norm:0.0003352576168254018 max memory_allocated 22566.11669921875 
[2025-02-28 18:02:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.26737499237060547 norm:0.0003368071629665792 max memory_allocated 22566.11669921875 
[2025-02-28 18:03:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.267291784286499 norm:0.00033374098711647093 max memory_allocated 22566.11669921875 
[2025-02-28 18:03:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.26723048090934753 norm:0.00033980776788666844 max memory_allocated 22566.11669921875 
[2025-02-28 18:04:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.26717379689216614 norm:0.00034284472349099815 max memory_allocated 22566.11669921875 
[2025-02-28 18:05:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.2670958340167999 norm:0.00035240690340287983 max memory_allocated 22566.11669921875 
[2025-02-28 18:05:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.26707524061203003 norm:0.0003568441024981439 max memory_allocated 22566.11669921875 
[2025-02-28 18:05:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 18:06:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.33192771673202515 norm:0.0034414129331707954 max memory_allocated 22566.28857421875 
[2025-02-28 18:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.32098188996315 norm:0.0018465920584276319 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.310639351606369 norm:0.0009423364535905421 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.3070041835308075 norm:0.0006490347441285849 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.30504465103149414 norm:0.0006163267535157502 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.30401545763015747 norm:0.0004909068811684847 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.3035845458507538 norm:0.00045913405483588576 max memory_allocated 22566.28857421875 
[2025-02-28 18:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.3034193217754364 norm:0.0004312890232540667 max memory_allocated 22566.28857421875 
[2025-02-28 18:10:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.3032858073711395 norm:0.00039762488449923694 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.30313974618911743 norm:0.00037737726233899593 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.30306491255760193 norm:0.0003774737997446209 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.3028164505958557 norm:0.000370834837667644 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.3027925193309784 norm:0.0003556855663191527 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.30273398756980896 norm:0.0003601243661250919 max memory_allocated 22566.28857421875 
[2025-02-28 18:14:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.3027332127094269 norm:0.0003521429025568068 max memory_allocated 22566.28857421875 
[2025-02-28 18:14:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.30266350507736206 norm:0.0003419588610995561 max memory_allocated 22566.28857421875 
[2025-02-28 18:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.3027569651603699 norm:0.0003364698204677552 max memory_allocated 22566.28857421875 
[2025-02-28 18:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.30271559953689575 norm:0.0003321743570268154 max memory_allocated 22566.28857421875 
[2025-02-28 18:16:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.30268174409866333 norm:0.0003252025635447353 max memory_allocated 22566.28857421875 
[2025-02-28 18:17:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.3026731610298157 norm:0.0003189881390426308 max memory_allocated 22566.28857421875 
[2025-02-28 18:17:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 18:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.37689438462257385 norm:0.006332142744213343 max memory_allocated 22566.46044921875 
[2025-02-28 18:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.3630913197994232 norm:0.003107690252363682 max memory_allocated 22566.46044921875 
[2025-02-28 18:18:54 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.35065963864326477 norm:0.0012651857687160373 max memory_allocated 22566.46044921875 
[2025-02-28 18:19:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.3461242616176605 norm:0.0007116602500900626 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.34418654441833496 norm:0.0005655179265886545 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.3433470129966736 norm:0.0005137462285347283 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.3427392840385437 norm:0.0004692711809184402 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.3422601819038391 norm:0.0004248635668773204 max memory_allocated 22566.46044921875 
[2025-02-28 18:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.341957151889801 norm:0.00040456114220432937 max memory_allocated 22566.46044921875 
[2025-02-28 18:22:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.34172511100769043 norm:0.00038706042687408626 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.3414744436740875 norm:0.000379279168555513 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.34131595492362976 norm:0.0003716100472956896 max memory_allocated 22566.46044921875 
[2025-02-28 18:24:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.3412625789642334 norm:0.000387170584872365 max memory_allocated 22566.46044921875 
[2025-02-28 18:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.3411405682563782 norm:0.00038485959521494806 max memory_allocated 22566.46044921875 
[2025-02-28 18:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.3410319685935974 norm:0.00038797882734797895 max memory_allocated 22566.46044921875 
[2025-02-28 18:26:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.3409460484981537 norm:0.0003722658730112016 max memory_allocated 22566.46044921875 
[2025-02-28 18:26:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.34088489413261414 norm:0.0003771415213122964 max memory_allocated 22566.46044921875 
[2025-02-28 18:27:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.3407520353794098 norm:0.00037700479151681066 max memory_allocated 22566.46044921875 
[2025-02-28 18:27:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.3407336473464966 norm:0.0003776822122745216 max memory_allocated 22566.46044921875 
[2025-02-28 18:28:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.3406641185283661 norm:0.0003723197150975466 max memory_allocated 22566.46044921875 
[2025-02-28 18:28:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 18:29:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.4176877737045288 norm:0.006140590645372868 max memory_allocated 22566.63232421875 
[2025-02-28 18:29:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.40392300486564636 norm:0.002112987684085965 max memory_allocated 22566.63232421875 
[2025-02-28 18:30:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.3919546604156494 norm:0.0007458804757334292 max memory_allocated 22566.63232421875 
[2025-02-28 18:30:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.38808077573776245 norm:0.0005271995905786753 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.38624706864356995 norm:0.0004635956138372421 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.3855192959308624 norm:0.00043232625466771424 max memory_allocated 22566.63232421875 
[2025-02-28 18:32:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.3851367235183716 norm:0.00040228699799627066 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.3848344683647156 norm:0.0003751754411496222 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.3845940828323364 norm:0.00035161766572855413 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.3844594359397888 norm:0.0003383653238415718 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.3843476176261902 norm:0.0003280049713794142 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.3842633068561554 norm:0.0003118565946351737 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.384131520986557 norm:0.00030049082124605775 max memory_allocated 22566.63232421875 
[2025-02-28 18:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.3840375542640686 norm:0.000297203310765326 max memory_allocated 22566.63232421875 
[2025-02-28 18:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.383992999792099 norm:0.00029366000671871006 max memory_allocated 22566.63232421875 
[2025-02-28 18:37:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.3839443325996399 norm:0.0002895510115195066 max memory_allocated 22566.63232421875 
[2025-02-28 18:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.3839174807071686 norm:0.0002914629003498703 max memory_allocated 22566.63232421875 
[2025-02-28 18:38:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.3838992118835449 norm:0.0002922220737673342 max memory_allocated 22566.63232421875 
[2025-02-28 18:39:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.3838551640510559 norm:0.00029504054691642523 max memory_allocated 22566.63232421875 
[2025-02-28 18:39:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.3838560879230499 norm:0.00028847355861216784 max memory_allocated 22566.63232421875 
[2025-02-28 18:40:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 18:40:03 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.47389018535614014 norm:0.019056573510169983 max memory_allocated 22566.91943359375 
[2025-02-28 18:41:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.45945701003074646 norm:0.014569375663995743 max memory_allocated 22566.91943359375 
[2025-02-28 18:41:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.4477272629737854 norm:0.00984932854771614 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.44308561086654663 norm:0.007439178414642811 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.44081586599349976 norm:0.006680822465568781 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.4398404061794281 norm:0.0061098323203623295 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.4392349421977997 norm:0.005601510871201754 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.43879321217536926 norm:0.00531343650072813 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.4384332597255707 norm:0.0048263478092849255 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.43816161155700684 norm:0.0044369325041770935 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.4379115104675293 norm:0.004280576482415199 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.4377453327178955 norm:0.004125861916691065 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.4376041293144226 norm:0.004128425382077694 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.43755578994750977 norm:0.004031425341963768 max memory_allocated 22566.91943359375 
[2025-02-28 18:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.43745070695877075 norm:0.0039005251601338387 max memory_allocated 22566.91943359375 
[2025-02-28 18:49:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.43748939037323 norm:0.0038291860837489367 max memory_allocated 22566.91943359375 
[2025-02-28 18:49:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.4373879134654999 norm:0.0038369514513760805 max memory_allocated 22566.91943359375 
[2025-02-28 18:50:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.4371982216835022 norm:0.003612872678786516 max memory_allocated 22566.91943359375 
[2025-02-28 18:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.4371296763420105 norm:0.003551115747541189 max memory_allocated 22566.91943359375 
[2025-02-28 18:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.4371645748615265 norm:0.0034527741372585297 max memory_allocated 22566.91943359375 
[2025-02-28 18:51:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 18:51:30 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:52:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.5483416318893433 norm:0.01996457576751709 max memory_allocated 22567.09130859375 
[2025-02-28 18:52:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.5254721641540527 norm:0.013654878363013268 max memory_allocated 22567.09130859375 
[2025-02-28 18:53:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.5092687606811523 norm:0.009173755533993244 max memory_allocated 22567.09130859375 
[2025-02-28 18:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.503277063369751 norm:0.007691321894526482 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.5006555318832397 norm:0.006673356983810663 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.49949437379837036 norm:0.005919122137129307 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.4987933039665222 norm:0.005254718009382486 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.49820202589035034 norm:0.004732481203973293 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.4977967441082001 norm:0.004373911302536726 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.4973966181278229 norm:0.004174866247922182 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.4972724914550781 norm:0.0041776252910494804 max memory_allocated 22567.09130859375 
[2025-02-28 18:58:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.4971744120121002 norm:0.004137401469051838 max memory_allocated 22567.09130859375 
[2025-02-28 18:58:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.49692821502685547 norm:0.0038507762365043163 max memory_allocated 22567.09130859375 
[2025-02-28 18:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.4968966245651245 norm:0.0037994906306266785 max memory_allocated 22567.09130859375 
[2025-02-28 18:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.4969245195388794 norm:0.0037765128072351217 max memory_allocated 22567.09130859375 
[2025-02-28 19:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.4968116283416748 norm:0.0036523996386677027 max memory_allocated 22567.09130859375 
[2025-02-28 19:01:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.49672600626945496 norm:0.0034089514520019293 max memory_allocated 22567.09130859375 
[2025-02-28 19:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.496770441532135 norm:0.0033338223583996296 max memory_allocated 22567.09130859375 
[2025-02-28 19:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.49681800603866577 norm:0.0033326419070363045 max memory_allocated 22567.09130859375 
[2025-02-28 19:02:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.4967939555644989 norm:0.003195495344698429 max memory_allocated 22567.09130859375 
[2025-02-28 19:02:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 19:02:56 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:03:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.607905387878418 norm:0.48026344180107117 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:1.6679959297180176 norm:1.0398932695388794 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:1.3385231494903564 norm:0.43037670850753784 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:1.0957790613174438 norm:0.1762281209230423 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:1.0468155145645142 norm:0.11820574849843979 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:1.0279009342193604 norm:0.10415838658809662 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:1.0208266973495483 norm:0.09009144455194473 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:1.0124539136886597 norm:0.14624378085136414 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.9886006116867065 norm:0.07972200214862823 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.9726471900939941 norm:0.07450535148382187 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.9665893912315369 norm:0.07202322036027908 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.9500859975814819 norm:0.06431471556425095 max memory_allocated 22567.26318359375 
[2025-02-28 19:10:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.9450119733810425 norm:0.06558424234390259 max memory_allocated 22567.26318359375 
[2025-02-28 19:10:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.9316567182540894 norm:0.055721454322338104 max memory_allocated 22567.26318359375 
[2025-02-28 19:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.921436607837677 norm:0.05859038233757019 max memory_allocated 22567.26318359375 
[2025-02-28 19:11:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.908366858959198 norm:0.053879380226135254 max memory_allocated 22567.26318359375 
[2025-02-28 19:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.9180483818054199 norm:0.06696087121963501 max memory_allocated 22567.26318359375 
[2025-02-28 19:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.899412214756012 norm:0.052946388721466064 max memory_allocated 22567.26318359375 
[2025-02-28 19:13:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.9095844626426697 norm:0.06290273368358612 max memory_allocated 22567.26318359375 
[2025-02-28 19:14:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.8913521766662598 norm:0.04663385823369026 max memory_allocated 22567.26318359375 
[2025-02-28 19:14:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 19:14:22 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:14:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:1.763221025466919 norm:0.12919357419013977 max memory_allocated 22567.43505859375 
[2025-02-28 19:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:1.6151437759399414 norm:0.08887872844934464 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:1.5033761262893677 norm:0.053672417998313904 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:1.4604928493499756 norm:0.04243047162890434 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:1.43934965133667 norm:0.03452591598033905 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:1.4220318794250488 norm:0.0324828065931797 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:1.4109201431274414 norm:0.030177399516105652 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:1.4042649269104004 norm:0.02603847347199917 max memory_allocated 22567.43505859375 
[2025-02-28 19:19:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:1.3987550735473633 norm:0.024997375905513763 max memory_allocated 22567.43505859375 
[2025-02-28 19:19:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:1.3921377658843994 norm:0.02414407953619957 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:1.3900275230407715 norm:0.021837696433067322 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:1.3858637809753418 norm:0.02162431925535202 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:1.38398015499115 norm:0.02109936624765396 max memory_allocated 22567.43505859375 
[2025-02-28 19:22:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:1.3810667991638184 norm:0.019076604396104813 max memory_allocated 22567.43505859375 
[2025-02-28 19:22:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:1.3792201280593872 norm:0.01828172616660595 max memory_allocated 22567.43505859375 
[2025-02-28 19:23:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:1.3777945041656494 norm:0.017605308443307877 max memory_allocated 22567.43505859375 
[2025-02-28 19:23:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:1.3747819662094116 norm:0.016554830595850945 max memory_allocated 22567.43505859375 
[2025-02-28 19:24:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:1.3739749193191528 norm:0.01566358283162117 max memory_allocated 22567.43505859375 
[2025-02-28 19:25:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:1.3704591989517212 norm:0.017352238297462463 max memory_allocated 22567.43505859375 
[2025-02-28 19:25:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:1.3698639869689941 norm:0.03191119432449341 max memory_allocated 22567.43505859375 
[2025-02-28 19:25:46 root] (main_calib_config2.py 380): INFO 21918.6425716877
[2025-02-28 19:25:51 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 19:27:02 root] (main_calib_config2.py 159): INFO wikitext2 : 6.410024642944336
[2025-02-28 19:27:02 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 19:28:52 root] (main_calib_config2.py 159): INFO c4 : 8.405250549316406
[2025-02-28 21:18:14 root] (main_calib_config2.py 170): INFO {'wikitext2': 6.410024642944336, 'c4': 8.405250549316406, 'results': {'piqa': {'acc': 0.7562568008705114, 'acc_stderr': 0.010017199471500617, 'acc_norm': 0.7535364526659413, 'acc_norm_stderr': 0.010054810789671813}, 'boolq': {'acc': 0.6562691131498471, 'acc_stderr': 0.008306973049593465}, 'hellaswag': {'acc': 0.5283808006373233, 'acc_stderr': 0.004981736689518747, 'acc_norm': 0.6857199761003784, 'acc_norm_stderr': 0.004632797375289768}, 'arc_easy': {'acc': 0.6506734006734006, 'acc_stderr': 0.009782853449399288, 'acc_norm': 0.5054713804713805, 'acc_norm_stderr': 0.01025916922861504}, 'winogrande': {'acc': 0.6069455406471981, 'acc_stderr': 0.013727276249108437}, 'arc_challenge': {'acc': 0.35665529010238906, 'acc_stderr': 0.013998056902620199, 'acc_norm': 0.3848122866894198, 'acc_norm_stderr': 0.014218371065251109}}, 'versions': {'piqa': 0, 'boolq': 1, 'hellaswag': 0, 'arc_easy': 0, 'winogrande': 0, 'arc_challenge': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
