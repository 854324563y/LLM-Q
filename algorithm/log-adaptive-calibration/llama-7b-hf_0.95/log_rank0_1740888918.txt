[2025-03-02 04:15:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.95', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.95.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 04:16:52 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 04:16:52 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.95.pkl
[2025-03-02 04:16:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 04:16:57 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:17:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.0031088695395737886 norm:0.002690092660486698 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.001874260837212205 norm:0.0016375239938497543 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0015919094439595938 norm:0.0015175105072557926 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.001504550687968731 norm:0.00143649079836905 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0014467278961092234 norm:0.001424369285814464 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0013813989935442805 norm:0.0013088081032037735 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0013567015994340181 norm:0.001262114499695599 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.001327704987488687 norm:0.0011379625648260117 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0012987395748496056 norm:0.0010189791209995747 max memory_allocated 22559.10693359375 
[2025-03-02 04:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0012853782391175628 norm:0.0009136587614193559 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0012593193678185344 norm:0.0008232032996602356 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.001243233447894454 norm:0.0007718184497207403 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0012068561045452952 norm:0.0006804789300076663 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0011957616079598665 norm:0.00061737623764202 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001187480054795742 norm:0.0005752405850216746 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0011829185532405972 norm:0.0005445734714157879 max memory_allocated 22559.10693359375 
[2025-03-02 04:26:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.001176358899101615 norm:0.0005034827045165002 max memory_allocated 22559.10693359375 
[2025-03-02 04:27:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.001170051284134388 norm:0.00046955945435911417 max memory_allocated 22559.10693359375 
[2025-03-02 04:27:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0011628781212493777 norm:0.00041757262079045177 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0011596090625971556 norm:0.00041608454193919897 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 04:28:19 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:28:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.013075601309537888 norm:0.014453801326453686 max memory_allocated 22559.27880859375 
[2025-03-02 04:29:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.007108302786946297 norm:0.00884055346250534 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.005804415792226791 norm:0.005277273245155811 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.0053633530624210835 norm:0.00433680135756731 max memory_allocated 22559.27880859375 
[2025-03-02 04:31:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.0051406011916697025 norm:0.003926185425370932 max memory_allocated 22559.27880859375 
[2025-03-02 04:31:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.004958771169185638 norm:0.0034864521585404873 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.0048597571440041065 norm:0.0032191681675612926 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.0047790491953492165 norm:0.0029951566830277443 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.004692653194069862 norm:0.0027297413907945156 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.004605742637068033 norm:0.002501262119039893 max memory_allocated 22559.27880859375 
[2025-03-02 04:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.004589395597577095 norm:0.0022766778711229563 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.004580260254442692 norm:0.0020250079687684774 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.004528909921646118 norm:0.0018106992356479168 max memory_allocated 22559.27880859375 
[2025-03-02 04:36:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.00451483903452754 norm:0.0015939396107569337 max memory_allocated 22559.27880859375 
[2025-03-02 04:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.00448150560259819 norm:0.0014223578618839383 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.0044608754105865955 norm:0.0012107716174796224 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.004457434173673391 norm:0.0010406080400571227 max memory_allocated 22559.27880859375 
[2025-03-02 04:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.004450657404959202 norm:0.0009623878868296742 max memory_allocated 22559.27880859375 
[2025-03-02 04:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004456298425793648 norm:0.0010024880757555366 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.004449703264981508 norm:0.0010652132332324982 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 04:39:42 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:40:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.11810608208179474 norm:0.03388690575957298 max memory_allocated 22559.45068359375 
[2025-03-02 04:40:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.040326885879039764 norm:0.02107471227645874 max memory_allocated 22559.45068359375 
[2025-03-02 04:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.020331036299467087 norm:0.014155340380966663 max memory_allocated 22559.45068359375 
[2025-03-02 04:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.01481284573674202 norm:0.008462516590952873 max memory_allocated 22559.45068359375 
[2025-03-02 04:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.012712517753243446 norm:0.006203690078109503 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.01114384364336729 norm:0.004743290599435568 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.010592147707939148 norm:0.004240807611495256 max memory_allocated 22559.45068359375 
[2025-03-02 04:44:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.01002479251474142 norm:0.0038879113271832466 max memory_allocated 22559.45068359375 
[2025-03-02 04:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.009762312285602093 norm:0.003993789199739695 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.009542999789118767 norm:0.0035988264717161655 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.009383343160152435 norm:0.0036030884366482496 max memory_allocated 22559.45068359375 
[2025-03-02 04:46:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.008951600641012192 norm:0.003456421894952655 max memory_allocated 22559.45068359375 
[2025-03-02 04:46:59 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.008951857686042786 norm:0.003318286966532469 max memory_allocated 22559.45068359375 
[2025-03-02 04:47:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.008791047148406506 norm:0.0030077616684138775 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.008739076554775238 norm:0.0029962370172142982 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.00851430930197239 norm:0.0027542689349502325 max memory_allocated 22559.45068359375 
[2025-03-02 04:49:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.008359065279364586 norm:0.002522818511351943 max memory_allocated 22559.45068359375 
[2025-03-02 04:49:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.00820588693022728 norm:0.0022087227553129196 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.008130984380841255 norm:0.0021531907841563225 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.008148051798343658 norm:0.002046407898887992 max memory_allocated 22559.45068359375 
[2025-03-02 04:51:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:51:40 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.012462189421057701 norm:0.0020436940249055624 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.009895515628159046 norm:0.0008587545016780496 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.009049385786056519 norm:0.00043605503742583096 max memory_allocated 22559.50732421875 
[2025-03-02 04:53:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.00865755695849657 norm:0.0002416422648821026 max memory_allocated 22559.50732421875 
[2025-03-02 04:53:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.008415104821324348 norm:0.00016361812595278025 max memory_allocated 22559.50732421875 
[2025-03-02 04:54:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.008257927373051643 norm:0.00011865586566273123 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.008169787935912609 norm:0.00010463433136465028 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.008147482760250568 norm:9.646487887948751e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.008134884759783745 norm:9.174643491860479e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.008134933188557625 norm:9.317025978816673e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.008125998079776764 norm:9.731944737723097e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.008119509555399418 norm:9.074300032807514e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.008110363967716694 norm:8.530110062565655e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.008109349757432938 norm:9.321248217020184e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:59:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.008103073574602604 norm:8.375980542041361e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.008096244186162949 norm:8.203519246308133e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.008094346150755882 norm:8.174526738002896e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.0081024793908 norm:8.274480933323503e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.008097158744931221 norm:8.521400741301477e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:02:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.008099224418401718 norm:8.544222509954125e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:02:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 05:03:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.01500620786100626 norm:0.001901928917504847 max memory_allocated 22559.67919921875 
[2025-03-02 05:03:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.012190786190330982 norm:0.0008393258904106915 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.01113904733210802 norm:0.00043796427780762315 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.010651732794940472 norm:0.0002438027149764821 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:15 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.010369863361120224 norm:0.00018862629076465964 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.010238682851195335 norm:0.00016327704361174256 max memory_allocated 22559.67919921875 
[2025-03-02 05:06:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.010185782797634602 norm:0.00015820356202311814 max memory_allocated 22559.67919921875 
[2025-03-02 05:06:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.010172612965106964 norm:0.00015696193440817297 max memory_allocated 22559.67919921875 
[2025-03-02 05:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.010155035182833672 norm:0.0001466898829676211 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.010142907500267029 norm:0.0001387043303111568 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.01013389602303505 norm:0.0001165645444416441 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.010130004957318306 norm:0.00013485531962942332 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.010126663371920586 norm:9.76638330030255e-05 max memory_allocated 22559.67919921875 
[2025-03-02 05:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.010128138586878777 norm:0.00014074123464524746 max memory_allocated 22559.67919921875 
[2025-03-02 05:10:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.010121172294020653 norm:0.00011165164323756471 max memory_allocated 22559.67919921875 
[2025-03-02 05:11:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.010113576427102089 norm:0.00011915027425857261 max memory_allocated 22559.67919921875 
[2025-03-02 05:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.010119431652128696 norm:0.00011838367208838463 max memory_allocated 22559.67919921875 
[2025-03-02 05:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.01010696031153202 norm:9.717625653138384e-05 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.010103507898747921 norm:9.540961764287204e-05 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.010101297870278358 norm:9.097427391679958e-05 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 05:14:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.016888737678527832 norm:0.0018975187558680773 max memory_allocated 22559.85107421875 
[2025-03-02 05:14:57 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.013863680884242058 norm:0.0008681084727868438 max memory_allocated 22559.85107421875 
[2025-03-02 05:15:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.012660087086260319 norm:0.00044452809379436076 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.01206656638532877 norm:0.000237881118664518 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.011751463636755943 norm:0.00013733337982557714 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.011594634503126144 norm:9.626743849366903e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.011538559570908546 norm:8.848041034070775e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.01149994507431984 norm:8.478872769046575e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:18:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.01148161105811596 norm:8.511191117577255e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.011461567133665085 norm:8.801569492788985e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.011447980999946594 norm:8.993208030005917e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:20:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.011431679129600525 norm:8.57008490129374e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:21:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.011418981477618217 norm:8.653832628624514e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:21:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.011408313177525997 norm:8.334854646818712e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:22:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.011401616968214512 norm:8.511717896908522e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.011394822038710117 norm:8.37651823530905e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:23:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.01139095053076744 norm:8.355538739124313e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.011394592933356762 norm:8.86710113263689e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.011386102996766567 norm:8.81964951986447e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.011384270153939724 norm:8.818221976980567e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:25:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 05:25:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.016710706055164337 norm:0.0011647411156445742 max memory_allocated 22560.02294921875 
[2025-03-02 05:26:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.01462574116885662 norm:0.00043282692786306143 max memory_allocated 22560.02294921875 
[2025-03-02 05:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.013902071863412857 norm:0.00026641320437192917 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.013520716689527035 norm:0.0001716095139272511 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.013244126923382282 norm:0.00012538775627035648 max memory_allocated 22560.02294921875 
[2025-03-02 05:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.01308930478990078 norm:0.00011403433745726943 max memory_allocated 22560.02294921875 
[2025-03-02 05:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.01301628164947033 norm:9.213668818119913e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.012982561253011227 norm:8.103415893856436e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.012969482690095901 norm:7.80083064455539e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.012959873303771019 norm:8.150433131959289e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.012949438765645027 norm:7.802771870046854e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.012945880182087421 norm:8.038661326281726e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.012946445494890213 norm:8.884769340511411e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.012934617698192596 norm:8.257584704551846e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.012934429571032524 norm:8.068959868978709e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:34:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.012927576899528503 norm:7.534942415077239e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.012928465381264687 norm:7.608300802530721e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.012925868853926659 norm:7.707678014412522e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:35:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.01293034665286541 norm:7.778709550620988e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:36:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.012922893278300762 norm:7.670396735193208e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:36:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 05:37:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.02006603218615055 norm:0.0013982921373099089 max memory_allocated 22560.19482421875 
[2025-03-02 05:37:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.016916770488023758 norm:0.0006029540672898293 max memory_allocated 22560.19482421875 
[2025-03-02 05:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.01594488136470318 norm:0.00035207573091611266 max memory_allocated 22560.19482421875 
[2025-03-02 05:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.015405828133225441 norm:0.00020878377836197615 max memory_allocated 22560.19482421875 
[2025-03-02 05:39:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.015083294361829758 norm:0.00015612506831530482 max memory_allocated 22560.19482421875 
[2025-03-02 05:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.014908719807863235 norm:0.00012372052879072726 max memory_allocated 22560.19482421875 
[2025-03-02 05:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.01480228453874588 norm:0.00011284231732133776 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:00 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.014751369133591652 norm:0.00010542622476350516 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.014719745144248009 norm:9.842404688242823e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:42:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.014684220775961876 norm:9.231859439751133e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:42:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.014679201878607273 norm:8.846151467878371e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:43:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.014655081555247307 norm:8.465957944281399e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:43:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.014635549858212471 norm:8.409217116422951e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.014625655487179756 norm:8.371873991563916e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.014630287885665894 norm:8.804036770015955e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:45:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.014615078456699848 norm:7.996690692380071e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.014620518311858177 norm:8.892383630154654e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.014609099365770817 norm:7.834634016035125e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:47:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.014607536606490612 norm:7.765022746752948e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.01460557896643877 norm:7.6196069130674e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:47:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.019853724166750908 norm:0.001021883450448513 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.017687521874904633 norm:0.0004226496384944767 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.01693749986588955 norm:0.0002255511935800314 max memory_allocated 22560.36669921875 
[2025-03-02 05:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.01653563603758812 norm:0.00016062158101703972 max memory_allocated 22560.36669921875 
[2025-03-02 05:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.01625569723546505 norm:0.00011977208487223834 max memory_allocated 22560.36669921875 
[2025-03-02 05:51:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.016087686643004417 norm:0.00010235818626824766 max memory_allocated 22560.36669921875 
[2025-03-02 05:51:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.01598401553928852 norm:9.089474042411894e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.015945326536893845 norm:8.249882375821471e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.01591864414513111 norm:7.854877912905067e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.015881085768342018 norm:7.317605195567012e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:54:03 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.015873827040195465 norm:7.493179873563349e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.015853695571422577 norm:7.467369141522795e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.015847211703658104 norm:7.239820115501061e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:55:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.015849236398935318 norm:7.307234045583755e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:56:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.01584046520292759 norm:7.325900514842942e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.015834281221032143 norm:7.179569365689531e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.015826761722564697 norm:7.196862861746922e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.015830907970666885 norm:7.363904296653345e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.01583300158381462 norm:7.143996481318027e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.015830975025892258 norm:7.255087257362902e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:59:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 05:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.02423391118645668 norm:0.001442715059965849 max memory_allocated 22560.53857421875 
[2025-03-02 06:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.020385969430208206 norm:0.0005491100018844008 max memory_allocated 22560.53857421875 
[2025-03-02 06:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.01911911368370056 norm:0.0002977655385620892 max memory_allocated 22560.53857421875 
[2025-03-02 06:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.018563631922006607 norm:0.0002130250068148598 max memory_allocated 22560.53857421875 
[2025-03-02 06:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.01820412464439869 norm:0.0001653545186854899 max memory_allocated 22560.53857421875 
[2025-03-02 06:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.01800464279949665 norm:0.00014147689216770232 max memory_allocated 22560.53857421875 
[2025-03-02 06:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.017878370359539986 norm:0.00012762461847160012 max memory_allocated 22560.53857421875 
[2025-03-02 06:03:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.01778635010123253 norm:0.00011715228174580261 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.017726868391036987 norm:0.0001089486904675141 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.017674002796411514 norm:9.613755537429824e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:05:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.017641350626945496 norm:9.195844177156687e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:05:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.017607998102903366 norm:8.473723573843017e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:06:32 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.017597317695617676 norm:8.415714546572417e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:07:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.017575109377503395 norm:7.902372453827411e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.017559843137860298 norm:8.053012425079942e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:08:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.017554782330989838 norm:7.940888463053852e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.017538871616125107 norm:7.486875256290659e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.017526941373944283 norm:7.424764771712944e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.01752575673162937 norm:7.602891855640337e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.017526432871818542 norm:7.597720832563937e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:10:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 06:11:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.023170214146375656 norm:0.0008851906168274581 max memory_allocated 22560.71044921875 
[2025-03-02 06:11:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.020902816206216812 norm:0.00038059166399762034 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.020040636882185936 norm:0.0002366017724853009 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.0195460207760334 norm:0.00016965401300694793 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.019230728968977928 norm:0.00013022846542298794 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.019037611782550812 norm:0.00010994946933351457 max memory_allocated 22560.71044921875 
[2025-03-02 06:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.018916910514235497 norm:9.330143075203523e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.018854275345802307 norm:8.648791845189407e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.018816335126757622 norm:7.896935858298093e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.018779253587126732 norm:7.279731653397903e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.018752720206975937 norm:6.584585935343057e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.018732693046331406 norm:6.498808943433687e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.01871882565319538 norm:6.320563261397183e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:18:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.018710056319832802 norm:6.135178409749642e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.018705636262893677 norm:6.018915883032605e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:19:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.01870729774236679 norm:6.079912418499589e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.01870276965200901 norm:5.9212397900409997e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.01869949884712696 norm:5.989407145534642e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:21:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.018694212660193443 norm:6.0263333580223843e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:21:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.018696218729019165 norm:6.0439670050982386e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:21:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 06:22:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.024184031412005424 norm:0.001057684887200594 max memory_allocated 22560.88232421875 
[2025-03-02 06:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.021705850958824158 norm:0.0004333255346864462 max memory_allocated 22560.88232421875 
[2025-03-02 06:23:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.020803013816475868 norm:0.00026230988441966474 max memory_allocated 22560.88232421875 
[2025-03-02 06:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.020239459350705147 norm:0.00016874488210305572 max memory_allocated 22560.88232421875 
[2025-03-02 06:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.019935164600610733 norm:0.00012967034126631916 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.019753092899918556 norm:0.00011157352128066123 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.019640998914837837 norm:9.56351068452932e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.01957356557250023 norm:8.019773667911068e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.019527379423379898 norm:7.399367314064875e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:27:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.019505087286233902 norm:6.958447920624167e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.01948973722755909 norm:6.559188477694988e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:28:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.01947900280356407 norm:6.702551763737574e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.019468136131763458 norm:6.413856317522004e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.019452685490250587 norm:6.311277684289962e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.019450955092906952 norm:6.360888801282272e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.01945246383547783 norm:6.398784171324223e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.019446352496743202 norm:6.289595330599695e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:32:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.0194406695663929 norm:6.165866216178983e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:32:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.019438453018665314 norm:6.284761911956593e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.019435519352555275 norm:6.323143315967172e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:33:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 06:33:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.024376606568694115 norm:0.0007661597337573767 max memory_allocated 22561.05419921875 
[2025-03-02 06:34:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.022522330284118652 norm:0.00035461271181702614 max memory_allocated 22561.05419921875 
[2025-03-02 06:35:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.021645082160830498 norm:0.00021630007540807128 max memory_allocated 22561.05419921875 
[2025-03-02 06:35:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.02114219218492508 norm:0.00016741931904107332 max memory_allocated 22561.05419921875 
[2025-03-02 06:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.020808126777410507 norm:0.00014186430780682713 max memory_allocated 22561.05419921875 
[2025-03-02 06:36:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.020579693838953972 norm:0.00012011822400381789 max memory_allocated 22561.05419921875 
[2025-03-02 06:37:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.020452037453651428 norm:0.00010719233250711113 max memory_allocated 22561.05419921875 
[2025-03-02 06:37:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.020357055589556694 norm:9.262391540687531e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.02031591720879078 norm:8.258383604697883e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.020286958664655685 norm:7.459937478415668e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:39:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.020248103886842728 norm:6.851738726254553e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:40:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.020215818658471107 norm:6.447418127208948e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:40:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.02020547166466713 norm:6.123714410932735e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:41:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.020203987136483192 norm:6.055244375602342e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:41:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.020197000354528427 norm:5.7310367992613465e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:42:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.02018113248050213 norm:5.5945645726751536e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.0201813243329525 norm:5.460605098051019e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.020173145458102226 norm:5.326624886947684e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:43:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.020168710500001907 norm:5.266902735456824e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:44:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.020165836438536644 norm:5.292734203976579e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:44:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 06:45:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.024670682847499847 norm:0.0006298766820691526 max memory_allocated 22561.22607421875 
[2025-03-02 06:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.023083744570612907 norm:0.000297725317068398 max memory_allocated 22561.22607421875 
[2025-03-02 06:46:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.02240588702261448 norm:0.00019101810175925493 max memory_allocated 22561.22607421875 
[2025-03-02 06:46:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.021950459107756615 norm:0.00014411915617529303 max memory_allocated 22561.22607421875 
[2025-03-02 06:47:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.021623779088258743 norm:0.00011931049084523693 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:05 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.021424217149615288 norm:9.747764124767855e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.021313881501555443 norm:8.401219383813441e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:49:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.021261265501379967 norm:7.860719779273495e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.021234259009361267 norm:7.08210573066026e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:50:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.02120198681950569 norm:6.60038786008954e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.021178385242819786 norm:6.204670353326946e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:51:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.021164579316973686 norm:5.981709546176717e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:51:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.021153001114726067 norm:5.739360494771972e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:52:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.021147971972823143 norm:5.9487123508006334e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.02114589512348175 norm:5.6080869399011135e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:53:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.021144278347492218 norm:5.6399712775601074e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.021142490208148956 norm:5.5369993788190186e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.02113923989236355 norm:5.528998008230701e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:55:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.021132513880729675 norm:5.4830557928653434e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:55:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.021130500361323357 norm:5.4380634537665173e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:56:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.027812842279672623 norm:0.001117021543905139 max memory_allocated 22561.39794921875 
[2025-03-02 06:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.025198113173246384 norm:0.00047671847278252244 max memory_allocated 22561.39794921875 
[2025-03-02 06:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.024199746549129486 norm:0.0002842252142727375 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.023612864315509796 norm:0.0001957342028617859 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.023217957466840744 norm:0.00014992503565736115 max memory_allocated 22561.39794921875 
[2025-03-02 06:59:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.02299691177904606 norm:0.00012666353723034263 max memory_allocated 22561.39794921875 
[2025-03-02 06:59:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.022877903655171394 norm:0.00010920570639427751 max memory_allocated 22561.39794921875 
[2025-03-02 07:00:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.022803034633398056 norm:9.799972031032667e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:01:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.022742070257663727 norm:9.008761844597757e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:01:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.02270430140197277 norm:8.790381252765656e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.022664016112685204 norm:7.797452417435125e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.022630730643868446 norm:7.167427975218743e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.022605374455451965 norm:6.496298010461032e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:03:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.022592736408114433 norm:6.235248292796314e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.022585803642868996 norm:6.15688186371699e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.022570917382836342 norm:6.0729467804776505e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.022567983716726303 norm:5.9501497162273154e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:06:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.022558653727173805 norm:5.790220166090876e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:06:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.022554676979780197 norm:5.8726163842948154e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:07:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.022549984976649284 norm:5.889972089789808e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:07:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 07:08:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.028215250000357628 norm:0.0008000467787496746 max memory_allocated 22561.56982421875 
[2025-03-02 07:08:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.02634154073894024 norm:0.00034754248918034136 max memory_allocated 22561.56982421875 
[2025-03-02 07:09:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.025531165301799774 norm:0.00021079725411254913 max memory_allocated 22561.56982421875 
[2025-03-02 07:09:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.025019008666276932 norm:0.00016108871204778552 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.024610240012407303 norm:0.00012120373139623553 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.02441178262233734 norm:0.00010538479546085 max memory_allocated 22561.56982421875 
[2025-03-02 07:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.02431042492389679 norm:9.14972770260647e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.02426380291581154 norm:8.456104842480272e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.024215092882514 norm:7.585503772133961e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.02417578734457493 norm:6.827453034929931e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:13:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.024148590862751007 norm:6.435564864659682e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:14:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.024132411926984787 norm:6.302926340140402e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.02412714995443821 norm:6.387080065906048e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.024106524884700775 norm:5.973396764602512e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:15:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.02409820631146431 norm:5.807307388749905e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.02409079112112522 norm:5.6436489103361964e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.02408575639128685 norm:5.706385491066612e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:17:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.02407759800553322 norm:5.482671258505434e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.02407856658101082 norm:5.3558003855869174e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.024073846638202667 norm:5.289529508445412e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:18:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 07:19:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.03174813091754913 norm:0.0013895482989028096 max memory_allocated 22561.74169921875 
[2025-03-02 07:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.028933456167578697 norm:0.00043887627543881536 max memory_allocated 22561.74169921875 
[2025-03-02 07:20:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.027985846623778343 norm:0.00025860106688924134 max memory_allocated 22561.74169921875 
[2025-03-02 07:21:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.02739952690899372 norm:0.00019300160056445748 max memory_allocated 22561.74169921875 
[2025-03-02 07:21:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.026965266093611717 norm:0.00015821406850591302 max memory_allocated 22561.74169921875 
[2025-03-02 07:22:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.026789410039782524 norm:0.00014566245954483747 max memory_allocated 22561.74169921875 
[2025-03-02 07:22:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.02665814198553562 norm:0.00011933518544537947 max memory_allocated 22561.74169921875 
[2025-03-02 07:23:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.026587866246700287 norm:0.00011165573232574388 max memory_allocated 22561.74169921875 
[2025-03-02 07:23:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.026519106701016426 norm:9.996465814765543e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.026472436264157295 norm:9.256454359274358e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:24:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.026437969878315926 norm:9.334093920188025e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.02640150673687458 norm:8.399477519560605e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:26:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.026378989219665527 norm:7.761913002468646e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:26:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.026359742507338524 norm:7.333562825806439e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.026350829750299454 norm:6.909572402946651e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:27:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.026325460523366928 norm:6.387180474121124e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:28:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.026309091597795486 norm:6.38639903627336e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:28:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.026312071830034256 norm:6.217234476935118e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:29:26 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.02631252259016037 norm:6.263477553147823e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.026306260377168655 norm:6.145143561298028e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:30:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 07:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.03513672947883606 norm:0.001484591979533434 max memory_allocated 22561.91357421875 
[2025-03-02 07:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.032329440116882324 norm:0.0005583715392276645 max memory_allocated 22561.91357421875 
[2025-03-02 07:31:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.03120022639632225 norm:0.00031299583497457206 max memory_allocated 22561.91357421875 
[2025-03-02 07:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.03046261891722679 norm:0.0002195553097408265 max memory_allocated 22561.91357421875 
[2025-03-02 07:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.03002990409731865 norm:0.00017700275930110365 max memory_allocated 22561.91357421875 
[2025-03-02 07:33:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.029812073335051537 norm:0.00014147433103062212 max memory_allocated 22561.91357421875 
[2025-03-02 07:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.029704153537750244 norm:0.0001239826815435663 max memory_allocated 22561.91357421875 
[2025-03-02 07:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.029644060879945755 norm:0.00010965323599521071 max memory_allocated 22561.91357421875 
[2025-03-02 07:35:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.029599661007523537 norm:0.00010118455247720703 max memory_allocated 22561.91357421875 
[2025-03-02 07:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.02955390140414238 norm:9.314347698818892e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:36:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.02952459454536438 norm:8.622377208666876e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:36:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.029491106048226357 norm:7.988576544448733e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:37:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.029475096613168716 norm:7.720084977336228e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.02945161983370781 norm:7.463607471436262e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.029439060017466545 norm:7.218385871965438e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.02942451648414135 norm:7.029464177321643e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.029410136863589287 norm:6.788384052924812e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:40:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.029409540817141533 norm:6.585301889572293e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:40:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.029415734112262726 norm:6.60372170386836e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.02941187471151352 norm:6.68202992528677e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:41:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 07:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.037655308842659 norm:0.0008364033419638872 max memory_allocated 22562.08544921875 
[2025-03-02 07:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.03592826426029205 norm:0.00032485410338267684 max memory_allocated 22562.08544921875 
[2025-03-02 07:43:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.03513116389513016 norm:0.0002134723326889798 max memory_allocated 22562.08544921875 
[2025-03-02 07:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.03443167358636856 norm:0.00015939769218675792 max memory_allocated 22562.08544921875 
[2025-03-02 07:44:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.0340164378285408 norm:0.00012506662460509688 max memory_allocated 22562.08544921875 
[2025-03-02 07:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.03388102352619171 norm:0.00011197252752026543 max memory_allocated 22562.08544921875 
[2025-03-02 07:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.03379172831773758 norm:0.00010453843424329534 max memory_allocated 22562.08544921875 
[2025-03-02 07:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.03373512998223305 norm:9.519400191493332e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:46:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.03368597477674484 norm:8.502198761561885e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.03363523632287979 norm:7.687009201617911e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.033608317375183105 norm:7.172092591645196e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.03358734771609306 norm:6.913417018949986e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.03357766941189766 norm:6.484138430096209e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:49:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.033574361354112625 norm:6.39376012259163e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.03356742486357689 norm:6.342663982650265e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.03355436027050018 norm:6.159797339932993e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.033545996993780136 norm:6.135175499366596e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.033529847860336304 norm:6.135284638730809e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:52:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.033526308834552765 norm:6.109249079599977e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:52:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.033522892743349075 norm:6.080864113755524e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:52:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.043632134795188904 norm:0.0012631232384592295 max memory_allocated 22562.25732421875 
[2025-03-02 07:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.04148229584097862 norm:0.0004209702310618013 max memory_allocated 22562.25732421875 
[2025-03-02 07:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.04057109355926514 norm:0.0002535694802645594 max memory_allocated 22562.25732421875 
[2025-03-02 07:55:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.039834801107645035 norm:0.00018459255807101727 max memory_allocated 22562.25732421875 
[2025-03-02 07:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.039440564811229706 norm:0.00015581636398565024 max memory_allocated 22562.25732421875 
[2025-03-02 07:56:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.039290234446525574 norm:0.00013502857473213226 max memory_allocated 22562.25732421875 
[2025-03-02 07:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.03921501338481903 norm:0.00011897890362888575 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.03914700448513031 norm:0.00010873529390664771 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.03910890221595764 norm:0.00010171144094783813 max memory_allocated 22562.25732421875 
[2025-03-02 07:58:29 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.03907759487628937 norm:9.290975867770612e-05 max memory_allocated 22562.25732421875 
[2025-03-02 07:59:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.03904210403561592 norm:8.122518920572475e-05 max memory_allocated 22562.25732421875 
[2025-03-02 07:59:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.039009612053632736 norm:7.600204844493419e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:00:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.03899035230278969 norm:7.428869139403105e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:00:43 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.038976073265075684 norm:7.208788156276569e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.03896361589431763 norm:6.993455463089049e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.03894367069005966 norm:6.739364471286535e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.03893531486392021 norm:6.899231084389612e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.038938187062740326 norm:6.66039704810828e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:03:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.038935910910367966 norm:6.689723522868007e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:04:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.03894026204943657 norm:6.634285091422498e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:04:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 08:04:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.053930096328258514 norm:0.0030379830859601498 max memory_allocated 22562.42919921875 
[2025-03-02 08:05:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.049873072654008865 norm:0.0008774902671575546 max memory_allocated 22562.42919921875 
[2025-03-02 08:05:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.04843636229634285 norm:0.0004257546679582447 max memory_allocated 22562.42919921875 
[2025-03-02 08:06:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.04745357111096382 norm:0.00030300760408863425 max memory_allocated 22562.42919921875 
[2025-03-02 08:07:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.04702894762158394 norm:0.00024329093866981566 max memory_allocated 22562.42919921875 
[2025-03-02 08:07:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.04685516282916069 norm:0.0002425113198114559 max memory_allocated 22562.42919921875 
[2025-03-02 08:08:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.04671488329768181 norm:0.00020106254669371992 max memory_allocated 22562.42919921875 
[2025-03-02 08:08:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.046630989760160446 norm:0.00018703720706980675 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.04654562100768089 norm:0.0001622713461983949 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.04648265987634659 norm:0.00015041648293845356 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.046422336250543594 norm:0.00014147826004773378 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.04638205096125603 norm:0.0001240413694176823 max memory_allocated 22562.42919921875 
[2025-03-02 08:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.0463557168841362 norm:0.00011890703899553046 max memory_allocated 22562.42919921875 
[2025-03-02 08:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.04633099585771561 norm:0.0001084733521565795 max memory_allocated 22562.42919921875 
[2025-03-02 08:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.04630269482731819 norm:0.00010136856144526973 max memory_allocated 22562.42919921875 
[2025-03-02 08:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.04629427194595337 norm:9.717744978843257e-05 max memory_allocated 22562.42919921875 
[2025-03-02 08:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.04629224166274071 norm:9.890564979286864e-05 max memory_allocated 22562.42919921875 
[2025-03-02 08:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.04627970606088638 norm:9.14807096705772e-05 max memory_allocated 22562.42919921875 
[2025-03-02 08:14:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.04625573009252548 norm:9.005420724861324e-05 max memory_allocated 22562.42919921875 
[2025-03-02 08:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.04625403508543968 norm:8.72648524818942e-05 max memory_allocated 22562.42919921875 
[2025-03-02 08:15:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 08:16:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.060566384345293045 norm:0.0017251144163310528 max memory_allocated 22562.60107421875 
[2025-03-02 08:16:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.05813247710466385 norm:0.00048262381460517645 max memory_allocated 22562.60107421875 
[2025-03-02 08:17:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.05702696368098259 norm:0.00029393014847300947 max memory_allocated 22562.60107421875 
[2025-03-02 08:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.05609454959630966 norm:0.00024597247829660773 max memory_allocated 22562.60107421875 
[2025-03-02 08:18:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.05570031702518463 norm:0.0002131811634171754 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.05552608519792557 norm:0.00018627314420882612 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.05542530119419098 norm:0.00017108322936110198 max memory_allocated 22562.60107421875 
[2025-03-02 08:20:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.05531701445579529 norm:0.00016092108853626996 max memory_allocated 22562.60107421875 
[2025-03-02 08:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.055242106318473816 norm:0.00014687770453747362 max memory_allocated 22562.60107421875 
[2025-03-02 08:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.05517955124378204 norm:0.00012748005974572152 max memory_allocated 22562.60107421875 
[2025-03-02 08:21:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.05512283369898796 norm:0.00012178336328361183 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.05507596582174301 norm:0.00011588543566176668 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.05505184829235077 norm:0.00010743844177341089 max memory_allocated 22562.60107421875 
[2025-03-02 08:23:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.055021923035383224 norm:0.00011030396854039282 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.054999496787786484 norm:0.00010000403563026339 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.0549766905605793 norm:9.57136508077383e-05 max memory_allocated 22562.60107421875 
[2025-03-02 08:25:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.0549660250544548 norm:9.048501669894904e-05 max memory_allocated 22562.60107421875 
[2025-03-02 08:25:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.05495463311672211 norm:9.158406464848667e-05 max memory_allocated 22562.60107421875 
[2025-03-02 08:26:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.054946377873420715 norm:9.032188972923905e-05 max memory_allocated 22562.60107421875 
[2025-03-02 08:26:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.05493757873773575 norm:9.293869516113773e-05 max memory_allocated 22562.60107421875 
[2025-03-02 08:26:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 08:27:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.07047030329704285 norm:0.0014469008892774582 max memory_allocated 22562.77294921875 
[2025-03-02 08:28:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.06808049976825714 norm:0.0006214146851561964 max memory_allocated 22562.77294921875 
[2025-03-02 08:28:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.06673964858055115 norm:0.00039425556315109134 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.06571896374225616 norm:0.0002878295199479908 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.06537029147148132 norm:0.00022354691463988274 max memory_allocated 22562.77294921875 
[2025-03-02 08:30:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.06521910429000854 norm:0.00018266827100887895 max memory_allocated 22562.77294921875 
[2025-03-02 08:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.0651158019900322 norm:0.00016142422100529075 max memory_allocated 22562.77294921875 
[2025-03-02 08:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.06502977013587952 norm:0.00014364722301252186 max memory_allocated 22562.77294921875 
[2025-03-02 08:32:02 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.06501750648021698 norm:0.0001328062789980322 max memory_allocated 22562.77294921875 
[2025-03-02 08:32:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.06494513154029846 norm:0.00012326586875133216 max memory_allocated 22562.77294921875 
[2025-03-02 08:33:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.0649011880159378 norm:0.00011527824972290546 max memory_allocated 22562.77294921875 
[2025-03-02 08:33:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.06489014625549316 norm:0.00011051991896238178 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.06487911939620972 norm:0.00010904814553214237 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.06484899669885635 norm:0.00010628322343109176 max memory_allocated 22562.77294921875 
[2025-03-02 08:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.06482462584972382 norm:0.00010510793799767271 max memory_allocated 22562.77294921875 
[2025-03-02 08:35:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.06480339169502258 norm:0.00010412713891128078 max memory_allocated 22562.77294921875 
[2025-03-02 08:36:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.06479058414697647 norm:0.00010254586959490553 max memory_allocated 22562.77294921875 
[2025-03-02 08:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.06478060781955719 norm:0.00010254833614453673 max memory_allocated 22562.77294921875 
[2025-03-02 08:37:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.06477464735507965 norm:0.00010264638694934547 max memory_allocated 22562.77294921875 
[2025-03-02 08:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.06476584076881409 norm:0.00010395394929219037 max memory_allocated 22562.77294921875 
[2025-03-02 08:38:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 08:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.08320768177509308 norm:0.001775737153366208 max memory_allocated 22562.94482421875 
[2025-03-02 08:39:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.08057457953691483 norm:0.0008799199131317437 max memory_allocated 22562.94482421875 
[2025-03-02 08:40:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.078946553170681 norm:0.0005694178980775177 max memory_allocated 22562.94482421875 
[2025-03-02 08:40:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.07776233553886414 norm:0.0004104897961951792 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.07735107839107513 norm:0.00031520522315986454 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.07716123014688492 norm:0.00025816640118137 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.07701931893825531 norm:0.0002235778811154887 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.07690422981977463 norm:0.00019870276446454227 max memory_allocated 22562.94482421875 
[2025-03-02 08:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.07683297991752625 norm:0.00017278417362831533 max memory_allocated 22562.94482421875 
[2025-03-02 08:43:58 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.0767713338136673 norm:0.0001489293936174363 max memory_allocated 22562.94482421875 
[2025-03-02 08:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.07674378156661987 norm:0.00014084522263146937 max memory_allocated 22562.94482421875 
[2025-03-02 08:45:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.07671241462230682 norm:0.00013700714043807238 max memory_allocated 22562.94482421875 
[2025-03-02 08:45:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.07666196674108505 norm:0.00013197833322919905 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.0766446441411972 norm:0.00013243335706647485 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.0766216516494751 norm:0.00013434074935503304 max memory_allocated 22562.94482421875 
[2025-03-02 08:47:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.07659398019313812 norm:0.000133167821331881 max memory_allocated 22562.94482421875 
[2025-03-02 08:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.07657923549413681 norm:0.00012882103328593075 max memory_allocated 22562.94482421875 
[2025-03-02 08:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.07657059282064438 norm:0.00012847705511376262 max memory_allocated 22562.94482421875 
[2025-03-02 08:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.07656756788492203 norm:0.00012650896678678691 max memory_allocated 22562.94482421875 
[2025-03-02 08:49:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.07656186819076538 norm:0.00012747324944939464 max memory_allocated 22562.94482421875 
[2025-03-02 08:49:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:50:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.09498134255409241 norm:0.001095716143026948 max memory_allocated 22563.11669921875 
[2025-03-02 08:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.0928182527422905 norm:0.0005334728048183024 max memory_allocated 22563.11669921875 
[2025-03-02 08:51:25 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.09117506444454193 norm:0.0003613581939134747 max memory_allocated 22563.11669921875 
[2025-03-02 08:51:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.09005959331989288 norm:0.0002787518606055528 max memory_allocated 22563.11669921875 
[2025-03-02 08:52:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.08977508544921875 norm:0.00023321621119976044 max memory_allocated 22563.11669921875 
[2025-03-02 08:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.08959917724132538 norm:0.00020011261221952736 max memory_allocated 22563.11669921875 
[2025-03-02 08:53:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.08947741985321045 norm:0.0001869802363216877 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.08936630189418793 norm:0.00016778177814558148 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.08927728980779648 norm:0.0001540649391245097 max memory_allocated 22563.11669921875 
[2025-03-02 08:55:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.08922079205513 norm:0.00014816598559264094 max memory_allocated 22563.11669921875 
[2025-03-02 08:55:54 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.08918217569589615 norm:0.00013642596604768187 max memory_allocated 22563.11669921875 
[2025-03-02 08:56:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.08913146704435349 norm:0.00012991612311452627 max memory_allocated 22563.11669921875 
[2025-03-02 08:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.08908642828464508 norm:0.00012309965677559376 max memory_allocated 22563.11669921875 
[2025-03-02 08:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.08905693143606186 norm:0.0001155782665591687 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.08903138339519501 norm:0.00011333706061122939 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.08901368081569672 norm:0.0001126961869886145 max memory_allocated 22563.11669921875 
[2025-03-02 08:59:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.08899857103824615 norm:0.00011137061665067449 max memory_allocated 22563.11669921875 
[2025-03-02 08:59:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.08899233490228653 norm:0.00010949710849672556 max memory_allocated 22563.11669921875 
[2025-03-02 09:00:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.08898446708917618 norm:0.00010958509665215388 max memory_allocated 22563.11669921875 
[2025-03-02 09:00:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.0889713317155838 norm:0.00010918260522885248 max memory_allocated 22563.11669921875 
[2025-03-02 09:01:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 09:01:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.10991374403238297 norm:0.0015430222265422344 max memory_allocated 22563.28857421875 
[2025-03-02 09:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.10753121972084045 norm:0.000754000386223197 max memory_allocated 22563.28857421875 
[2025-03-02 09:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.10565398633480072 norm:0.0004883615765720606 max memory_allocated 22563.28857421875 
[2025-03-02 09:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.1045197919011116 norm:0.00033666781382635236 max memory_allocated 22563.28857421875 
[2025-03-02 09:03:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.10424862056970596 norm:0.00026219876599498093 max memory_allocated 22563.28857421875 
[2025-03-02 09:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.10411788523197174 norm:0.00022132227604743093 max memory_allocated 22563.28857421875 
[2025-03-02 09:05:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.1040198802947998 norm:0.00018871852080337703 max memory_allocated 22563.28857421875 
[2025-03-02 09:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.10396008938550949 norm:0.00016532305744476616 max memory_allocated 22563.28857421875 
[2025-03-02 09:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.10391142964363098 norm:0.00015386017912533134 max memory_allocated 22563.28857421875 
[2025-03-02 09:06:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.10385975986719131 norm:0.00014926072617527097 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.10381601005792618 norm:0.00013803693582303822 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.10377657413482666 norm:0.00013384988415054977 max memory_allocated 22563.28857421875 
[2025-03-02 09:08:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.10375117510557175 norm:0.00013198304804973304 max memory_allocated 22563.28857421875 
[2025-03-02 09:08:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.10371490567922592 norm:0.00012619201152119786 max memory_allocated 22563.28857421875 
[2025-03-02 09:09:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.10369592159986496 norm:0.00012299971422180533 max memory_allocated 22563.28857421875 
[2025-03-02 09:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.10368180274963379 norm:0.0001223020808538422 max memory_allocated 22563.28857421875 
[2025-03-02 09:10:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.10365985333919525 norm:0.00012000031711068004 max memory_allocated 22563.28857421875 
[2025-03-02 09:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.10364554822444916 norm:0.00012089472147636116 max memory_allocated 22563.28857421875 
[2025-03-02 09:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.10363256186246872 norm:0.00011846947018057108 max memory_allocated 22563.28857421875 
[2025-03-02 09:12:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.10362762212753296 norm:0.00011893371993210167 max memory_allocated 22563.28857421875 
[2025-03-02 09:12:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 09:13:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.13155555725097656 norm:0.005152987316250801 max memory_allocated 22563.46044921875 
[2025-03-02 09:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.12655456364154816 norm:0.002579847350716591 max memory_allocated 22563.46044921875 
[2025-03-02 09:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.12335994839668274 norm:0.0015565797220915556 max memory_allocated 22563.46044921875 
[2025-03-02 09:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.12177774310112 norm:0.0010299928253516555 max memory_allocated 22563.46044921875 
[2025-03-02 09:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.12126578390598297 norm:0.0007400896865874529 max memory_allocated 22563.46044921875 
[2025-03-02 09:15:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.12096940726041794 norm:0.0005555712268687785 max memory_allocated 22563.46044921875 
[2025-03-02 09:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.12078661471605301 norm:0.0004406821681186557 max memory_allocated 22563.46044921875 
[2025-03-02 09:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.12064024060964584 norm:0.0003580456250347197 max memory_allocated 22563.46044921875 
[2025-03-02 09:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.12052840739488602 norm:0.0003057499707210809 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.1204415112733841 norm:0.0002654351410456002 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.12036550045013428 norm:0.00023886379494797438 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.12033034861087799 norm:0.0002176385751226917 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.12027879059314728 norm:0.00020427221897989511 max memory_allocated 22563.46044921875 
[2025-03-02 09:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.12026137113571167 norm:0.0001925952674355358 max memory_allocated 22563.46044921875 
[2025-03-02 09:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.12023720890283585 norm:0.0001843030477175489 max memory_allocated 22563.46044921875 
[2025-03-02 09:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.12022937834262848 norm:0.0001797777076717466 max memory_allocated 22563.46044921875 
[2025-03-02 09:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.12021932005882263 norm:0.00017459664377383888 max memory_allocated 22563.46044921875 
[2025-03-02 09:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.12020022422075272 norm:0.00017152729560621083 max memory_allocated 22563.46044921875 
[2025-03-02 09:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.12018789350986481 norm:0.00016929596313275397 max memory_allocated 22563.46044921875 
[2025-03-02 09:23:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.12017721682786942 norm:0.00016651312762405723 max memory_allocated 22563.46044921875 
[2025-03-02 09:23:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 09:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.14659897983074188 norm:0.0028013770934194326 max memory_allocated 22563.63232421875 
[2025-03-02 09:24:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.1430138349533081 norm:0.00138754490762949 max memory_allocated 22563.63232421875 
[2025-03-02 09:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.14034982025623322 norm:0.0008810176514089108 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.13913749158382416 norm:0.0006214899476617575 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.13883677124977112 norm:0.00048245626385323703 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.13863368332386017 norm:0.0003884927718900144 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.13847500085830688 norm:0.000327511370414868 max memory_allocated 22563.63232421875 
[2025-03-02 09:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.13834035396575928 norm:0.0002812518796417862 max memory_allocated 22563.63232421875 
[2025-03-02 09:28:54 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.13824042677879333 norm:0.0002473754284437746 max memory_allocated 22563.63232421875 
[2025-03-02 09:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.13819503784179688 norm:0.00022469559917226434 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.1381259560585022 norm:0.00020515122741926461 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.1380576193332672 norm:0.00019307012553326786 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.13801085948944092 norm:0.0001839253818616271 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.13797302544116974 norm:0.0001736887206789106 max memory_allocated 22563.63232421875 
[2025-03-02 09:32:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.13794441521167755 norm:0.0001685279858065769 max memory_allocated 22563.63232421875 
[2025-03-02 09:32:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.13793262839317322 norm:0.00016354318358935416 max memory_allocated 22563.63232421875 
[2025-03-02 09:33:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.13793449103832245 norm:0.00016605437849648297 max memory_allocated 22563.63232421875 
[2025-03-02 09:33:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.13790825009346008 norm:0.0001600732357474044 max memory_allocated 22563.63232421875 
[2025-03-02 09:34:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.1378961205482483 norm:0.00015747580619063228 max memory_allocated 22563.63232421875 
[2025-03-02 09:35:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.1378847062587738 norm:0.000158757931785658 max memory_allocated 22563.63232421875 
[2025-03-02 09:35:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 09:35:15 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:35:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.17012691497802734 norm:0.004184645600616932 max memory_allocated 22563.91943359375 
[2025-03-02 09:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.1665131151676178 norm:0.0033011087216436863 max memory_allocated 22563.91943359375 
[2025-03-02 09:36:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.16349679231643677 norm:0.002840251661837101 max memory_allocated 22563.91943359375 
[2025-03-02 09:37:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.16218963265419006 norm:0.0024205069057643414 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.16175898909568787 norm:0.0019686452578753233 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.16147735714912415 norm:0.0016951259458437562 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.16131025552749634 norm:0.0015832544304430485 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.16123057901859283 norm:0.0014533507637679577 max memory_allocated 22563.91943359375 
[2025-03-02 09:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.161119744181633 norm:0.001444813096895814 max memory_allocated 22563.91943359375 
[2025-03-02 09:40:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.16104304790496826 norm:0.0012161426711827517 max memory_allocated 22563.91943359375 
[2025-03-02 09:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.16088512539863586 norm:0.0011421388480812311 max memory_allocated 22563.91943359375 
[2025-03-02 09:41:58 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.1607997864484787 norm:0.0011628021020442247 max memory_allocated 22563.91943359375 
[2025-03-02 09:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.16079655289649963 norm:0.0011358073679730296 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.16076935827732086 norm:0.0011812062002718449 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.16072387993335724 norm:0.001058264751918614 max memory_allocated 22563.91943359375 
[2025-03-02 09:44:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.16066060960292816 norm:0.0010617751395329833 max memory_allocated 22563.91943359375 
[2025-03-02 09:44:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.16066691279411316 norm:0.0010523770470172167 max memory_allocated 22563.91943359375 
[2025-03-02 09:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.1606757789850235 norm:0.0010488575790077448 max memory_allocated 22563.91943359375 
[2025-03-02 09:45:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.16076605021953583 norm:0.0010556309716776013 max memory_allocated 22563.91943359375 
[2025-03-02 09:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.16097617149353027 norm:0.0012747558066621423 max memory_allocated 22563.91943359375 
[2025-03-02 09:46:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 09:46:39 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.20035520195960999 norm:0.005154973361641169 max memory_allocated 22564.09130859375 
[2025-03-02 09:47:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.1957412213087082 norm:0.003695512656122446 max memory_allocated 22564.09130859375 
[2025-03-02 09:48:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.19223351776599884 norm:0.0030278791673481464 max memory_allocated 22564.09130859375 
[2025-03-02 09:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.19088375568389893 norm:0.0026440622750669718 max memory_allocated 22564.09130859375 
[2025-03-02 09:49:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.1904664784669876 norm:0.0022822385653853416 max memory_allocated 22564.09130859375 
[2025-03-02 09:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.19008038938045502 norm:0.001988824224099517 max memory_allocated 22564.09130859375 
[2025-03-02 09:50:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.18988175690174103 norm:0.001775009441189468 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.18976904451847076 norm:0.0018527675420045853 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.18967881798744202 norm:0.0015861510764807463 max memory_allocated 22564.09130859375 
[2025-03-02 09:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.18971244990825653 norm:0.0014985207235440612 max memory_allocated 22564.09130859375 
[2025-03-02 09:52:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.18953166902065277 norm:0.0016352084930986166 max memory_allocated 22564.09130859375 
[2025-03-02 09:53:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.1892872303724289 norm:0.0013343520695343614 max memory_allocated 22564.09130859375 
[2025-03-02 09:53:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.18920032680034637 norm:0.0013203989947214723 max memory_allocated 22564.09130859375 
[2025-03-02 09:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.18920396268367767 norm:0.0012716802302747965 max memory_allocated 22564.09130859375 
[2025-03-02 09:55:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.18929514288902283 norm:0.0013787411153316498 max memory_allocated 22564.09130859375 
[2025-03-02 09:55:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.1893042027950287 norm:0.0012342121917754412 max memory_allocated 22564.09130859375 
[2025-03-02 09:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.18920916318893433 norm:0.0011446456192061305 max memory_allocated 22564.09130859375 
[2025-03-02 09:56:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.18915382027626038 norm:0.0013025717344135046 max memory_allocated 22564.09130859375 
[2025-03-02 09:57:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.1891426146030426 norm:0.0012927117059007287 max memory_allocated 22564.09130859375 
[2025-03-02 09:57:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.1890215426683426 norm:0.0012252946617081761 max memory_allocated 22564.09130859375 
[2025-03-02 09:58:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:58:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.27374541759490967 norm:0.015938280150294304 max memory_allocated 22564.26318359375 
[2025-03-02 09:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.25883638858795166 norm:0.015567193739116192 max memory_allocated 22564.26318359375 
[2025-03-02 09:59:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.25181764364242554 norm:0.016071541234850883 max memory_allocated 22564.26318359375 
[2025-03-02 10:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.2486378699541092 norm:0.01613325998187065 max memory_allocated 22564.26318359375 
[2025-03-02 10:00:52 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.24711200594902039 norm:0.016002265736460686 max memory_allocated 22564.26318359375 
[2025-03-02 10:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.2459593117237091 norm:0.01560673676431179 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.24513328075408936 norm:0.015360922552645206 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.2447856217622757 norm:0.015893196687102318 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.24409537017345428 norm:0.015292977914214134 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.2432478368282318 norm:0.013459951616823673 max memory_allocated 22564.26318359375 
[2025-03-02 10:04:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.24299904704093933 norm:0.013256354257464409 max memory_allocated 22564.26318359375 
[2025-03-02 10:04:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.24283580482006073 norm:0.012930375523865223 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.24265718460083008 norm:0.01234760694205761 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.24256828427314758 norm:0.012382344342768192 max memory_allocated 22564.26318359375 
[2025-03-02 10:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.24245882034301758 norm:0.012233160436153412 max memory_allocated 22564.26318359375 
[2025-03-02 10:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.24220389127731323 norm:0.011819475330412388 max memory_allocated 22564.26318359375 
[2025-03-02 10:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.24205027520656586 norm:0.011490246281027794 max memory_allocated 22564.26318359375 
[2025-03-02 10:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.24191950261592865 norm:0.011041981168091297 max memory_allocated 22564.26318359375 
[2025-03-02 10:08:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.2418607920408249 norm:0.010724538005888462 max memory_allocated 22564.26318359375 
[2025-03-02 10:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.24181446433067322 norm:0.010491885244846344 max memory_allocated 22564.26318359375 
[2025-03-02 10:09:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 10:09:30 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 10:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.4955408275127411 norm:0.034808069467544556 max memory_allocated 22564.43505859375 
[2025-03-02 10:10:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.4583774507045746 norm:0.02319388836622238 max memory_allocated 22564.43505859375 
[2025-03-02 10:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.43687671422958374 norm:0.016467686742544174 max memory_allocated 22564.43505859375 
[2025-03-02 10:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.4253583550453186 norm:0.013313760049641132 max memory_allocated 22564.43505859375 
[2025-03-02 10:12:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.419140487909317 norm:0.012505477294325829 max memory_allocated 22564.43505859375 
[2025-03-02 10:12:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.41459721326828003 norm:0.011525304988026619 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.41129136085510254 norm:0.011143691837787628 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.4091789722442627 norm:0.01125369593501091 max memory_allocated 22564.43505859375 
[2025-03-02 10:14:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.4074261784553528 norm:0.010422811843454838 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.4057936668395996 norm:0.010547107085585594 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.40495526790618896 norm:0.010365607216954231 max memory_allocated 22564.43505859375 
[2025-03-02 10:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.4039446711540222 norm:0.010314049199223518 max memory_allocated 22564.43505859375 
[2025-03-02 10:16:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.4032474458217621 norm:0.009928985498845577 max memory_allocated 22564.43505859375 
[2025-03-02 10:17:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.4027281403541565 norm:0.009947624057531357 max memory_allocated 22564.43505859375 
[2025-03-02 10:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.4022490978240967 norm:0.010032238438725471 max memory_allocated 22564.43505859375 
[2025-03-02 10:18:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.40158918499946594 norm:0.009483416564762592 max memory_allocated 22564.43505859375 
[2025-03-02 10:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.4011925756931305 norm:0.009282666258513927 max memory_allocated 22564.43505859375 
[2025-03-02 10:19:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.40107399225234985 norm:0.009769473224878311 max memory_allocated 22564.43505859375 
[2025-03-02 10:20:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.4009888470172882 norm:0.009903786703944206 max memory_allocated 22564.43505859375 
[2025-03-02 10:20:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.4006538689136505 norm:0.009554537013173103 max memory_allocated 22564.43505859375 
[2025-03-02 10:20:51 root] (main_calib_config2.py 372): INFO 21839.428736925125
[2025-03-02 10:20:56 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 10:22:07 root] (main_calib_config2.py 159): INFO wikitext2 : 5.774034023284912
[2025-03-02 10:22:07 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 10:23:57 root] (main_calib_config2.py 159): INFO c4 : 7.20963716506958
[2025-03-02 12:05:38 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.774034023284912, 'c4': 7.20963716506958, 'results': {'boolq': {'acc': 0.7186544342507645, 'acc_stderr': 0.007864527436306253}, 'hellaswag': {'acc': 0.5571599283011353, 'acc_stderr': 0.004957068377516511, 'acc_norm': 0.7208723361880104, 'acc_norm_stderr': 0.004476536569056588}, 'arc_challenge': {'acc': 0.3720136518771331, 'acc_stderr': 0.014124597881844458, 'acc_norm': 0.4061433447098976, 'acc_norm_stderr': 0.01435165669009786}, 'piqa': {'acc': 0.7736670293797606, 'acc_stderr': 0.009763294246879422, 'acc_norm': 0.7676822633297062, 'acc_norm_stderr': 0.009853201384168243}, 'winogrande': {'acc': 0.654301499605367, 'acc_stderr': 0.013366596951934371}, 'arc_easy': {'acc': 0.6628787878787878, 'acc_stderr': 0.009700146509130076, 'acc_norm': 0.515993265993266, 'acc_norm_stderr': 0.010254533589288184}}, 'versions': {'boolq': 1, 'hellaswag': 0, 'arc_challenge': 0, 'piqa': 0, 'winogrande': 0, 'arc_easy': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
