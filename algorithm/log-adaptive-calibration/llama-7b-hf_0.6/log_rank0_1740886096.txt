[2025-03-02 03:28:16 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.6', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.6.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 03:30:43 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-02 03:30:43 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.6.pkl
[2025-03-02 03:30:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 03:30:52 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.010517536662518978 norm:0.005673191975802183 max memory_allocated 22559.10693359375 
[2025-03-02 03:31:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.005630290135741234 norm:0.0029332791455090046 max memory_allocated 22559.10693359375 
[2025-03-02 03:32:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.00384060712531209 norm:0.0018827939638867974 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0033589894883334637 norm:0.0015484399627894163 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0032418319024145603 norm:0.0014430431183427572 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0031644513364881277 norm:0.001305333455093205 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.003115195082500577 norm:0.0011676917783915997 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.003074615728110075 norm:0.0010611064499244094 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:50 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0030348021537065506 norm:0.0009968194644898176 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0030074608512222767 norm:0.0009212342556566 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.002979874610900879 norm:0.0008428890141658485 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0029520050156861544 norm:0.000763748015742749 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.002924676053225994 norm:0.000688609026838094 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0029107225127518177 norm:0.0006294471677392721 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0029028658755123615 norm:0.0005822575185447931 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.002888471120968461 norm:0.0005329920677468181 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0028750591445714235 norm:0.0005021555116400123 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.002859237603843212 norm:0.0004711901128757745 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.002856452716514468 norm:0.0004645158478524536 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.002851729979738593 norm:0.00045892223715782166 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 03:42:08 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.02312871254980564 norm:0.01840377040207386 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.013262756168842316 norm:0.011667917482554913 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.00937518011778593 norm:0.006881600711494684 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.008456477895379066 norm:0.0050393519923090935 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.008058702573180199 norm:0.004389003850519657 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.0077837007120251656 norm:0.0037645334377884865 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.007579063531011343 norm:0.00348735973238945 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.007425467483699322 norm:0.0033012214116752148 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.007285427302122116 norm:0.003015774767845869 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.007170857395976782 norm:0.0027752970345318317 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.0070715127512812614 norm:0.002535392064601183 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.007028186693787575 norm:0.0023577092215418816 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.006993941497057676 norm:0.0021884310990571976 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.006941888015717268 norm:0.001957614440470934 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.0068997573107481 norm:0.0017707431688904762 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.006870302837342024 norm:0.0016339544672518969 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.006853187456727028 norm:0.0015001633437350392 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.006833156570792198 norm:0.0013508039992302656 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.006820500362664461 norm:0.0011949623003602028 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.006804590579122305 norm:0.0010960061335936189 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 03:53:26 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.0878787562251091 norm:0.027853460982441902 max memory_allocated 22559.45068359375 
[2025-03-02 03:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.04244726896286011 norm:0.015087950974702835 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.027239760383963585 norm:0.010929876938462257 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.021932141855359077 norm:0.008532754145562649 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.020153824239969254 norm:0.00792788714170456 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.018748702481389046 norm:0.006788297556340694 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.01824958249926567 norm:0.0062445527873933315 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.017850704491138458 norm:0.006037920713424683 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.017763182520866394 norm:0.005818800535053015 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.017665904015302658 norm:0.005787123925983906 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:33 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.017559915781021118 norm:0.005393613129854202 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.017393454909324646 norm:0.005321912467479706 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.01734878122806549 norm:0.005364435724914074 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.01731562800705433 norm:0.005508613307029009 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.017044657841324806 norm:0.005086472257971764 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.01743992790579796 norm:0.00547621538862586 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.017050694674253464 norm:0.005144637078046799 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.017014186829328537 norm:0.004955677315592766 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.016965176910161972 norm:0.004744563717395067 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:33 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.016878437250852585 norm:0.00465382682159543 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.028914768248796463 norm:0.0021868045441806316 max memory_allocated 22559.50732421875 
[2025-03-02 04:05:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.022278092801570892 norm:0.0008978138794191182 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.019119322299957275 norm:0.0004415649746078998 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.018010422587394714 norm:0.0002384902909398079 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.017376692965626717 norm:0.00014720269246026874 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.017015280202031136 norm:0.00012171993148513138 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:37 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.016878001391887665 norm:0.00011316374002490193 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.01680522970855236 norm:0.00010879131150431931 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.01679658144712448 norm:0.00010043072688858956 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.01677575707435608 norm:9.891310764942318e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.016757065430283546 norm:0.00010111140727531165 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.016755424439907074 norm:0.00010242354619549587 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.01673990860581398 norm:0.00010526052938075736 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.016729995608329773 norm:0.00011649070074781775 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.016716202720999718 norm:0.00010079459752887487 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.01671958900988102 norm:0.00010176069918088615 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.0167107954621315 norm:0.0001017895046970807 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.016715437173843384 norm:0.00010997935169143602 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.016697604209184647 norm:0.00010085153917316347 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.016697529703378677 norm:0.00010555343760643154 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 04:16:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.03667663037776947 norm:0.0021061424631625414 max memory_allocated 22559.67919921875 
[2025-03-02 04:17:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.02851536124944687 norm:0.0009233555174432695 max memory_allocated 22559.67919921875 
[2025-03-02 04:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.02420100010931492 norm:0.0004561425594147295 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.022572897374629974 norm:0.00028732590726576746 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.0218815915286541 norm:0.0002289700205437839 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.021530969068408012 norm:0.00022569445718545467 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.02152065932750702 norm:0.00020631581719499081 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.021316634491086006 norm:0.0001960528752533719 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.021266160532832146 norm:0.00019704853184521198 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.021209269762039185 norm:0.00018909870414063334 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.021177111193537712 norm:0.00018888300110120326 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.021176660433411598 norm:0.00018450862262398005 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.021126657724380493 norm:0.00018403396825306118 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.021118931472301483 norm:0.00019959101337008178 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.02109733782708645 norm:0.0001912802690640092 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.02108060009777546 norm:0.00018633539730217308 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.021054746583104134 norm:0.0001904554374050349 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.021051663905382156 norm:0.0001973203761735931 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.02107110619544983 norm:0.00018993549747392535 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.021056724712252617 norm:0.00020019728981424123 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 04:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.04071548581123352 norm:0.0020665181800723076 max memory_allocated 22559.85107421875 
[2025-03-02 04:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.032410673797130585 norm:0.0009588129469193518 max memory_allocated 22559.85107421875 
[2025-03-02 04:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.027743039652705193 norm:0.0004859651089645922 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.026154091581702232 norm:0.0002792862069327384 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.02533680759370327 norm:0.00019493376021273434 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.025017226114869118 norm:0.00017782645591069013 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:08 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.02481040358543396 norm:0.00014881107199471444 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.02468072809278965 norm:0.00014818205090705305 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.02461441420018673 norm:0.00015136132424231619 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.02454996481537819 norm:0.0001652143691899255 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.02448984608054161 norm:0.00013684851001016796 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.024442652240395546 norm:0.0001474971795687452 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.02440999262034893 norm:0.00014815246686339378 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.024388715624809265 norm:0.0001466132525820285 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.024360384792089462 norm:0.00014571193605661392 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.02434481307864189 norm:0.00014713253767695278 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.024336276575922966 norm:0.00014940943219698966 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.024324318394064903 norm:0.000147723825648427 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.024342583492398262 norm:0.0001507542619947344 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.024307098239660263 norm:0.0001412600395269692 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 04:39:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.04188603535294533 norm:0.000988904619589448 max memory_allocated 22560.02294921875 
[2025-03-02 04:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.03480920568108559 norm:0.00042091880459338427 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.03077072463929653 norm:0.0002460134564898908 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.02943066507577896 norm:0.0001645419397391379 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.028690766543149948 norm:0.00013802608009427786 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.028390994295477867 norm:0.0001407314121024683 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.02820873260498047 norm:0.0001248793414561078 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.028260279446840286 norm:0.00017985107842832804 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.028089359402656555 norm:0.00013094666064716876 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.028015293180942535 norm:0.0001305552723351866 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.0279935821890831 norm:0.0001386384101351723 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.02793589048087597 norm:0.00012979097664356232 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.027922069653868675 norm:0.00012714671902358532 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.02788667567074299 norm:0.00012940606393385679 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.027907460927963257 norm:0.00013740250142291188 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.027897993102669716 norm:0.00012612697901204228 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.027872975915670395 norm:0.00012974979472346604 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.02787972241640091 norm:0.0001334510452579707 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.02785590849816799 norm:0.00012395541125442833 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.027854470536112785 norm:0.000125126403872855 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 04:50:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.04865458235144615 norm:0.0012462030863389373 max memory_allocated 22560.19482421875 
[2025-03-02 04:50:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.040208205580711365 norm:0.0006334815407171845 max memory_allocated 22560.19482421875 
[2025-03-02 04:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.03536877781152725 norm:0.0003607469261623919 max memory_allocated 22560.19482421875 
[2025-03-02 04:51:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.03372425213456154 norm:0.00023275657440535724 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.0330076739192009 norm:0.00021596958686131984 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.0325300395488739 norm:0.00017323762585874647 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.032412320375442505 norm:0.00018199421174358577 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.03233765438199043 norm:0.0001828318345360458 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.03218621015548706 norm:0.0001467724796384573 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.03211737051606178 norm:0.00015103741316124797 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.032083556056022644 norm:0.00014106179878581315 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.032091766595840454 norm:0.00014534653746522963 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.032043684273958206 norm:0.00014520561671815813 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.031986940652132034 norm:0.00014718125748913735 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.031987063586711884 norm:0.0001472266303608194 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.03195535019040108 norm:0.00014672274119220674 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.031976331025362015 norm:0.00015662390796933323 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.031963150948286057 norm:0.00014690053649246693 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.03195645287632942 norm:0.00016412505647167563 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.031920552253723145 norm:0.00015238241758197546 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:01:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.05121484026312828 norm:0.000952280533965677 max memory_allocated 22560.36669921875 
[2025-03-02 05:02:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.04308995231986046 norm:0.0004414173308759928 max memory_allocated 22560.36669921875 
[2025-03-02 05:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.03819233924150467 norm:0.0002675248251762241 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.03662868216633797 norm:0.0002092602662742138 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.035824310034513474 norm:0.00016661440895404667 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.03545396402478218 norm:0.0001564871345181018 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.03525182604789734 norm:0.00015237981278914958 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.03508973866701126 norm:0.00014924649440217763 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.03500562533736229 norm:0.000146219419548288 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.0349423810839653 norm:0.00014584098244085908 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.03487488254904747 norm:0.00014864804688841105 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.034825198352336884 norm:0.0001352996623609215 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.034809187054634094 norm:0.0001358667650492862 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.03476396203041077 norm:0.00013269051851239055 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.03473478928208351 norm:0.00012778713426087052 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.03476383537054062 norm:0.00013170199235901237 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.03477810323238373 norm:0.00012630959099624306 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.03478269279003143 norm:0.00013442046474665403 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.03478078916668892 norm:0.00013975825277157128 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.03477252274751663 norm:0.0001486615219619125 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 05:12:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.05739346146583557 norm:0.001200888422317803 max memory_allocated 22560.53857421875 
[2025-03-02 05:13:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.047723300755023956 norm:0.0005884738056920469 max memory_allocated 22560.53857421875 
[2025-03-02 05:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.04245050624012947 norm:0.0003454440739005804 max memory_allocated 22560.53857421875 
[2025-03-02 05:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.040724121034145355 norm:0.00023992813657969236 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.039814542979002 norm:0.00018669998098630458 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.039349477738142014 norm:0.00017094438953790814 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.039148129522800446 norm:0.00016569357831031084 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.038990143686532974 norm:0.00015197601169347763 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.03888659179210663 norm:0.0001474383461754769 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.03881479799747467 norm:0.00013954879250377417 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.03874244540929794 norm:0.00013731660146731883 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.03869466483592987 norm:0.00013520391075871885 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.03867756575345993 norm:0.00012975728895980865 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.038627274334430695 norm:0.00012959790183231235 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.03857751935720444 norm:0.00013721144932787865 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.03852488100528717 norm:0.00012337019143160433 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.038516249507665634 norm:0.00012482109013944864 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.038509808480739594 norm:0.00012739333033096045 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.038497909903526306 norm:0.00012493389658629894 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.03850600868463516 norm:0.0001281688455492258 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 05:24:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.05584435537457466 norm:0.0008621709421277046 max memory_allocated 22560.71044921875 
[2025-03-02 05:24:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.049036573618650436 norm:0.0004187136946711689 max memory_allocated 22560.71044921875 
[2025-03-02 05:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.04452844709157944 norm:0.00025452603586018085 max memory_allocated 22560.71044921875 
[2025-03-02 05:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.0430394671857357 norm:0.0001856860180851072 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.04231436178088188 norm:0.00015221221838146448 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.04191812127828598 norm:0.00013708596816286445 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.0416870042681694 norm:0.00012005660391878337 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.041578300297260284 norm:0.0001126970601035282 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.04154093191027641 norm:0.00011029864981537685 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.04146687313914299 norm:0.00010253740038024262 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.04141795262694359 norm:0.0001018060720525682 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.04139923304319382 norm:0.00010780235606944188 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.04137369990348816 norm:0.00010275408567395061 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.041336026042699814 norm:9.867708286037669e-05 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.041341494768857956 norm:0.00010329087672289461 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.04133234918117523 norm:0.00010093770106323063 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.04132436215877533 norm:9.935499838320538e-05 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.04131679981946945 norm:0.00010131370072485879 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.04132223129272461 norm:0.00010111073788721114 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.04130835831165314 norm:0.00010173360351473093 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 05:35:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.058729369193315506 norm:0.0008645616471767426 max memory_allocated 22560.88232421875 
[2025-03-02 05:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.05144789069890976 norm:0.00042430119356140494 max memory_allocated 22560.88232421875 
[2025-03-02 05:36:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.04659010469913483 norm:0.0002568381605669856 max memory_allocated 22560.88232421875 
[2025-03-02 05:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.045135702937841415 norm:0.00017558824038133025 max memory_allocated 22560.88232421875 
[2025-03-02 05:37:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.044430337846279144 norm:0.00014075277431402355 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.044024012982845306 norm:0.00012022081500617787 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.043842434883117676 norm:0.00011517088569235057 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.04374068230390549 norm:0.00010621528053889051 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.04364961013197899 norm:0.00010939710773527622 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.04361100122332573 norm:0.00010741639562183991 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.043544892221689224 norm:0.00010209054744336754 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.043501291424036026 norm:9.897963172988966e-05 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.043484918773174286 norm:9.972020779969171e-05 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.04348307102918625 norm:0.00010081976506626233 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.0434570275247097 norm:0.0001048409758368507 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.04344858601689339 norm:0.00010322959133191034 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.04343099892139435 norm:0.00010126059351023287 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.04342281073331833 norm:0.00010134118929272518 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.043417636305093765 norm:0.00010036445746663958 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.04343627020716667 norm:0.00010323523747501895 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 05:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.061002813279628754 norm:0.000662639329675585 max memory_allocated 22561.05419921875 
[2025-03-02 05:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.05397912114858627 norm:0.000353925337549299 max memory_allocated 22561.05419921875 
[2025-03-02 05:47:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.04922182112932205 norm:0.0002365087711950764 max memory_allocated 22561.05419921875 
[2025-03-02 05:48:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.04764958471059799 norm:0.00018583613564260304 max memory_allocated 22561.05419921875 
[2025-03-02 05:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.04685402289032936 norm:0.00015912853996269405 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.04638918861746788 norm:0.00014410188305191696 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.04612657055258751 norm:0.00013106837286613882 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.04598110914230347 norm:0.00012418653932400048 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.045863207429647446 norm:0.0001125284397858195 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.04577676206827164 norm:0.00010466672392794862 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.04570337012410164 norm:0.00010526237019803375 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.045654766261577606 norm:9.951120591722429e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.04562751203775406 norm:9.643130033509806e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.04561709240078926 norm:9.73594214883633e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.045593924820423126 norm:9.206479444401339e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.04557926207780838 norm:9.031354420585558e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.04555525258183479 norm:9.121350740315393e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.045541029423475266 norm:9.482503810431808e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.045542456209659576 norm:9.121208131546155e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.045540690422058105 norm:9.250841685570776e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 05:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.06251244992017746 norm:0.0006002276204526424 max memory_allocated 22561.22607421875 
[2025-03-02 05:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.05592621490359306 norm:0.000306087255012244 max memory_allocated 22561.22607421875 
[2025-03-02 05:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.05127193406224251 norm:0.0002002371329581365 max memory_allocated 22561.22607421875 
[2025-03-02 05:59:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.049753498286008835 norm:0.00015729141887277365 max memory_allocated 22561.22607421875 
[2025-03-02 06:00:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.048993002623319626 norm:0.00013527653936762363 max memory_allocated 22561.22607421875 
[2025-03-02 06:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.04856329411268234 norm:0.00012568070087581873 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.04831157252192497 norm:0.00011526121670613065 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.04820042476058006 norm:0.00010859547910513356 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.04812263697385788 norm:9.964680066332221e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.04804234951734543 norm:9.705729462439194e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.0480097234249115 norm:9.855761891230941e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.04796559736132622 norm:9.155162842944264e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.04792763665318489 norm:8.725169755052775e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.04788202419877052 norm:8.798763155937195e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.047877173870801926 norm:9.01107705431059e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.04785686358809471 norm:8.963310392573476e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.04782174900174141 norm:8.885299030225724e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.04780106619000435 norm:8.851395978126675e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.04779500141739845 norm:8.906512084649876e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.04777492582798004 norm:8.696749864611775e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:09:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.06894230842590332 norm:0.001147130155004561 max memory_allocated 22561.39794921875 
[2025-03-02 06:09:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.060795143246650696 norm:0.0005455029895529151 max memory_allocated 22561.39794921875 
[2025-03-02 06:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.05548577383160591 norm:0.0003226542321499437 max memory_allocated 22561.39794921875 
[2025-03-02 06:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.053789813071489334 norm:0.00023034296464174986 max memory_allocated 22561.39794921875 
[2025-03-02 06:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.052915774285793304 norm:0.00018418070976622403 max memory_allocated 22561.39794921875 
[2025-03-02 06:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.05244320258498192 norm:0.00015464414900634438 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.05220402404665947 norm:0.00013872502313461155 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.05204934999346733 norm:0.00012966818758286536 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.05193313956260681 norm:0.0001266980543732643 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.051813896745443344 norm:0.00011870999878738075 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.05173041298985481 norm:0.00010688550537452102 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.05169793963432312 norm:0.00010187849693465978 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.0516691729426384 norm:0.00010045961971627548 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.05164350941777229 norm:9.98592222458683e-05 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.05161738023161888 norm:9.905742626870051e-05 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.051576610654592514 norm:0.00010111006122315302 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.05152324214577675 norm:9.591778507456183e-05 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.05149488151073456 norm:9.3060516519472e-05 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.051464322954416275 norm:9.432217484572902e-05 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.05145146697759628 norm:9.389739716425538e-05 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 06:20:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.0714595839381218 norm:0.00078398926416412 max memory_allocated 22561.56982421875 
[2025-03-02 06:20:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.06428338587284088 norm:0.00038707273779436946 max memory_allocated 22561.56982421875 
[2025-03-02 06:21:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.059088334441185 norm:0.00024686657707206905 max memory_allocated 22561.56982421875 
[2025-03-02 06:22:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.05737752839922905 norm:0.00017241854220628738 max memory_allocated 22561.56982421875 
[2025-03-02 06:22:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.05650508776307106 norm:0.00014515886141452938 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.05607616528868675 norm:0.00013286122702993453 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.05587509274482727 norm:0.0001252274087164551 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.055685319006443024 norm:0.00011112388165201992 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.055573150515556335 norm:0.0001000110714812763 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.0554693378508091 norm:9.554973803460598e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.05543109402060509 norm:0.00010625833238009363 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.055390506982803345 norm:0.00010010767437051982 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.055357545614242554 norm:0.00010465067316545174 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.05535666644573212 norm:9.807173773879185e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.0553295835852623 norm:9.487538045505062e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.055283382534980774 norm:0.00010053340520244092 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.05524385720491409 norm:9.571301779942587e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.055237606167793274 norm:0.00010134644253412262 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.05520172417163849 norm:8.876887295627967e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.055192507803440094 norm:8.674088167026639e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 06:31:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.07895800471305847 norm:0.0008956610690802336 max memory_allocated 22561.74169921875 
[2025-03-02 06:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.07040867954492569 norm:0.0004089417343493551 max memory_allocated 22561.74169921875 
[2025-03-02 06:32:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.06462223827838898 norm:0.0002461927360855043 max memory_allocated 22561.74169921875 
[2025-03-02 06:33:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.06286817789077759 norm:0.00018522830214351416 max memory_allocated 22561.74169921875 
[2025-03-02 06:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.062022797763347626 norm:0.0001644552539801225 max memory_allocated 22561.74169921875 
[2025-03-02 06:34:26 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.0615711435675621 norm:0.0001437823666492477 max memory_allocated 22561.74169921875 
[2025-03-02 06:34:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.06132104620337486 norm:0.0001323780743405223 max memory_allocated 22561.74169921875 
[2025-03-02 06:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.06115846335887909 norm:0.00012412716750986874 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.061009857803583145 norm:0.00011394579632906243 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.06090611591935158 norm:0.00011520119005581364 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.06085183471441269 norm:0.00011566994362510741 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.06080266833305359 norm:0.00010923664376605302 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.06073349714279175 norm:0.00010963456588797271 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.06068520247936249 norm:0.00010967950220219791 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.060623615980148315 norm:0.0001002383723971434 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.06057247519493103 norm:9.841442806646228e-05 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.060551390051841736 norm:9.979750029742718e-05 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.06052951514720917 norm:9.835078526521102e-05 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.06050710007548332 norm:0.00010074146121041849 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.060477204620838165 norm:0.00010061682405648753 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 06:42:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.08824627101421356 norm:0.0011430439772084355 max memory_allocated 22561.91357421875 
[2025-03-02 06:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.07907024770975113 norm:0.0005230240640230477 max memory_allocated 22561.91357421875 
[2025-03-02 06:44:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.07240933179855347 norm:0.0003119097091257572 max memory_allocated 22561.91357421875 
[2025-03-02 06:44:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.07049241662025452 norm:0.0002296321326866746 max memory_allocated 22561.91357421875 
[2025-03-02 06:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.06952421367168427 norm:0.00018083506438415498 max memory_allocated 22561.91357421875 
[2025-03-02 06:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.06912107765674591 norm:0.00016390984819736332 max memory_allocated 22561.91357421875 
[2025-03-02 06:46:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.06889738887548447 norm:0.0001509358116891235 max memory_allocated 22561.91357421875 
[2025-03-02 06:46:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.0687585324048996 norm:0.00013619783567264676 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.06861522048711777 norm:0.0001230626949109137 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.06850214302539825 norm:0.00012237767805345356 max memory_allocated 22561.91357421875 
[2025-03-02 06:48:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.0684114471077919 norm:0.0001184098728117533 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.06832045316696167 norm:0.00011220791202504188 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.06826406717300415 norm:0.00011065554281231016 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.06819571554660797 norm:0.00011117875692434609 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.06814184039831161 norm:0.00011058875679736957 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.06808240711688995 norm:0.00010728790948633105 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.06807852536439896 norm:0.00010589843441266567 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.06805779039859772 norm:0.00010619587555993348 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.06800754368305206 norm:0.00010404524800833315 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.06796546280384064 norm:0.00010478387412149459 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 06:54:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.0971977561712265 norm:0.0006816602544859052 max memory_allocated 22562.08544921875 
[2025-03-02 06:54:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.08852821588516235 norm:0.0003720078384503722 max memory_allocated 22562.08544921875 
[2025-03-02 06:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.0819697380065918 norm:0.00023573880025651306 max memory_allocated 22562.08544921875 
[2025-03-02 06:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.08013743162155151 norm:0.00020718996529467404 max memory_allocated 22562.08544921875 
[2025-03-02 06:56:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.07922643423080444 norm:0.00017424831457901746 max memory_allocated 22562.08544921875 
[2025-03-02 06:56:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.07887322455644608 norm:0.0001559980446472764 max memory_allocated 22562.08544921875 
[2025-03-02 06:57:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.07864362746477127 norm:0.00014865257253404707 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.07848383486270905 norm:0.0001380059984512627 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.07833871245384216 norm:0.00013243310968391597 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.07821525633335114 norm:0.0001277907140320167 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.07813680917024612 norm:0.0001255947136087343 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.07805472612380981 norm:0.00012191729911137372 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.07798155397176743 norm:0.00011650907254079357 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.07793506979942322 norm:0.00011483769048936665 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.07787219434976578 norm:0.00011303278006380424 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.07785142958164215 norm:0.00011086036829510704 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.07780129462480545 norm:0.000109517750388477 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.07775206118822098 norm:0.00010813035623868927 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.07774119824171066 norm:0.00010587168799247593 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.07770094275474548 norm:0.00010537417256273329 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.11146246641874313 norm:0.0008746550302021205 max memory_allocated 22562.25732421875 
[2025-03-02 07:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.10204354673624039 norm:0.00043033683323301375 max memory_allocated 22562.25732421875 
[2025-03-02 07:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.09495455771684647 norm:0.0002651759423315525 max memory_allocated 22562.25732421875 
[2025-03-02 07:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.09288526326417923 norm:0.00021714853937737644 max memory_allocated 22562.25732421875 
[2025-03-02 07:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.0919327661395073 norm:0.0001826429070206359 max memory_allocated 22562.25732421875 
[2025-03-02 07:08:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.09155474603176117 norm:0.00016960845096036792 max memory_allocated 22562.25732421875 
[2025-03-02 07:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.09131716191768646 norm:0.00015900751168373972 max memory_allocated 22562.25732421875 
[2025-03-02 07:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.09113352000713348 norm:0.00015089736552909017 max memory_allocated 22562.25732421875 
[2025-03-02 07:09:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.0909239798784256 norm:0.00014255079440772533 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.09077717363834381 norm:0.00013718480477109551 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.09069054573774338 norm:0.00012991004041396081 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.09058353304862976 norm:0.0001287323102587834 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.09055037051439285 norm:0.00013551110168918967 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.09047124534845352 norm:0.00013415070134215057 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.0903950184583664 norm:0.00013126470730639994 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.0903620794415474 norm:0.00012744919513352215 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.09032592922449112 norm:0.00012785328726749867 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.0902634859085083 norm:0.00012313069601077586 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.0902283564209938 norm:0.0001234733936144039 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.09018640965223312 norm:0.00012171144044259563 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 07:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.1335776448249817 norm:0.0016877911984920502 max memory_allocated 22562.42919921875 
[2025-03-02 07:17:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.12164367735385895 norm:0.0006614457815885544 max memory_allocated 22562.42919921875 
[2025-03-02 07:17:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.11308858543634415 norm:0.000421940756496042 max memory_allocated 22562.42919921875 
[2025-03-02 07:18:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.11057689040899277 norm:0.00033696097671054304 max memory_allocated 22562.42919921875 
[2025-03-02 07:18:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.10963419079780579 norm:0.00030075438553467393 max memory_allocated 22562.42919921875 
[2025-03-02 07:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.10915042459964752 norm:0.0002625944616738707 max memory_allocated 22562.42919921875 
[2025-03-02 07:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.10883701592683792 norm:0.0002506560704205185 max memory_allocated 22562.42919921875 
[2025-03-02 07:20:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.10860510170459747 norm:0.00021795311477035284 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.10831569880247116 norm:0.00019956877804361284 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.10809825360774994 norm:0.0001966132113011554 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.10795315355062485 norm:0.0001960094814421609 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.10782188177108765 norm:0.00018582725897431374 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.10769347101449966 norm:0.00018421541608404368 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.10754726827144623 norm:0.00017565861344337463 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.10745357722043991 norm:0.00017495242354925722 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.10739867389202118 norm:0.00017208668577950448 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.10732761770486832 norm:0.0001716932893032208 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.10726483911275864 norm:0.00016761985898483545 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.10722068697214127 norm:0.0001634488144190982 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.10719005763530731 norm:0.0001630645856494084 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 07:27:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.1549137830734253 norm:0.0019495352171361446 max memory_allocated 22562.60107421875 
[2025-03-02 07:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.1431591659784317 norm:0.0007687685429118574 max memory_allocated 22562.60107421875 
[2025-03-02 07:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.13362343609333038 norm:0.0004645712615456432 max memory_allocated 22562.60107421875 
[2025-03-02 07:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.1308862566947937 norm:0.00036586285568773746 max memory_allocated 22562.60107421875 
[2025-03-02 07:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.129858136177063 norm:0.00031943045905791223 max memory_allocated 22562.60107421875 
[2025-03-02 07:30:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.1294310986995697 norm:0.0002850067103281617 max memory_allocated 22562.60107421875 
[2025-03-02 07:31:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.12911899387836456 norm:0.00026389153208583593 max memory_allocated 22562.60107421875 
[2025-03-02 07:31:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.12886369228363037 norm:0.00023887665884103626 max memory_allocated 22562.60107421875 
[2025-03-02 07:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.12859869003295898 norm:0.00022623030235990882 max memory_allocated 22562.60107421875 
[2025-03-02 07:32:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.12840358912944794 norm:0.00021061250299680978 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.12823855876922607 norm:0.00019694824004545808 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.12808041274547577 norm:0.00018596832524053752 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.1279793083667755 norm:0.00018402461137156934 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.12786944210529327 norm:0.00017676784773357213 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.12775635719299316 norm:0.00016531223081983626 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.12767452001571655 norm:0.00016456386947538704 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.12760886549949646 norm:0.00017312413547188044 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.12754248082637787 norm:0.00017078995006158948 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.1274649202823639 norm:0.00019058362522628158 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.1274050772190094 norm:0.00018148617527913302 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 07:39:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.1775229573249817 norm:0.0012848067563027143 max memory_allocated 22562.77294921875 
[2025-03-02 07:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.1652120053768158 norm:0.0006844908930361271 max memory_allocated 22562.77294921875 
[2025-03-02 07:40:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.15532802045345306 norm:0.00043861515587195754 max memory_allocated 22562.77294921875 
[2025-03-02 07:40:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.15252730250358582 norm:0.0003397859400138259 max memory_allocated 22562.77294921875 
[2025-03-02 07:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.15164516866207123 norm:0.00027637797757051885 max memory_allocated 22562.77294921875 
[2025-03-02 07:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.15112391114234924 norm:0.00024346364079974592 max memory_allocated 22562.77294921875 
[2025-03-02 07:42:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.15075647830963135 norm:0.0002164695761166513 max memory_allocated 22562.77294921875 
[2025-03-02 07:43:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.1504732072353363 norm:0.00020751837291754782 max memory_allocated 22562.77294921875 
[2025-03-02 07:43:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.15026456117630005 norm:0.0001962206297321245 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.15008656680583954 norm:0.00019067779066972435 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.14990223944187164 norm:0.0001914433523779735 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.14975637197494507 norm:0.0001808138331398368 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.14966478943824768 norm:0.0001839365140767768 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.14951513707637787 norm:0.00017759663751348853 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.14942136406898499 norm:0.00017940733232535422 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.14931020140647888 norm:0.00017525798466522247 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.14922356605529785 norm:0.00017569134070072323 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.14914213120937347 norm:0.00017625278269406408 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.1491011083126068 norm:0.00017107570602092892 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.1490102857351303 norm:0.00017067829321604222 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 07:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.20544326305389404 norm:0.002010102616623044 max memory_allocated 22562.94482421875 
[2025-03-02 07:51:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.19281455874443054 norm:0.0010704430751502514 max memory_allocated 22562.94482421875 
[2025-03-02 07:51:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.1821409910917282 norm:0.0006568820681422949 max memory_allocated 22562.94482421875 
[2025-03-02 07:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.17919239401817322 norm:0.0004874706792179495 max memory_allocated 22562.94482421875 
[2025-03-02 07:52:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.1781960129737854 norm:0.000385801016818732 max memory_allocated 22562.94482421875 
[2025-03-02 07:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.17765599489212036 norm:0.0003200317150913179 max memory_allocated 22562.94482421875 
[2025-03-02 07:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.1772546023130417 norm:0.0002871036413125694 max memory_allocated 22562.94482421875 
[2025-03-02 07:54:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.17700108885765076 norm:0.00026860792422667146 max memory_allocated 22562.94482421875 
[2025-03-02 07:54:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.17679338157176971 norm:0.00023796320601832122 max memory_allocated 22562.94482421875 
[2025-03-02 07:55:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.17663179337978363 norm:0.00024174175632651895 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.17640773952007294 norm:0.00023412678274326026 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.17626836895942688 norm:0.0002209640952059999 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.17612457275390625 norm:0.0002206114586442709 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.17597997188568115 norm:0.00022090354468673468 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.17591093480587006 norm:0.00021833903156220913 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.1757543683052063 norm:0.00020790328562725335 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.1756424903869629 norm:0.00021392086637206376 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.17557872831821442 norm:0.0002165942860301584 max memory_allocated 22562.94482421875 
[2025-03-02 08:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.1755126714706421 norm:0.00021137244766578078 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.17544594407081604 norm:0.00021360671962611377 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:01:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.23433421552181244 norm:0.001140644308179617 max memory_allocated 22563.11669921875 
[2025-03-02 08:02:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.22141894698143005 norm:0.0007193332421593368 max memory_allocated 22563.11669921875 
[2025-03-02 08:02:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.20960551500320435 norm:0.0004645698645617813 max memory_allocated 22563.11669921875 
[2025-03-02 08:03:25 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.20634464919567108 norm:0.0003686333657242358 max memory_allocated 22563.11669921875 
[2025-03-02 08:03:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.20550987124443054 norm:0.00031629306613467634 max memory_allocated 22563.11669921875 
[2025-03-02 08:04:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.20502588152885437 norm:0.00029101819382049143 max memory_allocated 22563.11669921875 
[2025-03-02 08:05:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.20470619201660156 norm:0.0002629603259265423 max memory_allocated 22563.11669921875 
[2025-03-02 08:05:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.2044847011566162 norm:0.00024886129540391266 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.20423655211925507 norm:0.00023381673963740468 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:44 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.20399822294712067 norm:0.00022855904535390437 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.2038235068321228 norm:0.00022012260160408914 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.2036474645137787 norm:0.00021078895952086896 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.20358170568943024 norm:0.0002070919144898653 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.20345142483711243 norm:0.00020457545178942382 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.20333802700042725 norm:0.00020413706079125404 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.20325630903244019 norm:0.0002020588144659996 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.2031860202550888 norm:0.00019714172231033444 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.20312893390655518 norm:0.00019897875608876348 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.20306745171546936 norm:0.00019968584820162505 max memory_allocated 22563.11669921875 
[2025-03-02 08:12:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.20297744870185852 norm:0.00019500112102832645 max memory_allocated 22563.11669921875 
[2025-03-02 08:12:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 08:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.26761525869369507 norm:0.0014050793834030628 max memory_allocated 22563.28857421875 
[2025-03-02 08:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.2537647485733032 norm:0.000820520450361073 max memory_allocated 22563.28857421875 
[2025-03-02 08:14:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.24135006964206696 norm:0.0005408336874097586 max memory_allocated 22563.28857421875 
[2025-03-02 08:14:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.23802243173122406 norm:0.0004092814342584461 max memory_allocated 22563.28857421875 
[2025-03-02 08:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.23715993762016296 norm:0.00033137903665192425 max memory_allocated 22563.28857421875 
[2025-03-02 08:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.23668529093265533 norm:0.00027803832199424505 max memory_allocated 22563.28857421875 
[2025-03-02 08:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.23633678257465363 norm:0.00024388235760852695 max memory_allocated 22563.28857421875 
[2025-03-02 08:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.2360636591911316 norm:0.00022864605125505477 max memory_allocated 22563.28857421875 
[2025-03-02 08:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.2357846200466156 norm:0.0002087693428620696 max memory_allocated 22563.28857421875 
[2025-03-02 08:17:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.23555469512939453 norm:0.0002026978909270838 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.2353603094816208 norm:0.00019337492994964123 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.23522379994392395 norm:0.00019192865875083953 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.23510223627090454 norm:0.00018827957683242857 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:12 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.2349940836429596 norm:0.00019062546198256314 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.23487895727157593 norm:0.00018309117876924574 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.23475539684295654 norm:0.0001801374601200223 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.2346915304660797 norm:0.00017977820243686438 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.2346341758966446 norm:0.0001793368865037337 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.23453927040100098 norm:0.00018124467169400305 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.2344808280467987 norm:0.00018378008098807186 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 08:24:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.3103635907173157 norm:0.005714289844036102 max memory_allocated 22563.46044921875 
[2025-03-02 08:24:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.29285556077957153 norm:0.002892170799896121 max memory_allocated 22563.46044921875 
[2025-03-02 08:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.27845942974090576 norm:0.0017161292489618063 max memory_allocated 22563.46044921875 
[2025-03-02 08:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.2744154930114746 norm:0.001150453113950789 max memory_allocated 22563.46044921875 
[2025-03-02 08:26:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.2732352912425995 norm:0.0008396236225962639 max memory_allocated 22563.46044921875 
[2025-03-02 08:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.27263617515563965 norm:0.000650799716822803 max memory_allocated 22563.46044921875 
[2025-03-02 08:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.27213770151138306 norm:0.0005197991849854589 max memory_allocated 22563.46044921875 
[2025-03-02 08:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.2717434763908386 norm:0.0004371566465124488 max memory_allocated 22563.46044921875 
[2025-03-02 08:28:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.27141058444976807 norm:0.0003772210911847651 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.2711142897605896 norm:0.00033667482784949243 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.270902156829834 norm:0.00030921894358471036 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.2707153558731079 norm:0.0002862369001377374 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.270531564950943 norm:0.00026785110821947455 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.27038484811782837 norm:0.0002564725000411272 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.2702648341655731 norm:0.00024837328237481415 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.2701783776283264 norm:0.00024181324988603592 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.2700490653514862 norm:0.00023691629758104682 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.26995205879211426 norm:0.00023059466911945492 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.26985836029052734 norm:0.00022984495444688946 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.2697564363479614 norm:0.00022366731718648225 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 08:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.345264196395874 norm:0.0031719182152301073 max memory_allocated 22563.63232421875 
[2025-03-02 08:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.32890284061431885 norm:0.001658324501477182 max memory_allocated 22563.63232421875 
[2025-03-02 08:36:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.3145262598991394 norm:0.0010254450608044863 max memory_allocated 22563.63232421875 
[2025-03-02 08:37:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.3106705844402313 norm:0.0007102527306415141 max memory_allocated 22563.63232421875 
[2025-03-02 08:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.3097071349620819 norm:0.0005699832108803093 max memory_allocated 22563.63232421875 
[2025-03-02 08:38:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.3091890215873718 norm:0.00047733259270899 max memory_allocated 22563.63232421875 
[2025-03-02 08:38:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.308767706155777 norm:0.0003927923389710486 max memory_allocated 22563.63232421875 
[2025-03-02 08:39:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.30844977498054504 norm:0.00034667173167690635 max memory_allocated 22563.63232421875 
[2025-03-02 08:39:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.30822667479515076 norm:0.0003142763744108379 max memory_allocated 22563.63232421875 
[2025-03-02 08:40:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.30801212787628174 norm:0.00029353389982134104 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.3078013062477112 norm:0.00027465098537504673 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.30764830112457275 norm:0.0002624273765832186 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.3075065612792969 norm:0.0002455556532368064 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.3073541820049286 norm:0.00024393356579821557 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.3072595000267029 norm:0.00024041419965215027 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.3071541488170624 norm:0.00023836603213567287 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.3070589601993561 norm:0.00023265357594937086 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.3069706857204437 norm:0.00024639564799144864 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.3068937659263611 norm:0.00025164513499476016 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.30681130290031433 norm:0.00025155447656288743 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 08:46:15 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 08:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.3988799452781677 norm:0.013632290996611118 max memory_allocated 22563.91943359375 
[2025-03-02 08:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.3803430497646332 norm:0.011110223829746246 max memory_allocated 22563.91943359375 
[2025-03-02 08:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.36417579650878906 norm:0.007980101741850376 max memory_allocated 22563.91943359375 
[2025-03-02 08:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.3598887324333191 norm:0.007034733425825834 max memory_allocated 22563.91943359375 
[2025-03-02 08:49:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.3587154150009155 norm:0.006186237093061209 max memory_allocated 22563.91943359375 
[2025-03-02 08:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.35793817043304443 norm:0.005433186888694763 max memory_allocated 22563.91943359375 
[2025-03-02 08:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.3573915660381317 norm:0.004858735948801041 max memory_allocated 22563.91943359375 
[2025-03-02 08:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.3570975661277771 norm:0.004798294976353645 max memory_allocated 22563.91943359375 
[2025-03-02 08:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.35684239864349365 norm:0.004554544575512409 max memory_allocated 22563.91943359375 
[2025-03-02 08:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.35651761293411255 norm:0.004392904229462147 max memory_allocated 22563.91943359375 
[2025-03-02 08:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.35627293586730957 norm:0.004036768805235624 max memory_allocated 22563.91943359375 
[2025-03-02 08:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.3559975028038025 norm:0.0038736918941140175 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.35581666231155396 norm:0.0037189568392932415 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.3557553291320801 norm:0.003683285089209676 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.35562819242477417 norm:0.0035663677845150232 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.3555198311805725 norm:0.0035656066611409187 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.35534942150115967 norm:0.003384933341294527 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.35530346632003784 norm:0.003400198183953762 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.35517898201942444 norm:0.0031776688992977142 max memory_allocated 22563.91943359375 
[2025-03-02 08:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.355124831199646 norm:0.0032444715034216642 max memory_allocated 22563.91943359375 
[2025-03-02 08:57:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 08:57:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 08:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.46470552682876587 norm:0.014512486755847931 max memory_allocated 22564.09130859375 
[2025-03-02 08:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.44259440898895264 norm:0.010421372018754482 max memory_allocated 22564.09130859375 
[2025-03-02 08:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.4243873655796051 norm:0.0076572527177631855 max memory_allocated 22564.09130859375 
[2025-03-02 08:59:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.42008066177368164 norm:0.006539321970194578 max memory_allocated 22564.09130859375 
[2025-03-02 09:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.41897255182266235 norm:0.005574563983827829 max memory_allocated 22564.09130859375 
[2025-03-02 09:00:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.4180671274662018 norm:0.004698079079389572 max memory_allocated 22564.09130859375 
[2025-03-02 09:01:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.4174598455429077 norm:0.00419238256290555 max memory_allocated 22564.09130859375 
[2025-03-02 09:02:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.41712686419487 norm:0.004151787608861923 max memory_allocated 22564.09130859375 
[2025-03-02 09:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.41672107577323914 norm:0.003850852604955435 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.41644731163978577 norm:0.003910671919584274 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.4163614809513092 norm:0.0038774320855736732 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.41609448194503784 norm:0.0038885176181793213 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.415713369846344 norm:0.003309158608317375 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.4155683219432831 norm:0.003478607162833214 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.41546830534935 norm:0.0032694225665181875 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.4153333902359009 norm:0.0033523153979331255 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:01 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.41521942615509033 norm:0.0031523355282843113 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.4151366353034973 norm:0.0032431778963655233 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.41497576236724854 norm:0.002985485829412937 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.4149251878261566 norm:0.003081267001107335 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:08:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.5768800973892212 norm:0.021735109388828278 max memory_allocated 22564.26318359375 
[2025-03-02 09:09:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.5517352223396301 norm:0.01932588219642639 max memory_allocated 22564.26318359375 
[2025-03-02 09:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.5377864241600037 norm:0.018106428906321526 max memory_allocated 22564.26318359375 
[2025-03-02 09:11:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.5318946838378906 norm:0.01874392293393612 max memory_allocated 22564.26318359375 
[2025-03-02 09:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.5290955305099487 norm:0.019025038927793503 max memory_allocated 22564.26318359375 
[2025-03-02 09:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.5273318290710449 norm:0.019335154443979263 max memory_allocated 22564.26318359375 
[2025-03-02 09:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.5256620049476624 norm:0.017537008970975876 max memory_allocated 22564.26318359375 
[2025-03-02 09:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.5251489877700806 norm:0.016997437924146652 max memory_allocated 22564.26318359375 
[2025-03-02 09:13:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.5247699618339539 norm:0.016463283449411392 max memory_allocated 22564.26318359375 
[2025-03-02 09:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.524329662322998 norm:0.016224274411797523 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.5240837931632996 norm:0.0159979946911335 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.5239357948303223 norm:0.016067130491137505 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.5234569311141968 norm:0.015369942411780357 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.5231345295906067 norm:0.014502695761620998 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.522933840751648 norm:0.01401856541633606 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.5228919386863708 norm:0.014235293492674828 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.5227053761482239 norm:0.01346593163907528 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.5226613879203796 norm:0.01305890828371048 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.5225414633750916 norm:0.01283467747271061 max memory_allocated 22564.26318359375 
[2025-03-02 09:20:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.522537112236023 norm:0.012994617223739624 max memory_allocated 22564.26318359375 
[2025-03-02 09:20:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 09:20:12 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:20:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:1.0335042476654053 norm:0.05836736410856247 max memory_allocated 22564.43505859375 
[2025-03-02 09:21:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.9675319790840149 norm:0.03968825191259384 max memory_allocated 22564.43505859375 
[2025-03-02 09:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.9316152930259705 norm:0.0337243415415287 max memory_allocated 22564.43505859375 
[2025-03-02 09:22:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.9097597599029541 norm:0.033204320818185806 max memory_allocated 22564.43505859375 
[2025-03-02 09:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.8984442949295044 norm:0.03409126028418541 max memory_allocated 22564.43505859375 
[2025-03-02 09:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.8899719715118408 norm:0.033615488559007645 max memory_allocated 22564.43505859375 
[2025-03-02 09:24:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.8832489848136902 norm:0.030557822436094284 max memory_allocated 22564.43505859375 
[2025-03-02 09:24:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.8785961866378784 norm:0.03262906149029732 max memory_allocated 22564.43505859375 
[2025-03-02 09:25:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.8760257363319397 norm:0.03047465905547142 max memory_allocated 22564.43505859375 
[2025-03-02 09:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.8730151057243347 norm:0.0313691720366478 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.8699181079864502 norm:0.029198914766311646 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.8678982257843018 norm:0.029613114893436432 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.8685614466667175 norm:0.031840234994888306 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.8669983148574829 norm:0.03014408051967621 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.8631499409675598 norm:0.02460119128227234 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.8636087775230408 norm:0.02718665450811386 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.8615175485610962 norm:0.025648240000009537 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.862098217010498 norm:0.028407644480466843 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.861582338809967 norm:0.027305305004119873 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.8623371124267578 norm:0.029178356751799583 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:29 root] (main_calib_config2.py 380): INFO 21645.847692251205
[2025-03-02 09:31:34 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 09:32:44 root] (main_calib_config2.py 159): INFO wikitext2 : 5.869137763977051
[2025-03-02 09:32:44 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 09:34:32 root] (main_calib_config2.py 159): INFO c4 : 7.373904228210449
[2025-03-02 11:10:47 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.869137763977051, 'c4': 7.373904228210449, 'results': {'winogrande': {'acc': 0.6448303078137332, 'acc_stderr': 0.013450047479569257}, 'hellaswag': {'acc': 0.5514837681736706, 'acc_stderr': 0.004963259311700567, 'acc_norm': 0.7119099780920135, 'acc_norm_stderr': 0.004519476835646774}, 'piqa': {'acc': 0.7769314472252449, 'acc_stderr': 0.009713057213018518, 'acc_norm': 0.7731229597388466, 'acc_norm_stderr': 0.009771584259215175}, 'arc_challenge': {'acc': 0.3703071672354949, 'acc_stderr': 0.01411129875167495, 'acc_norm': 0.3984641638225256, 'acc_norm_stderr': 0.014306946052735569}, 'arc_easy': {'acc': 0.6523569023569024, 'acc_stderr': 0.009771868846830907, 'acc_norm': 0.5214646464646465, 'acc_norm_stderr': 0.010250325159456656}, 'boolq': {'acc': 0.7073394495412844, 'acc_stderr': 0.007957718503192683}}, 'versions': {'winogrande': 0, 'hellaswag': 0, 'piqa': 0, 'arc_challenge': 0, 'arc_easy': 0, 'boolq': 1}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
