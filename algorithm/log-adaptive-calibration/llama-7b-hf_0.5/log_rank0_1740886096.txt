[2025-03-02 03:28:16 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.5', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.5.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 03:30:43 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-02 03:30:43 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.5.pkl
[2025-03-02 03:30:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 03:30:52 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.012378459796309471 norm:0.009004523977637291 max memory_allocated 22559.10693359375 
[2025-03-02 03:31:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.006857371889054775 norm:0.0048804571852087975 max memory_allocated 22559.10693359375 
[2025-03-02 03:32:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0048676421865820885 norm:0.003459596773609519 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.004287741146981716 norm:0.002673201262950897 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.004028345923870802 norm:0.002155791036784649 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.003947211895138025 norm:0.001806514454074204 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0037966398522257805 norm:0.0014897873625159264 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0037154185120016336 norm:0.001331313163973391 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.003688683733344078 norm:0.001153422985225916 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.003661699593067169 norm:0.001018294831737876 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.003622764488682151 norm:0.0009127381490543485 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0036038882099092007 norm:0.0008232988766394556 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0036477919202297926 norm:0.000754335371311754 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:35 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0036486145108938217 norm:0.0006942327017895877 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0036000460386276245 norm:0.000662721402477473 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.003563866252079606 norm:0.0006108942325226963 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0035593851935118437 norm:0.0005944663425907493 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.003529918845742941 norm:0.0005837313365191221 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.003535791067406535 norm:0.0005890821339562535 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0035214032977819443 norm:0.0005247881636023521 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 03:42:06 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.039147090166807175 norm:0.02486172504723072 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.023581190034747124 norm:0.013623331673443317 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:45 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.017911061644554138 norm:0.007625026628375053 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.016301032155752182 norm:0.005926037207245827 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.015581934712827206 norm:0.0050076330080628395 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.015229564160108566 norm:0.004557086620479822 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.01494862325489521 norm:0.004144330509006977 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.014747431501746178 norm:0.0038339539896696806 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.014508534222841263 norm:0.003370768390595913 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.014315863139927387 norm:0.003003213321790099 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.014182234182953835 norm:0.002722117118537426 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.014098514802753925 norm:0.0024934408720582724 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.014059649780392647 norm:0.0022629895247519016 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.01399737037718296 norm:0.001984846778213978 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:24 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.013941510580480099 norm:0.0017605102621018887 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.013918341137468815 norm:0.0016111911972984672 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.013895773328840733 norm:0.0015906509943306446 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.01393939834088087 norm:0.001564738224260509 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.013906965963542461 norm:0.00158152065705508 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.013912057504057884 norm:0.0014108767500147223 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 03:53:22 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:53:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.09973893314599991 norm:0.027211155742406845 max memory_allocated 22559.45068359375 
[2025-03-02 03:54:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.053208258002996445 norm:0.015025286003947258 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.03717188537120819 norm:0.010393672622740269 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.03138479217886925 norm:0.00963590294122696 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.02910958230495453 norm:0.008318031206727028 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.02768881991505623 norm:0.00727370148524642 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.026700785383582115 norm:0.0070494418032467365 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.026341009885072708 norm:0.007132434286177158 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.026253702118992805 norm:0.006893395446240902 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.026008814573287964 norm:0.006555447820574045 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.02586205303668976 norm:0.006466907449066639 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.02574865147471428 norm:0.0061894855462014675 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.025479497388005257 norm:0.005839457735419273 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.02540605328977108 norm:0.005731021054089069 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.025287093594670296 norm:0.005402605980634689 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.025220997631549835 norm:0.005340063013136387 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.025289103388786316 norm:0.005212078802287579 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.025200255215168 norm:0.005483120679855347 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.0251117255538702 norm:0.005073800217360258 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.025152644142508507 norm:0.004974699113518 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.041299283504486084 norm:0.005290594417601824 max memory_allocated 22559.50732421875 
[2025-03-02 04:05:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.03143467754125595 norm:0.0021309920120984316 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.02709672786295414 norm:0.0010168044827878475 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.02554844506084919 norm:0.0005349491257220507 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.024739429354667664 norm:0.00031084087095223367 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.024316800758242607 norm:0.00022839019948150963 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.02411547303199768 norm:0.0001813176495488733 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.024044519290328026 norm:0.00016888069512788206 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.024037819355726242 norm:0.00016683925059624016 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.024015137925744057 norm:0.00015922602324280888 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.023987067863345146 norm:0.00016565209079999477 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.02397235669195652 norm:0.00015894498210400343 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.023977005854249 norm:0.00016900469199754298 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.02395886369049549 norm:0.00016579445218667388 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.023953057825565338 norm:0.00016436805890407413 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.023938994854688644 norm:0.00015867238107603043 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.023931654170155525 norm:0.00015903348685242236 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.02393779717385769 norm:0.00016684160800650716 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.02391381375491619 norm:0.00016007732483558357 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.023916851729154587 norm:0.00015984060883056372 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 04:16:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.05963502451777458 norm:0.004232093691825867 max memory_allocated 22559.67919921875 
[2025-03-02 04:17:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.04583042487502098 norm:0.0016258549876511097 max memory_allocated 22559.67919921875 
[2025-03-02 04:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.038758859038352966 norm:0.0008573097875341773 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.03616327792406082 norm:0.0005628825747407973 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.03492532670497894 norm:0.0004282921727281064 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.03432255983352661 norm:0.0003767094458453357 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.034082334488630295 norm:0.00034107573446817696 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.03395809978246689 norm:0.0003169183910358697 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.033812765032052994 norm:0.0002919603721238673 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.033704791218042374 norm:0.00029352103592827916 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.033671289682388306 norm:0.00028754243976436555 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.03363227844238281 norm:0.00028134870808571577 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.03357484191656113 norm:0.0002791964798234403 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.03353872522711754 norm:0.00027218894683755934 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.033512748777866364 norm:0.00027110689552500844 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.03348097950220108 norm:0.00026465384871698916 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.03348472714424133 norm:0.0002690460532903671 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.03347199782729149 norm:0.0002605938061606139 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.03345336765050888 norm:0.0002602769818622619 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.03343932703137398 norm:0.00026187492767348886 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 04:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.06354253739118576 norm:0.003042096272110939 max memory_allocated 22559.85107421875 
[2025-03-02 04:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.050499483942985535 norm:0.0012515549315139651 max memory_allocated 22559.85107421875 
[2025-03-02 04:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.04398464784026146 norm:0.0007335811969824135 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.04152408242225647 norm:0.0004834939318243414 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.04025338217616081 norm:0.00038528433651663363 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.039577651768922806 norm:0.00031725692679174244 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.03922780975699425 norm:0.0003005112521350384 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.039083532989025116 norm:0.00029118836391717196 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.03895872086286545 norm:0.00028072294662706554 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.03882865980267525 norm:0.0002695590374059975 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.03874051198363304 norm:0.0002773868036456406 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.03864329680800438 norm:0.00027588201919570565 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.03858594223856926 norm:0.0002810897130984813 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.03853415697813034 norm:0.0002777061890810728 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.03849036246538162 norm:0.00027561106253415346 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.038474828004837036 norm:0.00027363444678485394 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.03848681598901749 norm:0.0002805778640322387 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.03848649933934212 norm:0.00027291662991046906 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.03849906846880913 norm:0.00027139278245158494 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.03848227113485336 norm:0.0002654512063600123 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 04:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.05992652475833893 norm:0.002540670335292816 max memory_allocated 22560.02294921875 
[2025-03-02 04:39:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.049842897802591324 norm:0.001074710744433105 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.044621556997299194 norm:0.000543776957783848 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.04281186684966087 norm:0.0003068038495257497 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.04188675433397293 norm:0.0002252599224448204 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.041494742035865784 norm:0.00019475941371638328 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.041343849152326584 norm:0.00019671322661451995 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.04131224751472473 norm:0.00023500443785451353 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.04118434712290764 norm:0.00018951896345242858 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.04108157008886337 norm:0.00018036981055047363 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:27 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.041034091264009476 norm:0.0001789203379303217 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.04101087898015976 norm:0.0001834940630942583 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.04098351299762726 norm:0.00018894323147833347 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.04095589369535446 norm:0.00019078853074461222 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.04097258672118187 norm:0.0001917318149935454 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.04094863682985306 norm:0.00018954271217808127 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.04093440622091293 norm:0.00019657507073134184 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.04093654453754425 norm:0.00018935275147669017 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:52 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.0409361906349659 norm:0.00018890792853198946 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.04092158377170563 norm:0.00018625349912326783 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 04:50:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.07417844980955124 norm:0.0022290698252618313 max memory_allocated 22560.19482421875 
[2025-03-02 04:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.06105729937553406 norm:0.0009262285311706364 max memory_allocated 22560.19482421875 
[2025-03-02 04:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.054417893290519714 norm:0.0005549023044295609 max memory_allocated 22560.19482421875 
[2025-03-02 04:51:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.05204140767455101 norm:0.0004031257121823728 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.05085400119423866 norm:0.000301654014037922 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.05022041127085686 norm:0.0002694843278732151 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.049964383244514465 norm:0.0002580778091214597 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.04975709319114685 norm:0.00023774892906658351 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.04965195804834366 norm:0.000249562319368124 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.0496353954076767 norm:0.0002314104203833267 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.049476828426122665 norm:0.0002306748938281089 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.04945248365402222 norm:0.00022467751114163548 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.0494174063205719 norm:0.00022913675638847053 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.04941973835229874 norm:0.00021988344087731093 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.04938317835330963 norm:0.0002260680339531973 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.04940326511859894 norm:0.00022387225180864334 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.04939823970198631 norm:0.0002167138154618442 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.04939008504152298 norm:0.0002269939868710935 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.04937403276562691 norm:0.00022793770767748356 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.049351226538419724 norm:0.00023127133317757398 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.08353502303361893 norm:0.0021615084260702133 max memory_allocated 22560.36669921875 
[2025-03-02 05:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.06831876188516617 norm:0.0008750095148570836 max memory_allocated 22560.36669921875 
[2025-03-02 05:02:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.060320623219013214 norm:0.00048801981029100716 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.05762293189764023 norm:0.0003478436265140772 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.056246377527713776 norm:0.00028765207389369607 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.055527813732624054 norm:0.0002563288144301623 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.05517686903476715 norm:0.00024386036966461688 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.05494074895977974 norm:0.00022467717644758523 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.05480420961976051 norm:0.0002258449385408312 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.05475125461816788 norm:0.0002317347243661061 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.05472593382000923 norm:0.0002274239232065156 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.05462733283638954 norm:0.0002286480594193563 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.054540008306503296 norm:0.0002191364037571475 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.05447271093726158 norm:0.0002240043831989169 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.054434578865766525 norm:0.0002227396471425891 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.05439826846122742 norm:0.00022429658565670252 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.054494619369506836 norm:0.00024266596301458776 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.05445530265569687 norm:0.00023131365014705807 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.05443090945482254 norm:0.00022572409943677485 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.05442073196172714 norm:0.00022325810277834535 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 05:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.08806873112916946 norm:0.0019391848472878337 max memory_allocated 22560.53857421875 
[2025-03-02 05:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.07347044348716736 norm:0.0007880065240897238 max memory_allocated 22560.53857421875 
[2025-03-02 05:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.06608393043279648 norm:0.0004696481046266854 max memory_allocated 22560.53857421875 
[2025-03-02 05:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.06335997581481934 norm:0.0003304439887870103 max memory_allocated 22560.53857421875 
[2025-03-02 05:14:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.06207249313592911 norm:0.00026926747523248196 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.06139303743839264 norm:0.00024746928829699755 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.06108612194657326 norm:0.00023090878676157445 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.06092953681945801 norm:0.00021615534205920994 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.060784466564655304 norm:0.00021306802227627486 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.06064638867974281 norm:0.00019846086797770113 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.06058192998170853 norm:0.00019552072626538575 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.060490213334560394 norm:0.00019081556820310652 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.06043947860598564 norm:0.00018991707474924624 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.06041083112359047 norm:0.00018934544641524553 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.06037367135286331 norm:0.00019076059106737375 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.060336798429489136 norm:0.00019749498460441828 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.06031635403633118 norm:0.00019790767692029476 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.06033889949321747 norm:0.00019335934484843165 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.06031385809183121 norm:0.000190042017493397 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.06029844284057617 norm:0.00018942425958812237 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 05:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.07952724397182465 norm:0.0020677056163549423 max memory_allocated 22560.71044921875 
[2025-03-02 05:24:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.07039152830839157 norm:0.0009068757062777877 max memory_allocated 22560.71044921875 
[2025-03-02 05:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.06485161930322647 norm:0.0004843058704864234 max memory_allocated 22560.71044921875 
[2025-03-02 05:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.0629427507519722 norm:0.0003074121195822954 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.06203571707010269 norm:0.00023121669073589146 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.061554357409477234 norm:0.00019040769257117063 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.061318062245845795 norm:0.00017898280930239707 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.061157260090112686 norm:0.0001614748762222007 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.06111593544483185 norm:0.00015863862063270062 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.06104911118745804 norm:0.00015495659317821264 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.060973044484853745 norm:0.0001545048871776089 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.06094956398010254 norm:0.00015142056508921087 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.06091859191656113 norm:0.00014810668653808534 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.06089818850159645 norm:0.00014392287994269282 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.06090978533029556 norm:0.00014577541151084006 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.060907118022441864 norm:0.0001429555704817176 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.06091217324137688 norm:0.0001509432913735509 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.06089169532060623 norm:0.00014568347251042724 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.060877811163663864 norm:0.000146235222928226 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.06090332195162773 norm:0.00014519834076054394 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 05:35:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.0820607841014862 norm:0.002061612904071808 max memory_allocated 22560.88232421875 
[2025-03-02 05:35:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.07228315621614456 norm:0.0009823323925957084 max memory_allocated 22560.88232421875 
[2025-03-02 05:36:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.06642322242259979 norm:0.0005454979836940765 max memory_allocated 22560.88232421875 
[2025-03-02 05:36:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.06448744237422943 norm:0.0003451797238085419 max memory_allocated 22560.88232421875 
[2025-03-02 05:37:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.06355433911085129 norm:0.0002451653126627207 max memory_allocated 22560.88232421875 
[2025-03-02 05:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.06305622309446335 norm:0.00019867099763359874 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.06282538920640945 norm:0.00018135482969228178 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.06267905980348587 norm:0.00016594449698459357 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.06261935085058212 norm:0.0001656784297665581 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.062563456594944 norm:0.00016115994367282838 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.06249881535768509 norm:0.00015841491403989494 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.062440041452646255 norm:0.00015747762518003583 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.06246047094464302 norm:0.00015736283967271447 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.062423016875982285 norm:0.00015487932250835001 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.06239162012934685 norm:0.00015273610188160092 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.0623796284198761 norm:0.00015226226241793483 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.0623677596449852 norm:0.00014909087622072548 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.062361907213926315 norm:0.00015285708650480956 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.06236492469906807 norm:0.00015293445903807878 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.062367625534534454 norm:0.00015571046969853342 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 05:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.08266612887382507 norm:0.0013460969785228372 max memory_allocated 22561.05419921875 
[2025-03-02 05:46:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.07412257790565491 norm:0.0006374968797899783 max memory_allocated 22561.05419921875 
[2025-03-02 05:47:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.06867142021656036 norm:0.00037432933459058404 max memory_allocated 22561.05419921875 
[2025-03-02 05:48:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.06684570014476776 norm:0.00026886057457886636 max memory_allocated 22561.05419921875 
[2025-03-02 05:48:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.06585638225078583 norm:0.00021724231191910803 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.06530146300792694 norm:0.000191052706213668 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.06501852720975876 norm:0.0001740512961987406 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:14 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.06482250988483429 norm:0.00016339584544766694 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.06472927331924438 norm:0.000159134971909225 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.06462983042001724 norm:0.00014817906776443124 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.06455080211162567 norm:0.0001480605424148962 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.06449943780899048 norm:0.0001437300961697474 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.06449294090270996 norm:0.00014212590758688748 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.06444456428289413 norm:0.0001424601796315983 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.06442447006702423 norm:0.0001382566842949018 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.0644165650010109 norm:0.00013634719653055072 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.06440892815589905 norm:0.0001380101020913571 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.06440602242946625 norm:0.00013570011651609093 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.06441574543714523 norm:0.0001373392587993294 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.06441827863454819 norm:0.0001389822573401034 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 05:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.08377693593502045 norm:0.0013401958858594298 max memory_allocated 22561.22607421875 
[2025-03-02 05:58:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.07578472048044205 norm:0.00060077547095716 max memory_allocated 22561.22607421875 
[2025-03-02 05:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.07059206813573837 norm:0.00034212530590593815 max memory_allocated 22561.22607421875 
[2025-03-02 05:59:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.06882443279027939 norm:0.00023663458705414087 max memory_allocated 22561.22607421875 
[2025-03-02 05:59:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.06794102489948273 norm:0.00019455593428574502 max memory_allocated 22561.22607421875 
[2025-03-02 06:00:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.06743185222148895 norm:0.0001725008332869038 max memory_allocated 22561.22607421875 
[2025-03-02 06:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.06716147065162659 norm:0.00015788571909070015 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.06701041013002396 norm:0.00014679937157779932 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.0669325739145279 norm:0.00014162769366521388 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.06685108691453934 norm:0.0001383883209200576 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.0667838454246521 norm:0.00013519427739083767 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.0667353942990303 norm:0.00013207118900027126 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.0667039006948471 norm:0.0001315834524575621 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.06668632477521896 norm:0.00013110086729284376 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:21 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.06667371094226837 norm:0.00013193194172345102 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.06664718687534332 norm:0.00013111234875395894 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.06662793457508087 norm:0.00013111182488501072 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.06660146266222 norm:0.00013227792805992067 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.06657569110393524 norm:0.00013103376841172576 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.06656578183174133 norm:0.00013324865722097456 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:08:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.09208979457616806 norm:0.0025710912887007 max memory_allocated 22561.39794921875 
[2025-03-02 06:09:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.08170239627361298 norm:0.001153591088950634 max memory_allocated 22561.39794921875 
[2025-03-02 06:09:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.07550443708896637 norm:0.0006418267730623484 max memory_allocated 22561.39794921875 
[2025-03-02 06:10:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.07342936098575592 norm:0.00041490609874017537 max memory_allocated 22561.39794921875 
[2025-03-02 06:11:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.07236384600400925 norm:0.00030136812711134553 max memory_allocated 22561.39794921875 
[2025-03-02 06:11:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.07180431485176086 norm:0.00023899351072032005 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.07153052091598511 norm:0.00020574699738062918 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.07136312127113342 norm:0.00018527742940932512 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.07123193889856339 norm:0.00017740833573043346 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.07113103568553925 norm:0.00016851101827342063 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.07101929187774658 norm:0.00016065724776126444 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.07096400856971741 norm:0.00015353236813098192 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.07094292342662811 norm:0.00014957606617826968 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.07091551274061203 norm:0.00014979181287344545 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.0708824172616005 norm:0.00014752861170563847 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.07084374874830246 norm:0.0001464903907617554 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.07080882787704468 norm:0.00014736520824953914 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.07079237699508667 norm:0.00014609168283641338 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.07077711820602417 norm:0.0001477474725106731 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.07076267898082733 norm:0.0001476118341088295 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 06:20:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.09379425644874573 norm:0.001631417078897357 max memory_allocated 22561.56982421875 
[2025-03-02 06:20:39 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.0852072536945343 norm:0.000735332490876317 max memory_allocated 22561.56982421875 
[2025-03-02 06:21:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.0793323665857315 norm:0.0004156364593654871 max memory_allocated 22561.56982421875 
[2025-03-02 06:21:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.0773262232542038 norm:0.0002762092917691916 max memory_allocated 22561.56982421875 
[2025-03-02 06:22:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.07635846734046936 norm:0.00021168832608964294 max memory_allocated 22561.56982421875 
[2025-03-02 06:22:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.07586696743965149 norm:0.00018273467139806598 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.07564292848110199 norm:0.00016953377053141594 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.07544279843568802 norm:0.0001499826757935807 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.07530929148197174 norm:0.00014278195158112794 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.07525696605443954 norm:0.00013846169167663902 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.07519006729125977 norm:0.0001440525084035471 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.07518584281206131 norm:0.00014161618310026824 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.07514390349388123 norm:0.000142273202072829 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.07509170472621918 norm:0.00013611852773465216 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.07503729313611984 norm:0.00013388450315687805 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.07501011341810226 norm:0.0001317455171374604 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.07499217987060547 norm:0.00012970446550752968 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.0749746710062027 norm:0.0001313246611971408 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.07496350258588791 norm:0.0001352939725620672 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.07496359944343567 norm:0.00013526783732231706 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 06:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.10229838639497757 norm:0.001658782479353249 max memory_allocated 22561.74169921875 
[2025-03-02 06:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.09244974702596664 norm:0.0007193887140601873 max memory_allocated 22561.74169921875 
[2025-03-02 06:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.08607377856969833 norm:0.00040031480602920055 max memory_allocated 22561.74169921875 
[2025-03-02 06:33:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.08410955965518951 norm:0.0002829812001436949 max memory_allocated 22561.74169921875 
[2025-03-02 06:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.08307152986526489 norm:0.00023175090609584004 max memory_allocated 22561.74169921875 
[2025-03-02 06:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.08254928141832352 norm:0.00019735601381398737 max memory_allocated 22561.74169921875 
[2025-03-02 06:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.08231333643198013 norm:0.0001804842904675752 max memory_allocated 22561.74169921875 
[2025-03-02 06:35:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.0820923000574112 norm:0.00016335624968633056 max memory_allocated 22561.74169921875 
[2025-03-02 06:35:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.0819438099861145 norm:0.00015412652282975614 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.08185969293117523 norm:0.00015102370525710285 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.08178050816059113 norm:0.00014882917457725853 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.08173952996730804 norm:0.00015172116400208324 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.08165974915027618 norm:0.00014863711840007454 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.08159103244543076 norm:0.00014584610471501946 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.08157464116811752 norm:0.00014356682368088514 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.08154648542404175 norm:0.00014157961413729936 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.08152131736278534 norm:0.00014160637510940433 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.08149052411317825 norm:0.00014106123126111925 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.08146396279335022 norm:0.0001423728244844824 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.08142775297164917 norm:0.00013980815128888935 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 06:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.11428489536046982 norm:0.002294897800311446 max memory_allocated 22561.91357421875 
[2025-03-02 06:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.10326165705919266 norm:0.0010169045999646187 max memory_allocated 22561.91357421875 
[2025-03-02 06:43:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.0958368256688118 norm:0.0005705637158825994 max memory_allocated 22561.91357421875 
[2025-03-02 06:44:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.09353665262460709 norm:0.00037751777563244104 max memory_allocated 22561.91357421875 
[2025-03-02 06:44:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.09241628646850586 norm:0.00027810546453110874 max memory_allocated 22561.91357421875 
[2025-03-02 06:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.0919349268078804 norm:0.00022968887060415 max memory_allocated 22561.91357421875 
[2025-03-02 06:45:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.09166781604290009 norm:0.0002064291329588741 max memory_allocated 22561.91357421875 
[2025-03-02 06:46:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.0914488211274147 norm:0.00018563654157333076 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.0913221687078476 norm:0.00017660045705270022 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.0912293940782547 norm:0.0001727183989714831 max memory_allocated 22561.91357421875 
[2025-03-02 06:48:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.09113097190856934 norm:0.00016836021677590907 max memory_allocated 22561.91357421875 
[2025-03-02 06:48:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.09105046838521957 norm:0.00016038573812693357 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.09099935740232468 norm:0.0001594009663676843 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.0909242331981659 norm:0.00015676651673857123 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.09088123589754105 norm:0.00015606987290084362 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.09084855020046234 norm:0.00015567548689432442 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.09081588685512543 norm:0.00015238540072459728 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:58 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.09080587327480316 norm:0.0001529937726445496 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.09076234698295593 norm:0.00015143751807045192 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.0907285138964653 norm:0.00015065522165969014 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 06:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.12447286397218704 norm:0.0011142519069835544 max memory_allocated 22562.08544921875 
[2025-03-02 06:54:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.1149042621254921 norm:0.0005833403556607664 max memory_allocated 22562.08544921875 
[2025-03-02 06:54:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.10788464546203613 norm:0.0003568431711755693 max memory_allocated 22562.08544921875 
[2025-03-02 06:55:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.10579628497362137 norm:0.0002807587734423578 max memory_allocated 22562.08544921875 
[2025-03-02 06:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.1047498807311058 norm:0.0002304377849213779 max memory_allocated 22562.08544921875 
[2025-03-02 06:56:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.10436531156301498 norm:0.00020527385640889406 max memory_allocated 22562.08544921875 
[2025-03-02 06:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.10411850363016129 norm:0.00018959846056532115 max memory_allocated 22562.08544921875 
[2025-03-02 06:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.1039341390132904 norm:0.0001772465620888397 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.10380830615758896 norm:0.00017118007235694677 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.1036752313375473 norm:0.00016598738147877157 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.10355484485626221 norm:0.0001612104388186708 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.10348810255527496 norm:0.0001600817049620673 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.10340283811092377 norm:0.00015500902372878045 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.10335597395896912 norm:0.0001534418697701767 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.1033201664686203 norm:0.00015150444232858717 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.10329264402389526 norm:0.00015110813546925783 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.10325907915830612 norm:0.0001490549766458571 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.1032228022813797 norm:0.00014860255760140717 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.10319674015045166 norm:0.00014804390957579017 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.10316874086856842 norm:0.00014894902415107936 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:05:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.14208093285560608 norm:0.0013925815001130104 max memory_allocated 22562.25732421875 
[2025-03-02 07:05:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.13193315267562866 norm:0.0006614532903768122 max memory_allocated 22562.25732421875 
[2025-03-02 07:06:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.12440427392721176 norm:0.0003923180920537561 max memory_allocated 22562.25732421875 
[2025-03-02 07:06:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.12210480868816376 norm:0.00029661678127013147 max memory_allocated 22562.25732421875 
[2025-03-02 07:07:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.12099473923444748 norm:0.0002445518330205232 max memory_allocated 22562.25732421875 
[2025-03-02 07:07:49 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.12059096992015839 norm:0.00021853283396922052 max memory_allocated 22562.25732421875 
[2025-03-02 07:08:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.12033984065055847 norm:0.00019949501438532025 max memory_allocated 22562.25732421875 
[2025-03-02 07:08:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.12014484405517578 norm:0.00019005005015060306 max memory_allocated 22562.25732421875 
[2025-03-02 07:09:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.11993575096130371 norm:0.0001822319463826716 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.11980246752500534 norm:0.00017576946993358433 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.11972657591104507 norm:0.00017539836699143052 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.11965877562761307 norm:0.00017596562975086272 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.11957135051488876 norm:0.00016746485198382288 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.11949847638607025 norm:0.00016893786960281432 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.11942852288484573 norm:0.00016785465413704515 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.1193617731332779 norm:0.0001636897213757038 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.11930452287197113 norm:0.00016205679276026785 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.11925403773784637 norm:0.00016105121176224202 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.11921979486942291 norm:0.00015952037938404828 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.11919751018285751 norm:0.0001575916539877653 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 07:16:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.16914960741996765 norm:0.002370677189901471 max memory_allocated 22562.42919921875 
[2025-03-02 07:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.15639787912368774 norm:0.001097441534511745 max memory_allocated 22562.42919921875 
[2025-03-02 07:17:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.14737427234649658 norm:0.000667984364554286 max memory_allocated 22562.42919921875 
[2025-03-02 07:17:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.14457352459430695 norm:0.00048759407945908606 max memory_allocated 22562.42919921875 
[2025-03-02 07:18:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.14347055554389954 norm:0.00040453069959767163 max memory_allocated 22562.42919921875 
[2025-03-02 07:19:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.14292988181114197 norm:0.0003407105104997754 max memory_allocated 22562.42919921875 
[2025-03-02 07:19:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.1426406055688858 norm:0.0003129280812572688 max memory_allocated 22562.42919921875 
[2025-03-02 07:20:09 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.14231866598129272 norm:0.0002762256481219083 max memory_allocated 22562.42919921875 
[2025-03-02 07:20:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.1420312523841858 norm:0.0002545564784668386 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.1418246030807495 norm:0.0002455538196954876 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.14167779684066772 norm:0.00023453700123354793 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.14156793057918549 norm:0.0002303887449670583 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.1414301097393036 norm:0.00021900306455790997 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.14131063222885132 norm:0.00021876994287595153 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.14121036231517792 norm:0.00022269546752795577 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.1411595642566681 norm:0.00022389031073544174 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.14109846949577332 norm:0.00021448940970003605 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.14101846516132355 norm:0.00021525169722735882 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.14098744094371796 norm:0.0002141083823516965 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.1409446746110916 norm:0.00021083388128317893 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 07:27:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.19540409743785858 norm:0.001963161863386631 max memory_allocated 22562.60107421875 
[2025-03-02 07:28:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.18331287801265717 norm:0.0008476843941025436 max memory_allocated 22562.60107421875 
[2025-03-02 07:28:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.17342984676361084 norm:0.0005361057119444013 max memory_allocated 22562.60107421875 
[2025-03-02 07:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.17050668597221375 norm:0.00041135100764222443 max memory_allocated 22562.60107421875 
[2025-03-02 07:29:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.169343501329422 norm:0.00035231944639235735 max memory_allocated 22562.60107421875 
[2025-03-02 07:30:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.1688729226589203 norm:0.00031663101981393993 max memory_allocated 22562.60107421875 
[2025-03-02 07:30:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.1685425192117691 norm:0.00028812597156502306 max memory_allocated 22562.60107421875 
[2025-03-02 07:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.1682582050561905 norm:0.00026694475673139095 max memory_allocated 22562.60107421875 
[2025-03-02 07:31:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.16804523766040802 norm:0.0002607337955851108 max memory_allocated 22562.60107421875 
[2025-03-02 07:32:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.1678486466407776 norm:0.000246790616074577 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.16768740117549896 norm:0.0002378717763349414 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.16755734384059906 norm:0.00023226416669785976 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.16743318736553192 norm:0.00022628935403190553 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.16733138263225555 norm:0.00022195541532710195 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.1672225445508957 norm:0.000224004324991256 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.16712550818920135 norm:0.0002266282681375742 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.16704988479614258 norm:0.00022749831259716302 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.16700878739356995 norm:0.00021328363800421357 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.16695356369018555 norm:0.00022431113757193089 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.16688090562820435 norm:0.00022559273929800838 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 07:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.22605939209461212 norm:0.00260831112973392 max memory_allocated 22562.77294921875 
[2025-03-02 07:39:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.21249286830425262 norm:0.0013424803037196398 max memory_allocated 22562.77294921875 
[2025-03-02 07:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.2019001841545105 norm:0.0008252077968791127 max memory_allocated 22562.77294921875 
[2025-03-02 07:40:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.1987035870552063 norm:0.0005877550574950874 max memory_allocated 22562.77294921875 
[2025-03-02 07:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.19766844809055328 norm:0.00045651133405044675 max memory_allocated 22562.77294921875 
[2025-03-02 07:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.19704857468605042 norm:0.00037820072611793876 max memory_allocated 22562.77294921875 
[2025-03-02 07:42:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.19668468832969666 norm:0.0003338649694342166 max memory_allocated 22562.77294921875 
[2025-03-02 07:42:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.19637273252010345 norm:0.0003039674193132669 max memory_allocated 22562.77294921875 
[2025-03-02 07:43:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.1961401104927063 norm:0.000281129265204072 max memory_allocated 22562.77294921875 
[2025-03-02 07:43:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.19592036306858063 norm:0.00026747435913421214 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.1957252323627472 norm:0.0002580820582807064 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.19558003544807434 norm:0.000256655621342361 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:24 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.19542965292930603 norm:0.0002483153366483748 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.19533351063728333 norm:0.00024262990336865187 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.1952321082353592 norm:0.00024163427588064224 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.19509392976760864 norm:0.00023639193386770785 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.19501568377017975 norm:0.00023728623636998236 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.19494850933551788 norm:0.00023726385552436113 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.1948700249195099 norm:0.00023727453663013875 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.1948288232088089 norm:0.00023444330145139247 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 07:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.2616695463657379 norm:0.003914622589945793 max memory_allocated 22562.94482421875 
[2025-03-02 07:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.24761047959327698 norm:0.002017382998019457 max memory_allocated 22562.94482421875 
[2025-03-02 07:51:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.23621784150600433 norm:0.0012109546223655343 max memory_allocated 22562.94482421875 
[2025-03-02 07:51:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.23285703361034393 norm:0.0008324864320456982 max memory_allocated 22562.94482421875 
[2025-03-02 07:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.23163698613643646 norm:0.0006210065330378711 max memory_allocated 22562.94482421875 
[2025-03-02 07:52:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.23094771802425385 norm:0.0004975583287887275 max memory_allocated 22562.94482421875 
[2025-03-02 07:53:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.2306397259235382 norm:0.0004332986718509346 max memory_allocated 22562.94482421875 
[2025-03-02 07:53:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.2303272783756256 norm:0.00037544334190897644 max memory_allocated 22562.94482421875 
[2025-03-02 07:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.2300119251012802 norm:0.0003448275092523545 max memory_allocated 22562.94482421875 
[2025-03-02 07:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.22983697056770325 norm:0.00032133294735103846 max memory_allocated 22562.94482421875 
[2025-03-02 07:55:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.22963577508926392 norm:0.00030743531533516943 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.22943632304668427 norm:0.00029799179174005985 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.22926387190818787 norm:0.000286782014882192 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.2291477769613266 norm:0.0002820570662152022 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.22905482351779938 norm:0.0002807242562994361 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.22895528376102448 norm:0.00028188471333123744 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.22886203229427338 norm:0.0002745920210145414 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:24 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.22876088321208954 norm:0.00027167893131263554 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.22869370877742767 norm:0.0002735984162427485 max memory_allocated 22562.94482421875 
[2025-03-02 08:00:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.22865478694438934 norm:0.0002738122711889446 max memory_allocated 22562.94482421875 
[2025-03-02 08:00:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:01:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.2969541549682617 norm:0.0018036493565887213 max memory_allocated 22563.11669921875 
[2025-03-02 08:01:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.28343862295150757 norm:0.0010405649663880467 max memory_allocated 22563.11669921875 
[2025-03-02 08:02:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.2711490988731384 norm:0.0006529733655042946 max memory_allocated 22563.11669921875 
[2025-03-02 08:02:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.26760047674179077 norm:0.0004908707924187183 max memory_allocated 22563.11669921875 
[2025-03-02 08:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.26657170057296753 norm:0.0004086350672878325 max memory_allocated 22563.11669921875 
[2025-03-02 08:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.26615390181541443 norm:0.00036953564267605543 max memory_allocated 22563.11669921875 
[2025-03-02 08:04:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.2657967805862427 norm:0.00033724415698088706 max memory_allocated 22563.11669921875 
[2025-03-02 08:05:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.26553353667259216 norm:0.00031504163052886724 max memory_allocated 22563.11669921875 
[2025-03-02 08:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.26529034972190857 norm:0.00029997393721714616 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.2650616765022278 norm:0.0002905961009673774 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.2648860812187195 norm:0.000282697263173759 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.264730304479599 norm:0.00027499767020344734 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.2646767497062683 norm:0.00027442912687547505 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.2645595073699951 norm:0.0002661397447809577 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.26443198323249817 norm:0.00026355721638537943 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.26436686515808105 norm:0.0002608847280498594 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.2642788887023926 norm:0.0002650718670338392 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.2642095386981964 norm:0.00026129427715204656 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.26414191722869873 norm:0.00026318334857933223 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.2640584409236908 norm:0.00026216174592263997 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 08:12:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.3401722013950348 norm:0.002771650440990925 max memory_allocated 22563.28857421875 
[2025-03-02 08:13:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.3253357708454132 norm:0.0015584728680551052 max memory_allocated 22563.28857421875 
[2025-03-02 08:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.31224843859672546 norm:0.0009797632228583097 max memory_allocated 22563.28857421875 
[2025-03-02 08:14:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.3084806799888611 norm:0.0006956594297662377 max memory_allocated 22563.28857421875 
[2025-03-02 08:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.3074677288532257 norm:0.0005427693831734359 max memory_allocated 22563.28857421875 
[2025-03-02 08:15:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.3068751096725464 norm:0.00044239970156922936 max memory_allocated 22563.28857421875 
[2025-03-02 08:15:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.30652958154678345 norm:0.0003829118504654616 max memory_allocated 22563.28857421875 
[2025-03-02 08:16:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.3062073588371277 norm:0.00033661763882264495 max memory_allocated 22563.28857421875 
[2025-03-02 08:16:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.3059375286102295 norm:0.00031224629492498934 max memory_allocated 22563.28857421875 
[2025-03-02 08:17:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.30573922395706177 norm:0.00029456167249009013 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.3055775761604309 norm:0.00028276772354729474 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.30541086196899414 norm:0.0002716929011512548 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.30529075860977173 norm:0.00026642801822163165 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.3051987588405609 norm:0.0002662414335645735 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.30505889654159546 norm:0.00025934999575838447 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.30496978759765625 norm:0.00025386278866790235 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.30487918853759766 norm:0.0002563140296842903 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.30478569865226746 norm:0.0002560288703534752 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.30473968386650085 norm:0.0002543932059779763 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.3046818971633911 norm:0.00025487877428531647 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 08:23:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.39899149537086487 norm:0.011862285435199738 max memory_allocated 22563.46044921875 
[2025-03-02 08:24:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.3770802617073059 norm:0.005784426350146532 max memory_allocated 22563.46044921875 
[2025-03-02 08:24:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.3606167733669281 norm:0.003365828888490796 max memory_allocated 22563.46044921875 
[2025-03-02 08:25:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.35547906160354614 norm:0.0021998449228703976 max memory_allocated 22563.46044921875 
[2025-03-02 08:25:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.3538682162761688 norm:0.0015804219292476773 max memory_allocated 22563.46044921875 
[2025-03-02 08:26:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.35303962230682373 norm:0.001199657446704805 max memory_allocated 22563.46044921875 
[2025-03-02 08:27:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.35241034626960754 norm:0.000942918355576694 max memory_allocated 22563.46044921875 
[2025-03-02 08:27:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.3519308567047119 norm:0.0007711976650170982 max memory_allocated 22563.46044921875 
[2025-03-02 08:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.3515474498271942 norm:0.0006494561675935984 max memory_allocated 22563.46044921875 
[2025-03-02 08:28:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.35123908519744873 norm:0.0005668108933605254 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.3509480953216553 norm:0.0005090656923130155 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.3507143259048462 norm:0.00046555569861084223 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.3505246639251709 norm:0.0004344423650763929 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.35036274790763855 norm:0.00040920087485574186 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.35019633173942566 norm:0.00039144372567534447 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.35005950927734375 norm:0.0003771995543502271 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.34995245933532715 norm:0.0003684167459141463 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.3498838543891907 norm:0.00035975390346720815 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.34978723526000977 norm:0.0003553359129000455 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.34969794750213623 norm:0.000349865440512076 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 08:34:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.4402743875980377 norm:0.005961006972938776 max memory_allocated 22563.63232421875 
[2025-03-02 08:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.4218999445438385 norm:0.002999207703396678 max memory_allocated 22563.63232421875 
[2025-03-02 08:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.4062751233577728 norm:0.0018169357208535075 max memory_allocated 22563.63232421875 
[2025-03-02 08:36:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.40179795026779175 norm:0.0012460487196221948 max memory_allocated 22563.63232421875 
[2025-03-02 08:37:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.4006038010120392 norm:0.0009597180760465562 max memory_allocated 22563.63232421875 
[2025-03-02 08:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.4000236988067627 norm:0.0007830613758414984 max memory_allocated 22563.63232421875 
[2025-03-02 08:38:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.39956286549568176 norm:0.0006558036548085511 max memory_allocated 22563.63232421875 
[2025-03-02 08:38:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.3991720974445343 norm:0.0005629766965284944 max memory_allocated 22563.63232421875 
[2025-03-02 08:39:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.3988780975341797 norm:0.0005002934485673904 max memory_allocated 22563.63232421875 
[2025-03-02 08:39:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.39862093329429626 norm:0.00045182398753240705 max memory_allocated 22563.63232421875 
[2025-03-02 08:40:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.3983646631240845 norm:0.000419960415456444 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.3981679081916809 norm:0.0003914404660463333 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.39801764488220215 norm:0.0003727083094418049 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.3978990912437439 norm:0.00035892773303203285 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.3977898359298706 norm:0.00035301654133945704 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.3977232277393341 norm:0.0003444422036409378 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.39766573905944824 norm:0.00033392850309610367 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.3975539207458496 norm:0.00032806993112899363 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.3974645733833313 norm:0.0003260709345340729 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.39736407995224 norm:0.0003347930614836514 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 08:45:41 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 08:46:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.5050418972969055 norm:0.014220691286027431 max memory_allocated 22563.91943359375 
[2025-03-02 08:46:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.4852833151817322 norm:0.011303866282105446 max memory_allocated 22563.91943359375 
[2025-03-02 08:47:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.468238890171051 norm:0.008038865402340889 max memory_allocated 22563.91943359375 
[2025-03-02 08:47:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.463412880897522 norm:0.0070539191365242004 max memory_allocated 22563.91943359375 
[2025-03-02 08:48:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.4621364176273346 norm:0.006078213453292847 max memory_allocated 22563.91943359375 
[2025-03-02 08:49:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.46132341027259827 norm:0.005315781570971012 max memory_allocated 22563.91943359375 
[2025-03-02 08:49:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.4607241749763489 norm:0.004823419731110334 max memory_allocated 22563.91943359375 
[2025-03-02 08:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.46033626794815063 norm:0.0045826127752661705 max memory_allocated 22563.91943359375 
[2025-03-02 08:50:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.46002864837646484 norm:0.0044607678428292274 max memory_allocated 22563.91943359375 
[2025-03-02 08:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.4597863554954529 norm:0.004367248620837927 max memory_allocated 22563.91943359375 
[2025-03-02 08:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.4596109390258789 norm:0.004227904137223959 max memory_allocated 22563.91943359375 
[2025-03-02 08:52:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.45932772755622864 norm:0.004131240304559469 max memory_allocated 22563.91943359375 
[2025-03-02 08:52:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.45908740162849426 norm:0.0037924544885754585 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.4589722156524658 norm:0.0036873440258204937 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.45878520607948303 norm:0.0035908082500100136 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.4587353467941284 norm:0.0035166621673852205 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.458590567111969 norm:0.003535445546731353 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.45851585268974304 norm:0.003424606518819928 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.458413302898407 norm:0.003374881576746702 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.45836228132247925 norm:0.0033507877960801125 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 08:56:58 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 08:57:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.5890976190567017 norm:0.015518113039433956 max memory_allocated 22564.09130859375 
[2025-03-02 08:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.5644046068191528 norm:0.010941671207547188 max memory_allocated 22564.09130859375 
[2025-03-02 08:58:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.5446457266807556 norm:0.008026927709579468 max memory_allocated 22564.09130859375 
[2025-03-02 08:59:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.539602518081665 norm:0.006787667516618967 max memory_allocated 22564.09130859375 
[2025-03-02 08:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.5381124019622803 norm:0.005677192937582731 max memory_allocated 22564.09130859375 
[2025-03-02 09:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.5371434688568115 norm:0.004804712720215321 max memory_allocated 22564.09130859375 
[2025-03-02 09:00:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.5364589095115662 norm:0.00438454607501626 max memory_allocated 22564.09130859375 
[2025-03-02 09:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.5361268520355225 norm:0.0042760432697832584 max memory_allocated 22564.09130859375 
[2025-03-02 09:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.5356169939041138 norm:0.004165911581367254 max memory_allocated 22564.09130859375 
[2025-03-02 09:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.5353267788887024 norm:0.0038056825287640095 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.5350432395935059 norm:0.003796637523919344 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.5348178148269653 norm:0.003628546604886651 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.5346067547798157 norm:0.0034921434707939625 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.5343643426895142 norm:0.0034113258589059114 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.5342296957969666 norm:0.0033034267835319042 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.5341541171073914 norm:0.003329743165522814 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.5340158343315125 norm:0.003278598189353943 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.5339658856391907 norm:0.003236685413867235 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.5338249802589417 norm:0.0031602142844349146 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.5337565541267395 norm:0.003103605005890131 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:08:14 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.7893680930137634 norm:0.03394458442926407 max memory_allocated 22564.26318359375 
[2025-03-02 09:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.7340971231460571 norm:0.02356589585542679 max memory_allocated 22564.26318359375 
[2025-03-02 09:09:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.6961510181427002 norm:0.013638462871313095 max memory_allocated 22564.26318359375 
[2025-03-02 09:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.6868525147438049 norm:0.015821710228919983 max memory_allocated 22564.26318359375 
[2025-03-02 09:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.6830251216888428 norm:0.017736833542585373 max memory_allocated 22564.26318359375 
[2025-03-02 09:11:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.6806662082672119 norm:0.018580224364995956 max memory_allocated 22564.26318359375 
[2025-03-02 09:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.678654670715332 norm:0.01767093688249588 max memory_allocated 22564.26318359375 
[2025-03-02 09:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.677388608455658 norm:0.016511056572198868 max memory_allocated 22564.26318359375 
[2025-03-02 09:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.6765885353088379 norm:0.01637454703450203 max memory_allocated 22564.26318359375 
[2025-03-02 09:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.6765255928039551 norm:0.01624467596411705 max memory_allocated 22564.26318359375 
[2025-03-02 09:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.6759840846061707 norm:0.01652742736041546 max memory_allocated 22564.26318359375 
[2025-03-02 09:14:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.6757807731628418 norm:0.01671067252755165 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.6755335927009583 norm:0.01713138073682785 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.6750675439834595 norm:0.01702006720006466 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.6754732728004456 norm:0.017397312447428703 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.6746295094490051 norm:0.016948359087109566 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.6744328141212463 norm:0.01594196818768978 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.6746414303779602 norm:0.016668882220983505 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.6746523380279541 norm:0.016289841383695602 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.6739653944969177 norm:0.01674811728298664 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 09:19:31 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:20:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:1.4089572429656982 norm:0.09608373045921326 max memory_allocated 22564.43505859375 
[2025-03-02 09:20:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:1.2884360551834106 norm:0.06904178857803345 max memory_allocated 22564.43505859375 
[2025-03-02 09:21:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:1.2013031244277954 norm:0.050715941935777664 max memory_allocated 22564.43505859375 
[2025-03-02 09:21:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:1.175398588180542 norm:0.04952497035264969 max memory_allocated 22564.43505859375 
[2025-03-02 09:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:1.1634747982025146 norm:0.04892147704958916 max memory_allocated 22564.43505859375 
[2025-03-02 09:22:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:1.1554582118988037 norm:0.04874993488192558 max memory_allocated 22564.43505859375 
[2025-03-02 09:23:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:1.1473524570465088 norm:0.04631492868065834 max memory_allocated 22564.43505859375 
[2025-03-02 09:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:1.1431163549423218 norm:0.04517196863889694 max memory_allocated 22564.43505859375 
[2025-03-02 09:24:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:1.1400951147079468 norm:0.044222764670848846 max memory_allocated 22564.43505859375 
[2025-03-02 09:25:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:1.1369502544403076 norm:0.044548630714416504 max memory_allocated 22564.43505859375 
[2025-03-02 09:25:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:1.1345188617706299 norm:0.04213447868824005 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:1.1310999393463135 norm:0.04065411165356636 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:1.1298021078109741 norm:0.042743369936943054 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:1.1289455890655518 norm:0.04303080216050148 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:1.1283506155014038 norm:0.04130849242210388 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:1.1282827854156494 norm:0.045941147953271866 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:1.1271358728408813 norm:0.04193216562271118 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:1.127124309539795 norm:0.04314914345741272 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:1.1247395277023315 norm:0.04075394198298454 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:1.122115135192871 norm:0.03597954288125038 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:44 root] (main_calib_config2.py 380): INFO 21601.292833805084
[2025-03-02 09:30:49 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 09:31:59 root] (main_calib_config2.py 159): INFO wikitext2 : 5.9586181640625
[2025-03-02 09:32:00 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 09:33:48 root] (main_calib_config2.py 159): INFO c4 : 7.493456840515137
[2025-03-02 11:10:11 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.9586181640625, 'c4': 7.493456840515137, 'results': {'arc_challenge': {'acc': 0.36689419795221845, 'acc_stderr': 0.014084133118104296, 'acc_norm': 0.3993174061433447, 'acc_norm_stderr': 0.014312094557946707}, 'winogrande': {'acc': 0.6464088397790055, 'acc_stderr': 0.013436541262599957}, 'arc_easy': {'acc': 0.6616161616161617, 'acc_stderr': 0.009709034670525096, 'acc_norm': 0.5286195286195287, 'acc_norm_stderr': 0.010242962617927193}, 'hellaswag': {'acc': 0.5464050985859391, 'acc_stderr': 0.0049682446114293925, 'acc_norm': 0.709520015933081, 'acc_norm_stderr': 0.004530560646902539}, 'piqa': {'acc': 0.779651795429815, 'acc_stderr': 0.009670535456853143, 'acc_norm': 0.7752992383025027, 'acc_norm_stderr': 0.009738282586548392}, 'boolq': {'acc': 0.7079510703363915, 'acc_stderr': 0.007952834971031336}}, 'versions': {'arc_challenge': 0, 'winogrande': 0, 'arc_easy': 0, 'hellaswag': 0, 'piqa': 0, 'boolq': 1}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
