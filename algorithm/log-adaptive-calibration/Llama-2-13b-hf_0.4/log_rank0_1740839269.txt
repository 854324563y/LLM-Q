[2025-03-01 14:27:49 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.4', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.4.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-01 14:28:23 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-01 14:28:23 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.4.pkl
[2025-03-01 14:28:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-01 14:29:00 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.04024212807416916 norm:0.02888132818043232 max memory_allocated 29271.02001953125 
[2025-03-01 14:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.02758905291557312 norm:0.018166614696383476 max memory_allocated 29271.02001953125 
[2025-03-01 14:31:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.022553404793143272 norm:0.0167070422321558 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.020444627851247787 norm:0.011027337983250618 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.019546708092093468 norm:0.010547771118581295 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.01894867792725563 norm:0.009830079041421413 max memory_allocated 29271.02001953125 
[2025-03-01 14:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.018639469519257545 norm:0.008604166097939014 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.018420476466417313 norm:0.007478766143321991 max memory_allocated 29271.02001953125 
[2025-03-01 14:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.018464092165231705 norm:0.007112300954759121 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.018396832048892975 norm:0.00632823770865798 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.01824425905942917 norm:0.004876826889812946 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.018214087933301926 norm:0.004463797435164452 max memory_allocated 29271.02001953125 
[2025-03-01 14:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.018240854144096375 norm:0.004165785387158394 max memory_allocated 29271.02001953125 
[2025-03-01 14:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.018253779038786888 norm:0.0061059799045324326 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.018203098326921463 norm:0.003908456303179264 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.018220441415905952 norm:0.006729884538799524 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.018307769671082497 norm:0.007310627959668636 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:35 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.01829887554049492 norm:0.004672386683523655 max memory_allocated 29271.02001953125 
[2025-03-01 14:44:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.018244992941617966 norm:0.0044209323823452 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.018233928829431534 norm:0.0036829146556556225 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-01 14:45:32 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.08702525496482849 norm:0.022785961627960205 max memory_allocated 29271.02001953125 
[2025-03-01 14:47:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.07284566760063171 norm:0.015680920332670212 max memory_allocated 29271.02001953125 
[2025-03-01 14:47:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.06497038900852203 norm:0.011667097918689251 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.06214045733213425 norm:0.009216989390552044 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.06066219508647919 norm:0.007510602939873934 max memory_allocated 29271.02001953125 
[2025-03-01 14:50:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.05959927290678024 norm:0.005993682891130447 max memory_allocated 29271.02001953125 
[2025-03-01 14:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.058803245425224304 norm:0.0049764239229261875 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.05832343548536301 norm:0.004379838239401579 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.05806705355644226 norm:0.004212767351418734 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.057839393615722656 norm:0.003923087380826473 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.05774166062474251 norm:0.003949652425944805 max memory_allocated 29271.02001953125 
[2025-03-01 14:55:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.057593896985054016 norm:0.0038590659387409687 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.057571109384298325 norm:0.003861767938360572 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.05749418959021568 norm:0.0038411403074860573 max memory_allocated 29271.02001953125 
[2025-03-01 14:57:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.05734649673104286 norm:0.003796218428760767 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.05736636742949486 norm:0.0037675269413739443 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:24 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.05731114000082016 norm:0.0036668486427515745 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.0572379007935524 norm:0.0036416249349713326 max memory_allocated 29271.02001953125 
[2025-03-01 15:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.05718228965997696 norm:0.003629848826676607 max memory_allocated 29271.02001953125 
[2025-03-01 15:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.05716339871287346 norm:0.0035147531889379025 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-01 15:02:20 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 15:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.08483514934778214 norm:0.0197848342359066 max memory_allocated 29271.39501953125 
[2025-03-01 15:03:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.06944121420383453 norm:0.012190068140625954 max memory_allocated 29271.39501953125 
[2025-03-01 15:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.06167770177125931 norm:0.008398935198783875 max memory_allocated 29271.39501953125 
[2025-03-01 15:05:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.0584210604429245 norm:0.006474507041275501 max memory_allocated 29271.39501953125 
[2025-03-01 15:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.056921184062957764 norm:0.005184824578464031 max memory_allocated 29271.39501953125 
[2025-03-01 15:07:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.05591822415590286 norm:0.004205027129501104 max memory_allocated 29271.39501953125 
[2025-03-01 15:08:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.055087629705667496 norm:0.0033671383280307055 max memory_allocated 29271.39501953125 
[2025-03-01 15:08:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.05449344962835312 norm:0.0027795571368187666 max memory_allocated 29271.39501953125 
[2025-03-01 15:09:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.05411265045404434 norm:0.0025497479364275932 max memory_allocated 29271.39501953125 
[2025-03-01 15:10:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.05394349247217178 norm:0.002757547190412879 max memory_allocated 29271.39501953125 
[2025-03-01 15:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.05386095494031906 norm:0.0025647112634032965 max memory_allocated 29271.39501953125 
[2025-03-01 15:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.053642429411411285 norm:0.002508708043023944 max memory_allocated 29271.39501953125 
[2025-03-01 15:12:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.05360304191708565 norm:0.0024602129124104977 max memory_allocated 29271.39501953125 
[2025-03-01 15:13:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.05351370573043823 norm:0.002419673604890704 max memory_allocated 29271.39501953125 
[2025-03-01 15:14:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.053473807871341705 norm:0.0023057544603943825 max memory_allocated 29271.39501953125 
[2025-03-01 15:15:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.05337093025445938 norm:0.002236809115856886 max memory_allocated 29271.39501953125 
[2025-03-01 15:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.05335746333003044 norm:0.002144819824025035 max memory_allocated 29271.39501953125 
[2025-03-01 15:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.05332288146018982 norm:0.0020657742861658335 max memory_allocated 29271.39501953125 
[2025-03-01 15:17:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.05331433191895485 norm:0.0020336508750915527 max memory_allocated 29271.39501953125 
[2025-03-01 15:18:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.05326829105615616 norm:0.0020022960379719734 max memory_allocated 29271.39501953125 
[2025-03-01 15:18:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-01 15:19:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.27786940336227417 norm:0.020517662167549133 max memory_allocated 29271.39501953125 
[2025-03-01 15:20:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.23495271801948547 norm:0.013483023270964622 max memory_allocated 29271.39501953125 
[2025-03-01 15:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.18458816409111023 norm:0.010433983989059925 max memory_allocated 29271.39501953125 
[2025-03-01 15:22:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.16762521862983704 norm:0.00680189486593008 max memory_allocated 29271.39501953125 
[2025-03-01 15:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.16401411592960358 norm:0.006649397779256105 max memory_allocated 29271.39501953125 
[2025-03-01 15:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.15936852991580963 norm:0.006953230127692223 max memory_allocated 29271.39501953125 
[2025-03-01 15:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.15852274000644684 norm:0.007122756913304329 max memory_allocated 29271.39501953125 
[2025-03-01 15:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.15620207786560059 norm:0.007787020411342382 max memory_allocated 29271.39501953125 
[2025-03-01 15:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.15359532833099365 norm:0.0109805753454566 max memory_allocated 29271.39501953125 
[2025-03-01 15:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.15427811443805695 norm:0.009142203256487846 max memory_allocated 29271.39501953125 
[2025-03-01 15:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.14993707835674286 norm:0.009580088779330254 max memory_allocated 29271.39501953125 
[2025-03-01 15:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.14972670376300812 norm:0.009569128975272179 max memory_allocated 29271.39501953125 
[2025-03-01 15:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.1467946618795395 norm:0.00938026700168848 max memory_allocated 29271.39501953125 
[2025-03-01 15:30:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.14418354630470276 norm:0.00866016000509262 max memory_allocated 29271.39501953125 
[2025-03-01 15:31:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.14298786222934723 norm:0.007644995115697384 max memory_allocated 29271.39501953125 
[2025-03-01 15:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.14240142703056335 norm:0.00807168148458004 max memory_allocated 29271.39501953125 
[2025-03-01 15:32:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.14144302904605865 norm:0.00703472038730979 max memory_allocated 29271.39501953125 
[2025-03-01 15:33:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.13894616067409515 norm:0.006310963537544012 max memory_allocated 29271.39501953125 
[2025-03-01 15:34:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.14309683442115784 norm:0.00887785293161869 max memory_allocated 29271.39501953125 
[2025-03-01 15:35:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.14228326082229614 norm:0.0068330056965351105 max memory_allocated 29271.39501953125 
[2025-03-01 15:35:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-01 15:36:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.14590787887573242 norm:0.005937312263995409 max memory_allocated 29271.39501953125 
[2025-03-01 15:37:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.12975876033306122 norm:0.002670477144420147 max memory_allocated 29271.39501953125 
[2025-03-01 15:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.12102880328893661 norm:0.0014708169037476182 max memory_allocated 29271.39501953125 
[2025-03-01 15:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.11744166910648346 norm:0.0009428444900549948 max memory_allocated 29271.39501953125 
[2025-03-01 15:39:52 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.11555689573287964 norm:0.0007354657864198089 max memory_allocated 29271.39501953125 
[2025-03-01 15:40:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.11428534984588623 norm:0.0006314733764156699 max memory_allocated 29271.39501953125 
[2025-03-01 15:41:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.11371734738349915 norm:0.0005968129262328148 max memory_allocated 29271.39501953125 
[2025-03-01 15:42:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.11336804926395416 norm:0.0005705576040782034 max memory_allocated 29271.39501953125 
[2025-03-01 15:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.11323331296443939 norm:0.000547739036846906 max memory_allocated 29271.39501953125 
[2025-03-01 15:43:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.11284232139587402 norm:0.0005064094439148903 max memory_allocated 29271.39501953125 
[2025-03-01 15:44:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.1126314178109169 norm:0.00046360300621017814 max memory_allocated 29271.39501953125 
[2025-03-01 15:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.11262395977973938 norm:0.00046238978393375874 max memory_allocated 29271.39501953125 
[2025-03-01 15:46:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.11253069341182709 norm:0.0004660413833335042 max memory_allocated 29271.39501953125 
[2025-03-01 15:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.1124485433101654 norm:0.00044395815348252654 max memory_allocated 29271.39501953125 
[2025-03-01 15:48:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.11238246411085129 norm:0.00043311467743478715 max memory_allocated 29271.39501953125 
[2025-03-01 15:48:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.11230142414569855 norm:0.00043493707198649645 max memory_allocated 29271.39501953125 
[2025-03-01 15:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.11217387765645981 norm:0.00044662258005701005 max memory_allocated 29271.39501953125 
[2025-03-01 15:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.1121000275015831 norm:0.0004242240102030337 max memory_allocated 29271.39501953125 
[2025-03-01 15:51:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.11207565665245056 norm:0.0004182752745691687 max memory_allocated 29271.39501953125 
[2025-03-01 15:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.11205432564020157 norm:0.0004214645887259394 max memory_allocated 29271.39501953125 
[2025-03-01 15:52:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-01 15:53:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.15219569206237793 norm:0.007565134670585394 max memory_allocated 29271.81298828125 
[2025-03-01 15:54:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.1310376524925232 norm:0.0031507762614637613 max memory_allocated 29271.81298828125 
[2025-03-01 15:55:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.12097852677106857 norm:0.002032758202403784 max memory_allocated 29271.81298828125 
[2025-03-01 15:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.1175655871629715 norm:0.0014082161942496896 max memory_allocated 29271.81298828125 
[2025-03-01 15:56:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.11562174558639526 norm:0.0010566292330622673 max memory_allocated 29271.81298828125 
[2025-03-01 15:57:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.11444929242134094 norm:0.0008695870637893677 max memory_allocated 29271.81298828125 
[2025-03-01 15:58:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.11376684159040451 norm:0.0007477618637494743 max memory_allocated 29271.81298828125 
[2025-03-01 15:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.11341500282287598 norm:0.000670790090225637 max memory_allocated 29271.81298828125 
[2025-03-01 15:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.11317209154367447 norm:0.0006228779093362391 max memory_allocated 29271.81298828125 
[2025-03-01 16:00:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.11302293092012405 norm:0.0005799636710435152 max memory_allocated 29271.81298828125 
[2025-03-01 16:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.11290191859006882 norm:0.0005382603267207742 max memory_allocated 29271.81298828125 
[2025-03-01 16:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.11280978471040726 norm:0.0005188581999391317 max memory_allocated 29271.81298828125 
[2025-03-01 16:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.11273860186338425 norm:0.0005024313577450812 max memory_allocated 29271.81298828125 
[2025-03-01 16:03:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.1126663088798523 norm:0.0004883340443484485 max memory_allocated 29271.81298828125 
[2025-03-01 16:04:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.11261788010597229 norm:0.0004725117178168148 max memory_allocated 29271.81298828125 
[2025-03-01 16:05:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.11261016130447388 norm:0.00045803835382685065 max memory_allocated 29271.81298828125 
[2025-03-01 16:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.11256081610918045 norm:0.0004433213034644723 max memory_allocated 29271.81298828125 
[2025-03-01 16:07:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.11249208450317383 norm:0.00043483488843776286 max memory_allocated 29271.81298828125 
[2025-03-01 16:08:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.11243803799152374 norm:0.0004208807076793164 max memory_allocated 29271.81298828125 
[2025-03-01 16:08:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.11240211129188538 norm:0.00042064470471814275 max memory_allocated 29271.81298828125 
[2025-03-01 16:09:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-01 16:10:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.16089016199111938 norm:0.0060813031159341335 max memory_allocated 29271.81298828125 
[2025-03-01 16:10:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.13785821199417114 norm:0.0025632816832512617 max memory_allocated 29271.81298828125 
[2025-03-01 16:11:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.12480635941028595 norm:0.0011495513608679175 max memory_allocated 29271.81298828125 
[2025-03-01 16:12:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.12089721858501434 norm:0.0007802394684404135 max memory_allocated 29271.81298828125 
[2025-03-01 16:13:24 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.11889494955539703 norm:0.0005941471899859607 max memory_allocated 29271.81298828125 
[2025-03-01 16:14:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.11766494065523148 norm:0.0004902793443761766 max memory_allocated 29271.81298828125 
[2025-03-01 16:15:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.11704859882593155 norm:0.0004507605917751789 max memory_allocated 29271.81298828125 
[2025-03-01 16:15:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.11656972020864487 norm:0.00040849155629985034 max memory_allocated 29271.81298828125 
[2025-03-01 16:16:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.11630050092935562 norm:0.00040687117143534124 max memory_allocated 29271.81298828125 
[2025-03-01 16:17:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.11614809185266495 norm:0.0004008857358712703 max memory_allocated 29271.81298828125 
[2025-03-01 16:18:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.11604520678520203 norm:0.00041574236820451915 max memory_allocated 29271.81298828125 
[2025-03-01 16:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.1158767119050026 norm:0.00041293876711279154 max memory_allocated 29271.81298828125 
[2025-03-01 16:19:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.11572366207838058 norm:0.0003949039673898369 max memory_allocated 29271.81298828125 
[2025-03-01 16:20:45 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.1156717836856842 norm:0.0003849963832180947 max memory_allocated 29271.81298828125 
[2025-03-01 16:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.11559292674064636 norm:0.000378576252842322 max memory_allocated 29271.81298828125 
[2025-03-01 16:22:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.11552974581718445 norm:0.0003748098388314247 max memory_allocated 29271.81298828125 
[2025-03-01 16:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.11547277867794037 norm:0.00037165562389418483 max memory_allocated 29271.81298828125 
[2025-03-01 16:24:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.11547516286373138 norm:0.0003670909209176898 max memory_allocated 29271.81298828125 
[2025-03-01 16:24:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.11543624848127365 norm:0.0003641478542704135 max memory_allocated 29271.81298828125 
[2025-03-01 16:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.11542953550815582 norm:0.00036286970134824514 max memory_allocated 29271.81298828125 
[2025-03-01 16:25:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-01 16:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.18267954885959625 norm:0.008338776417076588 max memory_allocated 29271.81298828125 
[2025-03-01 16:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.15022730827331543 norm:0.00268196570686996 max memory_allocated 29271.81298828125 
[2025-03-01 16:28:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.13481925427913666 norm:0.001315247151069343 max memory_allocated 29271.81298828125 
[2025-03-01 16:29:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.13015440106391907 norm:0.000883178086951375 max memory_allocated 29271.81298828125 
[2025-03-01 16:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.1279778778553009 norm:0.0007211045012809336 max memory_allocated 29271.81298828125 
[2025-03-01 16:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.12664568424224854 norm:0.0006283717229962349 max memory_allocated 29271.81298828125 
[2025-03-01 16:31:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.12602053582668304 norm:0.0005997544503770769 max memory_allocated 29271.81298828125 
[2025-03-01 16:32:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.1255485713481903 norm:0.0005600479780696332 max memory_allocated 29271.81298828125 
[2025-03-01 16:33:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.12519116699695587 norm:0.0005578562268055975 max memory_allocated 29271.81298828125 
[2025-03-01 16:34:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.12501490116119385 norm:0.0005722962669096887 max memory_allocated 29271.81298828125 
[2025-03-01 16:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.1248692125082016 norm:0.0005618750583380461 max memory_allocated 29271.81298828125 
[2025-03-01 16:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.1247151643037796 norm:0.0005320769851095974 max memory_allocated 29271.81298828125 
[2025-03-01 16:36:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.12462799996137619 norm:0.0005150186480022967 max memory_allocated 29271.81298828125 
[2025-03-01 16:37:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.12457139790058136 norm:0.0005087026511318982 max memory_allocated 29271.81298828125 
[2025-03-01 16:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.12453518807888031 norm:0.0004884921945631504 max memory_allocated 29271.81298828125 
[2025-03-01 16:39:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.12451805919408798 norm:0.0004927129484713078 max memory_allocated 29271.81298828125 
[2025-03-01 16:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.12452680617570877 norm:0.00047857422032393515 max memory_allocated 29271.81298828125 
[2025-03-01 16:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.12450067698955536 norm:0.00048071591299958527 max memory_allocated 29271.81298828125 
[2025-03-01 16:41:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.12442699819803238 norm:0.0004942613886669278 max memory_allocated 29271.81298828125 
[2025-03-01 16:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.12435619533061981 norm:0.0004998752265237272 max memory_allocated 29271.81298828125 
[2025-03-01 16:42:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-01 16:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.18767377734184265 norm:0.00921650230884552 max memory_allocated 29272.37548828125 
[2025-03-01 16:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.15838198363780975 norm:0.00397062161937356 max memory_allocated 29272.37548828125 
[2025-03-01 16:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.14222025871276855 norm:0.00201212614774704 max memory_allocated 29272.37548828125 
[2025-03-01 16:45:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.13627831637859344 norm:0.0012113553239032626 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.13341812789440155 norm:0.000892224779818207 max memory_allocated 29272.37548828125 
[2025-03-01 16:47:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.13177558779716492 norm:0.0007165957940742373 max memory_allocated 29272.37548828125 
[2025-03-01 16:48:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.13091054558753967 norm:0.0006387629546225071 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.13034865260124207 norm:0.0005673913401551545 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.1298687905073166 norm:0.0005245088832452893 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.1294512003660202 norm:0.0004913336015306413 max memory_allocated 29272.37548828125 
[2025-03-01 16:51:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.12919223308563232 norm:0.0004710551875177771 max memory_allocated 29272.37548828125 
[2025-03-01 16:52:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.12912337481975555 norm:0.00047068073763512075 max memory_allocated 29272.37548828125 
[2025-03-01 16:53:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.12900803983211517 norm:0.00044764933409169316 max memory_allocated 29272.37548828125 
[2025-03-01 16:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.12893164157867432 norm:0.0004470722924452275 max memory_allocated 29272.37548828125 
[2025-03-01 16:54:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.12887626886367798 norm:0.0004723195161204785 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.12878136336803436 norm:0.00046972473501227796 max memory_allocated 29272.37548828125 
[2025-03-01 16:56:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.1287229061126709 norm:0.0004565522540360689 max memory_allocated 29272.37548828125 
[2025-03-01 16:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.12867824733257294 norm:0.0004467462422326207 max memory_allocated 29272.37548828125 
[2025-03-01 16:58:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.128619983792305 norm:0.00043021829333156347 max memory_allocated 29272.37548828125 
[2025-03-01 16:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.12862592935562134 norm:0.00042499418486841023 max memory_allocated 29272.37548828125 
[2025-03-01 16:59:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-01 17:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.2113492488861084 norm:0.0065368954092264175 max memory_allocated 29272.56298828125 
[2025-03-01 17:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.17503271996974945 norm:0.0031764693558216095 max memory_allocated 29272.56298828125 
[2025-03-01 17:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.15452724695205688 norm:0.0016347133787348866 max memory_allocated 29272.56298828125 
[2025-03-01 17:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.14816753566265106 norm:0.0010668952018022537 max memory_allocated 29272.56298828125 
[2025-03-01 17:03:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.14523759484291077 norm:0.0008537714020349085 max memory_allocated 29272.56298828125 
[2025-03-01 17:04:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.1434951275587082 norm:0.0007011742563918233 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.14238101243972778 norm:0.000617004232481122 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.14169751107692719 norm:0.0005794230964966118 max memory_allocated 29272.56298828125 
[2025-03-01 17:06:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.14130592346191406 norm:0.0005503551219590008 max memory_allocated 29272.56298828125 
[2025-03-01 17:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.14102788269519806 norm:0.0005321702337823808 max memory_allocated 29272.56298828125 
[2025-03-01 17:08:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.14084871113300323 norm:0.0005187461501918733 max memory_allocated 29272.56298828125 
[2025-03-01 17:09:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.1407729685306549 norm:0.000518087123055011 max memory_allocated 29272.56298828125 
[2025-03-01 17:09:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.14074766635894775 norm:0.0005010734312236309 max memory_allocated 29272.56298828125 
[2025-03-01 17:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.14066243171691895 norm:0.0005004927515983582 max memory_allocated 29272.56298828125 
[2025-03-01 17:11:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.14058789610862732 norm:0.0004851920821238309 max memory_allocated 29272.56298828125 
[2025-03-01 17:12:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.14054715633392334 norm:0.0004758196009788662 max memory_allocated 29272.56298828125 
[2025-03-01 17:13:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.1405332386493683 norm:0.00047077061026357114 max memory_allocated 29272.56298828125 
[2025-03-01 17:14:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.14050789177417755 norm:0.0004655156226363033 max memory_allocated 29272.56298828125 
[2025-03-01 17:14:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.14042502641677856 norm:0.00047036082833074033 max memory_allocated 29272.56298828125 
[2025-03-01 17:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.14043232798576355 norm:0.00046261685201898217 max memory_allocated 29272.56298828125 
[2025-03-01 17:15:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-01 17:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.21326492726802826 norm:0.009943193756043911 max memory_allocated 29272.75048828125 
[2025-03-01 17:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.17946630716323853 norm:0.004040698520839214 max memory_allocated 29272.75048828125 
[2025-03-01 17:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.1611277461051941 norm:0.0018149488605558872 max memory_allocated 29272.75048828125 
[2025-03-01 17:19:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.1549040675163269 norm:0.0011862277751788497 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.15189561247825623 norm:0.0009226377005688846 max memory_allocated 29272.75048828125 
[2025-03-01 17:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.15015721321105957 norm:0.0007859120378270745 max memory_allocated 29272.75048828125 
[2025-03-01 17:21:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.14914679527282715 norm:0.0006902903551235795 max memory_allocated 29272.75048828125 
[2025-03-01 17:22:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.14842723309993744 norm:0.0005874672206118703 max memory_allocated 29272.75048828125 
[2025-03-01 17:23:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.148105651140213 norm:0.0005471307085826993 max memory_allocated 29272.75048828125 
[2025-03-01 17:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.14783374965190887 norm:0.00048196836723946035 max memory_allocated 29272.75048828125 
[2025-03-01 17:25:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.1476961374282837 norm:0.00044439075281843543 max memory_allocated 29272.75048828125 
[2025-03-01 17:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.1475992649793625 norm:0.00043192622251808643 max memory_allocated 29272.75048828125 
[2025-03-01 17:26:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.14750882983207703 norm:0.0004293991660233587 max memory_allocated 29272.75048828125 
[2025-03-01 17:27:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.14739787578582764 norm:0.0004271398938726634 max memory_allocated 29272.75048828125 
[2025-03-01 17:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.14731140434741974 norm:0.00044448618427850306 max memory_allocated 29272.75048828125 
[2025-03-01 17:29:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.14718186855316162 norm:0.00046013903920538723 max memory_allocated 29272.75048828125 
[2025-03-01 17:29:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.14708690345287323 norm:0.0004643556894734502 max memory_allocated 29272.75048828125 
[2025-03-01 17:30:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.14703421294689178 norm:0.0004593887715600431 max memory_allocated 29272.75048828125 
[2025-03-01 17:31:36 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.14699673652648926 norm:0.0004504229873418808 max memory_allocated 29272.75048828125 
[2025-03-01 17:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.14690804481506348 norm:0.00043091349652968347 max memory_allocated 29272.75048828125 
[2025-03-01 17:32:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-01 17:33:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.2096039354801178 norm:0.005383159965276718 max memory_allocated 29272.93798828125 
[2025-03-01 17:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.18281786143779755 norm:0.0026107924059033394 max memory_allocated 29272.93798828125 
[2025-03-01 17:35:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.1656959354877472 norm:0.001207894179970026 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.15998557209968567 norm:0.0007758087594993412 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.15739864110946655 norm:0.0006144347717054188 max memory_allocated 29272.93798828125 
[2025-03-01 17:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.1558731347322464 norm:0.000544918526429683 max memory_allocated 29272.93798828125 
[2025-03-01 17:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.15498420596122742 norm:0.00047565996646881104 max memory_allocated 29272.93798828125 
[2025-03-01 17:39:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.15449850261211395 norm:0.00044717214768752456 max memory_allocated 29272.93798828125 
[2025-03-01 17:40:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.1541942059993744 norm:0.000434231071267277 max memory_allocated 29272.93798828125 
[2025-03-01 17:40:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.15393485128879547 norm:0.0004137525102123618 max memory_allocated 29272.93798828125 
[2025-03-01 17:41:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.15376776456832886 norm:0.0004168454615864903 max memory_allocated 29272.93798828125 
[2025-03-01 17:42:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.1536472886800766 norm:0.00041747192153707147 max memory_allocated 29272.93798828125 
[2025-03-01 17:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.15352003276348114 norm:0.0003766631707549095 max memory_allocated 29272.93798828125 
[2025-03-01 17:44:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.1534472107887268 norm:0.0003626238612923771 max memory_allocated 29272.93798828125 
[2025-03-01 17:45:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.1533651053905487 norm:0.0003545549407135695 max memory_allocated 29272.93798828125 
[2025-03-01 17:45:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.15329216420650482 norm:0.00036588881630450487 max memory_allocated 29272.93798828125 
[2025-03-01 17:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.15325671434402466 norm:0.00035866230609826744 max memory_allocated 29272.93798828125 
[2025-03-01 17:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.1532423496246338 norm:0.00034942300408147275 max memory_allocated 29272.93798828125 
[2025-03-01 17:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.1532658040523529 norm:0.000348911271430552 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.1532903015613556 norm:0.0003477168211247772 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-01 17:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.21003082394599915 norm:0.003920725546777248 max memory_allocated 29273.12548828125 
[2025-03-01 17:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.18359188735485077 norm:0.0017446662532165647 max memory_allocated 29273.12548828125 
[2025-03-01 17:51:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.1691780388355255 norm:0.000915642362087965 max memory_allocated 29273.12548828125 
[2025-03-01 17:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.16442178189754486 norm:0.0006336610531434417 max memory_allocated 29273.12548828125 
[2025-03-01 17:53:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.16210931539535522 norm:0.0005013325717300177 max memory_allocated 29273.12548828125 
[2025-03-01 17:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.16080500185489655 norm:0.00044875225285068154 max memory_allocated 29273.12548828125 
[2025-03-01 17:55:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.1600698083639145 norm:0.00041214763768948615 max memory_allocated 29273.12548828125 
[2025-03-01 17:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.1596299260854721 norm:0.0003815946984104812 max memory_allocated 29273.12548828125 
[2025-03-01 17:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.15939520299434662 norm:0.00036989033105783165 max memory_allocated 29273.12548828125 
[2025-03-01 17:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.1592782586812973 norm:0.0003643995733000338 max memory_allocated 29273.12548828125 
[2025-03-01 17:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.15921831130981445 norm:0.00035546516301110387 max memory_allocated 29273.12548828125 
[2025-03-01 17:59:15 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.15911445021629333 norm:0.0003505852655507624 max memory_allocated 29273.12548828125 
[2025-03-01 18:00:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.159055694937706 norm:0.00034966200473718345 max memory_allocated 29273.12548828125 
[2025-03-01 18:00:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.15899135172367096 norm:0.0003493166295811534 max memory_allocated 29273.12548828125 
[2025-03-01 18:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.158967986702919 norm:0.0003369989572092891 max memory_allocated 29273.12548828125 
[2025-03-01 18:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.1589280664920807 norm:0.00033654828439466655 max memory_allocated 29273.12548828125 
[2025-03-01 18:03:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.15889067947864532 norm:0.00032705505145713687 max memory_allocated 29273.12548828125 
[2025-03-01 18:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.15882796049118042 norm:0.0003248326829634607 max memory_allocated 29273.12548828125 
[2025-03-01 18:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.1588171422481537 norm:0.0003265520790591836 max memory_allocated 29273.12548828125 
[2025-03-01 18:05:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.1588112860918045 norm:0.0003208395792171359 max memory_allocated 29273.12548828125 
[2025-03-01 18:06:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-01 18:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.21543288230895996 norm:0.0068539222702383995 max memory_allocated 29273.31298828125 
[2025-03-01 18:07:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.1918240487575531 norm:0.003505463944748044 max memory_allocated 29273.31298828125 
[2025-03-01 18:08:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.1747828871011734 norm:0.00152299995534122 max memory_allocated 29273.31298828125 
[2025-03-01 18:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.16842564940452576 norm:0.0008864557021297514 max memory_allocated 29273.31298828125 
[2025-03-01 18:10:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.16557274758815765 norm:0.0006548080127686262 max memory_allocated 29273.31298828125 
[2025-03-01 18:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.1640239953994751 norm:0.0005658915033563972 max memory_allocated 29273.31298828125 
[2025-03-01 18:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.16314250230789185 norm:0.0005163316382095218 max memory_allocated 29273.31298828125 
[2025-03-01 18:12:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.16262629628181458 norm:0.0004877708270214498 max memory_allocated 29273.31298828125 
[2025-03-01 18:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.16228407621383667 norm:0.00047509471187368035 max memory_allocated 29273.31298828125 
[2025-03-01 18:14:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.16205649077892303 norm:0.00045272608986124396 max memory_allocated 29273.31298828125 
[2025-03-01 18:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.16183751821517944 norm:0.00043175570317544043 max memory_allocated 29273.31298828125 
[2025-03-01 18:15:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.16160181164741516 norm:0.0004073670716024935 max memory_allocated 29273.31298828125 
[2025-03-01 18:16:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.16145075857639313 norm:0.0003925273776985705 max memory_allocated 29273.31298828125 
[2025-03-01 18:17:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.16132763028144836 norm:0.00037583959056064487 max memory_allocated 29273.31298828125 
[2025-03-01 18:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.16127529740333557 norm:0.00036466147867031395 max memory_allocated 29273.31298828125 
[2025-03-01 18:19:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.16122715175151825 norm:0.00036860862746834755 max memory_allocated 29273.31298828125 
[2025-03-01 18:19:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.1611938327550888 norm:0.0003785354201681912 max memory_allocated 29273.31298828125 
[2025-03-01 18:20:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.16112257540225983 norm:0.00039020177791826427 max memory_allocated 29273.31298828125 
[2025-03-01 18:21:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.16106173396110535 norm:0.0003935591666959226 max memory_allocated 29273.31298828125 
[2025-03-01 18:22:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.16096991300582886 norm:0.0003594799491111189 max memory_allocated 29273.31298828125 
[2025-03-01 18:22:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-01 18:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.2078426331281662 norm:0.003143150359392166 max memory_allocated 29273.50048828125 
[2025-03-01 18:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.18838931620121002 norm:0.0015075053088366985 max memory_allocated 29273.50048828125 
[2025-03-01 18:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.17699652910232544 norm:0.0008442614343948662 max memory_allocated 29273.50048828125 
[2025-03-01 18:26:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.17231374979019165 norm:0.0005724413204006851 max memory_allocated 29273.50048828125 
[2025-03-01 18:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.1701659858226776 norm:0.0004648767353501171 max memory_allocated 29273.50048828125 
[2025-03-01 18:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.16894850134849548 norm:0.00041619763942435384 max memory_allocated 29273.50048828125 
[2025-03-01 18:28:29 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.16824451088905334 norm:0.0003883898607455194 max memory_allocated 29273.50048828125 
[2025-03-01 18:29:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.16783544421195984 norm:0.00036654225550591946 max memory_allocated 29273.50048828125 
[2025-03-01 18:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.1675843447446823 norm:0.00035362911876291037 max memory_allocated 29273.50048828125 
[2025-03-01 18:30:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.16749750077724457 norm:0.0003497989382594824 max memory_allocated 29273.50048828125 
[2025-03-01 18:31:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.16740190982818604 norm:0.0003426416660659015 max memory_allocated 29273.50048828125 
[2025-03-01 18:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.16735143959522247 norm:0.00033714924938976765 max memory_allocated 29273.50048828125 
[2025-03-01 18:33:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.16728824377059937 norm:0.0003342364216223359 max memory_allocated 29273.50048828125 
[2025-03-01 18:34:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.16722159087657928 norm:0.00033164984779432416 max memory_allocated 29273.50048828125 
[2025-03-01 18:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.16718024015426636 norm:0.00032946362625807524 max memory_allocated 29273.50048828125 
[2025-03-01 18:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.167164146900177 norm:0.0003290182212367654 max memory_allocated 29273.50048828125 
[2025-03-01 18:36:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.16714400053024292 norm:0.00032757085864432156 max memory_allocated 29273.50048828125 
[2025-03-01 18:37:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.16710227727890015 norm:0.00032626150641590357 max memory_allocated 29273.50048828125 
[2025-03-01 18:38:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.16712212562561035 norm:0.0003261890960857272 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.1670997589826584 norm:0.0003216215700376779 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-01 18:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.20324556529521942 norm:0.0030220786575227976 max memory_allocated 29273.68798828125 
[2025-03-01 18:41:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.18673741817474365 norm:0.0013660425320267677 max memory_allocated 29273.68798828125 
[2025-03-01 18:41:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.17599602043628693 norm:0.0006983430357649922 max memory_allocated 29273.68798828125 
[2025-03-01 18:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.17197228968143463 norm:0.0004915307508781552 max memory_allocated 29273.68798828125 
[2025-03-01 18:43:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.17019082605838776 norm:0.0004176654329057783 max memory_allocated 29273.68798828125 
[2025-03-01 18:44:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.16914181411266327 norm:0.0003795455559156835 max memory_allocated 29273.68798828125 
[2025-03-01 18:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.16855131089687347 norm:0.0003705336421262473 max memory_allocated 29273.68798828125 
[2025-03-01 18:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.16820722818374634 norm:0.00034873574622906744 max memory_allocated 29273.68798828125 
[2025-03-01 18:46:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.16795174777507782 norm:0.0003388991754036397 max memory_allocated 29273.68798828125 
[2025-03-01 18:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.16774019598960876 norm:0.0003280130331404507 max memory_allocated 29273.68798828125 
[2025-03-01 18:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.16760824620723724 norm:0.00032826000824570656 max memory_allocated 29273.68798828125 
[2025-03-01 18:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.16753660142421722 norm:0.0003236651245970279 max memory_allocated 29273.68798828125 
[2025-03-01 18:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.16748696565628052 norm:0.0003155348531436175 max memory_allocated 29273.68798828125 
[2025-03-01 18:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.1674153208732605 norm:0.00031060801120474935 max memory_allocated 29273.68798828125 
[2025-03-01 18:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.16736438870429993 norm:0.000309530965751037 max memory_allocated 29273.68798828125 
[2025-03-01 18:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.16735391318798065 norm:0.00030723793315701187 max memory_allocated 29273.68798828125 
[2025-03-01 18:53:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.1673416644334793 norm:0.00030800100648775697 max memory_allocated 29273.68798828125 
[2025-03-01 18:54:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.16732224822044373 norm:0.0003087996446993202 max memory_allocated 29273.68798828125 
[2025-03-01 18:55:03 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.16729649901390076 norm:0.0003059618466068059 max memory_allocated 29273.68798828125 
[2025-03-01 18:55:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.16726821660995483 norm:0.0003041059826500714 max memory_allocated 29273.68798828125 
[2025-03-01 18:56:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-01 18:57:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.20414882898330688 norm:0.003933526109904051 max memory_allocated 29273.87548828125 
[2025-03-01 18:57:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.18892613053321838 norm:0.0019767507910728455 max memory_allocated 29273.87548828125 
[2025-03-01 18:58:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.17783793807029724 norm:0.0008881151443347335 max memory_allocated 29273.87548828125 
[2025-03-01 18:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.17382106184959412 norm:0.0006499949959106743 max memory_allocated 29273.87548828125 
[2025-03-01 19:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.1718924343585968 norm:0.0005337658803910017 max memory_allocated 29273.87548828125 
[2025-03-01 19:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.17071083188056946 norm:0.0004903831868432462 max memory_allocated 29273.87548828125 
[2025-03-01 19:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.17002837359905243 norm:0.0004469418490771204 max memory_allocated 29273.87548828125 
[2025-03-01 19:02:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.16962966322898865 norm:0.0004301324370317161 max memory_allocated 29273.87548828125 
[2025-03-01 19:03:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.1694255769252777 norm:0.0004143074620515108 max memory_allocated 29273.87548828125 
[2025-03-01 19:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.16928885877132416 norm:0.00040435497066937387 max memory_allocated 29273.87548828125 
[2025-03-01 19:05:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.16918528079986572 norm:0.00038706909981556237 max memory_allocated 29273.87548828125 
[2025-03-01 19:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.16910885274410248 norm:0.0003754666249733418 max memory_allocated 29273.87548828125 
[2025-03-01 19:06:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.1690426617860794 norm:0.00036282173823565245 max memory_allocated 29273.87548828125 
[2025-03-01 19:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.16893142461776733 norm:0.000354380055796355 max memory_allocated 29273.87548828125 
[2025-03-01 19:08:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.16890034079551697 norm:0.0003533091221470386 max memory_allocated 29273.87548828125 
[2025-03-01 19:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.16893057525157928 norm:0.0003498836304061115 max memory_allocated 29273.87548828125 
[2025-03-01 19:10:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.16895093023777008 norm:0.00034368177875876427 max memory_allocated 29273.87548828125 
[2025-03-01 19:10:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.1689283847808838 norm:0.00033728816197253764 max memory_allocated 29273.87548828125 
[2025-03-01 19:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.16893282532691956 norm:0.0003362315474078059 max memory_allocated 29273.87548828125 
[2025-03-01 19:12:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.16894273459911346 norm:0.0003285766579210758 max memory_allocated 29273.87548828125 
[2025-03-01 19:12:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-01 19:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.2001529335975647 norm:0.004455515183508396 max memory_allocated 29274.06298828125 
[2025-03-01 19:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.18746796250343323 norm:0.002255858853459358 max memory_allocated 29274.06298828125 
[2025-03-01 19:15:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.17832204699516296 norm:0.0012485331390053034 max memory_allocated 29274.06298828125 
[2025-03-01 19:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.17489570379257202 norm:0.0008480099495500326 max memory_allocated 29274.06298828125 
[2025-03-01 19:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.17316582798957825 norm:0.0006826692260801792 max memory_allocated 29274.06298828125 
[2025-03-01 19:17:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.17208640277385712 norm:0.0005857880460098386 max memory_allocated 29274.06298828125 
[2025-03-01 19:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.17139695584774017 norm:0.0005108213517814875 max memory_allocated 29274.06298828125 
[2025-03-01 19:19:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.17102739214897156 norm:0.0004772983375005424 max memory_allocated 29274.06298828125 
[2025-03-01 19:20:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.17075562477111816 norm:0.00044070507283322513 max memory_allocated 29274.06298828125 
[2025-03-01 19:21:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.1705913543701172 norm:0.00042450177716091275 max memory_allocated 29274.06298828125 
[2025-03-01 19:21:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.17044733464717865 norm:0.00039893656503409147 max memory_allocated 29274.06298828125 
[2025-03-01 19:22:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.17034661769866943 norm:0.00039103953167796135 max memory_allocated 29274.06298828125 
[2025-03-01 19:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.17029142379760742 norm:0.0003822119615506381 max memory_allocated 29274.06298828125 
[2025-03-01 19:24:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.1702621430158615 norm:0.0003807246976066381 max memory_allocated 29274.06298828125 
[2025-03-01 19:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.17025353014469147 norm:0.0003703189140651375 max memory_allocated 29274.06298828125 
[2025-03-01 19:25:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.17020659148693085 norm:0.00036524891038425267 max memory_allocated 29274.06298828125 
[2025-03-01 19:26:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.17016850411891937 norm:0.00035822135396301746 max memory_allocated 29274.06298828125 
[2025-03-01 19:27:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.17013216018676758 norm:0.000350971648003906 max memory_allocated 29274.06298828125 
[2025-03-01 19:28:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.1701156497001648 norm:0.0003466969064902514 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.17005759477615356 norm:0.0003367980243638158 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-01 19:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.19859856367111206 norm:0.004816952161490917 max memory_allocated 29274.25048828125 
[2025-03-01 19:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.1869790405035019 norm:0.002442202065140009 max memory_allocated 29274.25048828125 
[2025-03-01 19:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.17907337844371796 norm:0.0012772164773195982 max memory_allocated 29274.25048828125 
[2025-03-01 19:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.17590303719043732 norm:0.0007902751676738262 max memory_allocated 29274.25048828125 
[2025-03-01 19:33:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.17431332170963287 norm:0.0006608907133340836 max memory_allocated 29274.25048828125 
[2025-03-01 19:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.17326876521110535 norm:0.000578744278755039 max memory_allocated 29274.25048828125 
[2025-03-01 19:35:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.17264413833618164 norm:0.0005337116308510303 max memory_allocated 29274.25048828125 
[2025-03-01 19:36:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.17234556376934052 norm:0.0005017406074330211 max memory_allocated 29274.25048828125 
[2025-03-01 19:36:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.1720987856388092 norm:0.00045801536180078983 max memory_allocated 29274.25048828125 
[2025-03-01 19:37:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.17191779613494873 norm:0.00042354033212177455 max memory_allocated 29274.25048828125 
[2025-03-01 19:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.1718091368675232 norm:0.00040717123192735016 max memory_allocated 29274.25048828125 
[2025-03-01 19:39:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.17176896333694458 norm:0.0003979565226472914 max memory_allocated 29274.25048828125 
[2025-03-01 19:40:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.17167431116104126 norm:0.00038080819649621844 max memory_allocated 29274.25048828125 
[2025-03-01 19:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.17161919176578522 norm:0.0003695293562486768 max memory_allocated 29274.25048828125 
[2025-03-01 19:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.17151162028312683 norm:0.0003512300900183618 max memory_allocated 29274.25048828125 
[2025-03-01 19:42:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.17145591974258423 norm:0.00033710067509673536 max memory_allocated 29274.25048828125 
[2025-03-01 19:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.17138463258743286 norm:0.0003211524453945458 max memory_allocated 29274.25048828125 
[2025-03-01 19:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.17134162783622742 norm:0.0003142145578749478 max memory_allocated 29274.25048828125 
[2025-03-01 19:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.17129652202129364 norm:0.0003068353980779648 max memory_allocated 29274.25048828125 
[2025-03-01 19:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.1712958663702011 norm:0.000303133565466851 max memory_allocated 29274.25048828125 
[2025-03-01 19:46:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-01 19:47:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.2008618414402008 norm:0.0037312242202460766 max memory_allocated 29274.43798828125 
[2025-03-01 19:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.1911734789609909 norm:0.0019207204459235072 max memory_allocated 29274.43798828125 
[2025-03-01 19:48:43 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.18396702408790588 norm:0.0010789165971800685 max memory_allocated 29274.43798828125 
[2025-03-01 19:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.18131470680236816 norm:0.000750768173020333 max memory_allocated 29274.43798828125 
[2025-03-01 19:50:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.1799446940422058 norm:0.0006310021854005754 max memory_allocated 29274.43798828125 
[2025-03-01 19:51:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.17908239364624023 norm:0.0005836088093928993 max memory_allocated 29274.43798828125 
[2025-03-01 19:51:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.17857906222343445 norm:0.0005315195303410292 max memory_allocated 29274.43798828125 
[2025-03-01 19:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.17829319834709167 norm:0.0004996301140636206 max memory_allocated 29274.43798828125 
[2025-03-01 19:53:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.17808818817138672 norm:0.0004572410834953189 max memory_allocated 29274.43798828125 
[2025-03-01 19:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.17794917523860931 norm:0.0004329931689426303 max memory_allocated 29274.43798828125 
[2025-03-01 19:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.17786645889282227 norm:0.0004058098129462451 max memory_allocated 29274.43798828125 
[2025-03-01 19:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.1777840405702591 norm:0.0003939562011510134 max memory_allocated 29274.43798828125 
[2025-03-01 19:56:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.17771990597248077 norm:0.0003726657887455076 max memory_allocated 29274.43798828125 
[2025-03-01 19:57:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.17769955098628998 norm:0.00036007724702358246 max memory_allocated 29274.43798828125 
[2025-03-01 19:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.17763128876686096 norm:0.00034663319820538163 max memory_allocated 29274.43798828125 
[2025-03-01 19:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.17758826911449432 norm:0.00033510130015201867 max memory_allocated 29274.43798828125 
[2025-03-01 20:00:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.17753995954990387 norm:0.00032419624039903283 max memory_allocated 29274.43798828125 
[2025-03-01 20:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.17750610411167145 norm:0.0003179998602718115 max memory_allocated 29274.43798828125 
[2025-03-01 20:01:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.1775486022233963 norm:0.0003179462219122797 max memory_allocated 29274.43798828125 
[2025-03-01 20:02:35 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.1775607019662857 norm:0.00030980532756075263 max memory_allocated 29274.43798828125 
[2025-03-01 20:02:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-01 20:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.20704326033592224 norm:0.002863138448446989 max memory_allocated 29274.62548828125 
[2025-03-01 20:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.19840984046459198 norm:0.001433212892152369 max memory_allocated 29274.62548828125 
[2025-03-01 20:05:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.19173885881900787 norm:0.000938618672080338 max memory_allocated 29274.62548828125 
[2025-03-01 20:06:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.18919050693511963 norm:0.0007090616854839027 max memory_allocated 29274.62548828125 
[2025-03-01 20:07:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.18785330653190613 norm:0.0006179850315675139 max memory_allocated 29274.62548828125 
[2025-03-01 20:07:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.1869177669286728 norm:0.0005366436089389026 max memory_allocated 29274.62548828125 
[2025-03-01 20:08:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.18641364574432373 norm:0.0005002764519304037 max memory_allocated 29274.62548828125 
[2025-03-01 20:09:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.18617616593837738 norm:0.000473756022984162 max memory_allocated 29274.62548828125 
[2025-03-01 20:10:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.18601733446121216 norm:0.00044027145486325026 max memory_allocated 29274.62548828125 
[2025-03-01 20:11:09 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.18592117726802826 norm:0.00041680384310893714 max memory_allocated 29274.62548828125 
[2025-03-01 20:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.18584637343883514 norm:0.0004056273028254509 max memory_allocated 29274.62548828125 
[2025-03-01 20:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.1857946217060089 norm:0.0003829407796729356 max memory_allocated 29274.62548828125 
[2025-03-01 20:13:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.1857532113790512 norm:0.000365971791325137 max memory_allocated 29274.62548828125 
[2025-03-01 20:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.18571516871452332 norm:0.000356418255250901 max memory_allocated 29274.62548828125 
[2025-03-01 20:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.1856829971075058 norm:0.0003436982515268028 max memory_allocated 29274.62548828125 
[2025-03-01 20:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.1856141984462738 norm:0.0003292021865490824 max memory_allocated 29274.62548828125 
[2025-03-01 20:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.18556350469589233 norm:0.0003274212358519435 max memory_allocated 29274.62548828125 
[2025-03-01 20:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.18557964265346527 norm:0.00032363241189159453 max memory_allocated 29274.62548828125 
[2025-03-01 20:18:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.18554560840129852 norm:0.0003155191952828318 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.18551909923553467 norm:0.00031036947621032596 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-01 20:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.22008779644966125 norm:0.0015206272946670651 max memory_allocated 29274.81298828125 
[2025-03-01 20:21:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.21058723330497742 norm:0.0008739125914871693 max memory_allocated 29274.81298828125 
[2025-03-01 20:22:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.20395596325397491 norm:0.0005821419763378799 max memory_allocated 29274.81298828125 
[2025-03-01 20:22:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.20143763720989227 norm:0.0004379971360322088 max memory_allocated 29274.81298828125 
[2025-03-01 20:23:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.20006528496742249 norm:0.0003663918760139495 max memory_allocated 29274.81298828125 
[2025-03-01 20:24:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.19914238154888153 norm:0.00032264477340504527 max memory_allocated 29274.81298828125 
[2025-03-01 20:25:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.19854100048542023 norm:0.0002984666789416224 max memory_allocated 29274.81298828125 
[2025-03-01 20:26:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.19821198284626007 norm:0.00028568162815645337 max memory_allocated 29274.81298828125 
[2025-03-01 20:27:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.19799968600273132 norm:0.0002742272336035967 max memory_allocated 29274.81298828125 
[2025-03-01 20:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.1977945864200592 norm:0.0002687650849111378 max memory_allocated 29274.81298828125 
[2025-03-01 20:28:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.1976868361234665 norm:0.0002648108929861337 max memory_allocated 29274.81298828125 
[2025-03-01 20:29:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.1975908875465393 norm:0.0002611096715554595 max memory_allocated 29274.81298828125 
[2025-03-01 20:30:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.1975117027759552 norm:0.0002587224589660764 max memory_allocated 29274.81298828125 
[2025-03-01 20:31:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.19743429124355316 norm:0.00025771831860765815 max memory_allocated 29274.81298828125 
[2025-03-01 20:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.19738973677158356 norm:0.0002550750505179167 max memory_allocated 29274.81298828125 
[2025-03-01 20:32:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.19733506441116333 norm:0.00025169397122226655 max memory_allocated 29274.81298828125 
[2025-03-01 20:33:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.19732314348220825 norm:0.00025050589465536177 max memory_allocated 29274.81298828125 
[2025-03-01 20:34:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.19725890457630157 norm:0.0002478075330145657 max memory_allocated 29274.81298828125 
[2025-03-01 20:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.19725513458251953 norm:0.0002486295416019857 max memory_allocated 29274.81298828125 
[2025-03-01 20:35:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.19723527133464813 norm:0.0002467538870405406 max memory_allocated 29274.81298828125 
[2025-03-01 20:36:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-01 20:37:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.22573180496692657 norm:0.00133427360560745 max memory_allocated 29275.00048828125 
[2025-03-01 20:37:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.21879182755947113 norm:0.0007294524693861604 max memory_allocated 29275.00048828125 
[2025-03-01 20:38:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.21329987049102783 norm:0.0005123359733261168 max memory_allocated 29275.00048828125 
[2025-03-01 20:39:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.21169152855873108 norm:0.0004166504368185997 max memory_allocated 29275.00048828125 
[2025-03-01 20:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.2105114907026291 norm:0.00036256739986129105 max memory_allocated 29275.00048828125 
[2025-03-01 20:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.209619402885437 norm:0.0003324839344713837 max memory_allocated 29275.00048828125 
[2025-03-01 20:42:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.2091023325920105 norm:0.0003060033777728677 max memory_allocated 29275.00048828125 
[2025-03-01 20:42:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.20883755385875702 norm:0.0002920899714808911 max memory_allocated 29275.00048828125 
[2025-03-01 20:43:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.20869627594947815 norm:0.0002791346632875502 max memory_allocated 29275.00048828125 
[2025-03-01 20:44:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.20859552919864655 norm:0.00027174685965292156 max memory_allocated 29275.00048828125 
[2025-03-01 20:45:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.2085108757019043 norm:0.0002635142591316253 max memory_allocated 29275.00048828125 
[2025-03-01 20:46:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.2084423452615738 norm:0.0002527114120312035 max memory_allocated 29275.00048828125 
[2025-03-01 20:46:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.20837970077991486 norm:0.00024511636001989245 max memory_allocated 29275.00048828125 
[2025-03-01 20:47:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.20832987129688263 norm:0.00024169828975573182 max memory_allocated 29275.00048828125 
[2025-03-01 20:48:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.20826123654842377 norm:0.000236750696785748 max memory_allocated 29275.00048828125 
[2025-03-01 20:49:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.20819172263145447 norm:0.00023241991584654897 max memory_allocated 29275.00048828125 
[2025-03-01 20:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.20816746354103088 norm:0.00022621778771281242 max memory_allocated 29275.00048828125 
[2025-03-01 20:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.20813432335853577 norm:0.00022600378724746406 max memory_allocated 29275.00048828125 
[2025-03-01 20:51:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.2081124633550644 norm:0.00022130832076072693 max memory_allocated 29275.00048828125 
[2025-03-01 20:52:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.20808282494544983 norm:0.00022159202490001917 max memory_allocated 29275.00048828125 
[2025-03-01 20:52:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-01 20:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.2428877055644989 norm:0.0013344688341021538 max memory_allocated 29275.18798828125 
[2025-03-01 20:54:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.23573412001132965 norm:0.0007297566626220942 max memory_allocated 29275.18798828125 
[2025-03-01 20:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.22984547913074493 norm:0.0004727692867163569 max memory_allocated 29275.18798828125 
[2025-03-01 20:56:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.22804033756256104 norm:0.00035068453871645033 max memory_allocated 29275.18798828125 
[2025-03-01 20:57:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.2268131524324417 norm:0.00029561479459516704 max memory_allocated 29275.18798828125 
[2025-03-01 20:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.22588449716567993 norm:0.0002624321496114135 max memory_allocated 29275.18798828125 
[2025-03-01 20:58:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.22533346712589264 norm:0.00023726641666144133 max memory_allocated 29275.18798828125 
[2025-03-01 20:59:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.22502070665359497 norm:0.00022241099213715643 max memory_allocated 29275.18798828125 
[2025-03-01 21:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.224816232919693 norm:0.00021111212845426053 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.22467155754566193 norm:0.00020294604473747313 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.22456571459770203 norm:0.00019812010577879846 max memory_allocated 29275.18798828125 
[2025-03-01 21:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.22448784112930298 norm:0.00019563574460335076 max memory_allocated 29275.18798828125 
[2025-03-01 21:03:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.22438944876194 norm:0.0001919893256854266 max memory_allocated 29275.18798828125 
[2025-03-01 21:04:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.22432319819927216 norm:0.00018678260676097125 max memory_allocated 29275.18798828125 
[2025-03-01 21:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.2242594063282013 norm:0.0001847942330641672 max memory_allocated 29275.18798828125 
[2025-03-01 21:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.2241840660572052 norm:0.0001848188112489879 max memory_allocated 29275.18798828125 
[2025-03-01 21:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.22412750124931335 norm:0.0001827137020882219 max memory_allocated 29275.18798828125 
[2025-03-01 21:07:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.22408661246299744 norm:0.0001830165710998699 max memory_allocated 29275.18798828125 
[2025-03-01 21:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.22405530512332916 norm:0.00018133157573174685 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.22401218116283417 norm:0.00017951242625713348 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-01 21:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.2590674161911011 norm:0.0008312008576467633 max memory_allocated 29275.37548828125 
[2025-03-01 21:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.25259897112846375 norm:0.00044665823224931955 max memory_allocated 29275.37548828125 
[2025-03-01 21:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.24689021706581116 norm:0.00031132588628679514 max memory_allocated 29275.37548828125 
[2025-03-01 21:12:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.24513563513755798 norm:0.0002679881581570953 max memory_allocated 29275.37548828125 
[2025-03-01 21:13:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.2439318150281906 norm:0.00024502023006789386 max memory_allocated 29275.37548828125 
[2025-03-01 21:14:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.24299250543117523 norm:0.0002343113737879321 max memory_allocated 29275.37548828125 
[2025-03-01 21:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.24245305359363556 norm:0.00022871990222483873 max memory_allocated 29275.37548828125 
[2025-03-01 21:16:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.24215827882289886 norm:0.00022431495017372072 max memory_allocated 29275.37548828125 
[2025-03-01 21:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.24199627339839935 norm:0.0002200248563895002 max memory_allocated 29275.37548828125 
[2025-03-01 21:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.24190263450145721 norm:0.00021988867956679314 max memory_allocated 29275.37548828125 
[2025-03-01 21:18:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.24177981913089752 norm:0.00021665735403075814 max memory_allocated 29275.37548828125 
[2025-03-01 21:19:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.24166594445705414 norm:0.0002162569435313344 max memory_allocated 29275.37548828125 
[2025-03-01 21:20:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.24159328639507294 norm:0.00021730830485466868 max memory_allocated 29275.37548828125 
[2025-03-01 21:21:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.24152736365795135 norm:0.0002171291853301227 max memory_allocated 29275.37548828125 
[2025-03-01 21:21:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.24148505926132202 norm:0.00022017738956492394 max memory_allocated 29275.37548828125 
[2025-03-01 21:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.24144956469535828 norm:0.00021715325419791043 max memory_allocated 29275.37548828125 
[2025-03-01 21:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.2413754016160965 norm:0.0002149042848031968 max memory_allocated 29275.37548828125 
[2025-03-01 21:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.24133679270744324 norm:0.0002152248634956777 max memory_allocated 29275.37548828125 
[2025-03-01 21:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.24128401279449463 norm:0.00021840285626240075 max memory_allocated 29275.37548828125 
[2025-03-01 21:26:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.2412719577550888 norm:0.00021745444973930717 max memory_allocated 29275.37548828125 
[2025-03-01 21:26:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-01 21:27:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.2792513966560364 norm:0.0008714164141565561 max memory_allocated 29275.56298828125 
[2025-03-01 21:28:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.2724113166332245 norm:0.0004505138495005667 max memory_allocated 29275.56298828125 
[2025-03-01 21:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.2662440538406372 norm:0.0003056623390875757 max memory_allocated 29275.56298828125 
[2025-03-01 21:29:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.26440316438674927 norm:0.00024343386758118868 max memory_allocated 29275.56298828125 
[2025-03-01 21:30:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.2631301283836365 norm:0.00021112951799295843 max memory_allocated 29275.56298828125 
[2025-03-01 21:31:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.26218414306640625 norm:0.00019397478899918497 max memory_allocated 29275.56298828125 
[2025-03-01 21:32:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.2616644501686096 norm:0.00018283988174516708 max memory_allocated 29275.56298828125 
[2025-03-01 21:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.26141873002052307 norm:0.00017373781884089112 max memory_allocated 29275.56298828125 
[2025-03-01 21:33:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.2612413167953491 norm:0.0001702737936284393 max memory_allocated 29275.56298828125 
[2025-03-01 21:34:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.261122465133667 norm:0.00016832994879223406 max memory_allocated 29275.56298828125 
[2025-03-01 21:35:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.2610200345516205 norm:0.00016638280067127198 max memory_allocated 29275.56298828125 
[2025-03-01 21:36:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.2609233260154724 norm:0.00016527902334928513 max memory_allocated 29275.56298828125 
[2025-03-01 21:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.2608415186405182 norm:0.0001650900230742991 max memory_allocated 29275.56298828125 
[2025-03-01 21:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.2607724070549011 norm:0.000164409342687577 max memory_allocated 29275.56298828125 
[2025-03-01 21:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.2607119679450989 norm:0.00016274630615953356 max memory_allocated 29275.56298828125 
[2025-03-01 21:39:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.2606515884399414 norm:0.00016267823230009526 max memory_allocated 29275.56298828125 
[2025-03-01 21:40:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.26061978936195374 norm:0.00016337267879862338 max memory_allocated 29275.56298828125 
[2025-03-01 21:41:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.26060110330581665 norm:0.00016404099005740136 max memory_allocated 29275.56298828125 
[2025-03-01 21:41:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.2605641186237335 norm:0.00016475445590913296 max memory_allocated 29275.56298828125 
[2025-03-01 21:42:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.26053524017333984 norm:0.00016326755576301366 max memory_allocated 29275.56298828125 
[2025-03-01 21:43:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-01 21:43:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.30349597334861755 norm:0.0011234722333028913 max memory_allocated 29275.75048828125 
[2025-03-01 21:44:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.296268105506897 norm:0.0006658658967353404 max memory_allocated 29275.75048828125 
[2025-03-01 21:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.28968024253845215 norm:0.0004804967902600765 max memory_allocated 29275.75048828125 
[2025-03-01 21:46:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.2877623438835144 norm:0.0003950118843931705 max memory_allocated 29275.75048828125 
[2025-03-01 21:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.28630486130714417 norm:0.00034294300712645054 max memory_allocated 29275.75048828125 
[2025-03-01 21:48:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.2852623164653778 norm:0.0003147402894683182 max memory_allocated 29275.75048828125 
[2025-03-01 21:48:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.2846912443637848 norm:0.00029870521393604577 max memory_allocated 29275.75048828125 
[2025-03-01 21:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.28439727425575256 norm:0.00028127850964665413 max memory_allocated 29275.75048828125 
[2025-03-01 21:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.28421181440353394 norm:0.0002706212399061769 max memory_allocated 29275.75048828125 
[2025-03-01 21:51:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.28405967354774475 norm:0.0002640743041411042 max memory_allocated 29275.75048828125 
[2025-03-01 21:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.2839289605617523 norm:0.00026028748834505677 max memory_allocated 29275.75048828125 
[2025-03-01 21:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.2837980091571808 norm:0.0002522125723771751 max memory_allocated 29275.75048828125 
[2025-03-01 21:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.28370243310928345 norm:0.0002492567873559892 max memory_allocated 29275.75048828125 
[2025-03-01 21:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.28361690044403076 norm:0.0002473205095157027 max memory_allocated 29275.75048828125 
[2025-03-01 21:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.2835584580898285 norm:0.00024581278557889163 max memory_allocated 29275.75048828125 
[2025-03-01 21:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.2835051417350769 norm:0.0002446408325340599 max memory_allocated 29275.75048828125 
[2025-03-01 21:57:00 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.2834605872631073 norm:0.0002415987546555698 max memory_allocated 29275.75048828125 
[2025-03-01 21:57:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.28339919447898865 norm:0.00024512430536560714 max memory_allocated 29275.75048828125 
[2025-03-01 21:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.28333696722984314 norm:0.00023926247376948595 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.2833140194416046 norm:0.0002410978195257485 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-01 22:00:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.32407864928245544 norm:0.0007637155940756202 max memory_allocated 29275.93798828125 
[2025-03-01 22:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.31724312901496887 norm:0.0004523083916865289 max memory_allocated 29275.93798828125 
[2025-03-01 22:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.31081297993659973 norm:0.0003174465091433376 max memory_allocated 29275.93798828125 
[2025-03-01 22:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.30901774764060974 norm:0.00025705405278131366 max memory_allocated 29275.93798828125 
[2025-03-01 22:03:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.3076854348182678 norm:0.00022149040887597948 max memory_allocated 29275.93798828125 
[2025-03-01 22:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.30665549635887146 norm:0.00019885812071152031 max memory_allocated 29275.93798828125 
[2025-03-01 22:05:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.3061521053314209 norm:0.00018639984773471951 max memory_allocated 29275.93798828125 
[2025-03-01 22:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.30591297149658203 norm:0.0001786329667083919 max memory_allocated 29275.93798828125 
[2025-03-01 22:07:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.30573034286499023 norm:0.00017363236111123115 max memory_allocated 29275.93798828125 
[2025-03-01 22:08:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.30560868978500366 norm:0.0001716974365990609 max memory_allocated 29275.93798828125 
[2025-03-01 22:08:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.3054977059364319 norm:0.00016725671594031155 max memory_allocated 29275.93798828125 
[2025-03-01 22:09:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.30540329217910767 norm:0.00016650168981868774 max memory_allocated 29275.93798828125 
[2025-03-01 22:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.3053089380264282 norm:0.00016562920063734055 max memory_allocated 29275.93798828125 
[2025-03-01 22:11:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.30524447560310364 norm:0.00016557851631660014 max memory_allocated 29275.93798828125 
[2025-03-01 22:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.3051910400390625 norm:0.0001642073766561225 max memory_allocated 29275.93798828125 
[2025-03-01 22:12:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.3051236569881439 norm:0.00016089918790385127 max memory_allocated 29275.93798828125 
[2025-03-01 22:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.3050696551799774 norm:0.00016198208322748542 max memory_allocated 29275.93798828125 
[2025-03-01 22:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.3050285577774048 norm:0.00016268920444417745 max memory_allocated 29275.93798828125 
[2025-03-01 22:15:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.30498215556144714 norm:0.00016232969937846065 max memory_allocated 29275.93798828125 
[2025-03-01 22:16:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.30495089292526245 norm:0.00016127392882481217 max memory_allocated 29275.93798828125 
[2025-03-01 22:16:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-01 22:17:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.35522958636283875 norm:0.0017085687723010778 max memory_allocated 29276.12548828125 
[2025-03-01 22:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.3476020097732544 norm:0.0011729118414223194 max memory_allocated 29276.12548828125 
[2025-03-01 22:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.3406446874141693 norm:0.0008813499007374048 max memory_allocated 29276.12548828125 
[2025-03-01 22:19:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.3384580612182617 norm:0.0007277355762198567 max memory_allocated 29276.12548828125 
[2025-03-01 22:20:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.33669525384902954 norm:0.000628356181550771 max memory_allocated 29276.12548828125 
[2025-03-01 22:21:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.3355383276939392 norm:0.0006256576161831617 max memory_allocated 29276.12548828125 
[2025-03-01 22:22:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.33483389019966125 norm:0.0005776186008006334 max memory_allocated 29276.12548828125 
[2025-03-01 22:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.33446377515792847 norm:0.0005694260471500456 max memory_allocated 29276.12548828125 
[2025-03-01 22:23:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.334258109331131 norm:0.0005070168990641832 max memory_allocated 29276.12548828125 
[2025-03-01 22:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.33410221338272095 norm:0.00048203737242147326 max memory_allocated 29276.12548828125 
[2025-03-01 22:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.3338605463504791 norm:0.0004693145747296512 max memory_allocated 29276.12548828125 
[2025-03-01 22:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.3338437080383301 norm:0.0004997395444661379 max memory_allocated 29276.12548828125 
[2025-03-01 22:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.3337318003177643 norm:0.0004567167488858104 max memory_allocated 29276.12548828125 
[2025-03-01 22:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.33363229036331177 norm:0.00043808514601550996 max memory_allocated 29276.12548828125 
[2025-03-01 22:28:49 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.3336508572101593 norm:0.0004364327760413289 max memory_allocated 29276.12548828125 
[2025-03-01 22:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.33353567123413086 norm:0.00041533319745212793 max memory_allocated 29276.12548828125 
[2025-03-01 22:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.3334357738494873 norm:0.00037992559373378754 max memory_allocated 29276.12548828125 
[2025-03-01 22:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.33315566182136536 norm:0.00041100362432189286 max memory_allocated 29276.12548828125 
[2025-03-01 22:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.33302029967308044 norm:0.0003845580213237554 max memory_allocated 29276.12548828125 
[2025-03-01 22:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.33306434750556946 norm:0.0003751026524696499 max memory_allocated 29276.12548828125 
[2025-03-01 22:33:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-01 22:34:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.38130125403404236 norm:0.0010365339694544673 max memory_allocated 29276.31298828125 
[2025-03-01 22:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.3738003373146057 norm:0.0005850089364685118 max memory_allocated 29276.31298828125 
[2025-03-01 22:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.36677369475364685 norm:0.0003941817849408835 max memory_allocated 29276.31298828125 
[2025-03-01 22:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.36476248502731323 norm:0.0003102458140347153 max memory_allocated 29276.31298828125 
[2025-03-01 22:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.3632694482803345 norm:0.000259331485722214 max memory_allocated 29276.31298828125 
[2025-03-01 22:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.3622432351112366 norm:0.0002268578828079626 max memory_allocated 29276.31298828125 
[2025-03-01 22:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.3617742955684662 norm:0.00020928085723426193 max memory_allocated 29276.31298828125 
[2025-03-01 22:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.36153727769851685 norm:0.0001971745805349201 max memory_allocated 29276.31298828125 
[2025-03-01 22:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.3613665997982025 norm:0.00018997213919647038 max memory_allocated 29276.31298828125 
[2025-03-01 22:41:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.3612353205680847 norm:0.00018528416694607586 max memory_allocated 29276.31298828125 
[2025-03-01 22:42:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.3611050844192505 norm:0.00018170863040722907 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.3609906733036041 norm:0.00018184423970524222 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.36089247465133667 norm:0.00018016954709310085 max memory_allocated 29276.31298828125 
[2025-03-01 22:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.3608179986476898 norm:0.00017847730487119406 max memory_allocated 29276.31298828125 
[2025-03-01 22:45:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.3607546091079712 norm:0.00017921462131198496 max memory_allocated 29276.31298828125 
[2025-03-01 22:46:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.36066851019859314 norm:0.00017914597992785275 max memory_allocated 29276.31298828125 
[2025-03-01 22:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.3606020510196686 norm:0.00017860918887890875 max memory_allocated 29276.31298828125 
[2025-03-01 22:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.3605487048625946 norm:0.00018009764607995749 max memory_allocated 29276.31298828125 
[2025-03-01 22:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.36050283908843994 norm:0.00017850971198640764 max memory_allocated 29276.31298828125 
[2025-03-01 22:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.360445499420166 norm:0.00017799990018829703 max memory_allocated 29276.31298828125 
[2025-03-01 22:49:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-01 22:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.41643035411834717 norm:0.0010581262176856399 max memory_allocated 29276.50048828125 
[2025-03-01 22:51:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.4071260094642639 norm:0.0005546672618947923 max memory_allocated 29276.50048828125 
[2025-03-01 22:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.39865776896476746 norm:0.0003510288952384144 max memory_allocated 29276.50048828125 
[2025-03-01 22:53:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.3961600661277771 norm:0.0002722236094996333 max memory_allocated 29276.50048828125 
[2025-03-01 22:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.39439988136291504 norm:0.00023419609351549298 max memory_allocated 29276.50048828125 
[2025-03-01 22:54:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.39337289333343506 norm:0.00021104846382513642 max memory_allocated 29276.50048828125 
[2025-03-01 22:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.3928770124912262 norm:0.00020032499742228538 max memory_allocated 29276.50048828125 
[2025-03-01 22:56:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.39261937141418457 norm:0.0001945124240592122 max memory_allocated 29276.50048828125 
[2025-03-01 22:57:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.3924408257007599 norm:0.0001929024583660066 max memory_allocated 29276.50048828125 
[2025-03-01 22:58:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.3922884464263916 norm:0.00018857739632949233 max memory_allocated 29276.50048828125 
[2025-03-01 22:58:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.39217427372932434 norm:0.00018674592138268054 max memory_allocated 29276.50048828125 
[2025-03-01 22:59:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.39208322763442993 norm:0.00018625656957738101 max memory_allocated 29276.50048828125 
[2025-03-01 23:00:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.3919885456562042 norm:0.00018471352814231068 max memory_allocated 29276.50048828125 
[2025-03-01 23:01:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.3919087052345276 norm:0.00018481191364116967 max memory_allocated 29276.50048828125 
[2025-03-01 23:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.3918418288230896 norm:0.00018490321235731244 max memory_allocated 29276.50048828125 
[2025-03-01 23:02:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.3917734920978546 norm:0.0001841038465499878 max memory_allocated 29276.50048828125 
[2025-03-01 23:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.39169201254844666 norm:0.00018503500905353576 max memory_allocated 29276.50048828125 
[2025-03-01 23:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.39163392782211304 norm:0.00018570205429568887 max memory_allocated 29276.50048828125 
[2025-03-01 23:05:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.3915880620479584 norm:0.00018561992328613997 max memory_allocated 29276.50048828125 
[2025-03-01 23:06:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.3915409445762634 norm:0.00018342636758461595 max memory_allocated 29276.50048828125 
[2025-03-01 23:06:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-01 23:07:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.4490390121936798 norm:0.0010912533616647124 max memory_allocated 29276.68798828125 
[2025-03-01 23:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.4400794804096222 norm:0.0005854577175341547 max memory_allocated 29276.68798828125 
[2025-03-01 23:09:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.43148311972618103 norm:0.0003756520163733512 max memory_allocated 29276.68798828125 
[2025-03-01 23:09:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.4289078712463379 norm:0.0002991272776853293 max memory_allocated 29276.68798828125 
[2025-03-01 23:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.4270923137664795 norm:0.0002571770455688238 max memory_allocated 29276.68798828125 
[2025-03-01 23:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.42611315846443176 norm:0.00023336832236964256 max memory_allocated 29276.68798828125 
[2025-03-01 23:12:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.42574185132980347 norm:0.0002238949527963996 max memory_allocated 29276.68798828125 
[2025-03-01 23:13:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.4255210757255554 norm:0.00022005831124261022 max memory_allocated 29276.68798828125 
[2025-03-01 23:13:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.42534998059272766 norm:0.00021272318554110825 max memory_allocated 29276.68798828125 
[2025-03-01 23:14:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.42525696754455566 norm:0.00021075975382700562 max memory_allocated 29276.68798828125 
[2025-03-01 23:15:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.4251362681388855 norm:0.0002130926732206717 max memory_allocated 29276.68798828125 
[2025-03-01 23:16:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.4250067472457886 norm:0.0002115613897331059 max memory_allocated 29276.68798828125 
[2025-03-01 23:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.42491233348846436 norm:0.00020983009017072618 max memory_allocated 29276.68798828125 
[2025-03-01 23:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.4248299300670624 norm:0.00020842872618231922 max memory_allocated 29276.68798828125 
[2025-03-01 23:18:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.42474454641342163 norm:0.00020737509476020932 max memory_allocated 29276.68798828125 
[2025-03-01 23:19:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.42463716864585876 norm:0.00020943149866070598 max memory_allocated 29276.68798828125 
[2025-03-01 23:20:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.4245791435241699 norm:0.00020938376837875694 max memory_allocated 29276.68798828125 
[2025-03-01 23:21:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.42451778054237366 norm:0.000210228085052222 max memory_allocated 29276.68798828125 
[2025-03-01 23:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.4244590997695923 norm:0.0002083283761749044 max memory_allocated 29276.68798828125 
[2025-03-01 23:22:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.4243941307067871 norm:0.0002087135799229145 max memory_allocated 29276.68798828125 
[2025-03-01 23:23:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-01 23:24:03 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.4894217848777771 norm:0.0013949633575975895 max memory_allocated 29276.87548828125 
[2025-03-01 23:24:52 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.47939616441726685 norm:0.0007256718236021698 max memory_allocated 29276.87548828125 
[2025-03-01 23:25:41 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.4699874222278595 norm:0.0004585999995470047 max memory_allocated 29276.87548828125 
[2025-03-01 23:26:30 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.4669465124607086 norm:0.0003466217021923512 max memory_allocated 29276.87548828125 
[2025-03-01 23:27:19 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.4649491012096405 norm:0.0002946084423456341 max memory_allocated 29276.87548828125 
[2025-03-01 23:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.4639345109462738 norm:0.0002606276248116046 max memory_allocated 29276.87548828125 
[2025-03-01 23:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.4635111391544342 norm:0.0002452513435855508 max memory_allocated 29276.87548828125 
[2025-03-01 23:29:46 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.46327337622642517 norm:0.00023410524590872228 max memory_allocated 29276.87548828125 
[2025-03-01 23:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.46308809518814087 norm:0.0002305945090483874 max memory_allocated 29276.87548828125 
[2025-03-01 23:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.4629286527633667 norm:0.00022064569930080324 max memory_allocated 29276.87548828125 
[2025-03-01 23:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.46276047825813293 norm:0.00021890131756663322 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.4626334607601166 norm:0.000216928863665089 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:51 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.46249687671661377 norm:0.0002137795090675354 max memory_allocated 29276.87548828125 
[2025-03-01 23:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.46241623163223267 norm:0.0002131939254468307 max memory_allocated 29276.87548828125 
[2025-03-01 23:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.4622911512851715 norm:0.00021277618361636996 max memory_allocated 29276.87548828125 
[2025-03-01 23:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.46221923828125 norm:0.00021069313515909016 max memory_allocated 29276.87548828125 
[2025-03-01 23:37:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.4621475040912628 norm:0.00021246490359771997 max memory_allocated 29276.87548828125 
[2025-03-01 23:37:55 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.462091863155365 norm:0.00021125130297150463 max memory_allocated 29276.87548828125 
[2025-03-01 23:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.4620490074157715 norm:0.00020987795141991228 max memory_allocated 29276.87548828125 
[2025-03-01 23:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.461993008852005 norm:0.0002096276293741539 max memory_allocated 29276.87548828125 
[2025-03-01 23:39:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-01 23:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.5287214517593384 norm:0.0013395075220614672 max memory_allocated 29277.06298828125 
[2025-03-01 23:41:31 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.5178605914115906 norm:0.0007031513378024101 max memory_allocated 29277.06298828125 
[2025-03-01 23:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.507932186126709 norm:0.000467471283627674 max memory_allocated 29277.06298828125 
[2025-03-01 23:43:09 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.5050551295280457 norm:0.00035135657526552677 max memory_allocated 29277.06298828125 
[2025-03-01 23:43:58 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.5031725764274597 norm:0.0002877348742913455 max memory_allocated 29277.06298828125 
[2025-03-01 23:44:47 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.502256453037262 norm:0.0002585169277153909 max memory_allocated 29277.06298828125 
[2025-03-01 23:45:36 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.5018212795257568 norm:0.00024222511274274439 max memory_allocated 29277.06298828125 
[2025-03-01 23:46:25 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.501498818397522 norm:0.000232038670219481 max memory_allocated 29277.06298828125 
[2025-03-01 23:47:14 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.5012587308883667 norm:0.00022466450172942132 max memory_allocated 29277.06298828125 
[2025-03-01 23:48:03 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.5010965466499329 norm:0.00022057756723370403 max memory_allocated 29277.06298828125 
[2025-03-01 23:48:51 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.5009022951126099 norm:0.0002185860212193802 max memory_allocated 29277.06298828125 
[2025-03-01 23:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.5007970333099365 norm:0.0002163258905056864 max memory_allocated 29277.06298828125 
[2025-03-01 23:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.5007103681564331 norm:0.00021769522572867572 max memory_allocated 29277.06298828125 
[2025-03-01 23:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.5006169080734253 norm:0.00021968409419059753 max memory_allocated 29277.06298828125 
[2025-03-01 23:52:08 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.5005323886871338 norm:0.00021722991368733346 max memory_allocated 29277.06298828125 
[2025-03-01 23:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.5004304647445679 norm:0.00021760474191978574 max memory_allocated 29277.06298828125 
[2025-03-01 23:53:45 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.5003577470779419 norm:0.00021738241775892675 max memory_allocated 29277.06298828125 
[2025-03-01 23:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.5003085136413574 norm:0.00021596580336336046 max memory_allocated 29277.06298828125 
[2025-03-01 23:55:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.5002322196960449 norm:0.00022065281518734992 max memory_allocated 29277.06298828125 
[2025-03-01 23:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.500188946723938 norm:0.00021949752408545464 max memory_allocated 29277.06298828125 
[2025-03-01 23:56:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-01 23:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.5790255069732666 norm:0.001367976889014244 max memory_allocated 29277.25048828125 
[2025-03-01 23:58:11 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.5674232244491577 norm:0.0008707137312740088 max memory_allocated 29277.25048828125 
[2025-03-01 23:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.5570651292800903 norm:0.0006282448885031044 max memory_allocated 29277.25048828125 
[2025-03-01 23:59:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.5534257292747498 norm:0.0005911452462896705 max memory_allocated 29277.25048828125 
[2025-03-02 00:00:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.5511075258255005 norm:0.00045545559260062873 max memory_allocated 29277.25048828125 
[2025-03-02 00:01:27 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.5499807596206665 norm:0.0004193906206637621 max memory_allocated 29277.25048828125 
[2025-03-02 00:02:16 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.5494718551635742 norm:0.00039573360118083656 max memory_allocated 29277.25048828125 
[2025-03-02 00:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.5490676760673523 norm:0.00037823946331627667 max memory_allocated 29277.25048828125 
[2025-03-02 00:03:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.5487702488899231 norm:0.00036162318428978324 max memory_allocated 29277.25048828125 
[2025-03-02 00:04:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.5484638214111328 norm:0.00034556901664473116 max memory_allocated 29277.25048828125 
[2025-03-02 00:05:32 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.5482403039932251 norm:0.0003371126367710531 max memory_allocated 29277.25048828125 
[2025-03-02 00:06:21 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.5480220317840576 norm:0.0003293911286164075 max memory_allocated 29277.25048828125 
[2025-03-02 00:07:10 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.5478368997573853 norm:0.00032034923788160086 max memory_allocated 29277.25048828125 
[2025-03-02 00:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.5477162003517151 norm:0.00031185586703941226 max memory_allocated 29277.25048828125 
[2025-03-02 00:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.5475332736968994 norm:0.0003109679091721773 max memory_allocated 29277.25048828125 
[2025-03-02 00:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.5473991632461548 norm:0.0003036020789295435 max memory_allocated 29277.25048828125 
[2025-03-02 00:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.5473098158836365 norm:0.0002999056887347251 max memory_allocated 29277.25048828125 
[2025-03-02 00:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.547203004360199 norm:0.00029788637766614556 max memory_allocated 29277.25048828125 
[2025-03-02 00:12:04 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.5471338629722595 norm:0.00029380773776210845 max memory_allocated 29277.25048828125 
[2025-03-02 00:12:53 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.5469965934753418 norm:0.0002905992732848972 max memory_allocated 29277.25048828125 
[2025-03-02 00:13:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 00:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.6325225830078125 norm:0.0026756434235721827 max memory_allocated 29277.43798828125 
[2025-03-02 00:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.6191339492797852 norm:0.001562856836244464 max memory_allocated 29277.43798828125 
[2025-03-02 00:15:39 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.607498049736023 norm:0.0010471654823049903 max memory_allocated 29277.43798828125 
[2025-03-02 00:16:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.6034436821937561 norm:0.0008032419136725366 max memory_allocated 29277.43798828125 
[2025-03-02 00:17:17 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.6009986996650696 norm:0.0006597895408049226 max memory_allocated 29277.43798828125 
[2025-03-02 00:18:07 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.5999341011047363 norm:0.0005687468219548464 max memory_allocated 29277.43798828125 
[2025-03-02 00:18:56 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.5993678569793701 norm:0.0005148745258338749 max memory_allocated 29277.43798828125 
[2025-03-02 00:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.5989046692848206 norm:0.00046780379489064217 max memory_allocated 29277.43798828125 
[2025-03-02 00:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.5985134840011597 norm:0.00043438051943667233 max memory_allocated 29277.43798828125 
[2025-03-02 00:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.5982024073600769 norm:0.00041273172246292233 max memory_allocated 29277.43798828125 
[2025-03-02 00:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.5978956818580627 norm:0.00039379147347062826 max memory_allocated 29277.43798828125 
[2025-03-02 00:23:01 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.5976965427398682 norm:0.0003814123629126698 max memory_allocated 29277.43798828125 
[2025-03-02 00:23:50 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.5975010395050049 norm:0.0003686559502966702 max memory_allocated 29277.43798828125 
[2025-03-02 00:24:39 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.5973309874534607 norm:0.00035744867636822164 max memory_allocated 29277.43798828125 
[2025-03-02 00:25:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.5972295999526978 norm:0.00035257148556411266 max memory_allocated 29277.43798828125 
[2025-03-02 00:26:17 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.5970649719238281 norm:0.00034416173002682626 max memory_allocated 29277.43798828125 
[2025-03-02 00:27:06 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.5969076156616211 norm:0.00033506241743452847 max memory_allocated 29277.43798828125 
[2025-03-02 00:27:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.596778392791748 norm:0.00033049299963749945 max memory_allocated 29277.43798828125 
[2025-03-02 00:28:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.5967012047767639 norm:0.0003234855830669403 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.5966447591781616 norm:0.0003218158381059766 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 00:29:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:30:42 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.7015774846076965 norm:0.014868493191897869 max memory_allocated 29277.77001953125 
[2025-03-02 00:31:32 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.6860215067863464 norm:0.012643332593142986 max memory_allocated 29277.77001953125 
[2025-03-02 00:32:21 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.6716927886009216 norm:0.009598569944500923 max memory_allocated 29277.77001953125 
[2025-03-02 00:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.6661203503608704 norm:0.007991118356585503 max memory_allocated 29277.77001953125 
[2025-03-02 00:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.6631144881248474 norm:0.006969777401536703 max memory_allocated 29277.77001953125 
[2025-03-02 00:34:48 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.6616920828819275 norm:0.006230312865227461 max memory_allocated 29277.77001953125 
[2025-03-02 00:35:38 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.6608160138130188 norm:0.005683377850800753 max memory_allocated 29277.77001953125 
[2025-03-02 00:36:27 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.6601189970970154 norm:0.005155912600457668 max memory_allocated 29277.77001953125 
[2025-03-02 00:37:16 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.6595832109451294 norm:0.0048152981325984 max memory_allocated 29277.77001953125 
[2025-03-02 00:38:05 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.6591436862945557 norm:0.0044744741171598434 max memory_allocated 29277.77001953125 
[2025-03-02 00:38:54 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.6587329506874084 norm:0.0042418865486979485 max memory_allocated 29277.77001953125 
[2025-03-02 00:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.6584300994873047 norm:0.004041631706058979 max memory_allocated 29277.77001953125 
[2025-03-02 00:40:33 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.6580430865287781 norm:0.003936043009161949 max memory_allocated 29277.77001953125 
[2025-03-02 00:41:22 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.657815158367157 norm:0.0037564458325505257 max memory_allocated 29277.77001953125 
[2025-03-02 00:42:11 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.6575870513916016 norm:0.0036575617268681526 max memory_allocated 29277.77001953125 
[2025-03-02 00:43:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.6574867367744446 norm:0.0035455713514238596 max memory_allocated 29277.77001953125 
[2025-03-02 00:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.6572460532188416 norm:0.003458938095718622 max memory_allocated 29277.77001953125 
[2025-03-02 00:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.6571316123008728 norm:0.0033449260517954826 max memory_allocated 29277.77001953125 
[2025-03-02 00:45:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.6570890545845032 norm:0.003292915876954794 max memory_allocated 29277.77001953125 
[2025-03-02 00:46:17 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.6569527387619019 norm:0.003205687738955021 max memory_allocated 29277.77001953125 
[2025-03-02 00:46:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 00:46:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:47:27 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.7799060940742493 norm:0.019519440829753876 max memory_allocated 29277.95751953125 
[2025-03-02 00:48:16 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.7601160407066345 norm:0.015469868667423725 max memory_allocated 29277.95751953125 
[2025-03-02 00:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.7423762083053589 norm:0.011579628102481365 max memory_allocated 29277.95751953125 
[2025-03-02 00:49:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.7356045246124268 norm:0.009906952269375324 max memory_allocated 29277.95751953125 
[2025-03-02 00:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.732255220413208 norm:0.008631150238215923 max memory_allocated 29277.95751953125 
[2025-03-02 00:51:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.7305408716201782 norm:0.007607636507600546 max memory_allocated 29277.95751953125 
[2025-03-02 00:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.7295622825622559 norm:0.006711383815854788 max memory_allocated 29277.95751953125 
[2025-03-02 00:53:11 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.7285296320915222 norm:0.006130313966423273 max memory_allocated 29277.95751953125 
[2025-03-02 00:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.727857232093811 norm:0.005689230747520924 max memory_allocated 29277.95751953125 
[2025-03-02 00:54:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.7274433374404907 norm:0.005362334195524454 max memory_allocated 29277.95751953125 
[2025-03-02 00:55:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.727202832698822 norm:0.004899183753877878 max memory_allocated 29277.95751953125 
[2025-03-02 00:56:28 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.7267988324165344 norm:0.004675887990742922 max memory_allocated 29277.95751953125 
[2025-03-02 00:57:17 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.7263519167900085 norm:0.004541951231658459 max memory_allocated 29277.95751953125 
[2025-03-02 00:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.7260326147079468 norm:0.0044927168637514114 max memory_allocated 29277.95751953125 
[2025-03-02 00:58:56 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.7258461713790894 norm:0.004423629492521286 max memory_allocated 29277.95751953125 
[2025-03-02 00:59:45 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.7259346842765808 norm:0.004362532868981361 max memory_allocated 29277.95751953125 
[2025-03-02 01:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.7243702411651611 norm:0.006410375237464905 max memory_allocated 29277.95751953125 
[2025-03-02 01:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.7223683595657349 norm:0.022748885676264763 max memory_allocated 29277.95751953125 
[2025-03-02 01:02:13 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.7219022512435913 norm:0.025113927200436592 max memory_allocated 29277.95751953125 
[2025-03-02 01:03:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.7213067412376404 norm:0.024270210415124893 max memory_allocated 29277.95751953125 
[2025-03-02 01:03:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 01:03:25 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:04:15 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.8842072486877441 norm:0.02263444848358631 max memory_allocated 29278.14501953125 
[2025-03-02 01:05:04 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.8607393503189087 norm:0.015650078654289246 max memory_allocated 29278.14501953125 
[2025-03-02 01:05:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.841429591178894 norm:0.009029585868120193 max memory_allocated 29278.14501953125 
[2025-03-02 01:06:42 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.8326530456542969 norm:0.007717427331954241 max memory_allocated 29278.14501953125 
[2025-03-02 01:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.8281761407852173 norm:0.006900195963680744 max memory_allocated 29278.14501953125 
[2025-03-02 01:08:20 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.8261650800704956 norm:0.006728854961693287 max memory_allocated 29278.14501953125 
[2025-03-02 01:09:10 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.8244507312774658 norm:0.006163517013192177 max memory_allocated 29278.14501953125 
[2025-03-02 01:09:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.8238176703453064 norm:0.006410988513380289 max memory_allocated 29278.14501953125 
[2025-03-02 01:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.8231391906738281 norm:0.006616010796278715 max memory_allocated 29278.14501953125 
[2025-03-02 01:11:37 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.822508692741394 norm:0.006928416434675455 max memory_allocated 29278.14501953125 
[2025-03-02 01:12:26 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.8220972418785095 norm:0.00710002426058054 max memory_allocated 29278.14501953125 
[2025-03-02 01:13:16 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.8219245672225952 norm:0.00690181739628315 max memory_allocated 29278.14501953125 
[2025-03-02 01:14:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.8219002485275269 norm:0.006981479935348034 max memory_allocated 29278.14501953125 
[2025-03-02 01:14:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.8214061260223389 norm:0.007559703662991524 max memory_allocated 29278.14501953125 
[2025-03-02 01:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.8213348388671875 norm:0.007339192554354668 max memory_allocated 29278.14501953125 
[2025-03-02 01:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.8207682371139526 norm:0.007186709903180599 max memory_allocated 29278.14501953125 
[2025-03-02 01:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.8203778266906738 norm:0.006866490934044123 max memory_allocated 29278.14501953125 
[2025-03-02 01:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.8199856281280518 norm:0.006331056356430054 max memory_allocated 29278.14501953125 
[2025-03-02 01:19:00 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.8197647333145142 norm:0.006034852005541325 max memory_allocated 29278.14501953125 
[2025-03-02 01:19:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.8196379542350769 norm:0.005942950490862131 max memory_allocated 29278.14501953125 
[2025-03-02 01:20:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 01:20:10 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:20:59 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:1.2224671840667725 norm:0.05502369627356529 max memory_allocated 29278.33251953125 
[2025-03-02 01:21:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:1.1584031581878662 norm:0.03713947907090187 max memory_allocated 29278.33251953125 
[2025-03-02 01:22:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:1.1112823486328125 norm:0.023594168946146965 max memory_allocated 29278.33251953125 
[2025-03-02 01:23:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:1.091695785522461 norm:0.019920505583286285 max memory_allocated 29278.33251953125 
[2025-03-02 01:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:1.0818415880203247 norm:0.018247287720441818 max memory_allocated 29278.33251953125 
[2025-03-02 01:25:05 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:1.0753684043884277 norm:0.016731878742575645 max memory_allocated 29278.33251953125 
[2025-03-02 01:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:1.070659875869751 norm:0.01575430855154991 max memory_allocated 29278.33251953125 
[2025-03-02 01:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:1.0672270059585571 norm:0.015785515308380127 max memory_allocated 29278.33251953125 
[2025-03-02 01:27:32 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:1.0638866424560547 norm:0.01597091555595398 max memory_allocated 29278.33251953125 
[2025-03-02 01:28:21 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:1.0612179040908813 norm:0.01470566913485527 max memory_allocated 29278.33251953125 
[2025-03-02 01:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:1.0599342584609985 norm:0.01467941328883171 max memory_allocated 29278.33251953125 
[2025-03-02 01:30:00 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:1.0588104724884033 norm:0.014693663455545902 max memory_allocated 29278.33251953125 
[2025-03-02 01:30:49 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:1.0571047067642212 norm:0.013839317485690117 max memory_allocated 29278.33251953125 
[2025-03-02 01:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:1.0559706687927246 norm:0.013662992045283318 max memory_allocated 29278.33251953125 
[2025-03-02 01:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:1.0556964874267578 norm:0.013232925906777382 max memory_allocated 29278.33251953125 
[2025-03-02 01:33:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:1.0548144578933716 norm:0.013171674683690071 max memory_allocated 29278.33251953125 
[2025-03-02 01:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:1.0544674396514893 norm:0.013092546723783016 max memory_allocated 29278.33251953125 
[2025-03-02 01:34:55 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:1.0534451007843018 norm:0.012625915929675102 max memory_allocated 29278.33251953125 
[2025-03-02 01:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:1.053415298461914 norm:0.012640814296901226 max memory_allocated 29278.33251953125 
[2025-03-02 01:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:1.0524808168411255 norm:0.012706836685538292 max memory_allocated 29278.33251953125 
[2025-03-02 01:36:47 root] (main_calib_config2.py 380): INFO 40104.79943728447
[2025-03-02 01:36:58 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-02 01:38:53 root] (main_calib_config2.py 159): INFO wikitext2 : 5.437028884887695
[2025-03-02 01:38:53 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-02 01:41:51 root] (main_calib_config2.py 159): INFO c4 : 7.27262020111084
[2025-03-02 03:46:33 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.437028884887695, 'c4': 7.27262020111084, 'results': {'hellaswag': {'acc': 0.5678151762597092, 'acc_stderr': 0.00494367338827628, 'acc_norm': 0.7342162915753834, 'acc_norm_stderr': 0.004408468107262733}, 'arc_easy': {'acc': 0.6898148148148148, 'acc_stderr': 0.009491721291998515, 'acc_norm': 0.5458754208754208, 'acc_norm_stderr': 0.010216507710244105}, 'arc_challenge': {'acc': 0.4044368600682594, 'acc_stderr': 0.01434203648343617, 'acc_norm': 0.4274744027303754, 'acc_norm_stderr': 0.014456862944650649}, 'winogrande': {'acc': 0.6203630623520127, 'acc_stderr': 0.013639245403711165}, 'boolq': {'acc': 0.6327217125382263, 'acc_stderr': 0.008431338702844847}, 'piqa': {'acc': 0.76550598476605, 'acc_stderr': 0.009885203143240547, 'acc_norm': 0.7687704026115343, 'acc_norm_stderr': 0.009837063180625338}}, 'versions': {'hellaswag': 0, 'arc_easy': 0, 'arc_challenge': 0, 'winogrande': 0, 'boolq': 1, 'piqa': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
