[2025-03-02 12:49:23 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.95', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.95.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.95.pkl
[2025-03-02 12:52:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.004875971470028162 norm:0.004556919913738966 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.002851136727258563 norm:0.0031197431962937117 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.002350140828639269 norm:0.0023820186033844948 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0020913570187985897 norm:0.001954092178493738 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0019290340133011341 norm:0.0016249262262135744 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0018204287625849247 norm:0.0014316251035779715 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0017258641310036182 norm:0.0012656735489144921 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0016866938676685095 norm:0.001202818239107728 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0016086776740849018 norm:0.0010388990631327033 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0015917000127956271 norm:0.0009992595296353102 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0015844216104596853 norm:0.0009062838507816195 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0015563075430691242 norm:0.0008465249557048082 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0015468733618035913 norm:0.0007838036981411278 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0015520919114351273 norm:0.0007719811401329935 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0015419337432831526 norm:0.0007400111644528806 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0015567332739010453 norm:0.0006981217884458601 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:50 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0015402922872453928 norm:0.0006875996477901936 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0015424214070662856 norm:0.0006772199994884431 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.001556331291794777 norm:0.0006459507858380675 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0015241443179547787 norm:0.0005860630772076547 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.008192615583539009 norm:0.005043152254074812 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.006039625033736229 norm:0.004384906031191349 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.005426489748060703 norm:0.0034719689283519983 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.005063429940491915 norm:0.002788715763017535 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.0048650577664375305 norm:0.0022698892280459404 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.004770565312355757 norm:0.0019859662279486656 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.004669700749218464 norm:0.0016749708447605371 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.004580877721309662 norm:0.001409501419402659 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.004475501365959644 norm:0.0011884855339303613 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.004401255398988724 norm:0.001106030773371458 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.004375088028609753 norm:0.0011568347690626979 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.0043144309893250465 norm:0.001058255904354155 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.004314024932682514 norm:0.0010858620516955853 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.004352024756371975 norm:0.0010937945917248726 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.004337606485933065 norm:0.0011377192568033934 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.004214057698845863 norm:0.000799895147792995 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.004185316618531942 norm:0.0007967787096276879 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.00424741068854928 norm:0.000854970479849726 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004286510869860649 norm:0.0008879360393621027 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.004289571661502123 norm:0.0007694756495766342 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:37 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.022538533434271812 norm:0.010908298194408417 max memory_allocated 29268.39501953125 
[2025-03-02 13:28:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.015153462067246437 norm:0.008150316774845123 max memory_allocated 29268.39501953125 
[2025-03-02 13:29:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.013098019175231457 norm:0.006831460166722536 max memory_allocated 29268.39501953125 
[2025-03-02 13:29:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.011604398488998413 norm:0.0048254854045808315 max memory_allocated 29268.39501953125 
[2025-03-02 13:30:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.010761179029941559 norm:0.0037704664282500744 max memory_allocated 29268.39501953125 
[2025-03-02 13:31:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.01023735012859106 norm:0.0034719440154731274 max memory_allocated 29268.39501953125 
[2025-03-02 13:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.009749265387654305 norm:0.0032030423171818256 max memory_allocated 29268.39501953125 
[2025-03-02 13:33:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.009344248101115227 norm:0.002670390298590064 max memory_allocated 29268.39501953125 
[2025-03-02 13:34:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.009142507798969746 norm:0.0027627693489193916 max memory_allocated 29268.39501953125 
[2025-03-02 13:34:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.009016848169267178 norm:0.0026239228900521994 max memory_allocated 29268.39501953125 
[2025-03-02 13:35:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.00888583343476057 norm:0.0023686569184064865 max memory_allocated 29268.39501953125 
[2025-03-02 13:36:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.008801329880952835 norm:0.0023682308383286 max memory_allocated 29268.39501953125 
[2025-03-02 13:37:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.008694310672581196 norm:0.0023389668203890324 max memory_allocated 29268.39501953125 
[2025-03-02 13:38:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.00864280853420496 norm:0.0022553764283657074 max memory_allocated 29268.39501953125 
[2025-03-02 13:39:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.008613267913460732 norm:0.0023097870871424675 max memory_allocated 29268.39501953125 
[2025-03-02 13:39:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.00850510224699974 norm:0.0018695840844884515 max memory_allocated 29268.39501953125 
[2025-03-02 13:40:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.008454250171780586 norm:0.0019068325636908412 max memory_allocated 29268.39501953125 
[2025-03-02 13:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.008416414260864258 norm:0.001667671836912632 max memory_allocated 29268.39501953125 
[2025-03-02 13:42:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.008386421948671341 norm:0.0015270444564521313 max memory_allocated 29268.39501953125 
[2025-03-02 13:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.008381329476833344 norm:0.0017232645768672228 max memory_allocated 29268.39501953125 
[2025-03-02 13:43:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:44:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.013200216926634312 norm:0.0016404055058956146 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.010537205263972282 norm:0.0006567045347765088 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.009744014590978622 norm:0.00035092703183181584 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.009415038861334324 norm:0.00023789073748048395 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.009195201098918915 norm:0.00016994329052977264 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.009038025513291359 norm:0.00014927425945643336 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.008917109109461308 norm:0.00013770714576821774 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.008831560611724854 norm:0.00013636892253998667 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.008785605430603027 norm:0.00012260035146027803 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.00875843409448862 norm:0.00011279276077402756 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.008746867999434471 norm:0.00010726553591666743 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.008737628348171711 norm:0.0001032529617077671 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.008726794272661209 norm:0.0001097439308068715 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.00872268807142973 norm:0.00010906340321525931 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.008713752031326294 norm:0.00010584268602542579 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.008707445114850998 norm:9.764709102455527e-05 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.008706397376954556 norm:0.00010080749052576721 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.008717677555978298 norm:0.00010630970064084977 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.00872634258121252 norm:0.00010251047206111252 max memory_allocated 29268.43798828125 
[2025-03-02 14:00:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.008712952956557274 norm:7.995124906301498e-05 max memory_allocated 29268.43798828125 
[2025-03-02 14:00:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.017998263239860535 norm:0.0033868004102259874 max memory_allocated 29268.62548828125 
[2025-03-02 14:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.013732477091252804 norm:0.001038808492012322 max memory_allocated 29268.62548828125 
[2025-03-02 14:03:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.012606529518961906 norm:0.0005625552730634809 max memory_allocated 29268.62548828125 
[2025-03-02 14:03:52 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.012130893766880035 norm:0.00041424136725254357 max memory_allocated 29268.62548828125 
[2025-03-02 14:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.011802999302744865 norm:0.00032150070182979107 max memory_allocated 29268.62548828125 
[2025-03-02 14:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.011575481854379177 norm:0.0002606688067317009 max memory_allocated 29268.62548828125 
[2025-03-02 14:06:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.011435152031481266 norm:0.0002228692319476977 max memory_allocated 29268.62548828125 
[2025-03-02 14:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.01134492363780737 norm:0.00019393661932554096 max memory_allocated 29268.62548828125 
[2025-03-02 14:08:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.011289417743682861 norm:0.00018226460088044405 max memory_allocated 29268.62548828125 
[2025-03-02 14:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.011266354471445084 norm:0.00016730633797124028 max memory_allocated 29268.62548828125 
[2025-03-02 14:09:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.011237511411309242 norm:0.00014985690359026194 max memory_allocated 29268.62548828125 
[2025-03-02 14:10:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.01121743768453598 norm:0.0001340897288173437 max memory_allocated 29268.62548828125 
[2025-03-02 14:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.011197686195373535 norm:0.000126533632283099 max memory_allocated 29268.62548828125 
[2025-03-02 14:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.011194230057299137 norm:0.00013389906962402165 max memory_allocated 29268.62548828125 
[2025-03-02 14:12:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.011168916709721088 norm:0.00012400091509334743 max memory_allocated 29268.62548828125 
[2025-03-02 14:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.01115948986262083 norm:0.00011807252303697169 max memory_allocated 29268.62548828125 
[2025-03-02 14:14:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.011146321892738342 norm:0.00011820948566310108 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.011141365393996239 norm:0.00011742940114345402 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.011134330183267593 norm:0.0001099128567148 max memory_allocated 29268.62548828125 
[2025-03-02 14:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.011126290075480938 norm:0.0001106547424569726 max memory_allocated 29268.62548828125 
[2025-03-02 14:17:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.021337106823921204 norm:0.0029172254726290703 max memory_allocated 29268.81298828125 
[2025-03-02 14:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.016201922670006752 norm:0.0009945158381015062 max memory_allocated 29268.81298828125 
[2025-03-02 14:19:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.014597253873944283 norm:0.0005174906109459698 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.013978034257888794 norm:0.00033615471329540014 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.013621235266327858 norm:0.00025437024305574596 max memory_allocated 29268.81298828125 
[2025-03-02 14:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.013375950045883656 norm:0.0002052135969279334 max memory_allocated 29268.81298828125 
[2025-03-02 14:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.013230446726083755 norm:0.00017468168516643345 max memory_allocated 29268.81298828125 
[2025-03-02 14:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.013151279650628567 norm:0.00014935378567315638 max memory_allocated 29268.81298828125 
[2025-03-02 14:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.013112826272845268 norm:0.00014340653433464468 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.013075681403279305 norm:0.00013092767039779574 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.0130413006991148 norm:0.00011806004476966336 max memory_allocated 29268.81298828125 
[2025-03-02 14:27:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.013027993030846119 norm:0.000113656249595806 max memory_allocated 29268.81298828125 
[2025-03-02 14:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.013011190108954906 norm:0.00010886206291615963 max memory_allocated 29268.81298828125 
[2025-03-02 14:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.013000326231122017 norm:0.0001062484661815688 max memory_allocated 29268.81298828125 
[2025-03-02 14:29:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.012983855791389942 norm:0.00010219196701655164 max memory_allocated 29268.81298828125 
[2025-03-02 14:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.012972379103302956 norm:0.0001042429285007529 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.012964240275323391 norm:0.00010102710803039372 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.012959804385900497 norm:0.00010002151975641027 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.012955179437994957 norm:9.767018491402268e-05 max memory_allocated 29268.81298828125 
[2025-03-02 14:34:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.012956243008375168 norm:9.885246254270896e-05 max memory_allocated 29268.81298828125 
[2025-03-02 14:34:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:35:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.025731632485985756 norm:0.0020272298716008663 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.021011725068092346 norm:0.0012488162610679865 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.018782740458846092 norm:0.0008647301001474261 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.01754608191549778 norm:0.000657153781503439 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.017061632126569748 norm:0.0005755547899752855 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.016521383076906204 norm:0.00048661703476682305 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.01611674763262272 norm:0.0003950198588427156 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.016006173565983772 norm:0.00041690494981594384 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.0157939326018095 norm:0.000393805792555213 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.015706254169344902 norm:0.0003484183980617672 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.01565128192305565 norm:0.00031942446366883814 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.015662578865885735 norm:0.0003209344286005944 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.015626167878508568 norm:0.00027905794559046626 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.015630358830094337 norm:0.0003251348971389234 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.015696514397859573 norm:0.00043082493357360363 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.015580791048705578 norm:0.00028784223832190037 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.015633465722203255 norm:0.0003682644746731967 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.01559448055922985 norm:0.00025631897733546793 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.015595723874866962 norm:0.0002781841903924942 max memory_allocated 29269.00048828125 
[2025-03-02 14:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.015586566179990768 norm:0.0002593122189864516 max memory_allocated 29269.00048828125 
[2025-03-02 14:51:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.02334604784846306 norm:0.0013717334950342774 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.019575979560613632 norm:0.0005944946897216141 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.01836150884628296 norm:0.000298100319923833 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.017824504524469376 norm:0.0001740183652145788 max memory_allocated 29269.18798828125 
[2025-03-02 14:55:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.01753784343600273 norm:0.00013640825636684895 max memory_allocated 29269.18798828125 
[2025-03-02 14:56:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.017332319170236588 norm:0.0001243000297108665 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.017210831865668297 norm:0.00011772150901379064 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.017126668244600296 norm:0.00010897397442022339 max memory_allocated 29269.18798828125 
[2025-03-02 14:58:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.017072822898626328 norm:9.929030784405768e-05 max memory_allocated 29269.18798828125 
[2025-03-02 14:59:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.01705162599682808 norm:0.00010289066267432645 max memory_allocated 29269.18798828125 
[2025-03-02 15:00:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.017031777650117874 norm:0.00010286209726473317 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.017015580087900162 norm:0.00010108482820214704 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.017006130889058113 norm:0.00010345870396122336 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.016992365941405296 norm:9.834352385951206e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.016991883516311646 norm:0.00010079642379423603 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.016993217170238495 norm:9.682988456916064e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:05:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.01698448695242405 norm:9.673451131675392e-05 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.01697666011750698 norm:0.00010078273044200614 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.016974838450551033 norm:0.00010197776282439008 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.016977427527308464 norm:0.0001017863251036033 max memory_allocated 29269.18798828125 
[2025-03-02 15:08:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:09:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.025321820750832558 norm:0.0014519307296723127 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.02146865427494049 norm:0.0005706814699806273 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.02033204399049282 norm:0.0002869020390789956 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.01984008029103279 norm:0.0001867257378762588 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.019499465823173523 norm:0.00014714377175550908 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.01928618736565113 norm:0.00012991669063922018 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.019162118434906006 norm:0.00012150641123298556 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.01909605972468853 norm:0.00010924157686531544 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.019059816375374794 norm:0.0001067871562554501 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.019027989357709885 norm:0.000104917460703291 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.019007835537195206 norm:0.00010317150736227632 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.018979225307703018 norm:9.68065214692615e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.01897469535470009 norm:9.842600411502644e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.01897539384663105 norm:9.65503859333694e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.018969830125570297 norm:9.357567614642903e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.018955279141664505 norm:9.174340084427968e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.018949760124087334 norm:9.305291314376518e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.018948214128613472 norm:9.288677392760292e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.018941912800073624 norm:9.112610860029235e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.01893279328942299 norm:9.089976083487272e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:25:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:26:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.02626722678542137 norm:0.001191718503832817 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.022911682724952698 norm:0.0005029848543927073 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.02177947387099266 norm:0.0002526415337342769 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.02127460204064846 norm:0.00015681817603763193 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.020977873355150223 norm:0.0001238393597304821 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.0207732692360878 norm:0.00010800399468280375 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.020652184262871742 norm:9.756643703440204e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.020579352974891663 norm:9.036814299179241e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.020550474524497986 norm:9.252496238332242e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.02052735537290573 norm:9.143755596596748e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.020516587421298027 norm:8.859738591127098e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.02050618827342987 norm:9.044558100868016e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:01 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.020486710593104362 norm:8.601902663940564e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.020481688901782036 norm:8.344765956280753e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.020479993894696236 norm:8.473089837934822e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.020476290956139565 norm:8.541800343664363e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.020467886701226234 norm:8.66496775415726e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.020463740453124046 norm:8.653687837067991e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:41:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.020464682951569557 norm:8.588011405663565e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.020461153239011765 norm:8.67175476741977e-05 max memory_allocated 29269.56298828125 
[2025-03-02 15:42:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:42:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.028010793030261993 norm:0.0010999487712979317 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.024526584893465042 norm:0.00041048089042305946 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.0235659908503294 norm:0.0002174821711378172 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.023104537278413773 norm:0.00015293761680368334 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.022784292697906494 norm:0.00012540590250864625 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.022562162950634956 norm:0.00010988249414367601 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.022423408925533295 norm:9.913284156937152e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.02233733795583248 norm:9.136152220889926e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:49:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.02229955792427063 norm:8.512836211593822e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.02227923274040222 norm:8.187906496459618e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.02226458489894867 norm:8.069979230640456e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.022245854139328003 norm:7.799239392625168e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.022240709513425827 norm:7.810325041646138e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.022237617522478104 norm:7.720400753896683e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.022225849330425262 norm:7.582500256830826e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.02222631126642227 norm:7.554804324172437e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.022235795855522156 norm:7.614978676429018e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.022235654294490814 norm:7.514523167628795e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.022234713658690453 norm:7.590701716253534e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:58:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.022223155945539474 norm:7.500619540223852e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:59:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.03059379570186138 norm:0.0011028985027223825 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.026927979663014412 norm:0.0004703430749941617 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.025632672011852264 norm:0.0002362029190408066 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.025076530873775482 norm:0.00015423422155436128 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.024718027561903 norm:0.00012446512118913233 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.024476952850818634 norm:0.00010715506505221128 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.024337049573659897 norm:9.564511856297031e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.024267639964818954 norm:9.02140891412273e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.024218745529651642 norm:8.747121319174767e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.024181030690670013 norm:8.282550697913393e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.02414274960756302 norm:8.293107384815812e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.024123409762978554 norm:7.990183803485706e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.024110058322548866 norm:7.632870983798057e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.024097394198179245 norm:7.655293302377686e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.024089768528938293 norm:7.540240039816126e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.024084141477942467 norm:7.388629455817863e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.024072974920272827 norm:7.259809353854507e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.0240608099848032 norm:7.220017141662538e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.024058163166046143 norm:7.33409178792499e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:15:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.02405519224703312 norm:7.203399582067505e-05 max memory_allocated 29269.93798828125 
[2025-03-02 16:15:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.030089350417256355 norm:0.0008778819465078413 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.02771051973104477 norm:0.00038093014154583216 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.026834761723876 norm:0.0002228519442724064 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.02634301222860813 norm:0.0001555481576360762 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.026010340079665184 norm:0.00012582495401147753 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.02578239142894745 norm:0.00010823531920323148 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.025657331570982933 norm:9.58358432399109e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.025584015995264053 norm:8.907966548576951e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.025534944608807564 norm:8.630944648757577e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.02550305798649788 norm:8.192889799829572e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.025484491139650345 norm:7.956602348713204e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.0254704337567091 norm:7.8294709965121e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.02545175515115261 norm:7.627244485775009e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.02543763257563114 norm:7.538223144365475e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.025434674695134163 norm:7.373681728495285e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.025437239557504654 norm:7.388042286038399e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:30:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.025440961122512817 norm:7.426229421980679e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:30:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.02543777972459793 norm:7.276210089912638e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.0254420917481184 norm:7.371544779743999e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:32:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.025431234389543533 norm:7.317407289519906e-05 max memory_allocated 29270.12548828125 
[2025-03-02 16:32:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:33:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.03110986389219761 norm:0.0006500253221020103 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.029053697362542152 norm:0.00031860574381425977 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.028233420103788376 norm:0.00020002566452603787 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.02773917093873024 norm:0.00014646041381638497 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.02736656367778778 norm:0.00011758695472963154 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.0271209217607975 norm:0.00010064575326396152 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.026966959238052368 norm:9.200296335620806e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.026884915307164192 norm:8.6683125118725e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.02682656981050968 norm:8.221162715926766e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.02678670734167099 norm:7.673913205508143e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.026759471744298935 norm:7.520765211666003e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.02674652449786663 norm:7.680052658542991e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.026730522513389587 norm:7.328265928663313e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.026711860671639442 norm:7.112132880138233e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.026708606630563736 norm:7.051399734336883e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.026699161157011986 norm:7.007547537796199e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:47:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.026700729504227638 norm:6.926037167431787e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:47:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.026706703007221222 norm:6.94733316777274e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.026695581153035164 norm:6.843456503702328e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:49:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.026691913604736328 norm:6.82109675835818e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:49:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.0335666798055172 norm:0.0009902692399919033 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.030833085998892784 norm:0.0004587251751217991 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.02982458285987377 norm:0.0002665937936399132 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.029254890978336334 norm:0.00018415480735711753 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.028861388564109802 norm:0.0001394186110701412 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.028592675924301147 norm:0.00011472221376607195 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.028430527076125145 norm:9.971464169211686e-05 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.02834349125623703 norm:9.146758384304121e-05 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.028297608718276024 norm:8.507968595949933e-05 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.028262251988053322 norm:7.893942529335618e-05 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.028234388679265976 norm:7.556905620731413e-05 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.02821025811135769 norm:7.363944314420223e-05 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.02818792685866356 norm:7.046972314128652e-05 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.02817634493112564 norm:7.084560638759285e-05 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.02816525101661682 norm:6.994500290602446e-05 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.0281592458486557 norm:6.900793960085139e-05 max memory_allocated 29270.50048828125 
[2025-03-02 17:04:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.028145935386419296 norm:6.804887379985303e-05 max memory_allocated 29270.50048828125 
[2025-03-02 17:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.0281439870595932 norm:6.854850653326139e-05 max memory_allocated 29270.50048828125 
[2025-03-02 17:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.028140418231487274 norm:6.895723345223814e-05 max memory_allocated 29270.50048828125 
[2025-03-02 17:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.028132466599345207 norm:6.914887489983812e-05 max memory_allocated 29270.50048828125 
[2025-03-02 17:06:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:07:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.03520293906331062 norm:0.000874089018907398 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.03281380236148834 norm:0.0003349472535774112 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.03199149668216705 norm:0.0002082184364553541 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.03147393837571144 norm:0.00015888091002125293 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.031054208055138588 norm:0.00012992051779292524 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.030770305544137955 norm:0.00011739632464013994 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.030608970671892166 norm:0.0001066597833414562 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.030515698716044426 norm:9.41555917961523e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.03044423833489418 norm:8.623724716017023e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.030419398099184036 norm:8.554358646506444e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.030374666675925255 norm:8.038966916501522e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.03033939003944397 norm:7.480480417143553e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.03031117282807827 norm:7.352034299401566e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.030285488814115524 norm:6.972665141802281e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.03027357906103134 norm:6.792889325879514e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:20:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.030256737023591995 norm:6.418315751943737e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.03024473786354065 norm:6.351745832944289e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.030242295935750008 norm:6.429534550989047e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.030231714248657227 norm:6.267934804782271e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.030229799449443817 norm:6.308097363216802e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:23:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:24:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.03666083514690399 norm:0.001052257837727666 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.03490994870662689 norm:0.0004943194799125195 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.03417247533798218 norm:0.00030106407939456403 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.03366658836603165 norm:0.00020728800154756755 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.03324625641107559 norm:0.00015188907855190337 max memory_allocated 29270.87548828125 
[2025-03-02 17:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.03297676891088486 norm:0.0001208902831422165 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.03285237029194832 norm:0.00010177060903515667 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.032793570309877396 norm:8.878419612301514e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.03276049718260765 norm:8.032983168959618e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.03272802382707596 norm:7.491275027859956e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.03270116448402405 norm:7.141647074604407e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:33:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.03267894312739372 norm:6.839823618065566e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.03267209231853485 norm:6.688181747449562e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.032658305019140244 norm:6.531614781124517e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.0326489582657814 norm:6.467618368333206e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.03264728933572769 norm:6.405494059436023e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:37:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.03264080360531807 norm:6.367391324602067e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:38:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.03263719379901886 norm:6.364960427163169e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:39:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.03263280540704727 norm:6.388766632881016e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.03263606131076813 norm:6.303450209088624e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:40:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:41:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.040478408336639404 norm:0.0013648401945829391 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.03806259483098984 norm:0.0005984703311696649 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.03710485249757767 norm:0.00035289747756905854 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.036458637565374374 norm:0.00023688124201726168 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.03597491234540939 norm:0.00017449702136218548 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.03568440303206444 norm:0.00013762175512965769 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.035550426691770554 norm:0.00011506269220262766 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.03546552732586861 norm:0.00010060837666969746 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.03541213274002075 norm:8.969507325673476e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.035373784601688385 norm:8.175379480235279e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.0353487990796566 norm:7.724888564553112e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.03533007577061653 norm:7.408551027765498e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.035313110798597336 norm:7.316689880099148e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.03529884293675423 norm:6.931537063792348e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.03529902920126915 norm:7.080098293954507e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.035285476595163345 norm:6.895018304931e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.03527357801795006 norm:6.777294038329273e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.03527285158634186 norm:6.827352626714855e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.035268936306238174 norm:6.852694787085056e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:57:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.03526495024561882 norm:6.829521589679644e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:57:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:58:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.04444124922156334 norm:0.001266041537746787 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.041959237307310104 norm:0.0005143104935996234 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.0409574955701828 norm:0.00029223275487311184 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.04028194397687912 norm:0.00019859697204083204 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.03977375477552414 norm:0.0001501325168646872 max memory_allocated 29271.25048828125 
[2025-03-02 18:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.0395001620054245 norm:0.00012299134687054902 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.03938242420554161 norm:0.00010710288188420236 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.03931581228971481 norm:9.631803550291806e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.03925088047981262 norm:8.951942436397076e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.03921797126531601 norm:8.621726010460407e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.039180412888526917 norm:8.259386959252879e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.03915240615606308 norm:7.957521302159876e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.03912165015935898 norm:7.645283767487854e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.03911152482032776 norm:7.496240868931636e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.03909709304571152 norm:7.496928446926177e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.039080437272787094 norm:7.266819011420012e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.03906617313623428 norm:7.168117008404806e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.03906968608498573 norm:7.088643906172365e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.039064764976501465 norm:7.09186278982088e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.03905806317925453 norm:7.094390457496047e-05 max memory_allocated 29271.25048828125 
[2025-03-02 18:14:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:15:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.04767762869596481 norm:0.00087747722864151 max memory_allocated 29271.43798828125 
[2025-03-02 18:16:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.04592907428741455 norm:0.00037576069007627666 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.045088425278663635 norm:0.0002322297659702599 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.04442482441663742 norm:0.00016312456864397973 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.043920762836933136 norm:0.0001245740568265319 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.043700773268938065 norm:0.00010456709424033761 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.04360900819301605 norm:9.353946370538324e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.04355041682720184 norm:8.548818004783243e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.04350210353732109 norm:7.847435335861519e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.04346265271306038 norm:7.568520231870934e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.04343637824058533 norm:7.262657163664699e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.043416038155555725 norm:7.141064270399511e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.04340038821101189 norm:6.980009493418038e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.043387893587350845 norm:6.935110286576673e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:27:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.043382201343774796 norm:6.946299254195765e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:27:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.043382104486227036 norm:6.920798477949575e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.04337513446807861 norm:6.796959496568888e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.043381236493587494 norm:7.019114855211228e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:30:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.04338185861706734 norm:6.822009163442999e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.04337003082036972 norm:6.811409548390657e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:31:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.053619496524333954 norm:0.0009266221895813942 max memory_allocated 29271.62548828125 
[2025-03-02 18:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.051078811287879944 norm:0.0003913483815267682 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.050027329474687576 norm:0.00024627475067973137 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.049246955662965775 norm:0.0001835298171499744 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.04870004206895828 norm:0.00014862943498883396 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.048472993075847626 norm:0.00012573334970511496 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.04834533482789993 norm:0.00011188763164682314 max memory_allocated 29271.62548828125 
[2025-03-02 18:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.048266440629959106 norm:0.000102403195342049 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.048204466700553894 norm:9.331788896815851e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.04815678298473358 norm:8.821264054859057e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.04811719059944153 norm:8.339908526977524e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.04808848723769188 norm:7.947457197587937e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:42:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.04805973544716835 norm:7.581356476293877e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:43:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.048037298023700714 norm:7.35269786673598e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:44:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.04803008958697319 norm:7.356814603554085e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.048012834042310715 norm:7.110162550816312e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:45:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.04799557104706764 norm:6.94042828399688e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.04798474907875061 norm:6.86665007378906e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:47:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.04797850549221039 norm:6.767677405150607e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:48:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.04797554016113281 norm:6.744980055373162e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:48:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.061255622655153275 norm:0.0013178354129195213 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.05802387744188309 norm:0.000576679187361151 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.05672843009233475 norm:0.0003534405550453812 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.05579511821269989 norm:0.00025285957963205874 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.055179256945848465 norm:0.00020052457693964243 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.0549352690577507 norm:0.00016677151143085212 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.05479635298252106 norm:0.00014368162374012172 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.05471346527338028 norm:0.00012923291069455445 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.05463501438498497 norm:0.0001185704895760864 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.05457418039441109 norm:0.00011101627023890615 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.054531656205654144 norm:0.00010374413250247017 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.05448925495147705 norm:9.872668306343257e-05 max memory_allocated 29271.81298828125 
[2025-03-02 18:59:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.05445101112127304 norm:9.277979552280158e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.05442991480231285 norm:9.010518260765821e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.0544099323451519 norm:8.719312609173357e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:01:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.05439469590783119 norm:8.622306631878018e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.05437752977013588 norm:8.534191874787211e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:03:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.054364919662475586 norm:8.414486364927143e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.054355520755052567 norm:8.109488408081234e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:05:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.0543527752161026 norm:7.96311505837366e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:05:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:06:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.06701382249593735 norm:0.0009504107874818146 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.06499597430229187 norm:0.00047107759746722877 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.06389115005731583 norm:0.0002963105798698962 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.062962606549263 norm:0.00021067257330287248 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.06241368502378464 norm:0.00016328354831784964 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.06220356002449989 norm:0.00013572428724728525 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.06210481375455856 norm:0.00011990388156846166 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.06204025074839592 norm:0.00010861000191653147 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.061997607350349426 norm:0.00010035793093265966 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.06195686385035515 norm:9.441998554393649e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.06192353367805481 norm:8.903896377887577e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:15:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.0619007907807827 norm:8.537885150872171e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.061872608959674835 norm:8.493188215652481e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.061859600245952606 norm:8.284648356493562e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.061842747032642365 norm:8.180533768609166e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:18:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.061829905956983566 norm:8.191430242732167e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:19:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.06182803586125374 norm:8.299582259496674e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.06181778386235237 norm:8.178783173207194e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:21:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.061807919293642044 norm:8.138704288285226e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.06180603429675102 norm:8.087512833299115e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:22:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.07651109993457794 norm:0.001132332719862461 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.07410039007663727 norm:0.0005531347123906016 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.07291266322135925 norm:0.0003470221417956054 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.07187972217798233 norm:0.0002496326342225075 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.07132658362388611 norm:0.00019747187616303563 max memory_allocated 29272.18798828125 
[2025-03-02 19:27:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.0711066946387291 norm:0.00016413307457696646 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.07097654044628143 norm:0.0001426884700777009 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.07088606804609299 norm:0.00012789975153282285 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.0708233118057251 norm:0.00011760275810956955 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.0707714706659317 norm:0.00011145132157253101 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.07072032988071442 norm:0.00010480063792783767 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.07068110257387161 norm:9.950074309017509e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.07065462321043015 norm:9.560903708916157e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.07063515484333038 norm:9.352051711175591e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.07061100751161575 norm:9.233533637598157e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.0705966204404831 norm:9.122208575718105e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.07058419287204742 norm:9.009712084662169e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.07056669145822525 norm:8.882781548891217e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.07057193666696548 norm:8.867870201356709e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:39:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.07057913392782211 norm:8.89095026650466e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:39:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.08542785048484802 norm:0.001313112210482359 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.0834345668554306 norm:0.0006672198069281876 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.08224931359291077 norm:0.0004230983613524586 max memory_allocated 29272.37548828125 
[2025-03-02 19:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.08113083243370056 norm:0.00030114606488496065 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.08061717450618744 norm:0.00022769598581362516 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.0804581418633461 norm:0.00018853307119570673 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.08035753667354584 norm:0.00016045641677919775 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.08028864115476608 norm:0.0001415447477484122 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.08023001253604889 norm:0.00013011987903155386 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.08019057661294937 norm:0.00011901678226422518 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.08016782253980637 norm:0.00011290783004369587 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.08014144003391266 norm:0.00010859117901418358 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.08012105524539948 norm:0.00010489582928130403 max memory_allocated 29272.37548828125 
[2025-03-02 19:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.08010473847389221 norm:0.00010323969763703644 max memory_allocated 29272.37548828125 
[2025-03-02 19:51:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.08008120208978653 norm:0.00010019829642260447 max memory_allocated 29272.37548828125 
[2025-03-02 19:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.0800764188170433 norm:0.00010032547288574278 max memory_allocated 29272.37548828125 
[2025-03-02 19:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.08006905019283295 norm:9.756090730661526e-05 max memory_allocated 29272.37548828125 
[2025-03-02 19:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.08006638288497925 norm:9.807800961425528e-05 max memory_allocated 29272.37548828125 
[2025-03-02 19:55:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.08005113154649734 norm:9.638769552111626e-05 max memory_allocated 29272.37548828125 
[2025-03-02 19:56:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.08005791157484055 norm:9.666561527410522e-05 max memory_allocated 29272.37548828125 
[2025-03-02 19:56:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:57:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.09545429050922394 norm:0.0009118311572819948 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.09383659809827805 norm:0.0004680839483626187 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.09268700331449509 norm:0.00031031607068143785 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.09154728800058365 norm:0.00022671365877613425 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.09112013131380081 norm:0.00018204607476945966 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.09095850586891174 norm:0.00015477344277314842 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.09086056053638458 norm:0.00013625342398881912 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.09078490734100342 norm:0.00012386548041831702 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.09072690457105637 norm:0.00011431601888034493 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.0906766951084137 norm:0.00010849463433260098 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.09064942598342896 norm:0.00010545163240749389 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.09062371402978897 norm:0.00010139098594663665 max memory_allocated 29272.56298828125 
[2025-03-02 20:07:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.09060810506343842 norm:9.892143134493381e-05 max memory_allocated 29272.56298828125 
[2025-03-02 20:07:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.09059128910303116 norm:9.719067747937515e-05 max memory_allocated 29272.56298828125 
[2025-03-02 20:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.0905737429857254 norm:9.586381202097982e-05 max memory_allocated 29272.56298828125 
[2025-03-02 20:09:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.09056363254785538 norm:9.41796024562791e-05 max memory_allocated 29272.56298828125 
[2025-03-02 20:10:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.0905553549528122 norm:9.395977394888178e-05 max memory_allocated 29272.56298828125 
[2025-03-02 20:11:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.09055691957473755 norm:9.486818453297019e-05 max memory_allocated 29272.56298828125 
[2025-03-02 20:12:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.09054878354072571 norm:9.468780626775697e-05 max memory_allocated 29272.56298828125 
[2025-03-02 20:12:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.09054809808731079 norm:9.388867329107597e-05 max memory_allocated 29272.56298828125 
[2025-03-02 20:13:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:14:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.10696915537118912 norm:0.0010551705490797758 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.10514028370380402 norm:0.0004572006000671536 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.10392622649669647 norm:0.0002851446915883571 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.1027090921998024 norm:0.00020724514615722 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.10231273621320724 norm:0.00016331675578840077 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.10217919945716858 norm:0.0001408043026458472 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.10210289061069489 norm:0.0001268614287255332 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.10203393548727036 norm:0.00011746712698368356 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.10198639333248138 norm:0.00011276468285359442 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.10194595903158188 norm:0.0001073238963726908 max memory_allocated 29272.75048828125 
[2025-03-02 20:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.10192325711250305 norm:0.00010472223948454484 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.10189970582723618 norm:0.00010209002357441932 max memory_allocated 29272.75048828125 
[2025-03-02 20:24:05 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.10187278687953949 norm:0.00010006607044488192 max memory_allocated 29272.75048828125 
[2025-03-02 20:24:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.10186102241277695 norm:9.872588270809501e-05 max memory_allocated 29272.75048828125 
[2025-03-02 20:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.10184843093156815 norm:9.912090172292665e-05 max memory_allocated 29272.75048828125 
[2025-03-02 20:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.10184482485055923 norm:9.882041194941849e-05 max memory_allocated 29272.75048828125 
[2025-03-02 20:27:25 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.1018306314945221 norm:9.65512081165798e-05 max memory_allocated 29272.75048828125 
[2025-03-02 20:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.10182062536478043 norm:9.709338337415829e-05 max memory_allocated 29272.75048828125 
[2025-03-02 20:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.10181427001953125 norm:9.676270565250888e-05 max memory_allocated 29272.75048828125 
[2025-03-02 20:29:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.10181228816509247 norm:9.705422417027876e-05 max memory_allocated 29272.75048828125 
[2025-03-02 20:30:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.12021077424287796 norm:0.0008396547636948526 max memory_allocated 29272.93798828125 
[2025-03-02 20:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.11838464438915253 norm:0.00043183733941987157 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.11696060001850128 norm:0.0002882613043766469 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.11564738303422928 norm:0.00021687296975869685 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.11524935811758041 norm:0.0001814014685805887 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.11508884280920029 norm:0.00016201853577513248 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.11497432738542557 norm:0.0001478764897910878 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.11488757282495499 norm:0.00013514506281353533 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.114818274974823 norm:0.00013077471521683037 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.11476746946573257 norm:0.00012213631998747587 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.11472047865390778 norm:0.00011745058873202652 max memory_allocated 29272.93798828125 
[2025-03-02 20:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.11469488590955734 norm:0.00011712574632838368 max memory_allocated 29272.93798828125 
[2025-03-02 20:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.1146690845489502 norm:0.00011505813017720357 max memory_allocated 29272.93798828125 
[2025-03-02 20:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.114640973508358 norm:0.00011196044215466827 max memory_allocated 29272.93798828125 
[2025-03-02 20:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.11462953686714172 norm:0.00011060618271585554 max memory_allocated 29272.93798828125 
[2025-03-02 20:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.11462584882974625 norm:0.00010850823309738189 max memory_allocated 29272.93798828125 
[2025-03-02 20:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.11461296677589417 norm:0.0001078662317013368 max memory_allocated 29272.93798828125 
[2025-03-02 20:45:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.1146043911576271 norm:0.00010768659558380023 max memory_allocated 29272.93798828125 
[2025-03-02 20:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.11460105329751968 norm:0.0001107764255721122 max memory_allocated 29272.93798828125 
[2025-03-02 20:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.11460498720407486 norm:0.00011029471352230757 max memory_allocated 29272.93798828125 
[2025-03-02 20:47:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:48:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.13349156081676483 norm:0.0011793484445661306 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.1315966099500656 norm:0.0004970394656993449 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.13024216890335083 norm:0.00035895308246836066 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.12895575165748596 norm:0.00029799516778439283 max memory_allocated 29273.12548828125 
[2025-03-02 20:51:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.12860262393951416 norm:0.0002593328827060759 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.12848304212093353 norm:0.00023732130648568273 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.12839441001415253 norm:0.00020499905804172158 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.12830887734889984 norm:0.0001890535932034254 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.12826043367385864 norm:0.0001791634422261268 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.12822380661964417 norm:0.000171214560396038 max memory_allocated 29273.12548828125 
[2025-03-02 20:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.12818770110607147 norm:0.00016333181702066213 max memory_allocated 29273.12548828125 
[2025-03-02 20:57:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.12815608084201813 norm:0.0001587618753546849 max memory_allocated 29273.12548828125 
[2025-03-02 20:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.12813617289066315 norm:0.00016250235785264522 max memory_allocated 29273.12548828125 
[2025-03-02 20:58:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.12811441719532013 norm:0.00015795066428836435 max memory_allocated 29273.12548828125 
[2025-03-02 20:59:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.12809744477272034 norm:0.00015215136227197945 max memory_allocated 29273.12548828125 
[2025-03-02 21:00:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.12808653712272644 norm:0.00015591992996633053 max memory_allocated 29273.12548828125 
[2025-03-02 21:01:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.1280762106180191 norm:0.0001445600501028821 max memory_allocated 29273.12548828125 
[2025-03-02 21:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.12806935608386993 norm:0.00014854021719656885 max memory_allocated 29273.12548828125 
[2025-03-02 21:03:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.12806808948516846 norm:0.00014936327352188528 max memory_allocated 29273.12548828125 
[2025-03-02 21:03:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.12805257737636566 norm:0.00014936874504201114 max memory_allocated 29273.12548828125 
[2025-03-02 21:04:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 21:04:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.14782382547855377 norm:0.0015380402328446507 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.145843043923378 norm:0.0007776158745400608 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.144151970744133 norm:0.00047783387708477676 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.14277994632720947 norm:0.0003253804170526564 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.1424740105867386 norm:0.00024541179300285876 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.14235883951187134 norm:0.00020103594579268247 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.14228413999080658 norm:0.00017148365441244096 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.14222030341625214 norm:0.00015360809629783034 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.1421690285205841 norm:0.00014093829668127 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.14213575422763824 norm:0.0001333356776740402 max memory_allocated 29273.31298828125 
[2025-03-02 21:13:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.14210735261440277 norm:0.00012758596858475357 max memory_allocated 29273.31298828125 
[2025-03-02 21:14:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.14209119975566864 norm:0.00012357908417470753 max memory_allocated 29273.31298828125 
[2025-03-02 21:14:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.1420792043209076 norm:0.00012147489178460091 max memory_allocated 29273.31298828125 
[2025-03-02 21:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.14205574989318848 norm:0.0001189655449707061 max memory_allocated 29273.31298828125 
[2025-03-02 21:16:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.14203697443008423 norm:0.00011800120410043746 max memory_allocated 29273.31298828125 
[2025-03-02 21:17:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.1420249044895172 norm:0.00011733845894923434 max memory_allocated 29273.31298828125 
[2025-03-02 21:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.1420154571533203 norm:0.00011650944361463189 max memory_allocated 29273.31298828125 
[2025-03-02 21:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.14201495051383972 norm:0.00011720184556907043 max memory_allocated 29273.31298828125 
[2025-03-02 21:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.14200878143310547 norm:0.00011676782014546916 max memory_allocated 29273.31298828125 
[2025-03-02 21:20:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.14201617240905762 norm:0.00011672886466840282 max memory_allocated 29273.31298828125 
[2025-03-02 21:21:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:21:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.16425807774066925 norm:0.0014822358498349786 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.16207097470760345 norm:0.0007334568072110415 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.16017058491706848 norm:0.00046562336501665413 max memory_allocated 29273.50048828125 
[2025-03-02 21:24:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.1587318480014801 norm:0.0003239486541133374 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.15840883553028107 norm:0.00025210066814906895 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.15826596319675446 norm:0.00020912211039103568 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.15817011892795563 norm:0.00018960508168675005 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.15809497237205505 norm:0.00017474076594226062 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.15810205042362213 norm:0.00019349990179762244 max memory_allocated 29273.50048828125 
[2025-03-02 21:29:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.15803484618663788 norm:0.00017211787053383887 max memory_allocated 29273.50048828125 
[2025-03-02 21:30:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.1579563319683075 norm:0.0001635820954106748 max memory_allocated 29273.50048828125 
[2025-03-02 21:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.15792396664619446 norm:0.00014263304183259606 max memory_allocated 29273.50048828125 
[2025-03-02 21:31:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.15791429579257965 norm:0.00014447201101575047 max memory_allocated 29273.50048828125 
[2025-03-02 21:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.1578707993030548 norm:0.0001342657778877765 max memory_allocated 29273.50048828125 
[2025-03-02 21:33:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.15785357356071472 norm:0.0001329415536019951 max memory_allocated 29273.50048828125 
[2025-03-02 21:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.15783245861530304 norm:0.0001305748155573383 max memory_allocated 29273.50048828125 
[2025-03-02 21:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.15783894062042236 norm:0.00013210801989771426 max memory_allocated 29273.50048828125 
[2025-03-02 21:36:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.15785279870033264 norm:0.00013276460231281817 max memory_allocated 29273.50048828125 
[2025-03-02 21:36:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.15784168243408203 norm:0.00013297132682055235 max memory_allocated 29273.50048828125 
[2025-03-02 21:37:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.1578136384487152 norm:0.0001313324028160423 max memory_allocated 29273.50048828125 
[2025-03-02 21:37:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.1811213195323944 norm:0.0017545187147334218 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.17870306968688965 norm:0.0008281951886601746 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.17661325633525848 norm:0.0004924840177409351 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.1752125769853592 norm:0.00033439608523622155 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.17494209110736847 norm:0.00025505476514808834 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.17480891942977905 norm:0.00020917004439979792 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.17473852634429932 norm:0.0001829677348723635 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.174671933054924 norm:0.0001657067477935925 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.17463113367557526 norm:0.00015531254757661372 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.17459572851657867 norm:0.00014559435658156872 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.1745624542236328 norm:0.00014081144763622433 max memory_allocated 29273.68798828125 
[2025-03-02 21:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.17454005777835846 norm:0.00013829435920342803 max memory_allocated 29273.68798828125 
[2025-03-02 21:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.17452578246593475 norm:0.0001349958620266989 max memory_allocated 29273.68798828125 
[2025-03-02 21:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.17450660467147827 norm:0.00013465202937368304 max memory_allocated 29273.68798828125 
[2025-03-02 21:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.1744961440563202 norm:0.00013471071724779904 max memory_allocated 29273.68798828125 
[2025-03-02 21:51:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.17448584735393524 norm:0.00013317176490090787 max memory_allocated 29273.68798828125 
[2025-03-02 21:52:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.17448297142982483 norm:0.00013271920033730567 max memory_allocated 29273.68798828125 
[2025-03-02 21:53:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.1744827926158905 norm:0.00013254693476483226 max memory_allocated 29273.68798828125 
[2025-03-02 21:53:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.17448332905769348 norm:0.00013178425433579832 max memory_allocated 29273.68798828125 
[2025-03-02 21:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.17447355389595032 norm:0.0001318188733421266 max memory_allocated 29273.68798828125 
[2025-03-02 21:54:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:55:48 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.19880405068397522 norm:0.0021357801742851734 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.19647479057312012 norm:0.0010514950845390558 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:27 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.19430990517139435 norm:0.0006314930506050587 max memory_allocated 29273.87548828125 
[2025-03-02 21:58:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.19290560483932495 norm:0.0004260264686308801 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.19264401495456696 norm:0.0003187759721186012 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:57 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.1924990713596344 norm:0.00025642209220677614 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:47 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.1923966258764267 norm:0.00021859539265278727 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.19232873618602753 norm:0.00019311926735099405 max memory_allocated 29273.87548828125 
[2025-03-02 22:02:27 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.19227898120880127 norm:0.00017673578986432403 max memory_allocated 29273.87548828125 
[2025-03-02 22:03:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.192228764295578 norm:0.0001656381064094603 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:07 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.19219151139259338 norm:0.0001568497100379318 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.19216598570346832 norm:0.00015224216622300446 max memory_allocated 29273.87548828125 
[2025-03-02 22:05:46 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.1921469271183014 norm:0.00014821220247540623 max memory_allocated 29273.87548828125 
[2025-03-02 22:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.1921297162771225 norm:0.00014678167644888163 max memory_allocated 29273.87548828125 
[2025-03-02 22:07:26 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.19211222231388092 norm:0.0001442960783606395 max memory_allocated 29273.87548828125 
[2025-03-02 22:08:16 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.19209451973438263 norm:0.00014506815932691097 max memory_allocated 29273.87548828125 
[2025-03-02 22:09:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.19208106398582458 norm:0.00014266814105212688 max memory_allocated 29273.87548828125 
[2025-03-02 22:09:56 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.19207938015460968 norm:0.00014085239672567695 max memory_allocated 29273.87548828125 
[2025-03-02 22:10:46 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.19207404553890228 norm:0.0001399273896822706 max memory_allocated 29273.87548828125 
[2025-03-02 22:11:36 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.19206731021404266 norm:0.0001395141298417002 max memory_allocated 29273.87548828125 
[2025-03-02 22:11:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:12:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.22030438482761383 norm:0.0012045650510117412 max memory_allocated 29274.06298828125 
[2025-03-02 22:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.2175186276435852 norm:0.0006448855856433511 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.21494951844215393 norm:0.00042166985804215074 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.21350128948688507 norm:0.0003065287892241031 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:03 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.21318399906158447 norm:0.000250076234806329 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.21301737427711487 norm:0.0002146725746570155 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.21289801597595215 norm:0.00019613932818174362 max memory_allocated 29274.06298828125 
[2025-03-02 22:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.21281927824020386 norm:0.00018603444914333522 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.2127329409122467 norm:0.00017428504361305386 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.21265845000743866 norm:0.00016691131168045104 max memory_allocated 29274.06298828125 
[2025-03-02 22:21:03 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.2126140594482422 norm:0.00016520137432962656 max memory_allocated 29274.06298828125 
[2025-03-02 22:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.21257835626602173 norm:0.00015963790065143257 max memory_allocated 29274.06298828125 
[2025-03-02 22:22:42 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.21255061030387878 norm:0.00015757083019707352 max memory_allocated 29274.06298828125 
[2025-03-02 22:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.21253684163093567 norm:0.0001569815503899008 max memory_allocated 29274.06298828125 
[2025-03-02 22:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.21255116164684296 norm:0.00015866686590015888 max memory_allocated 29274.06298828125 
[2025-03-02 22:25:12 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.2125406712293625 norm:0.0001607190351933241 max memory_allocated 29274.06298828125 
[2025-03-02 22:26:01 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.21250905096530914 norm:0.0001597277878317982 max memory_allocated 29274.06298828125 
[2025-03-02 22:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.21249249577522278 norm:0.00015865152818150818 max memory_allocated 29274.06298828125 
[2025-03-02 22:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.21248191595077515 norm:0.00015570652612950653 max memory_allocated 29274.06298828125 
[2025-03-02 22:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.21248582005500793 norm:0.0001579745439812541 max memory_allocated 29274.06298828125 
[2025-03-02 22:28:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.24449758231639862 norm:0.0016114054014906287 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.24151010811328888 norm:0.0007923048688098788 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.2386859655380249 norm:0.0004895476158708334 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:08 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.23725856840610504 norm:0.0003467464994173497 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:58 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.2369755208492279 norm:0.00027435109950602055 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.23679065704345703 norm:0.00022953105508349836 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.23665694892406464 norm:0.00020420848159119487 max memory_allocated 29274.25048828125 
[2025-03-02 22:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.23654018342494965 norm:0.0001884025550680235 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.23645904660224915 norm:0.00017733049753587693 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:08 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.23640237748622894 norm:0.00016928078548517078 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:58 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.23636078834533691 norm:0.00016490703274030238 max memory_allocated 29274.25048828125 
[2025-03-02 22:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.23631396889686584 norm:0.000161955802468583 max memory_allocated 29274.25048828125 
[2025-03-02 22:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.23628707230091095 norm:0.0001592128537595272 max memory_allocated 29274.25048828125 
[2025-03-02 22:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.23626407980918884 norm:0.00015727138088550419 max memory_allocated 29274.25048828125 
[2025-03-02 22:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.2362513393163681 norm:0.000155331363203004 max memory_allocated 29274.25048828125 
[2025-03-02 22:42:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.23622797429561615 norm:0.00015500288282055408 max memory_allocated 29274.25048828125 
[2025-03-02 22:42:57 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.23623163998126984 norm:0.00015619538316968828 max memory_allocated 29274.25048828125 
[2025-03-02 22:43:47 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.23621903359889984 norm:0.00015564914792776108 max memory_allocated 29274.25048828125 
[2025-03-02 22:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.2362057864665985 norm:0.0001551240566186607 max memory_allocated 29274.25048828125 
[2025-03-02 22:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.23618517816066742 norm:0.00015573459677398205 max memory_allocated 29274.25048828125 
[2025-03-02 22:45:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.27325522899627686 norm:0.0029827128164470196 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:25 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.26871463656425476 norm:0.0015515803825110197 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.2649783790111542 norm:0.0009484250331297517 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.2633172571659088 norm:0.0006479772855527699 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.2628689408302307 norm:0.0004797122091986239 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.262575626373291 norm:0.0003814835799857974 max memory_allocated 29274.43798828125 
[2025-03-02 22:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.26238593459129333 norm:0.00032202753936871886 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.262241005897522 norm:0.00027552005485631526 max memory_allocated 29274.43798828125 
[2025-03-02 22:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.2621459662914276 norm:0.00025265614385716617 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.26206234097480774 norm:0.00023879327636677772 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.26199233531951904 norm:0.0002281406195834279 max memory_allocated 29274.43798828125 
[2025-03-02 22:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.26193967461586 norm:0.0002171038358937949 max memory_allocated 29274.43798828125 
[2025-03-02 22:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.2619091868400574 norm:0.0002126452891388908 max memory_allocated 29274.43798828125 
[2025-03-02 22:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.26188454031944275 norm:0.00020881557429675013 max memory_allocated 29274.43798828125 
[2025-03-02 22:58:13 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.26185351610183716 norm:0.00021209759870544076 max memory_allocated 29274.43798828125 
[2025-03-02 22:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.2618488371372223 norm:0.0002081567217828706 max memory_allocated 29274.43798828125 
[2025-03-02 22:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.261839896440506 norm:0.00020490377210080624 max memory_allocated 29274.43798828125 
[2025-03-02 23:00:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.26181644201278687 norm:0.00020430496078915894 max memory_allocated 29274.43798828125 
[2025-03-02 23:01:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.2617996037006378 norm:0.00020487679284997284 max memory_allocated 29274.43798828125 
[2025-03-02 23:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.2617984414100647 norm:0.00020702951587736607 max memory_allocated 29274.43798828125 
[2025-03-02 23:02:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 23:02:41 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:03:32 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.30297401547431946 norm:0.0042702206410467625 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:22 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.2984057664871216 norm:0.0032019936479628086 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:12 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.2943984866142273 norm:0.0027347449213266373 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.29273223876953125 norm:0.0023451941087841988 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.2923176884651184 norm:0.0019059896003454924 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:42 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.29199743270874023 norm:0.0016420723404735327 max memory_allocated 29274.77001953125 
[2025-03-02 23:08:32 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.2917449474334717 norm:0.0014966491144150496 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.2915431559085846 norm:0.0013522207736968994 max memory_allocated 29274.77001953125 
[2025-03-02 23:10:12 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.2913920283317566 norm:0.0012620278866961598 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:02 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.2913099527359009 norm:0.0012343705166131258 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:52 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.29126274585723877 norm:0.001285959267988801 max memory_allocated 29274.77001953125 
[2025-03-02 23:12:42 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.2911626398563385 norm:0.0012695627519860864 max memory_allocated 29274.77001953125 
[2025-03-02 23:13:32 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.291056364774704 norm:0.001156291808001697 max memory_allocated 29274.77001953125 
[2025-03-02 23:14:23 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.29099035263061523 norm:0.001134848571382463 max memory_allocated 29274.77001953125 
[2025-03-02 23:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.2909451425075531 norm:0.0011222630273550749 max memory_allocated 29274.77001953125 
[2025-03-02 23:16:03 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.290907084941864 norm:0.0010761026060208678 max memory_allocated 29274.77001953125 
[2025-03-02 23:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.2908689081668854 norm:0.0010292934020981193 max memory_allocated 29274.77001953125 
[2025-03-02 23:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.29082340002059937 norm:0.0009881476871669292 max memory_allocated 29274.77001953125 
[2025-03-02 23:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.2907988727092743 norm:0.0009832328651100397 max memory_allocated 29274.77001953125 
[2025-03-02 23:19:23 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.29077666997909546 norm:0.0009642940131016076 max memory_allocated 29274.77001953125 
[2025-03-02 23:19:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:19:42 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.34518900513648987 norm:0.006042772904038429 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.3374384045600891 norm:0.005738220643252134 max memory_allocated 29274.95751953125 
[2025-03-02 23:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.33212822675704956 norm:0.0056084878742694855 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.3300381600856781 norm:0.005702338181436062 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.32938042283058167 norm:0.005254700314253569 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.3289388120174408 norm:0.0052610402926802635 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.3285079598426819 norm:0.0051709325052797794 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.32808664441108704 norm:0.004668376874178648 max memory_allocated 29274.95751953125 
[2025-03-02 23:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.32776185870170593 norm:0.00421878369525075 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.3276180028915405 norm:0.003923343028873205 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:52 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.32741841673851013 norm:0.003686262760311365 max memory_allocated 29274.95751953125 
[2025-03-02 23:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.3273311257362366 norm:0.0034753214567899704 max memory_allocated 29274.95751953125 
[2025-03-02 23:30:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.3272935748100281 norm:0.0034330093767493963 max memory_allocated 29274.95751953125 
[2025-03-02 23:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.32725584506988525 norm:0.003425143426284194 max memory_allocated 29274.95751953125 
[2025-03-02 23:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.32716697454452515 norm:0.0032446517143398523 max memory_allocated 29274.95751953125 
[2025-03-02 23:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.32708582282066345 norm:0.0031325628515332937 max memory_allocated 29274.95751953125 
[2025-03-02 23:33:52 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.3270684480667114 norm:0.003009178675711155 max memory_allocated 29274.95751953125 
[2025-03-02 23:34:42 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.32707881927490234 norm:0.0031017351429909468 max memory_allocated 29274.95751953125 
[2025-03-02 23:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.327129989862442 norm:0.0029510250315070152 max memory_allocated 29274.95751953125 
[2025-03-02 23:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.32742196321487427 norm:0.00343151343986392 max memory_allocated 29274.95751953125 
[2025-03-02 23:36:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:36:41 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.47917309403419495 norm:0.035475559532642365 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.44680291414260864 norm:0.02501843497157097 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.4292537271976471 norm:0.020218199118971825 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.42047834396362305 norm:0.016268469393253326 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.4155549705028534 norm:0.014564057812094688 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.4130398631095886 norm:0.012995046563446522 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.41168588399887085 norm:0.011009800247848034 max memory_allocated 29275.14501953125 
[2025-03-02 23:43:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.41011545062065125 norm:0.010223531164228916 max memory_allocated 29275.14501953125 
[2025-03-02 23:44:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.4088691174983978 norm:0.009654051624238491 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:01 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.40819960832595825 norm:0.009199895896017551 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.40747058391571045 norm:0.008505013771355152 max memory_allocated 29275.14501953125 
[2025-03-02 23:46:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.40687495470046997 norm:0.007941694930195808 max memory_allocated 29275.14501953125 
[2025-03-02 23:47:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.4063127040863037 norm:0.007515948265790939 max memory_allocated 29275.14501953125 
[2025-03-02 23:48:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.40612488985061646 norm:0.0076063452288508415 max memory_allocated 29275.14501953125 
[2025-03-02 23:49:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.40566781163215637 norm:0.006822654977440834 max memory_allocated 29275.14501953125 
[2025-03-02 23:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.4055410921573639 norm:0.006756003014743328 max memory_allocated 29275.14501953125 
[2025-03-02 23:50:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.40553534030914307 norm:0.00671825697645545 max memory_allocated 29275.14501953125 
[2025-03-02 23:51:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.40540993213653564 norm:0.006558671128004789 max memory_allocated 29275.14501953125 
[2025-03-02 23:52:32 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.4051958918571472 norm:0.006325638387352228 max memory_allocated 29275.14501953125 
[2025-03-02 23:53:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.40508347749710083 norm:0.006340831983834505 max memory_allocated 29275.14501953125 
[2025-03-02 23:53:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:53:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.8085054755210876 norm:0.046753447502851486 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:20 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.7487516403198242 norm:0.026815464720129967 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:10 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.7167728543281555 norm:0.020869866013526917 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:00 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.69691002368927 norm:0.01652621477842331 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:50 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.6855195164680481 norm:0.013997113332152367 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.6782774925231934 norm:0.013820025138556957 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.6732062101364136 norm:0.014251633547246456 max memory_allocated 29275.33251953125 
[2025-03-03 00:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.6702253222465515 norm:0.01486472599208355 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.6674848794937134 norm:0.013947011902928352 max memory_allocated 29275.33251953125 
[2025-03-03 00:02:00 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.6659308671951294 norm:0.013751654885709286 max memory_allocated 29275.33251953125 
[2025-03-03 00:02:50 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.6640645265579224 norm:0.013702202588319778 max memory_allocated 29275.33251953125 
[2025-03-03 00:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.6624755859375 norm:0.012878449633717537 max memory_allocated 29275.33251953125 
[2025-03-03 00:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.6618719696998596 norm:0.013209911063313484 max memory_allocated 29275.33251953125 
[2025-03-03 00:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.6604887247085571 norm:0.013178283348679543 max memory_allocated 29275.33251953125 
[2025-03-03 00:06:10 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.6593116521835327 norm:0.012751072645187378 max memory_allocated 29275.33251953125 
[2025-03-03 00:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.658804714679718 norm:0.013340531848371029 max memory_allocated 29275.33251953125 
[2025-03-03 00:07:51 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.6580747961997986 norm:0.013585105538368225 max memory_allocated 29275.33251953125 
[2025-03-03 00:08:41 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.6571534872055054 norm:0.012961886823177338 max memory_allocated 29275.33251953125 
[2025-03-03 00:09:31 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.6562916040420532 norm:0.013161747716367245 max memory_allocated 29275.33251953125 
[2025-03-03 00:10:21 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.6557908058166504 norm:0.012814156711101532 max memory_allocated 29275.33251953125 
[2025-03-03 00:10:35 root] (main_calib_config2.py 372): INFO 40685.1865541935
[2025-03-03 00:10:45 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:12:43 root] (main_calib_config2.py 159): INFO wikitext2 : 5.18646240234375
[2025-03-03 00:12:43 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:15:46 root] (main_calib_config2.py 159): INFO c4 : 6.719954490661621
[2025-03-03 02:16:13 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.18646240234375, 'c4': 6.719954490661621, 'results': {'piqa': {'acc': 0.7878128400435256, 'acc_stderr': 0.009539299828174044, 'acc_norm': 0.7850924918389554, 'acc_norm_stderr': 0.009583665082653313}, 'arc_challenge': {'acc': 0.4308873720136519, 'acc_stderr': 0.014471133392642468, 'acc_norm': 0.4334470989761092, 'acc_norm_stderr': 0.014481376224558896}, 'hellaswag': {'acc': 0.584744074885481, 'acc_stderr': 0.004917590378138208, 'acc_norm': 0.7550288787094205, 'acc_norm_stderr': 0.0042919113504307094}, 'winogrande': {'acc': 0.696921862667719, 'acc_stderr': 0.01291672746263446}, 'boolq': {'acc': 0.6758409785932722, 'acc_stderr': 0.0081864168783053}, 'arc_easy': {'acc': 0.734006734006734, 'acc_stderr': 0.009066789565615694, 'acc_norm': 0.5871212121212122, 'acc_norm_stderr': 0.010102837421104675}}, 'versions': {'piqa': 0, 'arc_challenge': 0, 'hellaswag': 0, 'winogrande': 0, 'boolq': 1, 'arc_easy': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
