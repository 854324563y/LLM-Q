[2025-02-28 13:24:58 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-7b-hf_0.75', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.75.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:25:04 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:25:05 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:25:05 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:25:05 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.75.pkl
[2025-02-28 13:25:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:25:09 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:25:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.005262426566332579 norm:0.009158051572740078 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.002964269369840622 norm:0.0057612257078289986 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0024327693972736597 norm:0.004205039702355862 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0022583012469112873 norm:0.0034695675130933523 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.002077077515423298 norm:0.002878628671169281 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0019635932985693216 norm:0.0024868508335202932 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0019143096869811416 norm:0.0022795742843300104 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0019130553118884563 norm:0.0022166194394230843 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.001867997576482594 norm:0.0019863781053572893 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.001815847703255713 norm:0.0017747021047398448 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0018100404413416982 norm:0.0016182789113372564 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0017697017174214125 norm:0.0014662932371720672 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:50 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0017669182270765305 norm:0.001307384460233152 max memory_allocated 22562.10693359375 
[2025-02-28 13:32:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0017600208520889282 norm:0.0012060310691595078 max memory_allocated 22562.10693359375 
[2025-02-28 13:32:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001723159453831613 norm:0.0010501445503905416 max memory_allocated 22562.10693359375 
[2025-02-28 13:33:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.001738554099574685 norm:0.0010105816181749105 max memory_allocated 22562.10693359375 
[2025-02-28 13:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.001728001399897039 norm:0.001020102296024561 max memory_allocated 22562.10693359375 
[2025-02-28 13:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0017591449432075024 norm:0.0010406236397102475 max memory_allocated 22562.10693359375 
[2025-02-28 13:34:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0016903514042496681 norm:0.0008006806601770222 max memory_allocated 22562.10693359375 
[2025-02-28 13:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0017155250534415245 norm:0.0008301441557705402 max memory_allocated 22562.10693359375 
[2025-02-28 13:35:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:35:36 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:36:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.030567951500415802 norm:0.02398398518562317 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.019079744815826416 norm:0.012422974221408367 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.014725416898727417 norm:0.01156050805002451 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.012370355427265167 norm:0.007285718806087971 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.011859656311571598 norm:0.007059440482407808 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.011557064950466156 norm:0.006864167749881744 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.011352606117725372 norm:0.006520802620798349 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.011520951986312866 norm:0.006827595643699169 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.011872449889779091 norm:0.007485050242394209 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.011435333639383316 norm:0.0072892531752586365 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.0119329197332263 norm:0.009029521606862545 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.011553938500583172 norm:0.009245387278497219 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.011658046394586563 norm:0.009071705862879753 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.012038521468639374 norm:0.01046887319535017 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.011640701442956924 norm:0.009867011569440365 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.012140966020524502 norm:0.009655547328293324 max memory_allocated 22562.27880859375 
[2025-02-28 13:44:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.011748716235160828 norm:0.009465864859521389 max memory_allocated 22562.27880859375 
[2025-02-28 13:44:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.011828337796032429 norm:0.009112130850553513 max memory_allocated 22562.27880859375 
[2025-02-28 13:45:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.01222060713917017 norm:0.010066710412502289 max memory_allocated 22562.27880859375 
[2025-02-28 13:45:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.01236223429441452 norm:0.010552075691521168 max memory_allocated 22562.27880859375 
[2025-02-28 13:46:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 13:46:03 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.020854396745562553 norm:0.007474894169718027 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.0159559715539217 norm:0.005337535869330168 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.01471855491399765 norm:0.004066875670105219 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.014022085815668106 norm:0.003335275687277317 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.013436590321362019 norm:0.002772865118458867 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.012986062094569206 norm:0.0023254109546542168 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.012733753770589828 norm:0.002007239032536745 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.012614422477781773 norm:0.0016889297403395176 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.012544548138976097 norm:0.0013921158388257027 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.01250314898788929 norm:0.001195038203150034 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.01247749850153923 norm:0.0011354145826771855 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.012511315755546093 norm:0.0012997016310691833 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.012498079799115658 norm:0.001234516385011375 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.012467470951378345 norm:0.001074428902938962 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.012453249655663967 norm:0.001053158426657319 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.012476379051804543 norm:0.0011132487561553717 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.012486739084124565 norm:0.0011053296038880944 max memory_allocated 22562.45068359375 
[2025-02-28 13:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.012462800368666649 norm:0.00107010907959193 max memory_allocated 22562.45068359375 
[2025-02-28 13:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.01245073787868023 norm:0.0010160962119698524 max memory_allocated 22562.45068359375 
[2025-02-28 13:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.012448249384760857 norm:0.0010204444406554103 max memory_allocated 22562.45068359375 
[2025-02-28 13:56:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 13:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.026917757466435432 norm:0.0012714981567114592 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.02087334543466568 norm:0.0005045617581345141 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.017941303551197052 norm:0.0002844875562004745 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.017073161900043488 norm:0.00018238105985801667 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.016452010720968246 norm:0.000142089236760512 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.016149977222085 norm:0.0001246649189852178 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.016059663146734238 norm:0.000108234045910649 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.016015656292438507 norm:0.00010246616875519976 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.015983259305357933 norm:9.878479613689706e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.01596401259303093 norm:9.105556819122285e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.015943635255098343 norm:8.510971383657306e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.01592373661696911 norm:8.503354911226779e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.015910064801573753 norm:8.333088044309989e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.015903733670711517 norm:8.473944035358727e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.015895551070570946 norm:8.331525896210223e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.01588674634695053 norm:8.464334678137675e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.015880152583122253 norm:8.32781515782699e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.01587606593966484 norm:8.194016118068248e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.015872374176979065 norm:8.107259782264009e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.015868905931711197 norm:8.25917231850326e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:07:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.02757832035422325 norm:0.0010039126500487328 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.022957079112529755 norm:0.00040721718687564135 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.021062493324279785 norm:0.00023878457432147115 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.019874397665262222 norm:0.00017781600763555616 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.01918719708919525 norm:0.00014309743710327893 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.01887776330113411 norm:0.00014301695046015084 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.01873457245528698 norm:0.00013068850967101753 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.018702344968914986 norm:0.00013346015475690365 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.018728725612163544 norm:0.0001550043816678226 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.01870117150247097 norm:0.00015596498269587755 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.0186439398676157 norm:0.00014737865421921015 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.01860779896378517 norm:0.00014596592518500984 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.01859118789434433 norm:0.0001416942832292989 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.01856887713074684 norm:0.0001449199189664796 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.018562760204076767 norm:0.0001465326058678329 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.01856895536184311 norm:0.0001501810911577195 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.018552111461758614 norm:0.00015055092808324844 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.018539289012551308 norm:0.00015069360961206257 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.01853221468627453 norm:0.00014954441576264799 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.018516723066568375 norm:0.00014697722508572042 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.03357073292136192 norm:0.0009678683127276599 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.027454683557152748 norm:0.000440677598817274 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.023821646347641945 norm:0.0002539681736379862 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.022693179547786713 norm:0.00016925015370361507 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.022065065801143646 norm:0.0001274081732844934 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.021803518757224083 norm:0.00010511826258152723 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.021706486120820045 norm:9.577903256285936e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.02165158838033676 norm:9.192185825668275e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.02160542458295822 norm:8.902826812118292e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.02156774327158928 norm:8.980684651760384e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.02154354378581047 norm:8.908614108804613e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.02152225933969021 norm:8.644416084280238e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.021500853821635246 norm:8.362120570382103e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.021487660706043243 norm:8.367891132365912e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:08 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.02147824317216873 norm:8.473653724649921e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.021471815183758736 norm:8.394289761781693e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.02146819233894348 norm:8.31413344712928e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.02146020531654358 norm:8.346830145455897e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.021452225744724274 norm:8.120740676531568e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.021442605182528496 norm:7.997151260497048e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 14:28:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.03824996575713158 norm:0.0010426188819110394 max memory_allocated 22563.02294921875 
[2025-02-28 14:28:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.03139600157737732 norm:0.0004835076106246561 max memory_allocated 22563.02294921875 
[2025-02-28 14:29:24 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.02716933749616146 norm:0.00027464295271784067 max memory_allocated 22563.02294921875 
[2025-02-28 14:29:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.02595069818198681 norm:0.00018305281992070377 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.025301752611994743 norm:0.00013571581803262234 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.024994898587465286 norm:0.00011572086805244908 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.0248553529381752 norm:0.00010613833728712052 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.024776320904493332 norm:9.990530088543892e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.024715866893529892 norm:9.585719089955091e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.024668022990226746 norm:9.488029172644019e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.02462049201130867 norm:9.302440594183281e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.02458931878209114 norm:9.05261913430877e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.024566957727074623 norm:8.709236135473475e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.02454741671681404 norm:8.799904026091099e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.024525826796889305 norm:8.633093966636807e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.0245070680975914 norm:8.495308429701254e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.024492328986525536 norm:8.618933497928083e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.024475088343024254 norm:8.486706065014005e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.024464130401611328 norm:8.263517520390451e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.024462096393108368 norm:8.425654959864914e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 14:38:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.04173493757843971 norm:0.0011081388220191002 max memory_allocated 22563.19482421875 
[2025-02-28 14:39:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.03468794748187065 norm:0.0005320892087183893 max memory_allocated 22563.19482421875 
[2025-02-28 14:39:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.03015909157693386 norm:0.00030668044928461313 max memory_allocated 22563.19482421875 
[2025-02-28 14:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.028916217386722565 norm:0.00020051826140843332 max memory_allocated 22563.19482421875 
[2025-02-28 14:40:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.028302626684308052 norm:0.00014624657342210412 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.02803020179271698 norm:0.00011700920731527731 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.02789965458214283 norm:0.00010405352804809809 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.027812637388706207 norm:9.42170518101193e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.027757106348872185 norm:8.979496487881988e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.02771415188908577 norm:8.856931526679546e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.027669720351696014 norm:8.718449680600315e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.02763843722641468 norm:8.552167855668813e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.02761208638548851 norm:8.398694626521319e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.02758312225341797 norm:8.321167842950672e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.027564438059926033 norm:8.077170787146315e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.02754668891429901 norm:8.048361632972956e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:00 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.027533330023288727 norm:7.980852387845516e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.027519525960087776 norm:7.986680429894477e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.02750672772526741 norm:7.825822831364349e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.027494650334119797 norm:7.813287811586633e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 14:49:14 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.04363323375582695 norm:0.0009236247278749943 max memory_allocated 22563.36669921875 
[2025-02-28 14:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.03700992837548256 norm:0.00047280488070100546 max memory_allocated 22563.36669921875 
[2025-02-28 14:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.032777730375528336 norm:0.00026599469128996134 max memory_allocated 22563.36669921875 
[2025-02-28 14:50:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.03157004341483116 norm:0.0001754896657075733 max memory_allocated 22563.36669921875 
[2025-02-28 14:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.030973704531788826 norm:0.00013286243483889848 max memory_allocated 22563.36669921875 
[2025-02-28 14:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.03071906417608261 norm:0.00011146951146656647 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.030606022104620934 norm:0.00010354349069530144 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.03053925558924675 norm:0.00010165091953240335 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.030496148392558098 norm:9.982642950490117e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.030450575053691864 norm:9.912368113873526e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.030417755246162415 norm:9.770900942385197e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.030393170192837715 norm:9.718289220472798e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.03037404641509056 norm:9.734626655699685e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.030349481850862503 norm:9.690243314253166e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.030336378142237663 norm:9.733538900036365e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.030320651829242706 norm:9.74323702394031e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.030307335779070854 norm:9.668714483268559e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.03029704838991165 norm:9.638202755013481e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.030290428549051285 norm:9.799785038921982e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.03028043359518051 norm:9.820710693020374e-05 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 14:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.044101323932409286 norm:0.0007447226671501994 max memory_allocated 22563.53857421875 
[2025-02-28 15:00:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.03830040246248245 norm:0.0003517014847602695 max memory_allocated 22563.53857421875 
[2025-02-28 15:00:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.03456292301416397 norm:0.00020033714827150106 max memory_allocated 22563.53857421875 
[2025-02-28 15:01:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.03350395709276199 norm:0.0001341763709206134 max memory_allocated 22563.53857421875 
[2025-02-28 15:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.03297560289502144 norm:0.00010566356650087982 max memory_allocated 22563.53857421875 
[2025-02-28 15:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.03272080421447754 norm:9.213713929057121e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:02:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.03260257840156555 norm:8.603019523434341e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:03:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.032543785870075226 norm:8.294684084830806e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:03:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.03249538689851761 norm:8.0603982496541e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.032465048134326935 norm:8.026829891605303e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.0324336513876915 norm:7.985215779626742e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.03241046518087387 norm:7.90315170888789e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.032406702637672424 norm:7.797707803547382e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.03239564597606659 norm:7.716847176197916e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.03238634765148163 norm:7.755689148325473e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.03237391263246536 norm:7.731480582151562e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.03236545994877815 norm:7.795150304445997e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.03235464543104172 norm:7.898220792412758e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.032345376908779144 norm:7.915884634712711e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.03233993425965309 norm:7.922550139483064e-05 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 15:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.04435433819890022 norm:0.0005721990019083023 max memory_allocated 22563.71044921875 
[2025-02-28 15:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.03939453884959221 norm:0.0002735441958066076 max memory_allocated 22563.71044921875 
[2025-02-28 15:11:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.03596196323633194 norm:0.00015169571270234883 max memory_allocated 22563.71044921875 
[2025-02-28 15:11:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.03503323346376419 norm:0.00011262121552135795 max memory_allocated 22563.71044921875 
[2025-02-28 15:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.03451695665717125 norm:9.76785013335757e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:12:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.03425774350762367 norm:9.041754674399272e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:13:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.034135520458221436 norm:8.687233639648184e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:13:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.03406878933310509 norm:8.362152584595606e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:14:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.034029945731163025 norm:8.251457620644942e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:14:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.03400290757417679 norm:8.162618905771524e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.03397795930504799 norm:8.062071719905362e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.03395286202430725 norm:7.922355143819004e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.03394105285406113 norm:8.01771238911897e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.03392384573817253 norm:7.874195580370724e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.03391356021165848 norm:7.861864287406206e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.033903852105140686 norm:7.960554648889229e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.03389487415552139 norm:7.943961827550083e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.03388777747750282 norm:7.758728315820917e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.03388534486293793 norm:7.758998253848404e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.03387871012091637 norm:7.720344001427293e-05 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 15:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.0452246367931366 norm:0.0005778054473921657 max memory_allocated 22563.88232421875 
[2025-02-28 15:20:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.040522944182157516 norm:0.000282366294413805 max memory_allocated 22563.88232421875 
[2025-02-28 15:21:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.03721975162625313 norm:0.00016445621440652758 max memory_allocated 22563.88232421875 
[2025-02-28 15:22:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.03630289435386658 norm:0.00011789286509156227 max memory_allocated 22563.88232421875 
[2025-02-28 15:22:31 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.03579319268465042 norm:9.549763490213081e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:23:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.03553016111254692 norm:8.409040310652927e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.03539922088384628 norm:7.966041448526084e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:24:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.03532717749476433 norm:7.572339382022619e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:24:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.035286612808704376 norm:7.396593719022349e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.03525708243250847 norm:7.292092050192878e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:25:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.03523634746670723 norm:7.200321124400944e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.0352151058614254 norm:7.124288094928488e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.03520241007208824 norm:7.02918550814502e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.03518546372652054 norm:7.009789260337129e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.035177186131477356 norm:6.994157592998818e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.035170283168554306 norm:6.93063047947362e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.03516246750950813 norm:6.917455175425857e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.035157859325408936 norm:6.856387335574254e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.035156410187482834 norm:6.889348878758028e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.03514920547604561 norm:6.851530633866787e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 15:30:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.04670347645878792 norm:0.00047589439782314 max memory_allocated 22564.05419921875 
[2025-02-28 15:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.04199059307575226 norm:0.000246376235736534 max memory_allocated 22564.05419921875 
[2025-02-28 15:31:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.03848741203546524 norm:0.00014212331734597683 max memory_allocated 22564.05419921875 
[2025-02-28 15:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.037560053169727325 norm:0.00010233890498057008 max memory_allocated 22564.05419921875 
[2025-02-28 15:32:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.037059538066387177 norm:8.481831173412502e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.0368039645254612 norm:7.602884579682723e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.03669026494026184 norm:7.170557364588603e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.036630213260650635 norm:7.102290692273527e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:34:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.036591045558452606 norm:6.99709344189614e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.036564718931913376 norm:6.888119241921231e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.03654187172651291 norm:6.879127613501623e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.036522332578897476 norm:6.805796147091314e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.03650602698326111 norm:6.814461085014045e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:37:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.03649118170142174 norm:6.777152157155797e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.0364777073264122 norm:6.80607627145946e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.03646957874298096 norm:6.786707672290504e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.036459021270275116 norm:6.770069740014151e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.03645326569676399 norm:6.789878534618765e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.03644745051860809 norm:6.68792927172035e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.03644387423992157 norm:6.673572352156043e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 15:41:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.04357772320508957 norm:0.0007175119826570153 max memory_allocated 22564.22607421875 
[2025-02-28 15:41:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.040732648223638535 norm:0.00036197257577441633 max memory_allocated 22564.22607421875 
[2025-02-28 15:42:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.03885668143630028 norm:0.0002348996786167845 max memory_allocated 22564.22607421875 
[2025-02-28 15:42:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.03768405318260193 norm:0.00018155302677769214 max memory_allocated 22564.22607421875 
[2025-02-28 15:43:21 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.03709340840578079 norm:0.00015305880515370518 max memory_allocated 22564.22607421875 
[2025-02-28 15:43:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.036770448088645935 norm:0.000135527370730415 max memory_allocated 22564.22607421875 
[2025-02-28 15:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.036593370139598846 norm:0.000126739963889122 max memory_allocated 22564.22607421875 
[2025-02-28 15:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.03649492934346199 norm:0.00012906167830806226 max memory_allocated 22564.22607421875 
[2025-02-28 15:45:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.03643158823251724 norm:0.00011740704212570563 max memory_allocated 22564.22607421875 
[2025-02-28 15:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.036383286118507385 norm:0.00011297847231617197 max memory_allocated 22564.22607421875 
[2025-02-28 15:46:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.03634243085980415 norm:0.00010837845911737531 max memory_allocated 22564.22607421875 
[2025-02-28 15:46:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.036321599036455154 norm:0.00010956898040603846 max memory_allocated 22564.22607421875 
[2025-02-28 15:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.03631027787923813 norm:0.00011447384167695418 max memory_allocated 22564.22607421875 
[2025-02-28 15:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.03631123900413513 norm:0.00011177893611602485 max memory_allocated 22564.22607421875 
[2025-02-28 15:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.036284394562244415 norm:0.00010900013148784637 max memory_allocated 22564.22607421875 
[2025-02-28 15:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.03625626116991043 norm:0.00010603619739413261 max memory_allocated 22564.22607421875 
[2025-02-28 15:49:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.03625901788473129 norm:0.00011345303209964186 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.03625202924013138 norm:0.0001068518467945978 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.036243826150894165 norm:0.0001089641300495714 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.036233916878700256 norm:0.00011881778482347727 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 15:51:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.043942324817180634 norm:0.0005289116525091231 max memory_allocated 22564.39794921875 
[2025-02-28 15:52:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.04127493500709534 norm:0.00028554198797792196 max memory_allocated 22564.39794921875 
[2025-02-28 15:52:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.03954293206334114 norm:0.0002015257196035236 max memory_allocated 22564.39794921875 
[2025-02-28 15:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.03842347115278244 norm:0.0001603638957021758 max memory_allocated 22564.39794921875 
[2025-02-28 15:53:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.03784310817718506 norm:0.00013919819321017712 max memory_allocated 22564.39794921875 
[2025-02-28 15:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.03750687092542648 norm:0.00012666519614867866 max memory_allocated 22564.39794921875 
[2025-02-28 15:54:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.03732990846037865 norm:0.0001142752225860022 max memory_allocated 22564.39794921875 
[2025-02-28 15:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.037226710468530655 norm:0.00011161851580254734 max memory_allocated 22564.39794921875 
[2025-02-28 15:55:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.03715808317065239 norm:0.0001147539442172274 max memory_allocated 22564.39794921875 
[2025-02-28 15:56:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.037096407264471054 norm:0.00010352394747314975 max memory_allocated 22564.39794921875 
[2025-02-28 15:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.03704197332262993 norm:0.00010002238559536636 max memory_allocated 22564.39794921875 
[2025-02-28 15:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.03701503574848175 norm:9.283148392569274e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.03700931742787361 norm:9.909692744258791e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.037016648799180984 norm:9.593066351953894e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:58:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.03698153421282768 norm:8.572339720558375e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.03697074577212334 norm:8.657098805997521e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:59:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.036949750036001205 norm:8.175849507097155e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:00:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.03694671764969826 norm:8.122486906358972e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.036945998668670654 norm:8.648256334709004e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.036946117877960205 norm:8.542504656361416e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 16:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.048628777265548706 norm:0.0006568402168340981 max memory_allocated 22564.56982421875 
[2025-02-28 16:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.0435936376452446 norm:0.00031287630554288626 max memory_allocated 22564.56982421875 
[2025-02-28 16:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.03991622477769852 norm:0.00017949013272300363 max memory_allocated 22564.56982421875 
[2025-02-28 16:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.03900665044784546 norm:0.00012538782902993262 max memory_allocated 22564.56982421875 
[2025-02-28 16:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.03844539076089859 norm:9.82487399596721e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.03812345117330551 norm:8.273092680610716e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:05:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.03797042742371559 norm:7.528918649768457e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.037873223423957825 norm:7.112448656698689e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:06:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.03781205415725708 norm:6.666278204647824e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:06:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.03776190057396889 norm:6.490419764304534e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:07:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.037728361785411835 norm:6.379620754159987e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:07:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.0376923643052578 norm:6.246934935916215e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:08:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.03766340762376785 norm:6.156267772894353e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.03763908892869949 norm:6.10221759416163e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.03761812672019005 norm:6.142307393020019e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:09:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.03760230541229248 norm:6.144988583400846e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:10:19 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.03758302330970764 norm:6.100765313021839e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:10:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.03756629675626755 norm:6.123141793068498e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.037553559988737106 norm:6.0366357502061874e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:11:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.037546876817941666 norm:6.080153616494499e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:11:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 16:12:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.04967050999403 norm:0.0006908453069627285 max memory_allocated 22564.74169921875 
[2025-02-28 16:13:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.044594768434762955 norm:0.0002938649267889559 max memory_allocated 22564.74169921875 
[2025-02-28 16:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.04070137441158295 norm:0.00016275275265797973 max memory_allocated 22564.74169921875 
[2025-02-28 16:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.039776336401700974 norm:0.00011772580910474062 max memory_allocated 22564.74169921875 
[2025-02-28 16:14:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.03918759897351265 norm:9.662580850999802e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.03882848843932152 norm:8.492655615555122e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.03864942118525505 norm:7.671918137930334e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:16:07 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.03855574503540993 norm:7.191816985141486e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:16:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.03848490118980408 norm:6.921555905137211e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:17:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.03842838108539581 norm:6.689611473120749e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:17:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.03837774693965912 norm:6.563931674463674e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:18:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.0383407324552536 norm:6.382508581737056e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:18:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.03831413388252258 norm:6.310177559498698e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.03828928619623184 norm:6.277574721025303e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:19:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.03826839104294777 norm:6.181019125506282e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:20:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.03824567422270775 norm:6.132002454251051e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:20:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.038222990930080414 norm:6.0540467529790476e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.038205672055482864 norm:6.074696284485981e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:21:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.03818529471755028 norm:5.9125213738298044e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.038175005465745926 norm:5.968765253783204e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:22:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 16:23:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.043668508529663086 norm:0.0005143571179360151 max memory_allocated 22564.91357421875 
[2025-02-28 16:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.04168907552957535 norm:0.00019104196690022945 max memory_allocated 22564.91357421875 
[2025-02-28 16:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.04057495296001434 norm:0.00013967877021059394 max memory_allocated 22564.91357421875 
[2025-02-28 16:24:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.03961535915732384 norm:0.00012731034075841308 max memory_allocated 22564.91357421875 
[2025-02-28 16:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.03899064287543297 norm:0.00011065066792070866 max memory_allocated 22564.91357421875 
[2025-02-28 16:25:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.03867059946060181 norm:9.406769095221534e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:26:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.03853980451822281 norm:9.368166502099484e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.038453228771686554 norm:9.024262544699013e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.038368646055459976 norm:8.416623313678429e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:27:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.03833922743797302 norm:7.754068792564794e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.03830308839678764 norm:7.214152719825506e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.03827608749270439 norm:7.352814282057807e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:29:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.038248173892498016 norm:6.594921433134004e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.03823234513401985 norm:6.668663263553753e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.038217511028051376 norm:6.93764304742217e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:30:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.038213007152080536 norm:6.887222843943164e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.03820149227976799 norm:7.106087286956608e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:31:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.038192540407180786 norm:7.055849710013717e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:32:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.03818655386567116 norm:7.478759653167799e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:32:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.03818419575691223 norm:7.187463052105159e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:32:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 16:33:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.04815778508782387 norm:0.0015219644410535693 max memory_allocated 22565.08544921875 
[2025-02-28 16:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.04538838937878609 norm:0.0006344590219669044 max memory_allocated 22565.08544921875 
[2025-02-28 16:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.0437871590256691 norm:0.0003612446307670325 max memory_allocated 22565.08544921875 
[2025-02-28 16:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.04259971156716347 norm:0.0002470947802066803 max memory_allocated 22565.08544921875 
[2025-02-28 16:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.04180482402443886 norm:0.00020200994913466275 max memory_allocated 22565.08544921875 
[2025-02-28 16:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.04139823094010353 norm:0.0001743047178024426 max memory_allocated 22565.08544921875 
[2025-02-28 16:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.04122242331504822 norm:0.0001529250293970108 max memory_allocated 22565.08544921875 
[2025-02-28 16:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.041131392121315 norm:0.00013712228974327445 max memory_allocated 22565.08544921875 
[2025-02-28 16:37:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.041055768728256226 norm:0.0001270573411602527 max memory_allocated 22565.08544921875 
[2025-02-28 16:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.04099137336015701 norm:0.0001224107836605981 max memory_allocated 22565.08544921875 
[2025-02-28 16:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.04095159471035004 norm:0.00011379457282600924 max memory_allocated 22565.08544921875 
[2025-02-28 16:39:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.04091506451368332 norm:0.00010950388968922198 max memory_allocated 22565.08544921875 
[2025-02-28 16:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.040882986038923264 norm:0.00010244275472359732 max memory_allocated 22565.08544921875 
[2025-02-28 16:40:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.040859296917915344 norm:9.937726281350479e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.040844082832336426 norm:9.663731907494366e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:41:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.040820710361003876 norm:8.963744767243043e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.040797919034957886 norm:8.394582255277783e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:42:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.04077577218413353 norm:8.194716065190732e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.040763307362794876 norm:8.038635132834315e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:43:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.04075269028544426 norm:7.774856931064278e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:43:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 16:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.04999881237745285 norm:0.0007009721593931317 max memory_allocated 22565.25732421875 
[2025-02-28 16:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.04770695045590401 norm:0.00032397740869782865 max memory_allocated 22565.25732421875 
[2025-02-28 16:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.04646483436226845 norm:0.00020804052473977208 max memory_allocated 22565.25732421875 
[2025-02-28 16:45:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.045488566160202026 norm:0.00014896216453053057 max memory_allocated 22565.25732421875 
[2025-02-28 16:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.04478668421506882 norm:0.00012137326848460361 max memory_allocated 22565.25732421875 
[2025-02-28 16:46:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.04442816227674484 norm:0.00010773232497740537 max memory_allocated 22565.25732421875 
[2025-02-28 16:46:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.04429302364587784 norm:9.544183558318764e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:47:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.04420860856771469 norm:8.849291771184653e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.04415532946586609 norm:8.830177102936432e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.04411580413579941 norm:8.281172631541267e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.044066525995731354 norm:8.160780998878181e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:49:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.04402941092848778 norm:7.56699446355924e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:50:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.044008977711200714 norm:7.134632323868573e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:50:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.043990835547447205 norm:6.864510214654729e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.04396387189626694 norm:6.849702185718343e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.04394470900297165 norm:7.085321703925729e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:52:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.0439402237534523 norm:7.282873411895707e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:52:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.04392671585083008 norm:6.617514009121805e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:53:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.04391583055257797 norm:6.482085882453248e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:53:35 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.04390352964401245 norm:6.344880239339545e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:53:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 16:54:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.05547941476106644 norm:0.0009570568217895925 max memory_allocated 22565.42919921875 
[2025-02-28 16:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.052485719323158264 norm:0.00033985316986218095 max memory_allocated 22565.42919921875 
[2025-02-28 16:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.05102561414241791 norm:0.00021775267668999732 max memory_allocated 22565.42919921875 
[2025-02-28 16:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.04995442554354668 norm:0.0001571418542880565 max memory_allocated 22565.42919921875 
[2025-02-28 16:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.04918680340051651 norm:0.00014084027498029172 max memory_allocated 22565.42919921875 
[2025-02-28 16:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.04878001660108566 norm:0.00012575852451846004 max memory_allocated 22565.42919921875 
[2025-02-28 16:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.04860949143767357 norm:0.00011543290747795254 max memory_allocated 22565.42919921875 
[2025-02-28 16:57:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.04850775748491287 norm:0.00011421854287618771 max memory_allocated 22565.42919921875 
[2025-02-28 16:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.04842841997742653 norm:0.00010502952500246465 max memory_allocated 22565.42919921875 
[2025-02-28 16:58:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.048372671008110046 norm:0.00010017499153036624 max memory_allocated 22565.42919921875 
[2025-02-28 16:59:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.04833925887942314 norm:9.944162593455985e-05 max memory_allocated 22565.42919921875 
[2025-02-28 16:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.04828748106956482 norm:9.68233507592231e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:00:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.04826238006353378 norm:9.284370025852695e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.048226311802864075 norm:8.656507998239249e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:01:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.04819441959261894 norm:8.487122977385297e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.048166755586862564 norm:8.23926311568357e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:02:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.048150792717933655 norm:8.687165973242372e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:02:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.04814397171139717 norm:8.923534915084019e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:03:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.04812311753630638 norm:9.000707359518856e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.04811381176114082 norm:9.163816139334813e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:04:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 17:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.058348964899778366 norm:0.00045936883543618023 max memory_allocated 22565.60107421875 
[2025-02-28 17:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.056734707206487656 norm:0.0002051678893622011 max memory_allocated 22565.60107421875 
[2025-02-28 17:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.055789586156606674 norm:0.00014695969002787024 max memory_allocated 22565.60107421875 
[2025-02-28 17:06:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.05493426322937012 norm:0.00012606926611624658 max memory_allocated 22565.60107421875 
[2025-02-28 17:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.05416198447346687 norm:0.0001005485319183208 max memory_allocated 22565.60107421875 
[2025-02-28 17:07:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.05377386137843132 norm:9.411298378836364e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.05365637689828873 norm:9.353963832836598e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.053596656769514084 norm:8.364869427168742e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.05354699119925499 norm:7.831124094082043e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.05350417271256447 norm:7.594389899168164e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.05346737429499626 norm:8.027779404073954e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:10:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.053450025618076324 norm:7.694294617976993e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:10:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.05342508852481842 norm:7.352209649980068e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.05341782793402672 norm:7.410520629491657e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:11:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.05339827761054039 norm:7.116160122677684e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.05338563770055771 norm:6.684030086034909e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.05336809903383255 norm:6.999347533565015e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.05335763469338417 norm:6.455944094341248e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:13:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.05334192141890526 norm:6.353625940391794e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.053324852138757706 norm:6.326322181848809e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:14:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 17:15:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.06867942959070206 norm:0.0014674747362732887 max memory_allocated 22565.77294921875 
[2025-02-28 17:15:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.06550577282905579 norm:0.0005244007334113121 max memory_allocated 22565.77294921875 
[2025-02-28 17:16:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.06396593898534775 norm:0.0002960011188406497 max memory_allocated 22565.77294921875 
[2025-02-28 17:16:40 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.0627240538597107 norm:0.00025005347561091185 max memory_allocated 22565.77294921875 
[2025-02-28 17:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.06183949485421181 norm:0.0002097422257065773 max memory_allocated 22565.77294921875 
[2025-02-28 17:17:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.061431802809238434 norm:0.00018277482013218105 max memory_allocated 22565.77294921875 
[2025-02-28 17:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.06129210442304611 norm:0.00016647300799377263 max memory_allocated 22565.77294921875 
[2025-02-28 17:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.061234112828969955 norm:0.00015763418923597783 max memory_allocated 22565.77294921875 
[2025-02-28 17:19:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.06116757541894913 norm:0.00014922086847946048 max memory_allocated 22565.77294921875 
[2025-02-28 17:19:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.061097245663404465 norm:0.00014129318878985941 max memory_allocated 22565.77294921875 
[2025-02-28 17:20:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.06104361265897751 norm:0.00013215100625529885 max memory_allocated 22565.77294921875 
[2025-02-28 17:20:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.060996152460575104 norm:0.00012434431118890643 max memory_allocated 22565.77294921875 
[2025-02-28 17:21:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.06096494570374489 norm:0.00011917369556613266 max memory_allocated 22565.77294921875 
[2025-02-28 17:21:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.06092778593301773 norm:0.00011225789785385132 max memory_allocated 22565.77294921875 
[2025-02-28 17:22:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.060905300080776215 norm:0.00010674987424863502 max memory_allocated 22565.77294921875 
[2025-02-28 17:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.06087975949048996 norm:0.0001057578920153901 max memory_allocated 22565.77294921875 
[2025-02-28 17:23:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.06087305769324303 norm:9.907911589834839e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:23:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.060839731246232986 norm:9.959409362636507e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:24:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.06081148236989975 norm:9.519175364403054e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:24:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.060788094997406006 norm:9.476612467551604e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:24:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 17:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.07689839601516724 norm:0.0016181019600480795 max memory_allocated 22565.94482421875 
[2025-02-28 17:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.07405547052621841 norm:0.0007218688842840493 max memory_allocated 22565.94482421875 
[2025-02-28 17:26:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.07227273285388947 norm:0.0003733821213245392 max memory_allocated 22565.94482421875 
[2025-02-28 17:27:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.07094889879226685 norm:0.0002820036606863141 max memory_allocated 22565.94482421875 
[2025-02-28 17:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.06999917328357697 norm:0.0002268333628308028 max memory_allocated 22565.94482421875 
[2025-02-28 17:28:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.06967680901288986 norm:0.00018739045481197536 max memory_allocated 22565.94482421875 
[2025-02-28 17:28:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.06955870240926743 norm:0.00016796727140899748 max memory_allocated 22565.94482421875 
[2025-02-28 17:29:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.06946763396263123 norm:0.00015809337492100894 max memory_allocated 22565.94482421875 
[2025-02-28 17:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.0694083720445633 norm:0.0001395146973663941 max memory_allocated 22565.94482421875 
[2025-02-28 17:30:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.06936991959810257 norm:0.00012112771219108254 max memory_allocated 22565.94482421875 
[2025-02-28 17:30:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.06932342797517776 norm:0.00012273533502593637 max memory_allocated 22565.94482421875 
[2025-02-28 17:31:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.06927565485239029 norm:0.00011614982940955088 max memory_allocated 22565.94482421875 
[2025-02-28 17:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.06924378126859665 norm:0.00010653943172656 max memory_allocated 22565.94482421875 
[2025-02-28 17:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.06919962167739868 norm:0.00010053829464595765 max memory_allocated 22565.94482421875 
[2025-02-28 17:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.06917949765920639 norm:9.487413626629859e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.06916338205337524 norm:9.095708082895726e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.06915318965911865 norm:9.221855725627393e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:34:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.06913615763187408 norm:8.593514940002933e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:34:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.06912125647068024 norm:8.124408486764878e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.06910862773656845 norm:7.633863424416631e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:35:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 17:35:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.08713771402835846 norm:0.0020536829251796007 max memory_allocated 22566.11669921875 
[2025-02-28 17:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.0835375040769577 norm:0.0006124310311861336 max memory_allocated 22566.11669921875 
[2025-02-28 17:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.08182154595851898 norm:0.0003935705462936312 max memory_allocated 22566.11669921875 
[2025-02-28 17:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.08037574589252472 norm:0.0003035108093172312 max memory_allocated 22566.11669921875 
[2025-02-28 17:38:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.07936806976795197 norm:0.0002491566410753876 max memory_allocated 22566.11669921875 
[2025-02-28 17:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.07906804233789444 norm:0.00021706170809920877 max memory_allocated 22566.11669921875 
[2025-02-28 17:39:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.07893779873847961 norm:0.00019571371376514435 max memory_allocated 22566.11669921875 
[2025-02-28 17:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.0788569375872612 norm:0.00017825877876020968 max memory_allocated 22566.11669921875 
[2025-02-28 17:40:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.07876579463481903 norm:0.00016218454402405769 max memory_allocated 22566.11669921875 
[2025-02-28 17:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.0787205696105957 norm:0.0001667608885327354 max memory_allocated 22566.11669921875 
[2025-02-28 17:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.07865864783525467 norm:0.0001579397649038583 max memory_allocated 22566.11669921875 
[2025-02-28 17:41:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.07862276583909988 norm:0.00014740077313035727 max memory_allocated 22566.11669921875 
[2025-02-28 17:42:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.07859808951616287 norm:0.00014054607891011983 max memory_allocated 22566.11669921875 
[2025-02-28 17:42:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.07855480164289474 norm:0.00013744516763836145 max memory_allocated 22566.11669921875 
[2025-02-28 17:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.07851539552211761 norm:0.0001342906034551561 max memory_allocated 22566.11669921875 
[2025-02-28 17:43:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.0784742683172226 norm:0.00012320837413426489 max memory_allocated 22566.11669921875 
[2025-02-28 17:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.07845109701156616 norm:0.00012183929356979206 max memory_allocated 22566.11669921875 
[2025-02-28 17:44:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.07842940837144852 norm:0.00011937758245039731 max memory_allocated 22566.11669921875 
[2025-02-28 17:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.07841844856739044 norm:0.00011977276881225407 max memory_allocated 22566.11669921875 
[2025-02-28 17:45:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.0784047320485115 norm:0.00011664039629977196 max memory_allocated 22566.11669921875 
[2025-02-28 17:45:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 17:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.09887762367725372 norm:0.0010276857065036893 max memory_allocated 22566.28857421875 
[2025-02-28 17:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.09592871367931366 norm:0.0005063587450422347 max memory_allocated 22566.28857421875 
[2025-02-28 17:47:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.09382268041372299 norm:0.00031837477581575513 max memory_allocated 22566.28857421875 
[2025-02-28 17:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.09224448353052139 norm:0.00023999353288672864 max memory_allocated 22566.28857421875 
[2025-02-28 17:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.09127593040466309 norm:0.00020617633708752692 max memory_allocated 22566.28857421875 
[2025-02-28 17:48:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.09095735102891922 norm:0.00018625256780069321 max memory_allocated 22566.28857421875 
[2025-02-28 17:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.09086984395980835 norm:0.00016367825446650386 max memory_allocated 22566.28857421875 
[2025-02-28 17:49:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.09078989923000336 norm:0.00014987697068136185 max memory_allocated 22566.28857421875 
[2025-02-28 17:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.09068118780851364 norm:0.000151123822433874 max memory_allocated 22566.28857421875 
[2025-02-28 17:51:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.09064753353595734 norm:0.00014052643382456154 max memory_allocated 22566.28857421875 
[2025-02-28 17:51:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.09059899300336838 norm:0.00013166545249987394 max memory_allocated 22566.28857421875 
[2025-02-28 17:52:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.09061779081821442 norm:0.00015862006694078445 max memory_allocated 22566.28857421875 
[2025-02-28 17:52:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.09069505333900452 norm:0.00016955897444859147 max memory_allocated 22566.28857421875 
[2025-02-28 17:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.09049028158187866 norm:0.0001255123206647113 max memory_allocated 22566.28857421875 
[2025-02-28 17:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.09037692844867706 norm:0.00011453877232270315 max memory_allocated 22566.28857421875 
[2025-02-28 17:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.09037954360246658 norm:0.00011132095096400008 max memory_allocated 22566.28857421875 
[2025-02-28 17:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.09031292051076889 norm:0.00011021478712791577 max memory_allocated 22566.28857421875 
[2025-02-28 17:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.09031277149915695 norm:0.0001071479928214103 max memory_allocated 22566.28857421875 
[2025-02-28 17:55:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.09029678255319595 norm:0.00010022275819210336 max memory_allocated 22566.28857421875 
[2025-02-28 17:56:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.0902920737862587 norm:9.989946556743234e-05 max memory_allocated 22566.28857421875 
[2025-02-28 17:56:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 17:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.11196254938840866 norm:0.001019167946651578 max memory_allocated 22566.46044921875 
[2025-02-28 17:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.10862374305725098 norm:0.0005057575763203204 max memory_allocated 22566.46044921875 
[2025-02-28 17:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.10648568719625473 norm:0.0003280988894402981 max memory_allocated 22566.46044921875 
[2025-02-28 17:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.10476232320070267 norm:0.00024880829732865095 max memory_allocated 22566.46044921875 
[2025-02-28 17:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.10383709520101547 norm:0.00020894822955597192 max memory_allocated 22566.46044921875 
[2025-02-28 17:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.10352863371372223 norm:0.00017980331904254854 max memory_allocated 22566.46044921875 
[2025-02-28 17:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.10336574912071228 norm:0.00016479143232572824 max memory_allocated 22566.46044921875 
[2025-02-28 18:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.10324213653802872 norm:0.0001545285776956007 max memory_allocated 22566.46044921875 
[2025-02-28 18:00:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.10312265157699585 norm:0.0001470120478188619 max memory_allocated 22566.46044921875 
[2025-02-28 18:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.10306288301944733 norm:0.00014176761033013463 max memory_allocated 22566.46044921875 
[2025-02-28 18:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.10300104320049286 norm:0.0001373133563902229 max memory_allocated 22566.46044921875 
[2025-02-28 18:02:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.10291177779436111 norm:0.00012839319242630154 max memory_allocated 22566.46044921875 
[2025-02-28 18:02:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.10287096351385117 norm:0.0001205015360028483 max memory_allocated 22566.46044921875 
[2025-02-28 18:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.10285552591085434 norm:0.00012215545575600117 max memory_allocated 22566.46044921875 
[2025-02-28 18:03:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.10282912105321884 norm:0.00012089032679796219 max memory_allocated 22566.46044921875 
[2025-02-28 18:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.10278484225273132 norm:0.00011971611820627004 max memory_allocated 22566.46044921875 
[2025-02-28 18:05:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.10276325047016144 norm:0.00011737905879272148 max memory_allocated 22566.46044921875 
[2025-02-28 18:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.10274715721607208 norm:0.00011791300494223833 max memory_allocated 22566.46044921875 
[2025-02-28 18:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.10275755822658539 norm:0.0001229994959430769 max memory_allocated 22566.46044921875 
[2025-02-28 18:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.10274745523929596 norm:0.00012095273268641904 max memory_allocated 22566.46044921875 
[2025-02-28 18:06:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 18:07:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.12835559248924255 norm:0.0021111085079610348 max memory_allocated 22566.63232421875 
[2025-02-28 18:07:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.12431597709655762 norm:0.0008405976695939898 max memory_allocated 22566.63232421875 
[2025-02-28 18:08:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.12173768132925034 norm:0.000408983847592026 max memory_allocated 22566.63232421875 
[2025-02-28 18:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.1198219358921051 norm:0.00028562950319610536 max memory_allocated 22566.63232421875 
[2025-02-28 18:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.11898274719715118 norm:0.00024672740255482495 max memory_allocated 22566.63232421875 
[2025-02-28 18:09:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.11876803636550903 norm:0.00020684153423644602 max memory_allocated 22566.63232421875 
[2025-02-28 18:10:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.11865762621164322 norm:0.00019615059136413038 max memory_allocated 22566.63232421875 
[2025-02-28 18:10:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.11856664717197418 norm:0.00018096131680067629 max memory_allocated 22566.63232421875 
[2025-02-28 18:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.118495412170887 norm:0.00016723141015972942 max memory_allocated 22566.63232421875 
[2025-02-28 18:11:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.1184428483247757 norm:0.00016257187235169113 max memory_allocated 22566.63232421875 
[2025-02-28 18:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.11839653551578522 norm:0.00015440814604517072 max memory_allocated 22566.63232421875 
[2025-02-28 18:12:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.11835537850856781 norm:0.00014560928684659302 max memory_allocated 22566.63232421875 
[2025-02-28 18:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.11831153929233551 norm:0.00013681281416211277 max memory_allocated 22566.63232421875 
[2025-02-28 18:13:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.11828640103340149 norm:0.00013130225124768913 max memory_allocated 22566.63232421875 
[2025-02-28 18:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.11824849247932434 norm:0.0001282331650145352 max memory_allocated 22566.63232421875 
[2025-02-28 18:14:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.11822910606861115 norm:0.00012493753456510603 max memory_allocated 22566.63232421875 
[2025-02-28 18:15:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.11822135001420975 norm:0.000123417325085029 max memory_allocated 22566.63232421875 
[2025-02-28 18:15:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.11819081753492355 norm:0.00011627361527644098 max memory_allocated 22566.63232421875 
[2025-02-28 18:16:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.1181701049208641 norm:0.00011532439384609461 max memory_allocated 22566.63232421875 
[2025-02-28 18:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.1181575208902359 norm:0.00011268338130321354 max memory_allocated 22566.63232421875 
[2025-02-28 18:17:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 18:17:10 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:17:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.1461537927389145 norm:0.0051261056214571 max memory_allocated 22566.91943359375 
[2025-02-28 18:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.14301589131355286 norm:0.0040589142590761185 max memory_allocated 22566.91943359375 
[2025-02-28 18:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.14051562547683716 norm:0.0032280271407216787 max memory_allocated 22566.91943359375 
[2025-02-28 18:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.13843759894371033 norm:0.0026634640526026487 max memory_allocated 22566.91943359375 
[2025-02-28 18:19:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.13761745393276215 norm:0.0022053373977541924 max memory_allocated 22566.91943359375 
[2025-02-28 18:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.13732783496379852 norm:0.0018688637064769864 max memory_allocated 22566.91943359375 
[2025-02-28 18:20:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.137140691280365 norm:0.0017018126090988517 max memory_allocated 22566.91943359375 
[2025-02-28 18:21:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.13716663420200348 norm:0.0017977042589336634 max memory_allocated 22566.91943359375 
[2025-02-28 18:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.13703706860542297 norm:0.001657612156122923 max memory_allocated 22566.91943359375 
[2025-02-28 18:22:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.13695122301578522 norm:0.0016452737618237734 max memory_allocated 22566.91943359375 
[2025-02-28 18:22:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.13700824975967407 norm:0.00142157101072371 max memory_allocated 22566.91943359375 
[2025-02-28 18:23:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.1368911862373352 norm:0.0015726888086646795 max memory_allocated 22566.91943359375 
[2025-02-28 18:23:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.13687220215797424 norm:0.0013811730314046144 max memory_allocated 22566.91943359375 
[2025-02-28 18:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.13680191338062286 norm:0.0014307834208011627 max memory_allocated 22566.91943359375 
[2025-02-28 18:24:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.1367286741733551 norm:0.0013818808365613222 max memory_allocated 22566.91943359375 
[2025-02-28 18:25:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.1367298662662506 norm:0.0013268955517560244 max memory_allocated 22566.91943359375 
[2025-02-28 18:25:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.136656254529953 norm:0.0013186781434342265 max memory_allocated 22566.91943359375 
[2025-02-28 18:26:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.1366976499557495 norm:0.0012944713234901428 max memory_allocated 22566.91943359375 
[2025-02-28 18:27:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.1366768479347229 norm:0.0013475175946950912 max memory_allocated 22566.91943359375 
[2025-02-28 18:27:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.1366819143295288 norm:0.0012795451330021024 max memory_allocated 22566.91943359375 
[2025-02-28 18:27:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 18:27:42 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:28:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.17861664295196533 norm:0.01006025355309248 max memory_allocated 22567.09130859375 
[2025-02-28 18:28:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.17042484879493713 norm:0.007495260797441006 max memory_allocated 22567.09130859375 
[2025-02-28 18:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.16533786058425903 norm:0.005124950315803289 max memory_allocated 22567.09130859375 
[2025-02-28 18:29:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.16240769624710083 norm:0.00406729057431221 max memory_allocated 22567.09130859375 
[2025-02-28 18:30:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.1612609177827835 norm:0.00345505285076797 max memory_allocated 22567.09130859375 
[2025-02-28 18:30:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.16077765822410583 norm:0.0029557766392827034 max memory_allocated 22567.09130859375 
[2025-02-28 18:31:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.16050750017166138 norm:0.0025450775865465403 max memory_allocated 22567.09130859375 
[2025-02-28 18:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.16030901670455933 norm:0.002200044458732009 max memory_allocated 22567.09130859375 
[2025-02-28 18:32:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.16023138165473938 norm:0.0020631863735616207 max memory_allocated 22567.09130859375 
[2025-02-28 18:32:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.16014227271080017 norm:0.002015242353081703 max memory_allocated 22567.09130859375 
[2025-02-28 18:33:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.16009077429771423 norm:0.0018984287744387984 max memory_allocated 22567.09130859375 
[2025-02-28 18:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.15999792516231537 norm:0.0017874506302177906 max memory_allocated 22567.09130859375 
[2025-02-28 18:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.15994302928447723 norm:0.0018830201588571072 max memory_allocated 22567.09130859375 
[2025-02-28 18:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.15996921062469482 norm:0.001795814954675734 max memory_allocated 22567.09130859375 
[2025-02-28 18:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.16000883281230927 norm:0.0020260117016732693 max memory_allocated 22567.09130859375 
[2025-02-28 18:35:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.15994544327259064 norm:0.0016514667076990008 max memory_allocated 22567.09130859375 
[2025-02-28 18:36:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.15989767014980316 norm:0.0018132856348529458 max memory_allocated 22567.09130859375 
[2025-02-28 18:36:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.1598525047302246 norm:0.0016259638359770179 max memory_allocated 22567.09130859375 
[2025-02-28 18:37:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.15985609591007233 norm:0.0016900686314329505 max memory_allocated 22567.09130859375 
[2025-02-28 18:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.15989777445793152 norm:0.0015933024697005749 max memory_allocated 22567.09130859375 
[2025-02-28 18:38:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 18:38:10 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.017856240272522 norm:0.14494706690311432 max memory_allocated 22567.26318359375 
[2025-02-28 18:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.7044588327407837 norm:0.12887224555015564 max memory_allocated 22567.26318359375 
[2025-02-28 18:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.4229784309864044 norm:0.059318091720342636 max memory_allocated 22567.26318359375 
[2025-02-28 18:40:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.3378610908985138 norm:0.03828522562980652 max memory_allocated 22567.26318359375 
[2025-02-28 18:40:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.3028418719768524 norm:0.03684883564710617 max memory_allocated 22567.26318359375 
[2025-02-28 18:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.27672040462493896 norm:0.03533700481057167 max memory_allocated 22567.26318359375 
[2025-02-28 18:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.2651190459728241 norm:0.034541551023721695 max memory_allocated 22567.26318359375 
[2025-02-28 18:42:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.25354570150375366 norm:0.03599607199430466 max memory_allocated 22567.26318359375 
[2025-02-28 18:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.24610954523086548 norm:0.033960841596126556 max memory_allocated 22567.26318359375 
[2025-02-28 18:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.2404991090297699 norm:0.027941852807998657 max memory_allocated 22567.26318359375 
[2025-02-28 18:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.23711109161376953 norm:0.026748519390821457 max memory_allocated 22567.26318359375 
[2025-02-28 18:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.233741894364357 norm:0.024890802800655365 max memory_allocated 22567.26318359375 
[2025-02-28 18:44:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.23151229321956635 norm:0.02379401959478855 max memory_allocated 22567.26318359375 
[2025-02-28 18:45:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.2293187379837036 norm:0.021036872640252113 max memory_allocated 22567.26318359375 
[2025-02-28 18:45:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.22805599868297577 norm:0.01969843916594982 max memory_allocated 22567.26318359375 
[2025-02-28 18:46:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.22767631709575653 norm:0.01969781704246998 max memory_allocated 22567.26318359375 
[2025-02-28 18:46:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.2270003855228424 norm:0.01889445260167122 max memory_allocated 22567.26318359375 
[2025-02-28 18:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.22707252204418182 norm:0.01933254487812519 max memory_allocated 22567.26318359375 
[2025-02-28 18:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.22713668644428253 norm:0.02003057301044464 max memory_allocated 22567.26318359375 
[2025-02-28 18:48:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.22646242380142212 norm:0.018865887075662613 max memory_allocated 22567.26318359375 
[2025-02-28 18:48:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 18:48:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:49:09 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.4657270312309265 norm:0.032290369272232056 max memory_allocated 22567.43505859375 
[2025-02-28 18:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.43576866388320923 norm:0.02323785610496998 max memory_allocated 22567.43505859375 
[2025-02-28 18:50:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.4186049997806549 norm:0.018843874335289 max memory_allocated 22567.43505859375 
[2025-02-28 18:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.40970319509506226 norm:0.016391560435295105 max memory_allocated 22567.43505859375 
[2025-02-28 18:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.40443286299705505 norm:0.015292758122086525 max memory_allocated 22567.43505859375 
[2025-02-28 18:51:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.40097472071647644 norm:0.014362616464495659 max memory_allocated 22567.43505859375 
[2025-02-28 18:52:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.39827901124954224 norm:0.013795454986393452 max memory_allocated 22567.43505859375 
[2025-02-28 18:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.3959173858165741 norm:0.013018959201872349 max memory_allocated 22567.43505859375 
[2025-02-28 18:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.3951735496520996 norm:0.014624129980802536 max memory_allocated 22567.43505859375 
[2025-02-28 18:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.39491698145866394 norm:0.014709590934216976 max memory_allocated 22567.43505859375 
[2025-02-28 18:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.3941379487514496 norm:0.014252384193241596 max memory_allocated 22567.43505859375 
[2025-02-28 18:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.39383435249328613 norm:0.013955479487776756 max memory_allocated 22567.43505859375 
[2025-02-28 18:55:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.3934342563152313 norm:0.01442697923630476 max memory_allocated 22567.43505859375 
[2025-02-28 18:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.39271172881126404 norm:0.01443476788699627 max memory_allocated 22567.43505859375 
[2025-02-28 18:56:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.39279183745384216 norm:0.014944436028599739 max memory_allocated 22567.43505859375 
[2025-02-28 18:56:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.3919064402580261 norm:0.013453434221446514 max memory_allocated 22567.43505859375 
[2025-02-28 18:57:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.39102816581726074 norm:0.012985967099666595 max memory_allocated 22567.43505859375 
[2025-02-28 18:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.3908540606498718 norm:0.012958550825715065 max memory_allocated 22567.43505859375 
[2025-02-28 18:58:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.39056068658828735 norm:0.012599838897585869 max memory_allocated 22567.43505859375 
[2025-02-28 18:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.39042505621910095 norm:0.011949214152991772 max memory_allocated 22567.43505859375 
[2025-02-28 18:59:04 root] (main_calib_config2.py 380): INFO 20039.176911592484
[2025-02-28 18:59:08 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 19:00:11 root] (main_calib_config2.py 159): INFO wikitext2 : 5.680052757263184
[2025-02-28 19:00:11 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 19:01:49 root] (main_calib_config2.py 159): INFO c4 : 7.255640029907227
[2025-02-28 20:42:21 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.680052757263184, 'c4': 7.255640029907227, 'results': {'arc_challenge': {'acc': 0.39419795221843, 'acc_stderr': 0.014280522667467325, 'acc_norm': 0.3993174061433447, 'acc_norm_stderr': 0.0143120945579467}, 'piqa': {'acc': 0.7752992383025027, 'acc_stderr': 0.009738282586548377, 'acc_norm': 0.7606093579978237, 'acc_norm_stderr': 0.009955884250291688}, 'hellaswag': {'acc': 0.5552678749253137, 'acc_stderr': 0.004959204773046209, 'acc_norm': 0.7142003584943238, 'acc_norm_stderr': 0.00450871089105385}, 'boolq': {'acc': 0.690519877675841, 'acc_stderr': 0.008085316258869081}, 'winogrande': {'acc': 0.6614048934490924, 'acc_stderr': 0.013300169865842412}, 'arc_easy': {'acc': 0.6851851851851852, 'acc_stderr': 0.009530150430975609, 'acc_norm': 0.5311447811447811, 'acc_norm_stderr': 0.010239860250021748}}, 'versions': {'arc_challenge': 0, 'piqa': 0, 'hellaswag': 0, 'boolq': 1, 'winogrande': 0, 'arc_easy': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
