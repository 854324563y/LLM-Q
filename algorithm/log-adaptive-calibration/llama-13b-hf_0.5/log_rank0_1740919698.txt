[2025-03-02 12:48:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.5', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.5.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.5.pkl
[2025-03-02 12:52:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.0220230370759964 norm:0.015335422940552235 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.012476049363613129 norm:0.007263189647346735 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.008783593773841858 norm:0.004529530648142099 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.007717353291809559 norm:0.003639868227764964 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.007326094899326563 norm:0.0030803075060248375 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.007031144108623266 norm:0.002449763473123312 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.006785514764487743 norm:0.0021302239038050175 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.006640567444264889 norm:0.0018899624701589346 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0066292183473706245 norm:0.001819777418859303 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.006484813988208771 norm:0.0015728131402283907 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0064360154792666435 norm:0.0014765853993594646 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.00637104082852602 norm:0.001338261878117919 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.006324784830212593 norm:0.0012286806013435125 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.006278120446950197 norm:0.0011824544053524733 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.006253086496144533 norm:0.0013407613150775433 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.006237030029296875 norm:0.0010546809062361717 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.006213541608303785 norm:0.001034511486068368 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0061905840411782265 norm:0.000980457989498973 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0061865272000432014 norm:0.0009338509989902377 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:01 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.006181520409882069 norm:0.0009357755770906806 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:20 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.0401112399995327 norm:0.019028080627322197 max memory_allocated 29268.02001953125 
[2025-03-02 13:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.024374784901738167 norm:0.009337752126157284 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.018892070278525352 norm:0.006283302325755358 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.01718101277947426 norm:0.005152848083525896 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.01653699390590191 norm:0.00452897883951664 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.0162004753947258 norm:0.004128037486225367 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.015958447009325027 norm:0.0037677979562431574 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.015764370560646057 norm:0.0033820397220551968 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.015569532290101051 norm:0.003100525587797165 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.015394965186715126 norm:0.002845133189111948 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.015250319615006447 norm:0.0026070857420563698 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.01512987818568945 norm:0.002378836739808321 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.015032537281513214 norm:0.002164986915886402 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.014956537634134293 norm:0.001956505235284567 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.014863364398479462 norm:0.0017522050766274333 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.014805453829467297 norm:0.001584058627486229 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.014768458902835846 norm:0.0014833281747996807 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.014780272729694843 norm:0.0015088022919371724 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.014784990809857845 norm:0.0015009406488388777 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.014767629094421864 norm:0.0015108949737623334 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.056256040930747986 norm:0.011241115629673004 max memory_allocated 29268.02001953125 
[2025-03-02 13:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.04092063009738922 norm:0.007429858669638634 max memory_allocated 29268.02001953125 
[2025-03-02 13:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.03484831005334854 norm:0.00619993731379509 max memory_allocated 29268.02001953125 
[2025-03-02 13:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.0320003405213356 norm:0.007941903546452522 max memory_allocated 29268.02001953125 
[2025-03-02 13:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.03058565780520439 norm:0.006213763263076544 max memory_allocated 29268.02001953125 
[2025-03-02 13:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.029363708570599556 norm:0.005652901716530323 max memory_allocated 29268.02001953125 
[2025-03-02 13:31:50 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.028649695217609406 norm:0.005399515852332115 max memory_allocated 29268.02001953125 
[2025-03-02 13:32:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.02797912433743477 norm:0.00519959069788456 max memory_allocated 29268.02001953125 
[2025-03-02 13:33:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.027516230940818787 norm:0.005122964270412922 max memory_allocated 29268.02001953125 
[2025-03-02 13:34:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.02714887075126171 norm:0.004876010585576296 max memory_allocated 29268.02001953125 
[2025-03-02 13:35:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.02695196494460106 norm:0.004735539201647043 max memory_allocated 29268.02001953125 
[2025-03-02 13:35:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.026900947093963623 norm:0.004519501235336065 max memory_allocated 29268.02001953125 
[2025-03-02 13:36:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.026714766398072243 norm:0.004555697552859783 max memory_allocated 29268.02001953125 
[2025-03-02 13:37:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.026739874854683876 norm:0.004447394981980324 max memory_allocated 29268.02001953125 
[2025-03-02 13:38:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.026496969163417816 norm:0.004371903371065855 max memory_allocated 29268.02001953125 
[2025-03-02 13:39:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.026591673493385315 norm:0.004350130911916494 max memory_allocated 29268.02001953125 
[2025-03-02 13:40:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.026628969237208366 norm:0.004175439476966858 max memory_allocated 29268.02001953125 
[2025-03-02 13:40:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.026532210409641266 norm:0.004104455932974815 max memory_allocated 29268.02001953125 
[2025-03-02 13:41:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.026682185009121895 norm:0.0040250616148114204 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.026393719017505646 norm:0.0038260812871158123 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:43:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.04565480723977089 norm:0.003937702625989914 max memory_allocated 29268.43798828125 
[2025-03-02 13:44:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.0348079688847065 norm:0.0015297208447009325 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.029926206916570663 norm:0.0007752585806883872 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.028301356360316277 norm:0.00046993896830827 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.027494637295603752 norm:0.0003030253283213824 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.026949472725391388 norm:0.00022898480528965592 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.026596056297421455 norm:0.00022428925149142742 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.026382487267255783 norm:0.00020784941443707794 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.02626323699951172 norm:0.00019758380949497223 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.026223421096801758 norm:0.0001963380491361022 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.02616078406572342 norm:0.0001806546642910689 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:40 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.026117464527487755 norm:0.00018073148385155946 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.026109283789992332 norm:0.0001773004187270999 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.026122253388166428 norm:0.0001773903495632112 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.026086237281560898 norm:0.00016071311256382614 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.026076870039105415 norm:0.0001815226423786953 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.026046032086014748 norm:0.00017403443052899092 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.02604307420551777 norm:0.0001785596105037257 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.02603364922106266 norm:0.00017870058945845813 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.02602318301796913 norm:0.0001888745609903708 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:00:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.06504382938146591 norm:0.00741869630292058 max memory_allocated 29268.62548828125 
[2025-03-02 14:01:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.049254074692726135 norm:0.002122273202985525 max memory_allocated 29268.62548828125 
[2025-03-02 14:02:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.04206285998225212 norm:0.001166031463071704 max memory_allocated 29268.62548828125 
[2025-03-02 14:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.039694491773843765 norm:0.0008828446734696627 max memory_allocated 29268.62548828125 
[2025-03-02 14:03:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.0383971631526947 norm:0.000649068271741271 max memory_allocated 29268.62548828125 
[2025-03-02 14:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.03768496960401535 norm:0.0005699783796444535 max memory_allocated 29268.62548828125 
[2025-03-02 14:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.03722754120826721 norm:0.0004715621180366725 max memory_allocated 29268.62548828125 
[2025-03-02 14:06:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.03696955740451813 norm:0.0004267065378371626 max memory_allocated 29268.62548828125 
[2025-03-02 14:06:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.03683105483651161 norm:0.00039654929423704743 max memory_allocated 29268.62548828125 
[2025-03-02 14:07:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.036690853536129 norm:0.00036723416997119784 max memory_allocated 29268.62548828125 
[2025-03-02 14:08:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.03658943995833397 norm:0.000355600961484015 max memory_allocated 29268.62548828125 
[2025-03-02 14:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.03653024137020111 norm:0.0003489250084385276 max memory_allocated 29268.62548828125 
[2025-03-02 14:10:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.03646952658891678 norm:0.00032942634425126016 max memory_allocated 29268.62548828125 
[2025-03-02 14:11:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.036434486508369446 norm:0.00032203897717408836 max memory_allocated 29268.62548828125 
[2025-03-02 14:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.0363987535238266 norm:0.0003104011411778629 max memory_allocated 29268.62548828125 
[2025-03-02 14:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.036392372101545334 norm:0.00031707523157820106 max memory_allocated 29268.62548828125 
[2025-03-02 14:13:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.036371488124132156 norm:0.000318527891067788 max memory_allocated 29268.62548828125 
[2025-03-02 14:14:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.03635312616825104 norm:0.0003185815876349807 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.0363476388156414 norm:0.0003310882020741701 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.036320146173238754 norm:0.000315584969939664 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.07409317791461945 norm:0.005731210112571716 max memory_allocated 29268.81298828125 
[2025-03-02 14:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.055852100253105164 norm:0.0016774764517322183 max memory_allocated 29268.81298828125 
[2025-03-02 14:18:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.04772809147834778 norm:0.0008955160155892372 max memory_allocated 29268.81298828125 
[2025-03-02 14:19:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.04493894428014755 norm:0.0005879136151634157 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.043475471436977386 norm:0.00045225376379676163 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.04260498285293579 norm:0.00037876644637435675 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.04209926351904869 norm:0.0003258095821365714 max memory_allocated 29268.81298828125 
[2025-03-02 14:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.04184678569436073 norm:0.0002873312041629106 max memory_allocated 29268.81298828125 
[2025-03-02 14:23:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.0416732057929039 norm:0.0002759316994342953 max memory_allocated 29268.81298828125 
[2025-03-02 14:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.04155682399868965 norm:0.00027353272889740765 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.041456758975982666 norm:0.00025310038472525775 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.04135444760322571 norm:0.00023229426005855203 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.041294872760772705 norm:0.00024657478206790984 max memory_allocated 29268.81298828125 
[2025-03-02 14:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.041232816874980927 norm:0.00023853944730944932 max memory_allocated 29268.81298828125 
[2025-03-02 14:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.04118386283516884 norm:0.00023776559100952 max memory_allocated 29268.81298828125 
[2025-03-02 14:29:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.041156619787216187 norm:0.00025499501498416066 max memory_allocated 29268.81298828125 
[2025-03-02 14:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.04106000065803528 norm:0.0002206691715400666 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.04101961851119995 norm:0.0002259545581182465 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.04100770130753517 norm:0.00023245251213666052 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.041025903075933456 norm:0.00023802345094736665 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.0868963748216629 norm:0.0031571241561323404 max memory_allocated 29269.00048828125 
[2025-03-02 14:34:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.06979899853467941 norm:0.0017237234860658646 max memory_allocated 29269.00048828125 
[2025-03-02 14:35:24 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.060324810445308685 norm:0.0013757417909801006 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.05670533329248428 norm:0.0011245066998526454 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.05601924657821655 norm:0.001132881734520197 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:52 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.054886892437934875 norm:0.0006232567247934639 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.054144926369190216 norm:0.0005346059915609658 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.053640637546777725 norm:0.0005115384701639414 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.05340226739645004 norm:0.0005341294454410672 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.05268094316124916 norm:0.0005298497853800654 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.052415937185287476 norm:0.0005244655185379088 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.0522775799036026 norm:0.00045258126920089126 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.05225905030965805 norm:0.0005337180919013917 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.05213061720132828 norm:0.0004395701107569039 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.051997147500514984 norm:0.00041432888247072697 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.05197254940867424 norm:0.0004766205092892051 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.05201129615306854 norm:0.0006070191157050431 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.05195073038339615 norm:0.0004565049894154072 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.051973529160022736 norm:0.0004819566383957863 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.05187525227665901 norm:0.00048055945080704987 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.08310329169034958 norm:0.001908247941173613 max memory_allocated 29269.18798828125 
[2025-03-02 14:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.0691632330417633 norm:0.0009222676162607968 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.06182026490569115 norm:0.0005258576711639762 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.059161148965358734 norm:0.0003542673075571656 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.05787438526749611 norm:0.0002852453326340765 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.05713215470314026 norm:0.00025611999444663525 max memory_allocated 29269.18798828125 
[2025-03-02 14:55:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.05672534182667732 norm:0.00024309995933435857 max memory_allocated 29269.18798828125 
[2025-03-02 14:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.05648299306631088 norm:0.00024373488849960268 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.056352660059928894 norm:0.00024755598860792816 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.056199394166469574 norm:0.00023218333080876619 max memory_allocated 29269.18798828125 
[2025-03-02 14:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.056083232164382935 norm:0.00022987222473602742 max memory_allocated 29269.18798828125 
[2025-03-02 14:59:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.05602530390024185 norm:0.00023402078659273684 max memory_allocated 29269.18798828125 
[2025-03-02 15:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.05596519634127617 norm:0.00023149832850322127 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.05596037209033966 norm:0.00023230494116432965 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.05593102052807808 norm:0.00023085580323822796 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.055907636880874634 norm:0.00022987027477938682 max memory_allocated 29269.18798828125 
[2025-03-02 15:03:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.05589224398136139 norm:0.0002281565248267725 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.055858172476291656 norm:0.0002235088322777301 max memory_allocated 29269.18798828125 
[2025-03-02 15:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.05585277080535889 norm:0.00022447400260716677 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.055826809257268906 norm:0.00022493003052659333 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.09183616936206818 norm:0.002869175747036934 max memory_allocated 29269.37548828125 
[2025-03-02 15:08:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.07613565027713776 norm:0.0011489070020616055 max memory_allocated 29269.37548828125 
[2025-03-02 15:08:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.06835944205522537 norm:0.0006322472472675145 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.06538175791501999 norm:0.00043025429476983845 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.06387810409069061 norm:0.0003410222998354584 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.06307686120271683 norm:0.00030762076494283974 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.06258081644773483 norm:0.0002815004554577172 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.06226678192615509 norm:0.0002572279190644622 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.062060847878456116 norm:0.00024419481633231044 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.061931122094392776 norm:0.00023817221517674625 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.061845287680625916 norm:0.00023296666040550917 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.06177463009953499 norm:0.00022725059534423053 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.061694517731666565 norm:0.00022404597257263958 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.0616527758538723 norm:0.00022466626251116395 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.06161046773195267 norm:0.00022574051399715245 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.061624810099601746 norm:0.0002271444973303005 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.06158144026994705 norm:0.000228539778618142 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.06155264377593994 norm:0.00022945237287785858 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.061507076025009155 norm:0.0002261124027427286 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.061474721878767014 norm:0.0002224232885055244 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.09203653782606125 norm:0.0020324033685028553 max memory_allocated 29269.56298828125 
[2025-03-02 15:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.0797933042049408 norm:0.0008193700341507792 max memory_allocated 29269.56298828125 
[2025-03-02 15:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.0728813111782074 norm:0.0004688092158176005 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.07035388052463531 norm:0.00033060446730814874 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.06916388124227524 norm:0.00027209758991375566 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.06848224252462387 norm:0.00024626869708299637 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.06809332221746445 norm:0.000233215992921032 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.06784664839506149 norm:0.00022170221200212836 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.06769704818725586 norm:0.00021277549967635423 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.06758127361536026 norm:0.00021009656484238803 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.06751345098018646 norm:0.0002048011519946158 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.06746453046798706 norm:0.00020107555610593408 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.06739985197782516 norm:0.00019947555847465992 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:32 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.06737896800041199 norm:0.00020253351249266416 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.06735949963331223 norm:0.0002020071551669389 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.0673353374004364 norm:0.00020191448857076466 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.067307248711586 norm:0.00019961176440119743 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.06729704886674881 norm:0.00019826009520329535 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.06727240234613419 norm:0.00020018871873617172 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.06726805120706558 norm:0.0001985346752917394 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:40:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.09587360173463821 norm:0.0016653714701533318 max memory_allocated 29269.75048828125 
[2025-03-02 15:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.08460376411676407 norm:0.0006813342915847898 max memory_allocated 29269.75048828125 
[2025-03-02 15:42:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.07806864380836487 norm:0.000388235755963251 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.07568667083978653 norm:0.000282669992884621 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.07455410808324814 norm:0.00024109118385240436 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.07391668856143951 norm:0.0002186773344874382 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.07356036454439163 norm:0.0002047371381195262 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.073341503739357 norm:0.0001949964207597077 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.07320474833250046 norm:0.00018665245443116874 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.0731465220451355 norm:0.00018353082123212516 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.0730886459350586 norm:0.000182578427484259 max memory_allocated 29269.75048828125 
[2025-03-02 15:49:36 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.07304061204195023 norm:0.0001813484268495813 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.07300500571727753 norm:0.0001805765350582078 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.07297147065401077 norm:0.00017878678045235574 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.07294009625911713 norm:0.00017806535470299423 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.07291878014802933 norm:0.0001787186338333413 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.07289621233940125 norm:0.0001775751734385267 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.07288050651550293 norm:0.0001784364867489785 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.07287556678056717 norm:0.00017820142966229469 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.07288560271263123 norm:0.00017907664005178958 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:57:18 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.10347946733236313 norm:0.0015116301365196705 max memory_allocated 29269.93798828125 
[2025-03-02 15:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.09218677878379822 norm:0.0007069325656630099 max memory_allocated 29269.93798828125 
[2025-03-02 15:58:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.08491411805152893 norm:0.0003960189060308039 max memory_allocated 29269.93798828125 
[2025-03-02 15:59:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.08237115293741226 norm:0.0002818272914737463 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.08123183995485306 norm:0.0002307796967215836 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.08058364689350128 norm:0.00020994231454096735 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.08021345734596252 norm:0.00019892520504072309 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.08001333475112915 norm:0.0001931314036482945 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.07988926023244858 norm:0.0001885858946479857 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.0797913521528244 norm:0.00018538441509008408 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.07972539961338043 norm:0.00018432871729601175 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.07967779785394669 norm:0.00018287095008417964 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.07962353527545929 norm:0.0001820108009269461 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.07958469539880753 norm:0.00018176529556512833 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.07956445962190628 norm:0.00018173587159253657 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.07952072471380234 norm:0.00018014000670518726 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.07950108498334885 norm:0.00017892442701850086 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.07948053628206253 norm:0.0001794947893358767 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.07946529239416122 norm:0.00017875945195555687 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.07943779975175858 norm:0.00017841692897491157 max memory_allocated 29269.93798828125 
[2025-03-02 16:13:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:14:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.10994832217693329 norm:0.001359013607725501 max memory_allocated 29270.12548828125 
[2025-03-02 16:14:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.09850584715604782 norm:0.0006451008375734091 max memory_allocated 29270.12548828125 
[2025-03-02 16:15:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.09092909842729568 norm:0.0003934937412850559 max memory_allocated 29270.12548828125 
[2025-03-02 16:16:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.08827340602874756 norm:0.000292695767711848 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.08712463080883026 norm:0.0002581329317763448 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:07 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.0864330530166626 norm:0.00024086165649350733 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.08604796230792999 norm:0.0002318906190339476 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.08582598716020584 norm:0.00022755320242140442 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.08568746596574783 norm:0.0002256635925732553 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.08558595180511475 norm:0.00022451154654845595 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.08551471680402756 norm:0.00022177047503646463 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.08542515337467194 norm:0.0002211043902207166 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.08539393544197083 norm:0.00022082505165599287 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.08536402881145477 norm:0.00022308799088932574 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.0853361114859581 norm:0.00021673338778782636 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.08531191945075989 norm:0.00021615962032228708 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.08530822396278381 norm:0.00021597712475340813 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.08529084175825119 norm:0.00021599129831884056 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.08528774231672287 norm:0.00021727329294662923 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.08526590466499329 norm:0.00021674708114005625 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:30:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.10556774586439133 norm:0.0017737242160364985 max memory_allocated 29270.31298828125 
[2025-03-02 16:31:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.09605017304420471 norm:0.0008334702579304576 max memory_allocated 29270.31298828125 
[2025-03-02 16:32:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.08992381393909454 norm:0.0004811562248505652 max memory_allocated 29270.31298828125 
[2025-03-02 16:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.08781114965677261 norm:0.00032933178590610623 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.08658606559038162 norm:0.00025332573568448424 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.08584177494049072 norm:0.0002096101234201342 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.08547549694776535 norm:0.0001865311642177403 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.085272416472435 norm:0.00017355376621708274 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.08512614667415619 norm:0.00016636215150356293 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.08504059165716171 norm:0.00016173477342817932 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.08495353162288666 norm:0.000157996139023453 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.08491239696741104 norm:0.00015520893794018775 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.08487019687891006 norm:0.00015357967640738934 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.08484982699155807 norm:0.0001517538767075166 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.08481762558221817 norm:0.00015165950753726065 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.08478548377752304 norm:0.00015070175868459046 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.08476542681455612 norm:0.00015060130681376904 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:40 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.08474631607532501 norm:0.0001503397070337087 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.08474101126194 norm:0.0001501121441833675 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.0847381204366684 norm:0.00015037365665193647 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.11215671896934509 norm:0.0028209856245666742 max memory_allocated 29270.50048828125 
[2025-03-02 16:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.10102617740631104 norm:0.001290331594645977 max memory_allocated 29270.50048828125 
[2025-03-02 16:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.09383300691843033 norm:0.0007207050221040845 max memory_allocated 29270.50048828125 
[2025-03-02 16:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.09160207211971283 norm:0.00047185964649543166 max memory_allocated 29270.50048828125 
[2025-03-02 16:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.0903884768486023 norm:0.0003417685511521995 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.0896582379937172 norm:0.00027316855266690254 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.0892726480960846 norm:0.00023077926016412675 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.0890568271279335 norm:0.00021053344244137406 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.08891041576862335 norm:0.00019599965889938176 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.08878382295370102 norm:0.0001877492031781003 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.08870893716812134 norm:0.00018277978233527392 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.08863136917352676 norm:0.00017713007400743663 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.08857911825180054 norm:0.0001729312352836132 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.08852498978376389 norm:0.0001686810574028641 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.08849464356899261 norm:0.00016954629973042756 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.08846267312765121 norm:0.00016739984857849777 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.08845111727714539 norm:0.00016697820683475584 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.08844724297523499 norm:0.00016763345047365874 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.08843130618333817 norm:0.00016749213682487607 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.08842344582080841 norm:0.00016787085041869432 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:04:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.11258585005998611 norm:0.00158715492580086 max memory_allocated 29270.68798828125 
[2025-03-02 17:04:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.10412696748971939 norm:0.00063973298529163 max memory_allocated 29270.68798828125 
[2025-03-02 17:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.09864525496959686 norm:0.00038652855437248945 max memory_allocated 29270.68798828125 
[2025-03-02 17:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.09669981151819229 norm:0.0002817253698594868 max memory_allocated 29270.68798828125 
[2025-03-02 17:07:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.09543506801128387 norm:0.00022760973661206663 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.09467598795890808 norm:0.00019894534489139915 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.09429758787155151 norm:0.00018106559582520276 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.09407711029052734 norm:0.00016895993030630052 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.09396287053823471 norm:0.0001592714397702366 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.09385205060243607 norm:0.00015442355652339756 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.09379668533802032 norm:0.0001518811477581039 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.09372659027576447 norm:0.00014846805424895138 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.09367101639509201 norm:0.0001473075826652348 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.09361347556114197 norm:0.00014723623462487012 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.09359552711248398 norm:0.00014577418914996088 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.09356552362442017 norm:0.00014540489064529538 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.09354850649833679 norm:0.00014593690866604447 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.09355171024799347 norm:0.000148463761433959 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.09353409707546234 norm:0.00014416025078389794 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.09351733326911926 norm:0.00014287840167526156 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.11850345879793167 norm:0.002680808538571 max memory_allocated 29270.87548828125 
[2025-03-02 17:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.1101810485124588 norm:0.0012188138207420707 max memory_allocated 29270.87548828125 
[2025-03-02 17:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.10451657325029373 norm:0.000710067106410861 max memory_allocated 29270.87548828125 
[2025-03-02 17:23:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.1025664359331131 norm:0.0004802299663424492 max memory_allocated 29270.87548828125 
[2025-03-02 17:24:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.10138693451881409 norm:0.00035198574187234044 max memory_allocated 29270.87548828125 
[2025-03-02 17:24:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.10072531551122665 norm:0.0002779582573566586 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.10039368271827698 norm:0.00023226760094985366 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.10020768642425537 norm:0.00020346205565147102 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.10009538382291794 norm:0.00018760879174806178 max memory_allocated 29270.87548828125 
[2025-03-02 17:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.10003050416707993 norm:0.00017608780763112009 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.09993850439786911 norm:0.0001687520561972633 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.09987740218639374 norm:0.0001631431223358959 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.0998302772641182 norm:0.00015918716962914914 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.09980106353759766 norm:0.00015737982175778598 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.09977449476718903 norm:0.00015516769781243056 max memory_allocated 29270.87548828125 
[2025-03-02 17:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.09975002706050873 norm:0.00015257022459991276 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.09971414506435394 norm:0.00015087073552422225 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.09969359636306763 norm:0.00014971195196267217 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.09968425333499908 norm:0.0001495261094532907 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.09968088567256927 norm:0.00015009590424597263 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:37:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.1285041868686676 norm:0.0036373946350067854 max memory_allocated 29271.06298828125 
[2025-03-02 17:38:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.11880018562078476 norm:0.0015565147623419762 max memory_allocated 29271.06298828125 
[2025-03-02 17:39:13 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.1122303381562233 norm:0.0008658434962853789 max memory_allocated 29271.06298828125 
[2025-03-02 17:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.1100231260061264 norm:0.0005703934584744275 max memory_allocated 29271.06298828125 
[2025-03-02 17:40:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.10863550007343292 norm:0.0004120779922232032 max memory_allocated 29271.06298828125 
[2025-03-02 17:41:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.10788924247026443 norm:0.00031943240901455283 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.10754042118787766 norm:0.00026309496024623513 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.10735200345516205 norm:0.00022716214880347252 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.10722418874502182 norm:0.00020288967061787844 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.10710897296667099 norm:0.00018632446881383657 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.1070183515548706 norm:0.0001759044680511579 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.10694363713264465 norm:0.00016881281044334173 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.10689343512058258 norm:0.00016339527792297304 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.10685771703720093 norm:0.00016025285003706813 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.10680919885635376 norm:0.0001570471649756655 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.10678772628307343 norm:0.00015455721586477011 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.10675706714391708 norm:0.00015324279956985265 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.10673805326223373 norm:0.0001518500503152609 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.10670711100101471 norm:0.0001514189934823662 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.10669898986816406 norm:0.00015160749899223447 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.14030760526657104 norm:0.0032344209030270576 max memory_allocated 29271.25048828125 
[2025-03-02 17:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.129956915974617 norm:0.001267366809770465 max memory_allocated 29271.25048828125 
[2025-03-02 17:55:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.12300915271043777 norm:0.000680072174873203 max memory_allocated 29271.25048828125 
[2025-03-02 17:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.12075541913509369 norm:0.0004475132445804775 max memory_allocated 29271.25048828125 
[2025-03-02 17:57:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.11940547078847885 norm:0.00033068485208787024 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.11869993805885315 norm:0.0002666981308721006 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.11835091561079025 norm:0.00023005364346317947 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.11813990026712418 norm:0.0002086780295940116 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.11802123486995697 norm:0.00019475443696137518 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.11788012832403183 norm:0.00018409865151625127 max memory_allocated 29271.25048828125 
[2025-03-02 18:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.1177913174033165 norm:0.0001786050561349839 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.11770755797624588 norm:0.00017270699026994407 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.11763295531272888 norm:0.00016923525254242122 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.11757557094097137 norm:0.00016676838276907802 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.11753290146589279 norm:0.00016537244664505124 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.11750084161758423 norm:0.00016326847253367305 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.11747908592224121 norm:0.00016240551485680044 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.11746381968259811 norm:0.00016286331810988486 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.11744076013565063 norm:0.00016331541701219976 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.11741195619106293 norm:0.000162019015988335 max memory_allocated 29271.25048828125 
[2025-03-02 18:10:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.15131202340126038 norm:0.002064244356006384 max memory_allocated 29271.43798828125 
[2025-03-02 18:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.14221791923046112 norm:0.0008756992756389081 max memory_allocated 29271.43798828125 
[2025-03-02 18:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.1351698487997055 norm:0.0005119097768329084 max memory_allocated 29271.43798828125 
[2025-03-02 18:13:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.13291609287261963 norm:0.0003532088012434542 max memory_allocated 29271.43798828125 
[2025-03-02 18:14:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.13158132135868073 norm:0.0002733590954449028 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.13094297051429749 norm:0.00022705290757585317 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.13065338134765625 norm:0.00020078144734725356 max memory_allocated 29271.43798828125 
[2025-03-02 18:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.1304565668106079 norm:0.00018532418471295387 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.1303236484527588 norm:0.00017458490037824959 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.13024136424064636 norm:0.0001708892814349383 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.13014955818653107 norm:0.00016588196740485728 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.1300782710313797 norm:0.00016443499771412462 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.13002362847328186 norm:0.00016045186202973127 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.12995998561382294 norm:0.00015899156278464943 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.12992645800113678 norm:0.00015829229960218072 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.12988071143627167 norm:0.00015596092271152884 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.12985773384571075 norm:0.00015717890346422791 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.1298350989818573 norm:0.0001548274012748152 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.12981754541397095 norm:0.00015435487148351967 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.12979255616664886 norm:0.00015302894462365657 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.16699156165122986 norm:0.0018091975944116712 max memory_allocated 29271.62548828125 
[2025-03-02 18:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.156705841422081 norm:0.0008075230289250612 max memory_allocated 29271.62548828125 
[2025-03-02 18:29:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.1487630009651184 norm:0.00048007493023760617 max memory_allocated 29271.62548828125 
[2025-03-02 18:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.14632238447666168 norm:0.00034385413164272904 max memory_allocated 29271.62548828125 
[2025-03-02 18:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.1449168622493744 norm:0.0002715638547670096 max memory_allocated 29271.62548828125 
[2025-03-02 18:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.14433693885803223 norm:0.00022987235570326447 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.14403988420963287 norm:0.00020737915474455804 max memory_allocated 29271.62548828125 
[2025-03-02 18:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.14384713768959045 norm:0.0001908431586343795 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.14368155598640442 norm:0.00018101566820405424 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.1435355544090271 norm:0.0001725653710309416 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.14343006908893585 norm:0.00016886999947018921 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.14334096014499664 norm:0.00016449899703729898 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.1432613730430603 norm:0.00016184945707209408 max memory_allocated 29271.62548828125 
[2025-03-02 18:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.14321550726890564 norm:0.00016133300960063934 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.14316719770431519 norm:0.00015980492753442377 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.14313194155693054 norm:0.00016034557484090328 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.1431030035018921 norm:0.00015894310490693897 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.14305035769939423 norm:0.00015800641267560422 max memory_allocated 29271.62548828125 
[2025-03-02 18:42:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.14300914108753204 norm:0.00015697053459007293 max memory_allocated 29271.62548828125 
[2025-03-02 18:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.14297793805599213 norm:0.00015628128312528133 max memory_allocated 29271.62548828125 
[2025-03-02 18:43:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:44:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.18963615596294403 norm:0.002330109942704439 max memory_allocated 29271.81298828125 
[2025-03-02 18:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.1772785633802414 norm:0.0011810795404016972 max memory_allocated 29271.81298828125 
[2025-03-02 18:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.16783733665943146 norm:0.0007065664976835251 max memory_allocated 29271.81298828125 
[2025-03-02 18:46:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.1650378406047821 norm:0.0004895234014838934 max memory_allocated 29271.81298828125 
[2025-03-02 18:47:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.1634528636932373 norm:0.0003640936338342726 max memory_allocated 29271.81298828125 
[2025-03-02 18:48:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.16280072927474976 norm:0.00029413457377813756 max memory_allocated 29271.81298828125 
[2025-03-02 18:49:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.1624796837568283 norm:0.00025579187786206603 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.16224226355552673 norm:0.00023063921253196895 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.1620742827653885 norm:0.00021624895452987403 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.16193866729736328 norm:0.0002070570772048086 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.1618516594171524 norm:0.00019891677948180586 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.16173212230205536 norm:0.0001920528884511441 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.16167263686656952 norm:0.0001899910857900977 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.1615971028804779 norm:0.0001869165716925636 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.16151565313339233 norm:0.00018416860257275403 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.16145575046539307 norm:0.00018430656928103417 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.16141973435878754 norm:0.00018290040316060185 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.16136489808559418 norm:0.00018150857067666948 max memory_allocated 29271.81298828125 
[2025-03-02 18:59:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.1613113135099411 norm:0.00018044280295725912 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.16130110621452332 norm:0.00018181664927396923 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.21166053414344788 norm:0.002176172798499465 max memory_allocated 29272.00048828125 
[2025-03-02 19:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.19952040910720825 norm:0.0010689902119338512 max memory_allocated 29272.00048828125 
[2025-03-02 19:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.18972861766815186 norm:0.0006427748594433069 max memory_allocated 29272.00048828125 
[2025-03-02 19:03:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.1868847757577896 norm:0.00046265622950159013 max memory_allocated 29272.00048828125 
[2025-03-02 19:04:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.18537026643753052 norm:0.0003604763187468052 max memory_allocated 29272.00048828125 
[2025-03-02 19:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.18477822840213776 norm:0.0003080772585235536 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.18444491922855377 norm:0.00027898303233087063 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.18418891727924347 norm:0.00025978172197937965 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.1839827448129654 norm:0.0002468931779731065 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.1838330328464508 norm:0.0002384200197411701 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.18370147049427032 norm:0.0002317353500984609 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.1835830807685852 norm:0.00022732712386641651 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.18346434831619263 norm:0.00022377222194336355 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.18334715068340302 norm:0.00022090302081778646 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.18326714634895325 norm:0.00021758204093202949 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.1831996738910675 norm:0.00021720543736591935 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.18313482403755188 norm:0.00021590851247310638 max memory_allocated 29272.00048828125 
[2025-03-02 19:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.18305981159210205 norm:0.00021240154455881566 max memory_allocated 29272.00048828125 
[2025-03-02 19:15:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.18302538990974426 norm:0.00021139784075785428 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.18297043442726135 norm:0.00020928168669342995 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.24021218717098236 norm:0.0025095546152442694 max memory_allocated 29272.18798828125 
[2025-03-02 19:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.22704771161079407 norm:0.0012306495336815715 max memory_allocated 29272.18798828125 
[2025-03-02 19:19:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.21654298901557922 norm:0.0007212709169834852 max memory_allocated 29272.18798828125 
[2025-03-02 19:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.21328853070735931 norm:0.0005100591224618256 max memory_allocated 29272.18798828125 
[2025-03-02 19:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.21165484189987183 norm:0.00039855216164141893 max memory_allocated 29272.18798828125 
[2025-03-02 19:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.21109409630298615 norm:0.0003389737685211003 max memory_allocated 29272.18798828125 
[2025-03-02 19:22:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.21074673533439636 norm:0.000300471147056669 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.2104865312576294 norm:0.00027748834691010416 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.21027369797229767 norm:0.0002645034983288497 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.21007564663887024 norm:0.0002523156290408224 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.20991754531860352 norm:0.00024182297056540847 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.20977935194969177 norm:0.00023771479027345777 max memory_allocated 29272.18798828125 
[2025-03-02 19:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.20967674255371094 norm:0.00023308975505642593 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.2095838189125061 norm:0.00022830833040643483 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.2094857394695282 norm:0.00022278526739683002 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.20939114689826965 norm:0.0002190595114370808 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.20933620631694794 norm:0.0002169419458368793 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.20928075909614563 norm:0.00021468721388373524 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.20923350751399994 norm:0.00021319642837624997 max memory_allocated 29272.18798828125 
[2025-03-02 19:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.20919474959373474 norm:0.00020937593944836408 max memory_allocated 29272.18798828125 
[2025-03-02 19:33:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.26705607771873474 norm:0.0030707281548529863 max memory_allocated 29272.37548828125 
[2025-03-02 19:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.25408482551574707 norm:0.0015161780174821615 max memory_allocated 29272.37548828125 
[2025-03-02 19:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.24330604076385498 norm:0.0009243858512490988 max memory_allocated 29272.37548828125 
[2025-03-02 19:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.2399182766675949 norm:0.0006421078578568995 max memory_allocated 29272.37548828125 
[2025-03-02 19:37:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.23831310868263245 norm:0.00048546941252425313 max memory_allocated 29272.37548828125 
[2025-03-02 19:38:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.23771749436855316 norm:0.00039797931094653904 max memory_allocated 29272.37548828125 
[2025-03-02 19:39:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.23732858896255493 norm:0.0003426798211876303 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.23705999553203583 norm:0.00030884824809618294 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.23685260117053986 norm:0.00028236076468601823 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.23665639758110046 norm:0.0002628955407999456 max memory_allocated 29272.37548828125 
[2025-03-02 19:42:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.2364848256111145 norm:0.0002509640180505812 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.23637655377388 norm:0.00024371914332732558 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.2362709939479828 norm:0.00023810984566807747 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.2361476719379425 norm:0.00023482432879973203 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.23605120182037354 norm:0.00023156237148214132 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.2359519600868225 norm:0.00022779888240620494 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.23588982224464417 norm:0.0002260595210827887 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.23582430183887482 norm:0.00022384733892977238 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.23576338589191437 norm:0.00022190574964042753 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.23570440709590912 norm:0.00021936722623649985 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.29782816767692566 norm:0.0019846693612635136 max memory_allocated 29272.56298828125 
[2025-03-02 19:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.2847414016723633 norm:0.0010373914847150445 max memory_allocated 29272.56298828125 
[2025-03-02 19:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.27318504452705383 norm:0.0006467322236858308 max memory_allocated 29272.56298828125 
[2025-03-02 19:53:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.2698111832141876 norm:0.00047222155262716115 max memory_allocated 29272.56298828125 
[2025-03-02 19:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.26831668615341187 norm:0.0003763752756640315 max memory_allocated 29272.56298828125 
[2025-03-02 19:55:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.26771286129951477 norm:0.00032582206767983735 max memory_allocated 29272.56298828125 
[2025-03-02 19:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.2673411965370178 norm:0.0002956318494398147 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.26706185936927795 norm:0.00027372059412300587 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.2668187916278839 norm:0.0002596766280476004 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.26660850644111633 norm:0.0002482781419530511 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.26644057035446167 norm:0.000244686147198081 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.26627475023269653 norm:0.00024053684319369495 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.2661530375480652 norm:0.00023702133330516517 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.26604145765304565 norm:0.00023254542611539364 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.2659417390823364 norm:0.00023178737319540232 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.26586005091667175 norm:0.00022872273984830827 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.265768826007843 norm:0.00022715229715686291 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.26571667194366455 norm:0.00022366295161191374 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.2656475305557251 norm:0.0002228707744507119 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.2655754089355469 norm:0.00022224007989279926 max memory_allocated 29272.56298828125 
[2025-03-02 20:07:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:08:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.3314412832260132 norm:0.0024854319635778666 max memory_allocated 29272.75048828125 
[2025-03-02 20:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.3172156810760498 norm:0.0010325935436412692 max memory_allocated 29272.75048828125 
[2025-03-02 20:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.3047446012496948 norm:0.0005918046808801591 max memory_allocated 29272.75048828125 
[2025-03-02 20:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.3010764718055725 norm:0.00042188953375443816 max memory_allocated 29272.75048828125 
[2025-03-02 20:11:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.29969391226768494 norm:0.0003401584690436721 max memory_allocated 29272.75048828125 
[2025-03-02 20:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.29914483428001404 norm:0.00029734018607996404 max memory_allocated 29272.75048828125 
[2025-03-02 20:12:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.2988121509552002 norm:0.00027114275144413114 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.29858359694480896 norm:0.00025694293435662985 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.29836857318878174 norm:0.00024575693532824516 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.2981427311897278 norm:0.00023701884492766112 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.29798781871795654 norm:0.00023431699082721025 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.29782259464263916 norm:0.00023010052973404527 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.2976944148540497 norm:0.00022671361512038857 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.2976086437702179 norm:0.0002260072506032884 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.29750856757164 norm:0.00022276390518527478 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.2974063456058502 norm:0.00022150820586830378 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.29730644822120667 norm:0.000221109003177844 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.29721930623054504 norm:0.00021980634483043104 max memory_allocated 29272.75048828125 
[2025-03-02 20:22:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.2971459627151489 norm:0.0002189387596445158 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.29707497358322144 norm:0.00021697244665119797 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.3718097507953644 norm:0.0018307907739654183 max memory_allocated 29272.93798828125 
[2025-03-02 20:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.3559853136539459 norm:0.0008863087277859449 max memory_allocated 29272.93798828125 
[2025-03-02 20:26:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.3415978252887726 norm:0.0005473380442708731 max memory_allocated 29272.93798828125 
[2025-03-02 20:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.3375660479068756 norm:0.0004062363295815885 max memory_allocated 29272.93798828125 
[2025-03-02 20:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.3360433876514435 norm:0.0003353527281433344 max memory_allocated 29272.93798828125 
[2025-03-02 20:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.3354790210723877 norm:0.0002999432326760143 max memory_allocated 29272.93798828125 
[2025-03-02 20:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.3350914716720581 norm:0.00028099113842472434 max memory_allocated 29272.93798828125 
[2025-03-02 20:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.3347853422164917 norm:0.00027039265842176974 max memory_allocated 29272.93798828125 
[2025-03-02 20:31:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.334509015083313 norm:0.00026089049060828984 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.33430731296539307 norm:0.0002537764376029372 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.33412015438079834 norm:0.0002468154998496175 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.33394840359687805 norm:0.00024280800425913185 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:35 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.33379125595092773 norm:0.00024309914442710578 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.33363908529281616 norm:0.00024207489332184196 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.33351796865463257 norm:0.00023982972197700292 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.333429217338562 norm:0.00024300612858496606 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.3333269953727722 norm:0.00024096918059512973 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.333222895860672 norm:0.00024106148339342326 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.33315014839172363 norm:0.0002405207633273676 max memory_allocated 29272.93798828125 
[2025-03-02 20:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.33307141065597534 norm:0.00023966295702848583 max memory_allocated 29272.93798828125 
[2025-03-02 20:40:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.41109997034072876 norm:0.0020638485439121723 max memory_allocated 29273.12548828125 
[2025-03-02 20:42:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.3948945999145508 norm:0.001067177508957684 max memory_allocated 29273.12548828125 
[2025-03-02 20:43:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.3799145221710205 norm:0.000685249047819525 max memory_allocated 29273.12548828125 
[2025-03-02 20:43:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.3754900097846985 norm:0.0005384075921028852 max memory_allocated 29273.12548828125 
[2025-03-02 20:44:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.37396305799484253 norm:0.0004803216434083879 max memory_allocated 29273.12548828125 
[2025-03-02 20:45:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.37339356541633606 norm:0.00043792062206193805 max memory_allocated 29273.12548828125 
[2025-03-02 20:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.37305793166160583 norm:0.00040978958713822067 max memory_allocated 29273.12548828125 
[2025-03-02 20:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.37276554107666016 norm:0.00039305604877881706 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.3724926710128784 norm:0.00038504350231960416 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.37226444482803345 norm:0.00038710940862074494 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.3720773160457611 norm:0.0003587972605600953 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.37192487716674805 norm:0.00035306686186231673 max memory_allocated 29273.12548828125 
[2025-03-02 20:51:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.3718010485172272 norm:0.0003520697355270386 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.37168169021606445 norm:0.00035351270344108343 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.37158823013305664 norm:0.000351361115463078 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.3715113401412964 norm:0.00036726228427141905 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.37140581011772156 norm:0.00036538488348014653 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.37131252884864807 norm:0.0003624963283073157 max memory_allocated 29273.12548828125 
[2025-03-02 20:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.37124884128570557 norm:0.00036594714038074017 max memory_allocated 29273.12548828125 
[2025-03-02 20:57:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.37119269371032715 norm:0.00038151536136865616 max memory_allocated 29273.12548828125 
[2025-03-02 20:57:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 20:58:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.4454056918621063 norm:0.0018254239112138748 max memory_allocated 29273.31298828125 
[2025-03-02 20:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.429536372423172 norm:0.0009477584972046316 max memory_allocated 29273.31298828125 
[2025-03-02 20:59:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.4144037365913391 norm:0.0005709261749871075 max memory_allocated 29273.31298828125 
[2025-03-02 21:00:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.4100463092327118 norm:0.0004037313046865165 max memory_allocated 29273.31298828125 
[2025-03-02 21:01:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.4086461067199707 norm:0.00032329544774256647 max memory_allocated 29273.31298828125 
[2025-03-02 21:02:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.4080701470375061 norm:0.0002797237248159945 max memory_allocated 29273.31298828125 
[2025-03-02 21:03:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.40768536925315857 norm:0.0002545663737691939 max memory_allocated 29273.31298828125 
[2025-03-02 21:03:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.4073827564716339 norm:0.00023750364198349416 max memory_allocated 29273.31298828125 
[2025-03-02 21:04:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.40712013840675354 norm:0.000226340998779051 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.4068911075592041 norm:0.00021894866949878633 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.4067014753818512 norm:0.0002162715682061389 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.4065227210521698 norm:0.0002109087072312832 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:01 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.40637385845184326 norm:0.00020894892804790288 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.40620648860931396 norm:0.00020537378441076726 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.4060850739479065 norm:0.00020396281615830958 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.4059792459011078 norm:0.0002046202280325815 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.4058603048324585 norm:0.00020357375615276396 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.40577954053878784 norm:0.00020107105956412852 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.40569007396698 norm:0.00019961458747275174 max memory_allocated 29273.31298828125 
[2025-03-02 21:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.40562909841537476 norm:0.0002004939306061715 max memory_allocated 29273.31298828125 
[2025-03-02 21:14:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:14:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.4943837821483612 norm:0.003500171471387148 max memory_allocated 29273.50048828125 
[2025-03-02 21:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.47637835144996643 norm:0.001686006784439087 max memory_allocated 29273.50048828125 
[2025-03-02 21:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.4599745571613312 norm:0.000992381013929844 max memory_allocated 29273.50048828125 
[2025-03-02 21:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.45526647567749023 norm:0.0006770950276404619 max memory_allocated 29273.50048828125 
[2025-03-02 21:18:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.4538123905658722 norm:0.0005275683361105621 max memory_allocated 29273.50048828125 
[2025-03-02 21:18:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.4531763195991516 norm:0.00045497549581341445 max memory_allocated 29273.50048828125 
[2025-03-02 21:19:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.4526839256286621 norm:0.0004094887990504503 max memory_allocated 29273.50048828125 
[2025-03-02 21:20:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.4523114860057831 norm:0.00036333719617687166 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.4520372748374939 norm:0.0003410575445741415 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.4517621099948883 norm:0.0003243016835767776 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.45150718092918396 norm:0.00031473400304093957 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.45131915807724 norm:0.0003081221948377788 max memory_allocated 29273.50048828125 
[2025-03-02 21:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.45116424560546875 norm:0.0003041297022718936 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.45098575949668884 norm:0.0002999287680722773 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:23 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.4508306384086609 norm:0.00029398282640613616 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.45070308446884155 norm:0.0002937401586677879 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.4505813419818878 norm:0.00029198589618317783 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.4504806101322174 norm:0.00029078018269501626 max memory_allocated 29273.50048828125 
[2025-03-02 21:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.4503840208053589 norm:0.0002895248762797564 max memory_allocated 29273.50048828125 
[2025-03-02 21:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.4503036141395569 norm:0.00029035951592959464 max memory_allocated 29273.50048828125 
[2025-03-02 21:30:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:31:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.5364056825637817 norm:0.002022701548412442 max memory_allocated 29273.68798828125 
[2025-03-02 21:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.5184545516967773 norm:0.000977606512606144 max memory_allocated 29273.68798828125 
[2025-03-02 21:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.5016437768936157 norm:0.0005864821141585708 max memory_allocated 29273.68798828125 
[2025-03-02 21:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.496666818857193 norm:0.00041392119601368904 max memory_allocated 29273.68798828125 
[2025-03-02 21:34:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.49523359537124634 norm:0.0003352107887621969 max memory_allocated 29273.68798828125 
[2025-03-02 21:35:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.4946209490299225 norm:0.00029535649809986353 max memory_allocated 29273.68798828125 
[2025-03-02 21:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.4941801428794861 norm:0.00027181138284504414 max memory_allocated 29273.68798828125 
[2025-03-02 21:37:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.493821382522583 norm:0.000259573629591614 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.4934919774532318 norm:0.0002481409173924476 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.49323832988739014 norm:0.00024389405734837055 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.4929918348789215 norm:0.0002406557323411107 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.4927946925163269 norm:0.00023711351968813688 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.49259260296821594 norm:0.00023348905961029232 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:17 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.4924389123916626 norm:0.0002357890916755423 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.4922804832458496 norm:0.00023761299962643534 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.49217450618743896 norm:0.0002386327541898936 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.4920647144317627 norm:0.0002309638075530529 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.4919997453689575 norm:0.0002409255102975294 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.49188554286956787 norm:0.0002278042520629242 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.4918133318424225 norm:0.0002280111366417259 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:48:20 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.5808501243591309 norm:0.002475532004609704 max memory_allocated 29273.87548828125 
[2025-03-02 21:49:09 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.5627098083496094 norm:0.0012401805724948645 max memory_allocated 29273.87548828125 
[2025-03-02 21:49:58 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.5453785061836243 norm:0.0007392631960101426 max memory_allocated 29273.87548828125 
[2025-03-02 21:50:48 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.5403774380683899 norm:0.0005159095744602382 max memory_allocated 29273.87548828125 
[2025-03-02 21:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.5389713048934937 norm:0.000410599575843662 max memory_allocated 29273.87548828125 
[2025-03-02 21:52:26 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.5383031964302063 norm:0.0003444962785579264 max memory_allocated 29273.87548828125 
[2025-03-02 21:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.5378692150115967 norm:0.0003040670999325812 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:05 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.5374879837036133 norm:0.00027853401843458414 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.5371573567390442 norm:0.00026291212998330593 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:43 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.5368872880935669 norm:0.00025238373200409114 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:32 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.5366418361663818 norm:0.0002457101072650403 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.5364300608634949 norm:0.00023907290596980602 max memory_allocated 29273.87548828125 
[2025-03-02 21:58:11 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.5362681746482849 norm:0.0002352725132368505 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.5361287593841553 norm:0.00023396914184559137 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:49 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.5359747409820557 norm:0.00023765992955304682 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.5358639359474182 norm:0.00022806010383646935 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:28 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.5357372760772705 norm:0.00023494659399148077 max memory_allocated 29273.87548828125 
[2025-03-02 22:02:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.5356258749961853 norm:0.0002295470330864191 max memory_allocated 29273.87548828125 
[2025-03-02 22:03:07 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.5355010032653809 norm:0.0002344261883990839 max memory_allocated 29273.87548828125 
[2025-03-02 22:03:56 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.5354123115539551 norm:0.00022673884814139456 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:05:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.6352514028549194 norm:0.001523069106042385 max memory_allocated 29274.06298828125 
[2025-03-02 22:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.6160937547683716 norm:0.0008660817402414978 max memory_allocated 29274.06298828125 
[2025-03-02 22:06:43 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.5983416438102722 norm:0.000617197307292372 max memory_allocated 29274.06298828125 
[2025-03-02 22:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.5932733416557312 norm:0.000474460975965485 max memory_allocated 29274.06298828125 
[2025-03-02 22:08:21 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.5919418334960938 norm:0.0004140973323956132 max memory_allocated 29274.06298828125 
[2025-03-02 22:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.5912694931030273 norm:0.0003797869139816612 max memory_allocated 29274.06298828125 
[2025-03-02 22:10:00 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.5908792018890381 norm:0.00036712767905555665 max memory_allocated 29274.06298828125 
[2025-03-02 22:10:49 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.5905526280403137 norm:0.000352455914253369 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.5903165340423584 norm:0.0003488961374387145 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.5900713205337524 norm:0.00033652031561359763 max memory_allocated 29274.06298828125 
[2025-03-02 22:13:17 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.589815616607666 norm:0.0003297892108093947 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:06 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.5897530913352966 norm:0.00033605826320126653 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:55 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.5895000696182251 norm:0.0003316985093988478 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.5893851518630981 norm:0.00033004183205775917 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.5891891717910767 norm:0.00033856582012958825 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.5890083312988281 norm:0.00033506183535791934 max memory_allocated 29274.06298828125 
[2025-03-02 22:18:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.5888748168945312 norm:0.0003226228873245418 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:02 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.5888198018074036 norm:0.00032955361530184746 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.5887104272842407 norm:0.0003182217769790441 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.5886343717575073 norm:0.00032672201632522047 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:21:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.7088883519172668 norm:0.003525656182318926 max memory_allocated 29274.25048828125 
[2025-03-02 22:22:37 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.6854132413864136 norm:0.0017012699972838163 max memory_allocated 29274.25048828125 
[2025-03-02 22:23:26 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.6640378832817078 norm:0.0009892339585348964 max memory_allocated 29274.25048828125 
[2025-03-02 22:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.6583284735679626 norm:0.0006910188822075725 max memory_allocated 29274.25048828125 
[2025-03-02 22:25:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.65702223777771 norm:0.0005526501918211579 max memory_allocated 29274.25048828125 
[2025-03-02 22:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.6563296914100647 norm:0.00047293928219005466 max memory_allocated 29274.25048828125 
[2025-03-02 22:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.6558653116226196 norm:0.000426240119850263 max memory_allocated 29274.25048828125 
[2025-03-02 22:27:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.6554571390151978 norm:0.0003990562981925905 max memory_allocated 29274.25048828125 
[2025-03-02 22:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.6550838351249695 norm:0.0003774646029341966 max memory_allocated 29274.25048828125 
[2025-03-02 22:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.6547440886497498 norm:0.0003661633818410337 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.6544641256332397 norm:0.00035494958865456283 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:50 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.6542333960533142 norm:0.0003458243445493281 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:39 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.6540312170982361 norm:0.0003453166864346713 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.6537538766860962 norm:0.00034384193713776767 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.6534772515296936 norm:0.00033586000790819526 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.6533713340759277 norm:0.0003366618766449392 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.65324866771698 norm:0.00033414785866625607 max memory_allocated 29274.25048828125 
[2025-03-02 22:35:45 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.6531183123588562 norm:0.0003325509314890951 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.6529947519302368 norm:0.0003292603068985045 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.6529008150100708 norm:0.0003279861994087696 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.7748839855194092 norm:0.003506431123241782 max memory_allocated 29274.43798828125 
[2025-03-02 22:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.7497305870056152 norm:0.0018621009076014161 max memory_allocated 29274.43798828125 
[2025-03-02 22:40:10 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.7271568179130554 norm:0.0011355218011885881 max memory_allocated 29274.43798828125 
[2025-03-02 22:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.7213648557662964 norm:0.0008012101170606911 max memory_allocated 29274.43798828125 
[2025-03-02 22:41:48 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.7197566032409668 norm:0.0006465850747190416 max memory_allocated 29274.43798828125 
[2025-03-02 22:42:38 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.7188220024108887 norm:0.0005673259147442877 max memory_allocated 29274.43798828125 
[2025-03-02 22:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.7180690169334412 norm:0.0005132918013259768 max memory_allocated 29274.43798828125 
[2025-03-02 22:44:16 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.7175431847572327 norm:0.00048431253526359797 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.7170631289482117 norm:0.0004568980075418949 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.7165762186050415 norm:0.0004453397123143077 max memory_allocated 29274.43798828125 
[2025-03-02 22:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.7165014147758484 norm:0.000432405446190387 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.7162270545959473 norm:0.0004168609157204628 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.7158893942832947 norm:0.0004037506296299398 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.7156185507774353 norm:0.0004046846879646182 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.7153526544570923 norm:0.0003966186195611954 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:50 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.715207576751709 norm:0.00039390206802636385 max memory_allocated 29274.43798828125 
[2025-03-02 22:51:39 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.7150402665138245 norm:0.0003976840525865555 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.714853823184967 norm:0.00039355139597319067 max memory_allocated 29274.43798828125 
[2025-03-02 22:53:18 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.7146799564361572 norm:0.000395312556065619 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:07 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.714531421661377 norm:0.00038809410762041807 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 22:54:26 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 22:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.8529384136199951 norm:0.015235772356390953 max memory_allocated 29274.77001953125 
[2025-03-02 22:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.8245230913162231 norm:0.011664397083222866 max memory_allocated 29274.77001953125 
[2025-03-02 22:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.7986823320388794 norm:0.008767400868237019 max memory_allocated 29274.77001953125 
[2025-03-02 22:57:43 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.7925902605056763 norm:0.007292536552995443 max memory_allocated 29274.77001953125 
[2025-03-02 22:58:32 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.7906931042671204 norm:0.005881432443857193 max memory_allocated 29274.77001953125 
[2025-03-02 22:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.7894367575645447 norm:0.004879412241280079 max memory_allocated 29274.77001953125 
[2025-03-02 23:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.7887407541275024 norm:0.0046449401415884495 max memory_allocated 29274.77001953125 
[2025-03-02 23:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.7882232069969177 norm:0.004536268301308155 max memory_allocated 29274.77001953125 
[2025-03-02 23:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.787776529788971 norm:0.004312832839787006 max memory_allocated 29274.77001953125 
[2025-03-02 23:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.7875662446022034 norm:0.004192896652966738 max memory_allocated 29274.77001953125 
[2025-03-02 23:03:29 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.7868850827217102 norm:0.00409878883510828 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.7864832282066345 norm:0.003762728301808238 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.7859716415405273 norm:0.003762568812817335 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.7856103181838989 norm:0.0035878103226423264 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.7853968143463135 norm:0.003558520693331957 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.7852219343185425 norm:0.003479418810456991 max memory_allocated 29274.77001953125 
[2025-03-02 23:08:25 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.7850295901298523 norm:0.003381814109161496 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.7848606705665588 norm:0.0033669834956526756 max memory_allocated 29274.77001953125 
[2025-03-02 23:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.7846736907958984 norm:0.0032881726510822773 max memory_allocated 29274.77001953125 
[2025-03-02 23:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.7845930457115173 norm:0.0032894639298319817 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:11:12 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:12:01 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.9744842052459717 norm:0.022247472777962685 max memory_allocated 29274.95751953125 
[2025-03-02 23:12:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.9353120923042297 norm:0.015326196327805519 max memory_allocated 29274.95751953125 
[2025-03-02 23:13:40 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.9021376371383667 norm:0.00979752279818058 max memory_allocated 29274.95751953125 
[2025-03-02 23:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.8926525115966797 norm:0.010999225080013275 max memory_allocated 29274.95751953125 
[2025-03-02 23:15:18 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.8899271488189697 norm:0.009847315959632397 max memory_allocated 29274.95751953125 
[2025-03-02 23:16:08 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.8882044553756714 norm:0.008351161144673824 max memory_allocated 29274.95751953125 
[2025-03-02 23:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.8871318697929382 norm:0.00731491157785058 max memory_allocated 29274.95751953125 
[2025-03-02 23:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.886159360408783 norm:0.006931188050657511 max memory_allocated 29274.95751953125 
[2025-03-02 23:18:36 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.8855003714561462 norm:0.0063975718803703785 max memory_allocated 29274.95751953125 
[2025-03-02 23:19:25 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.8849536776542664 norm:0.006076920311897993 max memory_allocated 29274.95751953125 
[2025-03-02 23:20:15 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.8845268487930298 norm:0.005732102319598198 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:04 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.884218156337738 norm:0.005650670733302832 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:53 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.8842140436172485 norm:0.006000985391438007 max memory_allocated 29274.95751953125 
[2025-03-02 23:22:43 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.8837319612503052 norm:0.005681019276380539 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.8832084536552429 norm:0.00514704454690218 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.8830929398536682 norm:0.004994660150259733 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:11 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.8828237056732178 norm:0.004868525080382824 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:00 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.8829752206802368 norm:0.004870075732469559 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.882576048374176 norm:0.004630435723811388 max memory_allocated 29274.95751953125 
[2025-03-02 23:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.8826802968978882 norm:0.004633043892681599 max memory_allocated 29274.95751953125 
[2025-03-02 23:27:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:27:58 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:28:47 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:1.2274208068847656 norm:0.058873500674963 max memory_allocated 29275.14501953125 
[2025-03-02 23:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:1.156986951828003 norm:0.03915964066982269 max memory_allocated 29275.14501953125 
[2025-03-02 23:30:26 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:1.1089043617248535 norm:0.029464690014719963 max memory_allocated 29275.14501953125 
[2025-03-02 23:31:15 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:1.092119574546814 norm:0.025363260880112648 max memory_allocated 29275.14501953125 
[2025-03-02 23:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:1.0842576026916504 norm:0.02136681228876114 max memory_allocated 29275.14501953125 
[2025-03-02 23:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:1.0792791843414307 norm:0.019537203013896942 max memory_allocated 29275.14501953125 
[2025-03-02 23:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:1.0766407251358032 norm:0.017571646720170975 max memory_allocated 29275.14501953125 
[2025-03-02 23:34:32 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:1.0743732452392578 norm:0.017131906002759933 max memory_allocated 29275.14501953125 
[2025-03-02 23:35:22 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:1.0723814964294434 norm:0.016340596601366997 max memory_allocated 29275.14501953125 
[2025-03-02 23:36:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:1.0717747211456299 norm:0.01622054912149906 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:00 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:1.0702943801879883 norm:0.015066592022776604 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:50 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:1.0693246126174927 norm:0.01449604146182537 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:1.0682753324508667 norm:0.013797695748507977 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:28 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:1.0678019523620605 norm:0.013551631011068821 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:18 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:1.0662479400634766 norm:0.012998257763683796 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:07 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:1.065383791923523 norm:0.012754556722939014 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:1.0652029514312744 norm:0.01304663810878992 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:1.0643510818481445 norm:0.012298466637730598 max memory_allocated 29275.14501953125 
[2025-03-02 23:43:35 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:1.0641114711761475 norm:0.012150616385042667 max memory_allocated 29275.14501953125 
[2025-03-02 23:44:24 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:1.0634562969207764 norm:0.011552689597010612 max memory_allocated 29275.14501953125 
[2025-03-02 23:44:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:44:43 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:45:32 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:2.0621297359466553 norm:0.11959367990493774 max memory_allocated 29275.33251953125 
[2025-03-02 23:46:22 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:1.9193594455718994 norm:0.07650180160999298 max memory_allocated 29275.33251953125 
[2025-03-02 23:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:1.8174216747283936 norm:0.04420563578605652 max memory_allocated 29275.33251953125 
[2025-03-02 23:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:1.7903789281845093 norm:0.041297197341918945 max memory_allocated 29275.33251953125 
[2025-03-02 23:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:1.7697702646255493 norm:0.04318348690867424 max memory_allocated 29275.33251953125 
[2025-03-02 23:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:1.7529067993164062 norm:0.043920423835515976 max memory_allocated 29275.33251953125 
[2025-03-02 23:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:1.740925908088684 norm:0.04074876010417938 max memory_allocated 29275.33251953125 
[2025-03-02 23:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:1.7345739603042603 norm:0.04112544655799866 max memory_allocated 29275.33251953125 
[2025-03-02 23:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:1.730781078338623 norm:0.04358932748436928 max memory_allocated 29275.33251953125 
[2025-03-02 23:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:1.7285802364349365 norm:0.04498555138707161 max memory_allocated 29275.33251953125 
[2025-03-02 23:53:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:1.7269304990768433 norm:0.045982882380485535 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:1.7242604494094849 norm:0.047953031957149506 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:1.720341682434082 norm:0.04319772496819496 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:1.7160378694534302 norm:0.039250198751688004 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:03 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:1.7140188217163086 norm:0.03918124735355377 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:52 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:1.7112233638763428 norm:0.03758669272065163 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:42 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:1.7099080085754395 norm:0.03808702155947685 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:31 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:1.708235740661621 norm:0.03749912977218628 max memory_allocated 29275.33251953125 
[2025-03-03 00:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:1.708391785621643 norm:0.03768324851989746 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:1.7083008289337158 norm:0.03918995335698128 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:24 root] (main_calib_config2.py 372): INFO 40134.18437623978
[2025-03-03 00:01:35 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:03:30 root] (main_calib_config2.py 159): INFO wikitext2 : 5.344696521759033
[2025-03-03 00:03:30 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:06:29 root] (main_calib_config2.py 159): INFO c4 : 6.929388999938965
