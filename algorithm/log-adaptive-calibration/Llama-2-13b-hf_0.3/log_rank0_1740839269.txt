[2025-03-01 14:27:49 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.3', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.3.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-01 14:28:23 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-01 14:28:23 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.3.pkl
[2025-03-01 14:28:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-01 14:29:00 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.04505348950624466 norm:0.030502650886774063 max memory_allocated 29271.02001953125 
[2025-03-01 14:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.029453709721565247 norm:0.018522264435887337 max memory_allocated 29271.02001953125 
[2025-03-01 14:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.023473624140024185 norm:0.014308875426650047 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0215000007301569 norm:0.01237701065838337 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.020399458706378937 norm:0.009926402941346169 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.019861392676830292 norm:0.009347159415483475 max memory_allocated 29271.02001953125 
[2025-03-01 14:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.019517622888088226 norm:0.009102819487452507 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.01929723098874092 norm:0.006848192773759365 max memory_allocated 29271.02001953125 
[2025-03-01 14:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.01917145401239395 norm:0.008076522499322891 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.018862806260585785 norm:0.005213504191488028 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.018903138116002083 norm:0.007494096178561449 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.018835343420505524 norm:0.005801364313811064 max memory_allocated 29271.02001953125 
[2025-03-01 14:39:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.018850892782211304 norm:0.004895742516964674 max memory_allocated 29271.02001953125 
[2025-03-01 14:40:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.01881730556488037 norm:0.005089583341032267 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.018887583166360855 norm:0.005240269470959902 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.01891019567847252 norm:0.004676282871514559 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.018977336585521698 norm:0.004201891832053661 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.01906011998653412 norm:0.0052591972053050995 max memory_allocated 29271.02001953125 
[2025-03-01 14:44:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.018947124481201172 norm:0.003379948204383254 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.018940426409244537 norm:0.00405757874250412 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-01 14:45:45 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.11525726318359375 norm:0.03141244873404503 max memory_allocated 29271.02001953125 
[2025-03-01 14:47:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.0918266624212265 norm:0.022055385634303093 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.07992283254861832 norm:0.015247455798089504 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.07536907494068146 norm:0.011707179248332977 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.0729246586561203 norm:0.00945190992206335 max memory_allocated 29271.02001953125 
[2025-03-01 14:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.07120165228843689 norm:0.0077143521048128605 max memory_allocated 29271.02001953125 
[2025-03-01 14:51:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.07005604356527328 norm:0.006401905789971352 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.06925301253795624 norm:0.005365451797842979 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.06865572929382324 norm:0.0049070147797465324 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.0684574767947197 norm:0.0048221698962152 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.06811030954122543 norm:0.004797707311809063 max memory_allocated 29271.02001953125 
[2025-03-01 14:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.06786735355854034 norm:0.004677210934460163 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.06766583770513535 norm:0.0046188365668058395 max memory_allocated 29271.02001953125 
[2025-03-01 14:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.06743144989013672 norm:0.004504311829805374 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.06726620346307755 norm:0.004331444855779409 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.06719161570072174 norm:0.0043328129686415195 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.06711345911026001 norm:0.0041889226995408535 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.06698688864707947 norm:0.004173813387751579 max memory_allocated 29271.02001953125 
[2025-03-01 15:01:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.06688987463712692 norm:0.00405048718675971 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.06677434593439102 norm:0.003899980802088976 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-01 15:02:36 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 15:03:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.14773821830749512 norm:0.02364157885313034 max memory_allocated 29271.02001953125 
[2025-03-01 15:04:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.12759849429130554 norm:0.016153652220964432 max memory_allocated 29271.02001953125 
[2025-03-01 15:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.1152477040886879 norm:0.01116170547902584 max memory_allocated 29271.02001953125 
[2025-03-01 15:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.10993006825447083 norm:0.008427895605564117 max memory_allocated 29271.02001953125 
[2025-03-01 15:06:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.10717952251434326 norm:0.006409015506505966 max memory_allocated 29271.02001953125 
[2025-03-01 15:07:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.10528872907161713 norm:0.005019431933760643 max memory_allocated 29271.02001953125 
[2025-03-01 15:08:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.104085274040699 norm:0.004801392089575529 max memory_allocated 29271.02001953125 
[2025-03-01 15:09:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.10319917649030685 norm:0.004596281331032515 max memory_allocated 29271.02001953125 
[2025-03-01 15:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.10257495939731598 norm:0.004403955768793821 max memory_allocated 29271.02001953125 
[2025-03-01 15:10:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.10214590281248093 norm:0.004290896933525801 max memory_allocated 29271.02001953125 
[2025-03-01 15:11:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.1017141044139862 norm:0.004206731915473938 max memory_allocated 29271.02001953125 
[2025-03-01 15:12:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.10133855789899826 norm:0.0041545964777469635 max memory_allocated 29271.02001953125 
[2025-03-01 15:13:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.10113399475812912 norm:0.004156286828219891 max memory_allocated 29271.02001953125 
[2025-03-01 15:14:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.10093484073877335 norm:0.0041352529078722 max memory_allocated 29271.02001953125 
[2025-03-01 15:15:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.10075885057449341 norm:0.0039586639031767845 max memory_allocated 29271.02001953125 
[2025-03-01 15:15:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.10065848380327225 norm:0.0038213939405977726 max memory_allocated 29271.02001953125 
[2025-03-01 15:16:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.1005815863609314 norm:0.0037350503262132406 max memory_allocated 29271.02001953125 
[2025-03-01 15:17:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.1004902720451355 norm:0.003677710425108671 max memory_allocated 29271.02001953125 
[2025-03-01 15:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.1004350483417511 norm:0.003624353324994445 max memory_allocated 29271.02001953125 
[2025-03-01 15:19:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.10038596391677856 norm:0.003619255032390356 max memory_allocated 29271.02001953125 
[2025-03-01 15:19:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-01 15:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.3411024808883667 norm:0.03268566355109215 max memory_allocated 29271.43798828125 
[2025-03-01 15:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.27961814403533936 norm:0.016533179208636284 max memory_allocated 29271.43798828125 
[2025-03-01 15:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.2263597697019577 norm:0.015233645215630531 max memory_allocated 29271.43798828125 
[2025-03-01 15:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.1959979087114334 norm:0.008634396828711033 max memory_allocated 29271.43798828125 
[2025-03-01 15:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.18522284924983978 norm:0.007447013631463051 max memory_allocated 29271.43798828125 
[2025-03-01 15:24:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.18186548352241516 norm:0.006702264305204153 max memory_allocated 29271.43798828125 
[2025-03-01 15:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.17657239735126495 norm:0.00609566830098629 max memory_allocated 29271.43798828125 
[2025-03-01 15:26:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.17252026498317719 norm:0.006088326685130596 max memory_allocated 29271.43798828125 
[2025-03-01 15:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.17251808941364288 norm:0.006097392179071903 max memory_allocated 29271.43798828125 
[2025-03-01 15:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.16978755593299866 norm:0.005787419155240059 max memory_allocated 29271.43798828125 
[2025-03-01 15:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.170134499669075 norm:0.006192618049681187 max memory_allocated 29271.43798828125 
[2025-03-01 15:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.16782045364379883 norm:0.005673419684171677 max memory_allocated 29271.43798828125 
[2025-03-01 15:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.1670251488685608 norm:0.005767131689935923 max memory_allocated 29271.43798828125 
[2025-03-01 15:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.16522517800331116 norm:0.005419012624770403 max memory_allocated 29271.43798828125 
[2025-03-01 15:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.16422569751739502 norm:0.005463265348225832 max memory_allocated 29271.43798828125 
[2025-03-01 15:32:40 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.1617491990327835 norm:0.006234708242118359 max memory_allocated 29271.43798828125 
[2025-03-01 15:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.1605662703514099 norm:0.005056899972259998 max memory_allocated 29271.43798828125 
[2025-03-01 15:34:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.15929560363292694 norm:0.004693690221756697 max memory_allocated 29271.43798828125 
[2025-03-01 15:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.15895159542560577 norm:0.00464722840115428 max memory_allocated 29271.43798828125 
[2025-03-01 15:35:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.16030310094356537 norm:0.004961942322552204 max memory_allocated 29271.43798828125 
[2025-03-01 15:36:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-01 15:37:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.22354845702648163 norm:0.009954225271940231 max memory_allocated 29271.43798828125 
[2025-03-01 15:37:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.20575913786888123 norm:0.005324461963027716 max memory_allocated 29271.43798828125 
[2025-03-01 15:38:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.1918797791004181 norm:0.0031754591036587954 max memory_allocated 29271.43798828125 
[2025-03-01 15:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.185287207365036 norm:0.0021943519823253155 max memory_allocated 29271.43798828125 
[2025-03-01 15:40:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.1818292737007141 norm:0.0018062741728499532 max memory_allocated 29271.43798828125 
[2025-03-01 15:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.1790810525417328 norm:0.0015301976818591356 max memory_allocated 29271.43798828125 
[2025-03-01 15:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.17728203535079956 norm:0.001322640455327928 max memory_allocated 29271.43798828125 
[2025-03-01 15:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.1761736124753952 norm:0.0012404767330735922 max memory_allocated 29271.43798828125 
[2025-03-01 15:43:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.1753578782081604 norm:0.0011835847981274128 max memory_allocated 29271.43798828125 
[2025-03-01 15:44:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.1746826320886612 norm:0.0011323466897010803 max memory_allocated 29271.43798828125 
[2025-03-01 15:45:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.17396722733974457 norm:0.0011231574462726712 max memory_allocated 29271.43798828125 
[2025-03-01 15:46:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.1737428456544876 norm:0.0011383751407265663 max memory_allocated 29271.43798828125 
[2025-03-01 15:47:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.17318017780780792 norm:0.0010804866906255484 max memory_allocated 29271.43798828125 
[2025-03-01 15:47:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.17289124429225922 norm:0.0010672896169126034 max memory_allocated 29271.43798828125 
[2025-03-01 15:48:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.17282502353191376 norm:0.0010668763425201178 max memory_allocated 29271.43798828125 
[2025-03-01 15:49:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.17274124920368195 norm:0.0010497751645743847 max memory_allocated 29271.43798828125 
[2025-03-01 15:50:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.172515869140625 norm:0.0010183594422414899 max memory_allocated 29271.43798828125 
[2025-03-01 15:51:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.17236551642417908 norm:0.0010230551706627011 max memory_allocated 29271.43798828125 
[2025-03-01 15:51:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.17223146557807922 norm:0.0010087594855576754 max memory_allocated 29271.43798828125 
[2025-03-01 15:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.17215155065059662 norm:0.0010031367419287562 max memory_allocated 29271.43798828125 
[2025-03-01 15:53:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-01 15:53:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.24790814518928528 norm:0.011893716640770435 max memory_allocated 29271.43798828125 
[2025-03-01 15:54:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.2282484620809555 norm:0.0048702009953558445 max memory_allocated 29271.43798828125 
[2025-03-01 15:55:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.2137429416179657 norm:0.002892346354201436 max memory_allocated 29271.43798828125 
[2025-03-01 15:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.20786504447460175 norm:0.0020262147299945354 max memory_allocated 29271.43798828125 
[2025-03-01 15:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.2046508938074112 norm:0.0014987816102802753 max memory_allocated 29271.43798828125 
[2025-03-01 15:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.20266734063625336 norm:0.001348069286905229 max memory_allocated 29271.43798828125 
[2025-03-01 15:58:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.20097103714942932 norm:0.0011631374945864081 max memory_allocated 29271.43798828125 
[2025-03-01 15:59:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.19985873997211456 norm:0.0011187747586518526 max memory_allocated 29271.43798828125 
[2025-03-01 16:00:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.19891326129436493 norm:0.0010708181653171778 max memory_allocated 29271.43798828125 
[2025-03-01 16:01:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.19819459319114685 norm:0.001022114884108305 max memory_allocated 29271.43798828125 
[2025-03-01 16:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.19762812554836273 norm:0.0009718128712847829 max memory_allocated 29271.43798828125 
[2025-03-01 16:03:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.19726963341236115 norm:0.0009660283103585243 max memory_allocated 29271.43798828125 
[2025-03-01 16:03:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.19692660868167877 norm:0.0009112259140238166 max memory_allocated 29271.43798828125 
[2025-03-01 16:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.19664759933948517 norm:0.00091552734375 max memory_allocated 29271.43798828125 
[2025-03-01 16:05:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.1964336633682251 norm:0.0008903671987354755 max memory_allocated 29271.43798828125 
[2025-03-01 16:06:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.19617429375648499 norm:0.0008945732261054218 max memory_allocated 29271.43798828125 
[2025-03-01 16:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.19606457650661469 norm:0.0008783757803030312 max memory_allocated 29271.43798828125 
[2025-03-01 16:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.19595786929130554 norm:0.0008926907321438193 max memory_allocated 29271.43798828125 
[2025-03-01 16:08:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.19571112096309662 norm:0.0008634502300992608 max memory_allocated 29271.43798828125 
[2025-03-01 16:09:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.19566527009010315 norm:0.0008773552253842354 max memory_allocated 29271.43798828125 
[2025-03-01 16:09:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-01 16:10:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.28616058826446533 norm:0.024073923006653786 max memory_allocated 29272.00048828125 
[2025-03-01 16:11:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.2615186274051666 norm:0.011700966395437717 max memory_allocated 29272.00048828125 
[2025-03-01 16:12:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.2418919950723648 norm:0.0035335987340658903 max memory_allocated 29272.00048828125 
[2025-03-01 16:13:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.23458564281463623 norm:0.002195836277678609 max memory_allocated 29272.00048828125 
[2025-03-01 16:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.2308194488286972 norm:0.0019293150398880243 max memory_allocated 29272.00048828125 
[2025-03-01 16:14:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.2282847762107849 norm:0.0017222244059666991 max memory_allocated 29272.00048828125 
[2025-03-01 16:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.22636093199253082 norm:0.0016110470751300454 max memory_allocated 29272.00048828125 
[2025-03-01 16:16:33 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.22447748482227325 norm:0.0015415862435474992 max memory_allocated 29272.00048828125 
[2025-03-01 16:17:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.22330273687839508 norm:0.0013965872349217534 max memory_allocated 29272.00048828125 
[2025-03-01 16:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.222096785902977 norm:0.0013203744310885668 max memory_allocated 29272.00048828125 
[2025-03-01 16:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.2213107794523239 norm:0.001262438832782209 max memory_allocated 29272.00048828125 
[2025-03-01 16:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.22073684632778168 norm:0.0012143818894401193 max memory_allocated 29272.00048828125 
[2025-03-01 16:20:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.22041639685630798 norm:0.001197058125399053 max memory_allocated 29272.00048828125 
[2025-03-01 16:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.2201208621263504 norm:0.0012266080593690276 max memory_allocated 29272.00048828125 
[2025-03-01 16:22:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.21987581253051758 norm:0.0011596711119636893 max memory_allocated 29272.00048828125 
[2025-03-01 16:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.21969449520111084 norm:0.0011477977968752384 max memory_allocated 29272.00048828125 
[2025-03-01 16:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.219560906291008 norm:0.0011486726580187678 max memory_allocated 29272.00048828125 
[2025-03-01 16:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.21926817297935486 norm:0.0011562674771994352 max memory_allocated 29272.00048828125 
[2025-03-01 16:25:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.21904966235160828 norm:0.0011172961676493287 max memory_allocated 29272.00048828125 
[2025-03-01 16:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.21889814734458923 norm:0.0010916506871581078 max memory_allocated 29272.00048828125 
[2025-03-01 16:26:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-01 16:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.33293673396110535 norm:0.0127744534984231 max memory_allocated 29272.18798828125 
[2025-03-01 16:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.2956928014755249 norm:0.004910876043140888 max memory_allocated 29272.18798828125 
[2025-03-01 16:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.27094683051109314 norm:0.002635431941598654 max memory_allocated 29272.18798828125 
[2025-03-01 16:30:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.26227259635925293 norm:0.0018314390908926725 max memory_allocated 29272.18798828125 
[2025-03-01 16:30:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.258394718170166 norm:0.0015481821028515697 max memory_allocated 29272.18798828125 
[2025-03-01 16:31:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.255487322807312 norm:0.001395741361193359 max memory_allocated 29272.18798828125 
[2025-03-01 16:32:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.2531932592391968 norm:0.0013031094567850232 max memory_allocated 29272.18798828125 
[2025-03-01 16:33:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.25150713324546814 norm:0.0012500685406848788 max memory_allocated 29272.18798828125 
[2025-03-01 16:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.25026145577430725 norm:0.0012253273744136095 max memory_allocated 29272.18798828125 
[2025-03-01 16:35:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.2493394911289215 norm:0.0012378271203488111 max memory_allocated 29272.18798828125 
[2025-03-01 16:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.24862290918827057 norm:0.0011769105913117528 max memory_allocated 29272.18798828125 
[2025-03-01 16:36:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.24802453815937042 norm:0.001155515550635755 max memory_allocated 29272.18798828125 
[2025-03-01 16:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.2476520538330078 norm:0.001134734251536429 max memory_allocated 29272.18798828125 
[2025-03-01 16:38:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.2472773939371109 norm:0.001139602973125875 max memory_allocated 29272.18798828125 
[2025-03-01 16:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.2470933347940445 norm:0.0011233515106141567 max memory_allocated 29272.18798828125 
[2025-03-01 16:39:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.24688105285167694 norm:0.0010954751633107662 max memory_allocated 29272.18798828125 
[2025-03-01 16:40:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.24667814373970032 norm:0.0010889195837080479 max memory_allocated 29272.18798828125 
[2025-03-01 16:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.24654853343963623 norm:0.001062021474353969 max memory_allocated 29272.18798828125 
[2025-03-01 16:42:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.24644587934017181 norm:0.0010495142778381705 max memory_allocated 29272.18798828125 
[2025-03-01 16:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.24646376073360443 norm:0.0010347289498895407 max memory_allocated 29272.18798828125 
[2025-03-01 16:43:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-01 16:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.3636230528354645 norm:0.032959312200546265 max memory_allocated 29272.37548828125 
[2025-03-01 16:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.32717645168304443 norm:0.021293049678206444 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.29983508586883545 norm:0.013340124860405922 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.2878614068031311 norm:0.008336616680026054 max memory_allocated 29272.37548828125 
[2025-03-01 16:47:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.27979692816734314 norm:0.00279748416505754 max memory_allocated 29272.37548828125 
[2025-03-01 16:48:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.27538907527923584 norm:0.0018528929213061929 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.27239206433296204 norm:0.0016455574659630656 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.27024349570274353 norm:0.0015022020088508725 max memory_allocated 29272.37548828125 
[2025-03-01 16:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.2687828838825226 norm:0.0013904497027397156 max memory_allocated 29272.37548828125 
[2025-03-01 16:51:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.26764440536499023 norm:0.0013001507613807917 max memory_allocated 29272.37548828125 
[2025-03-01 16:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.266826331615448 norm:0.001222854945808649 max memory_allocated 29272.37548828125 
[2025-03-01 16:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.2659841775894165 norm:0.0012062281602993608 max memory_allocated 29272.37548828125 
[2025-03-01 16:54:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.2654306888580322 norm:0.0011718783061951399 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.2650141716003418 norm:0.0011559058912098408 max memory_allocated 29272.37548828125 
[2025-03-01 16:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.2646942138671875 norm:0.0011248331284150481 max memory_allocated 29272.37548828125 
[2025-03-01 16:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.2643873989582062 norm:0.001118470449000597 max memory_allocated 29272.37548828125 
[2025-03-01 16:57:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.2641119360923767 norm:0.0010773773537948728 max memory_allocated 29272.37548828125 
[2025-03-01 16:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.26401805877685547 norm:0.001065527554601431 max memory_allocated 29272.37548828125 
[2025-03-01 16:59:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.2637641727924347 norm:0.0010551201412454247 max memory_allocated 29272.37548828125 
[2025-03-01 17:00:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.2636018991470337 norm:0.0010604491690173745 max memory_allocated 29272.37548828125 
[2025-03-01 17:00:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-01 17:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.41933104395866394 norm:0.03258036449551582 max memory_allocated 29272.56298828125 
[2025-03-01 17:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.3622238039970398 norm:0.012468202039599419 max memory_allocated 29272.56298828125 
[2025-03-01 17:02:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.3242967426776886 norm:0.006001422647386789 max memory_allocated 29272.56298828125 
[2025-03-01 17:03:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.3084684908390045 norm:0.0033286157995462418 max memory_allocated 29272.56298828125 
[2025-03-01 17:04:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.3023867905139923 norm:0.0027402385603636503 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.2977651357650757 norm:0.0022202336695045233 max memory_allocated 29272.56298828125 
[2025-03-01 17:06:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.2946733832359314 norm:0.0019316752441227436 max memory_allocated 29272.56298828125 
[2025-03-01 17:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.2923904359340668 norm:0.0017177903791889548 max memory_allocated 29272.56298828125 
[2025-03-01 17:07:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.2906169593334198 norm:0.0015946419443935156 max memory_allocated 29272.56298828125 
[2025-03-01 17:08:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.28942883014678955 norm:0.001475671073421836 max memory_allocated 29272.56298828125 
[2025-03-01 17:09:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.2883487641811371 norm:0.0014251306420192122 max memory_allocated 29272.56298828125 
[2025-03-01 17:10:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.2877316474914551 norm:0.0013642171397805214 max memory_allocated 29272.56298828125 
[2025-03-01 17:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.28713521361351013 norm:0.0012812481727451086 max memory_allocated 29272.56298828125 
[2025-03-01 17:12:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.28672462701797485 norm:0.0012079918524250388 max memory_allocated 29272.56298828125 
[2025-03-01 17:12:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.28586745262145996 norm:0.001148593844845891 max memory_allocated 29272.56298828125 
[2025-03-01 17:13:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.285643994808197 norm:0.0011584574822336435 max memory_allocated 29272.56298828125 
[2025-03-01 17:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.2855825424194336 norm:0.001150870113633573 max memory_allocated 29272.56298828125 
[2025-03-01 17:15:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.28546425700187683 norm:0.0011417617788538337 max memory_allocated 29272.56298828125 
[2025-03-01 17:16:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.2851884663105011 norm:0.001116847968660295 max memory_allocated 29272.56298828125 
[2025-03-01 17:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.28501737117767334 norm:0.0011789307463914156 max memory_allocated 29272.56298828125 
[2025-03-01 17:17:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-01 17:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.40749645233154297 norm:0.02204880304634571 max memory_allocated 29272.75048828125 
[2025-03-01 17:18:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.36228320002555847 norm:0.007865200750529766 max memory_allocated 29272.75048828125 
[2025-03-01 17:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.3332327902317047 norm:0.003923159558326006 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.32196110486984253 norm:0.0027006217278540134 max memory_allocated 29272.75048828125 
[2025-03-01 17:21:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.3167373836040497 norm:0.0021884371526539326 max memory_allocated 29272.75048828125 
[2025-03-01 17:22:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.3131920397281647 norm:0.00185482413507998 max memory_allocated 29272.75048828125 
[2025-03-01 17:23:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.31058865785598755 norm:0.001641386654227972 max memory_allocated 29272.75048828125 
[2025-03-01 17:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.3084425628185272 norm:0.0014610610669478774 max memory_allocated 29272.75048828125 
[2025-03-01 17:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.30691850185394287 norm:0.0014214599505066872 max memory_allocated 29272.75048828125 
[2025-03-01 17:25:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.3058033585548401 norm:0.001306914840824902 max memory_allocated 29272.75048828125 
[2025-03-01 17:26:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.30503174662590027 norm:0.0012952848337590694 max memory_allocated 29272.75048828125 
[2025-03-01 17:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.3043419122695923 norm:0.0011674652341753244 max memory_allocated 29272.75048828125 
[2025-03-01 17:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.30378496646881104 norm:0.0011567061301320791 max memory_allocated 29272.75048828125 
[2025-03-01 17:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.3032686710357666 norm:0.0010869610123336315 max memory_allocated 29272.75048828125 
[2025-03-01 17:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.30278801918029785 norm:0.0010462868958711624 max memory_allocated 29272.75048828125 
[2025-03-01 17:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.3025245666503906 norm:0.001046723104082048 max memory_allocated 29272.75048828125 
[2025-03-01 17:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.3023015856742859 norm:0.0009764008573256433 max memory_allocated 29272.75048828125 
[2025-03-01 17:32:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.3020525276660919 norm:0.0009591127163730562 max memory_allocated 29272.75048828125 
[2025-03-01 17:32:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.30204957723617554 norm:0.0009450548095628619 max memory_allocated 29272.75048828125 
[2025-03-01 17:33:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.301859974861145 norm:0.0009438579436391592 max memory_allocated 29272.75048828125 
[2025-03-01 17:34:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-01 17:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.4149862825870514 norm:0.027873199433088303 max memory_allocated 29272.93798828125 
[2025-03-01 17:35:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.3804283142089844 norm:0.011088433675467968 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.35006144642829895 norm:0.0048254807479679585 max memory_allocated 29272.93798828125 
[2025-03-01 17:37:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.33870428800582886 norm:0.002648859051987529 max memory_allocated 29272.93798828125 
[2025-03-01 17:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.33376622200012207 norm:0.001842961530201137 max memory_allocated 29272.93798828125 
[2025-03-01 17:39:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.3302941620349884 norm:0.001620443887077272 max memory_allocated 29272.93798828125 
[2025-03-01 17:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.3275335133075714 norm:0.0013767997734248638 max memory_allocated 29272.93798828125 
[2025-03-01 17:40:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.3253289759159088 norm:0.0012090241070836782 max memory_allocated 29272.93798828125 
[2025-03-01 17:41:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.32383283972740173 norm:0.0011901605175808072 max memory_allocated 29272.93798828125 
[2025-03-01 17:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.3226702809333801 norm:0.0011583456071093678 max memory_allocated 29272.93798828125 
[2025-03-01 17:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.32186731696128845 norm:0.0010802847100421786 max memory_allocated 29272.93798828125 
[2025-03-01 17:44:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.3210793137550354 norm:0.0010311020305380225 max memory_allocated 29272.93798828125 
[2025-03-01 17:44:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.3206104040145874 norm:0.0009806554298847914 max memory_allocated 29272.93798828125 
[2025-03-01 17:45:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.32020214200019836 norm:0.0009595708688721061 max memory_allocated 29272.93798828125 
[2025-03-01 17:46:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.3198933005332947 norm:0.0009064924088306725 max memory_allocated 29272.93798828125 
[2025-03-01 17:47:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.3195550739765167 norm:0.0008904142887331545 max memory_allocated 29272.93798828125 
[2025-03-01 17:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.3193510174751282 norm:0.0008751487475819886 max memory_allocated 29272.93798828125 
[2025-03-01 17:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.3188658058643341 norm:0.0008780205971561372 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.31859105825424194 norm:0.0008561248541809618 max memory_allocated 29272.93798828125 
[2025-03-01 17:50:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.31841856241226196 norm:0.0008501444244757295 max memory_allocated 29272.93798828125 
[2025-03-01 17:50:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-01 17:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.43412020802497864 norm:0.01728321611881256 max memory_allocated 29273.12548828125 
[2025-03-01 17:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.392118364572525 norm:0.007480373606085777 max memory_allocated 29273.12548828125 
[2025-03-01 17:53:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.3575790226459503 norm:0.003054462606087327 max memory_allocated 29273.12548828125 
[2025-03-01 17:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.34552377462387085 norm:0.0018951422534883022 max memory_allocated 29273.12548828125 
[2025-03-01 17:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.3403766453266144 norm:0.0014598174020648003 max memory_allocated 29273.12548828125 
[2025-03-01 17:55:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.33707818388938904 norm:0.0012781440746039152 max memory_allocated 29273.12548828125 
[2025-03-01 17:56:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.3344995379447937 norm:0.0011725464137271047 max memory_allocated 29273.12548828125 
[2025-03-01 17:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.33252567052841187 norm:0.001099990913644433 max memory_allocated 29273.12548828125 
[2025-03-01 17:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.33096209168434143 norm:0.0010189319727942348 max memory_allocated 29273.12548828125 
[2025-03-01 17:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.32987409830093384 norm:0.0009732545004226267 max memory_allocated 29273.12548828125 
[2025-03-01 18:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.3290431499481201 norm:0.0009391523199155927 max memory_allocated 29273.12548828125 
[2025-03-01 18:00:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.3283863365650177 norm:0.0008928850293159485 max memory_allocated 29273.12548828125 
[2025-03-01 18:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.3278135359287262 norm:0.0008591673686169088 max memory_allocated 29273.12548828125 
[2025-03-01 18:02:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.3272978663444519 norm:0.0008455263450741768 max memory_allocated 29273.12548828125 
[2025-03-01 18:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.32703062891960144 norm:0.0008530850172974169 max memory_allocated 29273.12548828125 
[2025-03-01 18:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.32678136229515076 norm:0.0008415685151703656 max memory_allocated 29273.12548828125 
[2025-03-01 18:05:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.3265460729598999 norm:0.0008165628532879055 max memory_allocated 29273.12548828125 
[2025-03-01 18:05:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.32637470960617065 norm:0.0007993686595000327 max memory_allocated 29273.12548828125 
[2025-03-01 18:06:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.32622405886650085 norm:0.0008166668703779578 max memory_allocated 29273.12548828125 
[2025-03-01 18:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.32610321044921875 norm:0.0007957456982694566 max memory_allocated 29273.12548828125 
[2025-03-01 18:07:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-01 18:08:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.4356408417224884 norm:0.022556794807314873 max memory_allocated 29273.31298828125 
[2025-03-01 18:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.3971360921859741 norm:0.010075943544507027 max memory_allocated 29273.31298828125 
[2025-03-01 18:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.3681492507457733 norm:0.00458589056506753 max memory_allocated 29273.31298828125 
[2025-03-01 18:11:05 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.35613441467285156 norm:0.0020822412334382534 max memory_allocated 29273.31298828125 
[2025-03-01 18:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.35094472765922546 norm:0.0016749093774706125 max memory_allocated 29273.31298828125 
[2025-03-01 18:12:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.347653329372406 norm:0.0014152926160022616 max memory_allocated 29273.31298828125 
[2025-03-01 18:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.34524092078208923 norm:0.0013319768477231264 max memory_allocated 29273.31298828125 
[2025-03-01 18:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.3431186079978943 norm:0.0011650208616629243 max memory_allocated 29273.31298828125 
[2025-03-01 18:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.3416590392589569 norm:0.0011157584376633167 max memory_allocated 29273.31298828125 
[2025-03-01 18:16:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.34046852588653564 norm:0.0010385609930381179 max memory_allocated 29273.31298828125 
[2025-03-01 18:16:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.33946219086647034 norm:0.0010191277833655477 max memory_allocated 29273.31298828125 
[2025-03-01 18:17:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.3387811481952667 norm:0.0009964349446818233 max memory_allocated 29273.31298828125 
[2025-03-01 18:18:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.33826249837875366 norm:0.000985505641438067 max memory_allocated 29273.31298828125 
[2025-03-01 18:19:21 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.3379293978214264 norm:0.000966324470937252 max memory_allocated 29273.31298828125 
[2025-03-01 18:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.33759409189224243 norm:0.0009440514841116965 max memory_allocated 29273.31298828125 
[2025-03-01 18:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.33711814880371094 norm:0.0009216085891239345 max memory_allocated 29273.31298828125 
[2025-03-01 18:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.3368779718875885 norm:0.0008857899229042232 max memory_allocated 29273.31298828125 
[2025-03-01 18:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.3365950286388397 norm:0.0008615880506113172 max memory_allocated 29273.31298828125 
[2025-03-01 18:23:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.3363949954509735 norm:0.0008579620625823736 max memory_allocated 29273.31298828125 
[2025-03-01 18:24:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.3362007439136505 norm:0.0008568797493353486 max memory_allocated 29273.31298828125 
[2025-03-01 18:24:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-01 18:25:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.43736326694488525 norm:0.018796313554048538 max memory_allocated 29273.50048828125 
[2025-03-01 18:26:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.4050247371196747 norm:0.010216791182756424 max memory_allocated 29273.50048828125 
[2025-03-01 18:27:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.3794741630554199 norm:0.006152826827019453 max memory_allocated 29273.50048828125 
[2025-03-01 18:27:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.36910688877105713 norm:0.0041603706777095795 max memory_allocated 29273.50048828125 
[2025-03-01 18:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.3639889359474182 norm:0.00308309867978096 max memory_allocated 29273.50048828125 
[2025-03-01 18:29:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.3604087233543396 norm:0.002412244910374284 max memory_allocated 29273.50048828125 
[2025-03-01 18:30:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.35747912526130676 norm:0.0017937073716893792 max memory_allocated 29273.50048828125 
[2025-03-01 18:31:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.3553144335746765 norm:0.0015752658946439624 max memory_allocated 29273.50048828125 
[2025-03-01 18:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.35369813442230225 norm:0.0014317859895527363 max memory_allocated 29273.50048828125 
[2025-03-01 18:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.35251134634017944 norm:0.0013515843311324716 max memory_allocated 29273.50048828125 
[2025-03-01 18:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.3516441583633423 norm:0.00131196528673172 max memory_allocated 29273.50048828125 
[2025-03-01 18:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.3508402109146118 norm:0.001180848921649158 max memory_allocated 29273.50048828125 
[2025-03-01 18:35:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.35039258003234863 norm:0.0011166376061737537 max memory_allocated 29273.50048828125 
[2025-03-01 18:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.34976527094841003 norm:0.0010653033386915922 max memory_allocated 29273.50048828125 
[2025-03-01 18:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.3493157625198364 norm:0.0010153985349461436 max memory_allocated 29273.50048828125 
[2025-03-01 18:37:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.34915369749069214 norm:0.0009938371367752552 max memory_allocated 29273.50048828125 
[2025-03-01 18:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.3488960266113281 norm:0.0009665093966759741 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.34858760237693787 norm:0.0009318320662714541 max memory_allocated 29273.50048828125 
[2025-03-01 18:40:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.34831053018569946 norm:0.0009230701252818108 max memory_allocated 29273.50048828125 
[2025-03-01 18:41:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.34805285930633545 norm:0.0009090215316973627 max memory_allocated 29273.50048828125 
[2025-03-01 18:41:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-01 18:42:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.41451746225357056 norm:0.009420786052942276 max memory_allocated 29273.68798828125 
[2025-03-01 18:43:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.3951871991157532 norm:0.00515933521091938 max memory_allocated 29273.68798828125 
[2025-03-01 18:43:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.3793888986110687 norm:0.0033157619182020426 max memory_allocated 29273.68798828125 
[2025-03-01 18:44:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.37107059359550476 norm:0.0019783631432801485 max memory_allocated 29273.68798828125 
[2025-03-01 18:45:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.36663904786109924 norm:0.0013034017756581306 max memory_allocated 29273.68798828125 
[2025-03-01 18:46:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.363741397857666 norm:0.0009199156775139272 max memory_allocated 29273.68798828125 
[2025-03-01 18:47:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.3614844083786011 norm:0.0008554318337701261 max memory_allocated 29273.68798828125 
[2025-03-01 18:48:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.3596773147583008 norm:0.0008132948423735797 max memory_allocated 29273.68798828125 
[2025-03-01 18:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.35827261209487915 norm:0.0007865320658311248 max memory_allocated 29273.68798828125 
[2025-03-01 18:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.35719722509384155 norm:0.000770927406847477 max memory_allocated 29273.68798828125 
[2025-03-01 18:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.35634300112724304 norm:0.0007554740877822042 max memory_allocated 29273.68798828125 
[2025-03-01 18:51:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.35577982664108276 norm:0.0007445158553309739 max memory_allocated 29273.68798828125 
[2025-03-01 18:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.35513463616371155 norm:0.0007340199663303792 max memory_allocated 29273.68798828125 
[2025-03-01 18:53:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.3548741042613983 norm:0.000729478313587606 max memory_allocated 29273.68798828125 
[2025-03-01 18:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.35444051027297974 norm:0.0007178134983405471 max memory_allocated 29273.68798828125 
[2025-03-01 18:54:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.35412174463272095 norm:0.0007143828552216291 max memory_allocated 29273.68798828125 
[2025-03-01 18:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.3538244664669037 norm:0.0007068460108712316 max memory_allocated 29273.68798828125 
[2025-03-01 18:56:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.353696346282959 norm:0.0007115164189599454 max memory_allocated 29273.68798828125 
[2025-03-01 18:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.35345524549484253 norm:0.0007042121142148972 max memory_allocated 29273.68798828125 
[2025-03-01 18:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.35329052805900574 norm:0.0007084094104357064 max memory_allocated 29273.68798828125 
[2025-03-01 18:58:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-01 18:59:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.4505758285522461 norm:0.02834617905318737 max memory_allocated 29273.87548828125 
[2025-03-01 18:59:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.4276333451271057 norm:0.01512300968170166 max memory_allocated 29273.87548828125 
[2025-03-01 19:00:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.39977818727493286 norm:0.00705043924972415 max memory_allocated 29273.87548828125 
[2025-03-01 19:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.3877865672111511 norm:0.004214854910969734 max memory_allocated 29273.87548828125 
[2025-03-01 19:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.3826277554035187 norm:0.002901194617152214 max memory_allocated 29273.87548828125 
[2025-03-01 19:03:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.3793603479862213 norm:0.002529287477955222 max memory_allocated 29273.87548828125 
[2025-03-01 19:04:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.3767402470111847 norm:0.0021688397973775864 max memory_allocated 29273.87548828125 
[2025-03-01 19:04:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.374664843082428 norm:0.0017671582754701376 max memory_allocated 29273.87548828125 
[2025-03-01 19:05:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.3730919659137726 norm:0.0015231914585456252 max memory_allocated 29273.87548828125 
[2025-03-01 19:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.3716680109500885 norm:0.0015092561952769756 max memory_allocated 29273.87548828125 
[2025-03-01 19:07:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.37046173214912415 norm:0.0014152105432003736 max memory_allocated 29273.87548828125 
[2025-03-01 19:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.3696069121360779 norm:0.001314575201831758 max memory_allocated 29273.87548828125 
[2025-03-01 19:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.3688291013240814 norm:0.0012379896361380816 max memory_allocated 29273.87548828125 
[2025-03-01 19:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.36811625957489014 norm:0.00113020243588835 max memory_allocated 29273.87548828125 
[2025-03-01 19:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.3676973283290863 norm:0.001120627741329372 max memory_allocated 29273.87548828125 
[2025-03-01 19:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.36719438433647156 norm:0.0010377869475632906 max memory_allocated 29273.87548828125 
[2025-03-01 19:12:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.36695143580436707 norm:0.0010481990175321698 max memory_allocated 29273.87548828125 
[2025-03-01 19:13:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.3666379451751709 norm:0.0010222946293652058 max memory_allocated 29273.87548828125 
[2025-03-01 19:14:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.36632809042930603 norm:0.0009998989989981055 max memory_allocated 29273.87548828125 
[2025-03-01 19:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.36612874269485474 norm:0.001023083459585905 max memory_allocated 29273.87548828125 
[2025-03-01 19:15:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-01 19:15:58 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.425159752368927 norm:0.01251993142068386 max memory_allocated 29274.06298828125 
[2025-03-01 19:16:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.4108513593673706 norm:0.005858446937054396 max memory_allocated 29274.06298828125 
[2025-03-01 19:17:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.3986523449420929 norm:0.0029679557774215937 max memory_allocated 29274.06298828125 
[2025-03-01 19:18:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.39332956075668335 norm:0.0021578106097877026 max memory_allocated 29274.06298828125 
[2025-03-01 19:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.3904864192008972 norm:0.0018271907465532422 max memory_allocated 29274.06298828125 
[2025-03-01 19:20:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.3883713483810425 norm:0.0016473890282213688 max memory_allocated 29274.06298828125 
[2025-03-01 19:20:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.38638103008270264 norm:0.0014291408006101847 max memory_allocated 29274.06298828125 
[2025-03-01 19:21:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.38462376594543457 norm:0.0012642949586734176 max memory_allocated 29274.06298828125 
[2025-03-01 19:22:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.3831647038459778 norm:0.0012699825456365943 max memory_allocated 29274.06298828125 
[2025-03-01 19:23:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.38194355368614197 norm:0.0010647044982761145 max memory_allocated 29274.06298828125 
[2025-03-01 19:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.38105645775794983 norm:0.0011171402875334024 max memory_allocated 29274.06298828125 
[2025-03-01 19:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.3801393508911133 norm:0.0010146417189389467 max memory_allocated 29274.06298828125 
[2025-03-01 19:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.3792739808559418 norm:0.0010625839931890368 max memory_allocated 29274.06298828125 
[2025-03-01 19:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.3788108229637146 norm:0.0009552141418680549 max memory_allocated 29274.06298828125 
[2025-03-01 19:27:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.3782896399497986 norm:0.001029795384965837 max memory_allocated 29274.06298828125 
[2025-03-01 19:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.3778309226036072 norm:0.0009350397158414125 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.37734055519104004 norm:0.0009826140012592077 max memory_allocated 29274.06298828125 
[2025-03-01 19:30:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.3769882321357727 norm:0.0008829981670714915 max memory_allocated 29274.06298828125 
[2025-03-01 19:30:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.37668564915657043 norm:0.0009257591445930302 max memory_allocated 29274.06298828125 
[2025-03-01 19:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.37649431824684143 norm:0.0008897563675418496 max memory_allocated 29274.06298828125 
[2025-03-01 19:31:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-01 19:32:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.4311743974685669 norm:0.008789950050413609 max memory_allocated 29274.25048828125 
[2025-03-01 19:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.4197070300579071 norm:0.0050916969776153564 max memory_allocated 29274.25048828125 
[2025-03-01 19:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.4099138379096985 norm:0.0034041968174278736 max memory_allocated 29274.25048828125 
[2025-03-01 19:35:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.40507689118385315 norm:0.002562728011980653 max memory_allocated 29274.25048828125 
[2025-03-01 19:36:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.40234479308128357 norm:0.0020476579666137695 max memory_allocated 29274.25048828125 
[2025-03-01 19:36:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.40019991993904114 norm:0.0017535489751026034 max memory_allocated 29274.25048828125 
[2025-03-01 19:37:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.3986603915691376 norm:0.0016801637830212712 max memory_allocated 29274.25048828125 
[2025-03-01 19:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.3971329927444458 norm:0.0015924269100651145 max memory_allocated 29274.25048828125 
[2025-03-01 19:39:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.3958301246166229 norm:0.0015138518065214157 max memory_allocated 29274.25048828125 
[2025-03-01 19:40:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.39440035820007324 norm:0.0014552365755662322 max memory_allocated 29274.25048828125 
[2025-03-01 19:41:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.3934325873851776 norm:0.0013705400051549077 max memory_allocated 29274.25048828125 
[2025-03-01 19:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.39220985770225525 norm:0.0012958715669810772 max memory_allocated 29274.25048828125 
[2025-03-01 19:42:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.39179641008377075 norm:0.0012368872994557023 max memory_allocated 29274.25048828125 
[2025-03-01 19:43:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.3910345435142517 norm:0.0011455982457846403 max memory_allocated 29274.25048828125 
[2025-03-01 19:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.3905692398548126 norm:0.0011075418442487717 max memory_allocated 29274.25048828125 
[2025-03-01 19:45:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.3899552524089813 norm:0.0010423562489449978 max memory_allocated 29274.25048828125 
[2025-03-01 19:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.3896583318710327 norm:0.0009972132975235581 max memory_allocated 29274.25048828125 
[2025-03-01 19:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.3892364501953125 norm:0.0009619174525141716 max memory_allocated 29274.25048828125 
[2025-03-01 19:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.38876670598983765 norm:0.0009407137986272573 max memory_allocated 29274.25048828125 
[2025-03-01 19:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.38849517703056335 norm:0.0009110757964663208 max memory_allocated 29274.25048828125 
[2025-03-01 19:48:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-01 19:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.4487009644508362 norm:0.005891081411391497 max memory_allocated 29274.43798828125 
[2025-03-01 19:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.43891802430152893 norm:0.003734447993338108 max memory_allocated 29274.43798828125 
[2025-03-01 19:51:18 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.4298020601272583 norm:0.0027993270196020603 max memory_allocated 29274.43798828125 
[2025-03-01 19:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.4250110983848572 norm:0.0019195047207176685 max memory_allocated 29274.43798828125 
[2025-03-01 19:52:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.4222202003002167 norm:0.0016350210644304752 max memory_allocated 29274.43798828125 
[2025-03-01 19:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.4200318455696106 norm:0.0014534913934767246 max memory_allocated 29274.43798828125 
[2025-03-01 19:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.4182940423488617 norm:0.0013714093947783113 max memory_allocated 29274.43798828125 
[2025-03-01 19:55:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.41709795594215393 norm:0.0012517448049038649 max memory_allocated 29274.43798828125 
[2025-03-01 19:56:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.41589102149009705 norm:0.0012161043705418706 max memory_allocated 29274.43798828125 
[2025-03-01 19:57:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.4148387014865875 norm:0.0011502500856295228 max memory_allocated 29274.43798828125 
[2025-03-01 19:57:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.41392505168914795 norm:0.0010930985445156693 max memory_allocated 29274.43798828125 
[2025-03-01 19:58:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.413126140832901 norm:0.0010508596897125244 max memory_allocated 29274.43798828125 
[2025-03-01 19:59:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.41249755024909973 norm:0.0010186901781708002 max memory_allocated 29274.43798828125 
[2025-03-01 20:00:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.4118637442588806 norm:0.000977074378170073 max memory_allocated 29274.43798828125 
[2025-03-01 20:01:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.41154685616493225 norm:0.0010023837676271796 max memory_allocated 29274.43798828125 
[2025-03-01 20:02:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.4107723832130432 norm:0.0009477444691583514 max memory_allocated 29274.43798828125 
[2025-03-01 20:02:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.4107331931591034 norm:0.0009489848162047565 max memory_allocated 29274.43798828125 
[2025-03-01 20:03:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.4101971387863159 norm:0.0009086232166737318 max memory_allocated 29274.43798828125 
[2025-03-01 20:04:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.4100085496902466 norm:0.000902776257134974 max memory_allocated 29274.43798828125 
[2025-03-01 20:05:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.40937235951423645 norm:0.0008727845270186663 max memory_allocated 29274.43798828125 
[2025-03-01 20:05:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-01 20:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.47254085540771484 norm:0.007027583196759224 max memory_allocated 29274.62548828125 
[2025-03-01 20:07:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.46293652057647705 norm:0.004100640304386616 max memory_allocated 29274.62548828125 
[2025-03-01 20:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.45287758111953735 norm:0.002607285510748625 max memory_allocated 29274.62548828125 
[2025-03-01 20:08:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.44770097732543945 norm:0.001842952100560069 max memory_allocated 29274.62548828125 
[2025-03-01 20:09:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.44491371512413025 norm:0.001601070282049477 max memory_allocated 29274.62548828125 
[2025-03-01 20:10:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.4427488446235657 norm:0.001477777841500938 max memory_allocated 29274.62548828125 
[2025-03-01 20:11:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.44095346331596375 norm:0.0013405124191194773 max memory_allocated 29274.62548828125 
[2025-03-01 20:12:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.4392656683921814 norm:0.0012055797269567847 max memory_allocated 29274.62548828125 
[2025-03-01 20:13:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.43821045756340027 norm:0.0011659912997856736 max memory_allocated 29274.62548828125 
[2025-03-01 20:13:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.43723827600479126 norm:0.0011583385057747364 max memory_allocated 29274.62548828125 
[2025-03-01 20:14:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.43617722392082214 norm:0.001028386759571731 max memory_allocated 29274.62548828125 
[2025-03-01 20:15:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.4352661967277527 norm:0.0009554401622153819 max memory_allocated 29274.62548828125 
[2025-03-01 20:16:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.4344760477542877 norm:0.0009054586989805102 max memory_allocated 29274.62548828125 
[2025-03-01 20:17:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.4341704249382019 norm:0.0009147822856903076 max memory_allocated 29274.62548828125 
[2025-03-01 20:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.43344786763191223 norm:0.0008566692704334855 max memory_allocated 29274.62548828125 
[2025-03-01 20:18:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.43331819772720337 norm:0.00088939891429618 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.43259987235069275 norm:0.000824600167106837 max memory_allocated 29274.62548828125 
[2025-03-01 20:20:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.4326227605342865 norm:0.0008388988790102303 max memory_allocated 29274.62548828125 
[2025-03-01 20:21:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.4321605861186981 norm:0.0008135018870234489 max memory_allocated 29274.62548828125 
[2025-03-01 20:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.4321065843105316 norm:0.0008237328729592264 max memory_allocated 29274.62548828125 
[2025-03-01 20:22:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-01 20:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.511544406414032 norm:0.008266853168606758 max memory_allocated 29274.81298828125 
[2025-03-01 20:24:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.5012052059173584 norm:0.00464035477489233 max memory_allocated 29274.81298828125 
[2025-03-01 20:24:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.4904814064502716 norm:0.003026966005563736 max memory_allocated 29274.81298828125 
[2025-03-01 20:25:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.48535794019699097 norm:0.002365989377722144 max memory_allocated 29274.81298828125 
[2025-03-01 20:26:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.4822816550731659 norm:0.001881790580227971 max memory_allocated 29274.81298828125 
[2025-03-01 20:27:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.480241060256958 norm:0.0017156570684164762 max memory_allocated 29274.81298828125 
[2025-03-01 20:28:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.4787224233150482 norm:0.0016339432913810015 max memory_allocated 29274.81298828125 
[2025-03-01 20:29:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.4774087965488434 norm:0.00155495828948915 max memory_allocated 29274.81298828125 
[2025-03-01 20:29:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.47604477405548096 norm:0.0014276953879743814 max memory_allocated 29274.81298828125 
[2025-03-01 20:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.4751424491405487 norm:0.0014489315217360854 max memory_allocated 29274.81298828125 
[2025-03-01 20:31:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.4738799035549164 norm:0.0012273151660338044 max memory_allocated 29274.81298828125 
[2025-03-01 20:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.4736415147781372 norm:0.0013772632228210568 max memory_allocated 29274.81298828125 
[2025-03-01 20:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.4726830720901489 norm:0.0011737752938643098 max memory_allocated 29274.81298828125 
[2025-03-01 20:34:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.4723880887031555 norm:0.0012837033718824387 max memory_allocated 29274.81298828125 
[2025-03-01 20:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.4714772701263428 norm:0.0010887981625273824 max memory_allocated 29274.81298828125 
[2025-03-01 20:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.47117164731025696 norm:0.0011822259984910488 max memory_allocated 29274.81298828125 
[2025-03-01 20:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.4707872271537781 norm:0.0011041557881981134 max memory_allocated 29274.81298828125 
[2025-03-01 20:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.4705131947994232 norm:0.0011415091576054692 max memory_allocated 29274.81298828125 
[2025-03-01 20:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.4699733555316925 norm:0.0010146632557734847 max memory_allocated 29274.81298828125 
[2025-03-01 20:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.4698706865310669 norm:0.0010888101533055305 max memory_allocated 29274.81298828125 
[2025-03-01 20:39:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-01 20:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.5458760261535645 norm:0.006350183393806219 max memory_allocated 29275.00048828125 
[2025-03-01 20:41:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.5373708009719849 norm:0.004095232114195824 max memory_allocated 29275.00048828125 
[2025-03-01 20:41:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.5275176167488098 norm:0.0027799257077276707 max memory_allocated 29275.00048828125 
[2025-03-01 20:42:40 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.5227525234222412 norm:0.00186831783503294 max memory_allocated 29275.00048828125 
[2025-03-01 20:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.5204745531082153 norm:0.0015896034892648458 max memory_allocated 29275.00048828125 
[2025-03-01 20:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.5187233686447144 norm:0.0013971650041639805 max memory_allocated 29275.00048828125 
[2025-03-01 20:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.5171948075294495 norm:0.0012626990210264921 max memory_allocated 29275.00048828125 
[2025-03-01 20:45:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.5157407522201538 norm:0.0011495683575049043 max memory_allocated 29275.00048828125 
[2025-03-01 20:46:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.5146155953407288 norm:0.001150303054600954 max memory_allocated 29275.00048828125 
[2025-03-01 20:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.5134643912315369 norm:0.0010584412375465035 max memory_allocated 29275.00048828125 
[2025-03-01 20:48:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.512850284576416 norm:0.0010806842474266887 max memory_allocated 29275.00048828125 
[2025-03-01 20:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.5119432210922241 norm:0.0010286428732797503 max memory_allocated 29275.00048828125 
[2025-03-01 20:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.5114485621452332 norm:0.0010338743450120091 max memory_allocated 29275.00048828125 
[2025-03-01 20:50:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.5107696652412415 norm:0.0009822503197938204 max memory_allocated 29275.00048828125 
[2025-03-01 20:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.510236382484436 norm:0.0009895734256133437 max memory_allocated 29275.00048828125 
[2025-03-01 20:52:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.5097657442092896 norm:0.0009432835504412651 max memory_allocated 29275.00048828125 
[2025-03-01 20:53:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.5093875527381897 norm:0.0009607278043404222 max memory_allocated 29275.00048828125 
[2025-03-01 20:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.5089094042778015 norm:0.0009293209295719862 max memory_allocated 29275.00048828125 
[2025-03-01 20:55:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.5087425708770752 norm:0.000946653017308563 max memory_allocated 29275.00048828125 
[2025-03-01 20:55:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.5084308981895447 norm:0.0008978116093203425 max memory_allocated 29275.00048828125 
[2025-03-01 20:56:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-01 20:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.5998708605766296 norm:0.021498102694749832 max memory_allocated 29275.18798828125 
[2025-03-01 20:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.5904582738876343 norm:0.012796387076377869 max memory_allocated 29275.18798828125 
[2025-03-01 20:58:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.5798116326332092 norm:0.007785286754369736 max memory_allocated 29275.18798828125 
[2025-03-01 20:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.5749480724334717 norm:0.0056258575059473515 max memory_allocated 29275.18798828125 
[2025-03-01 21:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.5721775889396667 norm:0.0043562292121350765 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.5700001120567322 norm:0.003692976199090481 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.5683261156082153 norm:0.003148194868117571 max memory_allocated 29275.18798828125 
[2025-03-01 21:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.5668918490409851 norm:0.002749942010268569 max memory_allocated 29275.18798828125 
[2025-03-01 21:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.5652862787246704 norm:0.0023560472764074802 max memory_allocated 29275.18798828125 
[2025-03-01 21:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.5638333559036255 norm:0.0019854058045893908 max memory_allocated 29275.18798828125 
[2025-03-01 21:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.5627163648605347 norm:0.0017849483992904425 max memory_allocated 29275.18798828125 
[2025-03-01 21:06:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.5618263483047485 norm:0.0015858937986195087 max memory_allocated 29275.18798828125 
[2025-03-01 21:06:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.5610266327857971 norm:0.001467700581997633 max memory_allocated 29275.18798828125 
[2025-03-01 21:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.560428261756897 norm:0.001374869025312364 max memory_allocated 29275.18798828125 
[2025-03-01 21:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.5598151683807373 norm:0.0013007342349737883 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.5592136979103088 norm:0.001202430110424757 max memory_allocated 29275.18798828125 
[2025-03-01 21:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.5588052272796631 norm:0.0011461795074865222 max memory_allocated 29275.18798828125 
[2025-03-01 21:11:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.5584217309951782 norm:0.0011143669253215194 max memory_allocated 29275.18798828125 
[2025-03-01 21:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.5580926537513733 norm:0.0010694819502532482 max memory_allocated 29275.18798828125 
[2025-03-01 21:12:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.5577718019485474 norm:0.001044510630890727 max memory_allocated 29275.18798828125 
[2025-03-01 21:12:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-01 21:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.6428811550140381 norm:0.005936819594353437 max memory_allocated 29275.37548828125 
[2025-03-01 21:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.6355927586555481 norm:0.004001712892204523 max memory_allocated 29275.37548828125 
[2025-03-01 21:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.6270865797996521 norm:0.0029378090985119343 max memory_allocated 29275.37548828125 
[2025-03-01 21:16:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.6234806180000305 norm:0.002246326766908169 max memory_allocated 29275.37548828125 
[2025-03-01 21:17:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.6213560700416565 norm:0.001896743313409388 max memory_allocated 29275.37548828125 
[2025-03-01 21:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.6197050213813782 norm:0.0017464037518948317 max memory_allocated 29275.37548828125 
[2025-03-01 21:18:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.6179622411727905 norm:0.0014993230579420924 max memory_allocated 29275.37548828125 
[2025-03-01 21:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.6164382696151733 norm:0.0013562154490500689 max memory_allocated 29275.37548828125 
[2025-03-01 21:20:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.6151998043060303 norm:0.0012495263945311308 max memory_allocated 29275.37548828125 
[2025-03-01 21:21:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.6140298247337341 norm:0.0012231704313308 max memory_allocated 29275.37548828125 
[2025-03-01 21:22:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.613186240196228 norm:0.0011884421110153198 max memory_allocated 29275.37548828125 
[2025-03-01 21:22:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.612114429473877 norm:0.001173230935819447 max memory_allocated 29275.37548828125 
[2025-03-01 21:23:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.6115739941596985 norm:0.0011704310309141874 max memory_allocated 29275.37548828125 
[2025-03-01 21:24:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.6105324625968933 norm:0.0010922224028035998 max memory_allocated 29275.37548828125 
[2025-03-01 21:25:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.6104808449745178 norm:0.0010874392464756966 max memory_allocated 29275.37548828125 
[2025-03-01 21:26:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.6096226572990417 norm:0.001039050635881722 max memory_allocated 29275.37548828125 
[2025-03-01 21:27:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.6094654202461243 norm:0.0010352232493460178 max memory_allocated 29275.37548828125 
[2025-03-01 21:27:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.608687162399292 norm:0.0010326672345399857 max memory_allocated 29275.37548828125 
[2025-03-01 21:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.6086829900741577 norm:0.0010256520472466946 max memory_allocated 29275.37548828125 
[2025-03-01 21:29:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.6082177758216858 norm:0.001008798135444522 max memory_allocated 29275.37548828125 
[2025-03-01 21:29:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-01 21:30:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.69834965467453 norm:0.004156594630330801 max memory_allocated 29275.56298828125 
[2025-03-01 21:31:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.6911200284957886 norm:0.0027562256436794996 max memory_allocated 29275.56298828125 
[2025-03-01 21:32:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.6823472380638123 norm:0.0020409999415278435 max memory_allocated 29275.56298828125 
[2025-03-01 21:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.6790384650230408 norm:0.0017274203710258007 max memory_allocated 29275.56298828125 
[2025-03-01 21:34:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.6772900223731995 norm:0.0014862214447930455 max memory_allocated 29275.56298828125 
[2025-03-01 21:34:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.6756623387336731 norm:0.001283494639210403 max memory_allocated 29275.56298828125 
[2025-03-01 21:35:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.6742465496063232 norm:0.0012013633968308568 max memory_allocated 29275.56298828125 
[2025-03-01 21:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.6727844476699829 norm:0.0011371118016541004 max memory_allocated 29275.56298828125 
[2025-03-01 21:37:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.6717423796653748 norm:0.0010828458471223712 max memory_allocated 29275.56298828125 
[2025-03-01 21:38:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.670586884021759 norm:0.0010233722859993577 max memory_allocated 29275.56298828125 
[2025-03-01 21:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.6697360277175903 norm:0.0009790008189156651 max memory_allocated 29275.56298828125 
[2025-03-01 21:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.6690337657928467 norm:0.0009609029511921108 max memory_allocated 29275.56298828125 
[2025-03-01 21:40:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.6684293746948242 norm:0.0009217833867296576 max memory_allocated 29275.56298828125 
[2025-03-01 21:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.6678000092506409 norm:0.001401534304022789 max memory_allocated 29275.56298828125 
[2025-03-01 21:42:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.6673744320869446 norm:0.0008841765229590237 max memory_allocated 29275.56298828125 
[2025-03-01 21:43:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.6669614315032959 norm:0.0008507218444719911 max memory_allocated 29275.56298828125 
[2025-03-01 21:43:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.6666487455368042 norm:0.0008489427855238318 max memory_allocated 29275.56298828125 
[2025-03-01 21:44:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.6662485003471375 norm:0.000824804708827287 max memory_allocated 29275.56298828125 
[2025-03-01 21:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.666100263595581 norm:0.0008119351114146411 max memory_allocated 29275.56298828125 
[2025-03-01 21:46:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.6657527089118958 norm:0.0007987359422259033 max memory_allocated 29275.56298828125 
[2025-03-01 21:46:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-01 21:47:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.7770863771438599 norm:0.012731716968119144 max memory_allocated 29275.75048828125 
[2025-03-01 21:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.768898069858551 norm:0.008639764040708542 max memory_allocated 29275.75048828125 
[2025-03-01 21:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.7582802772521973 norm:0.00618253368884325 max memory_allocated 29275.75048828125 
[2025-03-01 21:50:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.7525216341018677 norm:0.004587553441524506 max memory_allocated 29275.75048828125 
[2025-03-01 21:50:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.7497808337211609 norm:0.003706936724483967 max memory_allocated 29275.75048828125 
[2025-03-01 21:51:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.7475398778915405 norm:0.003131043864414096 max memory_allocated 29275.75048828125 
[2025-03-01 21:52:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.7451648712158203 norm:0.002383152022957802 max memory_allocated 29275.75048828125 
[2025-03-01 21:53:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.7430808544158936 norm:0.002015550620853901 max memory_allocated 29275.75048828125 
[2025-03-01 21:54:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.7414298057556152 norm:0.0019962911028414965 max memory_allocated 29275.75048828125 
[2025-03-01 21:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.7404506802558899 norm:0.0020438339561223984 max memory_allocated 29275.75048828125 
[2025-03-01 21:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.7393317222595215 norm:0.0019012527773156762 max memory_allocated 29275.75048828125 
[2025-03-01 21:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.7386089563369751 norm:0.0018276054179295897 max memory_allocated 29275.75048828125 
[2025-03-01 21:57:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.7378365993499756 norm:0.001747888745740056 max memory_allocated 29275.75048828125 
[2025-03-01 21:58:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.7375728487968445 norm:0.0017618928104639053 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.736542284488678 norm:0.0015893209492787719 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.7365688681602478 norm:0.0016734644304960966 max memory_allocated 29275.75048828125 
[2025-03-01 22:00:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.7357279062271118 norm:0.0015215040184557438 max memory_allocated 29275.75048828125 
[2025-03-01 22:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.7357397079467773 norm:0.001572854584082961 max memory_allocated 29275.75048828125 
[2025-03-01 22:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.7351323366165161 norm:0.0014730013208463788 max memory_allocated 29275.75048828125 
[2025-03-01 22:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.7352368831634521 norm:0.00158224580809474 max memory_allocated 29275.75048828125 
[2025-03-01 22:03:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-01 22:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.8352765440940857 norm:0.005095737054944038 max memory_allocated 29275.93798828125 
[2025-03-01 22:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.8276380300521851 norm:0.002852365607395768 max memory_allocated 29275.93798828125 
[2025-03-01 22:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.817815363407135 norm:0.0019314662786200643 max memory_allocated 29275.93798828125 
[2025-03-01 22:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.8143097162246704 norm:0.0016627382719889283 max memory_allocated 29275.93798828125 
[2025-03-01 22:07:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.8124805688858032 norm:0.0014334192965179682 max memory_allocated 29275.93798828125 
[2025-03-01 22:08:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.8107895255088806 norm:0.0013476802268996835 max memory_allocated 29275.93798828125 
[2025-03-01 22:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.8093138337135315 norm:0.0012959882151335478 max memory_allocated 29275.93798828125 
[2025-03-01 22:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.8079051971435547 norm:0.0012493064859881997 max memory_allocated 29275.93798828125 
[2025-03-01 22:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.8064595460891724 norm:0.0011677918955683708 max memory_allocated 29275.93798828125 
[2025-03-01 22:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.805415153503418 norm:0.0011462392285466194 max memory_allocated 29275.93798828125 
[2025-03-01 22:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.804570734500885 norm:0.0011507220333442092 max memory_allocated 29275.93798828125 
[2025-03-01 22:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.8036994934082031 norm:0.0010842537740245461 max memory_allocated 29275.93798828125 
[2025-03-01 22:14:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.8033971786499023 norm:0.0010925802635028958 max memory_allocated 29275.93798828125 
[2025-03-01 22:15:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.8025612235069275 norm:0.0010516323382034898 max memory_allocated 29275.93798828125 
[2025-03-01 22:15:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.802341639995575 norm:0.0010708272457122803 max memory_allocated 29275.93798828125 
[2025-03-01 22:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.801643967628479 norm:0.0010301311267539859 max memory_allocated 29275.93798828125 
[2025-03-01 22:17:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.8012733459472656 norm:0.0009869864443317056 max memory_allocated 29275.93798828125 
[2025-03-01 22:18:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.8008854389190674 norm:0.0009886481566354632 max memory_allocated 29275.93798828125 
[2025-03-01 22:19:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.8005564212799072 norm:0.0009082175674848258 max memory_allocated 29275.93798828125 
[2025-03-01 22:20:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.8003333210945129 norm:0.0009656600886955857 max memory_allocated 29275.93798828125 
[2025-03-01 22:20:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-01 22:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.9189133644104004 norm:0.012100880034267902 max memory_allocated 29276.12548828125 
[2025-03-01 22:22:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.9106917977333069 norm:0.007788192015141249 max memory_allocated 29276.12548828125 
[2025-03-01 22:22:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.900360107421875 norm:0.00542957428842783 max memory_allocated 29276.12548828125 
[2025-03-01 22:23:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.8963348269462585 norm:0.004065424203872681 max memory_allocated 29276.12548828125 
[2025-03-01 22:24:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.8937293291091919 norm:0.0032457164488732815 max memory_allocated 29276.12548828125 
[2025-03-01 22:25:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.891730546951294 norm:0.002782283816486597 max memory_allocated 29276.12548828125 
[2025-03-01 22:26:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.8898026943206787 norm:0.0024174917489290237 max memory_allocated 29276.12548828125 
[2025-03-01 22:27:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.8876500725746155 norm:0.00217836769297719 max memory_allocated 29276.12548828125 
[2025-03-01 22:27:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.886003851890564 norm:0.001945996074937284 max memory_allocated 29276.12548828125 
[2025-03-01 22:28:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.8844897747039795 norm:0.001841572462581098 max memory_allocated 29276.12548828125 
[2025-03-01 22:29:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.8831398487091064 norm:0.0016207275912165642 max memory_allocated 29276.12548828125 
[2025-03-01 22:30:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.8821910619735718 norm:0.0016330013750120997 max memory_allocated 29276.12548828125 
[2025-03-01 22:31:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.8814201951026917 norm:0.0016227916348725557 max memory_allocated 29276.12548828125 
[2025-03-01 22:31:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.8810103535652161 norm:0.0016908030956983566 max memory_allocated 29276.12548828125 
[2025-03-01 22:32:49 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.880393922328949 norm:0.0015360608231276274 max memory_allocated 29276.12548828125 
[2025-03-01 22:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.8800122737884521 norm:0.0015129331732168794 max memory_allocated 29276.12548828125 
[2025-03-01 22:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.8794415593147278 norm:0.0014655741397291422 max memory_allocated 29276.12548828125 
[2025-03-01 22:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.8792929649353027 norm:0.0014404585817828774 max memory_allocated 29276.12548828125 
[2025-03-01 22:36:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.878648579120636 norm:0.0014404450776055455 max memory_allocated 29276.12548828125 
[2025-03-01 22:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.8786707520484924 norm:0.0015627797693014145 max memory_allocated 29276.12548828125 
[2025-03-01 22:37:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-01 22:38:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:1.0008841753005981 norm:0.007847505621612072 max memory_allocated 29276.31298828125 
[2025-03-01 22:38:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.9925248622894287 norm:0.00451922882348299 max memory_allocated 29276.31298828125 
[2025-03-01 22:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.9820944666862488 norm:0.0027704082895070314 max memory_allocated 29276.31298828125 
[2025-03-01 22:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.9782392382621765 norm:0.0023031614255160093 max memory_allocated 29276.31298828125 
[2025-03-01 22:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.9759833216667175 norm:0.0018231285503134131 max memory_allocated 29276.31298828125 
[2025-03-01 22:42:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.9739972352981567 norm:0.001518708886578679 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.9718774557113647 norm:0.0012435844400897622 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.97011798620224 norm:0.0012082748580724 max memory_allocated 29276.31298828125 
[2025-03-01 22:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.9687138795852661 norm:0.0011104181176051497 max memory_allocated 29276.31298828125 
[2025-03-01 22:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.9676581025123596 norm:0.0011872680624946952 max memory_allocated 29276.31298828125 
[2025-03-01 22:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.966090202331543 norm:0.0009321111720055342 max memory_allocated 29276.31298828125 
[2025-03-01 22:47:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.9659006595611572 norm:0.0010697880061343312 max memory_allocated 29276.31298828125 
[2025-03-01 22:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.9645543694496155 norm:0.0008619253057986498 max memory_allocated 29276.31298828125 
[2025-03-01 22:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.9644103050231934 norm:0.0010427992092445493 max memory_allocated 29276.31298828125 
[2025-03-01 22:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.9631394743919373 norm:0.0009014770039357245 max memory_allocated 29276.31298828125 
[2025-03-01 22:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.9633623957633972 norm:0.0010327242780476809 max memory_allocated 29276.31298828125 
[2025-03-01 22:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.9623163342475891 norm:0.0008471388136968017 max memory_allocated 29276.31298828125 
[2025-03-01 22:52:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.9626632928848267 norm:0.0009787660092115402 max memory_allocated 29276.31298828125 
[2025-03-01 22:52:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.9616609811782837 norm:0.0008224031771533191 max memory_allocated 29276.31298828125 
[2025-03-01 22:53:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.9618794322013855 norm:0.0009855813113972545 max memory_allocated 29276.31298828125 
[2025-03-01 22:54:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-01 22:54:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.1019906997680664 norm:0.011048578657209873 max memory_allocated 29276.50048828125 
[2025-03-01 22:55:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:1.090608835220337 norm:0.00656237592920661 max memory_allocated 29276.50048828125 
[2025-03-01 22:56:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:1.0778800249099731 norm:0.004416448064148426 max memory_allocated 29276.50048828125 
[2025-03-01 22:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:1.0715845823287964 norm:0.003165406407788396 max memory_allocated 29276.50048828125 
[2025-03-01 22:58:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:1.068662405014038 norm:0.001974700717255473 max memory_allocated 29276.50048828125 
[2025-03-01 22:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:1.0663551092147827 norm:0.0016620112583041191 max memory_allocated 29276.50048828125 
[2025-03-01 22:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:1.064134955406189 norm:0.0015323566040024161 max memory_allocated 29276.50048828125 
[2025-03-01 23:00:42 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:1.0621896982192993 norm:0.0014664259506389499 max memory_allocated 29276.50048828125 
[2025-03-01 23:01:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:1.060251235961914 norm:0.0013896701857447624 max memory_allocated 29276.50048828125 
[2025-03-01 23:02:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:1.0587596893310547 norm:0.0013834971468895674 max memory_allocated 29276.50048828125 
[2025-03-01 23:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:1.0572792291641235 norm:0.001296722679398954 max memory_allocated 29276.50048828125 
[2025-03-01 23:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:1.0567189455032349 norm:0.0012892476515844464 max memory_allocated 29276.50048828125 
[2025-03-01 23:04:50 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:1.055676817893982 norm:0.0011900776298716664 max memory_allocated 29276.50048828125 
[2025-03-01 23:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:1.0548220872879028 norm:0.001211971859447658 max memory_allocated 29276.50048828125 
[2025-03-01 23:06:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:1.0543556213378906 norm:0.0011554802767932415 max memory_allocated 29276.50048828125 
[2025-03-01 23:07:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:1.0534931421279907 norm:0.001171959680505097 max memory_allocated 29276.50048828125 
[2025-03-01 23:08:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:1.0535627603530884 norm:0.0011113069485872984 max memory_allocated 29276.50048828125 
[2025-03-01 23:08:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:1.0523194074630737 norm:0.0011288325767964125 max memory_allocated 29276.50048828125 
[2025-03-01 23:09:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:1.0523438453674316 norm:0.0011158841662108898 max memory_allocated 29276.50048828125 
[2025-03-01 23:10:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:1.0513837337493896 norm:0.0011360942153260112 max memory_allocated 29276.50048828125 
[2025-03-01 23:10:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-01 23:11:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:1.1931917667388916 norm:0.010712605901062489 max memory_allocated 29276.68798828125 
[2025-03-01 23:12:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:1.1831583976745605 norm:0.007166273891925812 max memory_allocated 29276.68798828125 
[2025-03-01 23:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:1.1699206829071045 norm:0.004213997628539801 max memory_allocated 29276.68798828125 
[2025-03-01 23:14:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:1.163722276687622 norm:0.0025318560656160116 max memory_allocated 29276.68798828125 
[2025-03-01 23:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:1.1608949899673462 norm:0.002354496158659458 max memory_allocated 29276.68798828125 
[2025-03-01 23:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:1.1584107875823975 norm:0.002128130756318569 max memory_allocated 29276.68798828125 
[2025-03-01 23:16:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:1.1550761461257935 norm:0.0013407963560894132 max memory_allocated 29276.68798828125 
[2025-03-01 23:17:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:1.152277946472168 norm:0.0011837691999971867 max memory_allocated 29276.68798828125 
[2025-03-01 23:18:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:1.1506141424179077 norm:0.0010803129989653826 max memory_allocated 29276.68798828125 
[2025-03-01 23:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:1.1489300727844238 norm:0.001038762042298913 max memory_allocated 29276.68798828125 
[2025-03-01 23:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:1.1479920148849487 norm:0.001003888202831149 max memory_allocated 29276.68798828125 
[2025-03-01 23:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:1.146841049194336 norm:0.000984914950095117 max memory_allocated 29276.68798828125 
[2025-03-01 23:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:1.1465438604354858 norm:0.0009687811834737659 max memory_allocated 29276.68798828125 
[2025-03-01 23:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:1.1454365253448486 norm:0.0009571475093252957 max memory_allocated 29276.68798828125 
[2025-03-01 23:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:1.1455169916152954 norm:0.0009313572663813829 max memory_allocated 29276.68798828125 
[2025-03-01 23:24:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:1.144440770149231 norm:0.0009383120341226459 max memory_allocated 29276.68798828125 
[2025-03-01 23:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:1.1446425914764404 norm:0.0009070533560588956 max memory_allocated 29276.68798828125 
[2025-03-01 23:25:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:1.143625020980835 norm:0.0009009934728965163 max memory_allocated 29276.68798828125 
[2025-03-01 23:26:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:1.1438255310058594 norm:0.0008803328964859247 max memory_allocated 29276.68798828125 
[2025-03-01 23:27:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:1.1431418657302856 norm:0.0008747661486268044 max memory_allocated 29276.68798828125 
[2025-03-01 23:27:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-01 23:28:36 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:1.309248924255371 norm:0.016113709658384323 max memory_allocated 29276.87548828125 
[2025-03-01 23:29:26 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:1.2964661121368408 norm:0.009947980754077435 max memory_allocated 29276.87548828125 
[2025-03-01 23:30:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:1.281636357307434 norm:0.006610425189137459 max memory_allocated 29276.87548828125 
[2025-03-01 23:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:1.274154782295227 norm:0.004973533097654581 max memory_allocated 29276.87548828125 
[2025-03-01 23:31:54 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:1.270258903503418 norm:0.0036048516631126404 max memory_allocated 29276.87548828125 
[2025-03-01 23:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:1.26669180393219 norm:0.002300902269780636 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:34 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:1.2636218070983887 norm:0.0018529118970036507 max memory_allocated 29276.87548828125 
[2025-03-01 23:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:1.2613497972488403 norm:0.0018587018130347133 max memory_allocated 29276.87548828125 
[2025-03-01 23:35:13 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:1.2589328289031982 norm:0.0016542506637051702 max memory_allocated 29276.87548828125 
[2025-03-01 23:36:02 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:1.2582114934921265 norm:0.001772986608557403 max memory_allocated 29276.87548828125 
[2025-03-01 23:36:52 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:1.2564406394958496 norm:0.0015673968009650707 max memory_allocated 29276.87548828125 
[2025-03-01 23:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:1.2564315795898438 norm:0.0017379764467477798 max memory_allocated 29276.87548828125 
[2025-03-01 23:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:1.25373113155365 norm:0.0013464720686897635 max memory_allocated 29276.87548828125 
[2025-03-01 23:39:20 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:1.2554556131362915 norm:0.0017730827676132321 max memory_allocated 29276.87548828125 
[2025-03-01 23:40:10 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:1.2528738975524902 norm:0.0013710178900510073 max memory_allocated 29276.87548828125 
[2025-03-01 23:41:00 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:1.253588080406189 norm:0.001541256788186729 max memory_allocated 29276.87548828125 
[2025-03-01 23:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:1.250996708869934 norm:0.0012173822615295649 max memory_allocated 29276.87548828125 
[2025-03-01 23:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:1.2526966333389282 norm:0.0015129171079024673 max memory_allocated 29276.87548828125 
[2025-03-01 23:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:1.2503749132156372 norm:0.001201693550683558 max memory_allocated 29276.87548828125 
[2025-03-01 23:44:18 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:1.2510863542556763 norm:0.0014274847926571965 max memory_allocated 29276.87548828125 
[2025-03-01 23:44:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-01 23:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:1.4212427139282227 norm:0.013089722953736782 max memory_allocated 29277.06298828125 
[2025-03-01 23:46:16 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:1.4084551334381104 norm:0.009501603431999683 max memory_allocated 29277.06298828125 
[2025-03-01 23:47:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:1.3936004638671875 norm:0.007311645895242691 max memory_allocated 29277.06298828125 
[2025-03-01 23:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:1.3870410919189453 norm:0.005810716189444065 max memory_allocated 29277.06298828125 
[2025-03-01 23:48:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:1.3833093643188477 norm:0.004860022105276585 max memory_allocated 29277.06298828125 
[2025-03-01 23:49:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:1.3798273801803589 norm:0.00429493235424161 max memory_allocated 29277.06298828125 
[2025-03-01 23:50:24 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:1.375406265258789 norm:0.003657398046925664 max memory_allocated 29277.06298828125 
[2025-03-01 23:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:1.3736844062805176 norm:0.0032869975548237562 max memory_allocated 29277.06298828125 
[2025-03-01 23:52:03 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:1.370072841644287 norm:0.0028117166366428137 max memory_allocated 29277.06298828125 
[2025-03-01 23:52:53 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:1.3698289394378662 norm:0.002499581081792712 max memory_allocated 29277.06298828125 
[2025-03-01 23:53:42 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:1.3677420616149902 norm:0.0022456133738160133 max memory_allocated 29277.06298828125 
[2025-03-01 23:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:1.3676135540008545 norm:0.002254689810797572 max memory_allocated 29277.06298828125 
[2025-03-01 23:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:1.365678071975708 norm:0.0020915386267006397 max memory_allocated 29277.06298828125 
[2025-03-01 23:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:1.3654695749282837 norm:0.0021020665299147367 max memory_allocated 29277.06298828125 
[2025-03-01 23:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:1.363061547279358 norm:0.0019306702306494117 max memory_allocated 29277.06298828125 
[2025-03-01 23:57:50 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:1.3642077445983887 norm:0.0018955364357680082 max memory_allocated 29277.06298828125 
[2025-03-01 23:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:1.3627885580062866 norm:0.0015793992206454277 max memory_allocated 29277.06298828125 
[2025-03-01 23:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:1.3621069192886353 norm:0.0018816320225596428 max memory_allocated 29277.06298828125 
[2025-03-02 00:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:1.3611969947814941 norm:0.0015101450262591243 max memory_allocated 29277.06298828125 
[2025-03-02 00:01:09 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:1.3609927892684937 norm:0.0017564855515956879 max memory_allocated 29277.06298828125 
[2025-03-02 00:01:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 00:02:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:1.5552603006362915 norm:0.01300370879471302 max memory_allocated 29277.25048828125 
[2025-03-02 00:03:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:1.540626049041748 norm:0.008044194430112839 max memory_allocated 29277.25048828125 
[2025-03-02 00:03:56 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:1.5241001844406128 norm:0.005437307059764862 max memory_allocated 29277.25048828125 
[2025-03-02 00:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:1.516109585762024 norm:0.003992331679910421 max memory_allocated 29277.25048828125 
[2025-03-02 00:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:1.5114846229553223 norm:0.0033607645891606808 max memory_allocated 29277.25048828125 
[2025-03-02 00:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:1.507918357849121 norm:0.0027585914358496666 max memory_allocated 29277.25048828125 
[2025-03-02 00:07:15 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:1.5042134523391724 norm:0.0022647937294095755 max memory_allocated 29277.25048828125 
[2025-03-02 00:08:04 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:1.5010221004486084 norm:0.00199893768876791 max memory_allocated 29277.25048828125 
[2025-03-02 00:08:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:1.4983513355255127 norm:0.0017368394182994962 max memory_allocated 29277.25048828125 
[2025-03-02 00:09:44 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:1.4962825775146484 norm:0.0016448613023385406 max memory_allocated 29277.25048828125 
[2025-03-02 00:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:1.4943833351135254 norm:0.0015668682754039764 max memory_allocated 29277.25048828125 
[2025-03-02 00:11:23 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:1.4929726123809814 norm:0.0015043445164337754 max memory_allocated 29277.25048828125 
[2025-03-02 00:12:12 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:1.4919981956481934 norm:0.0014013254549354315 max memory_allocated 29277.25048828125 
[2025-03-02 00:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:1.490595817565918 norm:0.0013431772822514176 max memory_allocated 29277.25048828125 
[2025-03-02 00:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:1.4903558492660522 norm:0.00127783149946481 max memory_allocated 29277.25048828125 
[2025-03-02 00:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:1.4889862537384033 norm:0.0011970055056735873 max memory_allocated 29277.25048828125 
[2025-03-02 00:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:1.4890369176864624 norm:0.0011479145614430308 max memory_allocated 29277.25048828125 
[2025-03-02 00:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:1.487339973449707 norm:0.0011035726638510823 max memory_allocated 29277.25048828125 
[2025-03-02 00:17:10 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:1.4882621765136719 norm:0.001073690364137292 max memory_allocated 29277.25048828125 
[2025-03-02 00:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:1.4862626791000366 norm:0.0010284647578373551 max memory_allocated 29277.25048828125 
[2025-03-02 00:18:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 00:19:08 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:1.7035613059997559 norm:0.006153006572276354 max memory_allocated 29277.43798828125 
[2025-03-02 00:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:1.6899049282073975 norm:0.0043958630412817 max memory_allocated 29277.43798828125 
[2025-03-02 00:20:47 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:1.6738444566726685 norm:0.003522306215018034 max memory_allocated 29277.43798828125 
[2025-03-02 00:21:37 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:1.664489984512329 norm:0.0030491063371300697 max memory_allocated 29277.43798828125 
[2025-03-02 00:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:1.6592000722885132 norm:0.0027550780214369297 max memory_allocated 29277.43798828125 
[2025-03-02 00:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:1.6542160511016846 norm:0.0024661929346621037 max memory_allocated 29277.43798828125 
[2025-03-02 00:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:1.6513186693191528 norm:0.002334596822038293 max memory_allocated 29277.43798828125 
[2025-03-02 00:24:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:1.6460870504379272 norm:0.0020787804387509823 max memory_allocated 29277.43798828125 
[2025-03-02 00:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:1.6459168195724487 norm:0.002185691148042679 max memory_allocated 29277.43798828125 
[2025-03-02 00:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:1.6408445835113525 norm:0.001905988552607596 max memory_allocated 29277.43798828125 
[2025-03-02 00:27:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:1.6419647932052612 norm:0.001919334172271192 max memory_allocated 29277.43798828125 
[2025-03-02 00:28:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:1.6371681690216064 norm:0.0017000812804326415 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:1.6387696266174316 norm:0.0017548855394124985 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:1.6340240240097046 norm:0.0015393393114209175 max memory_allocated 29277.43798828125 
[2025-03-02 00:30:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:1.6359354257583618 norm:0.0016730079660192132 max memory_allocated 29277.43798828125 
[2025-03-02 00:31:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:1.6313382387161255 norm:0.00150798331014812 max memory_allocated 29277.43798828125 
[2025-03-02 00:32:22 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:1.634216547012329 norm:0.001655678846873343 max memory_allocated 29277.43798828125 
[2025-03-02 00:33:12 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:1.6294461488723755 norm:0.0014104752335697412 max memory_allocated 29277.43798828125 
[2025-03-02 00:34:02 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:1.6332511901855469 norm:0.0015685007674619555 max memory_allocated 29277.43798828125 
[2025-03-02 00:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:1.6275999546051025 norm:0.0013471172424033284 max memory_allocated 29277.43798828125 
[2025-03-02 00:35:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 00:35:10 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:35:59 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:1.9031660556793213 norm:0.036007050424814224 max memory_allocated 29277.77001953125 
[2025-03-02 00:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:1.8833787441253662 norm:0.032345399260520935 max memory_allocated 29277.77001953125 
[2025-03-02 00:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:1.8659394979476929 norm:0.030327236279845238 max memory_allocated 29277.77001953125 
[2025-03-02 00:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:1.8543787002563477 norm:0.028202025219798088 max memory_allocated 29277.77001953125 
[2025-03-02 00:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:1.8441946506500244 norm:0.025117697194218636 max memory_allocated 29277.77001953125 
[2025-03-02 00:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:1.8213599920272827 norm:0.020164962857961655 max memory_allocated 29277.77001953125 
[2025-03-02 00:40:58 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:1.8038386106491089 norm:0.015790365636348724 max memory_allocated 29277.77001953125 
[2025-03-02 00:41:48 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:1.8042964935302734 norm:0.018428854644298553 max memory_allocated 29277.77001953125 
[2025-03-02 00:42:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:1.8179655075073242 norm:0.02557029388844967 max memory_allocated 29277.77001953125 
[2025-03-02 00:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:1.8279117345809937 norm:0.022779101505875587 max memory_allocated 29277.77001953125 
[2025-03-02 00:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:1.8060588836669922 norm:0.015443052165210247 max memory_allocated 29277.77001953125 
[2025-03-02 00:45:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:1.78255033493042 norm:0.010680385865271091 max memory_allocated 29277.77001953125 
[2025-03-02 00:45:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:1.7780927419662476 norm:0.009852469898760319 max memory_allocated 29277.77001953125 
[2025-03-02 00:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:1.7772412300109863 norm:0.010117431171238422 max memory_allocated 29277.77001953125 
[2025-03-02 00:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:1.7864279747009277 norm:0.013157906010746956 max memory_allocated 29277.77001953125 
[2025-03-02 00:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:1.785994291305542 norm:0.013500436209142208 max memory_allocated 29277.77001953125 
[2025-03-02 00:49:16 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:1.7859216928482056 norm:0.013671833090484142 max memory_allocated 29277.77001953125 
[2025-03-02 00:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:1.7697455883026123 norm:0.010015787556767464 max memory_allocated 29277.77001953125 
[2025-03-02 00:50:56 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:1.771301031112671 norm:0.01150742918252945 max memory_allocated 29277.77001953125 
[2025-03-02 00:51:45 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:1.7720050811767578 norm:0.012508268468081951 max memory_allocated 29277.77001953125 
[2025-03-02 00:52:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 00:52:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:52:53 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:2.078476667404175 norm:0.0378238745033741 max memory_allocated 29277.95751953125 
[2025-03-02 00:53:43 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:2.060798406600952 norm:0.03765236586332321 max memory_allocated 29277.95751953125 
[2025-03-02 00:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:2.044377088546753 norm:0.03309363126754761 max memory_allocated 29277.95751953125 
[2025-03-02 00:55:23 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:2.0161921977996826 norm:0.025275303050875664 max memory_allocated 29277.95751953125 
[2025-03-02 00:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:1.9890822172164917 norm:0.017623551189899445 max memory_allocated 29277.95751953125 
[2025-03-02 00:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:1.9925824403762817 norm:0.025130541995167732 max memory_allocated 29277.95751953125 
[2025-03-02 00:57:52 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:2.010802984237671 norm:0.04053385555744171 max memory_allocated 29277.95751953125 
[2025-03-02 00:58:42 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:1.9785552024841309 norm:0.01720276288688183 max memory_allocated 29277.95751953125 
[2025-03-02 00:59:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:1.9626837968826294 norm:0.015429310500621796 max memory_allocated 29277.95751953125 
[2025-03-02 01:00:21 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:1.9550249576568604 norm:0.012032034806907177 max memory_allocated 29277.95751953125 
[2025-03-02 01:01:11 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:1.9524149894714355 norm:0.010909056290984154 max memory_allocated 29277.95751953125 
[2025-03-02 01:02:01 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:1.9527571201324463 norm:0.012823048047721386 max memory_allocated 29277.95751953125 
[2025-03-02 01:02:51 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:1.9542148113250732 norm:0.011649565771222115 max memory_allocated 29277.95751953125 
[2025-03-02 01:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:1.9477958679199219 norm:0.01073484681546688 max memory_allocated 29277.95751953125 
[2025-03-02 01:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:1.9450491666793823 norm:0.012863298878073692 max memory_allocated 29277.95751953125 
[2025-03-02 01:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:1.942101240158081 norm:0.011886881664395332 max memory_allocated 29277.95751953125 
[2025-03-02 01:06:10 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:1.9441941976547241 norm:0.015126336365938187 max memory_allocated 29277.95751953125 
[2025-03-02 01:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:1.9405940771102905 norm:0.016095204278826714 max memory_allocated 29277.95751953125 
[2025-03-02 01:07:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:1.949803352355957 norm:0.01559816487133503 max memory_allocated 29277.95751953125 
[2025-03-02 01:08:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:1.9369274377822876 norm:0.01645749621093273 max memory_allocated 29277.95751953125 
[2025-03-02 01:08:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 01:08:58 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:09:48 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:2.4054481983184814 norm:0.057548776268959045 max memory_allocated 29278.14501953125 
[2025-03-02 01:10:37 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:2.378582000732422 norm:0.05388981103897095 max memory_allocated 29278.14501953125 
[2025-03-02 01:11:27 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:2.355335235595703 norm:0.044536568224430084 max memory_allocated 29278.14501953125 
[2025-03-02 01:12:17 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:2.3355298042297363 norm:0.036078449338674545 max memory_allocated 29278.14501953125 
[2025-03-02 01:13:07 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:2.3180930614471436 norm:0.027828514575958252 max memory_allocated 29278.14501953125 
[2025-03-02 01:13:56 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:2.303180694580078 norm:0.027042903006076813 max memory_allocated 29278.14501953125 
[2025-03-02 01:14:46 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:2.2824888229370117 norm:0.020422128960490227 max memory_allocated 29278.14501953125 
[2025-03-02 01:15:36 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:2.286402702331543 norm:0.028171610087156296 max memory_allocated 29278.14501953125 
[2025-03-02 01:16:26 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:2.279432773590088 norm:0.02145962417125702 max memory_allocated 29278.14501953125 
[2025-03-02 01:17:15 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:2.2581119537353516 norm:0.015886714681982994 max memory_allocated 29278.14501953125 
[2025-03-02 01:18:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:2.2696645259857178 norm:0.015734754502773285 max memory_allocated 29278.14501953125 
[2025-03-02 01:18:55 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:2.256470203399658 norm:0.01989086903631687 max memory_allocated 29278.14501953125 
[2025-03-02 01:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:2.2710397243499756 norm:0.012681820429861546 max memory_allocated 29278.14501953125 
[2025-03-02 01:20:35 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:2.2462236881256104 norm:0.012511802837252617 max memory_allocated 29278.14501953125 
[2025-03-02 01:21:24 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:2.2465550899505615 norm:0.016074934974312782 max memory_allocated 29278.14501953125 
[2025-03-02 01:22:14 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:2.255232572555542 norm:0.012607419863343239 max memory_allocated 29278.14501953125 
[2025-03-02 01:23:04 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:2.2362890243530273 norm:0.011444577015936375 max memory_allocated 29278.14501953125 
[2025-03-02 01:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:2.238499164581299 norm:0.018794547766447067 max memory_allocated 29278.14501953125 
[2025-03-02 01:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:2.2348709106445312 norm:0.016083257272839546 max memory_allocated 29278.14501953125 
[2025-03-02 01:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:2.241894245147705 norm:0.01702122390270233 max memory_allocated 29278.14501953125 
[2025-03-02 01:25:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 01:25:52 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:26:42 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:3.373432159423828 norm:0.16907235980033875 max memory_allocated 29278.33251953125 
[2025-03-02 01:27:32 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:3.178595542907715 norm:0.12683430314064026 max memory_allocated 29278.33251953125 
[2025-03-02 01:28:21 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:3.0997350215911865 norm:0.115454763174057 max memory_allocated 29278.33251953125 
[2025-03-02 01:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:3.0285253524780273 norm:0.09699711203575134 max memory_allocated 29278.33251953125 
[2025-03-02 01:30:01 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:2.979494571685791 norm:0.07792480289936066 max memory_allocated 29278.33251953125 
[2025-03-02 01:30:50 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:2.953594446182251 norm:0.06961314380168915 max memory_allocated 29278.33251953125 
[2025-03-02 01:31:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:2.9337401390075684 norm:0.062415674328804016 max memory_allocated 29278.33251953125 
[2025-03-02 01:32:30 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:2.9179792404174805 norm:0.05637792497873306 max memory_allocated 29278.33251953125 
[2025-03-02 01:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:2.9070911407470703 norm:0.051957692950963974 max memory_allocated 29278.33251953125 
[2025-03-02 01:34:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:2.8956220149993896 norm:0.047445427626371384 max memory_allocated 29278.33251953125 
[2025-03-02 01:34:59 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:2.8853259086608887 norm:0.044703591614961624 max memory_allocated 29278.33251953125 
[2025-03-02 01:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:2.8759078979492188 norm:0.04227215424180031 max memory_allocated 29278.33251953125 
[2025-03-02 01:36:39 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:2.867333173751831 norm:0.04139682278037071 max memory_allocated 29278.33251953125 
[2025-03-02 01:37:28 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:2.8603498935699463 norm:0.040140267461538315 max memory_allocated 29278.33251953125 
[2025-03-02 01:38:18 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:2.853428840637207 norm:0.03974350169301033 max memory_allocated 29278.33251953125 
[2025-03-02 01:39:08 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:2.8465137481689453 norm:0.03864078223705292 max memory_allocated 29278.33251953125 
[2025-03-02 01:39:58 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:2.841506004333496 norm:0.038712143898010254 max memory_allocated 29278.33251953125 
[2025-03-02 01:40:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:2.837130546569824 norm:0.03848157823085785 max memory_allocated 29278.33251953125 
[2025-03-02 01:41:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:2.8366897106170654 norm:0.03913804516196251 max memory_allocated 29278.33251953125 
[2025-03-02 01:42:27 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:2.8351783752441406 norm:0.040772631764411926 max memory_allocated 29278.33251953125 
[2025-03-02 01:42:42 root] (main_calib_config2.py 380): INFO 40459.253714084625
[2025-03-02 01:42:52 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-02 01:44:48 root] (main_calib_config2.py 159): INFO wikitext2 : 7.614242076873779
[2025-03-02 01:44:48 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-02 01:47:47 root] (main_calib_config2.py 159): INFO c4 : 10.348816871643066
[2025-03-02 03:54:21 root] (main_calib_config2.py 170): INFO {'wikitext2': 7.614242076873779, 'c4': 10.348816871643066, 'results': {'boolq': {'acc': 0.6440366972477064, 'acc_stderr': 0.008374337517726581}, 'piqa': {'acc': 0.7274211099020674, 'acc_stderr': 0.01038925680329601, 'acc_norm': 0.7290533188248096, 'acc_norm_stderr': 0.010369718937426844}, 'arc_challenge': {'acc': 0.3319112627986348, 'acc_stderr': 0.013760988200880543, 'acc_norm': 0.35494880546075086, 'acc_norm_stderr': 0.013983036904094095}, 'winogrande': {'acc': 0.5887924230465666, 'acc_stderr': 0.013829128358676872}, 'arc_easy': {'acc': 0.609006734006734, 'acc_stderr': 0.01001299223254063, 'acc_norm': 0.48947811447811446, 'acc_norm_stderr': 0.010257511546488232}, 'hellaswag': {'acc': 0.5037841067516431, 'acc_stderr': 0.004989638507409934, 'acc_norm': 0.6545508862776339, 'acc_norm_stderr': 0.004745426656377576}}, 'versions': {'boolq': 1, 'piqa': 0, 'arc_challenge': 0, 'winogrande': 0, 'arc_easy': 0, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
