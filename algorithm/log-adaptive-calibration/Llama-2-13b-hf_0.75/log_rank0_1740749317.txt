[2025-02-28 13:28:37 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.75', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.75.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:28:46 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:28:46 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:28:47 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:28:47 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.75.pkl
[2025-02-28 13:28:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:29:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.006719864904880524 norm:0.011737397871911526 max memory_allocated 29271.02001953125 
[2025-02-28 13:30:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0037381844595074654 norm:0.006882166489958763 max memory_allocated 29271.02001953125 
[2025-02-28 13:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.003172470023855567 norm:0.005392225459218025 max memory_allocated 29271.02001953125 
[2025-02-28 13:32:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0028912248089909554 norm:0.004437804222106934 max memory_allocated 29271.02001953125 
[2025-02-28 13:32:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0026439845096319914 norm:0.0034606135450303555 max memory_allocated 29271.02001953125 
[2025-02-28 13:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.00243490026332438 norm:0.0027642783243209124 max memory_allocated 29271.02001953125 
[2025-02-28 13:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.002337272046133876 norm:0.002347674686461687 max memory_allocated 29271.02001953125 
[2025-02-28 13:35:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0023308689706027508 norm:0.002190499333664775 max memory_allocated 29271.02001953125 
[2025-02-28 13:35:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.00234104017727077 norm:0.0019631909672170877 max memory_allocated 29271.02001953125 
[2025-02-28 13:36:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.002305649220943451 norm:0.001647288678213954 max memory_allocated 29271.02001953125 
[2025-02-28 13:37:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0021788938902318478 norm:0.001565809128805995 max memory_allocated 29271.02001953125 
[2025-02-28 13:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.002160473493859172 norm:0.0013407141668722034 max memory_allocated 29271.02001953125 
[2025-02-28 13:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.00214828341268003 norm:0.0012894038809463382 max memory_allocated 29271.02001953125 
[2025-02-28 13:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.002198288217186928 norm:0.0012202714569866657 max memory_allocated 29271.02001953125 
[2025-02-28 13:40:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.002118276432156563 norm:0.001123432768508792 max memory_allocated 29271.02001953125 
[2025-02-28 13:41:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0020716991275548935 norm:0.0010376516729593277 max memory_allocated 29271.02001953125 
[2025-02-28 13:42:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0020776784513145685 norm:0.0009972242405638099 max memory_allocated 29271.02001953125 
[2025-02-28 13:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.002092581009492278 norm:0.0009645596146583557 max memory_allocated 29271.02001953125 
[2025-02-28 13:43:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0020974737126380205 norm:0.001019984600134194 max memory_allocated 29271.02001953125 
[2025-02-28 13:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0021289123687893152 norm:0.0009991961997002363 max memory_allocated 29271.02001953125 
[2025-02-28 13:44:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:44:41 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.013426173478364944 norm:0.010062411427497864 max memory_allocated 29271.02001953125 
[2025-02-28 13:46:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.009021101519465446 norm:0.006484918296337128 max memory_allocated 29271.02001953125 
[2025-02-28 13:46:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.007763777859508991 norm:0.004610050469636917 max memory_allocated 29271.02001953125 
[2025-02-28 13:47:45 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.007156441919505596 norm:0.003523800754919648 max memory_allocated 29271.02001953125 
[2025-02-28 13:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.006811362691223621 norm:0.002959863282740116 max memory_allocated 29271.02001953125 
[2025-02-28 13:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.006626534275710583 norm:0.00258744228631258 max memory_allocated 29271.02001953125 
[2025-02-28 13:50:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.006494077853858471 norm:0.002329680137336254 max memory_allocated 29271.02001953125 
[2025-02-28 13:50:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.006393440533429384 norm:0.002093852497637272 max memory_allocated 29271.02001953125 
[2025-02-28 13:51:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.006307942792773247 norm:0.00188293750397861 max memory_allocated 29271.02001953125 
[2025-02-28 13:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.006221328396350145 norm:0.0016649237368255854 max memory_allocated 29271.02001953125 
[2025-02-28 13:53:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.006126610096544027 norm:0.0014777830801904202 max memory_allocated 29271.02001953125 
[2025-02-28 13:53:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.006048896815627813 norm:0.0013263835571706295 max memory_allocated 29271.02001953125 
[2025-02-28 13:54:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.006013583391904831 norm:0.0012165377847850323 max memory_allocated 29271.02001953125 
[2025-02-28 13:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.005989494733512402 norm:0.001161367865279317 max memory_allocated 29271.02001953125 
[2025-02-28 13:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.0059331669472157955 norm:0.0010846006916835904 max memory_allocated 29271.02001953125 
[2025-02-28 13:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.005902464035898447 norm:0.0010731398360803723 max memory_allocated 29271.02001953125 
[2025-02-28 13:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.0058822487480938435 norm:0.0010698124533519149 max memory_allocated 29271.02001953125 
[2025-02-28 13:58:32 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.005899007897824049 norm:0.0011174409883096814 max memory_allocated 29271.02001953125 
[2025-02-28 13:59:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.005962751340121031 norm:0.0011952172499150038 max memory_allocated 29271.02001953125 
[2025-02-28 14:00:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.005980281159281731 norm:0.0011954826768487692 max memory_allocated 29271.02001953125 
[2025-02-28 14:00:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 14:00:21 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 14:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.014011435210704803 norm:0.004373827017843723 max memory_allocated 29271.02001953125 
[2025-02-28 14:01:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.011123870499432087 norm:0.003457664744928479 max memory_allocated 29271.02001953125 
[2025-02-28 14:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.010275408625602722 norm:0.0026851878501474857 max memory_allocated 29271.02001953125 
[2025-02-28 14:03:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.009889299049973488 norm:0.0023212628439068794 max memory_allocated 29271.02001953125 
[2025-02-28 14:04:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.00960865430533886 norm:0.0020386134274303913 max memory_allocated 29271.02001953125 
[2025-02-28 14:04:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.009362529031932354 norm:0.0017645424231886864 max memory_allocated 29271.02001953125 
[2025-02-28 14:05:45 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.009081494994461536 norm:0.001479118363931775 max memory_allocated 29271.02001953125 
[2025-02-28 14:06:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.00886162556707859 norm:0.0012940369779244065 max memory_allocated 29271.02001953125 
[2025-02-28 14:07:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.008708517998456955 norm:0.0011568756308406591 max memory_allocated 29271.02001953125 
[2025-02-28 14:08:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.008642159402370453 norm:0.0010294988751411438 max memory_allocated 29271.02001953125 
[2025-02-28 14:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.00860596913844347 norm:0.0009747433359734714 max memory_allocated 29271.02001953125 
[2025-02-28 14:09:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.00853741355240345 norm:0.0008340174681507051 max memory_allocated 29271.02001953125 
[2025-02-28 14:10:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.00858011282980442 norm:0.0009592120768502355 max memory_allocated 29271.02001953125 
[2025-02-28 14:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.008547172881662846 norm:0.0008553875959478319 max memory_allocated 29271.02001953125 
[2025-02-28 14:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.008451463654637337 norm:0.000694225775077939 max memory_allocated 29271.02001953125 
[2025-02-28 14:12:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.008451440371572971 norm:0.0006644546519964933 max memory_allocated 29271.02001953125 
[2025-02-28 14:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.008463582023978233 norm:0.0007014594157226384 max memory_allocated 29271.02001953125 
[2025-02-28 14:14:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.008540470153093338 norm:0.0008152913069352508 max memory_allocated 29271.02001953125 
[2025-02-28 14:15:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.008527792058885098 norm:0.0006355927907861769 max memory_allocated 29271.02001953125 
[2025-02-28 14:15:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.00843733735382557 norm:0.000575942627619952 max memory_allocated 29271.02001953125 
[2025-02-28 14:15:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 14:16:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.13364721834659576 norm:0.017437316477298737 max memory_allocated 29271.02001953125 
[2025-02-28 14:17:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.09792851656675339 norm:0.011201552115380764 max memory_allocated 29271.02001953125 
[2025-02-28 14:18:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.06565016508102417 norm:0.009174006059765816 max memory_allocated 29271.02001953125 
[2025-02-28 14:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.05977017804980278 norm:0.010106929577887058 max memory_allocated 29271.02001953125 
[2025-02-28 14:19:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.050366077572107315 norm:0.008425437845289707 max memory_allocated 29271.02001953125 
[2025-02-28 14:20:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.046816930174827576 norm:0.0073962765745818615 max memory_allocated 29271.02001953125 
[2025-02-28 14:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.04325392097234726 norm:0.006048654671758413 max memory_allocated 29271.02001953125 
[2025-02-28 14:22:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.041667595505714417 norm:0.005793246440589428 max memory_allocated 29271.02001953125 
[2025-02-28 14:22:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.04158087819814682 norm:0.005718728061765432 max memory_allocated 29271.02001953125 
[2025-02-28 14:23:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.040792133659124374 norm:0.0056802802719175816 max memory_allocated 29271.02001953125 
[2025-02-28 14:24:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.04095819965004921 norm:0.00532193761318922 max memory_allocated 29271.02001953125 
[2025-02-28 14:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.040921032428741455 norm:0.005704742390662432 max memory_allocated 29271.02001953125 
[2025-02-28 14:26:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.04058210179209709 norm:0.006229948718100786 max memory_allocated 29271.02001953125 
[2025-02-28 14:26:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.04079103469848633 norm:0.005847790278494358 max memory_allocated 29271.02001953125 
[2025-02-28 14:27:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.039969462901353836 norm:0.006068262737244368 max memory_allocated 29271.02001953125 
[2025-02-28 14:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.04029803350567818 norm:0.0056924764066934586 max memory_allocated 29271.02001953125 
[2025-02-28 14:29:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.04198590666055679 norm:0.006080202758312225 max memory_allocated 29271.02001953125 
[2025-02-28 14:29:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.040966808795928955 norm:0.006697452627122402 max memory_allocated 29271.02001953125 
[2025-02-28 14:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.03906228765845299 norm:0.006140152923762798 max memory_allocated 29271.02001953125 
[2025-02-28 14:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.036237556487321854 norm:0.0052298372611403465 max memory_allocated 29271.02001953125 
[2025-02-28 14:31:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.03704371675848961 norm:0.0006104137282818556 max memory_allocated 29271.62548828125 
[2025-02-28 14:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.03247511014342308 norm:0.000242895694100298 max memory_allocated 29271.62548828125 
[2025-02-28 14:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.029783427715301514 norm:0.0001347763609373942 max memory_allocated 29271.62548828125 
[2025-02-28 14:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.02911306917667389 norm:0.00010222557466477156 max memory_allocated 29271.62548828125 
[2025-02-28 14:35:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.028686223551630974 norm:8.707088272785768e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.028322305530309677 norm:7.87507087807171e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.028074556961655617 norm:7.611923501826823e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:37:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.02794209122657776 norm:7.381795148830861e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.027874041348695755 norm:7.253209332702681e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:39:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.027845080941915512 norm:7.16380964149721e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.027826374396681786 norm:7.194888894446194e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.02780647948384285 norm:7.226158049888909e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:41:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.02779538556933403 norm:7.253045623656362e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:42:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.027787990868091583 norm:7.238523539854214e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.027780575677752495 norm:7.397057197522372e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:43:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.02776995673775673 norm:7.405056385323405e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:44:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.027764376252889633 norm:7.465546514140442e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.02775874361395836 norm:7.363194890785962e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:46:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.0277499258518219 norm:7.378461305052042e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:47:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.027748286724090576 norm:7.391160761471838e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:47:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:48:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.040268827229738235 norm:0.00110998481977731 max memory_allocated 29271.62548828125 
[2025-02-28 14:48:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.034046560525894165 norm:0.00044440655619837344 max memory_allocated 29271.62548828125 
[2025-02-28 14:49:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.03199182078242302 norm:0.00023900889209471643 max memory_allocated 29271.62548828125 
[2025-02-28 14:50:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.03095526248216629 norm:0.00017807184485718608 max memory_allocated 29271.62548828125 
[2025-02-28 14:51:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.03021589294075966 norm:0.00015239306958392262 max memory_allocated 29271.62548828125 
[2025-02-28 14:51:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.029748618602752686 norm:0.00013576020137406886 max memory_allocated 29271.62548828125 
[2025-02-28 14:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.029452204704284668 norm:0.00012433876690920442 max memory_allocated 29271.62548828125 
[2025-02-28 14:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.02928842231631279 norm:0.00011276255099801347 max memory_allocated 29271.62548828125 
[2025-02-28 14:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.02920927293598652 norm:0.0001094959006877616 max memory_allocated 29271.62548828125 
[2025-02-28 14:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.02913968823850155 norm:0.00010752117668744177 max memory_allocated 29271.62548828125 
[2025-02-28 14:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.02909373678267002 norm:0.00010310774086974561 max memory_allocated 29271.62548828125 
[2025-02-28 14:56:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.029061300680041313 norm:9.998125460697338e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:57:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.02902277186512947 norm:9.817233512876555e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:58:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.02900146134197712 norm:9.519577724859118e-05 max memory_allocated 29271.62548828125 
[2025-02-28 14:58:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.029008740559220314 norm:0.00010050435230368748 max memory_allocated 29271.62548828125 
[2025-02-28 14:59:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.028988579288125038 norm:9.46857180679217e-05 max memory_allocated 29271.62548828125 
[2025-02-28 15:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.02898186631500721 norm:9.789909381652251e-05 max memory_allocated 29271.62548828125 
[2025-02-28 15:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.028966421261429787 norm:9.784522990230471e-05 max memory_allocated 29271.62548828125 
[2025-02-28 15:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.028942961245775223 norm:9.75033690338023e-05 max memory_allocated 29271.62548828125 
[2025-02-28 15:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.028933176770806313 norm:9.838539699558169e-05 max memory_allocated 29271.62548828125 
[2025-02-28 15:02:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 15:03:45 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.04284888878464699 norm:0.0013342343736439943 max memory_allocated 29271.62548828125 
[2025-02-28 15:04:31 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.036667197942733765 norm:0.0005603388999588788 max memory_allocated 29271.62548828125 
[2025-02-28 15:05:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.034373439848423004 norm:0.0003274356131441891 max memory_allocated 29271.62548828125 
[2025-02-28 15:06:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.033044882118701935 norm:0.00022550653375219554 max memory_allocated 29271.62548828125 
[2025-02-28 15:06:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.03219097480177879 norm:0.00018261959485244006 max memory_allocated 29271.62548828125 
[2025-02-28 15:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.03167076036334038 norm:0.00015617362805642188 max memory_allocated 29271.62548828125 
[2025-02-28 15:08:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.031394459307193756 norm:0.00014034434570930898 max memory_allocated 29271.62548828125 
[2025-02-28 15:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.03126216679811478 norm:0.00013529148418456316 max memory_allocated 29271.62548828125 
[2025-02-28 15:09:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.031167078763246536 norm:0.00013813872647006065 max memory_allocated 29271.62548828125 
[2025-02-28 15:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.031113268807530403 norm:0.00013257913815323263 max memory_allocated 29271.62548828125 
[2025-02-28 15:11:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.031062211841344833 norm:0.00012474220420699567 max memory_allocated 29271.62548828125 
[2025-02-28 15:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.031020918861031532 norm:0.00011877407814608887 max memory_allocated 29271.62548828125 
[2025-02-28 15:12:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.030996570363640785 norm:0.0001124257905757986 max memory_allocated 29271.62548828125 
[2025-02-28 15:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.03097175993025303 norm:0.00011968585749855265 max memory_allocated 29271.62548828125 
[2025-02-28 15:14:31 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.03097541630268097 norm:0.00012423245061654598 max memory_allocated 29271.62548828125 
[2025-02-28 15:15:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.030953720211982727 norm:0.00012998835882171988 max memory_allocated 29271.62548828125 
[2025-02-28 15:16:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.03094855323433876 norm:0.00013186490104999393 max memory_allocated 29271.62548828125 
[2025-02-28 15:16:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.030931727960705757 norm:0.00011682002514135092 max memory_allocated 29271.62548828125 
[2025-02-28 15:17:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.030923442915081978 norm:0.0001276371767744422 max memory_allocated 29271.62548828125 
[2025-02-28 15:18:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.03091634251177311 norm:0.00011998360423604026 max memory_allocated 29271.62548828125 
[2025-02-28 15:18:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 15:19:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.05200928449630737 norm:0.0014121055137366056 max memory_allocated 29272.18798828125 
[2025-02-28 15:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.04271094128489494 norm:0.0006116089061833918 max memory_allocated 29272.18798828125 
[2025-02-28 15:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.03930100426077843 norm:0.0003609467239584774 max memory_allocated 29272.18798828125 
[2025-02-28 15:21:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.03769553080201149 norm:0.0002743272634688765 max memory_allocated 29272.18798828125 
[2025-02-28 15:22:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.036808621138334274 norm:0.00024324477999471128 max memory_allocated 29272.18798828125 
[2025-02-28 15:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.03624863550066948 norm:0.00021960557205602527 max memory_allocated 29272.18798828125 
[2025-02-28 15:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.03581897169351578 norm:0.00019753498781938106 max memory_allocated 29272.18798828125 
[2025-02-28 15:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.03554443269968033 norm:0.00019147302373312414 max memory_allocated 29272.18798828125 
[2025-02-28 15:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.03537043556571007 norm:0.00018030080536846071 max memory_allocated 29272.18798828125 
[2025-02-28 15:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.03530845791101456 norm:0.00017986694001592696 max memory_allocated 29272.18798828125 
[2025-02-28 15:27:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.035258010029792786 norm:0.00017248182848561555 max memory_allocated 29272.18798828125 
[2025-02-28 15:27:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.035246286541223526 norm:0.0001751905947457999 max memory_allocated 29272.18798828125 
[2025-02-28 15:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.0352010615170002 norm:0.0001646155578782782 max memory_allocated 29272.18798828125 
[2025-02-28 15:29:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.035180021077394485 norm:0.00017168562044389546 max memory_allocated 29272.18798828125 
[2025-02-28 15:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.03514254465699196 norm:0.00016821391182020307 max memory_allocated 29272.18798828125 
[2025-02-28 15:30:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.03510238975286484 norm:0.00016344035975635052 max memory_allocated 29272.18798828125 
[2025-02-28 15:31:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.035090263932943344 norm:0.00016093443264253438 max memory_allocated 29272.18798828125 
[2025-02-28 15:32:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.03507017344236374 norm:0.0001529976725578308 max memory_allocated 29272.18798828125 
[2025-02-28 15:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.03504766896367073 norm:0.00015641518984921277 max memory_allocated 29272.18798828125 
[2025-02-28 15:34:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.034975674003362656 norm:0.0001537564239697531 max memory_allocated 29272.18798828125 
[2025-02-28 15:34:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 15:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.05165097117424011 norm:0.001304117264226079 max memory_allocated 29272.18798828125 
[2025-02-28 15:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.04452180117368698 norm:0.0006146725500002503 max memory_allocated 29272.18798828125 
[2025-02-28 15:36:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.04151647910475731 norm:0.0003639418864622712 max memory_allocated 29272.18798828125 
[2025-02-28 15:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.03988896682858467 norm:0.00025481381453573704 max memory_allocated 29272.18798828125 
[2025-02-28 15:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.03887815773487091 norm:0.00020149184274487197 max memory_allocated 29272.18798828125 
[2025-02-28 15:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.038301970809698105 norm:0.00017437833594158292 max memory_allocated 29272.18798828125 
[2025-02-28 15:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.03801439702510834 norm:0.00015870279457885772 max memory_allocated 29272.18798828125 
[2025-02-28 15:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.03783030807971954 norm:0.0001514114555902779 max memory_allocated 29272.18798828125 
[2025-02-28 15:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.0377131886780262 norm:0.00014306697994470596 max memory_allocated 29272.18798828125 
[2025-02-28 15:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.037636809051036835 norm:0.00013719631533604115 max memory_allocated 29272.18798828125 
[2025-02-28 15:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.03759084641933441 norm:0.00013451695849653333 max memory_allocated 29272.18798828125 
[2025-02-28 15:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.03754336014389992 norm:0.00013616992509923875 max memory_allocated 29272.18798828125 
[2025-02-28 15:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.03749126195907593 norm:0.00013121326628606766 max memory_allocated 29272.18798828125 
[2025-02-28 15:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.03747481852769852 norm:0.00013146561104804277 max memory_allocated 29272.18798828125 
[2025-02-28 15:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.037461329251527786 norm:0.00013349790242500603 max memory_allocated 29272.18798828125 
[2025-02-28 15:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.0374300554394722 norm:0.00012718109064735472 max memory_allocated 29272.18798828125 
[2025-02-28 15:47:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.03740913048386574 norm:0.000134686182718724 max memory_allocated 29272.18798828125 
[2025-02-28 15:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.03738901764154434 norm:0.00013086909893900156 max memory_allocated 29272.18798828125 
[2025-02-28 15:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.037383273243904114 norm:0.0001294990797759965 max memory_allocated 29272.18798828125 
[2025-02-28 15:49:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.03736695647239685 norm:0.00012781091209035367 max memory_allocated 29272.18798828125 
[2025-02-28 15:49:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 15:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.07302732020616531 norm:0.0028085571248084307 max memory_allocated 29272.18798828125 
[2025-02-28 15:51:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.055696822702884674 norm:0.001233101123943925 max memory_allocated 29272.18798828125 
[2025-02-28 15:52:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.048779312521219254 norm:0.0006481901509687304 max memory_allocated 29272.18798828125 
[2025-02-28 15:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.04592461511492729 norm:0.0004348976362962276 max memory_allocated 29272.18798828125 
[2025-02-28 15:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.04441988840699196 norm:0.0003460771404206753 max memory_allocated 29272.18798828125 
[2025-02-28 15:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.04354969412088394 norm:0.00029527643346227705 max memory_allocated 29272.18798828125 
[2025-02-28 15:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.043074123561382294 norm:0.0002769465500023216 max memory_allocated 29272.18798828125 
[2025-02-28 15:56:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.042745038866996765 norm:0.0002498519897926599 max memory_allocated 29272.18798828125 
[2025-02-28 15:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.04254896938800812 norm:0.0002465323777869344 max memory_allocated 29272.18798828125 
[2025-02-28 15:57:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.0424003042280674 norm:0.00023693391995038837 max memory_allocated 29272.18798828125 
[2025-02-28 15:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.04228164255619049 norm:0.0002228075172752142 max memory_allocated 29272.18798828125 
[2025-02-28 15:59:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.04215626046061516 norm:0.00021865512826479971 max memory_allocated 29272.18798828125 
[2025-02-28 15:59:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.04205615445971489 norm:0.0002237705048173666 max memory_allocated 29272.18798828125 
[2025-02-28 16:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.041965220123529434 norm:0.00020835627219639719 max memory_allocated 29272.18798828125 
[2025-02-28 16:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.04189683496952057 norm:0.00021334239863790572 max memory_allocated 29272.18798828125 
[2025-02-28 16:02:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.04181492328643799 norm:0.0001987855794141069 max memory_allocated 29272.18798828125 
[2025-02-28 16:03:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.041757982224226 norm:0.00020505799329839647 max memory_allocated 29272.18798828125 
[2025-02-28 16:03:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.041673749685287476 norm:0.00018854813242796808 max memory_allocated 29272.18798828125 
[2025-02-28 16:04:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.041631389409303665 norm:0.0001896966277854517 max memory_allocated 29272.18798828125 
[2025-02-28 16:05:22 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.04158985614776611 norm:0.00018142574117518961 max memory_allocated 29272.18798828125 
[2025-02-28 16:05:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 16:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.0563044473528862 norm:0.0012007283512502909 max memory_allocated 29272.18798828125 
[2025-02-28 16:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.05065448209643364 norm:0.0005812791059724987 max memory_allocated 29272.18798828125 
[2025-02-28 16:07:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.04676491767168045 norm:0.0003267349093221128 max memory_allocated 29272.18798828125 
[2025-02-28 16:08:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.04559185355901718 norm:0.00021261863003019243 max memory_allocated 29272.18798828125 
[2025-02-28 16:09:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.04491671919822693 norm:0.000153135450091213 max memory_allocated 29272.18798828125 
[2025-02-28 16:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.04454163834452629 norm:0.00012041977606713772 max memory_allocated 29272.18798828125 
[2025-02-28 16:11:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.0443587452173233 norm:0.0001043428128468804 max memory_allocated 29272.18798828125 
[2025-02-28 16:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.04427563399076462 norm:9.501768363406882e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.04422016069293022 norm:9.082971519092098e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.04417882859706879 norm:8.726285886950791e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:14:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.0441492423415184 norm:8.63486056914553e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:14:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.04412455856800079 norm:8.51910954224877e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:15:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.0441153310239315 norm:8.4841281932313e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:16:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.044097255915403366 norm:8.453044574707747e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.04407379776239395 norm:8.41629080241546e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:17:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.04406387358903885 norm:8.469350723316893e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.04405852407217026 norm:8.496916416333988e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.04404924437403679 norm:8.448160224361345e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:20:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.044043753296136856 norm:8.4752231487073e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:21:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.04403537139296532 norm:8.474470814689994e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:21:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 16:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.05815420299768448 norm:0.0006604103255085647 max memory_allocated 29272.18798828125 
[2025-02-28 16:22:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.053155481815338135 norm:0.00035337169538252056 max memory_allocated 29272.18798828125 
[2025-02-28 16:23:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.04944314435124397 norm:0.0002115212264470756 max memory_allocated 29272.18798828125 
[2025-02-28 16:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.04833337664604187 norm:0.00014157092664390802 max memory_allocated 29272.18798828125 
[2025-02-28 16:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.04770100861787796 norm:0.00010748791828518733 max memory_allocated 29272.18798828125 
[2025-02-28 16:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.04734751954674721 norm:9.434157982468605e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:26:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.04715651273727417 norm:8.917577360989526e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:27:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.047077298164367676 norm:8.809666178422049e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:28:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.047036055475473404 norm:8.792632434051484e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.047005973756313324 norm:8.78390419529751e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:29:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.04697330668568611 norm:8.76607809914276e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:30:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.046959228813648224 norm:8.901494584279135e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.046945977956056595 norm:8.773139416007325e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.04693644866347313 norm:8.811157749732956e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:32:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.04692859575152397 norm:8.860419620759785e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.046916741877794266 norm:8.562943548895419e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.0469096377491951 norm:8.52382872835733e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:35:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.046900540590286255 norm:8.470056491205469e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:35:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.046890079975128174 norm:8.453900227323174e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.046890322118997574 norm:8.4719191363547e-05 max memory_allocated 29272.18798828125 
[2025-02-28 16:36:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 16:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.0594203807413578 norm:0.0005966718890704215 max memory_allocated 29273.12548828125 
[2025-02-28 16:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.054480891674757004 norm:0.00030597689328715205 max memory_allocated 29273.12548828125 
[2025-02-28 16:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.05080394819378853 norm:0.00017743275384418666 max memory_allocated 29273.12548828125 
[2025-02-28 16:40:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.04978040233254433 norm:0.00012073376274202019 max memory_allocated 29273.12548828125 
[2025-02-28 16:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.04921625182032585 norm:9.532667172607034e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:41:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.04887738451361656 norm:8.367919508600608e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.04869937151670456 norm:7.824476051609963e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.04861070215702057 norm:7.524918328272179e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:43:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.04856857657432556 norm:7.407965313177556e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.04854161664843559 norm:7.342917524510995e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.048520877957344055 norm:7.32045155018568e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:46:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.04850360378623009 norm:7.385737262666225e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:46:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.04848840832710266 norm:7.417066080961376e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:47:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.04847755283117294 norm:7.435616862494498e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.048467736691236496 norm:7.422498310916126e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.04845650494098663 norm:7.405016367556527e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:50:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.048447806388139725 norm:7.365625788224861e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:50:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.04844214767217636 norm:7.3276023613289e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:51:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.04843636974692345 norm:7.39081806386821e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.0484321303665638 norm:7.496478065149859e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:52:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 16:53:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.06107021123170853 norm:0.0006799999391660094 max memory_allocated 29273.12548828125 
[2025-02-28 16:54:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.0563233308494091 norm:0.0003717506770044565 max memory_allocated 29273.12548828125 
[2025-02-28 16:54:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.05264100432395935 norm:0.00022699328837916255 max memory_allocated 29273.12548828125 
[2025-02-28 16:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.051565252244472504 norm:0.00015562769840471447 max memory_allocated 29273.12548828125 
[2025-02-28 16:56:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.05095807462930679 norm:0.00011512847413541749 max memory_allocated 29273.12548828125 
[2025-02-28 16:57:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.05060158669948578 norm:9.446763579035178e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:58:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.050415609031915665 norm:8.441456884611398e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:58:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.050318170338869095 norm:8.183704630937427e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:59:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.05026257783174515 norm:7.69591933931224e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:00:21 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.050228219479322433 norm:7.545850530732423e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.050198473036289215 norm:7.330186053877696e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:01:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.05017969012260437 norm:7.249884947668761e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.050162553787231445 norm:7.145969721022993e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:03:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.05014987289905548 norm:7.119623478502035e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.050138115882873535 norm:7.18663286534138e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.05013139173388481 norm:7.142528193071485e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.05012315511703491 norm:7.146815187297761e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:06:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.05011454597115517 norm:7.094795000739396e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:07:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.05010712891817093 norm:7.078629278112203e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:08:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.05010388791561127 norm:7.149059092625976e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:08:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 17:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.06278723478317261 norm:0.0007617475348524749 max memory_allocated 29273.12548828125 
[2025-02-28 17:09:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.057762861251831055 norm:0.0003648783313110471 max memory_allocated 29273.12548828125 
[2025-02-28 17:10:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.054107341915369034 norm:0.00019454087305348366 max memory_allocated 29273.12548828125 
[2025-02-28 17:11:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.05316042900085449 norm:0.0001313740503974259 max memory_allocated 29273.12548828125 
[2025-02-28 17:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.05261030048131943 norm:0.0001047225232468918 max memory_allocated 29273.12548828125 
[2025-02-28 17:12:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.0522497333586216 norm:9.249467984773219e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:13:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.05205533653497696 norm:8.608704956714064e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:14:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.05195178836584091 norm:8.27238181955181e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.051892295479774475 norm:8.032617915887386e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:16:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.051856204867362976 norm:8.018340304261073e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.05182560533285141 norm:7.938931230455637e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:17:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.05180220678448677 norm:7.941215153550729e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:18:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.05178472027182579 norm:7.98102846601978e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:19:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.051771100610494614 norm:8.018016524147242e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.05176173895597458 norm:8.043170964810997e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:20:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.05175583064556122 norm:8.057174272835255e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.051749683916568756 norm:8.138023258652538e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:22:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.051744915544986725 norm:8.363333472516388e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:22:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.05175154283642769 norm:8.273834828287363e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:23:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.051745932549238205 norm:8.354004967259243e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:23:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 17:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.06280389428138733 norm:0.0004227161989547312 max memory_allocated 29273.12548828125 
[2025-02-28 17:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.05832528695464134 norm:0.00022385020565707237 max memory_allocated 29273.12548828125 
[2025-02-28 17:26:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.05463859438896179 norm:0.00013676950766239315 max memory_allocated 29273.12548828125 
[2025-02-28 17:27:03 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.0537303127348423 norm:0.00010288238991051912 max memory_allocated 29273.12548828125 
[2025-02-28 17:27:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.05317425727844238 norm:8.641961903776973e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:28:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.052802566438913345 norm:7.618058589287102e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.052585750818252563 norm:7.07784784026444e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:30:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.05246483162045479 norm:6.75613628118299e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:30:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.05239901319146156 norm:6.542382470797747e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:31:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.052349530160427094 norm:6.3446415879298e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.05231765657663345 norm:6.264337571337819e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:33:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.0522875040769577 norm:6.200531788635999e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.0522674135863781 norm:6.177846080390736e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.05224933102726936 norm:6.184748781379312e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:35:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.05223199352622032 norm:6.140238838270307e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.05221891403198242 norm:6.189534906297922e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.052209533751010895 norm:6.208346894709393e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:37:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.052200134843587875 norm:6.16588004049845e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:38:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.05219418182969093 norm:6.201543874340132e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.05218715965747833 norm:6.220707291504368e-05 max memory_allocated 29273.12548828125 
[2025-02-28 17:39:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 17:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.0674961656332016 norm:0.001100943423807621 max memory_allocated 29273.12548828125 
[2025-02-28 17:41:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.06090027838945389 norm:0.0005367683479562402 max memory_allocated 29273.12548828125 
[2025-02-28 17:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.05796128138899803 norm:0.0003503253392409533 max memory_allocated 29273.12548828125 
[2025-02-28 17:42:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.05622304230928421 norm:0.0002525490999687463 max memory_allocated 29273.12548828125 
[2025-02-28 17:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.05528515577316284 norm:0.000209688107133843 max memory_allocated 29273.12548828125 
[2025-02-28 17:44:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.054674580693244934 norm:0.00018797334632836282 max memory_allocated 29273.12548828125 
[2025-02-28 17:45:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.05427331104874611 norm:0.00017273396952077746 max memory_allocated 29273.12548828125 
[2025-02-28 17:45:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.05401479825377464 norm:0.00015780226385686547 max memory_allocated 29273.12548828125 
[2025-02-28 17:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.05385042354464531 norm:0.00014910820755176246 max memory_allocated 29273.12548828125 
[2025-02-28 17:47:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.05374421551823616 norm:0.0001469819835620001 max memory_allocated 29273.12548828125 
[2025-02-28 17:48:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.05366566777229309 norm:0.00014401541557163 max memory_allocated 29273.12548828125 
[2025-02-28 17:48:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.05357404798269272 norm:0.00013613984629046172 max memory_allocated 29273.12548828125 
[2025-02-28 17:49:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.053484007716178894 norm:0.0001295989495702088 max memory_allocated 29273.12548828125 
[2025-02-28 17:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.05344345420598984 norm:0.00012553246051538736 max memory_allocated 29273.12548828125 
[2025-02-28 17:51:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.05340000241994858 norm:0.0001256425748579204 max memory_allocated 29273.12548828125 
[2025-02-28 17:51:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.05334245413541794 norm:0.0001236537646036595 max memory_allocated 29273.12548828125 
[2025-02-28 17:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.05327720195055008 norm:0.00011888756125699729 max memory_allocated 29273.12548828125 
[2025-02-28 17:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.05322229862213135 norm:0.0001172111151390709 max memory_allocated 29273.12548828125 
[2025-02-28 17:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.05318399891257286 norm:0.00011186584015376866 max memory_allocated 29273.12548828125 
[2025-02-28 17:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.053176991641521454 norm:0.00010822078183991835 max memory_allocated 29273.12548828125 
[2025-02-28 17:55:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 17:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.06401076167821884 norm:0.001007318263873458 max memory_allocated 29273.12548828125 
[2025-02-28 17:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.05967472493648529 norm:0.000543382135219872 max memory_allocated 29273.12548828125 
[2025-02-28 17:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.05758368968963623 norm:0.0003550637047737837 max memory_allocated 29273.12548828125 
[2025-02-28 17:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.05614110082387924 norm:0.00025536640896461904 max memory_allocated 29273.12548828125 
[2025-02-28 17:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.05532679334282875 norm:0.00021139960153959692 max memory_allocated 29273.12548828125 
[2025-02-28 17:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.0547822080552578 norm:0.00018407175957690924 max memory_allocated 29273.12548828125 
[2025-02-28 18:00:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.05446236580610275 norm:0.0001663560833549127 max memory_allocated 29273.12548828125 
[2025-02-28 18:01:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.05426511913537979 norm:0.00015701174561399966 max memory_allocated 29273.12548828125 
[2025-02-28 18:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.05413210391998291 norm:0.00014456664212048054 max memory_allocated 29273.12548828125 
[2025-02-28 18:03:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.054048046469688416 norm:0.0001420064363628626 max memory_allocated 29273.12548828125 
[2025-02-28 18:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.053974077105522156 norm:0.00013714944361709058 max memory_allocated 29273.12548828125 
[2025-02-28 18:04:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.053917884826660156 norm:0.00013198252418078482 max memory_allocated 29273.12548828125 
[2025-02-28 18:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.05388280749320984 norm:0.00013023789506405592 max memory_allocated 29273.12548828125 
[2025-02-28 18:06:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.053840406239032745 norm:0.00012658489868044853 max memory_allocated 29273.12548828125 
[2025-02-28 18:06:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.05379893630743027 norm:0.00012265401892364025 max memory_allocated 29273.12548828125 
[2025-02-28 18:07:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.05378224328160286 norm:0.0001220692356582731 max memory_allocated 29273.12548828125 
[2025-02-28 18:08:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.053748201578855515 norm:0.00012077140127075836 max memory_allocated 29273.12548828125 
[2025-02-28 18:09:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.05371851846575737 norm:0.00011760054621845484 max memory_allocated 29273.12548828125 
[2025-02-28 18:09:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.053693026304244995 norm:0.00011160228314111009 max memory_allocated 29273.12548828125 
[2025-02-28 18:10:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.0536821112036705 norm:0.0001138856096076779 max memory_allocated 29273.12548828125 
[2025-02-28 18:10:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 18:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.06359557062387466 norm:0.0007534995675086975 max memory_allocated 29273.25048828125 
[2025-02-28 18:12:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.05954093858599663 norm:0.00035359530011191964 max memory_allocated 29273.25048828125 
[2025-02-28 18:13:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.05790938436985016 norm:0.0002358959027333185 max memory_allocated 29273.25048828125 
[2025-02-28 18:14:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.05680222436785698 norm:0.0001821390469558537 max memory_allocated 29273.25048828125 
[2025-02-28 18:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.05601068586111069 norm:0.00015107812942005694 max memory_allocated 29273.25048828125 
[2025-02-28 18:15:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.05546461045742035 norm:0.0001315711415372789 max memory_allocated 29273.25048828125 
[2025-02-28 18:16:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.0551319494843483 norm:0.00011831998563138768 max memory_allocated 29273.25048828125 
[2025-02-28 18:17:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.05496605858206749 norm:0.0001092398670152761 max memory_allocated 29273.25048828125 
[2025-02-28 18:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.054885413497686386 norm:0.00010491551802260801 max memory_allocated 29273.25048828125 
[2025-02-28 18:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.05480360984802246 norm:9.924468031385913e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:19:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.054742492735385895 norm:9.695712651591748e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.054694827646017075 norm:9.493327524978667e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:20:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.05465516075491905 norm:9.01859239093028e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:21:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.05462276190519333 norm:8.851253369357437e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.054593876004219055 norm:8.524183067493141e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.05455855652689934 norm:8.38477790239267e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.05454052984714508 norm:8.044815331231803e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.05452074855566025 norm:7.749094220343977e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.05450907349586487 norm:7.690922939218581e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.05448345094919205 norm:7.481092325178906e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:26:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 18:27:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.06483913213014603 norm:0.0005988968769088387 max memory_allocated 29273.25048828125 
[2025-02-28 18:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.06165914237499237 norm:0.0003075879067182541 max memory_allocated 29273.25048828125 
[2025-02-28 18:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.060133740305900574 norm:0.0002052558702416718 max memory_allocated 29273.25048828125 
[2025-02-28 18:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.05906487628817558 norm:0.00015635223826393485 max memory_allocated 29273.25048828125 
[2025-02-28 18:30:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.05832513049244881 norm:0.00013287941692396998 max memory_allocated 29273.25048828125 
[2025-02-28 18:31:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.0578327439725399 norm:0.0001221447455463931 max memory_allocated 29273.25048828125 
[2025-02-28 18:32:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.05754006281495094 norm:0.0001135943311965093 max memory_allocated 29273.25048828125 
[2025-02-28 18:32:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.057369377464056015 norm:0.00010530121653573588 max memory_allocated 29273.25048828125 
[2025-02-28 18:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.05725482106208801 norm:9.795574442250654e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:34:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.05717208981513977 norm:9.635159221943468e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.05711451172828674 norm:9.226529073202983e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.05709216371178627 norm:8.985676686279476e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:36:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.0570451058447361 norm:8.499428076902404e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.05700834468007088 norm:8.393672032980248e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.056974850594997406 norm:8.187413914129138e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.05695391446352005 norm:7.942332740640268e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.05693305656313896 norm:7.709767669439316e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.056922223418951035 norm:7.516683399444446e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.05690128356218338 norm:7.700308196945116e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.05688779428601265 norm:7.548872963525355e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:42:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 18:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.06704284995794296 norm:0.0006169629632495344 max memory_allocated 29273.25048828125 
[2025-02-28 18:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.06421159207820892 norm:0.00030044035520404577 max memory_allocated 29273.25048828125 
[2025-02-28 18:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.06273307651281357 norm:0.0001982341054826975 max memory_allocated 29273.25048828125 
[2025-02-28 18:45:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.06170931085944176 norm:0.00014783954247832298 max memory_allocated 29273.25048828125 
[2025-02-28 18:46:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.06095445901155472 norm:0.00012435310054570436 max memory_allocated 29273.25048828125 
[2025-02-28 18:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.060417983680963516 norm:0.000109519598481711 max memory_allocated 29273.25048828125 
[2025-02-28 18:47:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.06009501963853836 norm:0.00010071182623505592 max memory_allocated 29273.25048828125 
[2025-02-28 18:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.05996032431721687 norm:9.4691313279327e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.05987806245684624 norm:8.862773393047974e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.05979888513684273 norm:8.389812137465924e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.05975081026554108 norm:8.168772183125839e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:51:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.05971561372280121 norm:7.770149386487901e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:52:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.059692103415727615 norm:7.966125122038648e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.059689514338970184 norm:7.730218203505501e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.059654928743839264 norm:7.611384353367612e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.05963854491710663 norm:7.350971281994134e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.059610188007354736 norm:7.065420504659414e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:56:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.05959756672382355 norm:7.06751161487773e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.059582024812698364 norm:7.250427734106779e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:57:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.059565335512161255 norm:7.055308378767222e-05 max memory_allocated 29273.25048828125 
[2025-02-28 18:57:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 18:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.07238583266735077 norm:0.0008126063621602952 max memory_allocated 29273.81298828125 
[2025-02-28 18:59:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.06878388673067093 norm:0.00039911497151479125 max memory_allocated 29273.81298828125 
[2025-02-28 19:00:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.06709180027246475 norm:0.00026003451785072684 max memory_allocated 29273.81298828125 
[2025-02-28 19:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.06597090512514114 norm:0.00019045843509957194 max memory_allocated 29273.81298828125 
[2025-02-28 19:01:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.06513448804616928 norm:0.0001585470454301685 max memory_allocated 29273.81298828125 
[2025-02-28 19:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.06452424079179764 norm:0.0001379442837787792 max memory_allocated 29273.81298828125 
[2025-02-28 19:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.0641791895031929 norm:0.0001282708690268919 max memory_allocated 29273.81298828125 
[2025-02-28 19:04:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.06399686634540558 norm:0.00011870705930050462 max memory_allocated 29273.81298828125 
[2025-02-28 19:04:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.06388440728187561 norm:0.00010980997467413545 max memory_allocated 29273.81298828125 
[2025-02-28 19:05:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.06381449848413467 norm:0.00010458962060511112 max memory_allocated 29273.81298828125 
[2025-02-28 19:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.06375487148761749 norm:9.962992771761492e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.06371060758829117 norm:9.641982614994049e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:07:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.06368343532085419 norm:9.317165677202865e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:08:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.06363844126462936 norm:9.118927118834108e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:09:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.06360010802745819 norm:8.970504131866619e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.06359363347291946 norm:8.772471483098343e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:11:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.06357556581497192 norm:8.362627704627812e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:11:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.06356806308031082 norm:8.216388232540339e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:12:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.06356850266456604 norm:8.153745875461027e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.06354770809412003 norm:7.917667244328186e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:13:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 19:14:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.07370779663324356 norm:0.0005152628291398287 max memory_allocated 29273.81298828125 
[2025-02-28 19:15:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.07170538604259491 norm:0.0002612109237816185 max memory_allocated 29273.81298828125 
[2025-02-28 19:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.07076343148946762 norm:0.00016738302656449378 max memory_allocated 29273.81298828125 
[2025-02-28 19:16:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.06995861232280731 norm:0.00013351193047128618 max memory_allocated 29273.81298828125 
[2025-02-28 19:17:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.06922692060470581 norm:0.00010972799645969644 max memory_allocated 29273.81298828125 
[2025-02-28 19:18:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.06868551671504974 norm:9.888717613648623e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:19:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.06835997849702835 norm:9.066591883311048e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.06822405010461807 norm:8.679656457388774e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.06814882159233093 norm:8.223805343732238e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:21:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.06809557974338531 norm:8.405478729400784e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:22:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.06805495917797089 norm:7.704944437136874e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:22:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.06801826506853104 norm:7.334047404583544e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.06800194084644318 norm:7.389748498098925e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.06798116862773895 norm:7.142574759200215e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:25:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.06796287000179291 norm:7.19526651664637e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.06792319566011429 norm:7.111299782991409e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:26:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.06793022155761719 norm:7.194134377641603e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.06792106479406357 norm:7.341917080339044e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:28:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.06790990382432938 norm:7.779354200465605e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:28:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.06790760159492493 norm:7.067113619996235e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:29:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 19:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.07918062806129456 norm:0.0005266506923362613 max memory_allocated 29273.81298828125 
[2025-02-28 19:30:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.07733950018882751 norm:0.0002771028957795352 max memory_allocated 29273.81298828125 
[2025-02-28 19:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.07633168995380402 norm:0.0001824083155952394 max memory_allocated 29273.81298828125 
[2025-02-28 19:32:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.0755235105752945 norm:0.00013843811757396907 max memory_allocated 29273.81298828125 
[2025-02-28 19:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.07478563487529755 norm:0.00011480670218588784 max memory_allocated 29273.81298828125 
[2025-02-28 19:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.0742073506116867 norm:0.00010279552225256339 max memory_allocated 29273.81298828125 
[2025-02-28 19:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.07390772551298141 norm:9.607525134924799e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.07376472651958466 norm:8.966303721535951e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:36:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.07369054853916168 norm:8.44802416395396e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.07363736629486084 norm:8.101019193418324e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:37:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.073606938123703 norm:7.915615424280986e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:38:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.0735572874546051 norm:7.741797890048474e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.07352906465530396 norm:7.577173528261483e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.07349994778633118 norm:7.195566286100075e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:40:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.07347314059734344 norm:6.916355050634593e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:41:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.0734645277261734 norm:6.892636156408116e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.07344679534435272 norm:6.927722279215232e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:43:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.07342659682035446 norm:0.00016227044397965074 max memory_allocated 29273.81298828125 
[2025-02-28 19:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.07342129945755005 norm:6.95840353728272e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.07341443002223969 norm:7.239618571475148e-05 max memory_allocated 29273.81298828125 
[2025-02-28 19:44:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 19:45:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.08512137085199356 norm:0.0004857035237364471 max memory_allocated 29274.37548828125 
[2025-02-28 19:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.08351893723011017 norm:0.0002572591765783727 max memory_allocated 29274.37548828125 
[2025-02-28 19:47:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.08254167437553406 norm:0.00017264217603951693 max memory_allocated 29274.37548828125 
[2025-02-28 19:48:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.08174074441194534 norm:0.00013242253044154495 max memory_allocated 29274.37548828125 
[2025-02-28 19:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.08093395084142685 norm:0.00010912275320151821 max memory_allocated 29274.37548828125 
[2025-02-28 19:49:33 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.08034669607877731 norm:9.317825606558472e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:50:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.08010341972112656 norm:8.831267041387036e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.08001428097486496 norm:8.502747368765995e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:51:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.07996316999197006 norm:7.788965740473941e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:52:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.07992587983608246 norm:7.859284960431978e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:53:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.07989388704299927 norm:8.071960473898798e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:54:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.07987385243177414 norm:7.991849270183593e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:54:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.07986382395029068 norm:8.120245911413804e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.07984818518161774 norm:7.389331585727632e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:56:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.0798335000872612 norm:7.175521022872999e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.07982993125915527 norm:7.302137964870781e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.07983057200908661 norm:7.334044494200498e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:58:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.07982785999774933 norm:7.244171865750104e-05 max memory_allocated 29274.37548828125 
[2025-02-28 19:59:33 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.07982644438743591 norm:7.199608808150515e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.07982751727104187 norm:7.524676038883626e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:00:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 20:01:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.09182372689247131 norm:0.0004838647728320211 max memory_allocated 29274.37548828125 
[2025-02-28 20:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.09040435403585434 norm:0.0002648764057084918 max memory_allocated 29274.37548828125 
[2025-02-28 20:02:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.08957607299089432 norm:0.00017500828835181892 max memory_allocated 29274.37548828125 
[2025-02-28 20:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.08880142122507095 norm:0.00013720970309805125 max memory_allocated 29274.37548828125 
[2025-02-28 20:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.088006392121315 norm:0.00011033509508706629 max memory_allocated 29274.37548828125 
[2025-02-28 20:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.08738633990287781 norm:9.611302084522322e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.08713047951459885 norm:8.420593076152727e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.08703230321407318 norm:7.812563853804022e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.08695942163467407 norm:7.495262252632529e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.0869322419166565 norm:7.195908256107941e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.08690614253282547 norm:6.980564648984e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.08686944097280502 norm:6.933516124263406e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:10:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.08684840798377991 norm:6.776308146072552e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.0868387296795845 norm:6.410912465071306e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:12:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.08681619167327881 norm:6.236434273887426e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.0868062973022461 norm:6.085938002797775e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:13:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.08680474758148193 norm:6.105768261477351e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.08679354935884476 norm:5.998760389047675e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:15:12 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.08678726851940155 norm:6.310398748610169e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:15:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.08678029477596283 norm:6.127059896243736e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:16:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 20:17:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.10081973671913147 norm:0.0005167850176803768 max memory_allocated 29274.37548828125 
[2025-02-28 20:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.09926090389490128 norm:0.0002991908695548773 max memory_allocated 29274.37548828125 
[2025-02-28 20:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.09823871403932571 norm:0.0002090286579914391 max memory_allocated 29274.37548828125 
[2025-02-28 20:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.09723443537950516 norm:0.0001560844830237329 max memory_allocated 29274.37548828125 
[2025-02-28 20:20:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.0962609201669693 norm:0.00012586868251673877 max memory_allocated 29274.37548828125 
[2025-02-28 20:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.09563136845827103 norm:0.00011197449930477887 max memory_allocated 29274.37548828125 
[2025-02-28 20:21:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.09540165960788727 norm:0.00010235864465357736 max memory_allocated 29274.37548828125 
[2025-02-28 20:22:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.09529004991054535 norm:9.463044261792675e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:23:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.09522373229265213 norm:9.002886508824304e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.09519784897565842 norm:8.945417357608676e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:24:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.09517533332109451 norm:8.760088530834764e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.09514700621366501 norm:8.695871656527743e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:26:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.09512678533792496 norm:9.244587272405624e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:27:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.09511017799377441 norm:8.415750198764727e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:27:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.0950932577252388 norm:8.238213194999844e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:28:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.09509426355361938 norm:8.071224146988243e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:29:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.09509501606225967 norm:8.321009954670444e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:30:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.09507289528846741 norm:8.110330236377195e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:30:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.09506542980670929 norm:8.125066960928962e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.09507814049720764 norm:8.011656609596685e-05 max memory_allocated 29274.37548828125 
[2025-02-28 20:31:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 20:32:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.10797156393527985 norm:0.00031919320463202894 max memory_allocated 29274.93798828125 
[2025-02-28 20:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.10679139196872711 norm:0.00019210833124816418 max memory_allocated 29274.93798828125 
[2025-02-28 20:34:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.10603582113981247 norm:0.00013932726869825274 max memory_allocated 29274.93798828125 
[2025-02-28 20:34:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.10523566603660583 norm:0.00011275203723926097 max memory_allocated 29274.93798828125 
[2025-02-28 20:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.10431307554244995 norm:9.864348248811439e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.10373644530773163 norm:8.96370256668888e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:37:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.10354361683130264 norm:8.10455676401034e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.10345598310232162 norm:7.517304038628936e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:38:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.10340043157339096 norm:7.03440819052048e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:39:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.10335252434015274 norm:6.717357609886676e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.10333093255758286 norm:6.933794065844268e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:41:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.10329936444759369 norm:6.796023808419704e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:41:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.10328060388565063 norm:7.00038654031232e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:42:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.10326419770717621 norm:6.544233474414796e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.10326097160577774 norm:6.430460780393332e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:44:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.10324040800333023 norm:9.301591489929706e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.10323403030633926 norm:6.161236524349079e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:45:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.10322408378124237 norm:6.104340718593448e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:46:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.10321471095085144 norm:6.238470086827874e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:47:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.10320661962032318 norm:6.199154449859634e-05 max memory_allocated 29274.93798828125 
[2025-02-28 20:47:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 20:48:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.11970376968383789 norm:0.0005811494775116444 max memory_allocated 29274.93798828125 
[2025-02-28 20:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.11792736500501633 norm:0.00035367681994102895 max memory_allocated 29274.93798828125 
[2025-02-28 20:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.11675826460123062 norm:0.0002510552585590631 max memory_allocated 29274.93798828125 
[2025-02-28 20:50:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.11572058498859406 norm:0.00019493162108119577 max memory_allocated 29274.93798828125 
[2025-02-28 20:51:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.11464094370603561 norm:0.00016600234084762633 max memory_allocated 29274.93798828125 
[2025-02-28 20:52:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.11403905600309372 norm:0.00014791125431656837 max memory_allocated 29274.93798828125 
[2025-02-28 20:52:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.11384015530347824 norm:0.00013889145338907838 max memory_allocated 29274.93798828125 
[2025-02-28 20:53:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.11373960971832275 norm:0.00012861787399742752 max memory_allocated 29274.93798828125 
[2025-02-28 20:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.11367472261190414 norm:0.0001226542517542839 max memory_allocated 29274.93798828125 
[2025-02-28 20:55:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.11363274604082108 norm:0.00011988884944003075 max memory_allocated 29274.93798828125 
[2025-02-28 20:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.11358833312988281 norm:0.0001136088467319496 max memory_allocated 29274.93798828125 
[2025-02-28 20:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.11356879770755768 norm:0.00011643164907582104 max memory_allocated 29274.93798828125 
[2025-02-28 20:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.11355534195899963 norm:0.00011763717338908464 max memory_allocated 29274.93798828125 
[2025-02-28 20:58:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.11354600638151169 norm:0.00011257181176915765 max memory_allocated 29274.93798828125 
[2025-02-28 20:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.11354327201843262 norm:0.00010461281635798514 max memory_allocated 29274.93798828125 
[2025-02-28 20:59:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.1135023832321167 norm:0.00011484049173304811 max memory_allocated 29274.93798828125 
[2025-02-28 21:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.11350486427545547 norm:0.00011303777137072757 max memory_allocated 29274.93798828125 
[2025-02-28 21:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.11349906027317047 norm:0.0001036800240399316 max memory_allocated 29274.93798828125 
[2025-02-28 21:02:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.1134844422340393 norm:0.00010931889119092375 max memory_allocated 29274.93798828125 
[2025-02-28 21:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.11346438527107239 norm:0.00010832626139745116 max memory_allocated 29274.93798828125 
[2025-02-28 21:03:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 21:04:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.12869296967983246 norm:0.0004478595219552517 max memory_allocated 29274.93798828125 
[2025-02-28 21:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.12746861577033997 norm:0.0002596118429210037 max memory_allocated 29274.93798828125 
[2025-02-28 21:05:32 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.1266709268093109 norm:0.00018498132703825831 max memory_allocated 29274.93798828125 
[2025-02-28 21:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.12573544681072235 norm:0.00014466154971159995 max memory_allocated 29274.93798828125 
[2025-02-28 21:07:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.12469089031219482 norm:0.00011879381781909615 max memory_allocated 29274.93798828125 
[2025-02-28 21:07:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.12416364252567291 norm:0.00011942243145313114 max memory_allocated 29274.93798828125 
[2025-02-28 21:08:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.12399922311306 norm:9.698535723146051e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:09:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.1239176094532013 norm:8.76820704434067e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.12386388331651688 norm:8.568316115997732e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:10:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.12383411824703217 norm:8.04869196144864e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:11:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.12380565702915192 norm:7.885298691689968e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:12:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.12379218637943268 norm:7.76661399868317e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.12377136945724487 norm:7.60779730626382e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.12377248704433441 norm:7.85085721872747e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:14:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.12375767529010773 norm:7.759204163448885e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:15:32 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.12374604493379593 norm:7.568708679173142e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:16:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.12373906373977661 norm:7.400986214634031e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.1237286627292633 norm:7.329712389037013e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.12371885776519775 norm:7.490289135603234e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:18:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.12371695041656494 norm:7.552401075372472e-05 max memory_allocated 29274.93798828125 
[2025-02-28 21:18:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 21:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.14171695709228516 norm:0.0005051575135439634 max memory_allocated 29275.50048828125 
[2025-02-28 21:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.13994449377059937 norm:0.00027895180392079055 max memory_allocated 29275.50048828125 
[2025-02-28 21:21:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.13873428106307983 norm:0.0001898513874039054 max memory_allocated 29275.50048828125 
[2025-02-28 21:21:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.13755513727664948 norm:0.0001493890886195004 max memory_allocated 29275.50048828125 
[2025-02-28 21:22:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.13643518090248108 norm:0.0001255277602467686 max memory_allocated 29275.50048828125 
[2025-02-28 21:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.13597071170806885 norm:0.00011001331586157903 max memory_allocated 29275.50048828125 
[2025-02-28 21:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.13581177592277527 norm:0.00010120169463334605 max memory_allocated 29275.50048828125 
[2025-02-28 21:25:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.1357228010892868 norm:9.673682507127523e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.13564637303352356 norm:9.099506860366091e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:26:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.13559597730636597 norm:8.750604320084676e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.1355668604373932 norm:8.505467121722177e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:28:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.13554176688194275 norm:8.250382961705327e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:28:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.1355137974023819 norm:7.916108006611466e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.1355026215314865 norm:8.066701411735266e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.1354840099811554 norm:7.945054676383734e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:31:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.13545693457126617 norm:7.63546850066632e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:31:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.13544881343841553 norm:7.693679071962833e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.13543987274169922 norm:7.921161886770278e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.13542145490646362 norm:7.876336167100817e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:34:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.1354186236858368 norm:7.895338058006018e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:34:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 21:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.15326164662837982 norm:0.00044146456639282405 max memory_allocated 29275.50048828125 
[2025-02-28 21:36:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.151972696185112 norm:0.00024477479746565223 max memory_allocated 29275.50048828125 
[2025-02-28 21:36:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.1509959101676941 norm:0.0001730591175146401 max memory_allocated 29275.50048828125 
[2025-02-28 21:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.14978791773319244 norm:0.00013422462507151067 max memory_allocated 29275.50048828125 
[2025-02-28 21:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.14870040118694305 norm:0.00011531991185620427 max memory_allocated 29275.50048828125 
[2025-02-28 21:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.14833088219165802 norm:0.00010161505633732304 max memory_allocated 29275.50048828125 
[2025-02-28 21:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.14822031557559967 norm:9.470967052038759e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:40:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.1481580287218094 norm:9.268502617487684e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.1481202393770218 norm:9.034949471242726e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:42:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.1480848342180252 norm:9.154138388112187e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:42:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.14804649353027344 norm:8.92851094249636e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:43:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.14801743626594543 norm:8.659257582621649e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.1479981690645218 norm:8.606218034401536e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:45:17 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.1479770839214325 norm:8.571836224291474e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:46:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.14796453714370728 norm:8.729333057999611e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:46:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.14795851707458496 norm:8.703127969056368e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.1479419320821762 norm:8.627126226201653e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.1479305922985077 norm:8.851869642967358e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.14793625473976135 norm:8.753072324907407e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.14794182777404785 norm:8.695428550709039e-05 max memory_allocated 29275.50048828125 
[2025-02-28 21:50:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-02-28 21:50:57 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.16882216930389404 norm:0.0005656955763697624 max memory_allocated 29275.87548828125 
[2025-02-28 21:51:43 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.1669844686985016 norm:0.00030688708648085594 max memory_allocated 29275.87548828125 
[2025-02-28 21:52:29 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.16567964851856232 norm:0.00021344328706618398 max memory_allocated 29275.87548828125 
[2025-02-28 21:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.16420477628707886 norm:0.00016225058061536402 max memory_allocated 29275.87548828125 
[2025-02-28 21:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.16302675008773804 norm:0.000135719747049734 max memory_allocated 29275.87548828125 
[2025-02-28 21:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.1626586616039276 norm:0.00012276071356609464 max memory_allocated 29275.87548828125 
[2025-02-28 21:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.16251426935195923 norm:0.00011355261813150719 max memory_allocated 29275.87548828125 
[2025-02-28 21:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.16241250932216644 norm:0.00010811621905304492 max memory_allocated 29275.87548828125 
[2025-02-28 21:57:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.1623445302248001 norm:0.00010578524234006181 max memory_allocated 29275.87548828125 
[2025-02-28 21:57:52 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.16229955852031708 norm:9.987279918277636e-05 max memory_allocated 29275.87548828125 
[2025-02-28 21:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.1622605174779892 norm:9.397412941325456e-05 max memory_allocated 29275.87548828125 
[2025-02-28 21:59:24 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.1622316688299179 norm:9.226462134392932e-05 max memory_allocated 29275.87548828125 
[2025-02-28 22:00:10 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.1622018665075302 norm:9.15436539798975e-05 max memory_allocated 29275.87548828125 
[2025-02-28 22:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.1621701419353485 norm:8.944289584178478e-05 max memory_allocated 29275.87548828125 
[2025-02-28 22:01:42 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.1621643453836441 norm:8.918792445911095e-05 max memory_allocated 29275.87548828125 
[2025-02-28 22:02:29 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.16214770078659058 norm:8.820602670311928e-05 max memory_allocated 29275.87548828125 
[2025-02-28 22:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.16214531660079956 norm:8.774919842835516e-05 max memory_allocated 29275.87548828125 
[2025-02-28 22:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.16214045882225037 norm:9.021968435263261e-05 max memory_allocated 29275.87548828125 
[2025-02-28 22:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.16212335228919983 norm:8.942234126152471e-05 max memory_allocated 29275.87548828125 
[2025-02-28 22:05:33 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.16211093962192535 norm:8.817437628749758e-05 max memory_allocated 29275.87548828125 
[2025-02-28 22:05:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-02-28 22:06:37 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.1833263486623764 norm:0.0005011921748518944 max memory_allocated 29276.06298828125 
[2025-02-28 22:07:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.1815033107995987 norm:0.00028278562240302563 max memory_allocated 29276.06298828125 
[2025-02-28 22:08:09 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.1801673024892807 norm:0.00019135657930746675 max memory_allocated 29276.06298828125 
[2025-02-28 22:08:55 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.17867296934127808 norm:0.0001447810500394553 max memory_allocated 29276.06298828125 
[2025-02-28 22:09:41 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.1775321364402771 norm:0.00012519278971012682 max memory_allocated 29276.06298828125 
[2025-02-28 22:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.1772392839193344 norm:0.00011690991232171655 max memory_allocated 29276.06298828125 
[2025-02-28 22:11:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.17709672451019287 norm:0.0001098202119464986 max memory_allocated 29276.06298828125 
[2025-02-28 22:11:59 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.17700783908367157 norm:0.00010155102791031823 max memory_allocated 29276.06298828125 
[2025-02-28 22:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.17693983018398285 norm:9.95579466689378e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.17691048979759216 norm:9.587089152773842e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:14:17 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.17688071727752686 norm:9.434911044081673e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:15:03 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.17685487866401672 norm:9.464332833886147e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:15:49 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.1768391877412796 norm:9.441237489227206e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:16:36 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.1768045872449875 norm:9.263701940653846e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:17:22 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.17680060863494873 norm:9.127504017669708e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:18:08 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.17679482698440552 norm:9.166324161924422e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:18:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.17678965628147125 norm:9.263229731004685e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.17677465081214905 norm:9.179224434774369e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.176768958568573 norm:9.39151577767916e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:21:12 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.17673569917678833 norm:9.443070302950218e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:21:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-02-28 22:22:15 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.20307657122612 norm:0.0005565457395277917 max memory_allocated 29276.06298828125 
[2025-02-28 22:23:01 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.20062197744846344 norm:0.0002943886211141944 max memory_allocated 29276.06298828125 
[2025-02-28 22:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.19884738326072693 norm:0.0002046206354862079 max memory_allocated 29276.06298828125 
[2025-02-28 22:24:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.1970229595899582 norm:0.00015768286539241672 max memory_allocated 29276.06298828125 
[2025-02-28 22:25:20 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.19591286778450012 norm:0.00013693863002117723 max memory_allocated 29276.06298828125 
[2025-02-28 22:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.19561125338077545 norm:0.00012667740520555526 max memory_allocated 29276.06298828125 
[2025-02-28 22:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.1954568773508072 norm:0.00011881269165314734 max memory_allocated 29276.06298828125 
[2025-02-28 22:27:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.19533845782279968 norm:0.00011221825116081163 max memory_allocated 29276.06298828125 
[2025-02-28 22:28:24 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.19526460766792297 norm:0.00010828504309756681 max memory_allocated 29276.06298828125 
[2025-02-28 22:29:10 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.19521433115005493 norm:0.00010677872342057526 max memory_allocated 29276.06298828125 
[2025-02-28 22:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.19517208635807037 norm:0.00010371924872742966 max memory_allocated 29276.06298828125 
[2025-02-28 22:30:42 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.19513635337352753 norm:0.00010126557754119858 max memory_allocated 29276.06298828125 
[2025-02-28 22:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.19511762261390686 norm:0.00010052586731035262 max memory_allocated 29276.06298828125 
[2025-02-28 22:32:15 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.19509872794151306 norm:9.581241465639323e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:33:01 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.19507627189159393 norm:9.446994226891547e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:33:47 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.19506217539310455 norm:9.359744581161067e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.19506524503231049 norm:9.145156218437478e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:35:19 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.19504904747009277 norm:9.012026566779241e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.19504192471504211 norm:9.105828939937055e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.195045605301857 norm:9.31775284698233e-05 max memory_allocated 29276.06298828125 
[2025-02-28 22:37:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-02-28 22:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.22358731925487518 norm:0.000993812340311706 max memory_allocated 29276.06298828125 
[2025-02-28 22:38:40 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.22095564007759094 norm:0.0005318301846273243 max memory_allocated 29276.06298828125 
[2025-02-28 22:39:26 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.21885506808757782 norm:0.00034123731893487275 max memory_allocated 29276.06298828125 
[2025-02-28 22:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.21673700213432312 norm:0.00024391774786636233 max memory_allocated 29276.06298828125 
[2025-02-28 22:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.2156907320022583 norm:0.00019179246737621725 max memory_allocated 29276.06298828125 
[2025-02-28 22:41:45 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.21539969742298126 norm:0.0001629305479582399 max memory_allocated 29276.06298828125 
[2025-02-28 22:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.21526369452476501 norm:0.00014222141180653125 max memory_allocated 29276.06298828125 
[2025-02-28 22:43:17 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.21516603231430054 norm:0.0001293932000407949 max memory_allocated 29276.06298828125 
[2025-02-28 22:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.2151058167219162 norm:0.00012195537419756874 max memory_allocated 29276.06298828125 
[2025-02-28 22:44:49 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.21504412591457367 norm:0.00011629374057520181 max memory_allocated 29276.06298828125 
[2025-02-28 22:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.21501843631267548 norm:0.00011376270413165912 max memory_allocated 29276.06298828125 
[2025-02-28 22:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.2149769812822342 norm:0.00010995462798746303 max memory_allocated 29276.06298828125 
[2025-02-28 22:47:07 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.21494416892528534 norm:0.00010600307723507285 max memory_allocated 29276.06298828125 
[2025-02-28 22:47:54 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.21492046117782593 norm:0.00010584651317913085 max memory_allocated 29276.06298828125 
[2025-02-28 22:48:40 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.21490786969661713 norm:0.00010665466834325343 max memory_allocated 29276.06298828125 
[2025-02-28 22:49:26 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.21489326655864716 norm:0.00010876118903979659 max memory_allocated 29276.06298828125 
[2025-02-28 22:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.21486106514930725 norm:0.00010711605136748403 max memory_allocated 29276.06298828125 
[2025-02-28 22:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.2148577868938446 norm:0.00010895258310483769 max memory_allocated 29276.06298828125 
[2025-02-28 22:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.21483126282691956 norm:0.00010478914919076487 max memory_allocated 29276.06298828125 
[2025-02-28 22:52:30 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.21482643485069275 norm:0.00010604005365166813 max memory_allocated 29276.06298828125 
[2025-02-28 22:52:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-02-28 22:52:47 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 22:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.2518008053302765 norm:0.006440238561481237 max memory_allocated 29276.06298828125 
[2025-02-28 22:54:20 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.2471790462732315 norm:0.005075258668512106 max memory_allocated 29276.06298828125 
[2025-02-28 22:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.2441267967224121 norm:0.00413220189511776 max memory_allocated 29276.06298828125 
[2025-02-28 22:55:52 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.24149061739444733 norm:0.003424594411626458 max memory_allocated 29276.06298828125 
[2025-02-28 22:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.24023553729057312 norm:0.0028429876547306776 max memory_allocated 29276.06298828125 
[2025-02-28 22:57:25 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.23977892100811005 norm:0.00237273913808167 max memory_allocated 29276.06298828125 
[2025-02-28 22:58:11 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.2394876480102539 norm:0.002049107803031802 max memory_allocated 29276.06298828125 
[2025-02-28 22:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.23934775590896606 norm:0.0020009600557386875 max memory_allocated 29276.06298828125 
[2025-02-28 22:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.23928029835224152 norm:0.001971270190551877 max memory_allocated 29276.06298828125 
[2025-02-28 23:00:30 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.23924300074577332 norm:0.0018670489080250263 max memory_allocated 29276.06298828125 
[2025-02-28 23:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.23912468552589417 norm:0.0019171726889908314 max memory_allocated 29276.06298828125 
[2025-02-28 23:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.2391621619462967 norm:0.001417583436705172 max memory_allocated 29276.06298828125 
[2025-02-28 23:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.23889552056789398 norm:0.0016865485813468695 max memory_allocated 29276.06298828125 
[2025-02-28 23:03:35 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.238910973072052 norm:0.0015414352528750896 max memory_allocated 29276.06298828125 
[2025-02-28 23:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.23881728947162628 norm:0.0016864761710166931 max memory_allocated 29276.06298828125 
[2025-02-28 23:05:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.23890382051467896 norm:0.001438263338059187 max memory_allocated 29276.06298828125 
[2025-02-28 23:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.23873493075370789 norm:0.0016374371480196714 max memory_allocated 29276.06298828125 
[2025-02-28 23:06:40 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.23875007033348083 norm:0.0014869160950183868 max memory_allocated 29276.06298828125 
[2025-02-28 23:07:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.23868931829929352 norm:0.0016121066873893142 max memory_allocated 29276.06298828125 
[2025-02-28 23:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.23872943222522736 norm:0.0015060711884871125 max memory_allocated 29276.06298828125 
[2025-02-28 23:08:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-02-28 23:08:30 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 23:09:16 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.28258267045021057 norm:0.006652240175753832 max memory_allocated 29276.06298828125 
[2025-02-28 23:10:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.2766622304916382 norm:0.005355836823582649 max memory_allocated 29276.06298828125 
[2025-02-28 23:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.2719067633152008 norm:0.004207816906273365 max memory_allocated 29276.06298828125 
[2025-02-28 23:11:35 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.268633097410202 norm:0.0035041479859501123 max memory_allocated 29276.06298828125 
[2025-02-28 23:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.267311155796051 norm:0.002981552854180336 max memory_allocated 29276.06298828125 
[2025-02-28 23:13:07 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.2669244706630707 norm:0.002514344872906804 max memory_allocated 29276.06298828125 
[2025-02-28 23:13:53 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.26663723587989807 norm:0.002121132565662265 max memory_allocated 29276.06298828125 
[2025-02-28 23:14:40 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.26632028818130493 norm:0.0023069086018949747 max memory_allocated 29276.06298828125 
[2025-02-28 23:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.2661716043949127 norm:0.00231869681738317 max memory_allocated 29276.06298828125 
[2025-02-28 23:16:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.266059547662735 norm:0.0022347266785800457 max memory_allocated 29276.06298828125 
[2025-02-28 23:16:59 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.266035795211792 norm:0.0024470919743180275 max memory_allocated 29276.06298828125 
[2025-02-28 23:17:45 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.26590919494628906 norm:0.0020698667503893375 max memory_allocated 29276.06298828125 
[2025-02-28 23:18:31 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.2658825218677521 norm:0.0015802908455953002 max memory_allocated 29276.06298828125 
[2025-02-28 23:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.26544255018234253 norm:0.0017702820478007197 max memory_allocated 29276.06298828125 
[2025-02-28 23:20:04 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.26521825790405273 norm:0.002625900087878108 max memory_allocated 29276.06298828125 
[2025-02-28 23:20:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.26509618759155273 norm:0.0034718720708042383 max memory_allocated 29276.06298828125 
[2025-02-28 23:21:36 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.2650066316127777 norm:0.003814356867223978 max memory_allocated 29276.06298828125 
[2025-02-28 23:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.2648884057998657 norm:0.0039552864618599415 max memory_allocated 29276.06298828125 
[2025-02-28 23:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.2646907567977905 norm:0.004044558387249708 max memory_allocated 29276.06298828125 
[2025-02-28 23:23:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.26460030674934387 norm:0.003841225290670991 max memory_allocated 29276.06298828125 
[2025-02-28 23:24:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-02-28 23:24:12 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 23:24:58 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.33587750792503357 norm:0.00847698375582695 max memory_allocated 29277.14501953125 
[2025-02-28 23:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.32418784499168396 norm:0.00441824272274971 max memory_allocated 29277.14501953125 
[2025-02-28 23:26:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.31432363390922546 norm:0.0043528457172214985 max memory_allocated 29277.14501953125 
[2025-02-28 23:27:17 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.3100818693637848 norm:0.0042963954620063305 max memory_allocated 29277.14501953125 
[2025-02-28 23:28:03 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.3085063397884369 norm:0.004084649030119181 max memory_allocated 29277.14501953125 
[2025-02-28 23:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.3077964186668396 norm:0.003880193689838052 max memory_allocated 29277.14501953125 
[2025-02-28 23:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.3072955906391144 norm:0.0037416971754282713 max memory_allocated 29277.14501953125 
[2025-02-28 23:30:22 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.3069233298301697 norm:0.0035553197376430035 max memory_allocated 29277.14501953125 
[2025-02-28 23:31:09 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.30663350224494934 norm:0.003485999768599868 max memory_allocated 29277.14501953125 
[2025-02-28 23:31:55 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.30644741654396057 norm:0.003457295475527644 max memory_allocated 29277.14501953125 
[2025-02-28 23:32:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.3062717914581299 norm:0.003392213024199009 max memory_allocated 29277.14501953125 
[2025-02-28 23:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.3060776889324188 norm:0.0033284961245954037 max memory_allocated 29277.14501953125 
[2025-02-28 23:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.3060041069984436 norm:0.003296872600913048 max memory_allocated 29277.14501953125 
[2025-02-28 23:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.3057979941368103 norm:0.003179767867550254 max memory_allocated 29277.14501953125 
[2025-02-28 23:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.30566734075546265 norm:0.0031729135662317276 max memory_allocated 29277.14501953125 
[2025-02-28 23:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.30549630522727966 norm:0.0030283944215625525 max memory_allocated 29277.14501953125 
[2025-02-28 23:37:19 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.3054780960083008 norm:0.0031476756557822227 max memory_allocated 29277.14501953125 
[2025-02-28 23:38:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.30545130372047424 norm:0.0032347573433071375 max memory_allocated 29277.14501953125 
[2025-02-28 23:38:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.3054118752479553 norm:0.0032620569691061974 max memory_allocated 29277.14501953125 
[2025-02-28 23:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.30531907081604004 norm:0.003283227328211069 max memory_allocated 29277.14501953125 
[2025-02-28 23:39:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-02-28 23:39:55 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 23:40:41 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.45360469818115234 norm:0.026696011424064636 max memory_allocated 29277.14501953125 
[2025-02-28 23:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.43315377831459045 norm:0.01853499934077263 max memory_allocated 29277.14501953125 
[2025-02-28 23:42:13 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.4229416251182556 norm:0.012898619286715984 max memory_allocated 29277.14501953125 
[2025-02-28 23:43:00 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.4162365198135376 norm:0.010208278894424438 max memory_allocated 29277.14501953125 
[2025-02-28 23:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.4124706983566284 norm:0.008399308659136295 max memory_allocated 29277.14501953125 
[2025-02-28 23:44:32 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.41041603684425354 norm:0.008686110377311707 max memory_allocated 29277.14501953125 
[2025-02-28 23:45:19 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.40909406542778015 norm:0.009642270393669605 max memory_allocated 29277.14501953125 
[2025-02-28 23:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.4076789617538452 norm:0.009323092177510262 max memory_allocated 29277.14501953125 
[2025-02-28 23:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.4067460000514984 norm:0.00875873677432537 max memory_allocated 29277.14501953125 
[2025-02-28 23:47:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.4061431288719177 norm:0.008828599937260151 max memory_allocated 29277.14501953125 
[2025-02-28 23:48:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.4053652882575989 norm:0.008226071484386921 max memory_allocated 29277.14501953125 
[2025-02-28 23:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.4051209092140198 norm:0.00790678896009922 max memory_allocated 29277.14501953125 
[2025-02-28 23:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.40512219071388245 norm:0.008272957056760788 max memory_allocated 29277.14501953125 
[2025-02-28 23:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.4049915075302124 norm:0.008436521515250206 max memory_allocated 29277.14501953125 
[2025-02-28 23:51:29 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.4049900770187378 norm:0.00863473117351532 max memory_allocated 29277.14501953125 
[2025-02-28 23:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.40500614047050476 norm:0.008636466227471828 max memory_allocated 29277.14501953125 
[2025-02-28 23:53:01 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.4045274555683136 norm:0.008552998304367065 max memory_allocated 29277.14501953125 
[2025-02-28 23:53:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.40463191270828247 norm:0.008603034541010857 max memory_allocated 29277.14501953125 
[2025-02-28 23:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.4042978584766388 norm:0.008369225077331066 max memory_allocated 29277.14501953125 
[2025-02-28 23:55:20 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.4039784371852875 norm:0.008106318302452564 max memory_allocated 29277.14501953125 
[2025-02-28 23:55:34 root] (main_calib_config2.py 380): INFO 37607.48085093498
[2025-02-28 23:55:43 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 23:57:31 root] (main_calib_config2.py 159): INFO wikitext2 : 5.045780658721924
[2025-02-28 23:57:31 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-01 00:00:19 root] (main_calib_config2.py 159): INFO c4 : 6.675647735595703
[2025-03-01 01:58:03 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.045780658721924, 'c4': 6.675647735595703, 'results': {'arc_easy': {'acc': 0.7226430976430976, 'acc_stderr': 0.009186490105111909, 'acc_norm': 0.563973063973064, 'acc_norm_stderr': 0.010175459582759734}, 'winogrande': {'acc': 0.6890292028413575, 'acc_stderr': 0.013009534736286067}, 'hellaswag': {'acc': 0.5883290181238797, 'acc_stderr': 0.0049113035697697935, 'acc_norm': 0.7559251145190201, 'acc_norm_stderr': 0.004286594977390903}, 'arc_challenge': {'acc': 0.43430034129692835, 'acc_stderr': 0.01448470304885736, 'acc_norm': 0.4351535836177474, 'acc_norm_stderr': 0.01448798619718605}, 'boolq': {'acc': 0.6590214067278287, 'acc_stderr': 0.00829097981816109}, 'piqa': {'acc': 0.7812840043525572, 'acc_stderr': 0.009644731932667556, 'acc_norm': 0.779107725788901, 'acc_norm_stderr': 0.009679088048842205}}, 'versions': {'arc_easy': 0, 'winogrande': 0, 'hellaswag': 0, 'arc_challenge': 0, 'boolq': 1, 'piqa': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
