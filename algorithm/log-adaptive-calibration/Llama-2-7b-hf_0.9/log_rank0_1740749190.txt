[2025-02-28 13:26:30 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-7b-hf_0.9', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.9.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:26:43 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:26:43 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:26:44 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:26:44 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.9.pkl
[2025-02-28 13:26:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:26:48 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:27:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.0038162970449775457 norm:0.006185957230627537 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.001937042805366218 norm:0.003289417829364538 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0015113318804651499 norm:0.002277155639603734 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0013582638930529356 norm:0.0019982026424258947 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0012547600781545043 norm:0.0017386551480740309 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0012064850889146328 norm:0.0016541959485039115 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0011697517475113273 norm:0.0015934820985421538 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0011289536487311125 norm:0.0014015806373208761 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.001095652929507196 norm:0.0013040623161941767 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0010728155029937625 norm:0.0011792383156716824 max memory_allocated 22562.10693359375 
[2025-02-28 13:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0010594193590804935 norm:0.0011278853053227067 max memory_allocated 22562.10693359375 
[2025-02-28 13:32:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.001047964789904654 norm:0.0010843914933502674 max memory_allocated 22562.10693359375 
[2025-02-28 13:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0010480405762791634 norm:0.0010413730051368475 max memory_allocated 22562.10693359375 
[2025-02-28 13:33:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0010294876992702484 norm:0.0009441966540180147 max memory_allocated 22562.10693359375 
[2025-02-28 13:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001028136583045125 norm:0.0008646330679766834 max memory_allocated 22562.10693359375 
[2025-02-28 13:34:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0010205504950135946 norm:0.0008252258412539959 max memory_allocated 22562.10693359375 
[2025-02-28 13:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0010084793902933598 norm:0.0007625464932061732 max memory_allocated 22562.10693359375 
[2025-02-28 13:36:01 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0010006113443523645 norm:0.0007185919675976038 max memory_allocated 22562.10693359375 
[2025-02-28 13:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0009959922172129154 norm:0.0006860457942821085 max memory_allocated 22562.10693359375 
[2025-02-28 13:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0009995750151574612 norm:0.0006463031750172377 max memory_allocated 22562.10693359375 
[2025-02-28 13:37:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:37:13 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:37:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.025049876421689987 norm:0.013486620038747787 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.016811102628707886 norm:0.009618430398404598 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.013175060041248798 norm:0.013867905363440514 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.013122254982590675 norm:0.011393632739782333 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.013024351559579372 norm:0.009197909384965897 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.011579534038901329 norm:0.007928216829895973 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.012292083352804184 norm:0.007000896148383617 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.011135181412100792 norm:0.00588083453476429 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.012073368765413761 norm:0.006641514133661985 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.012052238918840885 norm:0.007762423250824213 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.01160252746194601 norm:0.0070395865477621555 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.010779011994600296 norm:0.006592486519366503 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.010460307821631432 norm:0.00615753373131156 max memory_allocated 22562.27880859375 
[2025-02-28 13:44:24 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.01046082191169262 norm:0.006074376869946718 max memory_allocated 22562.27880859375 
[2025-02-28 13:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.010412577539682388 norm:0.006044351030141115 max memory_allocated 22562.27880859375 
[2025-02-28 13:45:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.010323598980903625 norm:0.005665355361998081 max memory_allocated 22562.27880859375 
[2025-02-28 13:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.013454017229378223 norm:0.007031704299151897 max memory_allocated 22562.27880859375 
[2025-02-28 13:46:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.011702587828040123 norm:0.0057541667483747005 max memory_allocated 22562.27880859375 
[2025-02-28 13:46:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.011126398108899593 norm:0.005436638370156288 max memory_allocated 22562.27880859375 
[2025-02-28 13:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.011264401488006115 norm:0.005632467567920685 max memory_allocated 22562.27880859375 
[2025-02-28 13:47:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 13:47:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.013459966517984867 norm:0.005618118681013584 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.011828847229480743 norm:0.00429078983142972 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.011320358142256737 norm:0.0034281988628208637 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.010937501676380634 norm:0.0028103208169341087 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.010558005422353745 norm:0.0024053894449025393 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.010210711508989334 norm:0.002029294613748789 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.010009117424488068 norm:0.0017050408059731126 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.009914510883390903 norm:0.0013518240302801132 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.009852403774857521 norm:0.0010445538209751248 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.009795736521482468 norm:0.0007975220796652138 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.009760868735611439 norm:0.000721667252946645 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.009802359156310558 norm:0.0009473386453464627 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.009795027785003185 norm:0.0009621927747502923 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.00973172951489687 norm:0.0007613238994963467 max memory_allocated 22562.45068359375 
[2025-02-28 13:55:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.009723782539367676 norm:0.0007510758005082607 max memory_allocated 22562.45068359375 
[2025-02-28 13:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.009730313904583454 norm:0.0008016781066544354 max memory_allocated 22562.45068359375 
[2025-02-28 13:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.009721903130412102 norm:0.0007864743238314986 max memory_allocated 22562.45068359375 
[2025-02-28 13:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.009717073291540146 norm:0.0007746000192128122 max memory_allocated 22562.45068359375 
[2025-02-28 13:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.009692922234535217 norm:0.0006953792180866003 max memory_allocated 22562.45068359375 
[2025-02-28 13:57:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.009691467508673668 norm:0.0006889338837936521 max memory_allocated 22562.45068359375 
[2025-02-28 13:58:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 13:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.016703348606824875 norm:0.001231625210493803 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.014454987831413746 norm:0.00048558294656686485 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.013605714775621891 norm:0.0002714475558605045 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.012980137020349503 norm:0.00015999935567378998 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.012428086251020432 norm:0.00012894654355477542 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.012173724360764027 norm:0.00010156627831747755 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.01211385615170002 norm:8.557558612665161e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.012091098353266716 norm:7.497990736737847e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.012079202570021152 norm:7.159481174312532e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.012071815319359303 norm:7.059251220198348e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.01206198800355196 norm:6.899947766214609e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.012050961144268513 norm:6.587206007679924e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.012046866118907928 norm:6.567173841176555e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.012038735672831535 norm:6.674853648291901e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.012037365697324276 norm:6.640631181653589e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.012031837366521358 norm:6.677689088974148e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.012028386816382408 norm:6.725410639774054e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:07:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.012026678770780563 norm:6.710308662150055e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:07:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.012024934403598309 norm:6.697510252706707e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:08:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.012024912983179092 norm:6.795336230425164e-05 max memory_allocated 22562.50732421875 
[2025-02-28 14:08:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:08:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.02078845538198948 norm:0.0010907729156315327 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.01709512248635292 norm:0.00045094231609255075 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.015606125816702843 norm:0.0002533873193897307 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.014878864400088787 norm:0.00016671982302796096 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.01449053455144167 norm:0.0001310853403992951 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.014288973063230515 norm:0.00011820656800409779 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.014218161813914776 norm:0.00010192854097113013 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.014194845221936703 norm:9.30525129660964e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.01417816337198019 norm:8.74821562319994e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.014162684790790081 norm:8.513503416907042e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.014149085618555546 norm:9.022636368172243e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.014131762087345123 norm:8.839485963108018e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.014145209453999996 norm:9.962833428289741e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.014137600548565388 norm:9.168130782200024e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.014131772331893444 norm:9.056753333425149e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.014143716543912888 norm:9.020010475069284e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.014154738746583462 norm:8.841027010930702e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.014153100550174713 norm:8.765520033193752e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.014147275127470493 norm:9.239376231562346e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.014160087332129478 norm:9.85083170235157e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:18:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.020627634599804878 norm:0.0008847255958244205 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.01874200999736786 norm:0.0004051273863296956 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.017692402005195618 norm:0.00023042412067297846 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.016872016713023186 norm:0.00014749531692359596 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.01633523590862751 norm:0.00010521731019252911 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.016142643988132477 norm:8.379375503864139e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.01609552837908268 norm:7.676558016100898e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.016078878194093704 norm:7.23076009307988e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.016062572598457336 norm:6.9400281063281e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.016050521284341812 norm:6.814707739977166e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.01603969931602478 norm:6.895871774759144e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.016039330512285233 norm:7.008991815382615e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.016034968197345734 norm:6.757528171874583e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.01603006385266781 norm:6.815569940954447e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.016030043363571167 norm:6.842333095846698e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.01603097654879093 norm:6.930893869139254e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.016027839854359627 norm:6.998812750680372e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.01602717861533165 norm:6.886792107252404e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.016025647521018982 norm:6.842552102170885e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.016022000461816788 norm:6.79500080877915e-05 max memory_allocated 22562.85107421875 
[2025-02-28 14:29:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 14:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.02323996089398861 norm:0.0009296932839788496 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.021125055849552155 norm:0.0004351403913460672 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.019963867962360382 norm:0.0002504840085748583 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.01908266171813011 norm:0.00016324060561601073 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.018563222140073776 norm:0.00011816387996077538 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.018357696011662483 norm:9.86802697298117e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.018289050087332726 norm:8.66927148308605e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.018262192606925964 norm:8.203001198126003e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.018240097910165787 norm:7.918436313048005e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.018226241692900658 norm:7.7653574408032e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.018219981342554092 norm:7.577066571684554e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.018209923058748245 norm:7.475305756088346e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.018198588863015175 norm:7.338239811360836e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.018192928284406662 norm:7.332349923672155e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.01818167418241501 norm:7.33295310055837e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.018176386132836342 norm:7.42867705412209e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.018169373273849487 norm:7.305578037630767e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.01816711202263832 norm:7.168616139097139e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.018168075010180473 norm:7.13842164259404e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.018165886402130127 norm:6.99865777278319e-05 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 14:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.02585318312048912 norm:0.0010139220394194126 max memory_allocated 22563.19482421875 
[2025-02-28 14:40:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.023648109287023544 norm:0.0004843563656322658 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.022311735898256302 norm:0.00028541829669848084 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.02139383554458618 norm:0.00018494168762117624 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.02090080827474594 norm:0.0001307421043748036 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.02071741409599781 norm:0.00010544709220994264 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.020651914179325104 norm:9.254347969545051e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.020619915798306465 norm:8.293373684864491e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.020600471645593643 norm:7.800141611369327e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.020584866404533386 norm:7.511005969718099e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.020578324794769287 norm:7.364443445112556e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.02056271769106388 norm:7.368670776486397e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.020553257316350937 norm:7.291692600119859e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.02054615691304207 norm:7.225488661788404e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.020541198551654816 norm:7.304603059310466e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.020539218559861183 norm:7.226973684737459e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.020540660247206688 norm:7.124951662262902e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.0205373615026474 norm:7.134918996598572e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.020530419424176216 norm:7.140445814002305e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.020530328154563904 norm:7.22259355825372e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 14:50:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.02934669889509678 norm:0.0009242710075341165 max memory_allocated 22563.36669921875 
[2025-02-28 14:50:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.025647370144724846 norm:0.0004739798605442047 max memory_allocated 22563.36669921875 
[2025-02-28 14:51:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.024110475555062294 norm:0.000297966820653528 max memory_allocated 22563.36669921875 
[2025-02-28 14:51:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.023264434188604355 norm:0.00022319912386592478 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.022723035886883736 norm:0.00020478015358094126 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.02241448312997818 norm:0.00019034970318898559 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.022230057045817375 norm:0.00015087216161191463 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.022101085633039474 norm:0.00015678467752877623 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.022055774927139282 norm:0.00017085587023757398 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.021992206573486328 norm:0.00014547696628142148 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.021936312317848206 norm:0.00013991320156492293 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.021906623616814613 norm:0.0001424630609108135 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.02190277725458145 norm:0.00013882078928872943 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.021879682317376137 norm:0.0001494674797868356 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.02187158353626728 norm:0.0001401168410666287 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.02185957320034504 norm:0.0001435473095625639 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.021846603602170944 norm:0.0001352685794699937 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.021827442571520805 norm:0.00014012875908520073 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.021823078393936157 norm:0.00015204572991933674 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.021811047568917274 norm:0.00014185816689860076 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 15:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.029943091794848442 norm:0.0008259235182777047 max memory_allocated 22563.53857421875 
[2025-02-28 15:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.026433372870087624 norm:0.0003669129218906164 max memory_allocated 22563.53857421875 
[2025-02-28 15:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.025038745254278183 norm:0.0002275704755447805 max memory_allocated 22563.53857421875 
[2025-02-28 15:02:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.024313095957040787 norm:0.00018407298193778843 max memory_allocated 22563.53857421875 
[2025-02-28 15:02:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.023807041347026825 norm:0.00016490666894242167 max memory_allocated 22563.53857421875 
[2025-02-28 15:03:22 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.023536356166005135 norm:0.00014089159958530217 max memory_allocated 22563.53857421875 
[2025-02-28 15:03:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.023396680131554604 norm:0.00013380238669924438 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.02329127863049507 norm:0.00011821273801615462 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.0232466422021389 norm:0.00012891215737909079 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.02320573292672634 norm:0.0001168528979178518 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.023160893470048904 norm:0.00011977682879660279 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.02314085140824318 norm:0.00011505982547532767 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.023117784410715103 norm:0.00011513851495692506 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.02308753691613674 norm:0.0001248783228220418 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.02308174967765808 norm:0.0001166559086414054 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.023124678060412407 norm:0.000129758394905366 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.023087158799171448 norm:0.000119234602607321 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.02306898683309555 norm:0.00011733084102161229 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.02307473123073578 norm:0.00012752779002767056 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.023070309311151505 norm:0.00011725900549208745 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 15:11:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.029199916869401932 norm:0.0005115052917972207 max memory_allocated 22563.71044921875 
[2025-02-28 15:11:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.026909831911325455 norm:0.00026338640600442886 max memory_allocated 22563.71044921875 
[2025-02-28 15:12:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.02579893171787262 norm:0.0001780777529347688 max memory_allocated 22563.71044921875 
[2025-02-28 15:12:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.02516215667128563 norm:0.00015604239888489246 max memory_allocated 22563.71044921875 
[2025-02-28 15:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.02470819652080536 norm:0.0001436005113646388 max memory_allocated 22563.71044921875 
[2025-02-28 15:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.024486687034368515 norm:0.00014208175707608461 max memory_allocated 22563.71044921875 
[2025-02-28 15:14:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.02430536039173603 norm:0.00011647531937342137 max memory_allocated 22563.71044921875 
[2025-02-28 15:14:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.024219626560807228 norm:0.00011322011414449662 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.02416548877954483 norm:0.00010633281635819003 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.024123113602399826 norm:0.00010966787522193044 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.024099277332425117 norm:0.00010494857269804925 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.024072717875242233 norm:0.00010098808706970885 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.024057209491729736 norm:0.00010045021190308034 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.024032769724726677 norm:0.00010007312812376767 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.024028144776821136 norm:0.00010240256960969418 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.02402501180768013 norm:0.00010064188245451078 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.02408280223608017 norm:0.00011171744699822739 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.024074070155620575 norm:0.000105751067167148 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.02406361512839794 norm:0.00010653983918018639 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.02406245470046997 norm:0.00010506714170332998 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 15:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.031498976051807404 norm:0.0006564815994352102 max memory_allocated 22563.88232421875 
[2025-02-28 15:22:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.028502749279141426 norm:0.0003404071612749249 max memory_allocated 22563.88232421875 
[2025-02-28 15:22:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.0271102674305439 norm:0.00023332919226959348 max memory_allocated 22563.88232421875 
[2025-02-28 15:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.02639913186430931 norm:0.0001950269943336025 max memory_allocated 22563.88232421875 
[2025-02-28 15:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.025907114148139954 norm:0.00016664630675222725 max memory_allocated 22563.88232421875 
[2025-02-28 15:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.025609206408262253 norm:0.0001528924040030688 max memory_allocated 22563.88232421875 
[2025-02-28 15:24:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.02545054815709591 norm:0.00014788753469474614 max memory_allocated 22563.88232421875 
[2025-02-28 15:25:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.0253578033298254 norm:0.00014391957665793598 max memory_allocated 22563.88232421875 
[2025-02-28 15:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.02526303008198738 norm:0.00012842888827435672 max memory_allocated 22563.88232421875 
[2025-02-28 15:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.025224588811397552 norm:0.0001221712736878544 max memory_allocated 22563.88232421875 
[2025-02-28 15:26:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.025156084448099136 norm:0.0001202832572744228 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.02510654553771019 norm:0.00011044785787817091 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.02506931684911251 norm:0.00010396230209153146 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.0250592902302742 norm:0.00010837949230335653 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.02504648081958294 norm:0.00010931657016044483 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.02503800578415394 norm:9.987284283852205e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.02502085268497467 norm:9.901190787786618e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.025009360164403915 norm:9.955315181287006e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.024990111589431763 norm:0.00010129491420229897 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.024983195587992668 norm:9.777794184628874e-05 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 15:31:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.03105083480477333 norm:0.0005505084991455078 max memory_allocated 22564.05419921875 
[2025-02-28 15:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.028662970289587975 norm:0.0002924816799350083 max memory_allocated 22564.05419921875 
[2025-02-28 15:32:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.02755756676197052 norm:0.00020471129391808063 max memory_allocated 22564.05419921875 
[2025-02-28 15:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.026920385658740997 norm:0.0001683584414422512 max memory_allocated 22564.05419921875 
[2025-02-28 15:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.02653997763991356 norm:0.00014989501505624503 max memory_allocated 22564.05419921875 
[2025-02-28 15:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.02627730928361416 norm:0.0001367867225781083 max memory_allocated 22564.05419921875 
[2025-02-28 15:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.026124516502022743 norm:0.00012091299868188798 max memory_allocated 22564.05419921875 
[2025-02-28 15:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.026027940213680267 norm:0.00011570006608963013 max memory_allocated 22564.05419921875 
[2025-02-28 15:35:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.02594424970448017 norm:0.00010842858318937942 max memory_allocated 22564.05419921875 
[2025-02-28 15:36:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.025900891050696373 norm:0.00011567114415811375 max memory_allocated 22564.05419921875 
[2025-02-28 15:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.025909334421157837 norm:0.00012153046554885805 max memory_allocated 22564.05419921875 
[2025-02-28 15:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.02585618942975998 norm:0.00011001492384821177 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.0258294939994812 norm:0.00010053753794636577 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.025818519294261932 norm:0.00010026495874626562 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.02579622156918049 norm:9.447457705391571e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.025770481675863266 norm:9.832526120590046e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.025744063779711723 norm:9.761841647559777e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.025737617164850235 norm:9.861746366368607e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.025737762451171875 norm:9.36511205509305e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.025737473741173744 norm:9.541540202917531e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 15:42:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.03024587407708168 norm:0.0006577738677151501 max memory_allocated 22564.22607421875 
[2025-02-28 15:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.028102416545152664 norm:0.00033127458300441504 max memory_allocated 22564.22607421875 
[2025-02-28 15:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.02706168033182621 norm:0.00021643322543241084 max memory_allocated 22564.22607421875 
[2025-02-28 15:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.02646360546350479 norm:0.00017061160178855062 max memory_allocated 22564.22607421875 
[2025-02-28 15:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.026058968156576157 norm:0.00013450106780510396 max memory_allocated 22564.22607421875 
[2025-02-28 15:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.025823000818490982 norm:0.00012014027743134648 max memory_allocated 22564.22607421875 
[2025-02-28 15:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.02567300945520401 norm:0.00011142953735543415 max memory_allocated 22564.22607421875 
[2025-02-28 15:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.025575682520866394 norm:0.0001039078488247469 max memory_allocated 22564.22607421875 
[2025-02-28 15:46:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.025515781715512276 norm:9.80763288680464e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.025468382984399796 norm:9.050615335581824e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:47:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.025437628850340843 norm:8.946366142481565e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:47:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.025424852967262268 norm:9.33058254304342e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:48:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.025386782363057137 norm:8.80955412867479e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.025351479649543762 norm:8.138935663737357e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.025350790470838547 norm:8.440072269877419e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.02533891797065735 norm:9.268856956623495e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.025366095826029778 norm:9.355923248222098e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.025338470935821533 norm:8.645957859698683e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.02531682513654232 norm:8.43406596686691e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.02530999854207039 norm:8.48267154651694e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 15:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.030540242791175842 norm:0.0005262166960164905 max memory_allocated 22564.39794921875 
[2025-02-28 15:53:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.028438977897167206 norm:0.00027750799199566245 max memory_allocated 22564.39794921875 
[2025-02-28 15:53:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.027449827641248703 norm:0.00019647979934234172 max memory_allocated 22564.39794921875 
[2025-02-28 15:54:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.026834705844521523 norm:0.0001548603904666379 max memory_allocated 22564.39794921875 
[2025-02-28 15:54:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.026454975828528404 norm:0.00013084431702736765 max memory_allocated 22564.39794921875 
[2025-02-28 15:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.026198001578450203 norm:0.00011489179451018572 max memory_allocated 22564.39794921875 
[2025-02-28 15:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.02606016956269741 norm:0.00010820155875990167 max memory_allocated 22564.39794921875 
[2025-02-28 15:56:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.02595636248588562 norm:0.00010656213271431625 max memory_allocated 22564.39794921875 
[2025-02-28 15:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.02587553672492504 norm:0.00010311212827218696 max memory_allocated 22564.39794921875 
[2025-02-28 15:57:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.0258127860724926 norm:9.651338041294366e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:57:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.025765912607312202 norm:8.985844760900363e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:58:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.02574491687119007 norm:8.829913713270798e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:58:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.025731803849339485 norm:8.579451241530478e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:59:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.025707192718982697 norm:8.430740854237229e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:59:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.025688331574201584 norm:7.935595931485295e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.025678245350718498 norm:7.517655467381701e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:00:50 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.025675229728221893 norm:7.321915472857654e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.025666508823633194 norm:7.04354461049661e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.025656459853053093 norm:7.034488953649998e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.025646360591053963 norm:6.939713784959167e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 16:03:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.030306005850434303 norm:0.000595862977206707 max memory_allocated 22564.56982421875 
[2025-02-28 16:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.028865717351436615 norm:0.00027582672191783786 max memory_allocated 22564.56982421875 
[2025-02-28 16:04:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.028002357110381126 norm:0.00016642340051475912 max memory_allocated 22564.56982421875 
[2025-02-28 16:04:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.027358630672097206 norm:0.00011475261999294162 max memory_allocated 22564.56982421875 
[2025-02-28 16:05:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.026927970349788666 norm:8.849571895552799e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:05:39 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.026700591668486595 norm:7.461168570443988e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:06:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.026601767167448997 norm:6.60561490803957e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:06:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.02655739337205887 norm:6.367227615555748e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.02653767727315426 norm:6.059027145965956e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:07:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.02652680315077305 norm:5.902064003748819e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:08:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.02651788480579853 norm:5.807716297567822e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:08:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.026509566232562065 norm:5.7319273764733225e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:09:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.026506332680583 norm:5.727664029109292e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.02649739384651184 norm:5.625182166113518e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:10:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.02649255283176899 norm:5.6507662520743906e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:10:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.02648983709514141 norm:5.618661452899687e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.02648930437862873 norm:5.531645001610741e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:11:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.026482604444026947 norm:5.583337042480707e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.026480989530682564 norm:5.588082058238797e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.026479588821530342 norm:5.5739386880304664e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 16:13:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.030330199748277664 norm:0.000579847430344671 max memory_allocated 22564.74169921875 
[2025-02-28 16:13:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.029097512364387512 norm:0.0002447751467116177 max memory_allocated 22564.74169921875 
[2025-02-28 16:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.028299927711486816 norm:0.00014803229714743793 max memory_allocated 22564.74169921875 
[2025-02-28 16:15:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.02768552117049694 norm:0.00010322329762857407 max memory_allocated 22564.74169921875 
[2025-02-28 16:15:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.027236217632889748 norm:8.140622230712324e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:16:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.02698264829814434 norm:7.065804675221443e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:16:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.026882760226726532 norm:6.431000656448305e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:17:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.026838693767786026 norm:6.0610582295339555e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:17:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.026821358129382133 norm:5.8998495660489425e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:18:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.026805559173226357 norm:5.7949000620283186e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.02679012529551983 norm:5.623277684208006e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:19:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.026777327060699463 norm:5.5113898270064965e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:19:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.02677380107343197 norm:5.505950321094133e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:20:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.026764990761876106 norm:5.482727647176944e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:20:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.026758862659335136 norm:5.392174352891743e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.026755034923553467 norm:5.445137503556907e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:21:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.026748375967144966 norm:5.361807779991068e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:22:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.02674822323024273 norm:5.4319036280503497e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:22:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.026743575930595398 norm:5.390393562265672e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.026742564514279366 norm:5.3662079153582454e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:23:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 16:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.03041256219148636 norm:0.000503996096085757 max memory_allocated 22564.91357421875 
[2025-02-28 16:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.028848376125097275 norm:0.00018535957497078925 max memory_allocated 22564.91357421875 
[2025-02-28 16:24:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.0282481350004673 norm:0.0001377847365802154 max memory_allocated 22564.91357421875 
[2025-02-28 16:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.027790553867816925 norm:0.00011590158828767017 max memory_allocated 22564.91357421875 
[2025-02-28 16:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.02745116874575615 norm:0.0001100131485145539 max memory_allocated 22564.91357421875 
[2025-02-28 16:26:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.027215909212827682 norm:8.661164611112326e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:26:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.027102405205368996 norm:9.106745710596442e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.02699478529393673 norm:8.374792378162965e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:27:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.026938680559396744 norm:7.44494391256012e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:28:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.02689054049551487 norm:6.75876290188171e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.026860905811190605 norm:6.416915130103007e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:29:28 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.0268272552639246 norm:6.606161332456395e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:29:58 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.026805540546774864 norm:6.213143933564425e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.026790786534547806 norm:6.001456858939491e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.026776129379868507 norm:5.719468754250556e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:31:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.02677169069647789 norm:5.7071269111474976e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:32:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.026763329282402992 norm:5.721785419154912e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:32:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.0267532579600811 norm:5.69123585592024e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.02677442505955696 norm:6.264364492380992e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.02675676718354225 norm:6.24938402324915e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:33:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 16:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.03301524743437767 norm:0.000667020445689559 max memory_allocated 22565.08544921875 
[2025-02-28 16:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.031187869608402252 norm:0.0003162390785291791 max memory_allocated 22565.08544921875 
[2025-02-28 16:35:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.030358292162418365 norm:0.00020204971951898187 max memory_allocated 22565.08544921875 
[2025-02-28 16:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.029708152636885643 norm:0.00015553171397186816 max memory_allocated 22565.08544921875 
[2025-02-28 16:36:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.029324466362595558 norm:0.00012769275053869933 max memory_allocated 22565.08544921875 
[2025-02-28 16:36:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.029095832258462906 norm:0.00010711543291108683 max memory_allocated 22565.08544921875 
[2025-02-28 16:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.028963953256607056 norm:8.980278653325513e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:37:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.028890343382954597 norm:8.485114085488021e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:38:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.02883140929043293 norm:7.948503480292857e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:38:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.028786323964595795 norm:7.498827471863478e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:39:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.028746969997882843 norm:7.149977318476886e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:39:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.028711922466754913 norm:6.764352292520925e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.02867921255528927 norm:6.565209332620725e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:40:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.02865421213209629 norm:6.515425775432959e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:41:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.02863410860300064 norm:6.362640124280006e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.02862037532031536 norm:6.209218554431573e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:42:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.028602629899978638 norm:5.970401980448514e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:42:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.02857952192425728 norm:5.4126074246596545e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.028572535142302513 norm:5.405106639955193e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:43:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.028564026579260826 norm:4.972366878064349e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:44:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 16:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.035585030913352966 norm:0.0007908123079687357 max memory_allocated 22565.25732421875 
[2025-02-28 16:45:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.03362652659416199 norm:0.0003514854470267892 max memory_allocated 22565.25732421875 
[2025-02-28 16:45:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.0326521210372448 norm:0.0002017664664890617 max memory_allocated 22565.25732421875 
[2025-02-28 16:46:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.03202977403998375 norm:0.00014990725321695209 max memory_allocated 22565.25732421875 
[2025-02-28 16:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.03161889687180519 norm:0.00012319409870542586 max memory_allocated 22565.25732421875 
[2025-02-28 16:47:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.03139876946806908 norm:0.00010187308362219483 max memory_allocated 22565.25732421875 
[2025-02-28 16:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.031293775886297226 norm:9.374774526804686e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:48:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.031240740790963173 norm:8.545704622520134e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:48:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.03119257278740406 norm:7.468689727829769e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:49:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.03116069734096527 norm:7.133128383429721e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:49:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.031128231436014175 norm:7.217838719952852e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.031097769737243652 norm:7.120383816072717e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.031081680208444595 norm:6.705251871608198e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.031060459092259407 norm:5.91565876675304e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.031040508300065994 norm:6.357181700877845e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.0310196690261364 norm:5.915110887144692e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.031000884249806404 norm:5.5006734328344464e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.030989138409495354 norm:5.7060537073994055e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:53:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.030975516885519028 norm:5.3664465667679906e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:54:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.030964549630880356 norm:5.032053013565019e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:54:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 16:54:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.03996196389198303 norm:0.0011486099101603031 max memory_allocated 22565.42919921875 
[2025-02-28 16:55:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.03721533715724945 norm:0.00045907413004897535 max memory_allocated 22565.42919921875 
[2025-02-28 16:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.035953182727098465 norm:0.0002403566613793373 max memory_allocated 22565.42919921875 
[2025-02-28 16:56:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.03526894375681877 norm:0.00017473925254307687 max memory_allocated 22565.42919921875 
[2025-02-28 16:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.03483228757977486 norm:0.00013384652265813202 max memory_allocated 22565.42919921875 
[2025-02-28 16:57:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.034596383571624756 norm:0.00012265314580872655 max memory_allocated 22565.42919921875 
[2025-02-28 16:58:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.034460943192243576 norm:0.00011163783347001299 max memory_allocated 22565.42919921875 
[2025-02-28 16:58:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.03437799960374832 norm:0.00010744002793217078 max memory_allocated 22565.42919921875 
[2025-02-28 16:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.03431423753499985 norm:0.0001015191082842648 max memory_allocated 22565.42919921875 
[2025-02-28 16:59:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.034272607415914536 norm:9.604224032955244e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.03423696011304855 norm:9.05870329006575e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:00:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.034204624593257904 norm:8.590679499320686e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:01:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.03416801244020462 norm:8.275101572507992e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.034134916961193085 norm:8.115266973618418e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:02:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.03410625457763672 norm:7.767843635519966e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.034089814871549606 norm:7.381954492302611e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:03:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.03406520560383797 norm:7.019028998911381e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.034050971269607544 norm:6.88548680045642e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.034033626317977905 norm:7.304694736376405e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:04:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.03400960564613342 norm:6.586105155292898e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:04:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 17:05:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.041517145931720734 norm:0.0005672441911883652 max memory_allocated 22565.60107421875 
[2025-02-28 17:05:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.040000177919864655 norm:0.00024417793611064553 max memory_allocated 22565.60107421875 
[2025-02-28 17:06:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.039354875683784485 norm:0.00016617157962173223 max memory_allocated 22565.60107421875 
[2025-02-28 17:06:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.03881080821156502 norm:0.00012652206351049244 max memory_allocated 22565.60107421875 
[2025-02-28 17:07:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.038350943475961685 norm:0.000109633278043475 max memory_allocated 22565.60107421875 
[2025-02-28 17:07:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.038123492151498795 norm:0.00010741714504547417 max memory_allocated 22565.60107421875 
[2025-02-28 17:08:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.038019195199012756 norm:9.217527986038476e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:08:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.03796784207224846 norm:8.626366616226733e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.037920061498880386 norm:8.089549373835325e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:09:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.03789009526371956 norm:7.000609184615314e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.037857428193092346 norm:6.634231249336153e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.03783661127090454 norm:6.457374547608197e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:11:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.0378204882144928 norm:6.575127190444618e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:11:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.037807222455739975 norm:6.188007682794705e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:12:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.037791065871715546 norm:6.0721260524587706e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:13:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.037772540003061295 norm:5.795866309199482e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.0377611443400383 norm:5.4772477596998215e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:14:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.03774591162800789 norm:5.221984611125663e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:14:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.03773742541670799 norm:5.450559183373116e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:15:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.0377332903444767 norm:5.05463540321216e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:15:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 17:15:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.04833119735121727 norm:0.0007232987554743886 max memory_allocated 22565.77294921875 
[2025-02-28 17:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.0459870882332325 norm:0.000302145752357319 max memory_allocated 22565.77294921875 
[2025-02-28 17:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.04499516263604164 norm:0.00040721462573856115 max memory_allocated 22565.77294921875 
[2025-02-28 17:17:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.04424674063920975 norm:0.00016457417223136872 max memory_allocated 22565.77294921875 
[2025-02-28 17:17:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.04374387860298157 norm:0.00014676415594294667 max memory_allocated 22565.77294921875 
[2025-02-28 17:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.043507691472768784 norm:0.00012187652464490384 max memory_allocated 22565.77294921875 
[2025-02-28 17:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.04340425506234169 norm:0.00011357118637533858 max memory_allocated 22565.77294921875 
[2025-02-28 17:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.04334492236375809 norm:0.00010778944852063432 max memory_allocated 22565.77294921875 
[2025-02-28 17:19:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.043286874890327454 norm:0.00010367584764026105 max memory_allocated 22565.77294921875 
[2025-02-28 17:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.04324227198958397 norm:9.675546607468277e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.043199531733989716 norm:9.226865950040519e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:21:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.043163273483514786 norm:9.267550922231749e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:21:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.04313461855053902 norm:8.549200720153749e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.04308803379535675 norm:8.193166286218911e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:22:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.04305938631296158 norm:8.112984505714849e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:23:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.04303815960884094 norm:7.792404358042404e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.043017707765102386 norm:7.676019595237449e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:24:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.04300092160701752 norm:7.706022006459534e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:24:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.04298163205385208 norm:7.127832213882357e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:25:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.042965542525053024 norm:7.53490676288493e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:25:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 17:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.05330382287502289 norm:0.0007496388861909509 max memory_allocated 22565.94482421875 
[2025-02-28 17:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.0516350194811821 norm:0.00042673497227951884 max memory_allocated 22565.94482421875 
[2025-02-28 17:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.050763435661792755 norm:0.00028923453646712005 max memory_allocated 22565.94482421875 
[2025-02-28 17:27:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.04995367303490639 norm:0.0002175608678953722 max memory_allocated 22565.94482421875 
[2025-02-28 17:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.04940967634320259 norm:0.00016236642841249704 max memory_allocated 22565.94482421875 
[2025-02-28 17:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.049219533801078796 norm:0.00012931477976962924 max memory_allocated 22565.94482421875 
[2025-02-28 17:29:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.04912407696247101 norm:0.00011638824798865244 max memory_allocated 22565.94482421875 
[2025-02-28 17:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.0490569993853569 norm:0.00010154239134863019 max memory_allocated 22565.94482421875 
[2025-02-28 17:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.04901441931724548 norm:9.082358155865222e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:30:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.048962727189064026 norm:8.940351835917681e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:31:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.048914551734924316 norm:8.371025614906102e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:31:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.04888879135251045 norm:7.309077045647427e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.048869434744119644 norm:7.326384366024286e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.04884061962366104 norm:7.401026232400909e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.04881932586431503 norm:6.450833461713046e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.048804450780153275 norm:6.688669964205474e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:34:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.048784613609313965 norm:6.11897194175981e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.04877539724111557 norm:5.9241207054583356e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.048770129680633545 norm:5.95856508880388e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:35:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.04876326024532318 norm:5.6265766033902764e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:35:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 17:36:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.06086757779121399 norm:0.0007508960552513599 max memory_allocated 22566.11669921875 
[2025-02-28 17:36:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.05870166793465614 norm:0.0003580727207008749 max memory_allocated 22566.11669921875 
[2025-02-28 17:37:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.05758345127105713 norm:0.00024964605108834803 max memory_allocated 22566.11669921875 
[2025-02-28 17:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.056717775762081146 norm:0.00018044630996882915 max memory_allocated 22566.11669921875 
[2025-02-28 17:38:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.05616350471973419 norm:0.00015682679077144712 max memory_allocated 22566.11669921875 
[2025-02-28 17:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.055998627096414566 norm:0.00013689007028006017 max memory_allocated 22566.11669921875 
[2025-02-28 17:39:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.055905383080244064 norm:0.00012690579751506448 max memory_allocated 22566.11669921875 
[2025-02-28 17:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.05583997070789337 norm:0.00012050317309331149 max memory_allocated 22566.11669921875 
[2025-02-28 17:40:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.05575636029243469 norm:0.00011061927943956107 max memory_allocated 22566.11669921875 
[2025-02-28 17:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.055699318647384644 norm:0.00010792360262712464 max memory_allocated 22566.11669921875 
[2025-02-28 17:41:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.05565009266138077 norm:0.00010573611507425085 max memory_allocated 22566.11669921875 
[2025-02-28 17:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.05560719966888428 norm:9.39342426136136e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.0555630624294281 norm:9.083685290534049e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:43:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.055528588593006134 norm:9.0358495071996e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.0554976686835289 norm:9.212920122081414e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:44:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.055477261543273926 norm:9.827291069086641e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.05545232445001602 norm:9.382740245200694e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.05543224886059761 norm:9.071381646208465e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:45:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.05541132390499115 norm:8.789259300101548e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:46:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.05539403110742569 norm:8.194573456421494e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:46:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 17:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.06960999965667725 norm:0.0006636640173383057 max memory_allocated 22566.28857421875 
[2025-02-28 17:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.06757044792175293 norm:0.0003436112601775676 max memory_allocated 22566.28857421875 
[2025-02-28 17:47:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.06622082740068436 norm:0.00024145562201738358 max memory_allocated 22566.28857421875 
[2025-02-28 17:48:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.0652308464050293 norm:0.00020325338118709624 max memory_allocated 22566.28857421875 
[2025-02-28 17:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.06464162468910217 norm:0.00017822162772063166 max memory_allocated 22566.28857421875 
[2025-02-28 17:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.0644788146018982 norm:0.00016131869051605463 max memory_allocated 22566.28857421875 
[2025-02-28 17:49:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.0643843486905098 norm:0.00014886351709719747 max memory_allocated 22566.28857421875 
[2025-02-28 17:50:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.06427018344402313 norm:0.0001381938491249457 max memory_allocated 22566.28857421875 
[2025-02-28 17:50:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.06417908519506454 norm:0.00012759314267896116 max memory_allocated 22566.28857421875 
[2025-02-28 17:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.06412166357040405 norm:0.00011558436381164938 max memory_allocated 22566.28857421875 
[2025-02-28 17:51:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.06406231224536896 norm:0.00011273185373283923 max memory_allocated 22566.28857421875 
[2025-02-28 17:52:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.06401031464338303 norm:0.00011209967487957329 max memory_allocated 22566.28857421875 
[2025-02-28 17:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.06403360515832901 norm:0.00013115443289279938 max memory_allocated 22566.28857421875 
[2025-02-28 17:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.06393945217132568 norm:0.00010767136700451374 max memory_allocated 22566.28857421875 
[2025-02-28 17:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.06390456855297089 norm:9.889258217299357e-05 max memory_allocated 22566.28857421875 
[2025-02-28 17:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.06387939304113388 norm:0.00010020962508860976 max memory_allocated 22566.28857421875 
[2025-02-28 17:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.06385646015405655 norm:9.432675869902596e-05 max memory_allocated 22566.28857421875 
[2025-02-28 17:55:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.0638309121131897 norm:9.174686420010403e-05 max memory_allocated 22566.28857421875 
[2025-02-28 17:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.06382738798856735 norm:8.983004954643548e-05 max memory_allocated 22566.28857421875 
[2025-02-28 17:56:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.06382051110267639 norm:8.703277126187459e-05 max memory_allocated 22566.28857421875 
[2025-02-28 17:56:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 17:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.07881300151348114 norm:0.0009154079598374665 max memory_allocated 22566.46044921875 
[2025-02-28 17:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.07634907215833664 norm:0.0004544435068964958 max memory_allocated 22566.46044921875 
[2025-02-28 17:58:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.07499475032091141 norm:0.0003063445910811424 max memory_allocated 22566.46044921875 
[2025-02-28 17:58:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.07405272126197815 norm:0.00024778067017905414 max memory_allocated 22566.46044921875 
[2025-02-28 17:59:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.07347644120454788 norm:0.0002043338754447177 max memory_allocated 22566.46044921875 
[2025-02-28 17:59:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.07322177290916443 norm:0.00017480834503658116 max memory_allocated 22566.46044921875 
[2025-02-28 18:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.07305864989757538 norm:0.00016006430087145418 max memory_allocated 22566.46044921875 
[2025-02-28 18:00:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.07294199615716934 norm:0.00015220613568089902 max memory_allocated 22566.46044921875 
[2025-02-28 18:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.07284043729305267 norm:0.00013891622074879706 max memory_allocated 22566.46044921875 
[2025-02-28 18:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.07277892529964447 norm:0.00013134395703673363 max memory_allocated 22566.46044921875 
[2025-02-28 18:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.07269568741321564 norm:0.0001215440861415118 max memory_allocated 22566.46044921875 
[2025-02-28 18:02:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.07261510193347931 norm:0.0001127728246501647 max memory_allocated 22566.46044921875 
[2025-02-28 18:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.0725705474615097 norm:0.00011082094715675339 max memory_allocated 22566.46044921875 
[2025-02-28 18:03:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.07252472639083862 norm:0.00011279691534582525 max memory_allocated 22566.46044921875 
[2025-02-28 18:04:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.07250332087278366 norm:0.00010873372957576066 max memory_allocated 22566.46044921875 
[2025-02-28 18:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.07247656583786011 norm:0.00010252801439492032 max memory_allocated 22566.46044921875 
[2025-02-28 18:05:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.07244087010622025 norm:0.00010569026198936626 max memory_allocated 22566.46044921875 
[2025-02-28 18:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.07243777811527252 norm:0.00010083066445076838 max memory_allocated 22566.46044921875 
[2025-02-28 18:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.07242268323898315 norm:9.641662472859025e-05 max memory_allocated 22566.46044921875 
[2025-02-28 18:06:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.07240824401378632 norm:9.455227700527757e-05 max memory_allocated 22566.46044921875 
[2025-02-28 18:07:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 18:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.08923575282096863 norm:0.0007616224465891719 max memory_allocated 22566.63232421875 
[2025-02-28 18:08:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.08682529628276825 norm:0.00039320738869719207 max memory_allocated 22566.63232421875 
[2025-02-28 18:08:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.08547826111316681 norm:0.00027046952163800597 max memory_allocated 22566.63232421875 
[2025-02-28 18:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.08435734361410141 norm:0.00020286598009988666 max memory_allocated 22566.63232421875 
[2025-02-28 18:09:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.08392289280891418 norm:0.00016541001969017088 max memory_allocated 22566.63232421875 
[2025-02-28 18:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.08377500623464584 norm:0.00014492742775473744 max memory_allocated 22566.63232421875 
[2025-02-28 18:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.08368503302335739 norm:0.00012868197518400848 max memory_allocated 22566.63232421875 
[2025-02-28 18:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.08361770212650299 norm:0.00012055630213581026 max memory_allocated 22566.63232421875 
[2025-02-28 18:11:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.08356425166130066 norm:0.00011523334978846833 max memory_allocated 22566.63232421875 
[2025-02-28 18:12:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.08351746946573257 norm:0.00010816505528055131 max memory_allocated 22566.63232421875 
[2025-02-28 18:12:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.0834716260433197 norm:0.00010210069012828171 max memory_allocated 22566.63232421875 
[2025-02-28 18:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.08344151079654694 norm:0.00010114612086908892 max memory_allocated 22566.63232421875 
[2025-02-28 18:13:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.0834072157740593 norm:9.777679952094331e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:14:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.08337903767824173 norm:9.138383757090196e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:14:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.08335605263710022 norm:9.322114055976272e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:15:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.08334005624055862 norm:9.226491238223389e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.083315908908844 norm:8.898091618902981e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:16:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.08330424875020981 norm:8.600542787462473e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.08329111337661743 norm:8.509457256877795e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:17:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.08328881859779358 norm:8.790556603344157e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:17:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 18:17:36 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.10234876722097397 norm:0.0037232746835798025 max memory_allocated 22566.91943359375 
[2025-02-28 18:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.1001555323600769 norm:0.0029308791272342205 max memory_allocated 22566.91943359375 
[2025-02-28 18:19:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.09866839647293091 norm:0.0024302189704030752 max memory_allocated 22566.91943359375 
[2025-02-28 18:19:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.09752728790044785 norm:0.002029119059443474 max memory_allocated 22566.91943359375 
[2025-02-28 18:20:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.09698887169361115 norm:0.001627095858566463 max memory_allocated 22566.91943359375 
[2025-02-28 18:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.09674865752458572 norm:0.0013822169275954366 max memory_allocated 22566.91943359375 
[2025-02-28 18:21:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.09659883379936218 norm:0.0013124251272529364 max memory_allocated 22566.91943359375 
[2025-02-28 18:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.09656916558742523 norm:0.0012933097314089537 max memory_allocated 22566.91943359375 
[2025-02-28 18:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.09651119261980057 norm:0.0013322823215276003 max memory_allocated 22566.91943359375 
[2025-02-28 18:22:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.09645114839076996 norm:0.0009777590166777372 max memory_allocated 22566.91943359375 
[2025-02-28 18:23:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.09630750119686127 norm:0.0011991787469014525 max memory_allocated 22566.91943359375 
[2025-02-28 18:23:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.09639860689640045 norm:0.0007594720227643847 max memory_allocated 22566.91943359375 
[2025-02-28 18:24:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.09615316987037659 norm:0.0009669307619333267 max memory_allocated 22566.91943359375 
[2025-02-28 18:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.09612005949020386 norm:0.0009770662290975451 max memory_allocated 22566.91943359375 
[2025-02-28 18:25:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.09613671898841858 norm:0.0009557787561789155 max memory_allocated 22566.91943359375 
[2025-02-28 18:25:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.09616449475288391 norm:0.0010086360853165388 max memory_allocated 22566.91943359375 
[2025-02-28 18:26:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.09622020274400711 norm:0.0008676996221765876 max memory_allocated 22566.91943359375 
[2025-02-28 18:26:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.09614656865596771 norm:0.0009219270432367921 max memory_allocated 22566.91943359375 
[2025-02-28 18:27:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.09612254798412323 norm:0.0009430571226403117 max memory_allocated 22566.91943359375 
[2025-02-28 18:27:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.09609132260084152 norm:0.0009257729398086667 max memory_allocated 22566.91943359375 
[2025-02-28 18:27:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 18:28:01 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.12488865107297897 norm:0.005343754775822163 max memory_allocated 22567.09130859375 
[2025-02-28 18:29:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.11920980364084244 norm:0.00394863449037075 max memory_allocated 22567.09130859375 
[2025-02-28 18:29:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.11590968817472458 norm:0.0029261524323374033 max memory_allocated 22567.09130859375 
[2025-02-28 18:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.11385207623243332 norm:0.0019597976934164762 max memory_allocated 22567.09130859375 
[2025-02-28 18:30:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.1129659116268158 norm:0.0011591841466724873 max memory_allocated 22567.09130859375 
[2025-02-28 18:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.11248458921909332 norm:0.0008831743616610765 max memory_allocated 22567.09130859375 
[2025-02-28 18:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.1122020035982132 norm:0.0009457875275984406 max memory_allocated 22567.09130859375 
[2025-02-28 18:32:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.1120321974158287 norm:0.0010967937996611 max memory_allocated 22567.09130859375 
[2025-02-28 18:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.11193192005157471 norm:0.0010125695262104273 max memory_allocated 22567.09130859375 
[2025-02-28 18:33:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.11184901744127274 norm:0.0009961089817807078 max memory_allocated 22567.09130859375 
[2025-02-28 18:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.11178150027990341 norm:0.0009509233059361577 max memory_allocated 22567.09130859375 
[2025-02-28 18:34:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.11172585189342499 norm:0.0009084797347895801 max memory_allocated 22567.09130859375 
[2025-02-28 18:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.1117001473903656 norm:0.0008902725530788302 max memory_allocated 22567.09130859375 
[2025-02-28 18:35:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.11166948825120926 norm:0.0008931777556426823 max memory_allocated 22567.09130859375 
[2025-02-28 18:35:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.11165807396173477 norm:0.0009024619357660413 max memory_allocated 22567.09130859375 
[2025-02-28 18:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.11168599128723145 norm:0.0010427022352814674 max memory_allocated 22567.09130859375 
[2025-02-28 18:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.11167184263467789 norm:0.0009680700022727251 max memory_allocated 22567.09130859375 
[2025-02-28 18:37:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.11170773953199387 norm:0.001102915732190013 max memory_allocated 22567.09130859375 
[2025-02-28 18:37:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.11172281950712204 norm:0.0011032421607524157 max memory_allocated 22567.09130859375 
[2025-02-28 18:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.11170496046543121 norm:0.0010120270308107138 max memory_allocated 22567.09130859375 
[2025-02-28 18:38:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 18:38:25 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.0430635213851929 norm:0.18054574728012085 max memory_allocated 22567.26318359375 
[2025-02-28 18:39:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.7162992358207703 norm:0.1565658301115036 max memory_allocated 22567.26318359375 
[2025-02-28 18:39:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.3671208918094635 norm:0.06609596312046051 max memory_allocated 22567.26318359375 
[2025-02-28 18:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.26687201857566833 norm:0.0435158871114254 max memory_allocated 22567.26318359375 
[2025-02-28 18:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.23556968569755554 norm:0.04206608235836029 max memory_allocated 22567.26318359375 
[2025-02-28 18:41:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.21737885475158691 norm:0.04078168794512749 max memory_allocated 22567.26318359375 
[2025-02-28 18:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.20568245649337769 norm:0.03926863148808479 max memory_allocated 22567.26318359375 
[2025-02-28 18:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.19779232144355774 norm:0.038983095437288284 max memory_allocated 22567.26318359375 
[2025-02-28 18:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.1911233812570572 norm:0.036945343017578125 max memory_allocated 22567.26318359375 
[2025-02-28 18:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.1864461898803711 norm:0.0357668437063694 max memory_allocated 22567.26318359375 
[2025-02-28 18:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.18161681294441223 norm:0.03325916826725006 max memory_allocated 22567.26318359375 
[2025-02-28 18:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.1786767542362213 norm:0.031398218125104904 max memory_allocated 22567.26318359375 
[2025-02-28 18:45:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.17688250541687012 norm:0.029202157631516457 max memory_allocated 22567.26318359375 
[2025-02-28 18:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.1744900792837143 norm:0.028119228780269623 max memory_allocated 22567.26318359375 
[2025-02-28 18:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.17324350774288177 norm:0.026005757972598076 max memory_allocated 22567.26318359375 
[2025-02-28 18:46:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.17185668647289276 norm:0.024489017203450203 max memory_allocated 22567.26318359375 
[2025-02-28 18:47:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.17105068266391754 norm:0.023922786116600037 max memory_allocated 22567.26318359375 
[2025-02-28 18:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.17141185700893402 norm:0.024854831397533417 max memory_allocated 22567.26318359375 
[2025-02-28 18:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.1710575670003891 norm:0.024752935394644737 max memory_allocated 22567.26318359375 
[2025-02-28 18:48:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.17011936008930206 norm:0.023411719128489494 max memory_allocated 22567.26318359375 
[2025-02-28 18:48:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 18:48:50 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:49:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.33834967017173767 norm:0.02824150025844574 max memory_allocated 22567.43505859375 
[2025-02-28 18:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.3154001832008362 norm:0.021228743717074394 max memory_allocated 22567.43505859375 
[2025-02-28 18:50:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.30341535806655884 norm:0.01756937801837921 max memory_allocated 22567.43505859375 
[2025-02-28 18:50:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.29640355706214905 norm:0.01505050528794527 max memory_allocated 22567.43505859375 
[2025-02-28 18:51:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.2910236120223999 norm:0.012250727042555809 max memory_allocated 22567.43505859375 
[2025-02-28 18:51:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.28806838393211365 norm:0.011188461445271969 max memory_allocated 22567.43505859375 
[2025-02-28 18:52:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.28611984848976135 norm:0.010233176872134209 max memory_allocated 22567.43505859375 
[2025-02-28 18:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.2848576307296753 norm:0.009856841526925564 max memory_allocated 22567.43505859375 
[2025-02-28 18:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.2836936414241791 norm:0.009809560142457485 max memory_allocated 22567.43505859375 
[2025-02-28 18:53:57 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.2829520106315613 norm:0.009790503419935703 max memory_allocated 22567.43505859375 
[2025-02-28 18:54:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.2827651798725128 norm:0.010464144870638847 max memory_allocated 22567.43505859375 
[2025-02-28 18:54:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.28246691823005676 norm:0.010417716577649117 max memory_allocated 22567.43505859375 
[2025-02-28 18:55:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.282085120677948 norm:0.010648050345480442 max memory_allocated 22567.43505859375 
[2025-02-28 18:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.2811504304409027 norm:0.009217450395226479 max memory_allocated 22567.43505859375 
[2025-02-28 18:56:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.2805711030960083 norm:0.008817549794912338 max memory_allocated 22567.43505859375 
[2025-02-28 18:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.28016820549964905 norm:0.008713987655937672 max memory_allocated 22567.43505859375 
[2025-02-28 18:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.28000837564468384 norm:0.008841527625918388 max memory_allocated 22567.43505859375 
[2025-02-28 18:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.2798384428024292 norm:0.008841863833367825 max memory_allocated 22567.43505859375 
[2025-02-28 18:58:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.27955764532089233 norm:0.008586470037698746 max memory_allocated 22567.43505859375 
[2025-02-28 18:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.2796053886413574 norm:0.008778691291809082 max memory_allocated 22567.43505859375 
[2025-02-28 18:59:12 root] (main_calib_config2.py 380): INFO 19948.98601436615
[2025-02-28 18:59:20 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 19:00:23 root] (main_calib_config2.py 159): INFO wikitext2 : 5.610344886779785
[2025-02-28 19:00:23 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 19:02:01 root] (main_calib_config2.py 159): INFO c4 : 7.170233249664307
[2025-02-28 20:42:53 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.610344886779785, 'c4': 7.170233249664307, 'results': {'winogrande': {'acc': 0.665351223362273, 'acc_stderr': 0.013261823629558368}, 'hellaswag': {'acc': 0.5581557458673571, 'acc_stderr': 0.004955914693717967, 'acc_norm': 0.7173869747062338, 'acc_norm_stderr': 0.004493495872000117}, 'arc_challenge': {'acc': 0.3984641638225256, 'acc_stderr': 0.014306946052735563, 'acc_norm': 0.4044368600682594, 'acc_norm_stderr': 0.014342036483436174}, 'piqa': {'acc': 0.7829162132752993, 'acc_stderr': 0.009618708415756782, 'acc_norm': 0.766050054406964, 'acc_norm_stderr': 0.009877236895137436}, 'boolq': {'acc': 0.6944954128440367, 'acc_stderr': 0.008056308685164815}, 'arc_easy': {'acc': 0.6742424242424242, 'acc_stderr': 0.00961664297688597, 'acc_norm': 0.5248316498316499, 'acc_norm_stderr': 0.010247123122159287}}, 'versions': {'winogrande': 0, 'hellaswag': 0, 'arc_challenge': 0, 'piqa': 0, 'boolq': 1, 'arc_easy': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
