[2025-03-01 14:27:49 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.45', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.45.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-01 14:28:23 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-01 14:28:23 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.45.pkl
[2025-03-01 14:28:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-01 14:29:00 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.03186681866645813 norm:0.026183675974607468 max memory_allocated 29271.02001953125 
[2025-03-01 14:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.022628769278526306 norm:0.0174191202968359 max memory_allocated 29271.02001953125 
[2025-03-01 14:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.01871618442237377 norm:0.013641271740198135 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.01732918992638588 norm:0.01131303422152996 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.016797907650470734 norm:0.00926305539906025 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.016461333259940147 norm:0.0077443537302315235 max memory_allocated 29271.02001953125 
[2025-03-01 14:34:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.016240326687693596 norm:0.006563760340213776 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.01608014665544033 norm:0.005677561275660992 max memory_allocated 29271.02001953125 
[2025-03-01 14:36:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.015933331102132797 norm:0.004859152715653181 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.015848999843001366 norm:0.004356544930487871 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.015834586694836617 norm:0.00403827428817749 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.015868116170167923 norm:0.003815000643953681 max memory_allocated 29271.02001953125 
[2025-03-01 14:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.015836430713534355 norm:0.0037302132695913315 max memory_allocated 29271.02001953125 
[2025-03-01 14:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.01593528501689434 norm:0.0036233265418559313 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.015747006982564926 norm:0.0032792212441563606 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.01570270210504532 norm:0.0031523711513727903 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.01579512096941471 norm:0.0032068523578345776 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.015820860862731934 norm:0.0030058925040066242 max memory_allocated 29271.02001953125 
[2025-03-01 14:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.016092395409941673 norm:0.0032717143185436726 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.016119569540023804 norm:0.0030411933548748493 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-01 14:45:50 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.04212142899632454 norm:0.017606262117624283 max memory_allocated 29271.02001953125 
[2025-03-01 14:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.03017105907201767 norm:0.010389456525444984 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.024878203868865967 norm:0.007008518557995558 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.023196060210466385 norm:0.005572724621742964 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.022426016628742218 norm:0.004605790600180626 max memory_allocated 29271.02001953125 
[2025-03-01 14:50:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.021964462473988533 norm:0.004061185754835606 max memory_allocated 29271.02001953125 
[2025-03-01 14:51:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.02161386050283909 norm:0.0035196035169065 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.021391823887825012 norm:0.0031287509482353926 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.02120591513812542 norm:0.002703609876334667 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.02103140763938427 norm:0.002423543483018875 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.02084515430033207 norm:0.0021069063805043697 max memory_allocated 29271.02001953125 
[2025-03-01 14:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.020751729607582092 norm:0.0019425610080361366 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.020677771419286728 norm:0.001858287607319653 max memory_allocated 29271.02001953125 
[2025-03-01 14:57:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.02060004509985447 norm:0.001854318892583251 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.020587902516126633 norm:0.001901852316223085 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.020666584372520447 norm:0.0017724904464557767 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.020435266196727753 norm:0.0016348689096048474 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.02045784890651703 norm:0.0016451869159936905 max memory_allocated 29271.02001953125 
[2025-03-01 15:01:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.02044381946325302 norm:0.0016715904930606484 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.020477458834648132 norm:0.001548898871988058 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-01 15:02:47 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 15:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.043683864176273346 norm:0.01443441305309534 max memory_allocated 29271.39501953125 
[2025-03-01 15:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.03435254096984863 norm:0.009983053430914879 max memory_allocated 29271.39501953125 
[2025-03-01 15:05:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.029707234352827072 norm:0.007315083406865597 max memory_allocated 29271.39501953125 
[2025-03-01 15:06:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.02795800007879734 norm:0.005589240230619907 max memory_allocated 29271.39501953125 
[2025-03-01 15:06:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.027028121054172516 norm:0.004492413252592087 max memory_allocated 29271.39501953125 
[2025-03-01 15:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.026422828435897827 norm:0.0036782948300242424 max memory_allocated 29271.39501953125 
[2025-03-01 15:08:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.02596822939813137 norm:0.0029609680641442537 max memory_allocated 29271.39501953125 
[2025-03-01 15:09:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.0255495123565197 norm:0.0024602983612567186 max memory_allocated 29271.39501953125 
[2025-03-01 15:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.025321580469608307 norm:0.0022052654530853033 max memory_allocated 29271.39501953125 
[2025-03-01 15:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.025249844416975975 norm:0.0021792235784232616 max memory_allocated 29271.39501953125 
[2025-03-01 15:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.025200070813298225 norm:0.0021303086541593075 max memory_allocated 29271.39501953125 
[2025-03-01 15:12:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.02512047253549099 norm:0.002065908396616578 max memory_allocated 29271.39501953125 
[2025-03-01 15:13:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.02509177103638649 norm:0.002004595473408699 max memory_allocated 29271.39501953125 
[2025-03-01 15:14:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.025030171498656273 norm:0.001896044472232461 max memory_allocated 29271.39501953125 
[2025-03-01 15:15:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.025038883090019226 norm:0.0017872247844934464 max memory_allocated 29271.39501953125 
[2025-03-01 15:16:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.024976905435323715 norm:0.001713120611384511 max memory_allocated 29271.39501953125 
[2025-03-01 15:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.02497164160013199 norm:0.0016638017259538174 max memory_allocated 29271.39501953125 
[2025-03-01 15:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.02496468648314476 norm:0.0016295734094455838 max memory_allocated 29271.39501953125 
[2025-03-01 15:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.024987634271383286 norm:0.0016004294157028198 max memory_allocated 29271.39501953125 
[2025-03-01 15:19:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.024966709315776825 norm:0.0015558801824226975 max memory_allocated 29271.39501953125 
[2025-03-01 15:19:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-01 15:20:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.1469331681728363 norm:0.017087483778595924 max memory_allocated 29271.39501953125 
[2025-03-01 15:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.11599190533161163 norm:0.009537198580801487 max memory_allocated 29271.39501953125 
[2025-03-01 15:22:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.09027424454689026 norm:0.008076597936451435 max memory_allocated 29271.39501953125 
[2025-03-01 15:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.07985129952430725 norm:0.007329562213271856 max memory_allocated 29271.39501953125 
[2025-03-01 15:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.06792007386684418 norm:0.006901271175593138 max memory_allocated 29271.39501953125 
[2025-03-01 15:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.06445669382810593 norm:0.00554910022765398 max memory_allocated 29271.39501953125 
[2025-03-01 15:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.060955144464969635 norm:0.005201682448387146 max memory_allocated 29271.39501953125 
[2025-03-01 15:26:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.0599970668554306 norm:0.004896435886621475 max memory_allocated 29271.39501953125 
[2025-03-01 15:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.057499103248119354 norm:0.004739176947623491 max memory_allocated 29271.39501953125 
[2025-03-01 15:28:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.05601842701435089 norm:0.004838564898818731 max memory_allocated 29271.39501953125 
[2025-03-01 15:28:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.058601316064596176 norm:0.005206851754337549 max memory_allocated 29271.39501953125 
[2025-03-01 15:29:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.0580228827893734 norm:0.004535745829343796 max memory_allocated 29271.39501953125 
[2025-03-01 15:30:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.057575568556785583 norm:0.004705809522420168 max memory_allocated 29271.39501953125 
[2025-03-01 15:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.05622386559844017 norm:0.004796790424734354 max memory_allocated 29271.39501953125 
[2025-03-01 15:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.058635689318180084 norm:0.004916571546345949 max memory_allocated 29271.39501953125 
[2025-03-01 15:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.05726711452007294 norm:0.004885375965386629 max memory_allocated 29271.39501953125 
[2025-03-01 15:33:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.05669211596250534 norm:0.0056721665896475315 max memory_allocated 29271.39501953125 
[2025-03-01 15:34:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.05413893982768059 norm:0.004752676002681255 max memory_allocated 29271.39501953125 
[2025-03-01 15:35:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.056820593774318695 norm:0.005116555839776993 max memory_allocated 29271.39501953125 
[2025-03-01 15:36:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.05605601146817207 norm:0.005389245226979256 max memory_allocated 29271.39501953125 
[2025-03-01 15:36:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-01 15:37:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.06351930648088455 norm:0.001653977669775486 max memory_allocated 29271.39501953125 
[2025-03-01 15:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.05311056226491928 norm:0.000624649750534445 max memory_allocated 29271.39501953125 
[2025-03-01 15:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.04826979339122772 norm:0.00035268536885268986 max memory_allocated 29271.39501953125 
[2025-03-01 15:39:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.046385154128074646 norm:0.0002681429614312947 max memory_allocated 29271.39501953125 
[2025-03-01 15:40:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.0454133003950119 norm:0.0002347213012399152 max memory_allocated 29271.39501953125 
[2025-03-01 15:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.04474352300167084 norm:0.00021721581288147718 max memory_allocated 29271.39501953125 
[2025-03-01 15:42:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.04433572664856911 norm:0.00022488963440991938 max memory_allocated 29271.39501953125 
[2025-03-01 15:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.04410789906978607 norm:0.00020218707504682243 max memory_allocated 29271.39501953125 
[2025-03-01 15:44:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.0439695306122303 norm:0.00019183434778824449 max memory_allocated 29271.39501953125 
[2025-03-01 15:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.04389388859272003 norm:0.00020450640295166522 max memory_allocated 29271.39501953125 
[2025-03-01 15:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.04387295991182327 norm:0.00020396584295667708 max memory_allocated 29271.39501953125 
[2025-03-01 15:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.043851085007190704 norm:0.00021131939138285816 max memory_allocated 29271.39501953125 
[2025-03-01 15:47:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.04381031543016434 norm:0.00019573711324483156 max memory_allocated 29271.39501953125 
[2025-03-01 15:48:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.0437956377863884 norm:0.0001978049986064434 max memory_allocated 29271.39501953125 
[2025-03-01 15:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.0437764935195446 norm:0.00020891324675176293 max memory_allocated 29271.39501953125 
[2025-03-01 15:49:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.04376961290836334 norm:0.00022242084378376603 max memory_allocated 29271.39501953125 
[2025-03-01 15:50:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.04376235231757164 norm:0.00021802241099067032 max memory_allocated 29271.39501953125 
[2025-03-01 15:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.043759144842624664 norm:0.00021794588246848434 max memory_allocated 29271.39501953125 
[2025-03-01 15:52:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.0437372624874115 norm:0.00022759863350074738 max memory_allocated 29271.39501953125 
[2025-03-01 15:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.04373595118522644 norm:0.00021544691117014736 max memory_allocated 29271.39501953125 
[2025-03-01 15:53:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-01 15:54:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.07007841020822525 norm:0.002185429446399212 max memory_allocated 29271.81298828125 
[2025-03-01 15:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.057002946734428406 norm:0.0008686085930094123 max memory_allocated 29271.81298828125 
[2025-03-01 15:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.05116845667362213 norm:0.0004559344379231334 max memory_allocated 29271.81298828125 
[2025-03-01 15:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.049164388328790665 norm:0.0003064824268221855 max memory_allocated 29271.81298828125 
[2025-03-01 15:57:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.047979775816202164 norm:0.0002405733393970877 max memory_allocated 29271.81298828125 
[2025-03-01 15:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.047243207693099976 norm:0.00020562428107950836 max memory_allocated 29271.81298828125 
[2025-03-01 15:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.0468362420797348 norm:0.00018828437896445394 max memory_allocated 29271.81298828125 
[2025-03-01 16:00:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.046613067388534546 norm:0.0001730537333060056 max memory_allocated 29271.81298828125 
[2025-03-01 16:01:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.04649830982089043 norm:0.0001687531330389902 max memory_allocated 29271.81298828125 
[2025-03-01 16:01:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.046393077820539474 norm:0.00016453010903205723 max memory_allocated 29271.81298828125 
[2025-03-01 16:02:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.04635711386799812 norm:0.00016278390830848366 max memory_allocated 29271.81298828125 
[2025-03-01 16:03:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.046299923211336136 norm:0.00016211665933951735 max memory_allocated 29271.81298828125 
[2025-03-01 16:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.04626661539077759 norm:0.00016937141481321305 max memory_allocated 29271.81298828125 
[2025-03-01 16:05:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.04624244570732117 norm:0.00016517285257577896 max memory_allocated 29271.81298828125 
[2025-03-01 16:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.046224020421504974 norm:0.00017208364442922175 max memory_allocated 29271.81298828125 
[2025-03-01 16:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.04620186239480972 norm:0.00017139516421593726 max memory_allocated 29271.81298828125 
[2025-03-01 16:07:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.04618439823389053 norm:0.00017139955889433622 max memory_allocated 29271.81298828125 
[2025-03-01 16:08:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.0461747869849205 norm:0.00017747322272043675 max memory_allocated 29271.81298828125 
[2025-03-01 16:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.04616113752126694 norm:0.00017244883929379284 max memory_allocated 29271.81298828125 
[2025-03-01 16:10:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.0461588017642498 norm:0.00016884329670574516 max memory_allocated 29271.81298828125 
[2025-03-01 16:10:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-01 16:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.07933107763528824 norm:0.0037063327617943287 max memory_allocated 29271.81298828125 
[2025-03-01 16:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.0633544772863388 norm:0.0014694074634462595 max memory_allocated 29271.81298828125 
[2025-03-01 16:12:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.05573594197630882 norm:0.0007371176034212112 max memory_allocated 29271.81298828125 
[2025-03-01 16:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.05315646529197693 norm:0.00044273596722632647 max memory_allocated 29271.81298828125 
[2025-03-01 16:14:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.05171282961964607 norm:0.00031361228320747614 max memory_allocated 29271.81298828125 
[2025-03-01 16:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.05086371675133705 norm:0.0002487760502845049 max memory_allocated 29271.81298828125 
[2025-03-01 16:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.05040527507662773 norm:0.00022307840117719024 max memory_allocated 29271.81298828125 
[2025-03-01 16:17:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.05014260113239288 norm:0.00020228810899425298 max memory_allocated 29271.81298828125 
[2025-03-01 16:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.049995314329862595 norm:0.0001991644676309079 max memory_allocated 29271.81298828125 
[2025-03-01 16:18:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.04989456385374069 norm:0.00019582668028306216 max memory_allocated 29271.81298828125 
[2025-03-01 16:19:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.04983512684702873 norm:0.0001975504565052688 max memory_allocated 29271.81298828125 
[2025-03-01 16:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.04980586841702461 norm:0.00019235553918406367 max memory_allocated 29271.81298828125 
[2025-03-01 16:21:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.049760978668928146 norm:0.0001876925816759467 max memory_allocated 29271.81298828125 
[2025-03-01 16:22:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.04975157231092453 norm:0.00018464522145222872 max memory_allocated 29271.81298828125 
[2025-03-01 16:22:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.049714263528585434 norm:0.00018171944248024374 max memory_allocated 29271.81298828125 
[2025-03-01 16:23:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.04967096820473671 norm:0.00018088167416863143 max memory_allocated 29271.81298828125 
[2025-03-01 16:24:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.04966278746724129 norm:0.00018544458725955337 max memory_allocated 29271.81298828125 
[2025-03-01 16:25:27 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.04965095967054367 norm:0.00018354968051426113 max memory_allocated 29271.81298828125 
[2025-03-01 16:26:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.04962609335780144 norm:0.0001824300125008449 max memory_allocated 29271.81298828125 
[2025-03-01 16:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.04961313679814339 norm:0.00018249657296109945 max memory_allocated 29271.81298828125 
[2025-03-01 16:27:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-01 16:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.09103989601135254 norm:0.0032893302850425243 max memory_allocated 29271.81298828125 
[2025-03-01 16:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.071736641228199 norm:0.001493383082561195 max memory_allocated 29271.81298828125 
[2025-03-01 16:29:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.06285370141267776 norm:0.0008477240335196257 max memory_allocated 29271.81298828125 
[2025-03-01 16:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.060004934668540955 norm:0.0005753380246460438 max memory_allocated 29271.81298828125 
[2025-03-01 16:31:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.05845468491315842 norm:0.0004372185794636607 max memory_allocated 29271.81298828125 
[2025-03-01 16:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.05752221494913101 norm:0.0003559775068424642 max memory_allocated 29271.81298828125 
[2025-03-01 16:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.056979645043611526 norm:0.0003172836732119322 max memory_allocated 29271.81298828125 
[2025-03-01 16:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.05669142305850983 norm:0.00030512313242070377 max memory_allocated 29271.81298828125 
[2025-03-01 16:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.05647459626197815 norm:0.00028663111152127385 max memory_allocated 29271.81298828125 
[2025-03-01 16:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.056288741528987885 norm:0.00027401463012211025 max memory_allocated 29271.81298828125 
[2025-03-01 16:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.05620456114411354 norm:0.00027611246332526207 max memory_allocated 29271.81298828125 
[2025-03-01 16:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.05611051619052887 norm:0.00026230947696603835 max memory_allocated 29271.81298828125 
[2025-03-01 16:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.05605814978480339 norm:0.0002657851728145033 max memory_allocated 29271.81298828125 
[2025-03-01 16:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.0560070239007473 norm:0.0002624463231768459 max memory_allocated 29271.81298828125 
[2025-03-01 16:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.05595151335000992 norm:0.0002571647346485406 max memory_allocated 29271.81298828125 
[2025-03-01 16:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.05589995160698891 norm:0.00025017379084602 max memory_allocated 29271.81298828125 
[2025-03-01 16:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.05588333308696747 norm:0.0002527508186176419 max memory_allocated 29271.81298828125 
[2025-03-01 16:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.05587561056017876 norm:0.00026159765548072755 max memory_allocated 29271.81298828125 
[2025-03-01 16:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.055846113711595535 norm:0.00025706226006150246 max memory_allocated 29271.81298828125 
[2025-03-01 16:44:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.05584346130490303 norm:0.00025850810925476253 max memory_allocated 29271.81298828125 
[2025-03-01 16:44:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-01 16:45:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.09468621760606766 norm:0.003433105070143938 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.07630374282598495 norm:0.0015621710335835814 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.0673670694231987 norm:0.0008428789442405105 max memory_allocated 29272.37548828125 
[2025-03-01 16:47:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.06404802203178406 norm:0.0005317802424542606 max memory_allocated 29272.37548828125 
[2025-03-01 16:48:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.06226928532123566 norm:0.00038030045107007027 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.061283234506845474 norm:0.00030114513356238604 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.060735780745744705 norm:0.0002603660395834595 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.060443222522735596 norm:0.0002358618366997689 max memory_allocated 29272.37548828125 
[2025-03-01 16:51:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.06026144325733185 norm:0.00022366296616382897 max memory_allocated 29272.37548828125 
[2025-03-01 16:52:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.06012110412120819 norm:0.0002147893246728927 max memory_allocated 29272.37548828125 
[2025-03-01 16:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.06005478650331497 norm:0.00021292887686286122 max memory_allocated 29272.37548828125 
[2025-03-01 16:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.05997701361775398 norm:0.0002095552918035537 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.05991126596927643 norm:0.00020705675706267357 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.05987722799181938 norm:0.0002042346022790298 max memory_allocated 29272.37548828125 
[2025-03-01 16:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.059831440448760986 norm:0.00020378586486913264 max memory_allocated 29272.37548828125 
[2025-03-01 16:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.059804413467645645 norm:0.00020180485444143414 max memory_allocated 29272.37548828125 
[2025-03-01 16:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.059793129563331604 norm:0.00020688347285613418 max memory_allocated 29272.37548828125 
[2025-03-01 16:59:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.05975466966629028 norm:0.00020242884056642652 max memory_allocated 29272.37548828125 
[2025-03-01 17:00:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.05974190682172775 norm:0.0002041599655058235 max memory_allocated 29272.37548828125 
[2025-03-01 17:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.05972552299499512 norm:0.00020232491078786552 max memory_allocated 29272.37548828125 
[2025-03-01 17:01:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-01 17:02:06 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.12040409445762634 norm:0.004594486206769943 max memory_allocated 29272.37548828125 
[2025-03-01 17:02:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.09045150130987167 norm:0.0020132302306592464 max memory_allocated 29272.37548828125 
[2025-03-01 17:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.07681328058242798 norm:0.0010323278838768601 max memory_allocated 29272.37548828125 
[2025-03-01 17:04:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.0724320188164711 norm:0.0006666713161394 max memory_allocated 29272.37548828125 
[2025-03-01 17:05:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.07013647258281708 norm:0.0004905203240923584 max memory_allocated 29272.37548828125 
[2025-03-01 17:06:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.06879299879074097 norm:0.00039069599006325006 max memory_allocated 29272.37548828125 
[2025-03-01 17:07:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.06798828393220901 norm:0.0003416573745198548 max memory_allocated 29272.37548828125 
[2025-03-01 17:07:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.06753583252429962 norm:0.0003165666130371392 max memory_allocated 29272.37548828125 
[2025-03-01 17:08:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.06726334989070892 norm:0.0003063815529458225 max memory_allocated 29272.37548828125 
[2025-03-01 17:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.06704607605934143 norm:0.00029828271362930536 max memory_allocated 29272.37548828125 
[2025-03-01 17:10:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.06686153262853622 norm:0.0002863569825422019 max memory_allocated 29272.37548828125 
[2025-03-01 17:11:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.0667247548699379 norm:0.00027576248976401985 max memory_allocated 29272.37548828125 
[2025-03-01 17:12:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.06665369123220444 norm:0.00027828419115394354 max memory_allocated 29272.37548828125 
[2025-03-01 17:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.06652635335922241 norm:0.0002672754635568708 max memory_allocated 29272.37548828125 
[2025-03-01 17:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.0664304718375206 norm:0.00026023155078291893 max memory_allocated 29272.37548828125 
[2025-03-01 17:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.06637212634086609 norm:0.00027250207494944334 max memory_allocated 29272.37548828125 
[2025-03-01 17:15:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.06631585210561752 norm:0.0002772618317976594 max memory_allocated 29272.37548828125 
[2025-03-01 17:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.06625698506832123 norm:0.00027241301722824574 max memory_allocated 29272.37548828125 
[2025-03-01 17:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.06618347764015198 norm:0.0002613773394841701 max memory_allocated 29272.37548828125 
[2025-03-01 17:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.06613555550575256 norm:0.0002565509348642081 max memory_allocated 29272.37548828125 
[2025-03-01 17:18:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-01 17:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.10937723517417908 norm:0.00393429771065712 max memory_allocated 29272.37548828125 
[2025-03-01 17:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.089632049202919 norm:0.0018183058127760887 max memory_allocated 29272.37548828125 
[2025-03-01 17:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.0798560306429863 norm:0.001006217789836228 max memory_allocated 29272.37548828125 
[2025-03-01 17:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.0759897455573082 norm:0.0006462925812229514 max memory_allocated 29272.37548828125 
[2025-03-01 17:22:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.07389742881059647 norm:0.0004618836974259466 max memory_allocated 29272.37548828125 
[2025-03-01 17:23:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.07280001044273376 norm:0.00036023976281285286 max memory_allocated 29272.37548828125 
[2025-03-01 17:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.07224562764167786 norm:0.0003054671105928719 max memory_allocated 29272.37548828125 
[2025-03-01 17:24:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.07195764780044556 norm:0.0002726289094425738 max memory_allocated 29272.37548828125 
[2025-03-01 17:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.07176554948091507 norm:0.0002536496031098068 max memory_allocated 29272.37548828125 
[2025-03-01 17:26:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.07164143025875092 norm:0.00024127340293489397 max memory_allocated 29272.37548828125 
[2025-03-01 17:27:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.0715228021144867 norm:0.0002300846972502768 max memory_allocated 29272.37548828125 
[2025-03-01 17:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.07142723351716995 norm:0.00022364515461958945 max memory_allocated 29272.37548828125 
[2025-03-01 17:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.0714021548628807 norm:0.00023761947522871196 max memory_allocated 29272.37548828125 
[2025-03-01 17:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.07135199010372162 norm:0.00023599405540153384 max memory_allocated 29272.37548828125 
[2025-03-01 17:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.07128506898880005 norm:0.00023139792028814554 max memory_allocated 29272.37548828125 
[2025-03-01 17:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.07126310467720032 norm:0.00022851528774481267 max memory_allocated 29272.37548828125 
[2025-03-01 17:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.07127004861831665 norm:0.00022672534396406263 max memory_allocated 29272.37548828125 
[2025-03-01 17:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.07122793793678284 norm:0.0002282285422552377 max memory_allocated 29272.37548828125 
[2025-03-01 17:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.07119132578372955 norm:0.00022015933063812554 max memory_allocated 29272.37548828125 
[2025-03-01 17:34:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.07117100059986115 norm:0.00021971795649733394 max memory_allocated 29272.37548828125 
[2025-03-01 17:35:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-01 17:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.10979469120502472 norm:0.0022330707870423794 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.09246694296598434 norm:0.0010686912573873997 max memory_allocated 29272.93798828125 
[2025-03-01 17:37:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.08356905728578568 norm:0.0006007553893141448 max memory_allocated 29272.93798828125 
[2025-03-01 17:38:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.0801103338599205 norm:0.0003919928567484021 max memory_allocated 29272.93798828125 
[2025-03-01 17:39:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.07839640974998474 norm:0.0002923810970969498 max memory_allocated 29272.93798828125 
[2025-03-01 17:40:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.07746603339910507 norm:0.00024358250084333122 max memory_allocated 29272.93798828125 
[2025-03-01 17:40:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.07700031250715256 norm:0.00022129066928755492 max memory_allocated 29272.93798828125 
[2025-03-01 17:41:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.076755590736866 norm:0.00021093967370688915 max memory_allocated 29272.93798828125 
[2025-03-01 17:42:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.07659301161766052 norm:0.00020505368593148887 max memory_allocated 29272.93798828125 
[2025-03-01 17:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.07649033516645432 norm:0.00019896350568160415 max memory_allocated 29272.93798828125 
[2025-03-01 17:44:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.07639529556035995 norm:0.00019267764582764357 max memory_allocated 29272.93798828125 
[2025-03-01 17:45:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.07631705701351166 norm:0.0001907060359371826 max memory_allocated 29272.93798828125 
[2025-03-01 17:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.07623666524887085 norm:0.0001880251948023215 max memory_allocated 29272.93798828125 
[2025-03-01 17:46:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.07621242105960846 norm:0.0001872182183433324 max memory_allocated 29272.93798828125 
[2025-03-01 17:47:31 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.07616982609033585 norm:0.00019075027375947684 max memory_allocated 29272.93798828125 
[2025-03-01 17:48:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.07613211870193481 norm:0.00018639062182046473 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.07611923664808273 norm:0.00019056648307014257 max memory_allocated 29272.93798828125 
[2025-03-01 17:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.0760997012257576 norm:0.00018559984164312482 max memory_allocated 29272.93798828125 
[2025-03-01 17:50:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.07608437538146973 norm:0.00018536922289058566 max memory_allocated 29272.93798828125 
[2025-03-01 17:51:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.076046884059906 norm:0.00018900498980656266 max memory_allocated 29272.93798828125 
[2025-03-01 17:51:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-01 17:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.11597128212451935 norm:0.0023146988824009895 max memory_allocated 29272.93798828125 
[2025-03-01 17:53:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.09696309268474579 norm:0.0010809357045218349 max memory_allocated 29272.93798828125 
[2025-03-01 17:54:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.08712437748908997 norm:0.0005935594090260565 max memory_allocated 29272.93798828125 
[2025-03-01 17:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.08357315510511398 norm:0.00038701065932400525 max memory_allocated 29272.93798828125 
[2025-03-01 17:56:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.08183756470680237 norm:0.0002941295097116381 max memory_allocated 29272.93798828125 
[2025-03-01 17:56:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.08090478926897049 norm:0.00025094609009101987 max memory_allocated 29272.93798828125 
[2025-03-01 17:57:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.08037441968917847 norm:0.00022508740948978812 max memory_allocated 29272.93798828125 
[2025-03-01 17:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.08007203787565231 norm:0.0002090396883431822 max memory_allocated 29272.93798828125 
[2025-03-01 17:59:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.07988431304693222 norm:0.00020083636627532542 max memory_allocated 29272.93798828125 
[2025-03-01 18:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.07977739721536636 norm:0.00019821262685582042 max memory_allocated 29272.93798828125 
[2025-03-01 18:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.07966512441635132 norm:0.00019013488781638443 max memory_allocated 29272.93798828125 
[2025-03-01 18:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.07960641384124756 norm:0.00018607494712341577 max memory_allocated 29272.93798828125 
[2025-03-01 18:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.07953420281410217 norm:0.00018396205268800259 max memory_allocated 29272.93798828125 
[2025-03-01 18:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.07947410643100739 norm:0.0001811425609048456 max memory_allocated 29272.93798828125 
[2025-03-01 18:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.07943354547023773 norm:0.0001787778892321512 max memory_allocated 29272.93798828125 
[2025-03-01 18:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.07939434796571732 norm:0.0001784343912731856 max memory_allocated 29272.93798828125 
[2025-03-01 18:06:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.07935476303100586 norm:0.00017951663176063448 max memory_allocated 29272.93798828125 
[2025-03-01 18:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.0793309435248375 norm:0.0001789190573617816 max memory_allocated 29272.93798828125 
[2025-03-01 18:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.07929456979036331 norm:0.00017723148630466312 max memory_allocated 29272.93798828125 
[2025-03-01 18:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.0792701244354248 norm:0.00017411170119885355 max memory_allocated 29272.93798828125 
[2025-03-01 18:08:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-01 18:09:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.11421163380146027 norm:0.0022578048519790173 max memory_allocated 29272.93798828125 
[2025-03-01 18:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.09842468798160553 norm:0.0011202895548194647 max memory_allocated 29272.93798828125 
[2025-03-01 18:11:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.09011446684598923 norm:0.0006582955829799175 max memory_allocated 29272.93798828125 
[2025-03-01 18:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.08667820692062378 norm:0.0004408274544402957 max memory_allocated 29272.93798828125 
[2025-03-01 18:13:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.08484876900911331 norm:0.0003330204344820231 max memory_allocated 29272.93798828125 
[2025-03-01 18:13:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.08383392542600632 norm:0.00027383360429666936 max memory_allocated 29272.93798828125 
[2025-03-01 18:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.08331817388534546 norm:0.00024640251649543643 max memory_allocated 29272.93798828125 
[2025-03-01 18:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.08300396054983139 norm:0.00022900261683389544 max memory_allocated 29272.93798828125 
[2025-03-01 18:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.08281189948320389 norm:0.0002123176964232698 max memory_allocated 29272.93798828125 
[2025-03-01 18:17:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.08267927914857864 norm:0.00020370534912217408 max memory_allocated 29272.93798828125 
[2025-03-01 18:18:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.08257200568914413 norm:0.0001970916782738641 max memory_allocated 29272.93798828125 
[2025-03-01 18:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.0824810042977333 norm:0.00019317521946504712 max memory_allocated 29272.93798828125 
[2025-03-01 18:19:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.08241457492113113 norm:0.00019417073053773493 max memory_allocated 29272.93798828125 
[2025-03-01 18:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.0823792815208435 norm:0.00019625708227977157 max memory_allocated 29272.93798828125 
[2025-03-01 18:21:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.08234404027462006 norm:0.0001968053256860003 max memory_allocated 29272.93798828125 
[2025-03-01 18:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.08229412883520126 norm:0.00019155848713126034 max memory_allocated 29272.93798828125 
[2025-03-01 18:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.08226291090250015 norm:0.0001889375562313944 max memory_allocated 29272.93798828125 
[2025-03-01 18:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.08224599063396454 norm:0.00018596150039229542 max memory_allocated 29272.93798828125 
[2025-03-01 18:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.08222930133342743 norm:0.00019111853907816112 max memory_allocated 29272.93798828125 
[2025-03-01 18:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.0822134017944336 norm:0.0001919416681630537 max memory_allocated 29272.93798828125 
[2025-03-01 18:25:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-01 18:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.11833225935697556 norm:0.0024567535147070885 max memory_allocated 29273.50048828125 
[2025-03-01 18:27:29 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.10224336385726929 norm:0.0012039783177897334 max memory_allocated 29273.50048828125 
[2025-03-01 18:28:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.09332543611526489 norm:0.0006660349317826331 max memory_allocated 29273.50048828125 
[2025-03-01 18:29:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.08964763581752777 norm:0.00042569730430841446 max memory_allocated 29273.50048828125 
[2025-03-01 18:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.0879889726638794 norm:0.0003164422232657671 max memory_allocated 29273.50048828125 
[2025-03-01 18:30:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.08704967796802521 norm:0.00026787325623445213 max memory_allocated 29273.50048828125 
[2025-03-01 18:31:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.08652707934379578 norm:0.00023489580780733377 max memory_allocated 29273.50048828125 
[2025-03-01 18:32:29 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.0862359032034874 norm:0.0002155864203814417 max memory_allocated 29273.50048828125 
[2025-03-01 18:33:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.08603119105100632 norm:0.0002032561314990744 max memory_allocated 29273.50048828125 
[2025-03-01 18:34:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.08588795363903046 norm:0.00019605788111221045 max memory_allocated 29273.50048828125 
[2025-03-01 18:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.08579380065202713 norm:0.00018954757251776755 max memory_allocated 29273.50048828125 
[2025-03-01 18:35:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.08572050929069519 norm:0.0001828861713875085 max memory_allocated 29273.50048828125 
[2025-03-01 18:36:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.08564072847366333 norm:0.0001813610433600843 max memory_allocated 29273.50048828125 
[2025-03-01 18:37:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.08556021749973297 norm:0.0001759818842401728 max memory_allocated 29273.50048828125 
[2025-03-01 18:38:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.0855116993188858 norm:0.00017485696298535913 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.0854780301451683 norm:0.00017568162002135068 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.08544793725013733 norm:0.00017817606567405164 max memory_allocated 29273.50048828125 
[2025-03-01 18:40:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.08544177561998367 norm:0.00018185575027018785 max memory_allocated 29273.50048828125 
[2025-03-01 18:41:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.08540627360343933 norm:0.00018133597041014582 max memory_allocated 29273.50048828125 
[2025-03-01 18:42:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.08536020666360855 norm:0.00018245293176732957 max memory_allocated 29273.50048828125 
[2025-03-01 18:42:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-01 18:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.11121329665184021 norm:0.0015064779436215758 max memory_allocated 29273.50048828125 
[2025-03-01 18:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.09944014251232147 norm:0.0007231198833324015 max memory_allocated 29273.50048828125 
[2025-03-01 18:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.09209229797124863 norm:0.0004200285766273737 max memory_allocated 29273.50048828125 
[2025-03-01 18:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.08932440727949142 norm:0.0002926589804701507 max memory_allocated 29273.50048828125 
[2025-03-01 18:46:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.08796656131744385 norm:0.00023676735872868448 max memory_allocated 29273.50048828125 
[2025-03-01 18:47:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.087155282497406 norm:0.00020529201719909906 max memory_allocated 29273.50048828125 
[2025-03-01 18:48:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.08669032156467438 norm:0.0001870706328190863 max memory_allocated 29273.50048828125 
[2025-03-01 18:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.08639955520629883 norm:0.00017336648306809366 max memory_allocated 29273.50048828125 
[2025-03-01 18:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.08623722195625305 norm:0.00016631794278509915 max memory_allocated 29273.50048828125 
[2025-03-01 18:51:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.08610142767429352 norm:0.0001615822548046708 max memory_allocated 29273.50048828125 
[2025-03-01 18:51:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.08600997179746628 norm:0.00015989360690582544 max memory_allocated 29273.50048828125 
[2025-03-01 18:52:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.08594048023223877 norm:0.0001557012292323634 max memory_allocated 29273.50048828125 
[2025-03-01 18:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.0858737975358963 norm:0.00015403535508085042 max memory_allocated 29273.50048828125 
[2025-03-01 18:54:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.08584755659103394 norm:0.00015349124441854656 max memory_allocated 29273.50048828125 
[2025-03-01 18:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.08580425381660461 norm:0.0001510019792476669 max memory_allocated 29273.50048828125 
[2025-03-01 18:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.08576799184083939 norm:0.0001473447773605585 max memory_allocated 29273.50048828125 
[2025-03-01 18:56:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.08574250340461731 norm:0.00014547754835803062 max memory_allocated 29273.50048828125 
[2025-03-01 18:57:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.08571714907884598 norm:0.0001454589219065383 max memory_allocated 29273.50048828125 
[2025-03-01 18:58:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.08568184822797775 norm:0.00014455050404649228 max memory_allocated 29273.50048828125 
[2025-03-01 18:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.08567475527524948 norm:0.00014390105206985027 max memory_allocated 29273.50048828125 
[2025-03-01 18:59:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-01 19:00:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.11579632759094238 norm:0.001939613139256835 max memory_allocated 29273.50048828125 
[2025-03-01 19:01:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.10269292443990707 norm:0.0008869011071510613 max memory_allocated 29273.50048828125 
[2025-03-01 19:02:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.09475763887166977 norm:0.0005098773399367929 max memory_allocated 29273.50048828125 
[2025-03-01 19:03:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.09185556322336197 norm:0.00035055718035437167 max memory_allocated 29273.50048828125 
[2025-03-01 19:03:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.09031962603330612 norm:0.00028523680521175265 max memory_allocated 29273.50048828125 
[2025-03-01 19:04:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.08940038830041885 norm:0.00025323149748146534 max memory_allocated 29273.50048828125 
[2025-03-01 19:05:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.08885346353054047 norm:0.00023182874429039657 max memory_allocated 29273.50048828125 
[2025-03-01 19:06:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.08850577473640442 norm:0.00022206871653907 max memory_allocated 29273.50048828125 
[2025-03-01 19:07:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.08826139569282532 norm:0.00021173711866140366 max memory_allocated 29273.50048828125 
[2025-03-01 19:08:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.08810076117515564 norm:0.00020277898875065148 max memory_allocated 29273.50048828125 
[2025-03-01 19:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.08801806718111038 norm:0.0001941895461641252 max memory_allocated 29273.50048828125 
[2025-03-01 19:09:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.08792909234762192 norm:0.00019411894027143717 max memory_allocated 29273.50048828125 
[2025-03-01 19:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.08787354826927185 norm:0.00018951755191665143 max memory_allocated 29273.50048828125 
[2025-03-01 19:11:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.08779491484165192 norm:0.00018352223560214043 max memory_allocated 29273.50048828125 
[2025-03-01 19:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.08774362504482269 norm:0.0001794986892491579 max memory_allocated 29273.50048828125 
[2025-03-01 19:12:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.08769097179174423 norm:0.00017620080325286835 max memory_allocated 29273.50048828125 
[2025-03-01 19:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.08763447403907776 norm:0.00017692420806270093 max memory_allocated 29273.50048828125 
[2025-03-01 19:14:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.08759451657533646 norm:0.00017615247634239495 max memory_allocated 29273.50048828125 
[2025-03-01 19:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.08754494041204453 norm:0.00017068396846298128 max memory_allocated 29273.50048828125 
[2025-03-01 19:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.08753085136413574 norm:0.0001725977926980704 max memory_allocated 29273.50048828125 
[2025-03-01 19:16:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-01 19:17:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.11181487143039703 norm:0.002924928907305002 max memory_allocated 29274.06298828125 
[2025-03-01 19:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.10123492777347565 norm:0.001447570393793285 max memory_allocated 29274.06298828125 
[2025-03-01 19:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.094671331346035 norm:0.0008577973349019885 max memory_allocated 29274.06298828125 
[2025-03-01 19:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.09210522472858429 norm:0.0005884882993996143 max memory_allocated 29274.06298828125 
[2025-03-01 19:20:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.0906938761472702 norm:0.0004518299247138202 max memory_allocated 29274.06298828125 
[2025-03-01 19:21:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.08983246982097626 norm:0.0003642783558461815 max memory_allocated 29274.06298828125 
[2025-03-01 19:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.08932424336671829 norm:0.0003085973730776459 max memory_allocated 29274.06298828125 
[2025-03-01 19:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.08900783956050873 norm:0.00027708683046512306 max memory_allocated 29274.06298828125 
[2025-03-01 19:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.08880672603845596 norm:0.00024918364943005145 max memory_allocated 29274.06298828125 
[2025-03-01 19:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.08867363631725311 norm:0.00023511884501203895 max memory_allocated 29274.06298828125 
[2025-03-01 19:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.08853352069854736 norm:0.0002228862576885149 max memory_allocated 29274.06298828125 
[2025-03-01 19:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.08845202624797821 norm:0.00021646273671649396 max memory_allocated 29274.06298828125 
[2025-03-01 19:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.08839762955904007 norm:0.0002076557429973036 max memory_allocated 29274.06298828125 
[2025-03-01 19:28:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.08835794776678085 norm:0.00020240845333319157 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.08831572532653809 norm:0.00019477489695418626 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.08829653263092041 norm:0.00019215454813092947 max memory_allocated 29274.06298828125 
[2025-03-01 19:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.08827033638954163 norm:0.00018705106049310416 max memory_allocated 29274.06298828125 
[2025-03-01 19:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.08825461566448212 norm:0.00018668663688004017 max memory_allocated 29274.06298828125 
[2025-03-01 19:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.08822371065616608 norm:0.00018457794794812799 max memory_allocated 29274.06298828125 
[2025-03-01 19:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.08820515871047974 norm:0.00018400541739538312 max memory_allocated 29274.06298828125 
[2025-03-01 19:33:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-01 19:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.10991372168064117 norm:0.001605871831998229 max memory_allocated 29274.06298828125 
[2025-03-01 19:35:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.10070174932479858 norm:0.0007609922904521227 max memory_allocated 29274.06298828125 
[2025-03-01 19:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.09515982121229172 norm:0.0004600977699737996 max memory_allocated 29274.06298828125 
[2025-03-01 19:36:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.09314674139022827 norm:0.0003231759765185416 max memory_allocated 29274.06298828125 
[2025-03-01 19:37:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.09188611805438995 norm:0.0002511504280846566 max memory_allocated 29274.06298828125 
[2025-03-01 19:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.09104640781879425 norm:0.00020791102724615484 max memory_allocated 29274.06298828125 
[2025-03-01 19:39:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.09054841846227646 norm:0.00018084947078023106 max memory_allocated 29274.06298828125 
[2025-03-01 19:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.0902882069349289 norm:0.00016500016499776393 max memory_allocated 29274.06298828125 
[2025-03-01 19:41:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.09011933207511902 norm:0.00015449397324118763 max memory_allocated 29274.06298828125 
[2025-03-01 19:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.08999782055616379 norm:0.0001471780997235328 max memory_allocated 29274.06298828125 
[2025-03-01 19:42:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.08990512788295746 norm:0.0001430875126970932 max memory_allocated 29274.06298828125 
[2025-03-01 19:43:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.08983217924833298 norm:0.00013788585783913732 max memory_allocated 29274.06298828125 
[2025-03-01 19:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.08976908773183823 norm:0.00013674421643372625 max memory_allocated 29274.06298828125 
[2025-03-01 19:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.08970075845718384 norm:0.00013074773596599698 max memory_allocated 29274.06298828125 
[2025-03-01 19:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.08965790271759033 norm:0.00012578607129398733 max memory_allocated 29274.06298828125 
[2025-03-01 19:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.08963488042354584 norm:0.00012730057642329484 max memory_allocated 29274.06298828125 
[2025-03-01 19:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.0895921140909195 norm:0.00012587184028234333 max memory_allocated 29274.06298828125 
[2025-03-01 19:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.08955669403076172 norm:0.00012661382788792253 max memory_allocated 29274.06298828125 
[2025-03-01 19:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.08952905237674713 norm:0.0001263608137378469 max memory_allocated 29274.06298828125 
[2025-03-01 19:50:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.08951936662197113 norm:0.00012472577509470284 max memory_allocated 29274.06298828125 
[2025-03-01 19:50:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-01 19:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.1121656745672226 norm:0.0011526909656822681 max memory_allocated 29274.06298828125 
[2025-03-01 19:52:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.10419107973575592 norm:0.000552129466086626 max memory_allocated 29274.06298828125 
[2025-03-01 19:52:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.09875722229480743 norm:0.00033207994420081377 max memory_allocated 29274.06298828125 
[2025-03-01 19:53:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.09690754860639572 norm:0.00023587577743455768 max memory_allocated 29274.06298828125 
[2025-03-01 19:54:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.09572673588991165 norm:0.00019023194909095764 max memory_allocated 29274.06298828125 
[2025-03-01 19:55:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.09494145214557648 norm:0.0001671162317506969 max memory_allocated 29274.06298828125 
[2025-03-01 19:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.09448510408401489 norm:0.00015167008677963167 max memory_allocated 29274.06298828125 
[2025-03-01 19:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.09424187988042831 norm:0.00014217791613191366 max memory_allocated 29274.06298828125 
[2025-03-01 19:57:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.09409061819314957 norm:0.00013472020509652793 max memory_allocated 29274.06298828125 
[2025-03-01 19:58:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.09396050870418549 norm:0.00012914053513668478 max memory_allocated 29274.06298828125 
[2025-03-01 19:59:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.09387880563735962 norm:0.00012582050112541765 max memory_allocated 29274.06298828125 
[2025-03-01 20:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.09382899105548859 norm:0.00012455304386094213 max memory_allocated 29274.06298828125 
[2025-03-01 20:01:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.09378009289503098 norm:0.00012355047510936856 max memory_allocated 29274.06298828125 
[2025-03-01 20:02:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.0937265008687973 norm:0.00012054554099449888 max memory_allocated 29274.06298828125 
[2025-03-01 20:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.09369126707315445 norm:0.00011984892626060173 max memory_allocated 29274.06298828125 
[2025-03-01 20:03:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.09364679455757141 norm:0.00011876015196321532 max memory_allocated 29274.06298828125 
[2025-03-01 20:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.09362838417291641 norm:0.00011910503235412762 max memory_allocated 29274.06298828125 
[2025-03-01 20:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.09359666705131531 norm:0.00011954637011513114 max memory_allocated 29274.06298828125 
[2025-03-01 20:06:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.09357752650976181 norm:0.00011969998013228178 max memory_allocated 29274.06298828125 
[2025-03-01 20:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.09355585277080536 norm:0.00011825546971522272 max memory_allocated 29274.06298828125 
[2025-03-01 20:07:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-01 20:08:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.11663217842578888 norm:0.0011308472603559494 max memory_allocated 29274.62548828125 
[2025-03-01 20:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.1089126393198967 norm:0.0005511267227120697 max memory_allocated 29274.62548828125 
[2025-03-01 20:09:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.10339263081550598 norm:0.00033662086934782565 max memory_allocated 29274.62548828125 
[2025-03-01 20:10:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.10149925202131271 norm:0.0002396109193796292 max memory_allocated 29274.62548828125 
[2025-03-01 20:11:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.10038139671087265 norm:0.00019229063764214516 max memory_allocated 29274.62548828125 
[2025-03-01 20:12:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.09962102770805359 norm:0.0001637902169022709 max memory_allocated 29274.62548828125 
[2025-03-01 20:13:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.09916739165782928 norm:0.00014854913752060384 max memory_allocated 29274.62548828125 
[2025-03-01 20:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.0989241674542427 norm:0.0001392416306771338 max memory_allocated 29274.62548828125 
[2025-03-01 20:14:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.09878486394882202 norm:0.000132644985569641 max memory_allocated 29274.62548828125 
[2025-03-01 20:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.0986698642373085 norm:0.00012721712118946016 max memory_allocated 29274.62548828125 
[2025-03-01 20:16:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.09857473522424698 norm:0.0001246865576831624 max memory_allocated 29274.62548828125 
[2025-03-01 20:17:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.09851335734128952 norm:0.00012183793296571821 max memory_allocated 29274.62548828125 
[2025-03-01 20:18:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.09845779836177826 norm:0.00012150975089753047 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.09841767698526382 norm:0.00011967062891926616 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.09837538003921509 norm:0.00011947281745960936 max memory_allocated 29274.62548828125 
[2025-03-01 20:20:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.09833986312150955 norm:0.00011900361278094351 max memory_allocated 29274.62548828125 
[2025-03-01 20:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.0983118787407875 norm:0.00012112801778130233 max memory_allocated 29274.62548828125 
[2025-03-01 20:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.09828511625528336 norm:0.00011986169556621462 max memory_allocated 29274.62548828125 
[2025-03-01 20:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.09826260060071945 norm:0.00011994815577054396 max memory_allocated 29274.62548828125 
[2025-03-01 20:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.0982489287853241 norm:0.00011662302858894691 max memory_allocated 29274.62548828125 
[2025-03-01 20:24:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-01 20:25:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.12641292810440063 norm:0.0012869203928858042 max memory_allocated 29274.81298828125 
[2025-03-01 20:26:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.11757523566484451 norm:0.0006566287484019995 max memory_allocated 29274.81298828125 
[2025-03-01 20:26:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.11142653226852417 norm:0.00041283093742094934 max memory_allocated 29274.81298828125 
[2025-03-01 20:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.10932175815105438 norm:0.0002995042596012354 max memory_allocated 29274.81298828125 
[2025-03-01 20:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.10809394717216492 norm:0.00024180889886338264 max memory_allocated 29274.81298828125 
[2025-03-01 20:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.10726958513259888 norm:0.00020690640667453408 max memory_allocated 29274.81298828125 
[2025-03-01 20:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.10675296932458878 norm:0.00018726820417214185 max memory_allocated 29274.81298828125 
[2025-03-01 20:30:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.10644927620887756 norm:0.00017498634406365454 max memory_allocated 29274.81298828125 
[2025-03-01 20:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.10626538842916489 norm:0.00016387477808166295 max memory_allocated 29274.81298828125 
[2025-03-01 20:32:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.10614475607872009 norm:0.00015834883379284292 max memory_allocated 29274.81298828125 
[2025-03-01 20:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.10603341460227966 norm:0.00015376108058262616 max memory_allocated 29274.81298828125 
[2025-03-01 20:34:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.10595985502004623 norm:0.00014742944040335715 max memory_allocated 29274.81298828125 
[2025-03-01 20:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.10589599609375 norm:0.00014677857689093798 max memory_allocated 29274.81298828125 
[2025-03-01 20:35:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.10582175850868225 norm:0.00014159464626573026 max memory_allocated 29274.81298828125 
[2025-03-01 20:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.10575255751609802 norm:0.00014077164814807475 max memory_allocated 29274.81298828125 
[2025-03-01 20:37:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.1057199090719223 norm:0.00013919227058067918 max memory_allocated 29274.81298828125 
[2025-03-01 20:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.10569535195827484 norm:0.00013659243995789438 max memory_allocated 29274.81298828125 
[2025-03-01 20:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.10564816743135452 norm:0.00013421692710835487 max memory_allocated 29274.81298828125 
[2025-03-01 20:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.10563056170940399 norm:0.00013520223728846759 max memory_allocated 29274.81298828125 
[2025-03-01 20:40:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.10560880601406097 norm:0.00013758188288193196 max memory_allocated 29274.81298828125 
[2025-03-01 20:41:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-01 20:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.13033124804496765 norm:0.0009637729963287711 max memory_allocated 29275.00048828125 
[2025-03-01 20:42:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.1238279789686203 norm:0.000474458618555218 max memory_allocated 29275.00048828125 
[2025-03-01 20:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.11854767799377441 norm:0.00028272171039134264 max memory_allocated 29275.00048828125 
[2025-03-01 20:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.1170886904001236 norm:0.0002087449684040621 max memory_allocated 29275.00048828125 
[2025-03-01 20:45:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.11602937430143356 norm:0.0001715776015771553 max memory_allocated 29275.00048828125 
[2025-03-01 20:46:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.11523370444774628 norm:0.0001531152956886217 max memory_allocated 29275.00048828125 
[2025-03-01 20:47:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.11477966606616974 norm:0.0001440665073459968 max memory_allocated 29275.00048828125 
[2025-03-01 20:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.11456292867660522 norm:0.00014646501222159714 max memory_allocated 29275.00048828125 
[2025-03-01 20:48:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.11440500617027283 norm:0.00013216296792961657 max memory_allocated 29275.00048828125 
[2025-03-01 20:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.11428097635507584 norm:0.00012813700595870614 max memory_allocated 29275.00048828125 
[2025-03-01 20:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.11416718363761902 norm:0.00012560788309201598 max memory_allocated 29275.00048828125 
[2025-03-01 20:51:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.11409452557563782 norm:0.0001238417171407491 max memory_allocated 29275.00048828125 
[2025-03-01 20:52:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.11404929310083389 norm:0.0001250694040209055 max memory_allocated 29275.00048828125 
[2025-03-01 20:52:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.11399754881858826 norm:0.0001229002809850499 max memory_allocated 29275.00048828125 
[2025-03-01 20:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.11394497007131577 norm:0.00012195050658192486 max memory_allocated 29275.00048828125 
[2025-03-01 20:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.11389390379190445 norm:0.00011870503658428788 max memory_allocated 29275.00048828125 
[2025-03-01 20:55:24 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.11387131363153458 norm:0.0001195149525301531 max memory_allocated 29275.00048828125 
[2025-03-01 20:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.11384540796279907 norm:0.00011932563938898966 max memory_allocated 29275.00048828125 
[2025-03-01 20:57:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.11382035166025162 norm:0.00012076966231688857 max memory_allocated 29275.00048828125 
[2025-03-01 20:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.11380697786808014 norm:0.00012266264820937067 max memory_allocated 29275.00048828125 
[2025-03-01 20:58:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-01 20:59:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.1410302370786667 norm:0.0009628881234675646 max memory_allocated 29275.18798828125 
[2025-03-01 20:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.1343357264995575 norm:0.0004899917403236032 max memory_allocated 29275.18798828125 
[2025-03-01 21:00:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.1287892907857895 norm:0.0002824666444212198 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.12720011174678802 norm:0.0002077994286082685 max memory_allocated 29275.18798828125 
[2025-03-01 21:02:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.12614235281944275 norm:0.0001718270214041695 max memory_allocated 29275.18798828125 
[2025-03-01 21:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.12533466517925262 norm:0.00015156676818151027 max memory_allocated 29275.18798828125 
[2025-03-01 21:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.12487106770277023 norm:0.0002003558911383152 max memory_allocated 29275.18798828125 
[2025-03-01 21:04:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.12464307993650436 norm:0.00013246925664134324 max memory_allocated 29275.18798828125 
[2025-03-01 21:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.12448766082525253 norm:0.00012993632117286325 max memory_allocated 29275.18798828125 
[2025-03-01 21:06:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.12437761574983597 norm:0.0001256345713045448 max memory_allocated 29275.18798828125 
[2025-03-01 21:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.12428031116724014 norm:0.00012298680667299777 max memory_allocated 29275.18798828125 
[2025-03-01 21:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.1242060512304306 norm:0.00012012948718620464 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.12415480613708496 norm:0.00011839835497085005 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.12410260736942291 norm:0.00011887005530297756 max memory_allocated 29275.18798828125 
[2025-03-01 21:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.12404567003250122 norm:0.00011870836897287518 max memory_allocated 29275.18798828125 
[2025-03-01 21:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.12401622533798218 norm:0.0001205088192364201 max memory_allocated 29275.18798828125 
[2025-03-01 21:12:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.12397880107164383 norm:0.00012201994832139462 max memory_allocated 29275.18798828125 
[2025-03-01 21:13:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.123957559466362 norm:0.00012455481919459999 max memory_allocated 29275.18798828125 
[2025-03-01 21:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.12394258379936218 norm:0.0001236553944181651 max memory_allocated 29275.18798828125 
[2025-03-01 21:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.12392634898424149 norm:0.00012563407653942704 max memory_allocated 29275.18798828125 
[2025-03-01 21:15:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-01 21:15:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.15160107612609863 norm:0.0008145695901475847 max memory_allocated 29275.37548828125 
[2025-03-01 21:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.14518335461616516 norm:0.0004203920834697783 max memory_allocated 29275.37548828125 
[2025-03-01 21:17:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.13965553045272827 norm:0.0002677683369256556 max memory_allocated 29275.37548828125 
[2025-03-01 21:18:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.1382027566432953 norm:0.00020738437888212502 max memory_allocated 29275.37548828125 
[2025-03-01 21:19:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.13713045418262482 norm:0.00017836701590567827 max memory_allocated 29275.37548828125 
[2025-03-01 21:20:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.13629817962646484 norm:0.00016543532547075301 max memory_allocated 29275.37548828125 
[2025-03-01 21:20:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.13584424555301666 norm:0.0001671724021434784 max memory_allocated 29275.37548828125 
[2025-03-01 21:21:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.13561326265335083 norm:0.00016057584434747696 max memory_allocated 29275.37548828125 
[2025-03-01 21:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.13548214733600616 norm:0.00016097903426270932 max memory_allocated 29275.37548828125 
[2025-03-01 21:23:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.1353742778301239 norm:0.00017312573618255556 max memory_allocated 29275.37548828125 
[2025-03-01 21:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.13528238236904144 norm:0.00018023219308815897 max memory_allocated 29275.37548828125 
[2025-03-01 21:25:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.13519875705242157 norm:0.00017333384312223643 max memory_allocated 29275.37548828125 
[2025-03-01 21:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.1351354569196701 norm:0.000173927764990367 max memory_allocated 29275.37548828125 
[2025-03-01 21:26:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.13508228957653046 norm:0.00017452973406761885 max memory_allocated 29275.37548828125 
[2025-03-01 21:27:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.13503669202327728 norm:0.0001762946048984304 max memory_allocated 29275.37548828125 
[2025-03-01 21:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.13499470055103302 norm:0.00017630036745686084 max memory_allocated 29275.37548828125 
[2025-03-01 21:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.13497623801231384 norm:0.00018085715419147164 max memory_allocated 29275.37548828125 
[2025-03-01 21:30:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.13494464755058289 norm:0.00017540596309117973 max memory_allocated 29275.37548828125 
[2025-03-01 21:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.13491632044315338 norm:0.00018798228120431304 max memory_allocated 29275.37548828125 
[2025-03-01 21:31:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.13488249480724335 norm:0.00018533371621742845 max memory_allocated 29275.37548828125 
[2025-03-01 21:31:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-01 21:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.16474737226963043 norm:0.0008060429827310145 max memory_allocated 29275.56298828125 
[2025-03-01 21:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.1580882966518402 norm:0.000392710993764922 max memory_allocated 29275.56298828125 
[2025-03-01 21:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.15217265486717224 norm:0.0002494636573828757 max memory_allocated 29275.56298828125 
[2025-03-01 21:35:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.15061476826667786 norm:0.00019132994930259883 max memory_allocated 29275.56298828125 
[2025-03-01 21:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.14947371184825897 norm:0.00016048540419433266 max memory_allocated 29275.56298828125 
[2025-03-01 21:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.1485804170370102 norm:0.00015688811254221946 max memory_allocated 29275.56298828125 
[2025-03-01 21:37:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.14815101027488708 norm:0.00013159138325136155 max memory_allocated 29275.56298828125 
[2025-03-01 21:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.1479574739933014 norm:0.00012437801342457533 max memory_allocated 29275.56298828125 
[2025-03-01 21:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.1478085070848465 norm:0.00012016142136417329 max memory_allocated 29275.56298828125 
[2025-03-01 21:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.14769777655601501 norm:0.00011610682850005105 max memory_allocated 29275.56298828125 
[2025-03-01 21:41:12 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.14760826528072357 norm:0.00011455165076768026 max memory_allocated 29275.56298828125 
[2025-03-01 21:42:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.1475246548652649 norm:0.00011349494161549956 max memory_allocated 29275.56298828125 
[2025-03-01 21:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.14745590090751648 norm:0.0001120078595704399 max memory_allocated 29275.56298828125 
[2025-03-01 21:43:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.14740094542503357 norm:0.00011095392983406782 max memory_allocated 29275.56298828125 
[2025-03-01 21:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.1473536491394043 norm:0.00010998633661074564 max memory_allocated 29275.56298828125 
[2025-03-01 21:45:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.14731423556804657 norm:0.00010965006367769092 max memory_allocated 29275.56298828125 
[2025-03-01 21:46:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.14727866649627686 norm:0.00010940300853690132 max memory_allocated 29275.56298828125 
[2025-03-01 21:47:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.14724938571453094 norm:0.00010785324411699548 max memory_allocated 29275.56298828125 
[2025-03-01 21:47:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.1472238153219223 norm:0.00010763776663225144 max memory_allocated 29275.56298828125 
[2025-03-01 21:48:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.14719273149967194 norm:0.00010816421126946807 max memory_allocated 29275.56298828125 
[2025-03-01 21:48:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-01 21:49:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.1804129183292389 norm:0.0009077634895220399 max memory_allocated 29275.75048828125 
[2025-03-01 21:50:39 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.1734527349472046 norm:0.0005092486971989274 max memory_allocated 29275.75048828125 
[2025-03-01 21:51:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.16712340712547302 norm:0.00033576751593500376 max memory_allocated 29275.75048828125 
[2025-03-01 21:52:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.16540704667568207 norm:0.00026217332924716175 max memory_allocated 29275.75048828125 
[2025-03-01 21:53:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.16412943601608276 norm:0.00023088720627129078 max memory_allocated 29275.75048828125 
[2025-03-01 21:53:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.16320103406906128 norm:0.00020354369189590216 max memory_allocated 29275.75048828125 
[2025-03-01 21:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.16275598108768463 norm:0.00018889145576395094 max memory_allocated 29275.75048828125 
[2025-03-01 21:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.16249939799308777 norm:0.00017439370276406407 max memory_allocated 29275.75048828125 
[2025-03-01 21:56:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.16234461963176727 norm:0.00016943670925684273 max memory_allocated 29275.75048828125 
[2025-03-01 21:57:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.16221866011619568 norm:0.00016524789680261165 max memory_allocated 29275.75048828125 
[2025-03-01 21:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.1621207296848297 norm:0.0001593627966940403 max memory_allocated 29275.75048828125 
[2025-03-01 21:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.16205306351184845 norm:0.00015890591021161526 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.16198313236236572 norm:0.00015152982086874545 max memory_allocated 29275.75048828125 
[2025-03-01 22:00:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.16189680993556976 norm:0.0001502265513408929 max memory_allocated 29275.75048828125 
[2025-03-01 22:01:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.1618402898311615 norm:0.00015334892668761313 max memory_allocated 29275.75048828125 
[2025-03-01 22:02:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.16179221868515015 norm:0.00015146032092161477 max memory_allocated 29275.75048828125 
[2025-03-01 22:03:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.16174151003360748 norm:0.00015483706374652684 max memory_allocated 29275.75048828125 
[2025-03-01 22:03:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.16168749332427979 norm:0.00014958986139390618 max memory_allocated 29275.75048828125 
[2025-03-01 22:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.16166037321090698 norm:0.00015495403204113245 max memory_allocated 29275.75048828125 
[2025-03-01 22:05:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.16163881123065948 norm:0.00016123621026054025 max memory_allocated 29275.75048828125 
[2025-03-01 22:05:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-01 22:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.19434356689453125 norm:0.0006280713714659214 max memory_allocated 29275.93798828125 
[2025-03-01 22:07:35 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.18769662082195282 norm:0.0003578179457690567 max memory_allocated 29275.93798828125 
[2025-03-01 22:08:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.1814454048871994 norm:0.00024415511870756745 max memory_allocated 29275.93798828125 
[2025-03-01 22:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.17978796362876892 norm:0.00019418196461629122 max memory_allocated 29275.93798828125 
[2025-03-01 22:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.17852835357189178 norm:0.00016645420691929758 max memory_allocated 29275.93798828125 
[2025-03-01 22:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.17764976620674133 norm:0.0001507543056504801 max memory_allocated 29275.93798828125 
[2025-03-01 22:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.17725533246994019 norm:0.00014047810691408813 max memory_allocated 29275.93798828125 
[2025-03-01 22:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.1770448386669159 norm:0.00013336622214410454 max memory_allocated 29275.93798828125 
[2025-03-01 22:13:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.17688922584056854 norm:0.00012924187467433512 max memory_allocated 29275.93798828125 
[2025-03-01 22:14:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.17677119374275208 norm:0.0001573212502989918 max memory_allocated 29275.93798828125 
[2025-03-01 22:15:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.17667606472969055 norm:0.0001279527641599998 max memory_allocated 29275.93798828125 
[2025-03-01 22:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.17659892141819 norm:0.00012450684153009206 max memory_allocated 29275.93798828125 
[2025-03-01 22:16:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.17652124166488647 norm:0.0001231048081535846 max memory_allocated 29275.93798828125 
[2025-03-01 22:17:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.17645186185836792 norm:0.00012048339704051614 max memory_allocated 29275.93798828125 
[2025-03-01 22:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.17639872431755066 norm:0.0001180740655399859 max memory_allocated 29275.93798828125 
[2025-03-01 22:19:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.17633584141731262 norm:0.00011678089504130185 max memory_allocated 29275.93798828125 
[2025-03-01 22:20:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.17627516388893127 norm:0.00011734204599633813 max memory_allocated 29275.93798828125 
[2025-03-01 22:20:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.17623469233512878 norm:0.00011699589958880097 max memory_allocated 29275.93798828125 
[2025-03-01 22:21:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.17620041966438293 norm:0.00012066399358445778 max memory_allocated 29275.93798828125 
[2025-03-01 22:22:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.17617319524288177 norm:0.00011957965762121603 max memory_allocated 29275.93798828125 
[2025-03-01 22:22:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-01 22:23:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.21684938669204712 norm:0.0012550638057291508 max memory_allocated 29276.12548828125 
[2025-03-01 22:24:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.20897577702999115 norm:0.0007281341822817922 max memory_allocated 29276.12548828125 
[2025-03-01 22:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.20209713280200958 norm:0.0005042339907959104 max memory_allocated 29276.12548828125 
[2025-03-01 22:26:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.20013871788978577 norm:0.0004112014139536768 max memory_allocated 29276.12548828125 
[2025-03-01 22:27:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.19851264357566833 norm:0.0003465856716502458 max memory_allocated 29276.12548828125 
[2025-03-01 22:27:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.19748832285404205 norm:0.0003340710827615112 max memory_allocated 29276.12548828125 
[2025-03-01 22:28:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.19704841077327728 norm:0.00034928982495330274 max memory_allocated 29276.12548828125 
[2025-03-01 22:29:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.19679677486419678 norm:0.0003306234139017761 max memory_allocated 29276.12548828125 
[2025-03-01 22:30:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.19664540886878967 norm:0.0003225056279916316 max memory_allocated 29276.12548828125 
[2025-03-01 22:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.1964614987373352 norm:0.0002803403476718813 max memory_allocated 29276.12548828125 
[2025-03-01 22:32:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.19622792303562164 norm:0.00024209577532019466 max memory_allocated 29276.12548828125 
[2025-03-01 22:32:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.19604498147964478 norm:0.00022037865710444748 max memory_allocated 29276.12548828125 
[2025-03-01 22:33:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.19593754410743713 norm:0.00022621857351623476 max memory_allocated 29276.12548828125 
[2025-03-01 22:34:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.19583523273468018 norm:0.00024489773204550147 max memory_allocated 29276.12548828125 
[2025-03-01 22:35:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.19579002261161804 norm:0.00025336843100376427 max memory_allocated 29276.12548828125 
[2025-03-01 22:36:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.19572564959526062 norm:0.00024500812287442386 max memory_allocated 29276.12548828125 
[2025-03-01 22:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.19566906988620758 norm:0.00023828414850868285 max memory_allocated 29276.12548828125 
[2025-03-01 22:37:49 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.19556762278079987 norm:0.00022281758720055223 max memory_allocated 29276.12548828125 
[2025-03-01 22:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.19555631279945374 norm:0.0002247024531243369 max memory_allocated 29276.12548828125 
[2025-03-01 22:39:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.19553931057453156 norm:0.00023791393323335797 max memory_allocated 29276.12548828125 
[2025-03-01 22:39:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-01 22:40:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.23346669971942902 norm:0.0009828497422859073 max memory_allocated 29276.31298828125 
[2025-03-01 22:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.2259581983089447 norm:0.0005489401519298553 max memory_allocated 29276.31298828125 
[2025-03-01 22:42:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.21903455257415771 norm:0.0003579558106139302 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.21718452870845795 norm:0.00027135646087117493 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.2157338559627533 norm:0.00022173122852109373 max memory_allocated 29276.31298828125 
[2025-03-01 22:44:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.2148609161376953 norm:0.00018848727631848305 max memory_allocated 29276.31298828125 
[2025-03-01 22:45:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.21449273824691772 norm:0.00017314071010332555 max memory_allocated 29276.31298828125 
[2025-03-01 22:46:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.21427889168262482 norm:0.00016031395352911204 max memory_allocated 29276.31298828125 
[2025-03-01 22:47:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.21411994099617004 norm:0.000148119856021367 max memory_allocated 29276.31298828125 
[2025-03-01 22:48:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.21401262283325195 norm:0.00014348741387948394 max memory_allocated 29276.31298828125 
[2025-03-01 22:48:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.21390263736248016 norm:0.00014001908130012453 max memory_allocated 29276.31298828125 
[2025-03-01 22:49:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.21380369365215302 norm:0.0001352488179691136 max memory_allocated 29276.31298828125 
[2025-03-01 22:50:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.2137187421321869 norm:0.00013377545110415667 max memory_allocated 29276.31298828125 
[2025-03-01 22:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.21362996101379395 norm:0.00013345369370654225 max memory_allocated 29276.31298828125 
[2025-03-01 22:52:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.21358634531497955 norm:0.00013330411456990987 max memory_allocated 29276.31298828125 
[2025-03-01 22:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.21352238953113556 norm:0.00013097785995341837 max memory_allocated 29276.31298828125 
[2025-03-01 22:53:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.21346601843833923 norm:0.0001293785171583295 max memory_allocated 29276.31298828125 
[2025-03-01 22:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.21342015266418457 norm:0.0001284769969061017 max memory_allocated 29276.31298828125 
[2025-03-01 22:55:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.21338006854057312 norm:0.00013950538414064795 max memory_allocated 29276.31298828125 
[2025-03-01 22:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.21333329379558563 norm:0.0001250481145689264 max memory_allocated 29276.31298828125 
[2025-03-01 22:56:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-01 22:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.25784870982170105 norm:0.001035246066749096 max memory_allocated 29276.50048828125 
[2025-03-01 22:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.24850715696811676 norm:0.000530787103343755 max memory_allocated 29276.50048828125 
[2025-03-01 22:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.2402510792016983 norm:0.0003262479149270803 max memory_allocated 29276.50048828125 
[2025-03-01 23:00:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.23793967068195343 norm:0.00024402917188126594 max memory_allocated 29276.50048828125 
[2025-03-01 23:00:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.23637372255325317 norm:0.000307203532429412 max memory_allocated 29276.50048828125 
[2025-03-01 23:01:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.23552602529525757 norm:0.00017534841026645154 max memory_allocated 29276.50048828125 
[2025-03-01 23:02:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.2351493537425995 norm:0.00016118244093377143 max memory_allocated 29276.50048828125 
[2025-03-01 23:03:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.2349107265472412 norm:0.0001520498190075159 max memory_allocated 29276.50048828125 
[2025-03-01 23:04:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.2347531020641327 norm:0.00014595988614019006 max memory_allocated 29276.50048828125 
[2025-03-01 23:05:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.23462443053722382 norm:0.00014183057646732777 max memory_allocated 29276.50048828125 
[2025-03-01 23:05:52 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.23449836671352386 norm:0.00014054070925340056 max memory_allocated 29276.50048828125 
[2025-03-01 23:06:42 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.2343910187482834 norm:0.00013375676644500345 max memory_allocated 29276.50048828125 
[2025-03-01 23:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.23431135714054108 norm:0.00013567812857218087 max memory_allocated 29276.50048828125 
[2025-03-01 23:08:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.2342309057712555 norm:0.00013128943101037294 max memory_allocated 29276.50048828125 
[2025-03-01 23:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.23415324091911316 norm:0.00013014377327635884 max memory_allocated 29276.50048828125 
[2025-03-01 23:10:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.23408782482147217 norm:0.00013023713836446404 max memory_allocated 29276.50048828125 
[2025-03-01 23:10:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.23403501510620117 norm:0.00013144206604920328 max memory_allocated 29276.50048828125 
[2025-03-01 23:11:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.23398315906524658 norm:0.00013057331671006978 max memory_allocated 29276.50048828125 
[2025-03-01 23:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.23394110798835754 norm:0.00012894229439552873 max memory_allocated 29276.50048828125 
[2025-03-01 23:13:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.23388785123825073 norm:0.00012887551565654576 max memory_allocated 29276.50048828125 
[2025-03-01 23:13:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-01 23:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.2794313430786133 norm:0.0010781660676002502 max memory_allocated 29276.68798828125 
[2025-03-01 23:15:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.2705123722553253 norm:0.0005543613224290311 max memory_allocated 29276.68798828125 
[2025-03-01 23:16:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.2622116506099701 norm:0.00034019610029645264 max memory_allocated 29276.68798828125 
[2025-03-01 23:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.25984999537467957 norm:0.00025450618704780936 max memory_allocated 29276.68798828125 
[2025-03-01 23:17:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.25823038816452026 norm:0.00020948071323800832 max memory_allocated 29276.68798828125 
[2025-03-01 23:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.25750476121902466 norm:0.00018021500727627426 max memory_allocated 29276.68798828125 
[2025-03-01 23:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.25720933079719543 norm:0.00016741157742217183 max memory_allocated 29276.68798828125 
[2025-03-01 23:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.2570092976093292 norm:0.00015539814194198698 max memory_allocated 29276.68798828125 
[2025-03-01 23:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.2568458318710327 norm:0.000148450315464288 max memory_allocated 29276.68798828125 
[2025-03-01 23:21:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.25672316551208496 norm:0.00014428369468078017 max memory_allocated 29276.68798828125 
[2025-03-01 23:22:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.2566055655479431 norm:0.000143622572068125 max memory_allocated 29276.68798828125 
[2025-03-01 23:23:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.2565174698829651 norm:0.00014460939564742148 max memory_allocated 29276.68798828125 
[2025-03-01 23:24:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.2564341723918915 norm:0.00014162437582854182 max memory_allocated 29276.68798828125 
[2025-03-01 23:25:17 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.25635826587677 norm:0.00014064089918974787 max memory_allocated 29276.68798828125 
[2025-03-01 23:26:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.25627991557121277 norm:0.00013949406275060028 max memory_allocated 29276.68798828125 
[2025-03-01 23:26:57 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.2562100291252136 norm:0.0001392078265780583 max memory_allocated 29276.68798828125 
[2025-03-01 23:27:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.2561508119106293 norm:0.00013897829921916127 max memory_allocated 29276.68798828125 
[2025-03-01 23:28:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.2561124861240387 norm:0.00013962121738586575 max memory_allocated 29276.68798828125 
[2025-03-01 23:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.2560671269893646 norm:0.00014012970495969057 max memory_allocated 29276.68798828125 
[2025-03-01 23:30:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.2560291886329651 norm:0.00013965890684630722 max memory_allocated 29276.68798828125 
[2025-03-01 23:30:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-01 23:31:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.3068331480026245 norm:0.001211662427522242 max memory_allocated 29276.87548828125 
[2025-03-01 23:32:14 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.2967635989189148 norm:0.0006043204921297729 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.2877321243286133 norm:0.0003602575743570924 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.28499436378479004 norm:0.0002650134265422821 max memory_allocated 29276.87548828125 
[2025-03-01 23:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.28328919410705566 norm:0.0002138112613465637 max memory_allocated 29276.87548828125 
[2025-03-01 23:35:34 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.2825419306755066 norm:0.00018969002121593803 max memory_allocated 29276.87548828125 
[2025-03-01 23:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.28222647309303284 norm:0.00017545092850923538 max memory_allocated 29276.87548828125 
[2025-03-01 23:37:14 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.28198859095573425 norm:0.00016756224795244634 max memory_allocated 29276.87548828125 
[2025-03-01 23:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.28178486227989197 norm:0.00016053576837293804 max memory_allocated 29276.87548828125 
[2025-03-01 23:38:53 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.2816157639026642 norm:0.00015443282609339803 max memory_allocated 29276.87548828125 
[2025-03-01 23:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.2814979553222656 norm:0.00015035670367069542 max memory_allocated 29276.87548828125 
[2025-03-01 23:40:33 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.28139153122901917 norm:0.00014523598656523973 max memory_allocated 29276.87548828125 
[2025-03-01 23:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.2812843322753906 norm:0.00014318968169391155 max memory_allocated 29276.87548828125 
[2025-03-01 23:42:13 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.2811907231807709 norm:0.00014033206389285624 max memory_allocated 29276.87548828125 
[2025-03-01 23:43:02 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.2811215817928314 norm:0.0001390814722981304 max memory_allocated 29276.87548828125 
[2025-03-01 23:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.28105682134628296 norm:0.00014038370864000171 max memory_allocated 29276.87548828125 
[2025-03-01 23:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.2809996008872986 norm:0.00018887549231294543 max memory_allocated 29276.87548828125 
[2025-03-01 23:45:32 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.2809353172779083 norm:0.00014028378063812852 max memory_allocated 29276.87548828125 
[2025-03-01 23:46:22 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.28088638186454773 norm:0.00013938573829364032 max memory_allocated 29276.87548828125 
[2025-03-01 23:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.28082340955734253 norm:0.00013993834727443755 max memory_allocated 29276.87548828125 
[2025-03-01 23:47:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-01 23:48:20 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.3340047001838684 norm:0.001030677231028676 max memory_allocated 29277.06298828125 
[2025-03-01 23:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.3234138488769531 norm:0.0005544106243178248 max memory_allocated 29277.06298828125 
[2025-03-01 23:50:00 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.3138643503189087 norm:0.0003358646063134074 max memory_allocated 29277.06298828125 
[2025-03-01 23:50:50 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.31110548973083496 norm:0.00024404595023952425 max memory_allocated 29277.06298828125 
[2025-03-01 23:51:40 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.3094101846218109 norm:0.0002048162423307076 max memory_allocated 29277.06298828125 
[2025-03-01 23:52:29 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.30872124433517456 norm:0.00018217672186437994 max memory_allocated 29277.06298828125 
[2025-03-01 23:53:19 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.3083440661430359 norm:0.0001756078127073124 max memory_allocated 29277.06298828125 
[2025-03-01 23:54:09 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.30808743834495544 norm:0.0001659267145441845 max memory_allocated 29277.06298828125 
[2025-03-01 23:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.30791401863098145 norm:0.00016025628428906202 max memory_allocated 29277.06298828125 
[2025-03-01 23:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.3077765107154846 norm:0.00015609200636390597 max memory_allocated 29277.06298828125 
[2025-03-01 23:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.30767822265625 norm:0.00015354363131336868 max memory_allocated 29277.06298828125 
[2025-03-01 23:57:29 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.3075551986694336 norm:0.00015475547115784138 max memory_allocated 29277.06298828125 
[2025-03-01 23:58:19 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.30745869874954224 norm:0.00015542923938483 max memory_allocated 29277.06298828125 
[2025-03-01 23:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.3073737621307373 norm:0.00015558931045234203 max memory_allocated 29277.06298828125 
[2025-03-01 23:59:58 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.30727672576904297 norm:0.00015569396782666445 max memory_allocated 29277.06298828125 
[2025-03-02 00:00:48 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.30722254514694214 norm:0.00015465673641301692 max memory_allocated 29277.06298828125 
[2025-03-02 00:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.3071587085723877 norm:0.00015530543169006705 max memory_allocated 29277.06298828125 
[2025-03-02 00:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.3070964217185974 norm:0.00015523124602623284 max memory_allocated 29277.06298828125 
[2025-03-02 00:03:18 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.30704882740974426 norm:0.00015632802387699485 max memory_allocated 29277.06298828125 
[2025-03-02 00:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.3070049583911896 norm:0.00015779757814016193 max memory_allocated 29277.06298828125 
[2025-03-02 00:04:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 00:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.36865371465682983 norm:0.0010670297779142857 max memory_allocated 29277.25048828125 
[2025-03-02 00:06:06 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.35689058899879456 norm:0.0005350164719857275 max memory_allocated 29277.25048828125 
[2025-03-02 00:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.3470049500465393 norm:0.00033302995143458247 max memory_allocated 29277.25048828125 
[2025-03-02 00:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.34388622641563416 norm:0.0002571683726273477 max memory_allocated 29277.25048828125 
[2025-03-02 00:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.34202826023101807 norm:0.0002171489759348333 max memory_allocated 29277.25048828125 
[2025-03-02 00:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.3413039445877075 norm:0.00019512770813889802 max memory_allocated 29277.25048828125 
[2025-03-02 00:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.3409106135368347 norm:0.00018415172235108912 max memory_allocated 29277.25048828125 
[2025-03-02 00:11:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.3406412601470947 norm:0.00017732332344166934 max memory_allocated 29277.25048828125 
[2025-03-02 00:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.34040117263793945 norm:0.0001719652791507542 max memory_allocated 29277.25048828125 
[2025-03-02 00:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.34019672870635986 norm:0.00016557937487959862 max memory_allocated 29277.25048828125 
[2025-03-02 00:13:35 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.3400344252586365 norm:0.00016615302592981607 max memory_allocated 29277.25048828125 
[2025-03-02 00:14:25 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.3398670554161072 norm:0.00016204667917918414 max memory_allocated 29277.25048828125 
[2025-03-02 00:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.33973199129104614 norm:0.00015977419388946146 max memory_allocated 29277.25048828125 
[2025-03-02 00:16:04 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.33961907029151917 norm:0.0001602382108103484 max memory_allocated 29277.25048828125 
[2025-03-02 00:16:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.3395051956176758 norm:0.00015901605365797877 max memory_allocated 29277.25048828125 
[2025-03-02 00:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.33940643072128296 norm:0.00015755071945022792 max memory_allocated 29277.25048828125 
[2025-03-02 00:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.33929890394210815 norm:0.00015678294585086405 max memory_allocated 29277.25048828125 
[2025-03-02 00:19:24 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.3392249345779419 norm:0.00015697084018029273 max memory_allocated 29277.25048828125 
[2025-03-02 00:20:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.3391653299331665 norm:0.00015768158482387662 max memory_allocated 29277.25048828125 
[2025-03-02 00:21:04 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.33911845088005066 norm:0.0001563311234349385 max memory_allocated 29277.25048828125 
[2025-03-02 00:21:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 00:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.4065805673599243 norm:0.0023088499438017607 max memory_allocated 29277.43798828125 
[2025-03-02 00:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.39326366782188416 norm:0.0011472534388303757 max memory_allocated 29277.43798828125 
[2025-03-02 00:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.38231953978538513 norm:0.0006830779020674527 max memory_allocated 29277.43798828125 
[2025-03-02 00:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.37868961691856384 norm:0.0004662672581616789 max memory_allocated 29277.43798828125 
[2025-03-02 00:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.3767675459384918 norm:0.00035215370007790625 max memory_allocated 29277.43798828125 
[2025-03-02 00:26:21 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.3760420083999634 norm:0.00028853630647063255 max memory_allocated 29277.43798828125 
[2025-03-02 00:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.37563470005989075 norm:0.0002515852393116802 max memory_allocated 29277.43798828125 
[2025-03-02 00:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.3753448724746704 norm:0.0002258192398585379 max memory_allocated 29277.43798828125 
[2025-03-02 00:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.3751492500305176 norm:0.00021070282673463225 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.3749596178531647 norm:0.0001991129684029147 max memory_allocated 29277.43798828125 
[2025-03-02 00:30:30 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.3747985363006592 norm:0.00018964333867188543 max memory_allocated 29277.43798828125 
[2025-03-02 00:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.37464985251426697 norm:0.0001843910722527653 max memory_allocated 29277.43798828125 
[2025-03-02 00:32:10 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.3745202124118805 norm:0.00018035146058537066 max memory_allocated 29277.43798828125 
[2025-03-02 00:33:00 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.37440943717956543 norm:0.00017793499864637852 max memory_allocated 29277.43798828125 
[2025-03-02 00:33:50 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.37431246042251587 norm:0.0001757127174641937 max memory_allocated 29277.43798828125 
[2025-03-02 00:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.3742140829563141 norm:0.00017321151972282678 max memory_allocated 29277.43798828125 
[2025-03-02 00:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.3741290271282196 norm:0.00017254738486371934 max memory_allocated 29277.43798828125 
[2025-03-02 00:36:19 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.3740479350090027 norm:0.00017338349425699562 max memory_allocated 29277.43798828125 
[2025-03-02 00:37:09 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.37397855520248413 norm:0.0001712907396722585 max memory_allocated 29277.43798828125 
[2025-03-02 00:37:58 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.3739085793495178 norm:0.00016876196605153382 max memory_allocated 29277.43798828125 
[2025-03-02 00:38:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 00:38:17 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:39:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.4557887315750122 norm:0.010383706539869308 max memory_allocated 29277.77001953125 
[2025-03-02 00:39:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.43948066234588623 norm:0.00787477195262909 max memory_allocated 29277.77001953125 
[2025-03-02 00:40:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.4263741075992584 norm:0.005932895001024008 max memory_allocated 29277.77001953125 
[2025-03-02 00:41:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.42187732458114624 norm:0.004957668483257294 max memory_allocated 29277.77001953125 
[2025-03-02 00:42:27 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.41967353224754333 norm:0.004116150550544262 max memory_allocated 29277.77001953125 
[2025-03-02 00:43:17 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.41876220703125 norm:0.003463207744061947 max memory_allocated 29277.77001953125 
[2025-03-02 00:44:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.4181705117225647 norm:0.003026543650776148 max memory_allocated 29277.77001953125 
[2025-03-02 00:44:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.4177360534667969 norm:0.002869251649826765 max memory_allocated 29277.77001953125 
[2025-03-02 00:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.41740667819976807 norm:0.002767688361927867 max memory_allocated 29277.77001953125 
[2025-03-02 00:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.41716089844703674 norm:0.0026306533254683018 max memory_allocated 29277.77001953125 
[2025-03-02 00:47:27 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.4169759154319763 norm:0.0026330389082431793 max memory_allocated 29277.77001953125 
[2025-03-02 00:48:17 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.4167940616607666 norm:0.0025233763735741377 max memory_allocated 29277.77001953125 
[2025-03-02 00:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.41656559705734253 norm:0.0024919346906244755 max memory_allocated 29277.77001953125 
[2025-03-02 00:49:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.41639572381973267 norm:0.0023494327906519175 max memory_allocated 29277.77001953125 
[2025-03-02 00:50:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.4161949157714844 norm:0.0023859525099396706 max memory_allocated 29277.77001953125 
[2025-03-02 00:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.41607484221458435 norm:0.00228503393009305 max memory_allocated 29277.77001953125 
[2025-03-02 00:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.4159495234489441 norm:0.0023303842172026634 max memory_allocated 29277.77001953125 
[2025-03-02 00:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.4158758223056793 norm:0.002259841188788414 max memory_allocated 29277.77001953125 
[2025-03-02 00:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.41576042771339417 norm:0.002283994108438492 max memory_allocated 29277.77001953125 
[2025-03-02 00:54:56 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.4157051146030426 norm:0.002172091044485569 max memory_allocated 29277.77001953125 
[2025-03-02 00:55:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 00:55:15 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.5110554695129395 norm:0.012358951382339 max memory_allocated 29277.95751953125 
[2025-03-02 00:56:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.4913586378097534 norm:0.009147346019744873 max memory_allocated 29277.95751953125 
[2025-03-02 00:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.47559455037117004 norm:0.006573186721652746 max memory_allocated 29277.95751953125 
[2025-03-02 00:58:35 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.4701176881790161 norm:0.005477735307067633 max memory_allocated 29277.95751953125 
[2025-03-02 00:59:25 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.4676865041255951 norm:0.004577276296913624 max memory_allocated 29277.95751953125 
[2025-03-02 01:00:15 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.4665878415107727 norm:0.003918041009455919 max memory_allocated 29277.95751953125 
[2025-03-02 01:01:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.46585267782211304 norm:0.0034109142143279314 max memory_allocated 29277.95751953125 
[2025-03-02 01:01:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.4653744101524353 norm:0.003160779597237706 max memory_allocated 29277.95751953125 
[2025-03-02 01:02:45 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.46503058075904846 norm:0.0030322973616421223 max memory_allocated 29277.95751953125 
[2025-03-02 01:03:35 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.4647611081600189 norm:0.00291395653039217 max memory_allocated 29277.95751953125 
[2025-03-02 01:04:25 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.464557945728302 norm:0.0029290136881172657 max memory_allocated 29277.95751953125 
[2025-03-02 01:05:15 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.4643073081970215 norm:0.002835863269865513 max memory_allocated 29277.95751953125 
[2025-03-02 01:06:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.4641597270965576 norm:0.0027853152714669704 max memory_allocated 29277.95751953125 
[2025-03-02 01:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.4639742076396942 norm:0.0026577627286314964 max memory_allocated 29277.95751953125 
[2025-03-02 01:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.46383291482925415 norm:0.0025912467390298843 max memory_allocated 29277.95751953125 
[2025-03-02 01:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.4637596905231476 norm:0.002553557977080345 max memory_allocated 29277.95751953125 
[2025-03-02 01:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.46366316080093384 norm:0.0025652931071817875 max memory_allocated 29277.95751953125 
[2025-03-02 01:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.46352577209472656 norm:0.0025174070615321398 max memory_allocated 29277.95751953125 
[2025-03-02 01:11:06 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.4634757339954376 norm:0.0025270218029618263 max memory_allocated 29277.95751953125 
[2025-03-02 01:11:56 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.46337395906448364 norm:0.0024707773700356483 max memory_allocated 29277.95751953125 
[2025-03-02 01:12:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 01:12:15 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:13:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.6121156215667725 norm:0.01448213029652834 max memory_allocated 29278.14501953125 
[2025-03-02 01:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.5862029790878296 norm:0.005570607725530863 max memory_allocated 29278.14501953125 
[2025-03-02 01:14:44 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.5620380640029907 norm:0.006172701250761747 max memory_allocated 29278.14501953125 
[2025-03-02 01:15:35 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.5537772178649902 norm:0.005821850150823593 max memory_allocated 29278.14501953125 
[2025-03-02 01:16:24 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.5505650639533997 norm:0.005834885872900486 max memory_allocated 29278.14501953125 
[2025-03-02 01:17:15 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.5491488575935364 norm:0.00586670683696866 max memory_allocated 29278.14501953125 
[2025-03-02 01:18:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.5479666590690613 norm:0.007062673568725586 max memory_allocated 29278.14501953125 
[2025-03-02 01:18:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.5467653274536133 norm:0.009122801013290882 max memory_allocated 29278.14501953125 
[2025-03-02 01:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.546140730381012 norm:0.009050490334630013 max memory_allocated 29278.14501953125 
[2025-03-02 01:20:35 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.5463516712188721 norm:0.009286830201745033 max memory_allocated 29278.14501953125 
[2025-03-02 01:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.5466927289962769 norm:0.009470926597714424 max memory_allocated 29278.14501953125 
[2025-03-02 01:22:15 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.5466295480728149 norm:0.009754170663654804 max memory_allocated 29278.14501953125 
[2025-03-02 01:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.5463739633560181 norm:0.009341645985841751 max memory_allocated 29278.14501953125 
[2025-03-02 01:23:55 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.5461652278900146 norm:0.009305654093623161 max memory_allocated 29278.14501953125 
[2025-03-02 01:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.5459622144699097 norm:0.008262318558990955 max memory_allocated 29278.14501953125 
[2025-03-02 01:25:35 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.5455265045166016 norm:0.007920381613075733 max memory_allocated 29278.14501953125 
[2025-03-02 01:26:25 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.5447442531585693 norm:0.006946066860109568 max memory_allocated 29278.14501953125 
[2025-03-02 01:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.5435658693313599 norm:0.0057905735448002815 max memory_allocated 29278.14501953125 
[2025-03-02 01:28:06 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.5430636405944824 norm:0.00539045175537467 max memory_allocated 29278.14501953125 
[2025-03-02 01:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.5429311394691467 norm:0.00537115428596735 max memory_allocated 29278.14501953125 
[2025-03-02 01:29:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 01:29:14 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:30:04 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.878025233745575 norm:0.05681459978222847 max memory_allocated 29278.33251953125 
[2025-03-02 01:30:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.8044060468673706 norm:0.03297244757413864 max memory_allocated 29278.33251953125 
[2025-03-02 01:31:44 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.7601370215415955 norm:0.022555481642484665 max memory_allocated 29278.33251953125 
[2025-03-02 01:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.7427688241004944 norm:0.019280415028333664 max memory_allocated 29278.33251953125 
[2025-03-02 01:33:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.7339696884155273 norm:0.016885284334421158 max memory_allocated 29278.33251953125 
[2025-03-02 01:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.7282993197441101 norm:0.014874238520860672 max memory_allocated 29278.33251953125 
[2025-03-02 01:35:04 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.7241630554199219 norm:0.013588770292699337 max memory_allocated 29278.33251953125 
[2025-03-02 01:35:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.7204910516738892 norm:0.013077429495751858 max memory_allocated 29278.33251953125 
[2025-03-02 01:36:44 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.7185611724853516 norm:0.012817302718758583 max memory_allocated 29278.33251953125 
[2025-03-02 01:37:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.7163759469985962 norm:0.012606002390384674 max memory_allocated 29278.33251953125 
[2025-03-02 01:38:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.7154899835586548 norm:0.012367148883640766 max memory_allocated 29278.33251953125 
[2025-03-02 01:39:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.7140334844589233 norm:0.01280695479363203 max memory_allocated 29278.33251953125 
[2025-03-02 01:40:04 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.713365375995636 norm:0.01251252368092537 max memory_allocated 29278.33251953125 
[2025-03-02 01:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.7121150493621826 norm:0.012349218130111694 max memory_allocated 29278.33251953125 
[2025-03-02 01:41:44 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.7113906145095825 norm:0.012166445143520832 max memory_allocated 29278.33251953125 
[2025-03-02 01:42:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.7109853029251099 norm:0.011690014973282814 max memory_allocated 29278.33251953125 
[2025-03-02 01:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.7102073431015015 norm:0.011729122139513493 max memory_allocated 29278.33251953125 
[2025-03-02 01:44:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.7093261480331421 norm:0.01143623050302267 max memory_allocated 29278.33251953125 
[2025-03-02 01:45:04 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.7089648246765137 norm:0.011170269921422005 max memory_allocated 29278.33251953125 
[2025-03-02 01:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.708547830581665 norm:0.011369027197360992 max memory_allocated 29278.33251953125 
[2025-03-02 01:46:09 root] (main_calib_config2.py 380): INFO 40666.27747416496
[2025-03-02 01:46:19 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-02 01:48:17 root] (main_calib_config2.py 159): INFO wikitext2 : 5.178870677947998
[2025-03-02 01:48:17 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-02 01:51:19 root] (main_calib_config2.py 159): INFO c4 : 6.872229099273682
[2025-03-02 03:58:31 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.178870677947998, 'c4': 6.872229099273682, 'results': {'hellaswag': {'acc': 0.5851424019119698, 'acc_stderr': 0.004916905095810846, 'acc_norm': 0.7497510456084445, 'acc_norm_stderr': 0.004322710911026375}, 'arc_challenge': {'acc': 0.4112627986348123, 'acc_stderr': 0.014379441068522073, 'acc_norm': 0.4249146757679181, 'acc_norm_stderr': 0.014445698968520769}, 'boolq': {'acc': 0.65565749235474, 'acc_stderr': 0.008310485054782988}, 'winogrande': {'acc': 0.6550907655880032, 'acc_stderr': 0.013359379805033687}, 'arc_easy': {'acc': 0.7150673400673401, 'acc_stderr': 0.009262170695590656, 'acc_norm': 0.5774410774410774, 'acc_norm_stderr': 0.010135978222981071}, 'piqa': {'acc': 0.779651795429815, 'acc_stderr': 0.009670535456853141, 'acc_norm': 0.7742110990206746, 'acc_norm_stderr': 0.009754980670917313}}, 'versions': {'hellaswag': 0, 'arc_challenge': 0, 'boolq': 1, 'winogrande': 0, 'arc_easy': 0, 'piqa': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
