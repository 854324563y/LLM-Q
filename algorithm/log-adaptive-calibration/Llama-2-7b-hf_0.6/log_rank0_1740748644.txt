[2025-02-28 13:17:24 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-7b-hf_0.6', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.6.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:20:27 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:20:27 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.6.pkl
[2025-02-28 13:20:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:20:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.00987227912992239 norm:0.011254163458943367 max memory_allocated 22562.10693359375 
[2025-02-28 13:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0054680053144693375 norm:0.006387422792613506 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.00391292804852128 norm:0.0043111033737659454 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.003316784044727683 norm:0.0032229814678430557 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.003122597234323621 norm:0.0028068001847714186 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0030012133065611124 norm:0.0023975532967597246 max memory_allocated 22562.10693359375 
[2025-02-28 13:24:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0029393869917839766 norm:0.0022012742701917887 max memory_allocated 22562.10693359375 
[2025-02-28 13:25:01 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0029191714711487293 norm:0.0020501308608800173 max memory_allocated 22562.10693359375 
[2025-02-28 13:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.002879426348954439 norm:0.0018294376786798239 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0028265612199902534 norm:0.0016549822175875306 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.002849954180419445 norm:0.0015469059580937028 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.002798698376864195 norm:0.0013740712311118841 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0027697996702045202 norm:0.0012527062790468335 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.002769700950011611 norm:0.00115118024405092 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.002740830183029175 norm:0.0010514348978176713 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.002743382006883621 norm:0.0009759737877175212 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0027168055530637503 norm:0.0009189646225422621 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0027158940210938454 norm:0.0009280202793888748 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.00273539824411273 norm:0.0009011932415887713 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.002715021837502718 norm:0.0008289480465464294 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:31:56 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:32:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.033036306500434875 norm:0.02444632165133953 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.022244025021791458 norm:0.01487790234386921 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.015470096841454506 norm:0.007765283342450857 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.015228593721985817 norm:0.016086649149656296 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.015294806100428104 norm:0.012242402881383896 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.01386540662497282 norm:0.010633355006575584 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.013337717391550541 norm:0.009333339519798756 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.013389010913670063 norm:0.008761273697018623 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.013417363166809082 norm:0.008575689047574997 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.012770058587193489 norm:0.0073513188399374485 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.012836085632443428 norm:0.007059786934405565 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.012945374473929405 norm:0.007185305468738079 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.013704129494726658 norm:0.008150982670485973 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.01376730389893055 norm:0.009350498206913471 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.013336224481463432 norm:0.008829012513160706 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.013294128701090813 norm:0.00875495932996273 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.013356536626815796 norm:0.008287292905151844 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.01287755649536848 norm:0.007992669939994812 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.013553809374570847 norm:0.008798103779554367 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.013962777331471443 norm:0.008996298536658287 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 13:43:23 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:43:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.02709095925092697 norm:0.006953258067369461 max memory_allocated 22562.45068359375 
[2025-02-28 13:44:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.019827045500278473 norm:0.004843980073928833 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.017220066860318184 norm:0.0035849048290401697 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:38 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.01641797088086605 norm:0.0029183102305978537 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.015854788944125175 norm:0.0024148018565028906 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:45 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.015399937517940998 norm:0.002015430713072419 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.015155350789427757 norm:0.0016739252023398876 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.015034498646855354 norm:0.00136092200409621 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.01497678179293871 norm:0.0011172316735610366 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.014926943928003311 norm:0.0009661575895734131 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.014935044571757317 norm:0.0010021275375038385 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.015030433423817158 norm:0.00089117675088346 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.015090969391167164 norm:0.0010386609937995672 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.01491023600101471 norm:0.0007602552068419755 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.014916498214006424 norm:0.0006868621567264199 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.014973670244216919 norm:0.0007635338697582483 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.014915751293301582 norm:0.0006823205039836466 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.014894435182213783 norm:0.000695002090651542 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.014954311773180962 norm:0.0006575424922630191 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:38 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.014914991334080696 norm:0.0006422271253541112 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 13:55:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.03504576161503792 norm:0.0027083661407232285 max memory_allocated 22562.50732421875 
[2025-02-28 13:55:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.026266925036907196 norm:0.0009807267924770713 max memory_allocated 22562.50732421875 
[2025-02-28 13:56:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.022528227418661118 norm:0.00048498203977942467 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.021384941413998604 norm:0.0003021312295459211 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.020679181441664696 norm:0.00023012715973891318 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.02034018188714981 norm:0.00019816463463939726 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.02020815573632717 norm:0.00015301108942367136 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.02015993930399418 norm:0.00014560998533852398 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.02011941373348236 norm:0.0001483236555941403 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.020072277635335922 norm:0.00014395630569197237 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.020052503794431686 norm:0.00013632961781695485 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.020026059821248055 norm:0.00014444382395595312 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.020033394917845726 norm:0.00015263422392308712 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.02001038007438183 norm:0.00014752583228982985 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.02000614069402218 norm:0.00014269480016082525 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.019993796944618225 norm:0.00013813267287332565 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.01998920366168022 norm:0.00013535073958337307 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.01998503878712654 norm:0.00013404528726823628 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.01997218281030655 norm:0.00038071488961577415 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.01996764913201332 norm:0.0001327083446085453 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.041729044169187546 norm:0.0013555861078202724 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.03199457377195358 norm:0.0005201767198741436 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.027187148109078407 norm:0.0002745275851339102 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.025623098015785217 norm:0.00020608118211384863 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.024793747812509537 norm:0.00017173968080896884 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.024402860552072525 norm:0.00016703520668670535 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.024195918813347816 norm:0.0001512409362476319 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.02409428358078003 norm:0.000153909350046888 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.024054380133748055 norm:0.00016422098269686103 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.023958200588822365 norm:0.00015330311725847423 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.02391802705824375 norm:0.00016120006330311298 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.023903999477624893 norm:0.00016443399363197386 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.02390877529978752 norm:0.0001755973498802632 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.023844970390200615 norm:0.00016084613162092865 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.02380988746881485 norm:0.0001639320544200018 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.02379685267806053 norm:0.00017244162154383957 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.023784829303622246 norm:0.0001794459531083703 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.023768225684762 norm:0.00016084827075246722 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.02376432530581951 norm:0.00016399603919126093 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.02375979535281658 norm:0.00015923638420645148 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:18:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.04211152344942093 norm:0.0009537490550428629 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.0344930961728096 norm:0.000445722573203966 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.03002573922276497 norm:0.0002779731585178524 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.028441457077860832 norm:0.00018642029317561537 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.027738329023122787 norm:0.0001646135642658919 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.027360908687114716 norm:0.00014533019566442817 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.027264561504125595 norm:0.00016287951439153403 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:08 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.02719264291226864 norm:0.0001476941251894459 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.027103442698717117 norm:0.0001517107739346102 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.027039309963583946 norm:0.0001475858298363164 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.027012331411242485 norm:0.00014511989138554782 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.027005810290575027 norm:0.00014873224426992238 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.02699948288500309 norm:0.00015629771223757416 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.026940736919641495 norm:0.00014498914242722094 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.02691173367202282 norm:0.00014898004883434623 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.02689887396991253 norm:0.00014966259186621755 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.026908544823527336 norm:0.00014923233538866043 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.02690776251256466 norm:0.00014027862926013768 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.026911960914731026 norm:0.00015103028272278607 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.026908107101917267 norm:0.00015789101598784328 max memory_allocated 22562.85107421875 
[2025-02-28 14:29:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 14:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.05040944367647171 norm:0.002015853999182582 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.04065864905714989 norm:0.0008475353242829442 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.03503090515732765 norm:0.00048743351362645626 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.032981082797050476 norm:0.00031709219911135733 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.03198496252298355 norm:0.0002472184132784605 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.03155894577503204 norm:0.00020570347260218114 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.03135636821389198 norm:0.00018092530081048608 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.03120569884777069 norm:0.00017018038488458842 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.031115852296352386 norm:0.0001579908566782251 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.031068366020917892 norm:0.00014623961760662496 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.031019259244203568 norm:0.00014568603364750743 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.030968764796853065 norm:0.00014571075735148042 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.030939698219299316 norm:0.00014326567179523408 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.03090905211865902 norm:0.0001401506015099585 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.0309026800096035 norm:0.00014184496831148863 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.03089492954313755 norm:0.00014112083590589464 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.030865930020809174 norm:0.00013479807239491493 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.03084203600883484 norm:0.00013558639329858124 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.030827030539512634 norm:0.00013804658374283463 max memory_allocated 22563.02294921875 
[2025-02-28 14:40:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.030792374163866043 norm:0.00014118671242613345 max memory_allocated 22563.02294921875 
[2025-02-28 14:40:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 14:41:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.05783538147807121 norm:0.0030127293430268764 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.045888904482126236 norm:0.002027602633461356 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.03937811776995659 norm:0.0005686248769052327 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.03704182431101799 norm:0.0003429977805353701 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.03606971725821495 norm:0.0002752383006736636 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.03558690473437309 norm:0.00023263339244294912 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.0353560671210289 norm:0.00020781432976946235 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.03521233797073364 norm:0.00018797078519128263 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.035109516233205795 norm:0.00018070290389005095 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.035037919878959656 norm:0.00017801304056774825 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.035014014691114426 norm:0.00016318942653015256 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.03497663885354996 norm:0.00015436734247487038 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.034914400428533554 norm:0.00013879523612558842 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.034888092428445816 norm:0.00014585698954761028 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.034838609397411346 norm:0.00014723069034516811 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.03479893505573273 norm:0.00014465872664004564 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.03480158746242523 norm:0.00013498857151716948 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.03478095307946205 norm:0.00013004944776184857 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.03475303575396538 norm:0.00012672824959736317 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.03473573178052902 norm:0.00012476983829401433 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 14:52:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.057177357375621796 norm:0.001039979630149901 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.04782474413514137 norm:0.000534619961399585 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.042309947311878204 norm:0.0003292713372502476 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.04048758000135422 norm:0.000250262557528913 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.039625510573387146 norm:0.0002084792940877378 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.03919367492198944 norm:0.00020489537564571947 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.03900059685111046 norm:0.0001922674273373559 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.03880298510193825 norm:0.00017003106768243015 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.03869438171386719 norm:0.00016838910232763737 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.03864990174770355 norm:0.0001881043572211638 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.03857588768005371 norm:0.00017514867067802697 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.03851744905114174 norm:0.00017571073840372264 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.03847113251686096 norm:0.00017541377746965736 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.038445696234703064 norm:0.0001800220925360918 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.038405291736125946 norm:0.00017020665109157562 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.03838391974568367 norm:0.00017121560813393444 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.038359854370355606 norm:0.00017391510482411832 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.038348160684108734 norm:0.00016536941984668374 max memory_allocated 22563.36669921875 
[2025-02-28 15:02:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.038337863981723785 norm:0.0001686038012849167 max memory_allocated 22563.36669921875 
[2025-02-28 15:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.03829792141914368 norm:0.0001523015962447971 max memory_allocated 22563.36669921875 
[2025-02-28 15:03:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 15:03:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.05828653275966644 norm:0.0009720012312754989 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.049550894647836685 norm:0.00040957587771117687 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.044491831213235855 norm:0.0002509691985324025 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:32 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.0428675152361393 norm:0.0001954912586370483 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.04205787181854248 norm:0.00018456962425261736 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.04167062044143677 norm:0.00017652522365096956 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.04145161435008049 norm:0.00014639896107837558 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.041339363902807236 norm:0.00014592094521503896 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.04122112691402435 norm:0.0001380889443680644 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.04118211939930916 norm:0.00013888107787352055 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.041120585054159164 norm:0.00013083196245133877 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:01 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.04108588397502899 norm:0.00014165538595989347 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.04106193035840988 norm:0.00014049114543013275 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.041059669107198715 norm:0.0001391939294990152 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.041030511260032654 norm:0.00013205036520957947 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.0410124808549881 norm:0.0001241950667463243 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.04100586473941803 norm:0.00012145346408942714 max memory_allocated 22563.53857421875 
[2025-02-28 15:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.04098203033208847 norm:0.0001231119385920465 max memory_allocated 22563.53857421875 
[2025-02-28 15:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.04098086059093475 norm:0.00012504633923526853 max memory_allocated 22563.53857421875 
[2025-02-28 15:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.040988605469465256 norm:0.00013258776743896306 max memory_allocated 22563.53857421875 
[2025-02-28 15:14:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 15:15:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.05825960636138916 norm:0.0006575253210030496 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.05128573998808861 norm:0.0003361306735314429 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.04660153016448021 norm:0.00020271843823138624 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.045128703117370605 norm:0.00016973819583654404 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.04441411420702934 norm:0.00016980431973934174 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.04397225379943848 norm:0.0001532398018753156 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.043802373111248016 norm:0.00016192052862606943 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.04361081123352051 norm:0.00013513013254851103 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.04350990802049637 norm:0.00014472073235083371 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.04346875101327896 norm:0.00013553447206504643 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.04339484125375748 norm:0.00013499845226760954 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.043360479176044464 norm:0.00013830262469127774 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.043334659188985825 norm:0.00012972025433555245 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.04332122579216957 norm:0.00012843402510043234 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.04330925643444061 norm:0.0001360178430331871 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.043308649212121964 norm:0.0001386162475682795 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.04330364987254143 norm:0.00014176881813909858 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.04326332360506058 norm:0.00013282049621921033 max memory_allocated 22563.71044921875 
[2025-02-28 15:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.04327793046832085 norm:0.00013983990356791764 max memory_allocated 22563.71044921875 
[2025-02-28 15:25:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.043244220316410065 norm:0.00012617376341950148 max memory_allocated 22563.71044921875 
[2025-02-28 15:26:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 15:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.06117412447929382 norm:0.0007637907401658595 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.05363837629556656 norm:0.00038401476922445 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.04878447949886322 norm:0.00025163180544041097 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.04716925323009491 norm:0.00020802594372071326 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.046406954526901245 norm:0.00019101458019576967 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:31 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.04593392834067345 norm:0.00017190363723784685 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.045692816376686096 norm:0.0001719783031148836 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.04554236680269241 norm:0.00016177284123841673 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.0454292818903923 norm:0.00015180784976109862 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.04534943029284477 norm:0.0001536945637781173 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.045284006744623184 norm:0.00015871434879954904 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.04521618038415909 norm:0.00013061260688118637 max memory_allocated 22563.88232421875 
[2025-02-28 15:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.04515619948506355 norm:0.00012626928219106048 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.04511323571205139 norm:0.000125167949590832 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.04509441554546356 norm:0.00013237711391411722 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.045092396438121796 norm:0.00012968783266842365 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.045077256858348846 norm:0.00012942876492161304 max memory_allocated 22563.88232421875 
[2025-02-28 15:36:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.04506409913301468 norm:0.0001341883762506768 max memory_allocated 22563.88232421875 
[2025-02-28 15:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.045048609375953674 norm:0.00013315989053808153 max memory_allocated 22563.88232421875 
[2025-02-28 15:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.04504191502928734 norm:0.0001312509848503396 max memory_allocated 22563.88232421875 
[2025-02-28 15:37:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 15:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.06175851821899414 norm:0.0006286519928835332 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.05484694615006447 norm:0.00033777114003896713 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.050102993845939636 norm:0.00022129560238681734 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.048585064709186554 norm:0.00018363737035542727 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.0478709414601326 norm:0.00016152544412761927 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.04749240726232529 norm:0.0001491810253355652 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.047232311218976974 norm:0.00014010551967658103 max memory_allocated 22564.05419921875 
[2025-02-28 15:42:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.04712705686688423 norm:0.00013394415145739913 max memory_allocated 22564.05419921875 
[2025-02-28 15:42:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.047055233269929886 norm:0.0001297171547776088 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.04696660116314888 norm:0.00013123280950821936 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.04690144583582878 norm:0.00013238868268672377 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.046908095479011536 norm:0.00013869609392713755 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.04684291034936905 norm:0.00012144613720010966 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.04677999019622803 norm:0.00012409825285430998 max memory_allocated 22564.05419921875 
[2025-02-28 15:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.046763479709625244 norm:0.00012628280092030764 max memory_allocated 22564.05419921875 
[2025-02-28 15:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.046740710735321045 norm:0.00012867667828686535 max memory_allocated 22564.05419921875 
[2025-02-28 15:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.04672784358263016 norm:0.00012034251994919032 max memory_allocated 22564.05419921875 
[2025-02-28 15:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.046717338263988495 norm:0.0001247240579687059 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.04669003561139107 norm:0.00011467938020359725 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.04668514430522919 norm:0.00011635271221166477 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 15:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.06088199466466904 norm:0.0008007516153156757 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.054432787001132965 norm:0.0004007310199085623 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.04987236112356186 norm:0.0002480472030583769 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.048341237008571625 norm:0.00019329623319208622 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.0476512536406517 norm:0.00016401142056565732 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.04724690690636635 norm:0.00014841891243122518 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.04701464623212814 norm:0.00013575665070675313 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.046864185482263565 norm:0.0001367853838019073 max memory_allocated 22564.22607421875 
[2025-02-28 15:54:05 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.04674677178263664 norm:0.0001279055722989142 max memory_allocated 22564.22607421875 
[2025-02-28 15:54:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.046674687415361404 norm:0.00011971554340561852 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.04659932851791382 norm:0.00011577922123251483 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.0465523898601532 norm:0.00012125835928600281 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.046540338546037674 norm:0.00012210312706883997 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.04651863873004913 norm:0.0001221492566401139 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.0464673712849617 norm:0.0001140970634878613 max memory_allocated 22564.22607421875 
[2025-02-28 15:58:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.04643307626247406 norm:0.00011523001012392342 max memory_allocated 22564.22607421875 
[2025-02-28 15:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.046421997249126434 norm:0.00011896981595782563 max memory_allocated 22564.22607421875 
[2025-02-28 15:59:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.04639798030257225 norm:0.0001188447859021835 max memory_allocated 22564.22607421875 
[2025-02-28 15:59:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.04641522839665413 norm:0.00012259632057975978 max memory_allocated 22564.22607421875 
[2025-02-28 16:00:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.04640170559287071 norm:0.00011420959344832227 max memory_allocated 22564.22607421875 
[2025-02-28 16:00:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 16:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.06127578020095825 norm:0.0005971515201963484 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.05506829172372818 norm:0.00031530315754935145 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.05067574232816696 norm:0.00021105119958519936 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.049276478588581085 norm:0.00016989727737382054 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.04857899621129036 norm:0.00014971228665672243 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:50 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.04817890748381615 norm:0.0001343158510280773 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.04791918024420738 norm:0.00011858734796987846 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.047760188579559326 norm:0.00011223537876503542 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.04766988754272461 norm:0.00011861432722071186 max memory_allocated 22564.39794921875 
[2025-02-28 16:06:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.04757576063275337 norm:0.00011272566916886717 max memory_allocated 22564.39794921875 
[2025-02-28 16:06:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.04749004915356636 norm:0.00010383788321632892 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.04744143784046173 norm:9.953889821190387e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.04740580916404724 norm:9.810012124944478e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.047384023666381836 norm:9.850245987763628e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.04736827686429024 norm:9.8534015705809e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.04732852429151535 norm:8.724604413146153e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:10:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.04731857031583786 norm:8.550022903364152e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.047312259674072266 norm:8.676967991050333e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.047301873564720154 norm:9.076717105926946e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:11:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.04728454351425171 norm:8.750684355618432e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:11:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 16:12:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.0640295147895813 norm:0.0008649714873172343 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.056229881942272186 norm:0.000421048462158069 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.0513664074242115 norm:0.0002581941371317953 max memory_allocated 22564.56982421875 
[2025-02-28 16:14:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.0498293936252594 norm:0.0001960088702617213 max memory_allocated 22564.56982421875 
[2025-02-28 16:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.04900408536195755 norm:0.00017083257262129337 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.0485093891620636 norm:0.00015608167450409383 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.048232950270175934 norm:0.0001436543243471533 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.04806862771511078 norm:0.0001385986543027684 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.04792627692222595 norm:0.0001249589113285765 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.047814950346946716 norm:0.0001173983546323143 max memory_allocated 22564.56982421875 
[2025-02-28 16:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.04774865135550499 norm:0.00011467000877019018 max memory_allocated 22564.56982421875 
[2025-02-28 16:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.04768509790301323 norm:0.00011551107309060171 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.04764284938573837 norm:0.00011370921129127964 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.047598306089639664 norm:0.00011242684558965266 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.04756096750497818 norm:0.00011248168448219076 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.04751313105225563 norm:0.00011124815500807017 max memory_allocated 22564.56982421875 
[2025-02-28 16:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.04747934266924858 norm:0.00010810741514433175 max memory_allocated 22564.56982421875 
[2025-02-28 16:22:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.0474553108215332 norm:0.00010119163198396564 max memory_allocated 22564.56982421875 
[2025-02-28 16:22:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.047428518533706665 norm:0.00010017103340942413 max memory_allocated 22564.56982421875 
[2025-02-28 16:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.04740078002214432 norm:9.821802814258263e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:23:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 16:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.0651727244257927 norm:0.0010776815470308065 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.05759577080607414 norm:0.00044765195343643427 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.0522301122546196 norm:0.0002641383034642786 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.050660304725170135 norm:0.0002056556986644864 max memory_allocated 22564.74169921875 
[2025-02-28 16:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.04982897266745567 norm:0.00017720067990012467 max memory_allocated 22564.74169921875 
[2025-02-28 16:26:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.049302056431770325 norm:0.000157575894263573 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.049020059406757355 norm:0.00014350362471304834 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.04883962497115135 norm:0.00013687080354429781 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.04868612065911293 norm:0.00012776459334418178 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.04858703911304474 norm:0.00012372805213090032 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.048488907516002655 norm:0.0001186152730952017 max memory_allocated 22564.74169921875 
[2025-02-28 16:30:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.04841037839651108 norm:0.00011247869406361133 max memory_allocated 22564.74169921875 
[2025-02-28 16:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.04834051802754402 norm:0.00010700284474296495 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.04829005151987076 norm:0.00010724193998612463 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.048243336379528046 norm:0.00010524086246732622 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.04818598926067352 norm:0.00010142164683202282 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.048146121203899384 norm:0.00010639781248755753 max memory_allocated 22564.74169921875 
[2025-02-28 16:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.048121415078639984 norm:0.00010532631858950481 max memory_allocated 22564.74169921875 
[2025-02-28 16:34:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.048080991953611374 norm:9.664044773671776e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.048064231872558594 norm:9.168266842607409e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:34:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 16:35:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.06178572028875351 norm:0.0006218611379154027 max memory_allocated 22564.91357421875 
[2025-02-28 16:35:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.05631063133478165 norm:0.00022725903545506299 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:28 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.05239136889576912 norm:0.00015920281293801963 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.05113469064235687 norm:0.0001395980507368222 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.05039942264556885 norm:0.00012258399510756135 max memory_allocated 22564.91357421875 
[2025-02-28 16:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.04997929185628891 norm:0.00010958024358842522 max memory_allocated 22564.91357421875 
[2025-02-28 16:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.04978129267692566 norm:0.00010045724775409326 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.04964038357138634 norm:0.00010137692152056843 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.04951440170407295 norm:9.756548388395458e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.04945044219493866 norm:8.889243326848373e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.049368422478437424 norm:8.23188602225855e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.049322083592414856 norm:8.407162385992706e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.04927591234445572 norm:7.664333679713309e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.04923779517412186 norm:7.724264287389815e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:43:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.04918593168258667 norm:7.383068441413343e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:43:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.049163855612277985 norm:7.490229472750798e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:44:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.04915692284703255 norm:7.873312279116362e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.04914963245391846 norm:8.321348286699504e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.04912248253822327 norm:7.466420356649905e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.04910547286272049 norm:7.585234561702237e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:46:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 16:46:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.06891566514968872 norm:0.0016951693687587976 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.06192783638834953 norm:0.0006932136020623147 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.05685770884156227 norm:0.00039374109474010766 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.05531598627567291 norm:0.00026080640964210033 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.05437645688652992 norm:0.00021627172827720642 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.05386458337306976 norm:0.00019168412836734205 max memory_allocated 22565.08544921875 
[2025-02-28 16:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.05360015109181404 norm:0.00016918212349992245 max memory_allocated 22565.08544921875 
[2025-02-28 16:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.05345020443201065 norm:0.00015504244947806 max memory_allocated 22565.08544921875 
[2025-02-28 16:51:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.0533149316906929 norm:0.00013887524255551398 max memory_allocated 22565.08544921875 
[2025-02-28 16:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.05322014540433884 norm:0.00013152119936421514 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.05314178019762039 norm:0.0001247614127350971 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.05307654291391373 norm:0.00011972609354415908 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.053016938269138336 norm:0.00011351003195159137 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.05295092239975929 norm:0.00010792944522108883 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.052897773683071136 norm:0.00010260352428304031 max memory_allocated 22565.08544921875 
[2025-02-28 16:55:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.05285501480102539 norm:0.00010269061021972448 max memory_allocated 22565.08544921875 
[2025-02-28 16:55:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.05280863866209984 norm:9.51170441112481e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:56:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.05277179926633835 norm:9.215018508257344e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.05273965001106262 norm:9.00549566722475e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.05270029231905937 norm:8.616312697995454e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:57:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 16:58:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.07145646214485168 norm:0.0008307832758873701 max memory_allocated 22565.25732421875 
[2025-02-28 16:58:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.06532122939825058 norm:0.00039283890509977937 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.06069263070821762 norm:0.0002322995278518647 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.059397660195827484 norm:0.00016786523337941617 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.05855201184749603 norm:0.000138621122459881 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.05809042975306511 norm:0.00012299427180550992 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.057867515832185745 norm:0.00010662269778549671 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.05774194747209549 norm:0.00010277460387442261 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.057630911469459534 norm:9.781341213965788e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.057527557015419006 norm:9.427749319002032e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.05743426829576492 norm:9.266292181564495e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.057376593351364136 norm:8.807549602352083e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.05731365829706192 norm:7.895079033914953e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.05726296454668045 norm:7.718110282439739e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.05722986161708832 norm:7.976422784850001e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:06:35 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.05718555673956871 norm:8.000977686606348e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:07:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.057142749428749084 norm:7.969008584041148e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:07:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.05710507929325104 norm:7.241570710903034e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:08:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.05708365887403488 norm:7.077530608512461e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:08:49 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.05707709118723869 norm:6.852963997516781e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:08:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 17:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.07939387112855911 norm:0.001125513343140483 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.07226180285215378 norm:0.0003994841827079654 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.06728264689445496 norm:0.00025268972967751324 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.06586623936891556 norm:0.0001886687387013808 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.06492696702480316 norm:0.00017014244804158807 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.06439922004938126 norm:0.0001571228203829378 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.06412873417139053 norm:0.00014042328984942287 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.06393617391586304 norm:0.00013840410974808037 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.06378637999296188 norm:0.00012978597078472376 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.06367500126361847 norm:0.00012774318747688085 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.06360569596290588 norm:0.00012100244202883914 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.0635068416595459 norm:0.00012165696534793824 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.06342098861932755 norm:0.00011056225775973871 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.06336066126823425 norm:0.00010897614993155003 max memory_allocated 22565.42919921875 
[2025-02-28 17:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.06329254060983658 norm:0.00010550302249612287 max memory_allocated 22565.42919921875 
[2025-02-28 17:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.06324164569377899 norm:0.00010317654232494533 max memory_allocated 22565.42919921875 
[2025-02-28 17:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.06318120658397675 norm:0.00010289654164807871 max memory_allocated 22565.42919921875 
[2025-02-28 17:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.06314288824796677 norm:0.00010324840695830062 max memory_allocated 22565.42919921875 
[2025-02-28 17:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.0631108507514 norm:0.00010120923980139196 max memory_allocated 22565.42919921875 
[2025-02-28 17:20:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.06307639181613922 norm:9.823639993555844e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:20:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 17:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.08425537496805191 norm:0.0005607780767604709 max memory_allocated 22565.60107421875 
[2025-02-28 17:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.07860922068357468 norm:0.00026635039830580354 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.07392099499702454 norm:0.0001674235099926591 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.07271996140480042 norm:0.0001460627099731937 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.07180259376764297 norm:0.00012389208131935447 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.07130183279514313 norm:0.00012198911281302571 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.07108194380998611 norm:0.00011339193588355556 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.07094445824623108 norm:0.00010849739919649437 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.0708082765340805 norm:9.994983702199534e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.07071223855018616 norm:0.00010203976125922054 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.07063490152359009 norm:9.91964916465804e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.07055389881134033 norm:9.613234578864649e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.07048684358596802 norm:9.49515524553135e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.07041633874177933 norm:8.94144395715557e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.07036757469177246 norm:8.857510692905635e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:29:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.07031698524951935 norm:8.572761726099998e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:29:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.07028308510780334 norm:9.019490971695632e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.07024163007736206 norm:8.25871029519476e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.07020676136016846 norm:8.274091669591144e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:31:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.07018598914146423 norm:8.070481271715835e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:31:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 17:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.09682144224643707 norm:0.0015153865097090602 max memory_allocated 22565.77294921875 
[2025-02-28 17:32:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.08966931700706482 norm:0.0005451904726214707 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.08438421785831451 norm:0.00031236562062986195 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.0827701985836029 norm:0.0002544377348385751 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.0817297101020813 norm:0.0002202118921559304 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.08123587816953659 norm:0.0001974443148355931 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.08101194351911545 norm:0.0001790839887689799 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.08085771650075912 norm:0.00016468575631733984 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.0807352215051651 norm:0.00015781882393639535 max memory_allocated 22565.77294921875 
[2025-02-28 17:37:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.08059420436620712 norm:0.0001509794674348086 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.08049718290567398 norm:0.00014956793165765703 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.08039684593677521 norm:0.0001401238259859383 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.08031248301267624 norm:0.00013316002150531858 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.08023273199796677 norm:0.00012773420894518495 max memory_allocated 22565.77294921875 
[2025-02-28 17:40:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.08016923815011978 norm:0.00012244627578184009 max memory_allocated 22565.77294921875 
[2025-02-28 17:40:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.08011257648468018 norm:0.00011689116945490241 max memory_allocated 22565.77294921875 
[2025-02-28 17:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.0800749659538269 norm:0.0001211038907058537 max memory_allocated 22565.77294921875 
[2025-02-28 17:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.08000383526086807 norm:0.0001100025256164372 max memory_allocated 22565.77294921875 
[2025-02-28 17:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.07995179295539856 norm:0.00010985501285176724 max memory_allocated 22565.77294921875 
[2025-02-28 17:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.07990473508834839 norm:0.00010908674448728561 max memory_allocated 22565.77294921875 
[2025-02-28 17:43:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 17:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.10935193300247192 norm:0.001820589299313724 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.10167187452316284 norm:0.0007803519256412983 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.09553837776184082 norm:0.0003873447421938181 max memory_allocated 22565.94482421875 
[2025-02-28 17:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.09383860975503922 norm:0.0002986603358294815 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.09272138774394989 norm:0.0002391891466686502 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.09224431961774826 norm:0.000203782765311189 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.09200406074523926 norm:0.0001795268035493791 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.09184236824512482 norm:0.00016691665223333985 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.09169647097587585 norm:0.00015681469812989235 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.09157541394233704 norm:0.00013577242498286068 max memory_allocated 22565.94482421875 
[2025-02-28 17:49:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.09147968888282776 norm:0.00013095761823933572 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.09138087928295135 norm:0.00012930996308568865 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.09129126369953156 norm:0.00012033541133860126 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.09122217446565628 norm:0.00011139475100208074 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.09114896506071091 norm:0.00010863867646548897 max memory_allocated 22565.94482421875 
[2025-02-28 17:52:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.09107507765293121 norm:0.00010440435289638117 max memory_allocated 22565.94482421875 
[2025-02-28 17:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.09103040397167206 norm:0.00010148712317459285 max memory_allocated 22565.94482421875 
[2025-02-28 17:53:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.09099240601062775 norm:9.717770444694906e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:53:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.09096509963274002 norm:9.26838256418705e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:54:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.09092521667480469 norm:8.964457083493471e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:54:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 17:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.12295444309711456 norm:0.002260899404063821 max memory_allocated 22566.11669921875 
[2025-02-28 17:55:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.11430788785219193 norm:0.0006410665228031576 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.10805265605449677 norm:0.0004043441731482744 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.1061466857790947 norm:0.00031302100978791714 max memory_allocated 22566.11669921875 
[2025-02-28 17:57:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.10495482385158539 norm:0.00026300043100491166 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.10448364913463593 norm:0.00022412254475057125 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.10428198426961899 norm:0.00020144970039837062 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.10411244630813599 norm:0.00019183583208359778 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.10395323485136032 norm:0.00017678577569313347 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.10382597893476486 norm:0.00018254006863571703 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.10371799767017365 norm:0.0001734840334393084 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.10360638052225113 norm:0.00016297929687425494 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.10352863371372223 norm:0.00015217716281767935 max memory_allocated 22566.11669921875 
[2025-02-28 18:02:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.10345453768968582 norm:0.00014764750085305423 max memory_allocated 22566.11669921875 
[2025-02-28 18:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.10337260365486145 norm:0.00014376972103491426 max memory_allocated 22566.11669921875 
[2025-02-28 18:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.10330764949321747 norm:0.0001361724571324885 max memory_allocated 22566.11669921875 
[2025-02-28 18:04:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.10324648767709732 norm:0.00013371625391300768 max memory_allocated 22566.11669921875 
[2025-02-28 18:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.10319898277521133 norm:0.00013052555732429028 max memory_allocated 22566.11669921875 
[2025-02-28 18:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.10315056890249252 norm:0.00013185205170884728 max memory_allocated 22566.11669921875 
[2025-02-28 18:05:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.10310035198926926 norm:0.00012937092105858028 max memory_allocated 22566.11669921875 
[2025-02-28 18:06:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 18:06:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.13992582261562347 norm:0.0014013184700161219 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.1312408298254013 norm:0.0007064455421641469 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.1238502711057663 norm:0.0003765564179047942 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.12170262634754181 norm:0.0002888533053919673 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.12056057900190353 norm:0.0002659141318872571 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.12011930346488953 norm:0.0002453796041663736 max memory_allocated 22566.28857421875 
[2025-02-28 18:10:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.11979508399963379 norm:0.000200361741008237 max memory_allocated 22566.28857421875 
[2025-02-28 18:10:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.1195642426609993 norm:0.00019167704158462584 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.11943140625953674 norm:0.00017372641013935208 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.11924853920936584 norm:0.00016050621343310922 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.11915168166160583 norm:0.0001567751169204712 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.119082510471344 norm:0.00016474383301101625 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.11895210295915604 norm:0.0001427752140443772 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.1188809871673584 norm:0.0001374080020468682 max memory_allocated 22566.28857421875 
[2025-02-28 18:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.11878787726163864 norm:0.000133541485411115 max memory_allocated 22566.28857421875 
[2025-02-28 18:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.11871885508298874 norm:0.00012981734471395612 max memory_allocated 22566.28857421875 
[2025-02-28 18:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.11869093030691147 norm:0.00012650758435484022 max memory_allocated 22566.28857421875 
[2025-02-28 18:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.118636853992939 norm:0.0001276207622140646 max memory_allocated 22566.28857421875 
[2025-02-28 18:16:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.11855050176382065 norm:0.0001206047018058598 max memory_allocated 22566.28857421875 
[2025-02-28 18:17:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.11850672215223312 norm:0.0001152562617789954 max memory_allocated 22566.28857421875 
[2025-02-28 18:17:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 18:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.15585201978683472 norm:0.0010776086710393429 max memory_allocated 22566.46044921875 
[2025-02-28 18:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.14726373553276062 norm:0.0005335666355676949 max memory_allocated 22566.46044921875 
[2025-02-28 18:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.14039257168769836 norm:0.00034274649806320667 max memory_allocated 22566.46044921875 
[2025-02-28 18:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.13810952007770538 norm:0.00026616756804287434 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.13695046305656433 norm:0.00021794487838633358 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.13650211691856384 norm:0.00019040016923099756 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.13621892035007477 norm:0.00017745012883096933 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.1359884887933731 norm:0.00016004059580154717 max memory_allocated 22566.46044921875 
[2025-02-28 18:22:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.13581937551498413 norm:0.0001567439321661368 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.13566215336322784 norm:0.00015210657147690654 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.13551920652389526 norm:0.00014386796101462096 max memory_allocated 22566.46044921875 
[2025-02-28 18:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.13538923859596252 norm:0.00014071444456931204 max memory_allocated 22566.46044921875 
[2025-02-28 18:24:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.1352771520614624 norm:0.00013215017679613084 max memory_allocated 22566.46044921875 
[2025-02-28 18:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.1352025717496872 norm:0.00013180666428525 max memory_allocated 22566.46044921875 
[2025-02-28 18:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.13511088490486145 norm:0.00012553518172353506 max memory_allocated 22566.46044921875 
[2025-02-28 18:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.13506421446800232 norm:0.00012701649393420666 max memory_allocated 22566.46044921875 
[2025-02-28 18:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.13500425219535828 norm:0.00013403448974713683 max memory_allocated 22566.46044921875 
[2025-02-28 18:27:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.1349591761827469 norm:0.00012813671492040157 max memory_allocated 22566.46044921875 
[2025-02-28 18:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.134904682636261 norm:0.00012702459935098886 max memory_allocated 22566.46044921875 
[2025-02-28 18:28:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.13487331569194794 norm:0.00013426438090391457 max memory_allocated 22566.46044921875 
[2025-02-28 18:28:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 18:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.17922315001487732 norm:0.0023354431614279747 max memory_allocated 22566.63232421875 
[2025-02-28 18:30:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.1688283085823059 norm:0.0009209045674651861 max memory_allocated 22566.63232421875 
[2025-02-28 18:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.16069117188453674 norm:0.0004247866163495928 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.15818904340267181 norm:0.0003438654530327767 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.15707774460315704 norm:0.00026342677301727235 max memory_allocated 22566.63232421875 
[2025-02-28 18:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.15667349100112915 norm:0.0002240578323835507 max memory_allocated 22566.63232421875 
[2025-02-28 18:32:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.15639926493167877 norm:0.00021108679356984794 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.15616962313652039 norm:0.00019707877072505653 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.15599367022514343 norm:0.0001855754089774564 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.1558249592781067 norm:0.0001763203472364694 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.15569263696670532 norm:0.00016878891619853675 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.15558812022209167 norm:0.00015896603872533888 max memory_allocated 22566.63232421875 
[2025-02-28 18:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.1554916799068451 norm:0.00015140116738621145 max memory_allocated 22566.63232421875 
[2025-02-28 18:36:46 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.1553991436958313 norm:0.00014674701378680766 max memory_allocated 22566.63232421875 
[2025-02-28 18:37:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.15532730519771576 norm:0.00014361653302330524 max memory_allocated 22566.63232421875 
[2025-02-28 18:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.15525472164154053 norm:0.00013862406194675714 max memory_allocated 22566.63232421875 
[2025-02-28 18:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.1551988422870636 norm:0.00013576107448898256 max memory_allocated 22566.63232421875 
[2025-02-28 18:39:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.1551421731710434 norm:0.00013001573097426444 max memory_allocated 22566.63232421875 
[2025-02-28 18:39:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.15509682893753052 norm:0.00012382926070131361 max memory_allocated 22566.63232421875 
[2025-02-28 18:40:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.15504232048988342 norm:0.00012199564662296325 max memory_allocated 22566.63232421875 
[2025-02-28 18:40:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 18:40:20 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.20291294157505035 norm:0.007513328455388546 max memory_allocated 22566.91943359375 
[2025-02-28 18:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.1932845115661621 norm:0.005631293635815382 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.18515129387378693 norm:0.0042306710965931416 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.18241658806800842 norm:0.003512810682877898 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.1812957376241684 norm:0.0028987869154661894 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.1807955652475357 norm:0.0024050232023000717 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.18048903346061707 norm:0.002160342177376151 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.18028739094734192 norm:0.0021503122989088297 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.18024934828281403 norm:0.0021666332613676786 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.18004868924617767 norm:0.0020981088746339083 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.1798366904258728 norm:0.0019031991250813007 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.17970329523086548 norm:0.001799536868929863 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.17960838973522186 norm:0.0017488965531811118 max memory_allocated 22566.91943359375 
[2025-02-28 18:48:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.17951852083206177 norm:0.0017292421543970704 max memory_allocated 22566.91943359375 
[2025-02-28 18:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.1794140487909317 norm:0.0016498618060722947 max memory_allocated 22566.91943359375 
[2025-02-28 18:49:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.17931461334228516 norm:0.001599965151399374 max memory_allocated 22566.91943359375 
[2025-02-28 18:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.17926272749900818 norm:0.0015432956861332059 max memory_allocated 22566.91943359375 
[2025-02-28 18:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.1792089343070984 norm:0.001524151535704732 max memory_allocated 22566.91943359375 
[2025-02-28 18:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.1791832447052002 norm:0.0014674658887088299 max memory_allocated 22566.91943359375 
[2025-02-28 18:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.1791248321533203 norm:0.0014497413067147136 max memory_allocated 22566.91943359375 
[2025-02-28 18:51:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 18:51:47 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:52:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.24550457298755646 norm:0.013478105887770653 max memory_allocated 22567.09130859375 
[2025-02-28 18:52:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.22906193137168884 norm:0.00944721233099699 max memory_allocated 22567.09130859375 
[2025-02-28 18:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.21717533469200134 norm:0.006151601672172546 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.21343426406383514 norm:0.005178768653422594 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.2118835747241974 norm:0.004345533438026905 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.21117357909679413 norm:0.003700532019138336 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.21074408292770386 norm:0.003159604500979185 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.21045342087745667 norm:0.0027640683110803366 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.2103787064552307 norm:0.0026791731361299753 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.21033363044261932 norm:0.0027578247245401144 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.21002744138240814 norm:0.0026218295097351074 max memory_allocated 22567.09130859375 
[2025-02-28 18:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.20978383719921112 norm:0.0023268614895641804 max memory_allocated 22567.09130859375 
[2025-02-28 18:59:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.20971032977104187 norm:0.0024251420982182026 max memory_allocated 22567.09130859375 
[2025-02-28 18:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.20967385172843933 norm:0.0023949043825268745 max memory_allocated 22567.09130859375 
[2025-02-28 19:00:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.20953607559204102 norm:0.0023213191889226437 max memory_allocated 22567.09130859375 
[2025-02-28 19:00:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.20942893624305725 norm:0.002063909312710166 max memory_allocated 22567.09130859375 
[2025-02-28 19:01:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.20938211679458618 norm:0.0021046337205916643 max memory_allocated 22567.09130859375 
[2025-02-28 19:01:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.20937635004520416 norm:0.0020519590470939875 max memory_allocated 22567.09130859375 
[2025-02-28 19:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.20922082662582397 norm:0.0019459177274256945 max memory_allocated 22567.09130859375 
[2025-02-28 19:03:01 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.2092299461364746 norm:0.001873181783594191 max memory_allocated 22567.09130859375 
[2025-02-28 19:03:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 19:03:14 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.1022510528564453 norm:0.13776308298110962 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.8758269548416138 norm:0.1191679835319519 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.5604144334793091 norm:0.06938742846250534 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.44927385449409485 norm:0.041249535977840424 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.3973095417022705 norm:0.03855890408158302 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.365349680185318 norm:0.035292234271764755 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.35183387994766235 norm:0.04091626778244972 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.33840489387512207 norm:0.035074155777692795 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.33155396580696106 norm:0.034514542669057846 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.32165348529815674 norm:0.031057799234986305 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.3226589858531952 norm:0.03353011608123779 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.32397961616516113 norm:0.03608706593513489 max memory_allocated 22567.26318359375 
[2025-02-28 19:10:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.3105996549129486 norm:0.032141294330358505 max memory_allocated 22567.26318359375 
[2025-02-28 19:11:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.3134647607803345 norm:0.032079316675662994 max memory_allocated 22567.26318359375 
[2025-02-28 19:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.3112216293811798 norm:0.03204046189785004 max memory_allocated 22567.26318359375 
[2025-02-28 19:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.3069794476032257 norm:0.029560886323451996 max memory_allocated 22567.26318359375 
[2025-02-28 19:12:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.3078088164329529 norm:0.0296783447265625 max memory_allocated 22567.26318359375 
[2025-02-28 19:13:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.3100275993347168 norm:0.03116801008582115 max memory_allocated 22567.26318359375 
[2025-02-28 19:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.30383846163749695 norm:0.0249891709536314 max memory_allocated 22567.26318359375 
[2025-02-28 19:14:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.3010926842689514 norm:0.02423539012670517 max memory_allocated 22567.26318359375 
[2025-02-28 19:14:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 19:14:41 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.5893443822860718 norm:0.037835247814655304 max memory_allocated 22567.43505859375 
[2025-02-28 19:15:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.553150475025177 norm:0.026729699224233627 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.5353925228118896 norm:0.02152964286506176 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.52412348985672 norm:0.018629785627126694 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.5173074007034302 norm:0.017536263912916183 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.5130005478858948 norm:0.01712833344936371 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.5084348917007446 norm:0.016757188364863396 max memory_allocated 22567.43505859375 
[2025-02-28 19:19:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.5050563216209412 norm:0.016579752787947655 max memory_allocated 22567.43505859375 
[2025-02-28 19:19:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.5027018189430237 norm:0.01598573662340641 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.5019902586936951 norm:0.016733527183532715 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.5006407499313354 norm:0.01647542417049408 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.500243067741394 norm:0.01604820042848587 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.4998415410518646 norm:0.016499493271112442 max memory_allocated 22567.43505859375 
[2025-02-28 19:22:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.49912458658218384 norm:0.016043536365032196 max memory_allocated 22567.43505859375 
[2025-02-28 19:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.498562216758728 norm:0.016094036400318146 max memory_allocated 22567.43505859375 
[2025-02-28 19:23:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.49868977069854736 norm:0.01639244519174099 max memory_allocated 22567.43505859375 
[2025-02-28 19:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.4987025260925293 norm:0.01628844439983368 max memory_allocated 22567.43505859375 
[2025-02-28 19:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.4989524781703949 norm:0.017150769010186195 max memory_allocated 22567.43505859375 
[2025-02-28 19:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.49767380952835083 norm:0.015447553247213364 max memory_allocated 22567.43505859375 
[2025-02-28 19:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.4980067014694214 norm:0.01646551489830017 max memory_allocated 22567.43505859375 
[2025-02-28 19:26:05 root] (main_calib_config2.py 380): INFO 21937.834498882294
[2025-02-28 19:26:10 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 19:27:21 root] (main_calib_config2.py 159): INFO wikitext2 : 5.739236831665039
[2025-02-28 19:27:21 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 19:29:11 root] (main_calib_config2.py 159): INFO c4 : 7.333722114562988
[2025-02-28 21:14:08 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.739236831665039, 'c4': 7.333722114562988, 'results': {'arc_easy': {'acc': 0.6738215488215489, 'acc_stderr': 0.009619849417035168, 'acc_norm': 0.5134680134680135, 'acc_norm_stderr': 0.010256060854840756}, 'boolq': {'acc': 0.6883792048929663, 'acc_stderr': 0.008100645491350575}, 'winogrande': {'acc': 0.6614048934490924, 'acc_stderr': 0.01330016986584242}, 'piqa': {'acc': 0.7763873775843307, 'acc_stderr': 0.009721489519176302, 'acc_norm': 0.76550598476605, 'acc_norm_stderr': 0.009885203143240541}, 'hellaswag': {'acc': 0.5531766580362477, 'acc_stderr': 0.004961481380023782, 'acc_norm': 0.711611232822147, 'acc_norm_stderr': 0.004520870679457048}, 'arc_challenge': {'acc': 0.3856655290102389, 'acc_stderr': 0.01422425097325717, 'acc_norm': 0.3924914675767918, 'acc_norm_stderr': 0.014269634635670712}}, 'versions': {'arc_easy': 0, 'boolq': 1, 'winogrande': 0, 'piqa': 0, 'hellaswag': 0, 'arc_challenge': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
