[2025-03-02 12:48:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.6', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.6.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.6.pkl
[2025-03-02 12:52:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.015046477317810059 norm:0.012117738835513592 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.008204638957977295 norm:0.00548133160918951 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.005599445663392544 norm:0.0034812367521226406 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.004835959058254957 norm:0.002797609195113182 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.004590657539665699 norm:0.002502791816368699 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:35 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.004389626439660788 norm:0.002131276298314333 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.004264120478183031 norm:0.001884859288111329 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0042033386416733265 norm:0.001716652768664062 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.004070995841175318 norm:0.0015437733381986618 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.004027074668556452 norm:0.0014033983461558819 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0039956578984856606 norm:0.0013044944498687983 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0039392453618347645 norm:0.0012417995603755116 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.003899291390553117 norm:0.001127410912886262 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0038752013351768255 norm:0.00106210692320019 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0038540305104106665 norm:0.000974118011072278 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.003822389291599393 norm:0.000929761677980423 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0038055304903537035 norm:0.0008659269660711288 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.003808665322139859 norm:0.0008311483543366194 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0037746268790215254 norm:0.0007907306426204741 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.003796142525970936 norm:0.0007845450309105217 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:29 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.026925567537546158 norm:0.016869621351361275 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.015084115788340569 norm:0.008848650380969048 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.010466614738106728 norm:0.005440406035631895 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.009272684343159199 norm:0.004616665653884411 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.00886593572795391 norm:0.004135806113481522 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.00857038889080286 norm:0.0037307394668459892 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.008345499634742737 norm:0.0034551832359284163 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.00816161185503006 norm:0.00316100986674428 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.008012155070900917 norm:0.0029626102186739445 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.007897643372416496 norm:0.00271387561224401 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.007758879568427801 norm:0.002497203880921006 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.007669083774089813 norm:0.0023630706127732992 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.007559962570667267 norm:0.0021084242034703493 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.007475104182958603 norm:0.0019593960605561733 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.0074273631907999516 norm:0.0018048033816739917 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.00739472359418869 norm:0.0016352256061509252 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.007341798860579729 norm:0.0014945740113034844 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.007282500620931387 norm:0.001364787109196186 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.007256682496517897 norm:0.0013057177420705557 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.007296328898519278 norm:0.0013220198452472687 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:23 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.03312971815466881 norm:0.009074673056602478 max memory_allocated 29268.02001953125 
[2025-03-02 13:28:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.025231121107935905 norm:0.008532484993338585 max memory_allocated 29268.02001953125 
[2025-03-02 13:28:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.021836061030626297 norm:0.007573834154754877 max memory_allocated 29268.02001953125 
[2025-03-02 13:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.021005868911743164 norm:0.006348222494125366 max memory_allocated 29268.02001953125 
[2025-03-02 13:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.019823020324110985 norm:0.005905897822231054 max memory_allocated 29268.02001953125 
[2025-03-02 13:31:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.018830377608537674 norm:0.0052076904103159904 max memory_allocated 29268.02001953125 
[2025-03-02 13:32:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.018382936716079712 norm:0.005411661695688963 max memory_allocated 29268.02001953125 
[2025-03-02 13:33:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.017984552308917046 norm:0.005127291195094585 max memory_allocated 29268.02001953125 
[2025-03-02 13:33:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.017675502225756645 norm:0.004974794574081898 max memory_allocated 29268.02001953125 
[2025-03-02 13:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.017393404617905617 norm:0.004642164800316095 max memory_allocated 29268.02001953125 
[2025-03-02 13:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.017293298617005348 norm:0.004591300152242184 max memory_allocated 29268.02001953125 
[2025-03-02 13:36:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.01719145104289055 norm:0.00447433814406395 max memory_allocated 29268.02001953125 
[2025-03-02 13:37:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.01701933890581131 norm:0.004162150900810957 max memory_allocated 29268.02001953125 
[2025-03-02 13:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.016944795846939087 norm:0.004296442493796349 max memory_allocated 29268.02001953125 
[2025-03-02 13:38:50 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.016905775293707848 norm:0.004273579455912113 max memory_allocated 29268.02001953125 
[2025-03-02 13:39:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.01703876256942749 norm:0.004162493161857128 max memory_allocated 29268.02001953125 
[2025-03-02 13:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.01689775288105011 norm:0.004120074212551117 max memory_allocated 29268.02001953125 
[2025-03-02 13:41:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.016708191484212875 norm:0.003528317902237177 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.016757048666477203 norm:0.0037441025488078594 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:59 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.01678161695599556 norm:0.0037539491895586252 max memory_allocated 29268.02001953125 
[2025-03-02 13:43:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:44:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.03224615380167961 norm:0.001604603254236281 max memory_allocated 29268.43798828125 
[2025-03-02 13:44:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.02465203031897545 norm:0.0006480587762780488 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.020842429250478745 norm:0.00034220656380057335 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.019665375351905823 norm:0.0002361153601668775 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.01905813440680504 norm:0.00014572170039173216 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.018624722957611084 norm:0.00013190938625484705 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.018342874944210052 norm:0.0001234751398442313 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.01819000393152237 norm:0.00012954525300301611 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.018091022968292236 norm:0.0001233979273820296 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.018063681200146675 norm:0.00015033782983664423 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.018084056675434113 norm:0.0001577718066982925 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.017981059849262238 norm:0.0001151787000708282 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.017954381182789803 norm:0.00011548586917342618 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.01793614961206913 norm:0.00010993191972374916 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.01793738454580307 norm:0.00011447700671851635 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.01792723685503006 norm:0.00011574196832953021 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.017900239676237106 norm:0.00010814198321895674 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.01787721924483776 norm:0.00010654587822500616 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.017885075882077217 norm:0.00011301501945126802 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.017886441200971603 norm:0.00011485407594591379 max memory_allocated 29268.43798828125 
[2025-03-02 14:00:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.03983178734779358 norm:0.0020552934147417545 max memory_allocated 29268.62548828125 
[2025-03-02 14:01:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.031007226556539536 norm:0.0007608730811625719 max memory_allocated 29268.62548828125 
[2025-03-02 14:02:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.026477228850126266 norm:0.0004940082435496151 max memory_allocated 29268.62548828125 
[2025-03-02 14:03:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.024996113032102585 norm:0.00034298337413929403 max memory_allocated 29268.62548828125 
[2025-03-02 14:04:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.02423754334449768 norm:0.00026894203620031476 max memory_allocated 29268.62548828125 
[2025-03-02 14:05:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.02369091473519802 norm:0.00020788167603313923 max memory_allocated 29268.62548828125 
[2025-03-02 14:05:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.02340221218764782 norm:0.00018868203915189952 max memory_allocated 29268.62548828125 
[2025-03-02 14:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.0233010221272707 norm:0.00018062735034618527 max memory_allocated 29268.62548828125 
[2025-03-02 14:07:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.02322096936404705 norm:0.00015706443809904158 max memory_allocated 29268.62548828125 
[2025-03-02 14:08:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.02316603809595108 norm:0.00015123772027436644 max memory_allocated 29268.62548828125 
[2025-03-02 14:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.023129764944314957 norm:0.00014216719137039036 max memory_allocated 29268.62548828125 
[2025-03-02 14:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.02317056618630886 norm:0.00020264666818547994 max memory_allocated 29268.62548828125 
[2025-03-02 14:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.02307426929473877 norm:0.00015063969476614147 max memory_allocated 29268.62548828125 
[2025-03-02 14:11:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.02301676943898201 norm:0.0001331208331976086 max memory_allocated 29268.62548828125 
[2025-03-02 14:12:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.022989625111222267 norm:0.0001227420725626871 max memory_allocated 29268.62548828125 
[2025-03-02 14:13:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.02299785241484642 norm:0.00012689126015175134 max memory_allocated 29268.62548828125 
[2025-03-02 14:14:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.022973744198679924 norm:0.00011890455789398402 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.02295880764722824 norm:0.0001272084191441536 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.02293725684285164 norm:0.00012097036960767582 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.02293947897851467 norm:0.0001266517792828381 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:17:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.04763764142990112 norm:0.0024514244869351387 max memory_allocated 29268.81298828125 
[2025-03-02 14:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.036206427961587906 norm:0.0009971766266971827 max memory_allocated 29268.81298828125 
[2025-03-02 14:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.030849633738398552 norm:0.0005414398619905114 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.029039673507213593 norm:0.0003494597040116787 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.028086453676223755 norm:0.00024736803607083857 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.027519075199961662 norm:0.00020483591652009636 max memory_allocated 29268.81298828125 
[2025-03-02 14:22:47 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.027230601757764816 norm:0.00019295951642561704 max memory_allocated 29268.81298828125 
[2025-03-02 14:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.027046609669923782 norm:0.0001657039683777839 max memory_allocated 29268.81298828125 
[2025-03-02 14:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.026966722682118416 norm:0.00016573471657466143 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:16 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.026898769661784172 norm:0.00016921751375775784 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.02683253586292267 norm:0.00015066539344843477 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.02679116651415825 norm:0.00016131358279380947 max memory_allocated 29268.81298828125 
[2025-03-02 14:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.026751238852739334 norm:0.00014004693366587162 max memory_allocated 29268.81298828125 
[2025-03-02 14:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.026704203337430954 norm:0.00015329265443142503 max memory_allocated 29268.81298828125 
[2025-03-02 14:29:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.02668829821050167 norm:0.00014425901463255286 max memory_allocated 29268.81298828125 
[2025-03-02 14:30:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.02665998972952366 norm:0.00014489014574792236 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.026629706844687462 norm:0.00014223705511540174 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.026594268158078194 norm:0.0001425866357749328 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.026578625664114952 norm:0.0001423810754204169 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.02657676301896572 norm:0.00013980527000967413 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.060243699699640274 norm:0.0020101810805499554 max memory_allocated 29269.00048828125 
[2025-03-02 14:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.047162655740976334 norm:0.0012559762690216303 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.03962191939353943 norm:0.0011378960916772485 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.03712717816233635 norm:0.001006069127470255 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.03572399914264679 norm:0.000901527761016041 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.0349537618458271 norm:0.0008213644614443183 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.03445049002766609 norm:0.0007574579794891179 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.03421590104699135 norm:0.0007090088329277933 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.03391183540225029 norm:0.0005194788100197911 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.033751361072063446 norm:0.000530361314304173 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.03377661854028702 norm:0.0005367528065107763 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.03368964418768883 norm:0.000576444435864687 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.03354964032769203 norm:0.0005664578056894243 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.03347070887684822 norm:0.0006714469054713845 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.03344128653407097 norm:0.0006089716916903853 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.033568087965250015 norm:0.0007347406935878098 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.033436119556427 norm:0.00046632910380139947 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.03346507251262665 norm:0.0005314241861924529 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.03343131020665169 norm:0.0005124823655933142 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.03340831771492958 norm:0.00048810202861204743 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.05453822389245033 norm:0.0014001952949911356 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.04504294693470001 norm:0.0006566971424035728 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.039615992456674576 norm:0.00033735373290255666 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.03793122619390488 norm:0.0002165662735933438 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.03711211308836937 norm:0.00017274766287300736 max memory_allocated 29269.18798828125 
[2025-03-02 14:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.03662334382534027 norm:0.0001535927294753492 max memory_allocated 29269.18798828125 
[2025-03-02 14:56:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.03633324056863785 norm:0.00014575349632650614 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.036177799105644226 norm:0.00014047548756934702 max memory_allocated 29269.18798828125 
[2025-03-02 14:58:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.03610536456108093 norm:0.00014186225598677993 max memory_allocated 29269.18798828125 
[2025-03-02 14:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.03601627051830292 norm:0.00014623074093833566 max memory_allocated 29269.18798828125 
[2025-03-02 14:59:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.03598404675722122 norm:0.00014374959573615342 max memory_allocated 29269.18798828125 
[2025-03-02 15:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.03594233840703964 norm:0.0001412202400388196 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.035900551825761795 norm:0.00013818724255543202 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.035872094333171844 norm:0.00013904768275097013 max memory_allocated 29269.18798828125 
[2025-03-02 15:03:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.03586561977863312 norm:0.0001388243108522147 max memory_allocated 29269.18798828125 
[2025-03-02 15:03:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.03585629165172577 norm:0.00012883084127679467 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.03583512455224991 norm:0.0001292086235480383 max memory_allocated 29269.18798828125 
[2025-03-02 15:05:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.03582596406340599 norm:0.0001318771974183619 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.03579545021057129 norm:0.00013010457041673362 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:17 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.03581148013472557 norm:0.00013721261348109692 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:08:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.05899213254451752 norm:0.0016335028922185302 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.049012988805770874 norm:0.0006739511154592037 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.043789058923721313 norm:0.00035611301427707076 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.04197266697883606 norm:0.0002482097188476473 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.04107072949409485 norm:0.000211943726753816 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.04052252322435379 norm:0.00018465894390828907 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.04022425040602684 norm:0.00016942985530477017 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.04002678021788597 norm:0.00016367090574931353 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:03 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.03990805894136429 norm:0.00015608672401867807 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.03983045741915703 norm:0.00015336238720919937 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.039774972945451736 norm:0.00015045871259644628 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.03972199931740761 norm:0.00014422251842916012 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.03967023640871048 norm:0.0001422411878593266 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.03966720029711723 norm:0.00015619212354067713 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.039649587124586105 norm:0.00016089912969619036 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.03963944688439369 norm:0.00014975837257225066 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.039622027426958084 norm:0.00015426430036313832 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.03958818316459656 norm:0.00014497802476398647 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.03958412632346153 norm:0.00014576975081581622 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.03960442543029785 norm:0.00014438673679251224 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:25:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.06048004329204559 norm:0.0013023101491853595 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.05176589637994766 norm:0.000566610018722713 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.04667936637997627 norm:0.0002974272065330297 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.045072685927152634 norm:0.00020121372654102743 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.044263556599617004 norm:0.00016382348258048296 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.04378197714686394 norm:0.0001453031727578491 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.04349988326430321 norm:0.0001365072384942323 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.04332525283098221 norm:0.00012687919661402702 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.04323611035943031 norm:0.00012691784650087357 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.043172843754291534 norm:0.00012852632789872587 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.04312651976943016 norm:0.0001264394959434867 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.04308115690946579 norm:0.00012515616253949702 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.0430535152554512 norm:0.00012394593795761466 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.04303407296538353 norm:0.0001275307877222076 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.04300229251384735 norm:0.00012550964311230928 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.04299071431159973 norm:0.00012480607256293297 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.04297463595867157 norm:0.00012124697241233662 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.04297146201133728 norm:0.00012792357301805168 max memory_allocated 29269.56298828125 
[2025-03-02 15:40:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.04297201335430145 norm:0.0001233582297572866 max memory_allocated 29269.56298828125 
[2025-03-02 15:41:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.04298677295446396 norm:0.0001246147439815104 max memory_allocated 29269.56298828125 
[2025-03-02 15:41:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.06258003413677216 norm:0.0010749793145805597 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.05464117228984833 norm:0.00044355166028253734 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.0499059297144413 norm:0.00024140685854945332 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.048350729048252106 norm:0.00017585771274752915 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.04763442650437355 norm:0.00015126702783163637 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.047161974012851715 norm:0.00013361903256736696 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.046879447996616364 norm:0.00012499306467361748 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.0467551164329052 norm:0.00012194924056529999 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.046655841171741486 norm:0.00011523494322318584 max memory_allocated 29269.75048828125 
[2025-03-02 15:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.04662926867604256 norm:0.00011886759602930397 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.046546097844839096 norm:0.0001109799777623266 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.046497318893671036 norm:0.00010790402302518487 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.046467576175928116 norm:0.0001101447269320488 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.04642629995942116 norm:0.00010943039524136111 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.04641970247030258 norm:0.00010847656812984496 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.046403918415308 norm:0.00010644579742802307 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.04640742763876915 norm:0.00010440015466883779 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.046404946595430374 norm:0.00010525473044253886 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.04640360549092293 norm:0.00010823346383403987 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.04640968516469002 norm:0.00010963870590785518 max memory_allocated 29269.75048828125 
[2025-03-02 15:58:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.06777315586805344 norm:0.0011711523402482271 max memory_allocated 29269.93798828125 
[2025-03-02 15:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.059539034962654114 norm:0.00050836376613006 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.05408520996570587 norm:0.0002713257563300431 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.05247274786233902 norm:0.00018245819956064224 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.0516883060336113 norm:0.00015034979151096195 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.05119353532791138 norm:0.0001333115651505068 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.05088963732123375 norm:0.000123780409921892 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.050731997936964035 norm:0.00011761618952732533 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.05062401667237282 norm:0.00011501332483021542 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.05055835098028183 norm:0.00011258581071160734 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.05050152167677879 norm:0.00011238561273785308 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.050468381494283676 norm:0.00010803867189679295 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.050424303859472275 norm:0.00010895455488935113 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.050384219735860825 norm:0.0001085385592887178 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.05037426948547363 norm:0.00010626329458318651 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.05035999417304993 norm:0.00010457805183250457 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.050346843898296356 norm:0.00010633504280121997 max memory_allocated 29269.93798828125 
[2025-03-02 16:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.05033351853489876 norm:0.00010451972775626928 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.050321340560913086 norm:0.00010448161629028618 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.050310906022787094 norm:0.00010506670514587313 max memory_allocated 29269.93798828125 
[2025-03-02 16:15:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:16:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.07001018524169922 norm:0.000977391260676086 max memory_allocated 29270.12548828125 
[2025-03-02 16:16:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.06240471452474594 norm:0.0004469171108212322 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.05716630443930626 norm:0.00026053734472952783 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.05546402558684349 norm:0.0001856307208072394 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.05459264665842056 norm:0.00015424897719640285 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.054066289216279984 norm:0.00013859965838491917 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.053775377571582794 norm:0.00012153576244600117 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.05363034829497337 norm:0.00011710137914633378 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.05354047939181328 norm:0.00011374230234650895 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.05349075794219971 norm:0.0001131168901338242 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.053441643714904785 norm:0.00011253702541580424 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:07 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.053395017981529236 norm:0.00010954661411233246 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.05334656685590744 norm:0.00010804639896377921 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.05329958349466324 norm:0.00010684540757210925 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.05327582731842995 norm:0.00010564971307758242 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.05326278507709503 norm:0.00010669563198462129 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.05324379354715347 norm:0.00010521952935960144 max memory_allocated 29270.12548828125 
[2025-03-02 16:30:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.0532323494553566 norm:0.00010345634655095637 max memory_allocated 29270.12548828125 
[2025-03-02 16:30:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.05321815609931946 norm:0.00010432110138935968 max memory_allocated 29270.12548828125 
[2025-03-02 16:31:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.05321233719587326 norm:0.00010304713941877708 max memory_allocated 29270.12548828125 
[2025-03-02 16:32:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.07292352616786957 norm:0.000731922744307667 max memory_allocated 29270.31298828125 
[2025-03-02 16:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.06561804562807083 norm:0.00037778422120027244 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.06040417402982712 norm:0.00023652485106140375 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.05870335176587105 norm:0.00017820777429733425 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.05771099030971527 norm:0.0001474777382100001 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.05713888257741928 norm:0.00013067266263533384 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.056816112250089645 norm:0.00012069200602127239 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.056638069450855255 norm:0.00011670785170281306 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.05652383714914322 norm:0.00011108121543657035 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.056436341255903244 norm:0.00010801610187627375 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.05637102946639061 norm:0.00010489473061170429 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.05632297694683075 norm:0.00010534586908761412 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.05627323314547539 norm:0.00010029197437688708 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.05624063313007355 norm:9.796878293855116e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.056210584938526154 norm:9.858253179118037e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.05618997663259506 norm:9.82079072855413e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.05616511031985283 norm:9.700893861008808e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:47:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.056139662861824036 norm:9.5484392659273e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:47:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.05613141506910324 norm:9.708246943773702e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.05613257735967636 norm:9.764865535544232e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:49:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.0785117968916893 norm:0.001140030799433589 max memory_allocated 29270.50048828125 
[2025-03-02 16:50:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.07028760015964508 norm:0.0005628225626423955 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.06424903869628906 norm:0.0003300929965917021 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.06248883903026581 norm:0.00023575640807393938 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.06156398355960846 norm:0.00018542268662713468 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.06099048629403114 norm:0.00015906135377008468 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.060668300837278366 norm:0.00014478593948297203 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.06050034612417221 norm:0.00013595358177553862 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.060354083776474 norm:0.00012913481623400003 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.06026676669716835 norm:0.00012628476542886347 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.06019531935453415 norm:0.00012278827489353716 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.06012376397848129 norm:0.00011526742309797555 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.06008099764585495 norm:0.00011443929543020204 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.06004061922430992 norm:0.00011163061572005972 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.060005296021699905 norm:0.00010952734010061249 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.0599767342209816 norm:0.00010907095565926284 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.059944331645965576 norm:0.00010956452751997858 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.05992517247796059 norm:0.00010922054934781045 max memory_allocated 29270.50048828125 
[2025-03-02 17:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.05991053208708763 norm:0.00010819983435794711 max memory_allocated 29270.50048828125 
[2025-03-02 17:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.05990496277809143 norm:0.00010953775199595839 max memory_allocated 29270.50048828125 
[2025-03-02 17:05:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:06:39 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.08084557950496674 norm:0.0008268230594694614 max memory_allocated 29270.68798828125 
[2025-03-02 17:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.07379809021949768 norm:0.0003667151613626629 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.06890808790922165 norm:0.0002465236175339669 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.06723438203334808 norm:0.00019408547086641192 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.0661359578371048 norm:0.00016251447959803045 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.06548140197992325 norm:0.00014773954171687365 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.06516079604625702 norm:0.00013602768012788147 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.06495504081249237 norm:0.0001243694860022515 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.06482167541980743 norm:0.00011406554403947666 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.06474129855632782 norm:0.00011110178456874564 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.06465570628643036 norm:0.00010721368016675115 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.06459643691778183 norm:0.00010371288226451725 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.06456094980239868 norm:0.00010262324940413237 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.0645049586892128 norm:0.0001004969744826667 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.06448327749967575 norm:9.991490514948964e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.0644569918513298 norm:9.848759509623051e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.06443613022565842 norm:9.844308078754693e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:20:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.06440557539463043 norm:9.711345046525821e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.06439746171236038 norm:9.665167453931645e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:22:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.06439170241355896 norm:9.691152081359178e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:22:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.08479470759630203 norm:0.0011412526946514845 max memory_allocated 29270.87548828125 
[2025-03-02 17:24:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.07828954607248306 norm:0.0005552223883569241 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.07343018800020218 norm:0.0003365623124409467 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.07185174524784088 norm:0.00023974859504960477 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.0708991140127182 norm:0.00018576256115920842 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.07033208012580872 norm:0.0001535356423119083 max memory_allocated 29270.87548828125 
[2025-03-02 17:28:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.07004882395267487 norm:0.00013312758528627455 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.06989647448062897 norm:0.0001222198479808867 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.06980745494365692 norm:0.00011830739094875753 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.0697239562869072 norm:0.00011080082185799256 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.06966973096132278 norm:0.00010839983588084579 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.06961245089769363 norm:0.00010629431926645339 max memory_allocated 29270.87548828125 
[2025-03-02 17:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.06956477463245392 norm:0.00010424004722153768 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.0695340558886528 norm:0.00010310171637684107 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.06949914246797562 norm:0.00010182859841734171 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.06947191059589386 norm:0.00010206738079432398 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.06945857405662537 norm:0.00010277899855282158 max memory_allocated 29270.87548828125 
[2025-03-02 17:37:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.0694468542933464 norm:0.00010242876305710524 max memory_allocated 29270.87548828125 
[2025-03-02 17:38:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.06942054629325867 norm:0.00010210300388280302 max memory_allocated 29270.87548828125 
[2025-03-02 17:39:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.06941162049770355 norm:0.00010139056394109502 max memory_allocated 29270.87548828125 
[2025-03-02 17:39:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:40:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.0929877758026123 norm:0.0015299780061468482 max memory_allocated 29271.06298828125 
[2025-03-02 17:41:13 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.08539879322052002 norm:0.0006954225245863199 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.07965850085020065 norm:0.0004034979792777449 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.07788221538066864 norm:0.00027885186136700213 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.07674112915992737 norm:0.00021081659360788763 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.07613132894039154 norm:0.00017037676298059523 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.07582676410675049 norm:0.00014592827938031405 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.07566383481025696 norm:0.0001297243288718164 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.07557176798582077 norm:0.0001184557841042988 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.0754946917295456 norm:0.00011116944369859993 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.07542496174573898 norm:0.00010635115177137777 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.07535326480865479 norm:0.00010273052612319589 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.07530148327350616 norm:0.00010044473310699686 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.07526574283838272 norm:9.74672511802055e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:58 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.0752263143658638 norm:9.630018030293286e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.07518964260816574 norm:9.449739445699379e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.07515302300453186 norm:9.392658103024587e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:54:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.0751427710056305 norm:9.334836067864671e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:55:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.07513394951820374 norm:9.376323578180745e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:56:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.07511559128761292 norm:9.47496882872656e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:56:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:57:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.10267307609319687 norm:0.001461791223846376 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.09441456943750381 norm:0.0006274337065406144 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.08828575164079666 norm:0.00035075179766863585 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.08641862869262695 norm:0.0002468862512614578 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.08523958921432495 norm:0.00019351921218913049 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.08465123176574707 norm:0.00016495469026267529 max memory_allocated 29271.25048828125 
[2025-03-02 18:02:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.08435212075710297 norm:0.00014797953190281987 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.08419443666934967 norm:0.0001367705117445439 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.0840795636177063 norm:0.00012892141239717603 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.0839606299996376 norm:0.00012167328532086685 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.0838555172085762 norm:0.00011712618288584054 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.0837787464261055 norm:0.00011426470155129209 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.08370877802371979 norm:0.00011053979687858373 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.08365733921527863 norm:0.00010997818753821775 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.08362574130296707 norm:0.00010729983478086069 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.08359614759683609 norm:0.00010698079131543636 max memory_allocated 29271.25048828125 
[2025-03-02 18:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.08357261121273041 norm:0.00010601627582218498 max memory_allocated 29271.25048828125 
[2025-03-02 18:11:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.0835404247045517 norm:0.00010609148012008518 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.08351968228816986 norm:0.00010524621757213026 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.08350533246994019 norm:0.00010564134572632611 max memory_allocated 29271.25048828125 
[2025-03-02 18:13:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:14:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.11178821325302124 norm:0.0009753124904818833 max memory_allocated 29271.43798828125 
[2025-03-02 18:14:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.10416499525308609 norm:0.00045383244287222624 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.09772266447544098 norm:0.0002745046222116798 max memory_allocated 29271.43798828125 
[2025-03-02 18:16:35 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.0957990363240242 norm:0.00020058153313584626 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.09465514123439789 norm:0.0001661611022427678 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.09413905441761017 norm:0.00014304107753559947 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.09385353326797485 norm:0.00013078111805953085 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.09369257092475891 norm:0.0001213829091284424 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.09359252452850342 norm:0.00011850272858282551 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.09348321706056595 norm:0.00011586036998778582 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.09341835975646973 norm:0.00011129461927339435 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.09334966540336609 norm:0.00011018632358172908 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.09330416470766068 norm:0.00010831870167749003 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.09327144175767899 norm:0.00010571440361673012 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.09322672337293625 norm:0.00010581772949080914 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.09319204092025757 norm:0.00010513479355722666 max memory_allocated 29271.43798828125 
[2025-03-02 18:27:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.09316299855709076 norm:0.00010290652426192537 max memory_allocated 29271.43798828125 
[2025-03-02 18:28:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.09312693029642105 norm:0.00010300675057806075 max memory_allocated 29271.43798828125 
[2025-03-02 18:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.09309421479701996 norm:0.00010218835814157501 max memory_allocated 29271.43798828125 
[2025-03-02 18:29:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.09306376427412033 norm:0.00010143157851416618 max memory_allocated 29271.43798828125 
[2025-03-02 18:30:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:30:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.12488283216953278 norm:0.0010041013592854142 max memory_allocated 29271.62548828125 
[2025-03-02 18:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.11572816967964172 norm:0.0004824751813430339 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.10834433883428574 norm:0.00028426601784303784 max memory_allocated 29271.62548828125 
[2025-03-02 18:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.10620757192373276 norm:0.00021396021475084126 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.10498818755149841 norm:0.00017900076636578888 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.10447776317596436 norm:0.00015784800052642822 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.10421052575111389 norm:0.0001434316800441593 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.10402342677116394 norm:0.00013373568071983755 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.10386960953474045 norm:0.00012537134170997888 max memory_allocated 29271.62548828125 
[2025-03-02 18:38:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.10373454540967941 norm:0.00012019270798191428 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.1036161333322525 norm:0.00011744116636691615 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.10352883487939835 norm:0.00011390929284971207 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.10347079485654831 norm:0.0001107330244849436 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.1034260168671608 norm:0.00011080325930379331 max memory_allocated 29271.62548828125 
[2025-03-02 18:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.10337988287210464 norm:0.00010988071881001815 max memory_allocated 29271.62548828125 
[2025-03-02 18:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.10334496200084686 norm:0.00010903104703174904 max memory_allocated 29271.62548828125 
[2025-03-02 18:44:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.10330908745527267 norm:0.0001074560423148796 max memory_allocated 29271.62548828125 
[2025-03-02 18:45:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.10327115654945374 norm:0.00010506472608540207 max memory_allocated 29271.62548828125 
[2025-03-02 18:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.10324283689260483 norm:0.00010400153405498713 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.10320337116718292 norm:0.0001024458251777105 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.14210326969623566 norm:0.001152118667960167 max memory_allocated 29271.81298828125 
[2025-03-02 18:48:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.13147737085819244 norm:0.0006069723749533296 max memory_allocated 29271.81298828125 
[2025-03-02 18:49:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.12288656830787659 norm:0.0003796807141043246 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.1204911470413208 norm:0.00028263244894333184 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.11916539818048477 norm:0.00022328627528622746 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.11861477792263031 norm:0.00018699083011597395 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.1182856485247612 norm:0.00016563083045184612 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.11809519678354263 norm:0.00015548565716017038 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.1179077997803688 norm:0.0001465386594645679 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.11778345704078674 norm:0.00014045632269699126 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.1177070364356041 norm:0.000136783070047386 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.11762179434299469 norm:0.00013182083785068244 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.11755743622779846 norm:0.00013056174793746322 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.11746691912412643 norm:0.00012891019287053496 max memory_allocated 29271.81298828125 
[2025-03-02 18:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.11738846451044083 norm:0.0001272614172194153 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.11733844876289368 norm:0.00012519901792984456 max memory_allocated 29271.81298828125 
[2025-03-02 19:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.1172909289598465 norm:0.0001268157211598009 max memory_allocated 29271.81298828125 
[2025-03-02 19:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.11725978553295135 norm:0.00012620790221262723 max memory_allocated 29271.81298828125 
[2025-03-02 19:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.11721761524677277 norm:0.00012427782348822802 max memory_allocated 29271.81298828125 
[2025-03-02 19:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.117185577750206 norm:0.00012326656724326313 max memory_allocated 29271.81298828125 
[2025-03-02 19:03:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.15934759378433228 norm:0.001091386191546917 max memory_allocated 29272.00048828125 
[2025-03-02 19:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.14862002432346344 norm:0.0005746842361986637 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.1395721137523651 norm:0.0003621935611590743 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.13706599175930023 norm:0.000281411106698215 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.13576321303844452 norm:0.000233752783969976 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.13526038825511932 norm:0.0002111448411596939 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.13497965037822723 norm:0.00019688368774950504 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.1347375512123108 norm:0.0001855028822319582 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.13455548882484436 norm:0.00017934180505108088 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.1344195008277893 norm:0.0001760946906870231 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.13428576290607452 norm:0.00017283341730944812 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.13413918018341064 norm:0.00016817670257296413 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.13403762876987457 norm:0.00016537880583200604 max memory_allocated 29272.00048828125 
[2025-03-02 19:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.1339583694934845 norm:0.00016327519551850855 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.1338610202074051 norm:0.0001602899719728157 max memory_allocated 29272.00048828125 
[2025-03-02 19:17:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.13379959762096405 norm:0.00015810008335392922 max memory_allocated 29272.00048828125 
[2025-03-02 19:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.13374710083007812 norm:0.00015736723435111344 max memory_allocated 29272.00048828125 
[2025-03-02 19:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.13369646668434143 norm:0.00015873023949097842 max memory_allocated 29272.00048828125 
[2025-03-02 19:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.13362321257591248 norm:0.00015460155555047095 max memory_allocated 29272.00048828125 
[2025-03-02 19:20:29 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.1335849016904831 norm:0.00015466225158888847 max memory_allocated 29272.00048828125 
[2025-03-02 19:20:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:21:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.18217912316322327 norm:0.0013730061473324895 max memory_allocated 29272.18798828125 
[2025-03-02 19:22:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.17020776867866516 norm:0.0007091080769896507 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.16036126017570496 norm:0.0004266380856279284 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.1573951244354248 norm:0.0003194825258105993 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.15599115192890167 norm:0.00026614542002789676 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.15547719597816467 norm:0.00023500500537920743 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.1551855057477951 norm:0.0002177644200855866 max memory_allocated 29272.18798828125 
[2025-03-02 19:27:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.15492284297943115 norm:0.0002038295497186482 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.1547163873910904 norm:0.00019416146096773446 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.15452511608600616 norm:0.00018628223915584385 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.15443365275859833 norm:0.00018134202400688082 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.15429174900054932 norm:0.0001755067496560514 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.1542029082775116 norm:0.00017109517648350447 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.15406185388565063 norm:0.00016793467511888593 max memory_allocated 29272.18798828125 
[2025-03-02 19:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.15398462116718292 norm:0.00016526046965736896 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.15391181409358978 norm:0.00016101205255836248 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.15380626916885376 norm:0.00015938268916215748 max memory_allocated 29272.18798828125 
[2025-03-02 19:35:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.15376165509223938 norm:0.00015825119044166058 max memory_allocated 29272.18798828125 
[2025-03-02 19:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.1536940038204193 norm:0.00015589346003253013 max memory_allocated 29272.18798828125 
[2025-03-02 19:37:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.15366852283477783 norm:0.00015606133092660457 max memory_allocated 29272.18798828125 
[2025-03-02 19:37:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:38:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.18586204946041107 norm:0.0028590750880539417 max memory_allocated 29272.37548828125 
[2025-03-02 19:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.18158122897148132 norm:0.0014382264344021678 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.17833901941776276 norm:0.0008899785461835563 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.17538607120513916 norm:0.0006088133668527007 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.17405037581920624 norm:0.0004518058558460325 max memory_allocated 29272.37548828125 
[2025-03-02 19:42:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.17373207211494446 norm:0.0003635704633779824 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.17354831099510193 norm:0.00030704159871675074 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.17342382669448853 norm:0.0002725131926126778 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.17338965833187103 norm:0.0002505320589989424 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.17333728075027466 norm:0.0002340615028515458 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.17329390347003937 norm:0.00022389277000911534 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.17327497899532318 norm:0.00021798163652420044 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.17324510216712952 norm:0.0002122651058016345 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.1732284277677536 norm:0.00020769963157363236 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.17321117222309113 norm:0.00020677440625149757 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.1731833517551422 norm:0.00020296142611186951 max memory_allocated 29272.37548828125 
[2025-03-02 19:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.17317001521587372 norm:0.00020115787629038095 max memory_allocated 29272.37548828125 
[2025-03-02 19:52:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.1731691062450409 norm:0.00019975811301264912 max memory_allocated 29272.37548828125 
[2025-03-02 19:53:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.1731714904308319 norm:0.0001991495955735445 max memory_allocated 29272.37548828125 
[2025-03-02 19:54:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.17316265404224396 norm:0.00019879272440448403 max memory_allocated 29272.37548828125 
[2025-03-02 19:54:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.226033553481102 norm:0.0010944533860310912 max memory_allocated 29272.56298828125 
[2025-03-02 19:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.213815838098526 norm:0.0005962922004982829 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.20281681418418884 norm:0.0003720790264196694 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.19979196786880493 norm:0.0002897035446949303 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.1984642595052719 norm:0.000244720111368224 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.1979617029428482 norm:0.00021909487259108573 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.1976131796836853 norm:0.00020500336540862918 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.19736406207084656 norm:0.00019125183462165296 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.1971442699432373 norm:0.0001831212139222771 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.19693028926849365 norm:0.00017839249630924314 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.19674885272979736 norm:0.0001756202691467479 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.19660808145999908 norm:0.00017089472385123372 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.19648821651935577 norm:0.00016827357467263937 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.19636598229408264 norm:0.00016684539150446653 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.1962626874446869 norm:0.00016585024422965944 max memory_allocated 29272.56298828125 
[2025-03-02 20:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.19619549810886383 norm:0.00016426670481450856 max memory_allocated 29272.56298828125 
[2025-03-02 20:08:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.19610819220542908 norm:0.0001633748906897381 max memory_allocated 29272.56298828125 
[2025-03-02 20:09:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.19604511559009552 norm:0.00016099555068649352 max memory_allocated 29272.56298828125 
[2025-03-02 20:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.19599281251430511 norm:0.00015807485033292323 max memory_allocated 29272.56298828125 
[2025-03-02 20:11:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.19592465460300446 norm:0.0001576796203153208 max memory_allocated 29272.56298828125 
[2025-03-02 20:11:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:12:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.23165716230869293 norm:0.0022825347259640694 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.22784094512462616 norm:0.0009449758799746633 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:53 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.22463461756706238 norm:0.0005599685828201473 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.22155903279781342 norm:0.0003908864164259285 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.220443457365036 norm:0.0003059091104660183 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.2201770842075348 norm:0.00026516756042838097 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:12 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.22005605697631836 norm:0.00023965243599377573 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.21997174620628357 norm:0.00022542834631167352 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.21990954875946045 norm:0.0002159618161385879 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.2198750376701355 norm:0.00021157746959943324 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.21983075141906738 norm:0.000207001983653754 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.21980732679367065 norm:0.00020449738076422364 max memory_allocated 29272.75048828125 
[2025-03-02 20:22:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.21978171169757843 norm:0.00020361508359201252 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:00 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.21976043283939362 norm:0.00020196440163999796 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.21975326538085938 norm:0.00020144166774116457 max memory_allocated 29272.75048828125 
[2025-03-02 20:24:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.2197348177433014 norm:0.0002016494981944561 max memory_allocated 29272.75048828125 
[2025-03-02 20:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.21972966194152832 norm:0.00020149670308455825 max memory_allocated 29272.75048828125 
[2025-03-02 20:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.21972240507602692 norm:0.00020151161879766732 max memory_allocated 29272.75048828125 
[2025-03-02 20:27:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.2197277843952179 norm:0.00020192028023302555 max memory_allocated 29272.75048828125 
[2025-03-02 20:27:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.2197241187095642 norm:0.00020151307398919016 max memory_allocated 29272.75048828125 
[2025-03-02 20:28:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:29:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.2835373282432556 norm:0.0010136672062799335 max memory_allocated 29272.93798828125 
[2025-03-02 20:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.2686586380004883 norm:0.0005265563377179205 max memory_allocated 29272.93798828125 
[2025-03-02 20:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.2549228072166443 norm:0.00033825013088062406 max memory_allocated 29272.93798828125 
[2025-03-02 20:31:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.25124508142471313 norm:0.00026699717273004353 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.24992801249027252 norm:0.000233989063417539 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.24940679967403412 norm:0.00021427737374324352 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.24900199472904205 norm:0.00020269067317713052 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.24872973561286926 norm:0.00019392598187550902 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.24847933650016785 norm:0.0001864403166109696 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.24829831719398499 norm:0.00018147798255085945 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.2480774074792862 norm:0.00017687621584627777 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.2478976994752884 norm:0.00017511942132841796 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.24774320423603058 norm:0.00017366197425872087 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.24763090908527374 norm:0.00017457555804867297 max memory_allocated 29272.93798828125 
[2025-03-02 20:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.24751430749893188 norm:0.00017479617963545024 max memory_allocated 29272.93798828125 
[2025-03-02 20:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.2474096119403839 norm:0.00017216586275026202 max memory_allocated 29272.93798828125 
[2025-03-02 20:42:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.24729809165000916 norm:0.000168490078067407 max memory_allocated 29272.93798828125 
[2025-03-02 20:43:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.24721543490886688 norm:0.00016818064614199102 max memory_allocated 29272.93798828125 
[2025-03-02 20:44:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.24713635444641113 norm:0.00016838544979691505 max memory_allocated 29272.93798828125 
[2025-03-02 20:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.2470492124557495 norm:0.00017013565229717642 max memory_allocated 29272.93798828125 
[2025-03-02 20:45:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.3136546015739441 norm:0.001174948294647038 max memory_allocated 29273.12548828125 
[2025-03-02 20:46:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.29834824800491333 norm:0.0006447283667512238 max memory_allocated 29273.12548828125 
[2025-03-02 20:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.28390854597091675 norm:0.0004392671398818493 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.2798319458961487 norm:0.0003802202409133315 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.2785552144050598 norm:0.00033899961272254586 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.27806761860847473 norm:0.0002993592934217304 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.27771300077438354 norm:0.0002809067955240607 max memory_allocated 29273.12548828125 
[2025-03-02 20:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.2774100601673126 norm:0.0002655261487234384 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.27715975046157837 norm:0.0002624782791826874 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.27698108553886414 norm:0.0002619520528241992 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.2767965793609619 norm:0.00025653393822722137 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.27665647864341736 norm:0.00025961807114072144 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.27652108669281006 norm:0.00026526665897108614 max memory_allocated 29273.12548828125 
[2025-03-02 20:56:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.27638131380081177 norm:0.00026364100631326437 max memory_allocated 29273.12548828125 
[2025-03-02 20:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.2762603461742401 norm:0.0002542728907428682 max memory_allocated 29273.12548828125 
[2025-03-02 20:58:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.2761627435684204 norm:0.00025747506879270077 max memory_allocated 29273.12548828125 
[2025-03-02 20:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.2760774791240692 norm:0.00026276419521309435 max memory_allocated 29273.12548828125 
[2025-03-02 21:00:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.27599969506263733 norm:0.00026720063760876656 max memory_allocated 29273.12548828125 
[2025-03-02 21:00:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.2759156823158264 norm:0.0002661096805240959 max memory_allocated 29273.12548828125 
[2025-03-02 21:01:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.27586784958839417 norm:0.00027330650482326746 max memory_allocated 29273.12548828125 
[2025-03-02 21:01:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 21:02:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.3441010117530823 norm:0.0018264458049088717 max memory_allocated 29273.31298828125 
[2025-03-02 21:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.32808277010917664 norm:0.0009456477127969265 max memory_allocated 29273.31298828125 
[2025-03-02 21:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.31294867396354675 norm:0.0005617291899397969 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.30876389145851135 norm:0.0003885599144268781 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.3075351119041443 norm:0.0003010790387634188 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.3070633113384247 norm:0.0002539056586101651 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.3067152798175812 norm:0.00022388450452126563 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.30642935633659363 norm:0.00020330552069935948 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.3061947822570801 norm:0.00018990844546351582 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.30598002672195435 norm:0.0001811271213227883 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.30579930543899536 norm:0.00017508956079836935 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.305622935295105 norm:0.00017025294073391706 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.3054620623588562 norm:0.00016605848213657737 max memory_allocated 29273.31298828125 
[2025-03-02 21:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.3053244352340698 norm:0.0001645712327444926 max memory_allocated 29273.31298828125 
[2025-03-02 21:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.30519992113113403 norm:0.0001630659244256094 max memory_allocated 29273.31298828125 
[2025-03-02 21:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.30509325861930847 norm:0.00016079889610409737 max memory_allocated 29273.31298828125 
[2025-03-02 21:16:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.30498990416526794 norm:0.00015903430175967515 max memory_allocated 29273.31298828125 
[2025-03-02 21:16:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.3048911988735199 norm:0.000159159186296165 max memory_allocated 29273.31298828125 
[2025-03-02 21:17:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.30481916666030884 norm:0.0001571784378029406 max memory_allocated 29273.31298828125 
[2025-03-02 21:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.30474233627319336 norm:0.00015569142124149948 max memory_allocated 29273.31298828125 
[2025-03-02 21:18:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:19:42 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.3777896463871002 norm:0.0017429522704333067 max memory_allocated 29273.50048828125 
[2025-03-02 21:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.3614605665206909 norm:0.0008804366225376725 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.345881849527359 norm:0.0005271196132525802 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.3417348265647888 norm:0.0003783521242439747 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.3405628800392151 norm:0.00030983053147792816 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.33999544382095337 norm:0.00028184906113892794 max memory_allocated 29273.50048828125 
[2025-03-02 21:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.3395821750164032 norm:0.00026330346008762717 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.33926665782928467 norm:0.00023473880719393492 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.3389538526535034 norm:0.00021981511963531375 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.33869585394859314 norm:0.00021368189482018352 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.3385011553764343 norm:0.00020956994558218867 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.33833998441696167 norm:0.0002062795392703265 max memory_allocated 29273.50048828125 
[2025-03-02 21:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.33816954493522644 norm:0.00020543014397844672 max memory_allocated 29273.50048828125 
[2025-03-02 21:30:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.3380073308944702 norm:0.00020241158199496567 max memory_allocated 29273.50048828125 
[2025-03-02 21:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.33789026737213135 norm:0.0002021180116571486 max memory_allocated 29273.50048828125 
[2025-03-02 21:32:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.33776435256004333 norm:0.00020179789862595499 max memory_allocated 29273.50048828125 
[2025-03-02 21:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.3376501798629761 norm:0.00020018361101392657 max memory_allocated 29273.50048828125 
[2025-03-02 21:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.3375511169433594 norm:0.00019726534083019942 max memory_allocated 29273.50048828125 
[2025-03-02 21:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.33747053146362305 norm:0.00019881746266037226 max memory_allocated 29273.50048828125 
[2025-03-02 21:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.3373749256134033 norm:0.00020407084957696497 max memory_allocated 29273.50048828125 
[2025-03-02 21:35:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:36:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.41549670696258545 norm:0.0020625218749046326 max memory_allocated 29273.68798828125 
[2025-03-02 21:37:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.39751797914505005 norm:0.0009958642767742276 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.3812168836593628 norm:0.0005888548912480474 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.37655317783355713 norm:0.00040699864621274173 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.3752778470516205 norm:0.0003222009108867496 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.37473687529563904 norm:0.00027581164613366127 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.37432700395584106 norm:0.0002468604943715036 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.37399202585220337 norm:0.00022834261471871287 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.3736768960952759 norm:0.00021699213539250195 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.3734199106693268 norm:0.0002077967074001208 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.37320441007614136 norm:0.00020202073210384697 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.37303194403648376 norm:0.00019629532471299171 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.3728597164154053 norm:0.00019397145661059767 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.37269923090934753 norm:0.00019502696522977203 max memory_allocated 29273.68798828125 
[2025-03-02 21:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.3725503087043762 norm:0.00019783456809818745 max memory_allocated 29273.68798828125 
[2025-03-02 21:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.37245044112205505 norm:0.0001945417607203126 max memory_allocated 29273.68798828125 
[2025-03-02 21:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.3723306655883789 norm:0.0001955904735950753 max memory_allocated 29273.68798828125 
[2025-03-02 21:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.372241735458374 norm:0.0001953632163349539 max memory_allocated 29273.68798828125 
[2025-03-02 21:51:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.37215569615364075 norm:0.00019922369392588735 max memory_allocated 29273.68798828125 
[2025-03-02 21:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.37207531929016113 norm:0.00019909915863536298 max memory_allocated 29273.68798828125 
[2025-03-02 21:52:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.4515644907951355 norm:0.002497856505215168 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.43345388770103455 norm:0.0012539519229903817 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:11 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.4164298474788666 norm:0.0007368579390458763 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:01 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.41185393929481506 norm:0.0005026900907978415 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.41066980361938477 norm:0.00038759279414080083 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:40 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.4100801348686218 norm:0.0003207818663213402 max memory_allocated 29273.87548828125 
[2025-03-02 21:58:30 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.40965402126312256 norm:0.0002778000489342958 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.4093055725097656 norm:0.0002507530152797699 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:10 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.40900057554244995 norm:0.00023120820696931332 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.4087541699409485 norm:0.00021824844588991255 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.4085434675216675 norm:0.00020892071188427508 max memory_allocated 29273.87548828125 
[2025-03-02 22:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.408334881067276 norm:0.0002033209166256711 max memory_allocated 29273.87548828125 
[2025-03-02 22:03:29 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.4081527888774872 norm:0.00019883186905644834 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.40799567103385925 norm:0.00019429756503086537 max memory_allocated 29273.87548828125 
[2025-03-02 22:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.407867431640625 norm:0.00019148584397044033 max memory_allocated 29273.87548828125 
[2025-03-02 22:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.407742977142334 norm:0.0001897373585961759 max memory_allocated 29273.87548828125 
[2025-03-02 22:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.4076249301433563 norm:0.00018712642486207187 max memory_allocated 29273.87548828125 
[2025-03-02 22:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.4075128138065338 norm:0.0001855495065683499 max memory_allocated 29273.87548828125 
[2025-03-02 22:08:28 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.4074282646179199 norm:0.00018422420544084162 max memory_allocated 29273.87548828125 
[2025-03-02 22:09:18 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.4073481857776642 norm:0.00018283678218722343 max memory_allocated 29273.87548828125 
[2025-03-02 22:09:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.49421757459640503 norm:0.0014129887567833066 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:16 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.47544050216674805 norm:0.0007663787109777331 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.45791351795196533 norm:0.0004860028566326946 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:56 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.45341774821281433 norm:0.000363209837814793 max memory_allocated 29274.06298828125 
[2025-03-02 22:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.45236364006996155 norm:0.000308274436974898 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:35 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.45176419615745544 norm:0.0002710380358621478 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:25 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.4512757956981659 norm:0.0002564567548688501 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:15 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.4508713483810425 norm:0.00024118756118696183 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.45054876804351807 norm:0.00023112414055503905 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:55 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.45023608207702637 norm:0.00022572475427296013 max memory_allocated 29274.06298828125 
[2025-03-02 22:18:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.44995516538619995 norm:0.00022286304738372564 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.4497389495372772 norm:0.00022401665046345443 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:24 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.4495460093021393 norm:0.00022057877504266798 max memory_allocated 29274.06298828125 
[2025-03-02 22:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.4493663012981415 norm:0.00022044214711058885 max memory_allocated 29274.06298828125 
[2025-03-02 22:22:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.4492192566394806 norm:0.0002189385413657874 max memory_allocated 29274.06298828125 
[2025-03-02 22:22:53 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.44911491870880127 norm:0.0002197779540438205 max memory_allocated 29274.06298828125 
[2025-03-02 22:23:43 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.44899898767471313 norm:0.00022284143778961152 max memory_allocated 29274.06298828125 
[2025-03-02 22:24:33 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.44885003566741943 norm:0.00022035115398466587 max memory_allocated 29274.06298828125 
[2025-03-02 22:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.44873079657554626 norm:0.0002221550530521199 max memory_allocated 29274.06298828125 
[2025-03-02 22:26:12 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.4486185312271118 norm:0.00021689954155590385 max memory_allocated 29274.06298828125 
[2025-03-02 22:26:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:27:21 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.5490765571594238 norm:0.0019596917554736137 max memory_allocated 29274.25048828125 
[2025-03-02 22:28:11 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.5275194048881531 norm:0.001013391651213169 max memory_allocated 29274.25048828125 
[2025-03-02 22:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.5072939991950989 norm:0.0005839235382154584 max memory_allocated 29274.25048828125 
[2025-03-02 22:29:50 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.5023446083068848 norm:0.00042565923649817705 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:40 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.5012961030006409 norm:0.00035270460648462176 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:30 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.5007004141807556 norm:0.00031077416497282684 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:20 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.5002541542053223 norm:0.000285077840089798 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:09 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.49984976649284363 norm:0.00026698788860812783 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.4995419681072235 norm:0.0002561723522376269 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.499268114566803 norm:0.00025208492297679186 max memory_allocated 29274.25048828125 
[2025-03-02 22:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.4990077018737793 norm:0.00024632763233967125 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.49874815344810486 norm:0.0002424514532322064 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:18 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.49850994348526 norm:0.00023731686815153807 max memory_allocated 29274.25048828125 
[2025-03-02 22:38:08 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.498252272605896 norm:0.00024024613958317786 max memory_allocated 29274.25048828125 
[2025-03-02 22:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.49803537130355835 norm:0.00023851370497141033 max memory_allocated 29274.25048828125 
[2025-03-02 22:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.49790558218955994 norm:0.0002329921117052436 max memory_allocated 29274.25048828125 
[2025-03-02 22:40:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.4978047013282776 norm:0.00023278318985830992 max memory_allocated 29274.25048828125 
[2025-03-02 22:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.4977032244205475 norm:0.00023454826441593468 max memory_allocated 29274.25048828125 
[2025-03-02 22:42:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.49761897325515747 norm:0.0002336034958716482 max memory_allocated 29274.25048828125 
[2025-03-02 22:43:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.49749478697776794 norm:0.00023068609880283475 max memory_allocated 29274.25048828125 
[2025-03-02 22:43:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:44:16 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.6074166893959045 norm:0.00346158049069345 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.5825477242469788 norm:0.001836032490245998 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.5603809356689453 norm:0.001106919371522963 max memory_allocated 29274.43798828125 
[2025-03-02 22:46:45 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.5552985668182373 norm:0.0007696918910369277 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.5540229082107544 norm:0.0006116889999248087 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.5531909465789795 norm:0.0005108262412250042 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.5525209307670593 norm:0.0004502181545831263 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:04 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.5519222021102905 norm:0.0004051682772114873 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:54 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.5514205694198608 norm:0.00038116704672574997 max memory_allocated 29274.43798828125 
[2025-03-02 22:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.5511581897735596 norm:0.0003556088777258992 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.5508447289466858 norm:0.00035030030994676054 max memory_allocated 29274.43798828125 
[2025-03-02 22:53:23 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.5505020022392273 norm:0.00033029820770025253 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:13 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.5502256155014038 norm:0.00032353357528336346 max memory_allocated 29274.43798828125 
[2025-03-02 22:55:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.5500074625015259 norm:0.0003194755990989506 max memory_allocated 29274.43798828125 
[2025-03-02 22:55:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.5498289465904236 norm:0.0003137911844532937 max memory_allocated 29274.43798828125 
[2025-03-02 22:56:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.5496693253517151 norm:0.0003106001822743565 max memory_allocated 29274.43798828125 
[2025-03-02 22:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.5495408177375793 norm:0.0003134759026579559 max memory_allocated 29274.43798828125 
[2025-03-02 22:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.5493816137313843 norm:0.0003079046728089452 max memory_allocated 29274.43798828125 
[2025-03-02 22:59:12 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.5492201447486877 norm:0.0003053359396290034 max memory_allocated 29274.43798828125 
[2025-03-02 23:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.5490531921386719 norm:0.0003009681822732091 max memory_allocated 29274.43798828125 
[2025-03-02 23:00:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 23:00:20 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.6734814643859863 norm:0.014512022025883198 max memory_allocated 29274.77001953125 
[2025-03-02 23:02:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.6450456976890564 norm:0.011002486571669579 max memory_allocated 29274.77001953125 
[2025-03-02 23:02:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.6196076273918152 norm:0.008259383961558342 max memory_allocated 29274.77001953125 
[2025-03-02 23:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.6141431331634521 norm:0.0069634015671908855 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.6125850677490234 norm:0.005596842151135206 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.6114767789840698 norm:0.004673929885029793 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.6107746362686157 norm:0.0043353121727705 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.6102080941200256 norm:0.0041370936669409275 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.6098316311836243 norm:0.003916015382856131 max memory_allocated 29274.77001953125 
[2025-03-02 23:08:41 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.6093746423721313 norm:0.003927136771380901 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:31 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.6087684035301208 norm:0.003633856773376465 max memory_allocated 29274.77001953125 
[2025-03-02 23:10:21 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.6082077026367188 norm:0.003443359863013029 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:11 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.6077651977539062 norm:0.0032947766594588757 max memory_allocated 29274.77001953125 
[2025-03-02 23:12:01 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.6076524257659912 norm:0.003306849393993616 max memory_allocated 29274.77001953125 
[2025-03-02 23:12:51 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.6075193881988525 norm:0.0032769390381872654 max memory_allocated 29274.77001953125 
[2025-03-02 23:13:41 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.6073612570762634 norm:0.0032770782709121704 max memory_allocated 29274.77001953125 
[2025-03-02 23:14:31 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.607204794883728 norm:0.0032116828951984644 max memory_allocated 29274.77001953125 
[2025-03-02 23:15:21 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.6070123314857483 norm:0.003241174155846238 max memory_allocated 29274.77001953125 
[2025-03-02 23:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.6068888902664185 norm:0.003078227397054434 max memory_allocated 29274.77001953125 
[2025-03-02 23:17:01 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.6067264080047607 norm:0.003055643755942583 max memory_allocated 29274.77001953125 
[2025-03-02 23:17:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:17:19 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:18:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.7736166715621948 norm:0.019738132134079933 max memory_allocated 29274.95751953125 
[2025-03-02 23:18:59 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.73561692237854 norm:0.013368990272283554 max memory_allocated 29274.95751953125 
[2025-03-02 23:19:49 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.7032448649406433 norm:0.009300126694142818 max memory_allocated 29274.95751953125 
[2025-03-02 23:20:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.6957201957702637 norm:0.009975381195545197 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.6936344504356384 norm:0.009908425621688366 max memory_allocated 29274.95751953125 
[2025-03-02 23:22:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.6919776201248169 norm:0.008398632518947124 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.6908200979232788 norm:0.007062308490276337 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.6899956464767456 norm:0.006302397232502699 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:49 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.6890961527824402 norm:0.005765985697507858 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.6886970400810242 norm:0.005693361628800631 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.6884505748748779 norm:0.0057149543426930904 max memory_allocated 29274.95751953125 
[2025-03-02 23:27:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.6882404088973999 norm:0.00554224569350481 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.6874825954437256 norm:0.005190062336623669 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:59 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.6871741414070129 norm:0.004852049518376589 max memory_allocated 29274.95751953125 
[2025-03-02 23:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.6871036887168884 norm:0.004854321014136076 max memory_allocated 29274.95751953125 
[2025-03-02 23:30:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.6870691776275635 norm:0.004701345693320036 max memory_allocated 29274.95751953125 
[2025-03-02 23:31:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.6868371367454529 norm:0.004635523073375225 max memory_allocated 29274.95751953125 
[2025-03-02 23:32:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.6869839429855347 norm:0.004731307737529278 max memory_allocated 29274.95751953125 
[2025-03-02 23:33:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.6866334676742554 norm:0.004709073808044195 max memory_allocated 29274.95751953125 
[2025-03-02 23:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.6862655282020569 norm:0.004512943793088198 max memory_allocated 29274.95751953125 
[2025-03-02 23:34:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:34:19 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.9664303660392761 norm:0.04751686006784439 max memory_allocated 29275.14501953125 
[2025-03-02 23:35:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.9179571866989136 norm:0.03382236883044243 max memory_allocated 29275.14501953125 
[2025-03-02 23:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.884819746017456 norm:0.027418438345193863 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.8668844103813171 norm:0.02352004311978817 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:29 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.85796058177948 norm:0.02012435533106327 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.8516989350318909 norm:0.016610201448202133 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:09 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.8481130599975586 norm:0.015640638768672943 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.8451806902885437 norm:0.014335647225379944 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.8429340720176697 norm:0.013860302977263927 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.8421169519424438 norm:0.012995515018701553 max memory_allocated 29275.14501953125 
[2025-03-02 23:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.8411720395088196 norm:0.012849858961999416 max memory_allocated 29275.14501953125 
[2025-03-02 23:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.8402025699615479 norm:0.01193799078464508 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.8400338292121887 norm:0.01181909441947937 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.8393235802650452 norm:0.011401906609535217 max memory_allocated 29275.14501953125 
[2025-03-02 23:46:48 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.8383580446243286 norm:0.011179791763424873 max memory_allocated 29275.14501953125 
[2025-03-02 23:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.8382142782211304 norm:0.01124588493257761 max memory_allocated 29275.14501953125 
[2025-03-02 23:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.8377950191497803 norm:0.011153909377753735 max memory_allocated 29275.14501953125 
[2025-03-02 23:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.8376625776290894 norm:0.010965967550873756 max memory_allocated 29275.14501953125 
[2025-03-02 23:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.8378093838691711 norm:0.010545503348112106 max memory_allocated 29275.14501953125 
[2025-03-02 23:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.8378825187683105 norm:0.010632366873323917 max memory_allocated 29275.14501953125 
[2025-03-02 23:51:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:51:17 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:1.4965300559997559 norm:0.060567982494831085 max memory_allocated 29275.33251953125 
[2025-03-02 23:52:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:1.4329750537872314 norm:0.037930555641651154 max memory_allocated 29275.33251953125 
[2025-03-02 23:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:1.3997406959533691 norm:0.026785511523485184 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:1.3777559995651245 norm:0.02296811155974865 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:1.3626846075057983 norm:0.02037067525088787 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:17 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:1.3523293733596802 norm:0.02509193681180477 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:1.347733497619629 norm:0.027576105669140816 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:1.3423138856887817 norm:0.027306389063596725 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:1.339432954788208 norm:0.027864625677466393 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:1.3385069370269775 norm:0.03004092164337635 max memory_allocated 29275.33251953125 
[2025-03-03 00:00:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:1.3369214534759521 norm:0.02626112662255764 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:1.3364192247390747 norm:0.02784353867173195 max memory_allocated 29275.33251953125 
[2025-03-03 00:02:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:1.334789514541626 norm:0.02758927084505558 max memory_allocated 29275.33251953125 
[2025-03-03 00:02:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:1.3322771787643433 norm:0.025563053786754608 max memory_allocated 29275.33251953125 
[2025-03-03 00:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:1.330917239189148 norm:0.025531871244311333 max memory_allocated 29275.33251953125 
[2025-03-03 00:04:36 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:1.3315743207931519 norm:0.027908090502023697 max memory_allocated 29275.33251953125 
[2025-03-03 00:05:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:1.32913339138031 norm:0.027724258601665497 max memory_allocated 29275.33251953125 
[2025-03-03 00:06:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:1.3269121646881104 norm:0.023392220959067345 max memory_allocated 29275.33251953125 
[2025-03-03 00:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:1.3248194456100464 norm:0.025049403309822083 max memory_allocated 29275.33251953125 
[2025-03-03 00:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:1.326214075088501 norm:0.02471185103058815 max memory_allocated 29275.33251953125 
[2025-03-03 00:08:11 root] (main_calib_config2.py 372): INFO 40540.28247117996
[2025-03-03 00:08:21 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:10:19 root] (main_calib_config2.py 159): INFO wikitext2 : 5.27443265914917
[2025-03-03 00:10:19 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:13:20 root] (main_calib_config2.py 159): INFO c4 : 6.836146354675293
