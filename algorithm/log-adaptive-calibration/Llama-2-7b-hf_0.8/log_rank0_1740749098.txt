[2025-02-28 13:24:58 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-7b-hf_0.8', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.8.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:25:04 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:25:05 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:25:05 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:25:05 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.8.pkl
[2025-02-28 13:25:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:25:10 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:25:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.004135809373110533 norm:0.006150030996650457 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.002276377519592643 norm:0.0033781505189836025 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0018642621580511332 norm:0.002400768920779228 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0016784342005848885 norm:0.0019967753905802965 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0015843326691538095 norm:0.0018349271267652512 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0015261704102158546 norm:0.0017423840472474694 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.001484735868871212 norm:0.001561803393997252 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0014569511404260993 norm:0.0015512699028477073 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.001429214607924223 norm:0.0013927016407251358 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0014136799145489931 norm:0.0013053218135610223 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0013918125769123435 norm:0.0012215441092848778 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.001363506424240768 norm:0.001118350657634437 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0013427973026409745 norm:0.0010863237548619509 max memory_allocated 22562.10693359375 
[2025-02-28 13:32:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0013410572428256273 norm:0.001062885974533856 max memory_allocated 22562.10693359375 
[2025-02-28 13:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0013149587903171778 norm:0.0009789642645046115 max memory_allocated 22562.10693359375 
[2025-02-28 13:33:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.001337281079031527 norm:0.0010591066675260663 max memory_allocated 22562.10693359375 
[2025-02-28 13:33:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0013047851389274001 norm:0.0008983379229903221 max memory_allocated 22562.10693359375 
[2025-02-28 13:34:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0012947509530931711 norm:0.0008554732194170356 max memory_allocated 22562.10693359375 
[2025-02-28 13:34:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0012796607334166765 norm:0.0008216318674385548 max memory_allocated 22562.10693359375 
[2025-02-28 13:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0012620999477803707 norm:0.0007409673999063671 max memory_allocated 22562.10693359375 
[2025-02-28 13:35:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:35:39 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.0258374884724617 norm:0.012876625172793865 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.01803717389702797 norm:0.01290300115942955 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.014146754518151283 norm:0.015690429136157036 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.012877026572823524 norm:0.009473005309700966 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.011984187178313732 norm:0.008337724953889847 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.01144739892333746 norm:0.008623896166682243 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.012695188634097576 norm:0.008685880340635777 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.01123381033539772 norm:0.007668440230190754 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.01093452237546444 norm:0.006715511437505484 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.011281623505055904 norm:0.0066139777190983295 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.010926111601293087 norm:0.006249823607504368 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.010886510834097862 norm:0.006308537442237139 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.010783764533698559 norm:0.006230855826288462 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.011796659789979458 norm:0.006544029340147972 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.011392409913241863 norm:0.006171870976686478 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.011390730738639832 norm:0.005923116113990545 max memory_allocated 22562.27880859375 
[2025-02-28 13:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.01068806927651167 norm:0.00588449789211154 max memory_allocated 22562.27880859375 
[2025-02-28 13:44:56 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.013273138552904129 norm:0.007881315425038338 max memory_allocated 22562.27880859375 
[2025-02-28 13:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.012644588947296143 norm:0.006668642163276672 max memory_allocated 22562.27880859375 
[2025-02-28 13:45:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.012133087031543255 norm:0.006977444514632225 max memory_allocated 22562.27880859375 
[2025-02-28 13:46:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 13:46:09 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.017762046307325363 norm:0.0068742381408810616 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.013886263594031334 norm:0.005253882147371769 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.012701401486992836 norm:0.003843493526801467 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.01198825053870678 norm:0.0031074711587280035 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.01152090448886156 norm:0.002552742836996913 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.01115078292787075 norm:0.0021292956080287695 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.010935868136584759 norm:0.0017630148213356733 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.010839163325726986 norm:0.0014495337381958961 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.010779540985822678 norm:0.0011635172413662076 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.010749390348792076 norm:0.0009701065137051046 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:50 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.010788992047309875 norm:0.0010650871554389596 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.010821133852005005 norm:0.0010805822676047683 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.01073683425784111 norm:0.0008956944802775979 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.010755984112620354 norm:0.0009182216599583626 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.010817078873515129 norm:0.0009843581356108189 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.010805952362716198 norm:0.0009327814914286137 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.010729661211371422 norm:0.0007582469843327999 max memory_allocated 22562.45068359375 
[2025-02-28 13:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.01073443703353405 norm:0.0007175515638664365 max memory_allocated 22562.45068359375 
[2025-02-28 13:55:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.010744963772594929 norm:0.0007396811852231622 max memory_allocated 22562.45068359375 
[2025-02-28 13:56:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.010751255787909031 norm:0.0007512160809710622 max memory_allocated 22562.45068359375 
[2025-02-28 13:56:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 13:57:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.020419958978891373 norm:0.0012574749998748302 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.016978351399302483 norm:0.0005328021361492574 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.015657348558306694 norm:0.00030362416873686016 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.014796197414398193 norm:0.0001982210815185681 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.014202738180756569 norm:0.00015992896805983037 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.013948631472885609 norm:0.00014627951895818114 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.013881096616387367 norm:0.00013403809862211347 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.01385568454861641 norm:0.00011594009993132204 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.013849113136529922 norm:0.00011364692909410223 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.013842828571796417 norm:0.00011494073987705633 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.013840028084814548 norm:0.00011343828373355791 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.013833165168762207 norm:0.00011340317723806947 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.01381190400570631 norm:0.00010407099034637213 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.013827812857925892 norm:0.00011333274596836418 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.013825315982103348 norm:0.00010936048784060404 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.013828731141984463 norm:0.00010797905270010233 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.013823253102600574 norm:0.00010639138054102659 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.013836358673870564 norm:0.00010410096001578495 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.01382626872509718 norm:0.00010572811879683286 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.013821418397128582 norm:0.00010110910079674795 max memory_allocated 22562.50732421875 
[2025-02-28 14:07:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:07:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.024139802902936935 norm:0.001095724175684154 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.02043093740940094 norm:0.0004617027589119971 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.01875903084874153 norm:0.0002550156495999545 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.017700349912047386 norm:0.0001695430401014164 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.017113355919718742 norm:0.00013229442993178964 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.01688106544315815 norm:0.00011670307139866054 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.01679782196879387 norm:0.00010373233817517757 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.016767537221312523 norm:0.00010294071398675442 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.01675589010119438 norm:9.908546780934557e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:15 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.016752595081925392 norm:9.502303873887286e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.016735978424549103 norm:9.658990893512964e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.016729015856981277 norm:9.498906001681462e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.01672457717359066 norm:9.5095339929685e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.016718599945306778 norm:9.567610686644912e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.01671479642391205 norm:9.668777784099802e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.01670805923640728 norm:9.301744285039604e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.0167049802839756 norm:9.651072468841448e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.01671081781387329 norm:9.815525845624506e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.01670684479176998 norm:9.514342673355713e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.016706956550478935 norm:9.754090569913387e-05 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:18:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.024482257664203644 norm:0.0008760281489230692 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.02206987328827381 norm:0.00041242525912821293 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.020773405209183693 norm:0.00025549589190632105 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.01984197460114956 norm:0.0001885576784843579 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.019163716584444046 norm:0.0001440218329662457 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.01893521286547184 norm:0.00013062701327726245 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.018900975584983826 norm:0.00017480348469689488 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.01883036457002163 norm:0.00013841793406754732 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.018784180283546448 norm:0.00013819607556797564 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.018747305497527122 norm:0.00012592699204105884 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.018714120611548424 norm:0.000137926428578794 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.018727846443653107 norm:0.0001613672502571717 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.01874261349439621 norm:0.00014707667287439108 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.018703440204262733 norm:0.0001348016521660611 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:17 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.018710725009441376 norm:0.0001360695605399087 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.018692366778850555 norm:0.00013404466153588146 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.0187201090157032 norm:0.00014631949306931347 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.018704786896705627 norm:0.00014119794650468975 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.01868899166584015 norm:0.00013558476348407567 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.018688753247261047 norm:0.00013926344399806112 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 14:28:33 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.029289042577147484 norm:0.001064402749761939 max memory_allocated 22563.02294921875 
[2025-02-28 14:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.025893986225128174 norm:0.0004884705413132906 max memory_allocated 22563.02294921875 
[2025-02-28 14:29:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.024113722145557404 norm:0.00028710957849398255 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.022852368652820587 norm:0.0001993896730709821 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.02222765050828457 norm:0.0001491997390985489 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.02195371314883232 norm:0.00012470503861550242 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.021857786923646927 norm:0.00011958245158893988 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.02180805802345276 norm:0.00011229863594053313 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.02175825834274292 norm:0.00010507054685149342 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.02173737809062004 norm:0.00010399646998848766 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.021723993122577667 norm:0.00010191296314587817 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.021699564531445503 norm:0.00010118451609741896 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.02169046923518181 norm:0.00010296818072674796 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.02168472856283188 norm:0.00010485325037734583 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:45 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.021690823137760162 norm:0.00010791808745125309 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.021680502220988274 norm:0.0001101524248952046 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.021678615361452103 norm:0.00010626907169353217 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.021673530340194702 norm:0.00010447822569403797 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.021665630862116814 norm:0.00010193297930527478 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.021657507866621017 norm:0.00010243456199532375 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 14:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.033636126667261124 norm:0.0012120235478505492 max memory_allocated 22563.19482421875 
[2025-02-28 14:39:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.02923114411532879 norm:0.0005313358269631863 max memory_allocated 22563.19482421875 
[2025-02-28 14:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.02714959904551506 norm:0.00033774515031836927 max memory_allocated 22563.19482421875 
[2025-02-28 14:40:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.02582164853811264 norm:0.00023341865744441748 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.0251801535487175 norm:0.00018123674090020359 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.02492089942097664 norm:0.00015767730656079948 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.02477048523724079 norm:0.0001313603133894503 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.024713264778256416 norm:0.00012764488928951323 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.02466629259288311 norm:0.0001222665305249393 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.024639558047056198 norm:0.00011023585102520883 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.024612033739686012 norm:0.00010651305638020858 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.024580946192145348 norm:0.00010625705908751115 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.02455371990799904 norm:0.00010584318079054356 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.02454015240073204 norm:9.761434193933383e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.024526897817850113 norm:9.854659583652392e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.024518268182873726 norm:9.598761971574277e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.024509813636541367 norm:9.680547373136505e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.02450033649802208 norm:9.929115185514092e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.02449270524084568 norm:9.710536687634885e-05 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.024501584470272064 norm:0.00010260535054840147 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 14:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.03582089766860008 norm:0.0009351560729555786 max memory_allocated 22563.36669921875 
[2025-02-28 14:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.03187451511621475 norm:0.0004907403490506113 max memory_allocated 22563.36669921875 
[2025-02-28 14:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.029872627928853035 norm:0.0003105459036305547 max memory_allocated 22563.36669921875 
[2025-02-28 14:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.02867088094353676 norm:0.00023738003801554441 max memory_allocated 22563.36669921875 
[2025-02-28 14:51:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.02795199677348137 norm:0.0001994832418859005 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.027603646740317345 norm:0.0001971764286281541 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.027464114129543304 norm:0.0001698138366919011 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.02731158398091793 norm:0.00015803243150003254 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.0272676944732666 norm:0.00016177812358364463 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.02720448188483715 norm:0.0001728304341668263 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.027175189927220345 norm:0.00016681713168509305 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.027123592793941498 norm:0.00016486254753544927 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.02709108032286167 norm:0.00016504651284776628 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.0270802341401577 norm:0.00016385101480409503 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.02705366723239422 norm:0.00015128646919038147 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.027041234076023102 norm:0.00016200169920921326 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.027025675401091576 norm:0.00016408180817961693 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.027026424184441566 norm:0.0001566865248605609 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.027012275531888008 norm:0.00014543400902766734 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:14 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.027013778686523438 norm:0.00014456850476562977 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 14:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.036973707377910614 norm:0.0008522686548531055 max memory_allocated 22563.53857421875 
[2025-02-28 15:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.033182695508003235 norm:0.00037171508301980793 max memory_allocated 22563.53857421875 
[2025-02-28 15:00:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.03147272765636444 norm:0.00023715232964605093 max memory_allocated 22563.53857421875 
[2025-02-28 15:01:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.030366763472557068 norm:0.0001800882600946352 max memory_allocated 22563.53857421875 
[2025-02-28 15:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.029711153358221054 norm:0.00017573956574779004 max memory_allocated 22563.53857421875 
[2025-02-28 15:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.029391905292868614 norm:0.00015077936404850334 max memory_allocated 22563.53857421875 
[2025-02-28 15:03:01 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.029247883707284927 norm:0.00014391930017154664 max memory_allocated 22563.53857421875 
[2025-02-28 15:03:32 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.02914608269929886 norm:0.00012936406710650772 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.029105976223945618 norm:0.00013525593385566026 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.029049260541796684 norm:0.0001268437918042764 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.029040014371275902 norm:0.00012948134099133313 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.02899124287068844 norm:0.00012395772500894964 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:06 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.0289992094039917 norm:0.00013210813631303608 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.028967179358005524 norm:0.00012252884334884584 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.02894686348736286 norm:0.0001272406370844692 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.02895670384168625 norm:0.0001267236948478967 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.028947407379746437 norm:0.00012410794442985207 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.02894921973347664 norm:0.00012625842646230012 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.02893788553774357 norm:0.00012549347593449056 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.028943242505192757 norm:0.00011903262929990888 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 15:10:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.036614008247852325 norm:0.0005109227495267987 max memory_allocated 22563.71044921875 
[2025-02-28 15:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.03427552059292793 norm:0.0002718595787882805 max memory_allocated 22563.71044921875 
[2025-02-28 15:11:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.03283882886171341 norm:0.00018683477537706494 max memory_allocated 22563.71044921875 
[2025-02-28 15:11:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.031853340566158295 norm:0.00016755657270550728 max memory_allocated 22563.71044921875 
[2025-02-28 15:12:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.03120334818959236 norm:0.00015286584675777704 max memory_allocated 22563.71044921875 
[2025-02-28 15:12:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.030930321663618088 norm:0.0001475607859902084 max memory_allocated 22563.71044921875 
[2025-02-28 15:13:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.030732037499547005 norm:0.00012749593588523567 max memory_allocated 22563.71044921875 
[2025-02-28 15:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.030651921406388283 norm:0.00012687496200669557 max memory_allocated 22563.71044921875 
[2025-02-28 15:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.030604315921664238 norm:0.00012587328092195094 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.030552545562386513 norm:0.00012698315549641848 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.03051573783159256 norm:0.00011635422561084852 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.0305094663053751 norm:0.00011830941366497427 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.030498333275318146 norm:0.00011778562475228682 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.0305455531924963 norm:0.00013284172746352851 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.03051764704287052 norm:0.00011529018956935033 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.030500415712594986 norm:0.00011220917076570913 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.030504826456308365 norm:0.00012061756569892168 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.030490119010210037 norm:0.00011980331328231841 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.030490871518850327 norm:0.00012722295650746673 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.030478429049253464 norm:0.00012100052845198661 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 15:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.03943503648042679 norm:0.000663487589918077 max memory_allocated 22563.88232421875 
[2025-02-28 15:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.03631018102169037 norm:0.0003444183384999633 max memory_allocated 22563.88232421875 
[2025-02-28 15:21:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.03462676703929901 norm:0.00023824053641874343 max memory_allocated 22563.88232421875 
[2025-02-28 15:22:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.0335661843419075 norm:0.00020376262546051294 max memory_allocated 22563.88232421875 
[2025-02-28 15:22:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.03287426009774208 norm:0.00017534701328258961 max memory_allocated 22563.88232421875 
[2025-02-28 15:23:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.032493382692337036 norm:0.00015971592802088708 max memory_allocated 22563.88232421875 
[2025-02-28 15:23:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.03233761712908745 norm:0.0001607114536454901 max memory_allocated 22563.88232421875 
[2025-02-28 15:24:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.032233014702796936 norm:0.00014850104344077408 max memory_allocated 22563.88232421875 
[2025-02-28 15:24:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.03215703368186951 norm:0.00014699094754178077 max memory_allocated 22563.88232421875 
[2025-02-28 15:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.032087378203868866 norm:0.0001325220800936222 max memory_allocated 22563.88232421875 
[2025-02-28 15:26:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.03205504268407822 norm:0.00012542353942990303 max memory_allocated 22563.88232421875 
[2025-02-28 15:26:31 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.032010503113269806 norm:0.00012311589671298862 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.03196434676647186 norm:0.0001196731100208126 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.0319487489759922 norm:0.00011272336996626109 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.031938306987285614 norm:0.00011727451055776328 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.03192981332540512 norm:0.00011889676534337923 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.031910449266433716 norm:0.0001129767406382598 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.03191307187080383 norm:0.00011325691593810916 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.03191329911351204 norm:0.0001171557159977965 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.03190124034881592 norm:0.00011465859279269353 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 15:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.03947284072637558 norm:0.0005529500776901841 max memory_allocated 22564.05419921875 
[2025-02-28 15:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.036901071667671204 norm:0.00029665438341908157 max memory_allocated 22564.05419921875 
[2025-02-28 15:32:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.03551648184657097 norm:0.00021243320952635258 max memory_allocated 22564.05419921875 
[2025-02-28 15:32:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.03450305014848709 norm:0.0001757898135110736 max memory_allocated 22564.05419921875 
[2025-02-28 15:33:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.03394271060824394 norm:0.00015682782395742834 max memory_allocated 22564.05419921875 
[2025-02-28 15:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.033579885959625244 norm:0.0001422798086423427 max memory_allocated 22564.05419921875 
[2025-02-28 15:34:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.033419981598854065 norm:0.00012943163164891303 max memory_allocated 22564.05419921875 
[2025-02-28 15:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.03334716707468033 norm:0.00012575641449075192 max memory_allocated 22564.05419921875 
[2025-02-28 15:35:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.03325141221284866 norm:0.00012180345947854221 max memory_allocated 22564.05419921875 
[2025-02-28 15:35:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.03322187811136246 norm:0.00013177358778193593 max memory_allocated 22564.05419921875 
[2025-02-28 15:36:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.03320132941007614 norm:0.000134098285343498 max memory_allocated 22564.05419921875 
[2025-02-28 15:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.03311840817332268 norm:0.0001125206399592571 max memory_allocated 22564.05419921875 
[2025-02-28 15:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.03312422335147858 norm:0.00011603238817770034 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.03309149667620659 norm:0.00011181710578966886 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.03307206556200981 norm:0.00011103421275038272 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.03305584564805031 norm:0.00011160478607052937 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.03304808586835861 norm:0.00011023343540728092 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.03304662927985191 norm:0.00010715072858147323 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.033046383410692215 norm:9.973242413252592e-05 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.03303208202123642 norm:0.00010702131112338975 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 15:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.03896084427833557 norm:0.0007122139795683324 max memory_allocated 22564.22607421875 
[2025-02-28 15:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.03666113689541817 norm:0.00035800994373857975 max memory_allocated 22564.22607421875 
[2025-02-28 15:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.03520544618368149 norm:0.0002354977623326704 max memory_allocated 22564.22607421875 
[2025-02-28 15:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.034258291125297546 norm:0.00018151049152947962 max memory_allocated 22564.22607421875 
[2025-02-28 15:43:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.033679887652397156 norm:0.00015022935986053199 max memory_allocated 22564.22607421875 
[2025-02-28 15:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.0333433672785759 norm:0.00013473289436660707 max memory_allocated 22564.22607421875 
[2025-02-28 15:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.03318861871957779 norm:0.00012509322550613433 max memory_allocated 22564.22607421875 
[2025-02-28 15:45:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.03307913616299629 norm:0.00011792813893407583 max memory_allocated 22564.22607421875 
[2025-02-28 15:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.03299330919981003 norm:0.00010910286073340103 max memory_allocated 22564.22607421875 
[2025-02-28 15:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.03296419233083725 norm:0.0001061695147654973 max memory_allocated 22564.22607421875 
[2025-02-28 15:46:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.0329413041472435 norm:0.00010677352838683873 max memory_allocated 22564.22607421875 
[2025-02-28 15:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.032912950962781906 norm:0.00010864606883842498 max memory_allocated 22564.22607421875 
[2025-02-28 15:47:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.03288552165031433 norm:0.0001034814486047253 max memory_allocated 22564.22607421875 
[2025-02-28 15:48:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.03285869583487511 norm:0.00010277819819748402 max memory_allocated 22564.22607421875 
[2025-02-28 15:49:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.03284693881869316 norm:0.00010537014168221503 max memory_allocated 22564.22607421875 
[2025-02-28 15:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.03284376114606857 norm:0.00010363248293288052 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.03283735737204552 norm:0.00010470510460436344 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.03283236548304558 norm:0.00010742314043454826 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.032818421721458435 norm:9.759113163454458e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.032797276973724365 norm:9.604405204299837e-05 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 15:52:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.039127711206674576 norm:0.0005324234953150153 max memory_allocated 22564.39794921875 
[2025-02-28 15:52:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.03692631050944328 norm:0.0002848384319804609 max memory_allocated 22564.39794921875 
[2025-02-28 15:53:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.03566339612007141 norm:0.00020406043040566146 max memory_allocated 22564.39794921875 
[2025-02-28 15:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.0347505584359169 norm:0.00016458523168694228 max memory_allocated 22564.39794921875 
[2025-02-28 15:54:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.03416353091597557 norm:0.0001400654437020421 max memory_allocated 22564.39794921875 
[2025-02-28 15:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.03383166342973709 norm:0.00012248272832948714 max memory_allocated 22564.39794921875 
[2025-02-28 15:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.033669836819171906 norm:0.0001167118243756704 max memory_allocated 22564.39794921875 
[2025-02-28 15:55:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.033555012196302414 norm:0.00011457092477940023 max memory_allocated 22564.39794921875 
[2025-02-28 15:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.0334797129034996 norm:0.00011121560237370431 max memory_allocated 22564.39794921875 
[2025-02-28 15:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.03340420871973038 norm:0.00010325237235520035 max memory_allocated 22564.39794921875 
[2025-02-28 15:57:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.03336413949728012 norm:9.567492816131562e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:57:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.033337581902742386 norm:9.60452962317504e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.033334650099277496 norm:9.75656439550221e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.03331667557358742 norm:9.404519369127229e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.03329472988843918 norm:8.521035488229245e-05 max memory_allocated 22564.39794921875 
[2025-02-28 15:59:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.03328237310051918 norm:8.167144551407546e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:00:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.03327856957912445 norm:8.239595626946539e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.03326984494924545 norm:8.624999463791028e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.03327073156833649 norm:7.99187837401405e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.033255934715270996 norm:8.078494283836335e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 16:02:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.041732057929039 norm:0.0008904517162591219 max memory_allocated 22564.56982421875 
[2025-02-28 16:03:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.038306184113025665 norm:0.00037191080627962947 max memory_allocated 22564.56982421875 
[2025-02-28 16:03:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.036461059004068375 norm:0.00023722884361632168 max memory_allocated 22564.56982421875 
[2025-02-28 16:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.0353672094643116 norm:0.00017170322826132178 max memory_allocated 22564.56982421875 
[2025-02-28 16:04:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.034776389598846436 norm:0.00013897572353016585 max memory_allocated 22564.56982421875 
[2025-02-28 16:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.03446732088923454 norm:0.0001297331036766991 max memory_allocated 22564.56982421875 
[2025-02-28 16:05:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.03430512174963951 norm:0.0001197175879497081 max memory_allocated 22564.56982421875 
[2025-02-28 16:06:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.034207262098789215 norm:0.00011036968498956412 max memory_allocated 22564.56982421875 
[2025-02-28 16:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.03413919731974602 norm:0.00010237033711746335 max memory_allocated 22564.56982421875 
[2025-02-28 16:07:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.03409101068973541 norm:0.00010029903933173046 max memory_allocated 22564.56982421875 
[2025-02-28 16:07:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.034036897122859955 norm:0.00010123303218279034 max memory_allocated 22564.56982421875 
[2025-02-28 16:08:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.03399338200688362 norm:9.774084173841402e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:08:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.033955156803131104 norm:9.06655186554417e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.03393251821398735 norm:8.892297046259046e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:09:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.03390604630112648 norm:8.71198863023892e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:10:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.03387586772441864 norm:8.327546674991027e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.03385503962635994 norm:8.168435306288302e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:11:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.03384636342525482 norm:7.946164259919897e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.03383861109614372 norm:7.636738882865757e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.03382212668657303 norm:7.48096063034609e-05 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 16:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.042589928954839706 norm:0.00108356773853302 max memory_allocated 22564.74169921875 
[2025-02-28 16:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.03888897970318794 norm:0.0004323431639932096 max memory_allocated 22564.74169921875 
[2025-02-28 16:14:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.03700486570596695 norm:0.0002457835653331131 max memory_allocated 22564.74169921875 
[2025-02-28 16:14:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.03591696918010712 norm:0.00018193900177720934 max memory_allocated 22564.74169921875 
[2025-02-28 16:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.035294804722070694 norm:0.00015031910152174532 max memory_allocated 22564.74169921875 
[2025-02-28 16:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.034941717982292175 norm:0.00013662275159731507 max memory_allocated 22564.74169921875 
[2025-02-28 16:16:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.03475777804851532 norm:0.00012802467972505838 max memory_allocated 22564.74169921875 
[2025-02-28 16:16:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.03464459255337715 norm:0.00011850573355332017 max memory_allocated 22564.74169921875 
[2025-02-28 16:17:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.03457006439566612 norm:0.00011115482629975304 max memory_allocated 22564.74169921875 
[2025-02-28 16:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.03452056273818016 norm:0.0001061680814018473 max memory_allocated 22564.74169921875 
[2025-02-28 16:18:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.03446381166577339 norm:9.905682236421853e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.03441082686185837 norm:9.580620826454833e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:19:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.03437589854001999 norm:9.536667494103312e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:19:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.034345872700214386 norm:9.486345516052097e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:20:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.0343036986887455 norm:9.32887924136594e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:20:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.034275300800800323 norm:8.681822509970516e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:21:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.034245338290929794 norm:8.135024108923972e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:21:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.034227676689624786 norm:8.513099601259455e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:22:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.03420314937829971 norm:8.385494584217668e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.034197378903627396 norm:7.549009751528502e-05 max memory_allocated 22564.74169921875 
[2025-02-28 16:23:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 16:23:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.03925461322069168 norm:0.0005805076216347516 max memory_allocated 22564.91357421875 
[2025-02-28 16:24:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.03746649622917175 norm:0.00020011089509353042 max memory_allocated 22564.91357421875 
[2025-02-28 16:24:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.03656040504574776 norm:0.0001417749881511554 max memory_allocated 22564.91357421875 
[2025-02-28 16:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.03582305461168289 norm:0.00013005144137423486 max memory_allocated 22564.91357421875 
[2025-02-28 16:25:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.03523378446698189 norm:0.00011309948604321107 max memory_allocated 22564.91357421875 
[2025-02-28 16:26:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.034905508160591125 norm:9.388677426613867e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:26:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.03478166088461876 norm:8.848169818520546e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:27:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.03467555716633797 norm:8.974639786174521e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.034602656960487366 norm:8.2413200289011e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:28:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.034563228487968445 norm:7.654885848751292e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:28:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.03453180938959122 norm:7.002548954915255e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.03450018912553787 norm:7.395895954687148e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:29:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.03445667028427124 norm:6.491186650237069e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:30:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.034432683140039444 norm:6.829295307397842e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:30:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.034427110105752945 norm:6.497088179457933e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.03441677242517471 norm:6.235919863684103e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:31:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.034420520067214966 norm:6.539899914059788e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.03442884981632233 norm:7.027198444120586e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:32:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.034400638192892075 norm:6.32393202977255e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.03440035507082939 norm:6.582913192687556e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:33:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 16:34:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.042361874133348465 norm:0.0007259988924488425 max memory_allocated 22565.08544921875 
[2025-02-28 16:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.04037093371152878 norm:0.00034798082197085023 max memory_allocated 22565.08544921875 
[2025-02-28 16:35:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.03932821378111839 norm:0.0002235889551229775 max memory_allocated 22565.08544921875 
[2025-02-28 16:35:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.038382358849048615 norm:0.0001672493090154603 max memory_allocated 22565.08544921875 
[2025-02-28 16:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.03771939501166344 norm:0.00013552280142903328 max memory_allocated 22565.08544921875 
[2025-02-28 16:36:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.03737481310963631 norm:0.0001206171145895496 max memory_allocated 22565.08544921875 
[2025-02-28 16:37:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.037226203829050064 norm:9.986753866542131e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.037148989737033844 norm:9.420644346391782e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:38:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.03709077462553978 norm:8.634647383587435e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.037052784115076065 norm:8.238876034738496e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:39:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.037016239017248154 norm:8.174855611287057e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.03698352351784706 norm:7.795004057697952e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.036942627280950546 norm:7.566346175735816e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.036919016391038895 norm:7.063527300488204e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:41:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.036899928003549576 norm:7.17911243555136e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.03688090294599533 norm:7.042950892355293e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.03685470670461655 norm:6.664457760052755e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.036841291934251785 norm:6.418077828129753e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.03683030605316162 norm:6.289393058978021e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:43:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.03683268278837204 norm:6.391950591932982e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:44:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 16:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.045569878071546555 norm:0.0008051273180171847 max memory_allocated 22565.25732421875 
[2025-02-28 16:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.04354752600193024 norm:0.00035791355185210705 max memory_allocated 22565.25732421875 
[2025-02-28 16:45:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.04236966744065285 norm:0.00020875068730674684 max memory_allocated 22565.25732421875 
[2025-02-28 16:46:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.04147366061806679 norm:0.00015332170005422086 max memory_allocated 22565.25732421875 
[2025-02-28 16:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.04080444574356079 norm:0.0001238805562024936 max memory_allocated 22565.25732421875 
[2025-02-28 16:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.040478043258190155 norm:0.00010469619883224368 max memory_allocated 22565.25732421875 
[2025-02-28 16:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.0403662770986557 norm:9.72950947470963e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:48:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.040313638746738434 norm:9.176194726023823e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:48:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.04026343300938606 norm:8.170987712219357e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:49:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.04022305831313133 norm:7.235737575683743e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.04019324481487274 norm:7.928109698696062e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.04016907140612602 norm:7.609656313434243e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:50:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.04015122726559639 norm:7.084185199346393e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:51:18 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.040133316069841385 norm:6.74378898111172e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.04011080414056778 norm:6.903427856741473e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:52:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.04008195921778679 norm:6.403278530342504e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:52:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.04005768895149231 norm:6.088391091907397e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:53:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.040046945214271545 norm:6.0578458942472935e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.040036074817180634 norm:5.9164289268665016e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.04002465680241585 norm:5.6225610023830086e-05 max memory_allocated 22565.25732421875 
[2025-02-28 16:54:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 16:55:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.050916384905576706 norm:0.0011896522482857108 max memory_allocated 22565.42919921875 
[2025-02-28 16:55:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.04808975011110306 norm:0.0004682412836700678 max memory_allocated 22565.42919921875 
[2025-02-28 16:56:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.04664445295929909 norm:0.0002455966314300895 max memory_allocated 22565.42919921875 
[2025-02-28 16:56:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.045723892748355865 norm:0.0001765271445037797 max memory_allocated 22565.42919921875 
[2025-02-28 16:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.04500262811779976 norm:0.0001415425504092127 max memory_allocated 22565.42919921875 
[2025-02-28 16:57:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.044638995081186295 norm:0.00012886110926046968 max memory_allocated 22565.42919921875 
[2025-02-28 16:58:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.04449485242366791 norm:0.00011722586350515485 max memory_allocated 22565.42919921875 
[2025-02-28 16:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.044411204755306244 norm:0.00011315591837046668 max memory_allocated 22565.42919921875 
[2025-02-28 16:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.04434231296181679 norm:0.00010685029701562598 max memory_allocated 22565.42919921875 
[2025-02-28 16:59:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.044292155653238297 norm:9.934518311638385e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:00:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.04425309598445892 norm:9.343554120277986e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:00:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.04422175884246826 norm:9.095871064346284e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:01:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.04418577253818512 norm:8.865122799761593e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:01:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.04416109248995781 norm:9.236686310032383e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:02:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.04413160681724548 norm:8.728662942303345e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.044110007584095 norm:8.209333464037627e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:03:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.04408752918243408 norm:7.60029797675088e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:03:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.04407055303454399 norm:7.423006900353357e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.04406234622001648 norm:7.960505172377452e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:04:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.04404280334711075 norm:7.833580457372591e-05 max memory_allocated 22565.42919921875 
[2025-02-28 17:04:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 17:05:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.05498300865292549 norm:0.0017434274777770042 max memory_allocated 22565.60107421875 
[2025-02-28 17:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.051940351724624634 norm:0.0005160524742677808 max memory_allocated 22565.60107421875 
[2025-02-28 17:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.05059491842985153 norm:0.00023867140407674015 max memory_allocated 22565.60107421875 
[2025-02-28 17:07:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.04981037229299545 norm:0.00019148801220580935 max memory_allocated 22565.60107421875 
[2025-02-28 17:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.04924092814326286 norm:0.00016965638496913016 max memory_allocated 22565.60107421875 
[2025-02-28 17:08:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.04893783852458 norm:0.00016356822743546218 max memory_allocated 22565.60107421875 
[2025-02-28 17:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.04879222437739372 norm:0.00013985853001940995 max memory_allocated 22565.60107421875 
[2025-02-28 17:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.04871809482574463 norm:0.00012877692643087357 max memory_allocated 22565.60107421875 
[2025-02-28 17:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.04867810755968094 norm:0.0001052898951456882 max memory_allocated 22565.60107421875 
[2025-02-28 17:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.048623960465192795 norm:0.00010094005119754001 max memory_allocated 22565.60107421875 
[2025-02-28 17:10:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.04859105870127678 norm:0.00010025616211351007 max memory_allocated 22565.60107421875 
[2025-02-28 17:11:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.048562467098236084 norm:9.361180127598345e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:11:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.04854732006788254 norm:8.78786449902691e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.048523709177970886 norm:8.682823681738228e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:12:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.04850196838378906 norm:8.523810538463295e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:13:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.048495642840862274 norm:8.137223630910739e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.04847545921802521 norm:8.09676930657588e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:14:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.04844776913523674 norm:7.485663081752136e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:14:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.048443421721458435 norm:7.241139974212274e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:15:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.048444487154483795 norm:7.238354010041803e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:15:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 17:16:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.061862021684646606 norm:0.0007234935183078051 max memory_allocated 22565.77294921875 
[2025-02-28 17:16:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.059469882398843765 norm:0.0005577822448685765 max memory_allocated 22565.77294921875 
[2025-02-28 17:17:02 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.058284685015678406 norm:0.00019510550191625953 max memory_allocated 22565.77294921875 
[2025-02-28 17:17:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.057247649878263474 norm:0.00017151725478470325 max memory_allocated 22565.77294921875 
[2025-02-28 17:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.05643207207322121 norm:0.00014567820471711457 max memory_allocated 22565.77294921875 
[2025-02-28 17:18:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.056078117340803146 norm:0.00012809032341465354 max memory_allocated 22565.77294921875 
[2025-02-28 17:19:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.05595925822854042 norm:0.00011451502359705046 max memory_allocated 22565.77294921875 
[2025-02-28 17:19:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.055900972336530685 norm:0.0001060393187799491 max memory_allocated 22565.77294921875 
[2025-02-28 17:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.055854491889476776 norm:0.00010333027603337541 max memory_allocated 22565.77294921875 
[2025-02-28 17:20:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.055795781314373016 norm:0.0001007595201372169 max memory_allocated 22565.77294921875 
[2025-02-28 17:21:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.055756792426109314 norm:9.458641579840332e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.05571923404932022 norm:9.13853436941281e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:22:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.055695392191410065 norm:9.406786557519808e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.055660516023635864 norm:9.060431329999119e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.05562780052423477 norm:8.524618169758469e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:23:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.05559882894158363 norm:8.353321754839271e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.05557942017912865 norm:8.292257552966475e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.05556093528866768 norm:8.194626570912078e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:25:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.05554087832570076 norm:7.79108377173543e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.055525392293930054 norm:8.27732656034641e-05 max memory_allocated 22565.77294921875 
[2025-02-28 17:25:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 17:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.06882815808057785 norm:0.0007829449605196714 max memory_allocated 22565.94482421875 
[2025-02-28 17:26:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.06702995300292969 norm:0.0004382463521324098 max memory_allocated 22565.94482421875 
[2025-02-28 17:27:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.06591702252626419 norm:0.00030260608764365315 max memory_allocated 22565.94482421875 
[2025-02-28 17:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.06475882232189178 norm:0.00022506495588459074 max memory_allocated 22565.94482421875 
[2025-02-28 17:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.06388715654611588 norm:0.00016642628179397434 max memory_allocated 22565.94482421875 
[2025-02-28 17:29:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.0636131688952446 norm:0.00013234707876108587 max memory_allocated 22565.94482421875 
[2025-02-28 17:29:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.06351965665817261 norm:0.00011776813335018232 max memory_allocated 22565.94482421875 
[2025-02-28 17:30:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.06345444917678833 norm:0.00010548980935709551 max memory_allocated 22565.94482421875 
[2025-02-28 17:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.06340517848730087 norm:9.54835704760626e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:31:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.06335306167602539 norm:9.325117571279407e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:31:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.06330843269824982 norm:8.657268335809931e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:32:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.06327463686466217 norm:8.08560725999996e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.06324924528598785 norm:7.845943764550611e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:33:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.06322970986366272 norm:8.009411976672709e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:33:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.06321199983358383 norm:7.051201828289777e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:34:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.06319991499185562 norm:7.10336389602162e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:34:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.06319520622491837 norm:7.526647095801309e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:35:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.06317965686321259 norm:6.660573853878304e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.06316833198070526 norm:6.673899770248681e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:36:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.06316171586513519 norm:6.428773485822603e-05 max memory_allocated 22565.94482421875 
[2025-02-28 17:36:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 17:36:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.07834992557764053 norm:0.0007669649785384536 max memory_allocated 22566.11669921875 
[2025-02-28 17:37:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.07605060189962387 norm:0.00036659292527474463 max memory_allocated 22566.11669921875 
[2025-02-28 17:37:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.07471519708633423 norm:0.0002547488547861576 max memory_allocated 22566.11669921875 
[2025-02-28 17:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.07345127314329147 norm:0.00018431269563734531 max memory_allocated 22566.11669921875 
[2025-02-28 17:38:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.07254718244075775 norm:0.0001546134299132973 max memory_allocated 22566.11669921875 
[2025-02-28 17:39:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.07230189442634583 norm:0.000145905782119371 max memory_allocated 22566.11669921875 
[2025-02-28 17:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.07221188396215439 norm:0.0001254484086530283 max memory_allocated 22566.11669921875 
[2025-02-28 17:40:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.07213655114173889 norm:0.00012149074609624222 max memory_allocated 22566.11669921875 
[2025-02-28 17:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.07205745577812195 norm:0.00012182367936475202 max memory_allocated 22566.11669921875 
[2025-02-28 17:41:33 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.0719919353723526 norm:0.00011260663450229913 max memory_allocated 22566.11669921875 
[2025-02-28 17:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.0719466507434845 norm:0.00011040561366826296 max memory_allocated 22566.11669921875 
[2025-02-28 17:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.07190030813217163 norm:0.00010144204134121537 max memory_allocated 22566.11669921875 
[2025-02-28 17:43:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.07187344878911972 norm:9.920501179294661e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:43:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.07184065878391266 norm:9.806158777792007e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:44:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.0718071311712265 norm:9.501031308900565e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.07178248465061188 norm:9.375683293910697e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.07175210118293762 norm:9.300848614657298e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:45:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.07174745202064514 norm:9.846121247392148e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:46:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.07172378152608871 norm:9.474183025304228e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:46:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.07169616222381592 norm:8.898907253751531e-05 max memory_allocated 22566.11669921875 
[2025-02-28 17:46:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 17:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.08973664045333862 norm:0.0006718755466863513 max memory_allocated 22566.28857421875 
[2025-02-28 17:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.08758042007684708 norm:0.0003603750665206462 max memory_allocated 22566.28857421875 
[2025-02-28 17:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.08587198704481125 norm:0.00025650556199252605 max memory_allocated 22566.28857421875 
[2025-02-28 17:48:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.0844227746129036 norm:0.0002073074138024822 max memory_allocated 22566.28857421875 
[2025-02-28 17:49:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.08352478593587875 norm:0.00018114405975211412 max memory_allocated 22566.28857421875 
[2025-02-28 17:49:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.08328287303447723 norm:0.00016849051462486386 max memory_allocated 22566.28857421875 
[2025-02-28 17:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.0831661969423294 norm:0.00015025735774543136 max memory_allocated 22566.28857421875 
[2025-02-28 17:51:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.0831136703491211 norm:0.00014775576710235327 max memory_allocated 22566.28857421875 
[2025-02-28 17:51:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.08300359547138214 norm:0.0001323785982094705 max memory_allocated 22566.28857421875 
[2025-02-28 17:52:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.08294051885604858 norm:0.0001242328726220876 max memory_allocated 22566.28857421875 
[2025-02-28 17:52:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.08289346843957901 norm:0.00012153173884144053 max memory_allocated 22566.28857421875 
[2025-02-28 17:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.08284051716327667 norm:0.00011492156772874296 max memory_allocated 22566.28857421875 
[2025-02-28 17:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.08279532194137573 norm:0.00011752497812267393 max memory_allocated 22566.28857421875 
[2025-02-28 17:54:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.08275996893644333 norm:0.00011384840036043897 max memory_allocated 22566.28857421875 
[2025-02-28 17:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.08272405713796616 norm:0.00010789121733978391 max memory_allocated 22566.28857421875 
[2025-02-28 17:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.08270218968391418 norm:0.00010954962635878474 max memory_allocated 22566.28857421875 
[2025-02-28 17:55:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.08267706632614136 norm:0.00010740531433839351 max memory_allocated 22566.28857421875 
[2025-02-28 17:56:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.08266027271747589 norm:0.00010061507055070251 max memory_allocated 22566.28857421875 
[2025-02-28 17:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.08263539522886276 norm:0.00010278104309691116 max memory_allocated 22566.28857421875 
[2025-02-28 17:57:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.08263561129570007 norm:9.91630950011313e-05 max memory_allocated 22566.28857421875 
[2025-02-28 17:57:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 17:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.10165418684482574 norm:0.0009391958592459559 max memory_allocated 22566.46044921875 
[2025-02-28 17:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.09904757887125015 norm:0.00047643689322285354 max memory_allocated 22566.46044921875 
[2025-02-28 17:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.09738955646753311 norm:0.000322854844853282 max memory_allocated 22566.46044921875 
[2025-02-28 17:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.09592434018850327 norm:0.0002523771836422384 max memory_allocated 22566.46044921875 
[2025-02-28 18:00:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.0950550064444542 norm:0.00020808364206459373 max memory_allocated 22566.46044921875 
[2025-02-28 18:00:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.09478021413087845 norm:0.00017786090029403567 max memory_allocated 22566.46044921875 
[2025-02-28 18:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.09461026638746262 norm:0.0001613071362953633 max memory_allocated 22566.46044921875 
[2025-02-28 18:01:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.09445972740650177 norm:0.0001536466006655246 max memory_allocated 22566.46044921875 
[2025-02-28 18:02:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.0943833589553833 norm:0.00014760068734176457 max memory_allocated 22566.46044921875 
[2025-02-28 18:02:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.09430435299873352 norm:0.00013910490088164806 max memory_allocated 22566.46044921875 
[2025-02-28 18:03:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.09426271915435791 norm:0.00012970455281902105 max memory_allocated 22566.46044921875 
[2025-02-28 18:03:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.09418631345033646 norm:0.0001220762642333284 max memory_allocated 22566.46044921875 
[2025-02-28 18:04:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.09415965527296066 norm:0.0001182979394798167 max memory_allocated 22566.46044921875 
[2025-02-28 18:04:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.09410547465085983 norm:0.00012031431833747774 max memory_allocated 22566.46044921875 
[2025-02-28 18:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.09407377243041992 norm:0.00011572211951715872 max memory_allocated 22566.46044921875 
[2025-02-28 18:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.0940294936299324 norm:0.00011910135071957484 max memory_allocated 22566.46044921875 
[2025-02-28 18:06:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.09400935471057892 norm:0.00011205783084733412 max memory_allocated 22566.46044921875 
[2025-02-28 18:06:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.09400393068790436 norm:0.00011285270738881081 max memory_allocated 22566.46044921875 
[2025-02-28 18:07:12 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.09398219734430313 norm:0.00010464125807629898 max memory_allocated 22566.46044921875 
[2025-02-28 18:07:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.0939660295844078 norm:0.00010084777750307694 max memory_allocated 22566.46044921875 
[2025-02-28 18:07:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 18:08:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.11546783149242401 norm:0.0007649957551620901 max memory_allocated 22566.63232421875 
[2025-02-28 18:08:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.11295254528522491 norm:0.00040390455978922546 max memory_allocated 22566.63232421875 
[2025-02-28 18:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.11117957532405853 norm:0.0002738476323429495 max memory_allocated 22566.63232421875 
[2025-02-28 18:09:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.10948818176984787 norm:0.00020567422325257212 max memory_allocated 22566.63232421875 
[2025-02-28 18:10:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.10878483206033707 norm:0.0001685484021436423 max memory_allocated 22566.63232421875 
[2025-02-28 18:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.10862941294908524 norm:0.00015444996824953705 max memory_allocated 22566.63232421875 
[2025-02-28 18:11:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.10853739082813263 norm:0.00013743084855377674 max memory_allocated 22566.63232421875 
[2025-02-28 18:12:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.10846158117055893 norm:0.00013120293442625552 max memory_allocated 22566.63232421875 
[2025-02-28 18:12:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.10839644074440002 norm:0.00011923330021090806 max memory_allocated 22566.63232421875 
[2025-02-28 18:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.10835078358650208 norm:0.00011420901864767075 max memory_allocated 22566.63232421875 
[2025-02-28 18:13:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.10831164568662643 norm:0.00010887884127441794 max memory_allocated 22566.63232421875 
[2025-02-28 18:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.10828235745429993 norm:0.00010628750897012651 max memory_allocated 22566.63232421875 
[2025-02-28 18:14:35 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.10825284570455551 norm:0.00010457630560267717 max memory_allocated 22566.63232421875 
[2025-02-28 18:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.10823195427656174 norm:0.0001007228420348838 max memory_allocated 22566.63232421875 
[2025-02-28 18:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.10820318758487701 norm:9.982494520954788e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:16:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.10817723721265793 norm:9.674416651250795e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:16:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.10816272348165512 norm:9.346930892206728e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:17:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.10815482586622238 norm:9.369202598463744e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.10814548283815384 norm:9.49912573560141e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.10813659429550171 norm:9.161067282548174e-05 max memory_allocated 22566.63232421875 
[2025-02-28 18:18:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 18:18:22 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:18:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.1332242339849472 norm:0.004166067112237215 max memory_allocated 22566.91943359375 
[2025-02-28 18:19:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.1306411325931549 norm:0.003272737842053175 max memory_allocated 22566.91943359375 
[2025-02-28 18:19:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.12859784066677094 norm:0.0027500702999532223 max memory_allocated 22566.91943359375 
[2025-02-28 18:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.12675029039382935 norm:0.002318211365491152 max memory_allocated 22566.91943359375 
[2025-02-28 18:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.12603145837783813 norm:0.0018930936930701137 max memory_allocated 22566.91943359375 
[2025-02-28 18:21:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.1257621943950653 norm:0.0016116737388074398 max memory_allocated 22566.91943359375 
[2025-02-28 18:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.12557952105998993 norm:0.001495039090514183 max memory_allocated 22566.91943359375 
[2025-02-28 18:22:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.12559248507022858 norm:0.001520174671895802 max memory_allocated 22566.91943359375 
[2025-02-28 18:23:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.1255030632019043 norm:0.0014969308394938707 max memory_allocated 22566.91943359375 
[2025-02-28 18:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.12543106079101562 norm:0.0012942524626851082 max memory_allocated 22566.91943359375 
[2025-02-28 18:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.12530109286308289 norm:0.0013759604189544916 max memory_allocated 22566.91943359375 
[2025-02-28 18:24:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.1253419667482376 norm:0.0012313851621001959 max memory_allocated 22566.91943359375 
[2025-02-28 18:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.12530723214149475 norm:0.0013282221043482423 max memory_allocated 22566.91943359375 
[2025-02-28 18:25:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.1252540946006775 norm:0.001171061652712524 max memory_allocated 22566.91943359375 
[2025-02-28 18:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.12518349289894104 norm:0.001194344717077911 max memory_allocated 22566.91943359375 
[2025-02-28 18:26:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.1251334547996521 norm:0.0011623925529420376 max memory_allocated 22566.91943359375 
[2025-02-28 18:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.12513771653175354 norm:0.0011136638931930065 max memory_allocated 22566.91943359375 
[2025-02-28 18:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.12507681548595428 norm:0.001117073930799961 max memory_allocated 22566.91943359375 
[2025-02-28 18:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.125108540058136 norm:0.0011045850114896894 max memory_allocated 22566.91943359375 
[2025-02-28 18:28:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.12507954239845276 norm:0.0011088872561231256 max memory_allocated 22566.91943359375 
[2025-02-28 18:28:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 18:28:52 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:29:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.16202791035175323 norm:0.005822863429784775 max memory_allocated 22567.09130859375 
[2025-02-28 18:29:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.15548203885555267 norm:0.004452548921108246 max memory_allocated 22567.09130859375 
[2025-02-28 18:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.1512909084558487 norm:0.003455163910984993 max memory_allocated 22567.09130859375 
[2025-02-28 18:30:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.14846950769424438 norm:0.0023224728647619486 max memory_allocated 22567.09130859375 
[2025-02-28 18:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.1472359597682953 norm:0.0015890983631834388 max memory_allocated 22567.09130859375 
[2025-02-28 18:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.14680631458759308 norm:0.0015260668005794287 max memory_allocated 22567.09130859375 
[2025-02-28 18:32:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.14661429822444916 norm:0.0015255118487402797 max memory_allocated 22567.09130859375 
[2025-02-28 18:33:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.14645855128765106 norm:0.0014278130838647485 max memory_allocated 22567.09130859375 
[2025-02-28 18:33:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.14633548259735107 norm:0.0013089505955576897 max memory_allocated 22567.09130859375 
[2025-02-28 18:34:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.14625057578086853 norm:0.001213535899296403 max memory_allocated 22567.09130859375 
[2025-02-28 18:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.14615631103515625 norm:0.0010806508362293243 max memory_allocated 22567.09130859375 
[2025-02-28 18:35:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.1460844725370407 norm:0.0010506256949156523 max memory_allocated 22567.09130859375 
[2025-02-28 18:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.14604976773262024 norm:0.000974767142906785 max memory_allocated 22567.09130859375 
[2025-02-28 18:36:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.1460341364145279 norm:0.0009665739489719272 max memory_allocated 22567.09130859375 
[2025-02-28 18:36:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.1460360884666443 norm:0.0011345013044774532 max memory_allocated 22567.09130859375 
[2025-02-28 18:37:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.14610758423805237 norm:0.0013159256195649505 max memory_allocated 22567.09130859375 
[2025-02-28 18:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.146072655916214 norm:0.0012249217834323645 max memory_allocated 22567.09130859375 
[2025-02-28 18:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.14601045846939087 norm:0.0011432948522269726 max memory_allocated 22567.09130859375 
[2025-02-28 18:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.1460379660129547 norm:0.001126240473240614 max memory_allocated 22567.09130859375 
[2025-02-28 18:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.1460411250591278 norm:0.0011117779649794102 max memory_allocated 22567.09130859375 
[2025-02-28 18:39:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 18:39:23 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:39:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.1196308135986328 norm:0.18629702925682068 max memory_allocated 22567.26318359375 
[2025-02-28 18:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.7746790647506714 norm:0.1649109125137329 max memory_allocated 22567.26318359375 
[2025-02-28 18:40:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.3974378705024719 norm:0.0657152459025383 max memory_allocated 22567.26318359375 
[2025-02-28 18:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.30231571197509766 norm:0.04650250822305679 max memory_allocated 22567.26318359375 
[2025-02-28 18:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.27194181084632874 norm:0.046622637659311295 max memory_allocated 22567.26318359375 
[2025-02-28 18:42:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.25586774945259094 norm:0.04292675480246544 max memory_allocated 22567.26318359375 
[2025-02-28 18:42:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.2449304759502411 norm:0.04007245600223541 max memory_allocated 22567.26318359375 
[2025-02-28 18:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.2379191368818283 norm:0.0391935259103775 max memory_allocated 22567.26318359375 
[2025-02-28 18:44:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.2312586009502411 norm:0.03720918670296669 max memory_allocated 22567.26318359375 
[2025-02-28 18:44:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.22677026689052582 norm:0.0358969122171402 max memory_allocated 22567.26318359375 
[2025-02-28 18:45:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.22255778312683105 norm:0.034004323184490204 max memory_allocated 22567.26318359375 
[2025-02-28 18:45:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.21875828504562378 norm:0.031114725396037102 max memory_allocated 22567.26318359375 
[2025-02-28 18:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.21627023816108704 norm:0.030305828899145126 max memory_allocated 22567.26318359375 
[2025-02-28 18:46:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.21428215503692627 norm:0.028656480833888054 max memory_allocated 22567.26318359375 
[2025-02-28 18:47:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.2127743363380432 norm:0.027484405785799026 max memory_allocated 22567.26318359375 
[2025-02-28 18:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.21162888407707214 norm:0.02620530128479004 max memory_allocated 22567.26318359375 
[2025-02-28 18:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.21031522750854492 norm:0.02459593489766121 max memory_allocated 22567.26318359375 
[2025-02-28 18:48:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.21015875041484833 norm:0.025136051699519157 max memory_allocated 22567.26318359375 
[2025-02-28 18:49:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.2097558081150055 norm:0.02496139518916607 max memory_allocated 22567.26318359375 
[2025-02-28 18:49:42 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.20909227430820465 norm:0.023547383025288582 max memory_allocated 22567.26318359375 
[2025-02-28 18:49:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 18:49:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:50:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.40370625257492065 norm:0.028168827295303345 max memory_allocated 22567.43505859375 
[2025-02-28 18:50:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.37998107075691223 norm:0.020521245896816254 max memory_allocated 22567.43505859375 
[2025-02-28 18:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.36791837215423584 norm:0.01728612743318081 max memory_allocated 22567.43505859375 
[2025-02-28 18:51:57 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.35978734493255615 norm:0.014689634554088116 max memory_allocated 22567.43505859375 
[2025-02-28 18:52:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.3542255759239197 norm:0.01247989758849144 max memory_allocated 22567.43505859375 
[2025-02-28 18:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.3505544662475586 norm:0.011249082162976265 max memory_allocated 22567.43505859375 
[2025-02-28 18:53:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.34841588139533997 norm:0.010496648959815502 max memory_allocated 22567.43505859375 
[2025-02-28 18:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.34688907861709595 norm:0.01007056050002575 max memory_allocated 22567.43505859375 
[2025-02-28 18:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.34607380628585815 norm:0.010212600231170654 max memory_allocated 22567.43505859375 
[2025-02-28 18:55:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.34516751766204834 norm:0.009718457236886024 max memory_allocated 22567.43505859375 
[2025-02-28 18:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.3445521295070648 norm:0.009430060163140297 max memory_allocated 22567.43505859375 
[2025-02-28 18:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.3436795473098755 norm:0.009061955846846104 max memory_allocated 22567.43505859375 
[2025-02-28 18:56:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.34397950768470764 norm:0.010309848003089428 max memory_allocated 22567.43505859375 
[2025-02-28 18:57:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.3431587815284729 norm:0.0091119185090065 max memory_allocated 22567.43505859375 
[2025-02-28 18:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.34284594655036926 norm:0.008995081298053265 max memory_allocated 22567.43505859375 
[2025-02-28 18:58:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.3423589766025543 norm:0.008731012232601643 max memory_allocated 22567.43505859375 
[2025-02-28 18:58:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.3422781527042389 norm:0.00914697628468275 max memory_allocated 22567.43505859375 
[2025-02-28 18:59:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.34176135063171387 norm:0.008507761172950268 max memory_allocated 22567.43505859375 
[2025-02-28 18:59:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.3415182828903198 norm:0.008473267778754234 max memory_allocated 22567.43505859375 
[2025-02-28 19:00:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.3413003087043762 norm:0.008519316092133522 max memory_allocated 22567.43505859375 
[2025-02-28 19:00:21 root] (main_calib_config2.py 380): INFO 20116.33538389206
[2025-02-28 19:00:25 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 19:01:29 root] (main_calib_config2.py 159): INFO wikitext2 : 5.66037130355835
[2025-02-28 19:01:29 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 19:03:08 root] (main_calib_config2.py 159): INFO c4 : 7.223411560058594
[2025-02-28 20:43:48 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.66037130355835, 'c4': 7.223411560058594, 'results': {'arc_challenge': {'acc': 0.3916382252559727, 'acc_stderr': 0.01426412212493822, 'acc_norm': 0.3924914675767918, 'acc_norm_stderr': 0.01426963463567071}, 'piqa': {'acc': 0.7725788900979326, 'acc_stderr': 0.009779850767847244, 'acc_norm': 0.7693144722524483, 'acc_norm_stderr': 0.009828959550983096}, 'boolq': {'acc': 0.6798165137614679, 'acc_stderr': 0.00815995679430225}, 'hellaswag': {'acc': 0.5541724756024696, 'acc_stderr': 0.004960408362133241, 'acc_norm': 0.7148974307906791, 'acc_norm_stderr': 0.004505406176606848}, 'winogrande': {'acc': 0.664561957379637, 'acc_stderr': 0.013269575904851429}, 'arc_easy': {'acc': 0.6616161616161617, 'acc_stderr': 0.009709034670525096, 'acc_norm': 0.5168350168350169, 'acc_norm_stderr': 0.010253966261288898}}, 'versions': {'arc_challenge': 0, 'piqa': 0, 'boolq': 1, 'hellaswag': 0, 'winogrande': 0, 'arc_easy': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
