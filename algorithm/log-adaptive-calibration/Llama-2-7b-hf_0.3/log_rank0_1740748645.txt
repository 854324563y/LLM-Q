[2025-02-28 13:17:25 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-7b-hf_0.3', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.3.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:20:27 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:20:27 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.3.pkl
[2025-02-28 13:20:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:20:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.04326880723237991 norm:0.03346666321158409 max memory_allocated 22562.10693359375 
[2025-02-28 13:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.027776997536420822 norm:0.01984453946352005 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.022210540249943733 norm:0.015549721196293831 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0201665461063385 norm:0.013210684061050415 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.019131489098072052 norm:0.011523036286234856 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.018551532179117203 norm:0.01153915748000145 max memory_allocated 22562.10693359375 
[2025-02-28 13:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.018238287419080734 norm:0.009468013420701027 max memory_allocated 22562.10693359375 
[2025-02-28 13:24:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.01794012263417244 norm:0.006652673240751028 max memory_allocated 22562.10693359375 
[2025-02-28 13:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.017754128202795982 norm:0.006394356023520231 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.017735760658979416 norm:0.005669564940035343 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.017649579793214798 norm:0.00461007934063673 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.017620977014303207 norm:0.00455621350556612 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.01751420646905899 norm:0.004155802074819803 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.017503950744867325 norm:0.0038898750208318233 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.017478594556450844 norm:0.004704028367996216 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.01743001863360405 norm:0.0043426319025456905 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.017510470002889633 norm:0.0038107442669570446 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.017465699464082718 norm:0.0037805065512657166 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.017329754307866096 norm:0.0031725093722343445 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.01748678833246231 norm:0.003620799630880356 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:31:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.23887419700622559 norm:0.09833697229623795 max memory_allocated 22562.27880859375 
[2025-02-28 13:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.17450463771820068 norm:0.06390409171581268 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.14568766951560974 norm:0.04053768515586853 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.13420353829860687 norm:0.03744592145085335 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.12672658264636993 norm:0.035382453352212906 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.12423110753297806 norm:0.034330543130636215 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.11850505322217941 norm:0.0314614474773407 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.11570079624652863 norm:0.03161223977804184 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.11453135311603546 norm:0.031209519132971764 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.11174102872610092 norm:0.029590144753456116 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.11218661814928055 norm:0.029466982930898666 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.11163817346096039 norm:0.02879677526652813 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.11135084927082062 norm:0.028364403173327446 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.11145725101232529 norm:0.02710387110710144 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.11146996915340424 norm:0.027182765305042267 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.11087390780448914 norm:0.02618902362883091 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.10940460115671158 norm:0.025638341903686523 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.1091499924659729 norm:0.024622023105621338 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.11015921086072922 norm:0.024510208517313004 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.11002638190984726 norm:0.024378059431910515 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 13:43:15 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.1679627150297165 norm:0.03736146539449692 max memory_allocated 22562.45068359375 
[2025-02-28 13:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.14463774859905243 norm:0.021954018622636795 max memory_allocated 22562.45068359375 
[2025-02-28 13:44:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.1310070902109146 norm:0.014001849107444286 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.12555190920829773 norm:0.01129304338246584 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.12257467955350876 norm:0.009578020311892033 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.12063409388065338 norm:0.007919714786112309 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.11930528283119202 norm:0.006501666270196438 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.11840865761041641 norm:0.005707048811018467 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.11776500195264816 norm:0.0051634470000863075 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.11737886071205139 norm:0.005063497461378574 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.1171659529209137 norm:0.0050673168152570724 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.11691838502883911 norm:0.00472864368930459 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.11681464314460754 norm:0.004394050221890211 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.11661656200885773 norm:0.004257895518094301 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.11656307429075241 norm:0.00422624358907342 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.11649208515882492 norm:0.004085006657987833 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.11648134887218475 norm:0.003995158243924379 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.11646309494972229 norm:0.0039040204137563705 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.11639580875635147 norm:0.0038292896933853626 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.11643754690885544 norm:0.0038293497636914253 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 13:55:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.20969906449317932 norm:0.01638931594789028 max memory_allocated 22562.50732421875 
[2025-02-28 13:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.18236447870731354 norm:0.005798179656267166 max memory_allocated 22562.50732421875 
[2025-02-28 13:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.16368162631988525 norm:0.00272520468570292 max memory_allocated 22562.50732421875 
[2025-02-28 13:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.15739482641220093 norm:0.001796018797904253 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.15421681106090546 norm:0.0015173469437286258 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.1523287147283554 norm:0.0013964235549792647 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.15106341242790222 norm:0.0013537477934733033 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.15041932463645935 norm:0.001485997810959816 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.14965912699699402 norm:0.0013090720167383552 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.14916448295116425 norm:0.001258727628737688 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.14890578389167786 norm:0.001241490594111383 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.1485050618648529 norm:0.0012278547510504723 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.14823395013809204 norm:0.0011980491690337658 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.14811396598815918 norm:0.0011682341573759913 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.14798662066459656 norm:0.0011676130816340446 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.14780941605567932 norm:0.0011433045146986842 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.14776945114135742 norm:0.0011417506029829383 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.14766013622283936 norm:0.0011899976525455713 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.14760926365852356 norm:0.001164649031125009 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.14760692417621613 norm:0.0011278565507382154 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:06:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.26120525598526 norm:0.03801919147372246 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.2216864377260208 norm:0.011795645579695702 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.19603103399276733 norm:0.004324224777519703 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.18825511634349823 norm:0.002730386331677437 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.18435776233673096 norm:0.0020600829739123583 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.18173299729824066 norm:0.0017451392486691475 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.17981238663196564 norm:0.001580837881192565 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.1786365807056427 norm:0.0014426769921556115 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.17772556841373444 norm:0.0013636592775583267 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.17717081308364868 norm:0.0012884389143437147 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.1767704039812088 norm:0.001285594655200839 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.17641833424568176 norm:0.0012335516512393951 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.17620119452476501 norm:0.0012009672354906797 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.17599914968013763 norm:0.001171258045360446 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.17581957578659058 norm:0.0011603779857978225 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.1757298707962036 norm:0.001142360968515277 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.17568077147006989 norm:0.001138658612035215 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.17558476328849792 norm:0.0011344451922923326 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.1754191666841507 norm:0.001130374032072723 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.17533014714717865 norm:0.0011208461364731193 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:17:57 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.2764490246772766 norm:0.015284967608749866 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.2471267729997635 norm:0.006335870828479528 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.21920494735240936 norm:0.0027563476469367743 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.20990140736103058 norm:0.0017771831480786204 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.2054785043001175 norm:0.001471261610276997 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.20271684229373932 norm:0.0012932593235746026 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.2010355144739151 norm:0.0012102347100153565 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.19990843534469604 norm:0.0012114385608583689 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.19907096028327942 norm:0.001192740397527814 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.19846555590629578 norm:0.001175566460005939 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.1981094777584076 norm:0.0011460842797532678 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.19774842262268066 norm:0.0011452932376414537 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.19748246669769287 norm:0.001130750053562224 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.19726599752902985 norm:0.001120509346947074 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.19706663489341736 norm:0.0011246465146541595 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.19692422449588776 norm:0.0011232069227844477 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.1967739462852478 norm:0.0011023988481611013 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.19666628539562225 norm:0.0010745602194219828 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.1965940296649933 norm:0.001083571114577353 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.1965721994638443 norm:0.001078970031812787 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 14:29:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.31305861473083496 norm:0.02410280890762806 max memory_allocated 22563.02294921875 
[2025-02-28 14:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.2760546803474426 norm:0.009242145344614983 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.25353050231933594 norm:0.005222771316766739 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.2438739389181137 norm:0.0034293332137167454 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:33 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.23818090558052063 norm:0.002487563295289874 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.23467124998569489 norm:0.002084216335788369 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.23243412375450134 norm:0.0019005027133971453 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.2309800386428833 norm:0.0017152270302176476 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.2298283576965332 norm:0.0015431733336299658 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.22871243953704834 norm:0.001408663229085505 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.228202223777771 norm:0.0013734981184825301 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.22784900665283203 norm:0.0013455479638651013 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.22752182185649872 norm:0.001298632938414812 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.22722898423671722 norm:0.0012619919143617153 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.22702008485794067 norm:0.001242139027453959 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.22670932114124298 norm:0.0012108362279832363 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.22649534046649933 norm:0.0011880401289090514 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.2263302356004715 norm:0.001177975325845182 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.22613608837127686 norm:0.0011638945434242487 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.2259267419576645 norm:0.0011439886875450611 max memory_allocated 22563.02294921875 
[2025-02-28 14:40:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 14:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.3312811553478241 norm:0.013313260860741138 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.2936718463897705 norm:0.005220761056989431 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.2722129821777344 norm:0.0031478069722652435 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.263907253742218 norm:0.00238422816619277 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.259375661611557 norm:0.0019796930719166994 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.25614845752716064 norm:0.0017107579624280334 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.2540782690048218 norm:0.0015437479596585035 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.2525249123573303 norm:0.0014481820398941636 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.25128746032714844 norm:0.0013284151209518313 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.2505700886249542 norm:0.0013027017703279853 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:17 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.24998903274536133 norm:0.0012572088744491339 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.24958693981170654 norm:0.0012148278765380383 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.2492678165435791 norm:0.0011754700681194663 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.24901911616325378 norm:0.0011779216583818197 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.24879243969917297 norm:0.001160907093435526 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.24877667427062988 norm:0.0011291973059996963 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.24868988990783691 norm:0.002146641258150339 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.24862103164196014 norm:0.001110703800804913 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.24841664731502533 norm:0.0010860849870368838 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.2482786774635315 norm:0.0010813572444021702 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 14:52:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.3670739531517029 norm:0.021366771310567856 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.3244396150112152 norm:0.007347690407186747 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.2917747497558594 norm:0.0031452106777578592 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.28104832768440247 norm:0.0020390674471855164 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.2760920226573944 norm:0.0017778081819415092 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.2727092504501343 norm:0.0016206159489229321 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.2704285979270935 norm:0.0015274176839739084 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.2690291702747345 norm:0.0014189832145348191 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.2678981125354767 norm:0.001347156474366784 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.2670658826828003 norm:0.0013001986080780625 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.26650872826576233 norm:0.001226311083883047 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.2660500407218933 norm:0.0011762179201468825 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.2658116817474365 norm:0.0011791076976805925 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.26565441489219666 norm:0.001167917507700622 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.26538774371147156 norm:0.001157678896561265 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.26514631509780884 norm:0.0011344649828970432 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.2650555968284607 norm:0.0011070939945057034 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.26500460505485535 norm:0.0010510594584047794 max memory_allocated 22563.36669921875 
[2025-02-28 15:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.2648012042045593 norm:0.001027971040457487 max memory_allocated 22563.36669921875 
[2025-02-28 15:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.26468759775161743 norm:0.0010065665701404214 max memory_allocated 22563.36669921875 
[2025-02-28 15:02:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 15:03:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.3586917221546173 norm:0.013594432733952999 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.32498568296432495 norm:0.004910103976726532 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.30219393968582153 norm:0.0024709177669137716 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.29350411891937256 norm:0.0018139946041628718 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.28902509808540344 norm:0.0015332960756495595 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.285967618227005 norm:0.0013724880991503596 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.28393611311912537 norm:0.0012672821758314967 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:22 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.28256428241729736 norm:0.0011873337207362056 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.28158843517303467 norm:0.0011418870417401195 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.28087663650512695 norm:0.00110748375300318 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.2802741527557373 norm:0.0010531798470765352 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.27986860275268555 norm:0.0010259178234264255 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.2795630395412445 norm:0.0009955093264579773 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.2792920470237732 norm:0.000983847538009286 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.2790794372558594 norm:0.0009657969931140542 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.27884531021118164 norm:0.0009537833393551409 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.2786397337913513 norm:0.0009398926049470901 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.27849066257476807 norm:0.0009262243402190506 max memory_allocated 22563.53857421875 
[2025-02-28 15:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.27838853001594543 norm:0.0009217291953973472 max memory_allocated 22563.53857421875 
[2025-02-28 15:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.27825456857681274 norm:0.0009023758466355503 max memory_allocated 22563.53857421875 
[2025-02-28 15:14:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 15:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.3682222366333008 norm:0.022991769015789032 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.3395441770553589 norm:0.009948192164301872 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.3161190152168274 norm:0.004665779415518045 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.304542601108551 norm:0.0016442278865724802 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.29881608486175537 norm:0.0011052965419366956 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.2953273057937622 norm:0.0010308829369023442 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.2929268181324005 norm:0.0009749424061737955 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.29132747650146484 norm:0.00093236961401999 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.29016217589378357 norm:0.000905884662643075 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.289326548576355 norm:0.0008778931223787367 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.2886504530906677 norm:0.0008632772951386869 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.28824543952941895 norm:0.0008583726594224572 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.28792619705200195 norm:0.0008615842089056969 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.28768980503082275 norm:0.0008475262438878417 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.28748923540115356 norm:0.0008383054519072175 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.2872993052005768 norm:0.0008338284678757191 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.287158727645874 norm:0.0008268750971183181 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.2870717942714691 norm:0.0008338339976035058 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.28697437047958374 norm:0.0008252945262938738 max memory_allocated 22563.71044921875 
[2025-02-28 15:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.2868573069572449 norm:0.0008340144995599985 max memory_allocated 22563.71044921875 
[2025-02-28 15:25:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 15:26:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.3697897493839264 norm:0.014830888248980045 max memory_allocated 22563.88232421875 
[2025-02-28 15:26:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.33735448122024536 norm:0.006217829883098602 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.31696656346321106 norm:0.003514564596116543 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.30801668763160706 norm:0.0023654568940401077 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.30320411920547485 norm:0.0017853074241429567 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.3000507056713104 norm:0.0014205184997990727 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.29794007539749146 norm:0.0012219413183629513 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.29656219482421875 norm:0.0011819530045613647 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.2954728603363037 norm:0.0010705181630328298 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.29466259479522705 norm:0.0009944416815415025 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.2941146790981293 norm:0.000945542473345995 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.2936550974845886 norm:0.0009024150785990059 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.29337674379348755 norm:0.000869263312779367 max memory_allocated 22563.88232421875 
[2025-02-28 15:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.2931275963783264 norm:0.0008617762941867113 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.2928621470928192 norm:0.000843539834022522 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.2926384508609772 norm:0.000828560849186033 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.2924920618534088 norm:0.0008094462682493031 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.29238876700401306 norm:0.000810443249065429 max memory_allocated 22563.88232421875 
[2025-02-28 15:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.2922983467578888 norm:0.0008075348450802267 max memory_allocated 22563.88232421875 
[2025-02-28 15:36:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.2922038435935974 norm:0.0008109769551083446 max memory_allocated 22563.88232421875 
[2025-02-28 15:37:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 15:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.36029428243637085 norm:0.006463800091296434 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.33782094717025757 norm:0.0029211880173534155 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.32077574729919434 norm:0.0017767057288438082 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.3131633400917053 norm:0.0013080360367894173 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.3089688718318939 norm:0.001110245706513524 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.3063347339630127 norm:0.0010063749505206943 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.3045901358127594 norm:0.0009382135467603803 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.3033376634120941 norm:0.0008948415634222329 max memory_allocated 22564.05419921875 
[2025-02-28 15:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.3023935556411743 norm:0.0008547461475245655 max memory_allocated 22564.05419921875 
[2025-02-28 15:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.3017420768737793 norm:0.0008251297986134887 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.3012637794017792 norm:0.000802733760792762 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.3008950352668762 norm:0.0007871690904721618 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.3006604015827179 norm:0.0007713708910159767 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.30038541555404663 norm:0.0007692072540521622 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.3002093434333801 norm:0.000767888966947794 max memory_allocated 22564.05419921875 
[2025-02-28 15:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.300020307302475 norm:0.0007594191120006144 max memory_allocated 22564.05419921875 
[2025-02-28 15:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.2998856008052826 norm:0.0007496299222111702 max memory_allocated 22564.05419921875 
[2025-02-28 15:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.2997850775718689 norm:0.0007458796608261764 max memory_allocated 22564.05419921875 
[2025-02-28 15:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.2997264862060547 norm:0.0007448912947438657 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.2996582090854645 norm:0.0007521227234974504 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 15:49:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.3701740503311157 norm:0.022811122238636017 max memory_allocated 22564.22607421875 
[2025-02-28 15:49:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.3417246639728546 norm:0.009566973894834518 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.322773277759552 norm:0.005165632348507643 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.3140393793582916 norm:0.002646344481036067 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.30893611907958984 norm:0.0014608115889132023 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.3057118058204651 norm:0.0012592688435688615 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.303462415933609 norm:0.0011476266663521528 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.30171671509742737 norm:0.001066348166204989 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.30049774050712585 norm:0.001009027473628521 max memory_allocated 22564.22607421875 
[2025-02-28 15:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.299603670835495 norm:0.0009626566316001117 max memory_allocated 22564.22607421875 
[2025-02-28 15:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.29893064498901367 norm:0.000945354753639549 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.2984008193016052 norm:0.0008819184731692076 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.2979552745819092 norm:0.0008532701176591218 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.29763343930244446 norm:0.0008334783487953246 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.297345906496048 norm:0.0008188523934222758 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.29714012145996094 norm:0.0008031430770643055 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.2969980537891388 norm:0.0007953662425279617 max memory_allocated 22564.22607421875 
[2025-02-28 15:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.2968558371067047 norm:0.0007844522478990257 max memory_allocated 22564.22607421875 
[2025-02-28 15:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.2966882288455963 norm:0.0007760121952742338 max memory_allocated 22564.22607421875 
[2025-02-28 15:59:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.29657840728759766 norm:0.0007760980515740812 max memory_allocated 22564.22607421875 
[2025-02-28 15:59:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 16:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.35803258419036865 norm:0.007591377478092909 max memory_allocated 22564.39794921875 
[2025-02-28 16:00:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.33811742067337036 norm:0.00331739685498178 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.32334867119789124 norm:0.0017685058992356062 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.3167839050292969 norm:0.0011687055230140686 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.3131875991821289 norm:0.000973431917373091 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.310599684715271 norm:0.0008882092079147696 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.3088951110839844 norm:0.0008515443187206984 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.3075271546840668 norm:0.000818233413156122 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.3065628409385681 norm:0.0007994748302735388 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.30576902627944946 norm:0.0007791350362822413 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.3051703870296478 norm:0.0007631644839420915 max memory_allocated 22564.39794921875 
[2025-02-28 16:06:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.30472177267074585 norm:0.0007557114586234093 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.3043699562549591 norm:0.0007456718594767153 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.3041257858276367 norm:0.0007375084096565843 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.30391645431518555 norm:0.0007389861275441945 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.30373769998550415 norm:0.0007348904036916792 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.30355826020240784 norm:0.0007323266472667456 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.3033784329891205 norm:0.0007304211612790823 max memory_allocated 22564.39794921875 
[2025-02-28 16:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.30323728919029236 norm:0.0007263501174747944 max memory_allocated 22564.39794921875 
[2025-02-28 16:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.30309540033340454 norm:0.0007239303085952997 max memory_allocated 22564.39794921875 
[2025-02-28 16:11:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 16:11:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.37011346220970154 norm:0.016260098665952682 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.3456295430660248 norm:0.0066440352238714695 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.3272266983985901 norm:0.002948974957689643 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.3198429346084595 norm:0.001455976627767086 max memory_allocated 22564.56982421875 
[2025-02-28 16:14:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.3160327970981598 norm:0.001054295222274959 max memory_allocated 22564.56982421875 
[2025-02-28 16:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.3133068084716797 norm:0.0009391352068632841 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.3113067150115967 norm:0.0008751658606342971 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.30986902117729187 norm:0.0008405826520174742 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.30872783064842224 norm:0.000799796893261373 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.30786600708961487 norm:0.0007872623391449451 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.30727335810661316 norm:0.000772712635807693 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.30682429671287537 norm:0.0007580118253827095 max memory_allocated 22564.56982421875 
[2025-02-28 16:18:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.30639219284057617 norm:0.0007407681550830603 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.3060440421104431 norm:0.0007405804353766143 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.3058164417743683 norm:0.0007343090255744755 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.305525004863739 norm:0.0007253548828884959 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.3052990436553955 norm:0.0007163197151385248 max memory_allocated 22564.56982421875 
[2025-02-28 16:21:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.30511385202407837 norm:0.0007110330043360591 max memory_allocated 22564.56982421875 
[2025-02-28 16:21:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.30493903160095215 norm:0.0007115149637684226 max memory_allocated 22564.56982421875 
[2025-02-28 16:22:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.3048548400402069 norm:0.0007118354551494122 max memory_allocated 22564.56982421875 
[2025-02-28 16:22:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 16:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.4191761612892151 norm:0.03548930585384369 max memory_allocated 22564.74169921875 
[2025-02-28 16:23:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.3784582316875458 norm:0.01460577268153429 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.34645944833755493 norm:0.006141875870525837 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.3324529230594635 norm:0.0027654205914586782 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.32727310061454773 norm:0.0018461036961525679 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.324357271194458 norm:0.0016054607694968581 max memory_allocated 22564.74169921875 
[2025-02-28 16:26:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.32209286093711853 norm:0.0014718601014465094 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.3203592598438263 norm:0.001399276894517243 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.31901341676712036 norm:0.0013429154641926289 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.3177996575832367 norm:0.0012720400700345635 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.3169223964214325 norm:0.0012463948223739862 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.316200852394104 norm:0.0012259710347279906 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.31554749608039856 norm:0.001172542804852128 max memory_allocated 22564.74169921875 
[2025-02-28 16:30:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.3150077164173126 norm:0.001124890404753387 max memory_allocated 22564.74169921875 
[2025-02-28 16:30:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.31461086869239807 norm:0.001114797662012279 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.31424665451049805 norm:0.001075651845894754 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.31392550468444824 norm:0.0010480423225089908 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.3137162923812866 norm:0.0010404326021671295 max memory_allocated 22564.74169921875 
[2025-02-28 16:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.31343966722488403 norm:0.0010257489047944546 max memory_allocated 22564.74169921875 
[2025-02-28 16:33:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.3132009506225586 norm:0.0010197957744821906 max memory_allocated 22564.74169921875 
[2025-02-28 16:33:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 16:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.36810171604156494 norm:0.009382916614413261 max memory_allocated 22564.91357421875 
[2025-02-28 16:35:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.3535973131656647 norm:0.004085483495146036 max memory_allocated 22564.91357421875 
[2025-02-28 16:35:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.34121596813201904 norm:0.0020994471851736307 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.3362954258918762 norm:0.0011584109161049128 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.333766371011734 norm:0.0010072324657812715 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.3318127989768982 norm:0.000960938457865268 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.3302455246448517 norm:0.0009346604929305613 max memory_allocated 22564.91357421875 
[2025-02-28 16:38:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.3289593756198883 norm:0.0009099892340600491 max memory_allocated 22564.91357421875 
[2025-02-28 16:38:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.3279481530189514 norm:0.0008874615887179971 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.32707861065864563 norm:0.0008711057016626 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.3263700604438782 norm:0.0008559280540794134 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.32584911584854126 norm:0.0008333504665642977 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:13 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.3254055678844452 norm:0.0008209733641706407 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.32502514123916626 norm:0.0008214841363951564 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.3247094750404358 norm:0.0008098590769805014 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.32437968254089355 norm:0.000800812675151974 max memory_allocated 22564.91357421875 
[2025-02-28 16:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.3241187632083893 norm:0.0007914394373074174 max memory_allocated 22564.91357421875 
[2025-02-28 16:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.3239140212535858 norm:0.000791770638898015 max memory_allocated 22564.91357421875 
[2025-02-28 16:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.3237724304199219 norm:0.0007882284699007869 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.3236387372016907 norm:0.0007852851413190365 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 16:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.39749133586883545 norm:0.018422313034534454 max memory_allocated 22565.08544921875 
[2025-02-28 16:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.3801683187484741 norm:0.00804718304425478 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.36611124873161316 norm:0.0042202589102089405 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.35954082012176514 norm:0.0022268404718488455 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.3560882806777954 norm:0.0012474837712943554 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.35398784279823303 norm:0.0010972096351906657 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.35232847929000854 norm:0.001044449512846768 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.3509945571422577 norm:0.000999209936708212 max memory_allocated 22565.08544921875 
[2025-02-28 16:50:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.34986239671707153 norm:0.000966628547757864 max memory_allocated 22565.08544921875 
[2025-02-28 16:50:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.3489566743373871 norm:0.000926832901313901 max memory_allocated 22565.08544921875 
[2025-02-28 16:51:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.3483009338378906 norm:0.0009059382136911154 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.34782329201698303 norm:0.0008747551473788917 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.347359836101532 norm:0.0008611081866547465 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.3469069004058838 norm:0.0008455532952211797 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.34660229086875916 norm:0.0008367491536773741 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.34632885456085205 norm:0.0008167674532160163 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.3459911644458771 norm:0.0008111645583994687 max memory_allocated 22565.08544921875 
[2025-02-28 16:55:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.3457823395729065 norm:0.000802936963737011 max memory_allocated 22565.08544921875 
[2025-02-28 16:55:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.3455614149570465 norm:0.0007986436830833554 max memory_allocated 22565.08544921875 
[2025-02-28 16:56:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.34539884328842163 norm:0.0007964245742186904 max memory_allocated 22565.08544921875 
[2025-02-28 16:56:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 16:57:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.41663888096809387 norm:0.016168886795639992 max memory_allocated 22565.25732421875 
[2025-02-28 16:57:49 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.402617484331131 norm:0.008579270914196968 max memory_allocated 22565.25732421875 
[2025-02-28 16:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.3887253999710083 norm:0.004279022570699453 max memory_allocated 22565.25732421875 
[2025-02-28 16:58:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.3827584385871887 norm:0.0013118924107402563 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.38032957911491394 norm:0.0009191491408273578 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.37861722707748413 norm:0.0008451361209154129 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.3772569000720978 norm:0.0008139987476170063 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.37610143423080444 norm:0.0007706526084803045 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.3751692473888397 norm:0.0007476782193407416 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.3744465410709381 norm:0.0007235375815071166 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.3738965690135956 norm:0.0007104896940290928 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.37342172861099243 norm:0.0006994741852395236 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.37303683161735535 norm:0.0006971278344281018 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.37269410490989685 norm:0.0006863990565761924 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.37237000465393066 norm:0.0006717114592902362 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.37211325764656067 norm:0.0006669857539236546 max memory_allocated 22565.25732421875 
[2025-02-28 17:06:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.37189221382141113 norm:0.0006661739898845553 max memory_allocated 22565.25732421875 
[2025-02-28 17:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.3717030882835388 norm:0.000661080121062696 max memory_allocated 22565.25732421875 
[2025-02-28 17:07:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.3715294599533081 norm:0.0006627352559007704 max memory_allocated 22565.25732421875 
[2025-02-28 17:07:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.37137681245803833 norm:0.0006643205415457487 max memory_allocated 22565.25732421875 
[2025-02-28 17:08:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 17:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.45671504735946655 norm:0.013997160829603672 max memory_allocated 22565.42919921875 
[2025-02-28 17:09:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.4441429376602173 norm:0.007972218096256256 max memory_allocated 22565.42919921875 
[2025-02-28 17:09:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.430724561214447 norm:0.004695230163633823 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.42424631118774414 norm:0.003101928625255823 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.4211428165435791 norm:0.002516789361834526 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.41823917627334595 norm:0.0014306778321042657 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.416307657957077 norm:0.0012537915026769042 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.4148687720298767 norm:0.0011560427956283092 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.41379207372665405 norm:0.0010986512061208487 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.4129149615764618 norm:0.0010447477689012885 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.412198543548584 norm:0.0009991026017814875 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.41165733337402344 norm:0.0009785478468984365 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.41120976209640503 norm:0.0009622995276004076 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.4108121991157532 norm:0.0009448617929592729 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.4104785919189453 norm:0.0009303356055170298 max memory_allocated 22565.42919921875 
[2025-02-28 17:17:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.4101717472076416 norm:0.0009217689512297511 max memory_allocated 22565.42919921875 
[2025-02-28 17:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.40981289744377136 norm:0.0008780549396760762 max memory_allocated 22565.42919921875 
[2025-02-28 17:18:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.40959861874580383 norm:0.0008670323295518756 max memory_allocated 22565.42919921875 
[2025-02-28 17:18:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.40942493081092834 norm:0.0008631073287688196 max memory_allocated 22565.42919921875 
[2025-02-28 17:19:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.40926072001457214 norm:0.0008629566291347146 max memory_allocated 22565.42919921875 
[2025-02-28 17:19:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 17:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.4893222749233246 norm:0.01285504549741745 max memory_allocated 22565.60107421875 
[2025-02-28 17:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.47752195596694946 norm:0.006479467265307903 max memory_allocated 22565.60107421875 
[2025-02-28 17:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.46580541133880615 norm:0.0031425573397427797 max memory_allocated 22565.60107421875 
[2025-02-28 17:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.4605076313018799 norm:0.0011347585823386908 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.45858168601989746 norm:0.0008576933178119361 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.4569557309150696 norm:0.0008048864547163248 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.4555325210094452 norm:0.0007660250994376838 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.4542354941368103 norm:0.0007302513113245368 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.4533843994140625 norm:0.000713957124389708 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.45273640751838684 norm:0.0007075073081068695 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.4522688090801239 norm:0.0006991258123889565 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.4518274664878845 norm:0.0006973914569243789 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.4514530897140503 norm:0.0006937821744941175 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.4511951208114624 norm:0.0006863480666652322 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.4509310722351074 norm:0.0006825583404861391 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.45072034001350403 norm:0.0006828741170465946 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.4505273103713989 norm:0.0006796960951760411 max memory_allocated 22565.60107421875 
[2025-02-28 17:29:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.45040372014045715 norm:0.0006763669662177563 max memory_allocated 22565.60107421875 
[2025-02-28 17:30:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.4502955675125122 norm:0.0006740799290128052 max memory_allocated 22565.60107421875 
[2025-02-28 17:30:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.450167715549469 norm:0.0006729232845827937 max memory_allocated 22565.60107421875 
[2025-02-28 17:30:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 17:31:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.5413736701011658 norm:0.005161714740097523 max memory_allocated 22565.77294921875 
[2025-02-28 17:31:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.5318540930747986 norm:0.0027505154721438885 max memory_allocated 22565.77294921875 
[2025-02-28 17:32:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.5225058794021606 norm:0.001560065196827054 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.5186395049095154 norm:0.0009653886081650853 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.5165931582450867 norm:0.0007892659050412476 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.5149555206298828 norm:0.0007643571007065475 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.5135986804962158 norm:0.000744096003472805 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.5123884081840515 norm:0.0007377760484814644 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.5116474032402039 norm:0.00074483931530267 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.5110788345336914 norm:0.0007845389191061258 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.5103697180747986 norm:0.0007484785746783018 max memory_allocated 22565.77294921875 
[2025-02-28 17:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.5099831819534302 norm:0.000756702444050461 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.5096766352653503 norm:0.0007481879438273609 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.5093653202056885 norm:0.0007345614139921963 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.5092068314552307 norm:0.0007245077867992222 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.5089100003242493 norm:0.0007113390602171421 max memory_allocated 22565.77294921875 
[2025-02-28 17:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.5087000727653503 norm:0.0007150080637075007 max memory_allocated 22565.77294921875 
[2025-02-28 17:40:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.5084899663925171 norm:0.0007210361654870212 max memory_allocated 22565.77294921875 
[2025-02-28 17:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.5084272027015686 norm:0.0007413319544866681 max memory_allocated 22565.77294921875 
[2025-02-28 17:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.5083273649215698 norm:0.0007483032532036304 max memory_allocated 22565.77294921875 
[2025-02-28 17:42:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 17:42:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.6002129912376404 norm:0.0050041028298437595 max memory_allocated 22565.94482421875 
[2025-02-28 17:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.590121328830719 norm:0.0028775238897651434 max memory_allocated 22565.94482421875 
[2025-02-28 17:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.5798668265342712 norm:0.0018232152797281742 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.5759947299957275 norm:0.0011495024664327502 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.5737040638923645 norm:0.0009213347802869976 max memory_allocated 22565.94482421875 
[2025-02-28 17:45:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.5719426870346069 norm:0.0007756666745990515 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.5705459117889404 norm:0.0007134936167858541 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.5693861246109009 norm:0.0006833386141806841 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.5685617327690125 norm:0.0006632957374677062 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.5679314136505127 norm:0.0006511261453852057 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.5674473643302917 norm:0.0006463525933213532 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.5670986175537109 norm:0.0006412561051547527 max memory_allocated 22565.94482421875 
[2025-02-28 17:49:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.5668240189552307 norm:0.0006344957510009408 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.5665585994720459 norm:0.000630018359515816 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.566318929195404 norm:0.0006244404357858002 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.5661357045173645 norm:0.000618935446254909 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.5659990310668945 norm:0.0006150133558548987 max memory_allocated 22565.94482421875 
[2025-02-28 17:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.5658504962921143 norm:0.000610613264143467 max memory_allocated 22565.94482421875 
[2025-02-28 17:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.5657176971435547 norm:0.0006093206466175616 max memory_allocated 22565.94482421875 
[2025-02-28 17:53:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.56561678647995 norm:0.0006049314397387207 max memory_allocated 22565.94482421875 
[2025-02-28 17:53:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 17:54:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.6721343994140625 norm:0.007567098829895258 max memory_allocated 22566.11669921875 
[2025-02-28 17:54:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.6590771675109863 norm:0.003723425092175603 max memory_allocated 22566.11669921875 
[2025-02-28 17:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.6472160220146179 norm:0.0020150032360106707 max memory_allocated 22566.11669921875 
[2025-02-28 17:55:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.6422827839851379 norm:0.001064053038135171 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.6396801471710205 norm:0.0007130980957299471 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.6376529335975647 norm:0.0006915724952705204 max memory_allocated 22566.11669921875 
[2025-02-28 17:57:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.6359577775001526 norm:0.0006854792009107769 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.6346856951713562 norm:0.0006740765529684722 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.6337118148803711 norm:0.0006954460986889899 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.6330737471580505 norm:0.0006962743354961276 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.6326566338539124 norm:0.0006838528788648546 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.6322718262672424 norm:0.000686792132910341 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.6320109367370605 norm:0.0006796556990593672 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.6316710710525513 norm:0.0006691321032121778 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.6314626932144165 norm:0.0006701531237922609 max memory_allocated 22566.11669921875 
[2025-02-28 18:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.6312757730484009 norm:0.0006755475187674165 max memory_allocated 22566.11669921875 
[2025-02-28 18:03:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.6310691833496094 norm:0.0006813364452682436 max memory_allocated 22566.11669921875 
[2025-02-28 18:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.6309125423431396 norm:0.0007120214868336916 max memory_allocated 22566.11669921875 
[2025-02-28 18:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.630815327167511 norm:0.0007144218543544412 max memory_allocated 22566.11669921875 
[2025-02-28 18:04:44 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.6306866407394409 norm:0.0007152521866373718 max memory_allocated 22566.11669921875 
[2025-02-28 18:04:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 18:05:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.7598642706871033 norm:0.01867619901895523 max memory_allocated 22566.28857421875 
[2025-02-28 18:06:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.748396635055542 norm:0.012250991538167 max memory_allocated 22566.28857421875 
[2025-02-28 18:06:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.7349259257316589 norm:0.00807957723736763 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.7298001646995544 norm:0.0059525626711547375 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.7272502779960632 norm:0.004750801250338554 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.7222970128059387 norm:0.0032082959078252316 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.7197870016098022 norm:0.003113208105787635 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.7184287309646606 norm:0.002884818706661463 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.716628909111023 norm:0.002362622646614909 max memory_allocated 22566.28857421875 
[2025-02-28 18:10:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.7164022922515869 norm:0.0024121461901813745 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.7151221036911011 norm:0.001854541478678584 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.714665949344635 norm:0.002015517558902502 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:12 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.7137539982795715 norm:0.0016699773259460926 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.7134779095649719 norm:0.0015666658291593194 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.7132518291473389 norm:0.0016337200067937374 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.7124767303466797 norm:0.001391357509419322 max memory_allocated 22566.28857421875 
[2025-02-28 18:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.7123676538467407 norm:0.0013301413273438811 max memory_allocated 22566.28857421875 
[2025-02-28 18:15:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.7119828462600708 norm:0.0012676327023655176 max memory_allocated 22566.28857421875 
[2025-02-28 18:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.7116372585296631 norm:0.0011772734578698874 max memory_allocated 22566.28857421875 
[2025-02-28 18:16:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.7113330364227295 norm:0.0011202982859686017 max memory_allocated 22566.28857421875 
[2025-02-28 18:16:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 18:16:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.8493712544441223 norm:0.006105076987296343 max memory_allocated 22566.46044921875 
[2025-02-28 18:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.834580659866333 norm:0.003265049774199724 max memory_allocated 22566.46044921875 
[2025-02-28 18:17:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.8186501860618591 norm:0.0017904655542224646 max memory_allocated 22566.46044921875 
[2025-02-28 18:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.8121255040168762 norm:0.0012102591572329402 max memory_allocated 22566.46044921875 
[2025-02-28 18:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.8085395097732544 norm:0.0009699680376797915 max memory_allocated 22566.46044921875 
[2025-02-28 18:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.8057920336723328 norm:0.0008708285167813301 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.8036057353019714 norm:0.000840298249386251 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.8020381927490234 norm:0.0008080179104581475 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.8008798956871033 norm:0.0007859282777644694 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:54 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.8000619411468506 norm:0.000771966646425426 max memory_allocated 22566.46044921875 
[2025-02-28 18:22:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.7994328141212463 norm:0.0007708888733759522 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.7989457249641418 norm:0.0007621879340149462 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.7984845638275146 norm:0.0007490849820896983 max memory_allocated 22566.46044921875 
[2025-02-28 18:24:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.7981463074684143 norm:0.0007423693896271288 max memory_allocated 22566.46044921875 
[2025-02-28 18:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.7977937459945679 norm:0.000727525562979281 max memory_allocated 22566.46044921875 
[2025-02-28 18:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.7974671721458435 norm:0.0007118047215044498 max memory_allocated 22566.46044921875 
[2025-02-28 18:25:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.7971892952919006 norm:0.0007067688275128603 max memory_allocated 22566.46044921875 
[2025-02-28 18:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.7969505786895752 norm:0.0007031511631794274 max memory_allocated 22566.46044921875 
[2025-02-28 18:26:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.7967672944068909 norm:0.0006999557954259217 max memory_allocated 22566.46044921875 
[2025-02-28 18:27:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.7965753078460693 norm:0.0007047544931992888 max memory_allocated 22566.46044921875 
[2025-02-28 18:27:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 18:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.949192464351654 norm:0.009982341900467873 max memory_allocated 22566.63232421875 
[2025-02-28 18:28:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.9335777163505554 norm:0.005107151344418526 max memory_allocated 22566.63232421875 
[2025-02-28 18:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.9173871278762817 norm:0.0029767861124128103 max memory_allocated 22566.63232421875 
[2025-02-28 18:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.9110919237136841 norm:0.0021373142953962088 max memory_allocated 22566.63232421875 
[2025-02-28 18:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.9076619148254395 norm:0.001726458896882832 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.9044386744499207 norm:0.0013946800027042627 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.9019591212272644 norm:0.001168184680864215 max memory_allocated 22566.63232421875 
[2025-02-28 18:32:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.900043785572052 norm:0.0009500450687482953 max memory_allocated 22566.63232421875 
[2025-02-28 18:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.8984769582748413 norm:0.0007689950871281326 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.8975368142127991 norm:0.0006545112119056284 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.8968716859817505 norm:0.0006481201271526515 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.8963477611541748 norm:0.0006451138178817928 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.8959593772888184 norm:0.0006445778999477625 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.8956469297409058 norm:0.0006412044167518616 max memory_allocated 22566.63232421875 
[2025-02-28 18:36:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.895351767539978 norm:0.0006410773494280875 max memory_allocated 22566.63232421875 
[2025-02-28 18:36:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.8951221704483032 norm:0.0006375968223437667 max memory_allocated 22566.63232421875 
[2025-02-28 18:37:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.8949117064476013 norm:0.0006329368334263563 max memory_allocated 22566.63232421875 
[2025-02-28 18:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.894688606262207 norm:0.0006297313375398517 max memory_allocated 22566.63232421875 
[2025-02-28 18:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.8945382833480835 norm:0.0006321515538729727 max memory_allocated 22566.63232421875 
[2025-02-28 18:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.8944039940834045 norm:0.0006361529813148081 max memory_allocated 22566.63232421875 
[2025-02-28 18:39:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 18:39:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:1.082708716392517 norm:0.029971446841955185 max memory_allocated 22566.91943359375 
[2025-02-28 18:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:1.0629565715789795 norm:0.023074496537446976 max memory_allocated 22566.91943359375 
[2025-02-28 18:40:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:1.040945291519165 norm:0.01621154323220253 max memory_allocated 22566.91943359375 
[2025-02-28 18:41:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:1.031317114830017 norm:0.013209912925958633 max memory_allocated 22566.91943359375 
[2025-02-28 18:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:1.0263882875442505 norm:0.011159252375364304 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:1.021996259689331 norm:0.009291183203458786 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:1.0189896821975708 norm:0.008058522827923298 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:1.0167659521102905 norm:0.007297098636627197 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:1.0151393413543701 norm:0.006765981204807758 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:1.0140104293823242 norm:0.0064589050598442554 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:1.0130773782730103 norm:0.006285857874900103 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:1.0123251676559448 norm:0.006200573407113552 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:1.0115985870361328 norm:0.006164067424833775 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:1.010931372642517 norm:0.006063710432499647 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:1.010414481163025 norm:0.005866235587745905 max memory_allocated 22566.91943359375 
[2025-02-28 18:48:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:1.009977102279663 norm:0.00576888769865036 max memory_allocated 22566.91943359375 
[2025-02-28 18:48:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:1.009612798690796 norm:0.005741771310567856 max memory_allocated 22566.91943359375 
[2025-02-28 18:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:1.0094259977340698 norm:0.00574388587847352 max memory_allocated 22566.91943359375 
[2025-02-28 18:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:1.0089530944824219 norm:0.005620413459837437 max memory_allocated 22566.91943359375 
[2025-02-28 18:50:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:1.0086846351623535 norm:0.0055512613616883755 max memory_allocated 22566.91943359375 
[2025-02-28 18:50:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 18:50:30 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:51:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:1.2315694093704224 norm:0.030076025053858757 max memory_allocated 22567.09130859375 
[2025-02-28 18:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:1.2031753063201904 norm:0.023428160697221756 max memory_allocated 22567.09130859375 
[2025-02-28 18:52:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:1.176213264465332 norm:0.01704411767423153 max memory_allocated 22567.09130859375 
[2025-02-28 18:52:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:1.1630768775939941 norm:0.0140311848372221 max memory_allocated 22567.09130859375 
[2025-02-28 18:53:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:1.1553934812545776 norm:0.011436994187533855 max memory_allocated 22567.09130859375 
[2025-02-28 18:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:1.1499414443969727 norm:0.009660875424742699 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:1.146399974822998 norm:0.008807171136140823 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:1.144105076789856 norm:0.008096418343484402 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:1.1421724557876587 norm:0.007857365533709526 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:1.1409175395965576 norm:0.007510416209697723 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:1.1398067474365234 norm:0.007533402182161808 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:1.1390857696533203 norm:0.007399311289191246 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:1.138620138168335 norm:0.007851210422813892 max memory_allocated 22567.09130859375 
[2025-02-28 18:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:1.137773871421814 norm:0.007506422698497772 max memory_allocated 22567.09130859375 
[2025-02-28 18:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:1.1368961334228516 norm:0.007072189822793007 max memory_allocated 22567.09130859375 
[2025-02-28 18:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:1.1363723278045654 norm:0.006911206990480423 max memory_allocated 22567.09130859375 
[2025-02-28 19:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:1.1357380151748657 norm:0.0067011215724051 max memory_allocated 22567.09130859375 
[2025-02-28 19:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:1.1352810859680176 norm:0.006605189759284258 max memory_allocated 22567.09130859375 
[2025-02-28 19:01:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:1.1351534128189087 norm:0.006871902849525213 max memory_allocated 22567.09130859375 
[2025-02-28 19:01:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:1.1347275972366333 norm:0.006707463879138231 max memory_allocated 22567.09130859375 
[2025-02-28 19:01:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 19:01:55 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:02:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:2.7468392848968506 norm:0.5815678238868713 max memory_allocated 22567.26318359375 
[2025-02-28 19:03:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:2.9895198345184326 norm:1.5369210243225098 max memory_allocated 22567.26318359375 
[2025-02-28 19:03:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:2.450727939605713 norm:0.6287564635276794 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:1.8751789331436157 norm:0.2788260877132416 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:1.7909680604934692 norm:0.2114778459072113 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:1.768596887588501 norm:0.21446260809898376 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:1.756536602973938 norm:0.21181733906269073 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:1.7447715997695923 norm:0.19124042987823486 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:1.739571452140808 norm:0.19378161430358887 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:1.7276862859725952 norm:0.19400189816951752 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:1.7150907516479492 norm:0.18901313841342926 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:1.7064952850341797 norm:0.17754079401493073 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:1.6921708583831787 norm:0.1750953495502472 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:1.6864328384399414 norm:0.1530853807926178 max memory_allocated 22567.26318359375 
[2025-02-28 19:10:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:1.6808271408081055 norm:0.15553472936153412 max memory_allocated 22567.26318359375 
[2025-02-28 19:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:1.6820932626724243 norm:0.15309087932109833 max memory_allocated 22567.26318359375 
[2025-02-28 19:11:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:1.6809110641479492 norm:0.1387205868959427 max memory_allocated 22567.26318359375 
[2025-02-28 19:12:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:1.6774239540100098 norm:0.12303298711776733 max memory_allocated 22567.26318359375 
[2025-02-28 19:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:1.678110957145691 norm:0.1210356205701828 max memory_allocated 22567.26318359375 
[2025-02-28 19:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:1.6769909858703613 norm:0.10638339817523956 max memory_allocated 22567.26318359375 
[2025-02-28 19:13:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 19:13:20 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:3.54034686088562 norm:0.2840479612350464 max memory_allocated 22567.43505859375 
[2025-02-28 19:14:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:3.2549281120300293 norm:0.22323334217071533 max memory_allocated 22567.43505859375 
[2025-02-28 19:15:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:3.0049571990966797 norm:0.16932885348796844 max memory_allocated 22567.43505859375 
[2025-02-28 19:15:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:2.90483021736145 norm:0.1526487171649933 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:2.857977867126465 norm:0.15017706155776978 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:2.811495304107666 norm:0.13413111865520477 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:2.780832052230835 norm:0.12547951936721802 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:2.755589485168457 norm:0.1151958629488945 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:2.735940456390381 norm:0.11180831491947174 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:2.7214739322662354 norm:0.10800421237945557 max memory_allocated 22567.43505859375 
[2025-02-28 19:19:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:2.7048840522766113 norm:0.10174044966697693 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:2.6881916522979736 norm:0.09400761127471924 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:2.6765284538269043 norm:0.09171469509601593 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:2.6671907901763916 norm:0.0923173576593399 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:2.653909683227539 norm:0.0854615569114685 max memory_allocated 22567.43505859375 
[2025-02-28 19:22:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:2.6451363563537598 norm:0.08349405974149704 max memory_allocated 22567.43505859375 
[2025-02-28 19:22:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:2.638620138168335 norm:0.08054539561271667 max memory_allocated 22567.43505859375 
[2025-02-28 19:23:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:2.630826234817505 norm:0.08091995120048523 max memory_allocated 22567.43505859375 
[2025-02-28 19:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:2.625444173812866 norm:0.08135973662137985 max memory_allocated 22567.43505859375 
[2025-02-28 19:24:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:2.6219987869262695 norm:0.08100038766860962 max memory_allocated 22567.43505859375 
[2025-02-28 19:24:42 root] (main_calib_config2.py 380): INFO 21854.981402158737
[2025-02-28 19:24:47 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 19:25:58 root] (main_calib_config2.py 159): INFO wikitext2 : 8.500999450683594
[2025-02-28 19:25:58 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 19:27:47 root] (main_calib_config2.py 159): INFO c4 : 11.803873062133789
[2025-02-28 19:27:57 datasets.load] (load.py 1272): WARNING Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/hellaswag/512a66dd8b1b1643ab4a48aa4f150d04c91680da6a4096498a5e5f799623d5ae (last modified on Tue Feb 18 03:27:10 2025) since it couldn't be found locally at hellaswag., or remotely on the Hugging Face Hub.
[2025-02-28 21:11:20 root] (main_calib_config2.py 170): INFO {'wikitext2': 8.500999450683594, 'c4': 11.803873062133789, 'results': {'hellaswag': {'acc': 0.45200159330810596, 'acc_stderr': 0.004966736811010495, 'acc_norm': 0.5916152160924119, 'acc_norm_stderr': 0.004905304371090881}, 'arc_challenge': {'acc': 0.2977815699658703, 'acc_stderr': 0.013363080107244489, 'acc_norm': 0.3319112627986348, 'acc_norm_stderr': 0.013760988200880531}, 'piqa': {'acc': 0.6942328618063112, 'acc_stderr': 0.010749627366141636, 'acc_norm': 0.6991294885745375, 'acc_norm_stderr': 0.010700745724145972}, 'boolq': {'acc': 0.6376146788990825, 'acc_stderr': 0.00840730865586404}, 'winogrande': {'acc': 0.5714285714285714, 'acc_stderr': 0.013908353814606698}, 'arc_easy': {'acc': 0.563973063973064, 'acc_stderr': 0.010175459582759738, 'acc_norm': 0.44865319865319864, 'acc_norm_stderr': 0.010205540414612874}}, 'versions': {'hellaswag': 0, 'arc_challenge': 0, 'piqa': 0, 'boolq': 1, 'winogrande': 0, 'arc_easy': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
