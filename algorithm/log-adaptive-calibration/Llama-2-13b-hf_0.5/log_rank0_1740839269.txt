[2025-03-01 14:27:49 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.5', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.5.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-01 14:28:23 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-01 14:28:23 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.5.pkl
[2025-03-01 14:28:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-01 14:29:00 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.014134017750620842 norm:0.016326429322361946 max memory_allocated 29271.02001953125 
[2025-03-01 14:30:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.008116553537547588 norm:0.008286808617413044 max memory_allocated 29271.02001953125 
[2025-03-01 14:31:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.005948583595454693 norm:0.005681047216057777 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.005163388792425394 norm:0.004574790131300688 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0049283867701888084 norm:0.0038206190802156925 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.004675411153584719 norm:0.0032335659489035606 max memory_allocated 29271.02001953125 
[2025-03-01 14:34:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.004505385644733906 norm:0.002716982737183571 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.004472627770155668 norm:0.0024039677809923887 max memory_allocated 29271.02001953125 
[2025-03-01 14:36:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0043549612164497375 norm:0.0020913511980324984 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.004344819113612175 norm:0.001858185394667089 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.004255570005625486 norm:0.0016107637202367187 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.004234155640006065 norm:0.00151006446685642 max memory_allocated 29271.02001953125 
[2025-03-01 14:39:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.004225770942866802 norm:0.0014998181723058224 max memory_allocated 29271.02001953125 
[2025-03-01 14:40:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.00420740619301796 norm:0.0013629022287204862 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.004248461686074734 norm:0.0013609594898298383 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.00413689948618412 norm:0.0011670221574604511 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.004162934608757496 norm:0.0011585054453462362 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.004158436320722103 norm:0.0011164237512275577 max memory_allocated 29271.02001953125 
[2025-03-01 14:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0042012594640254974 norm:0.0011159077985212207 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.004184327553957701 norm:0.0011004583211615682 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-01 14:45:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:46:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.02975223772227764 norm:0.013582783751189709 max memory_allocated 29271.02001953125 
[2025-03-01 14:47:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.01887376792728901 norm:0.008075138553977013 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:06 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.01466126274317503 norm:0.005591090768575668 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.013394472189247608 norm:0.004409432411193848 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.012920526787638664 norm:0.003767864778637886 max memory_allocated 29271.02001953125 
[2025-03-01 14:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.012638759799301624 norm:0.0033625594805926085 max memory_allocated 29271.02001953125 
[2025-03-01 14:51:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.01241761539131403 norm:0.0029834487941116095 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.012265034019947052 norm:0.002668075729161501 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.01213049329817295 norm:0.0024306948762387037 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.012011606246232986 norm:0.0021612283308058977 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.011902970261871815 norm:0.001880917465314269 max memory_allocated 29271.02001953125 
[2025-03-01 14:55:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.011819093488156796 norm:0.001712668570689857 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.011768647469580173 norm:0.0016378313302993774 max memory_allocated 29271.02001953125 
[2025-03-01 14:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.01174356322735548 norm:0.0015930298250168562 max memory_allocated 29271.02001953125 
[2025-03-01 14:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.011722723953425884 norm:0.0016071331920102239 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.011773169040679932 norm:0.0014972856733947992 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.011727474629878998 norm:0.0014843069948256016 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.011769570410251617 norm:0.0014041115064173937 max memory_allocated 29271.02001953125 
[2025-03-01 15:01:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.011665751226246357 norm:0.0013441574992612004 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.011686884798109531 norm:0.0012615934247151017 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-01 15:02:21 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 15:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.03316795453429222 norm:0.011608559638261795 max memory_allocated 29271.02001953125 
[2025-03-01 15:04:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.02509515918791294 norm:0.008156617172062397 max memory_allocated 29271.02001953125 
[2025-03-01 15:04:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.021254519000649452 norm:0.005895652342587709 max memory_allocated 29271.02001953125 
[2025-03-01 15:05:38 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.019967898726463318 norm:0.004795275628566742 max memory_allocated 29271.02001953125 
[2025-03-01 15:06:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.019348416477441788 norm:0.003923921845853329 max memory_allocated 29271.02001953125 
[2025-03-01 15:07:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.018927421420812607 norm:0.0033103772439062595 max memory_allocated 29271.02001953125 
[2025-03-01 15:08:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.018528882414102554 norm:0.0027821436524391174 max memory_allocated 29271.02001953125 
[2025-03-01 15:08:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.018310898914933205 norm:0.002448193496093154 max memory_allocated 29271.02001953125 
[2025-03-01 15:09:45 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.01809116080403328 norm:0.0022763521410524845 max memory_allocated 29271.02001953125 
[2025-03-01 15:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.01797451265156269 norm:0.002045103581622243 max memory_allocated 29271.02001953125 
[2025-03-01 15:11:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.017883772030472755 norm:0.0019272308563813567 max memory_allocated 29271.02001953125 
[2025-03-01 15:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.017813745886087418 norm:0.0018569603562355042 max memory_allocated 29271.02001953125 
[2025-03-01 15:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.017839686945080757 norm:0.00183358252979815 max memory_allocated 29271.02001953125 
[2025-03-01 15:13:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.017823178321123123 norm:0.0017128832405433059 max memory_allocated 29271.02001953125 
[2025-03-01 15:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.01772109791636467 norm:0.0016979135107249022 max memory_allocated 29271.02001953125 
[2025-03-01 15:15:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.017737865447998047 norm:0.001681092893704772 max memory_allocated 29271.02001953125 
[2025-03-01 15:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.01774708926677704 norm:0.0016768480418249965 max memory_allocated 29271.02001953125 
[2025-03-01 15:17:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.017760055139660835 norm:0.001687143463641405 max memory_allocated 29271.02001953125 
[2025-03-01 15:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.017749682068824768 norm:0.0015885636676102877 max memory_allocated 29271.02001953125 
[2025-03-01 15:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.017720352858304977 norm:0.0015316734788939357 max memory_allocated 29271.02001953125 
[2025-03-01 15:19:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-01 15:19:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.18238331377506256 norm:0.017512504011392593 max memory_allocated 29271.43798828125 
[2025-03-01 15:20:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.13663770258426666 norm:0.010834143497049809 max memory_allocated 29271.43798828125 
[2025-03-01 15:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.09121838957071304 norm:0.0064397770911455154 max memory_allocated 29271.43798828125 
[2025-03-01 15:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.08220767229795456 norm:0.005471250042319298 max memory_allocated 29271.43798828125 
[2025-03-01 15:23:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.07678481936454773 norm:0.005815725773572922 max memory_allocated 29271.43798828125 
[2025-03-01 15:24:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.07297496497631073 norm:0.0056450581178069115 max memory_allocated 29271.43798828125 
[2025-03-01 15:24:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.07027260959148407 norm:0.00573422247543931 max memory_allocated 29271.43798828125 
[2025-03-01 15:25:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.06813651323318481 norm:0.005170872434973717 max memory_allocated 29271.43798828125 
[2025-03-01 15:26:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.0664827898144722 norm:0.004398107994347811 max memory_allocated 29271.43798828125 
[2025-03-01 15:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.06554024666547775 norm:0.005047404207289219 max memory_allocated 29271.43798828125 
[2025-03-01 15:28:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.06162022054195404 norm:0.003272715490311384 max memory_allocated 29271.43798828125 
[2025-03-01 15:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.05955677852034569 norm:0.00285495538264513 max memory_allocated 29271.43798828125 
[2025-03-01 15:29:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.060259945690631866 norm:0.0033605718053877354 max memory_allocated 29271.43798828125 
[2025-03-01 15:30:33 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.05924475938081741 norm:0.0031908219680190086 max memory_allocated 29271.43798828125 
[2025-03-01 15:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.05865182727575302 norm:0.0033077532425522804 max memory_allocated 29271.43798828125 
[2025-03-01 15:32:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.0593707375228405 norm:0.003306209808215499 max memory_allocated 29271.43798828125 
[2025-03-01 15:33:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.059540826827287674 norm:0.004223446827381849 max memory_allocated 29271.43798828125 
[2025-03-01 15:33:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.05976657569408417 norm:0.004124149214476347 max memory_allocated 29271.43798828125 
[2025-03-01 15:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.060531988739967346 norm:0.00446725869551301 max memory_allocated 29271.43798828125 
[2025-03-01 15:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.05926411226391792 norm:0.00392004381865263 max memory_allocated 29271.43798828125 
[2025-03-01 15:35:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-01 15:36:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.057878896594047546 norm:0.0016759805148467422 max memory_allocated 29271.43798828125 
[2025-03-01 15:37:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.04951159283518791 norm:0.0006257685017772019 max memory_allocated 29271.43798828125 
[2025-03-01 15:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.04553952440619469 norm:0.0003318039234727621 max memory_allocated 29271.43798828125 
[2025-03-01 15:39:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.04419922083616257 norm:0.00024243061488959938 max memory_allocated 29271.43798828125 
[2025-03-01 15:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.04347916692495346 norm:0.00020425941329449415 max memory_allocated 29271.43798828125 
[2025-03-01 15:40:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.04297497123479843 norm:0.00020361559290904552 max memory_allocated 29271.43798828125 
[2025-03-01 15:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.04260141775012016 norm:0.0001946562115335837 max memory_allocated 29271.43798828125 
[2025-03-01 15:42:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.04241762310266495 norm:0.00018621621711645275 max memory_allocated 29271.43798828125 
[2025-03-01 15:43:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.042318377643823624 norm:0.00017787613614927977 max memory_allocated 29271.43798828125 
[2025-03-01 15:43:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.04227256029844284 norm:0.00018734113837126642 max memory_allocated 29271.43798828125 
[2025-03-01 15:44:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.04223333299160004 norm:0.00018785908468998969 max memory_allocated 29271.43798828125 
[2025-03-01 15:45:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.04218709468841553 norm:0.00018993555568158627 max memory_allocated 29271.43798828125 
[2025-03-01 15:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.04214664548635483 norm:0.0001900548959383741 max memory_allocated 29271.43798828125 
[2025-03-01 15:47:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.042124535888433456 norm:0.00019110507855657488 max memory_allocated 29271.43798828125 
[2025-03-01 15:48:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.04210131987929344 norm:0.00018920082948170602 max memory_allocated 29271.43798828125 
[2025-03-01 15:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.04207136854529381 norm:0.0001870565756689757 max memory_allocated 29271.43798828125 
[2025-03-01 15:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.04205440729856491 norm:0.00018992781406268477 max memory_allocated 29271.43798828125 
[2025-03-01 15:50:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.042039770632982254 norm:0.00018674373859539628 max memory_allocated 29271.43798828125 
[2025-03-01 15:51:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.042033903300762177 norm:0.00018951865786220878 max memory_allocated 29271.43798828125 
[2025-03-01 15:52:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.042026299983263016 norm:0.00019093957962468266 max memory_allocated 29271.43798828125 
[2025-03-01 15:52:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-01 15:53:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.0644252747297287 norm:0.002039505634456873 max memory_allocated 29271.43798828125 
[2025-03-01 15:54:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.05339708924293518 norm:0.0008328169351443648 max memory_allocated 29271.43798828125 
[2025-03-01 15:55:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.04831620305776596 norm:0.0004464457160793245 max memory_allocated 29271.43798828125 
[2025-03-01 15:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.04667313024401665 norm:0.00029807680402882397 max memory_allocated 29271.43798828125 
[2025-03-01 15:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.045668505132198334 norm:0.0002325832610949874 max memory_allocated 29271.43798828125 
[2025-03-01 15:57:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.045013178139925 norm:0.0001927042903844267 max memory_allocated 29271.43798828125 
[2025-03-01 15:58:17 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.044649574905633926 norm:0.00017075428331736475 max memory_allocated 29271.43798828125 
[2025-03-01 15:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.04446118697524071 norm:0.00016014678112696856 max memory_allocated 29271.43798828125 
[2025-03-01 15:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.04435310885310173 norm:0.0001592692278791219 max memory_allocated 29271.43798828125 
[2025-03-01 16:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.044283173978328705 norm:0.00015262936358340085 max memory_allocated 29271.43798828125 
[2025-03-01 16:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.04422174394130707 norm:0.00015694797912146896 max memory_allocated 29271.43798828125 
[2025-03-01 16:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.044177763164043427 norm:0.00015520553279202431 max memory_allocated 29271.43798828125 
[2025-03-01 16:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.044128626585006714 norm:0.00014849880244582891 max memory_allocated 29271.43798828125 
[2025-03-01 16:04:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.04410511627793312 norm:0.0001486836263211444 max memory_allocated 29271.43798828125 
[2025-03-01 16:04:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.044090598821640015 norm:0.00015032158989924937 max memory_allocated 29271.43798828125 
[2025-03-01 16:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.04407666623592377 norm:0.00015220989007502794 max memory_allocated 29271.43798828125 
[2025-03-01 16:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.04405301436781883 norm:0.00015355429786723107 max memory_allocated 29271.43798828125 
[2025-03-01 16:07:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.04402858018875122 norm:0.0001456113823223859 max memory_allocated 29271.43798828125 
[2025-03-01 16:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.044020622968673706 norm:0.00015359399549197406 max memory_allocated 29271.43798828125 
[2025-03-01 16:08:57 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.044015903025865555 norm:0.0001564956910442561 max memory_allocated 29271.43798828125 
[2025-03-01 16:09:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-01 16:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.07364131510257721 norm:0.0035156896337866783 max memory_allocated 29272.00048828125 
[2025-03-01 16:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.059474099427461624 norm:0.0014184562023729086 max memory_allocated 29272.00048828125 
[2025-03-01 16:11:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.05275484174489975 norm:0.0007123941904865205 max memory_allocated 29272.00048828125 
[2025-03-01 16:12:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.05050677806138992 norm:0.00042778023635037243 max memory_allocated 29272.00048828125 
[2025-03-01 16:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.049222610890865326 norm:0.00030410123872570693 max memory_allocated 29272.00048828125 
[2025-03-01 16:14:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.04848472401499748 norm:0.00024395139189437032 max memory_allocated 29272.00048828125 
[2025-03-01 16:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.04805837571620941 norm:0.00021375143842305988 max memory_allocated 29272.00048828125 
[2025-03-01 16:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.04783693328499794 norm:0.0001954946928890422 max memory_allocated 29272.00048828125 
[2025-03-01 16:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.04770435765385628 norm:0.0001899285416584462 max memory_allocated 29272.00048828125 
[2025-03-01 16:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.04762676730751991 norm:0.0001864747318904847 max memory_allocated 29272.00048828125 
[2025-03-01 16:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.04756195843219757 norm:0.00018336990615352988 max memory_allocated 29272.00048828125 
[2025-03-01 16:19:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.04750950261950493 norm:0.0001830471446737647 max memory_allocated 29272.00048828125 
[2025-03-01 16:19:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.0474688895046711 norm:0.00017990187916439027 max memory_allocated 29272.00048828125 
[2025-03-01 16:20:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.04742009565234184 norm:0.00018406615708954632 max memory_allocated 29272.00048828125 
[2025-03-01 16:21:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.04738019406795502 norm:0.00018507210188545287 max memory_allocated 29272.00048828125 
[2025-03-01 16:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.047339603304862976 norm:0.00017804637900553644 max memory_allocated 29272.00048828125 
[2025-03-01 16:23:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.04733114317059517 norm:0.00018225064559374005 max memory_allocated 29272.00048828125 
[2025-03-01 16:24:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.04733269661664963 norm:0.00018154042481910437 max memory_allocated 29272.00048828125 
[2025-03-01 16:24:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.04731970280408859 norm:0.00019482681818772107 max memory_allocated 29272.00048828125 
[2025-03-01 16:25:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.04728781804442406 norm:0.00018220421043224633 max memory_allocated 29272.00048828125 
[2025-03-01 16:25:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-01 16:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.08941666781902313 norm:0.002372930757701397 max memory_allocated 29272.18798828125 
[2025-03-01 16:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.07174539566040039 norm:0.0009892055531963706 max memory_allocated 29272.18798828125 
[2025-03-01 16:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.06347253918647766 norm:0.000603340333327651 max memory_allocated 29272.18798828125 
[2025-03-01 16:29:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.060744646936655045 norm:0.00044082466047257185 max memory_allocated 29272.18798828125 
[2025-03-01 16:30:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.05942532792687416 norm:0.0003742398112080991 max memory_allocated 29272.18798828125 
[2025-03-01 16:30:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.0586031936109066 norm:0.000337507895892486 max memory_allocated 29272.18798828125 
[2025-03-01 16:31:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.05806886404752731 norm:0.000306608562823385 max memory_allocated 29272.18798828125 
[2025-03-01 16:32:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.05779063701629639 norm:0.0002982862642966211 max memory_allocated 29272.18798828125 
[2025-03-01 16:33:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.05758506432175636 norm:0.0002923564752563834 max memory_allocated 29272.18798828125 
[2025-03-01 16:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.057429373264312744 norm:0.00029767409432679415 max memory_allocated 29272.18798828125 
[2025-03-01 16:35:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.05732408165931702 norm:0.0002940918202511966 max memory_allocated 29272.18798828125 
[2025-03-01 16:35:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.05724708363413811 norm:0.00028350838692858815 max memory_allocated 29272.18798828125 
[2025-03-01 16:36:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.057148586958646774 norm:0.00027514633256942034 max memory_allocated 29272.18798828125 
[2025-03-01 16:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.05712568014860153 norm:0.0002762586227618158 max memory_allocated 29272.18798828125 
[2025-03-01 16:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.05706960707902908 norm:0.00027688537375070155 max memory_allocated 29272.18798828125 
[2025-03-01 16:39:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.057007938623428345 norm:0.00027803893317468464 max memory_allocated 29272.18798828125 
[2025-03-01 16:39:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.05696126073598862 norm:0.0002793005551211536 max memory_allocated 29272.18798828125 
[2025-03-01 16:40:47 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.05692092329263687 norm:0.00027294448227621615 max memory_allocated 29272.18798828125 
[2025-03-01 16:41:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.05691983923316002 norm:0.0002739989722613245 max memory_allocated 29272.18798828125 
[2025-03-01 16:42:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.05685621500015259 norm:0.00027357976068742573 max memory_allocated 29272.18798828125 
[2025-03-01 16:42:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-01 16:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.09243740886449814 norm:0.0026431959122419357 max memory_allocated 29272.37548828125 
[2025-03-01 16:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.0768829807639122 norm:0.0013312269002199173 max memory_allocated 29272.37548828125 
[2025-03-01 16:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.06901002675294876 norm:0.0008358872728422284 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.06612637639045715 norm:0.0006052472162991762 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.06445625424385071 norm:0.0004793580446857959 max memory_allocated 29272.37548828125 
[2025-03-01 16:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.06349615752696991 norm:0.00041175817023031414 max memory_allocated 29272.37548828125 
[2025-03-01 16:48:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.06292476505041122 norm:0.00036691955756396055 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.06260459125041962 norm:0.00034360907739028335 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.06237749010324478 norm:0.0003159334301017225 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.06220155581831932 norm:0.0003022616438101977 max memory_allocated 29272.37548828125 
[2025-03-01 16:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.06207671016454697 norm:0.0002898937673307955 max memory_allocated 29272.37548828125 
[2025-03-01 16:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.061969589442014694 norm:0.00028318926342763007 max memory_allocated 29272.37548828125 
[2025-03-01 16:53:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.06187327951192856 norm:0.0002810597943607718 max memory_allocated 29272.37548828125 
[2025-03-01 16:54:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.06181494519114494 norm:0.0002719973854254931 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.06177876889705658 norm:0.00026797284954227507 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.06173315644264221 norm:0.00026482754037715495 max memory_allocated 29272.37548828125 
[2025-03-01 16:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.06170731782913208 norm:0.0002617135760374367 max memory_allocated 29272.37548828125 
[2025-03-01 16:57:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.06168287992477417 norm:0.0002606758498586714 max memory_allocated 29272.37548828125 
[2025-03-01 16:58:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.06164063885807991 norm:0.0002576950937509537 max memory_allocated 29272.37548828125 
[2025-03-01 16:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.06162070482969284 norm:0.00025486625963822007 max memory_allocated 29272.37548828125 
[2025-03-01 16:59:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-01 17:00:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.12385059893131256 norm:0.0043327584862709045 max memory_allocated 29272.56298828125 
[2025-03-01 17:01:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.09516238421201706 norm:0.0019977902993559837 max memory_allocated 29272.56298828125 
[2025-03-01 17:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.08068805187940598 norm:0.0010427357628941536 max memory_allocated 29272.56298828125 
[2025-03-01 17:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.07637907564640045 norm:0.0007121029775589705 max memory_allocated 29272.56298828125 
[2025-03-01 17:03:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.07416762411594391 norm:0.0005518589168787003 max memory_allocated 29272.56298828125 
[2025-03-01 17:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.07288936525583267 norm:0.00046015993575565517 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.07209353893995285 norm:0.0004137404030188918 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.07154890894889832 norm:0.00038552330806851387 max memory_allocated 29272.56298828125 
[2025-03-01 17:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.07119058072566986 norm:0.0003677152853924781 max memory_allocated 29272.56298828125 
[2025-03-01 17:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.07091699540615082 norm:0.000349120469763875 max memory_allocated 29272.56298828125 
[2025-03-01 17:08:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.07068575173616409 norm:0.00033158110454678535 max memory_allocated 29272.56298828125 
[2025-03-01 17:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.07056185603141785 norm:0.0003172077122144401 max memory_allocated 29272.56298828125 
[2025-03-01 17:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.07042472064495087 norm:0.0003084528725594282 max memory_allocated 29272.56298828125 
[2025-03-01 17:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.07031097263097763 norm:0.0003046309866476804 max memory_allocated 29272.56298828125 
[2025-03-01 17:11:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.07023512572050095 norm:0.00030019512632861733 max memory_allocated 29272.56298828125 
[2025-03-01 17:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.07014932483434677 norm:0.000288324779830873 max memory_allocated 29272.56298828125 
[2025-03-01 17:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.07004743814468384 norm:0.00028236451908014715 max memory_allocated 29272.56298828125 
[2025-03-01 17:14:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.0699617937207222 norm:0.0002824532857630402 max memory_allocated 29272.56298828125 
[2025-03-01 17:14:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.06989601254463196 norm:0.00028006668435409665 max memory_allocated 29272.56298828125 
[2025-03-01 17:15:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.06985515356063843 norm:0.0002780213253572583 max memory_allocated 29272.56298828125 
[2025-03-01 17:16:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-01 17:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.11236384510993958 norm:0.0023903686087578535 max memory_allocated 29272.75048828125 
[2025-03-01 17:17:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.09394999593496323 norm:0.001153896446339786 max memory_allocated 29272.75048828125 
[2025-03-01 17:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.08431262522935867 norm:0.0006635701865889132 max memory_allocated 29272.75048828125 
[2025-03-01 17:19:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.08064350485801697 norm:0.00047121429815888405 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.078819639980793 norm:0.00037124473601579666 max memory_allocated 29272.75048828125 
[2025-03-01 17:21:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.07776997983455658 norm:0.00032000328064896166 max memory_allocated 29272.75048828125 
[2025-03-01 17:21:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.07720445096492767 norm:0.0002937573008239269 max memory_allocated 29272.75048828125 
[2025-03-01 17:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.0768582671880722 norm:0.00027369667077437043 max memory_allocated 29272.75048828125 
[2025-03-01 17:23:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.0766497477889061 norm:0.00026080303359776735 max memory_allocated 29272.75048828125 
[2025-03-01 17:24:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.07649633288383484 norm:0.00025123480008915067 max memory_allocated 29272.75048828125 
[2025-03-01 17:25:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.07636599987745285 norm:0.0002429891173960641 max memory_allocated 29272.75048828125 
[2025-03-01 17:25:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.07627139985561371 norm:0.00023527354642283171 max memory_allocated 29272.75048828125 
[2025-03-01 17:26:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.07618556916713715 norm:0.00023207861522678286 max memory_allocated 29272.75048828125 
[2025-03-01 17:27:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.07611742615699768 norm:0.00023246525961440057 max memory_allocated 29272.75048828125 
[2025-03-01 17:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.0760602205991745 norm:0.00022769076167605817 max memory_allocated 29272.75048828125 
[2025-03-01 17:29:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.07601208984851837 norm:0.0002257216692669317 max memory_allocated 29272.75048828125 
[2025-03-01 17:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.07594265043735504 norm:0.00022279948461800814 max memory_allocated 29272.75048828125 
[2025-03-01 17:30:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.07591421902179718 norm:0.00022403406910598278 max memory_allocated 29272.75048828125 
[2025-03-01 17:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.07587142288684845 norm:0.00022136179904919118 max memory_allocated 29272.75048828125 
[2025-03-01 17:32:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.0758310854434967 norm:0.00021933105017524213 max memory_allocated 29272.75048828125 
[2025-03-01 17:32:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-01 17:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.11640763282775879 norm:0.0020541937556117773 max memory_allocated 29272.93798828125 
[2025-03-01 17:34:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.09837916493415833 norm:0.0009304019040428102 max memory_allocated 29272.93798828125 
[2025-03-01 17:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.08907110244035721 norm:0.0005092251230962574 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.08583924919366837 norm:0.0003611996944528073 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.08419966697692871 norm:0.0002980270655825734 max memory_allocated 29272.93798828125 
[2025-03-01 17:37:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.08332911133766174 norm:0.0002659792953636497 max memory_allocated 29272.93798828125 
[2025-03-01 17:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.08277381956577301 norm:0.00024709742865525186 max memory_allocated 29272.93798828125 
[2025-03-01 17:39:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.0824338048696518 norm:0.00023311199038289487 max memory_allocated 29272.93798828125 
[2025-03-01 17:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.08225814998149872 norm:0.00022969546262174845 max memory_allocated 29272.93798828125 
[2025-03-01 17:41:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.08213149756193161 norm:0.00022080830240156502 max memory_allocated 29272.93798828125 
[2025-03-01 17:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.08203304558992386 norm:0.0002201405877713114 max memory_allocated 29272.93798828125 
[2025-03-01 17:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.0819484069943428 norm:0.0002168294449802488 max memory_allocated 29272.93798828125 
[2025-03-01 17:43:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.08185140788555145 norm:0.00021281774388626218 max memory_allocated 29272.93798828125 
[2025-03-01 17:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.0817895457148552 norm:0.00020800047786906362 max memory_allocated 29272.93798828125 
[2025-03-01 17:45:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.08175821602344513 norm:0.00020634685643017292 max memory_allocated 29272.93798828125 
[2025-03-01 17:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.08169959485530853 norm:0.00020898529328405857 max memory_allocated 29272.93798828125 
[2025-03-01 17:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.08167809247970581 norm:0.0002111399226123467 max memory_allocated 29272.93798828125 
[2025-03-01 17:47:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.08163587749004364 norm:0.0002091063215630129 max memory_allocated 29272.93798828125 
[2025-03-01 17:48:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.08162248134613037 norm:0.00021184473007451743 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.0815877616405487 norm:0.00021510626538656652 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-01 17:50:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.12386578321456909 norm:0.0029054642654955387 max memory_allocated 29273.12548828125 
[2025-03-01 17:51:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.10337074100971222 norm:0.001207941211760044 max memory_allocated 29273.12548828125 
[2025-03-01 17:51:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.09269797056913376 norm:0.0006162270437926054 max memory_allocated 29273.12548828125 
[2025-03-01 17:52:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.08916454762220383 norm:0.00042635417776182294 max memory_allocated 29273.12548828125 
[2025-03-01 17:53:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.08755995333194733 norm:0.0003406169998925179 max memory_allocated 29273.12548828125 
[2025-03-01 17:54:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.08662790060043335 norm:0.00029357304447330534 max memory_allocated 29273.12548828125 
[2025-03-01 17:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.08606816083192825 norm:0.0002621696621645242 max memory_allocated 29273.12548828125 
[2025-03-01 17:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.0857439637184143 norm:0.0002487257297616452 max memory_allocated 29273.12548828125 
[2025-03-01 17:56:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.08552984148263931 norm:0.00023962648992892355 max memory_allocated 29273.12548828125 
[2025-03-01 17:57:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.08533772826194763 norm:0.00022957895998843014 max memory_allocated 29273.12548828125 
[2025-03-01 17:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.0852082371711731 norm:0.00021678580378647894 max memory_allocated 29273.12548828125 
[2025-03-01 17:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.08511433005332947 norm:0.0002122924051946029 max memory_allocated 29273.12548828125 
[2025-03-01 18:00:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.08502228558063507 norm:0.000205208474653773 max memory_allocated 29273.12548828125 
[2025-03-01 18:00:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.08494449406862259 norm:0.00020155683159828186 max memory_allocated 29273.12548828125 
[2025-03-01 18:01:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.08489487320184708 norm:0.00019917009922210127 max memory_allocated 29273.12548828125 
[2025-03-01 18:02:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.08485349267721176 norm:0.00019765281467698514 max memory_allocated 29273.12548828125 
[2025-03-01 18:03:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.08479684591293335 norm:0.0001953902537934482 max memory_allocated 29273.12548828125 
[2025-03-01 18:04:15 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.08474130928516388 norm:0.00019555345352273434 max memory_allocated 29273.12548828125 
[2025-03-01 18:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.08470054715871811 norm:0.00019482178322505206 max memory_allocated 29273.12548828125 
[2025-03-01 18:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.08466816693544388 norm:0.00019215296197216958 max memory_allocated 29273.12548828125 
[2025-03-01 18:06:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-01 18:07:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.11922945082187653 norm:0.0020098744425922632 max memory_allocated 29273.31298828125 
[2025-03-01 18:07:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.10346509516239166 norm:0.0008648823131807148 max memory_allocated 29273.31298828125 
[2025-03-01 18:08:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.09531406313180923 norm:0.0005161263979971409 max memory_allocated 29273.31298828125 
[2025-03-01 18:09:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.09212009608745575 norm:0.00038171716732904315 max memory_allocated 29273.31298828125 
[2025-03-01 18:10:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.09048985689878464 norm:0.0003112686099484563 max memory_allocated 29273.31298828125 
[2025-03-01 18:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.08951244503259659 norm:0.0002712542191147804 max memory_allocated 29273.31298828125 
[2025-03-01 18:11:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.08898595720529556 norm:0.0002519905974622816 max memory_allocated 29273.31298828125 
[2025-03-01 18:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.08866625279188156 norm:0.00023874449834693223 max memory_allocated 29273.31298828125 
[2025-03-01 18:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.08843466639518738 norm:0.0002286340604769066 max memory_allocated 29273.31298828125 
[2025-03-01 18:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.08828258514404297 norm:0.0002238104643765837 max memory_allocated 29273.31298828125 
[2025-03-01 18:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.08815521001815796 norm:0.00021416781237348914 max memory_allocated 29273.31298828125 
[2025-03-01 18:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.08804374933242798 norm:0.00020662584574893117 max memory_allocated 29273.31298828125 
[2025-03-01 18:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.08794045448303223 norm:0.00020672210666816682 max memory_allocated 29273.31298828125 
[2025-03-01 18:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.08786162734031677 norm:0.0002047437010332942 max memory_allocated 29273.31298828125 
[2025-03-01 18:18:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.08780346810817719 norm:0.0002036186633631587 max memory_allocated 29273.31298828125 
[2025-03-01 18:19:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.08774037659168243 norm:0.00019810943922493607 max memory_allocated 29273.31298828125 
[2025-03-01 18:20:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.08770675212144852 norm:0.00019587115093600005 max memory_allocated 29273.31298828125 
[2025-03-01 18:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.08768026530742645 norm:0.0001957813074113801 max memory_allocated 29273.31298828125 
[2025-03-01 18:21:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.0876593291759491 norm:0.00019872911798302084 max memory_allocated 29273.31298828125 
[2025-03-01 18:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.08762216567993164 norm:0.0001939109351951629 max memory_allocated 29273.31298828125 
[2025-03-01 18:22:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-01 18:23:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.12268465012311935 norm:0.001644645701162517 max memory_allocated 29273.50048828125 
[2025-03-01 18:24:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.10821491479873657 norm:0.0008458643569611013 max memory_allocated 29273.50048828125 
[2025-03-01 18:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.09976202994585037 norm:0.0005202180473133922 max memory_allocated 29273.50048828125 
[2025-03-01 18:26:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.09629491716623306 norm:0.0003673534083645791 max memory_allocated 29273.50048828125 
[2025-03-01 18:27:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.09481312334537506 norm:0.0003042839525733143 max memory_allocated 29273.50048828125 
[2025-03-01 18:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.09395644068717957 norm:0.0002701135235838592 max memory_allocated 29273.50048828125 
[2025-03-01 18:28:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.09341610223054886 norm:0.0002506275486666709 max memory_allocated 29273.50048828125 
[2025-03-01 18:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.09307736903429031 norm:0.0002369205903960392 max memory_allocated 29273.50048828125 
[2025-03-01 18:30:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.09283336997032166 norm:0.00023022317327558994 max memory_allocated 29273.50048828125 
[2025-03-01 18:31:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.09270024299621582 norm:0.0002270216355100274 max memory_allocated 29273.50048828125 
[2025-03-01 18:31:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.09258083254098892 norm:0.0002213504194514826 max memory_allocated 29273.50048828125 
[2025-03-01 18:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.09249794483184814 norm:0.0002150873770006001 max memory_allocated 29273.50048828125 
[2025-03-01 18:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.0924205407500267 norm:0.00021431592176668346 max memory_allocated 29273.50048828125 
[2025-03-01 18:34:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.09234244376420975 norm:0.00021091301459819078 max memory_allocated 29273.50048828125 
[2025-03-01 18:35:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.09231050312519073 norm:0.00021076940174680203 max memory_allocated 29273.50048828125 
[2025-03-01 18:36:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.0922573059797287 norm:0.00020913701155222952 max memory_allocated 29273.50048828125 
[2025-03-01 18:36:50 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.09221670031547546 norm:0.0002073410141747445 max memory_allocated 29273.50048828125 
[2025-03-01 18:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.0921701192855835 norm:0.0002044593566097319 max memory_allocated 29273.50048828125 
[2025-03-01 18:38:29 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.09215521067380905 norm:0.00020799148478545249 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.09211846441030502 norm:0.00020820021745748818 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-01 18:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.1213286742568016 norm:0.0020308089442551136 max memory_allocated 29273.68798828125 
[2025-03-01 18:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.10771362483501434 norm:0.0008874816121533513 max memory_allocated 29273.68798828125 
[2025-03-01 18:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.09940191358327866 norm:0.00045848218724131584 max memory_allocated 29273.68798828125 
[2025-03-01 18:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.09645075350999832 norm:0.0003194322343915701 max memory_allocated 29273.68798828125 
[2025-03-01 18:43:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.09508712589740753 norm:0.0002728975669015199 max memory_allocated 29273.68798828125 
[2025-03-01 18:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.09426302462816238 norm:0.0002446277067065239 max memory_allocated 29273.68798828125 
[2025-03-01 18:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.09379024803638458 norm:0.00023058021906763315 max memory_allocated 29273.68798828125 
[2025-03-01 18:46:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.09349490702152252 norm:0.00022052571875974536 max memory_allocated 29273.68798828125 
[2025-03-01 18:46:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.09327627718448639 norm:0.00021145599021110684 max memory_allocated 29273.68798828125 
[2025-03-01 18:47:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.09311600029468536 norm:0.00020698511798400432 max memory_allocated 29273.68798828125 
[2025-03-01 18:48:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.09298604726791382 norm:0.00020200647122692317 max memory_allocated 29273.68798828125 
[2025-03-01 18:49:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.09289979934692383 norm:0.00019937810429837555 max memory_allocated 29273.68798828125 
[2025-03-01 18:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.0928117036819458 norm:0.00019777429406531155 max memory_allocated 29273.68798828125 
[2025-03-01 18:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.09275447577238083 norm:0.00019704579608514905 max memory_allocated 29273.68798828125 
[2025-03-01 18:51:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.09269914031028748 norm:0.00019635673379525542 max memory_allocated 29273.68798828125 
[2025-03-01 18:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.09264485538005829 norm:0.00019527619588188827 max memory_allocated 29273.68798828125 
[2025-03-01 18:53:32 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.09259943664073944 norm:0.0001962479145731777 max memory_allocated 29273.68798828125 
[2025-03-01 18:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.09256472438573837 norm:0.00019352631352376193 max memory_allocated 29273.68798828125 
[2025-03-01 18:55:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.09253116697072983 norm:0.00019171592430211604 max memory_allocated 29273.68798828125 
[2025-03-01 18:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.0925106629729271 norm:0.00019288584007881582 max memory_allocated 29273.68798828125 
[2025-03-01 18:56:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-01 18:57:07 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.12316951155662537 norm:0.001810764311812818 max memory_allocated 29273.87548828125 
[2025-03-01 18:57:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.10976238548755646 norm:0.0008040126995183527 max memory_allocated 29273.87548828125 
[2025-03-01 18:58:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.10151149332523346 norm:0.0004780611488968134 max memory_allocated 29273.87548828125 
[2025-03-01 18:59:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.09848781675100327 norm:0.0003416472172830254 max memory_allocated 29273.87548828125 
[2025-03-01 19:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.09703431278467178 norm:0.00029496318893507123 max memory_allocated 29273.87548828125 
[2025-03-01 19:01:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.09620197117328644 norm:0.0002703264763113111 max memory_allocated 29273.87548828125 
[2025-03-01 19:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.09564635902643204 norm:0.0002528855693526566 max memory_allocated 29273.87548828125 
[2025-03-01 19:02:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.09530803561210632 norm:0.00024380607646889985 max memory_allocated 29273.87548828125 
[2025-03-01 19:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.09508472681045532 norm:0.0002390153968008235 max memory_allocated 29273.87548828125 
[2025-03-01 19:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.09488590061664581 norm:0.00023084651911631227 max memory_allocated 29273.87548828125 
[2025-03-01 19:05:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.09474082291126251 norm:0.00022389650985132903 max memory_allocated 29273.87548828125 
[2025-03-01 19:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.09464199095964432 norm:0.00022204899869393557 max memory_allocated 29273.87548828125 
[2025-03-01 19:06:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.09455155581235886 norm:0.0002221875183749944 max memory_allocated 29273.87548828125 
[2025-03-01 19:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.09447453916072845 norm:0.00021375063806772232 max memory_allocated 29273.87548828125 
[2025-03-01 19:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.09439820796251297 norm:0.00020539906108751893 max memory_allocated 29273.87548828125 
[2025-03-01 19:09:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.09432896226644516 norm:0.00020730035612359643 max memory_allocated 29273.87548828125 
[2025-03-01 19:10:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.09426945447921753 norm:0.00020615551329683512 max memory_allocated 29273.87548828125 
[2025-03-01 19:11:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.09423299133777618 norm:0.0002059972903225571 max memory_allocated 29273.87548828125 
[2025-03-01 19:11:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.09417761117219925 norm:0.00020148197654634714 max memory_allocated 29273.87548828125 
[2025-03-01 19:12:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.09412936866283417 norm:0.00019848920055665076 max memory_allocated 29273.87548828125 
[2025-03-01 19:12:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-01 19:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.11369787156581879 norm:0.002933705458417535 max memory_allocated 29274.06298828125 
[2025-03-01 19:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.1036805510520935 norm:0.0014517984818667173 max memory_allocated 29274.06298828125 
[2025-03-01 19:15:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.09748180210590363 norm:0.0008606649353168905 max memory_allocated 29274.06298828125 
[2025-03-01 19:16:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.09527366608381271 norm:0.0005844752304255962 max memory_allocated 29274.06298828125 
[2025-03-01 19:17:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.09400880336761475 norm:0.0004416125302668661 max memory_allocated 29274.06298828125 
[2025-03-01 19:17:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.09317398816347122 norm:0.00035256840055808425 max memory_allocated 29274.06298828125 
[2025-03-01 19:18:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.09268154948949814 norm:0.0002986765466630459 max memory_allocated 29274.06298828125 
[2025-03-01 19:19:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.09238410741090775 norm:0.0002632177493069321 max memory_allocated 29274.06298828125 
[2025-03-01 19:20:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.0921693965792656 norm:0.00023937963123898953 max memory_allocated 29274.06298828125 
[2025-03-01 19:21:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.09202400594949722 norm:0.0002226150973001495 max memory_allocated 29274.06298828125 
[2025-03-01 19:22:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.0919220894575119 norm:0.0002092851500492543 max memory_allocated 29274.06298828125 
[2025-03-01 19:22:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.09183993190526962 norm:0.00019928129040636122 max memory_allocated 29274.06298828125 
[2025-03-01 19:23:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.0917612835764885 norm:0.0001907872938318178 max memory_allocated 29274.06298828125 
[2025-03-01 19:24:28 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.09171251952648163 norm:0.0001856657472671941 max memory_allocated 29274.06298828125 
[2025-03-01 19:25:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.09166668355464935 norm:0.00018266192637383938 max memory_allocated 29274.06298828125 
[2025-03-01 19:26:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.09163828194141388 norm:0.00017564457084517926 max memory_allocated 29274.06298828125 
[2025-03-01 19:26:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.09160147607326508 norm:0.0001714216632535681 max memory_allocated 29274.06298828125 
[2025-03-01 19:27:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.09155955165624619 norm:0.00016923439397942275 max memory_allocated 29274.06298828125 
[2025-03-01 19:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.09154091030359268 norm:0.00017118538380600512 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.09152517467737198 norm:0.00017045701679307967 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-01 19:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.1107867881655693 norm:0.0014529373729601502 max memory_allocated 29274.25048828125 
[2025-03-01 19:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.10230406373739243 norm:0.0006952871335670352 max memory_allocated 29274.25048828125 
[2025-03-01 19:32:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.09716849029064178 norm:0.0004217753012198955 max memory_allocated 29274.25048828125 
[2025-03-01 19:32:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.0954420194029808 norm:0.0002999745775014162 max memory_allocated 29274.25048828125 
[2025-03-01 19:33:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.09435582160949707 norm:0.0002331495488760993 max memory_allocated 29274.25048828125 
[2025-03-01 19:34:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.09361226856708527 norm:0.0001943141542142257 max memory_allocated 29274.25048828125 
[2025-03-01 19:35:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.09313709288835526 norm:0.0001690266653895378 max memory_allocated 29274.25048828125 
[2025-03-01 19:36:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.09288831055164337 norm:0.00015492152306251228 max memory_allocated 29274.25048828125 
[2025-03-01 19:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.09273631870746613 norm:0.00014390048454515636 max memory_allocated 29274.25048828125 
[2025-03-01 19:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.09259659051895142 norm:0.0001358819572487846 max memory_allocated 29274.25048828125 
[2025-03-01 19:38:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.0925157442688942 norm:0.00013221395784057677 max memory_allocated 29274.25048828125 
[2025-03-01 19:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.0924508199095726 norm:0.00013039918849244714 max memory_allocated 29274.25048828125 
[2025-03-01 19:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.0923764705657959 norm:0.00012532895198091865 max memory_allocated 29274.25048828125 
[2025-03-01 19:41:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.09231897443532944 norm:0.00012306051212362945 max memory_allocated 29274.25048828125 
[2025-03-01 19:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.09228269010782242 norm:0.0001228033797815442 max memory_allocated 29274.25048828125 
[2025-03-01 19:42:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.0922379195690155 norm:0.0001195623044623062 max memory_allocated 29274.25048828125 
[2025-03-01 19:43:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.0922025740146637 norm:0.0001171520707430318 max memory_allocated 29274.25048828125 
[2025-03-01 19:44:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.09218155592679977 norm:0.00011725533113349229 max memory_allocated 29274.25048828125 
[2025-03-01 19:45:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.09215335547924042 norm:0.00011631948291324079 max memory_allocated 29274.25048828125 
[2025-03-01 19:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.09212746471166611 norm:0.00011466475552879274 max memory_allocated 29274.25048828125 
[2025-03-01 19:46:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-01 19:47:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.11231692880392075 norm:0.0010351280216127634 max memory_allocated 29274.43798828125 
[2025-03-01 19:48:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.10494395345449448 norm:0.0005119048291817307 max memory_allocated 29274.43798828125 
[2025-03-01 19:48:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.09985769540071487 norm:0.0003118275781162083 max memory_allocated 29274.43798828125 
[2025-03-01 19:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.09826678782701492 norm:0.00022287511092144996 max memory_allocated 29274.43798828125 
[2025-03-01 19:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.09728294610977173 norm:0.000180395960342139 max memory_allocated 29274.43798828125 
[2025-03-01 19:51:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.09661306440830231 norm:0.00015922370948828757 max memory_allocated 29274.43798828125 
[2025-03-01 19:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.09619413316249847 norm:0.0001431173732271418 max memory_allocated 29274.43798828125 
[2025-03-01 19:52:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.09594937413930893 norm:0.00013200148532632738 max memory_allocated 29274.43798828125 
[2025-03-01 19:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.09579493850469589 norm:0.00012540222087409347 max memory_allocated 29274.43798828125 
[2025-03-01 19:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.095694899559021 norm:0.00012268566933926195 max memory_allocated 29274.43798828125 
[2025-03-01 19:55:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.09561548382043839 norm:0.00011924390855710953 max memory_allocated 29274.43798828125 
[2025-03-01 19:56:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.09556278586387634 norm:0.00011725517106242478 max memory_allocated 29274.43798828125 
[2025-03-01 19:57:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.09550155699253082 norm:0.00011588623601710424 max memory_allocated 29274.43798828125 
[2025-03-01 19:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.09543967247009277 norm:0.00011244318739045411 max memory_allocated 29274.43798828125 
[2025-03-01 19:58:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.09540001302957535 norm:0.00011315101437503472 max memory_allocated 29274.43798828125 
[2025-03-01 19:59:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.09535382688045502 norm:0.00011067403829656541 max memory_allocated 29274.43798828125 
[2025-03-01 20:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.09532015025615692 norm:0.0001112788449972868 max memory_allocated 29274.43798828125 
[2025-03-01 20:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.0952945277094841 norm:0.00011135371460113674 max memory_allocated 29274.43798828125 
[2025-03-01 20:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.09526361525058746 norm:0.00011096339585492387 max memory_allocated 29274.43798828125 
[2025-03-01 20:02:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.0952429249882698 norm:0.0001099899600376375 max memory_allocated 29274.43798828125 
[2025-03-01 20:03:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-01 20:03:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.11624587327241898 norm:0.0010275290114805102 max memory_allocated 29274.62548828125 
[2025-03-01 20:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.10891158878803253 norm:0.0004965214757248759 max memory_allocated 29274.62548828125 
[2025-03-01 20:05:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.10368555784225464 norm:0.0003006869519595057 max memory_allocated 29274.62548828125 
[2025-03-01 20:06:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.10206727683544159 norm:0.00021477592235896736 max memory_allocated 29274.62548828125 
[2025-03-01 20:07:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.10110791027545929 norm:0.0001732499076751992 max memory_allocated 29274.62548828125 
[2025-03-01 20:08:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.1003839448094368 norm:0.00014945272414479405 max memory_allocated 29274.62548828125 
[2025-03-01 20:08:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.09994509816169739 norm:0.00013627955922856927 max memory_allocated 29274.62548828125 
[2025-03-01 20:09:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.09973257035017014 norm:0.0001294791727559641 max memory_allocated 29274.62548828125 
[2025-03-01 20:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.09958599507808685 norm:0.00012187259562779218 max memory_allocated 29274.62548828125 
[2025-03-01 20:11:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.09950387477874756 norm:0.00011929066386073828 max memory_allocated 29274.62548828125 
[2025-03-01 20:12:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.09941529482603073 norm:0.00011530855408636853 max memory_allocated 29274.62548828125 
[2025-03-01 20:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.09933395683765411 norm:0.0001117871142923832 max memory_allocated 29274.62548828125 
[2025-03-01 20:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.09927397966384888 norm:0.00011284988431725651 max memory_allocated 29274.62548828125 
[2025-03-01 20:14:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.09924303740262985 norm:0.00010968201968353242 max memory_allocated 29274.62548828125 
[2025-03-01 20:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.09920435398817062 norm:0.0001086246338672936 max memory_allocated 29274.62548828125 
[2025-03-01 20:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.09917328506708145 norm:0.00010826296056620777 max memory_allocated 29274.62548828125 
[2025-03-01 20:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.09914572536945343 norm:0.00010846552322618663 max memory_allocated 29274.62548828125 
[2025-03-01 20:17:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.09912126511335373 norm:0.00010810881212819368 max memory_allocated 29274.62548828125 
[2025-03-01 20:18:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.09909530729055405 norm:0.00010889724944718182 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.09906633198261261 norm:0.00010686599125619978 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-01 20:20:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.12445835024118423 norm:0.0012471125228330493 max memory_allocated 29274.81298828125 
[2025-03-01 20:21:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.11627180874347687 norm:0.0006362830172292888 max memory_allocated 29274.81298828125 
[2025-03-01 20:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.11056362092494965 norm:0.0003980807086918503 max memory_allocated 29274.81298828125 
[2025-03-01 20:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.10886038839817047 norm:0.0002871456672437489 max memory_allocated 29274.81298828125 
[2025-03-01 20:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.10777739435434341 norm:0.00023160995624493808 max memory_allocated 29274.81298828125 
[2025-03-01 20:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.10700484365224838 norm:0.00019791777594946325 max memory_allocated 29274.81298828125 
[2025-03-01 20:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.10651762783527374 norm:0.00017966372251976281 max memory_allocated 29274.81298828125 
[2025-03-01 20:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.10623089969158173 norm:0.0001649166370043531 max memory_allocated 29274.81298828125 
[2025-03-01 20:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.1060602217912674 norm:0.0001564803533256054 max memory_allocated 29274.81298828125 
[2025-03-01 20:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.1059325709939003 norm:0.00015052575326990336 max memory_allocated 29274.81298828125 
[2025-03-01 20:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.10582104325294495 norm:0.00014369671407621354 max memory_allocated 29274.81298828125 
[2025-03-01 20:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.10573669523000717 norm:0.00013828912051394582 max memory_allocated 29274.81298828125 
[2025-03-01 20:30:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.10566261410713196 norm:0.0001351426326436922 max memory_allocated 29274.81298828125 
[2025-03-01 20:31:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.10560262948274612 norm:0.00013244038564153016 max memory_allocated 29274.81298828125 
[2025-03-01 20:32:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.10553869605064392 norm:0.00012958687148056924 max memory_allocated 29274.81298828125 
[2025-03-01 20:32:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.10551060736179352 norm:0.00012843555305153131 max memory_allocated 29274.81298828125 
[2025-03-01 20:33:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.10546697676181793 norm:0.00012590723054017872 max memory_allocated 29274.81298828125 
[2025-03-01 20:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.10542657226324081 norm:0.00012553799024317414 max memory_allocated 29274.81298828125 
[2025-03-01 20:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.10539765655994415 norm:0.00012383118155412376 max memory_allocated 29274.81298828125 
[2025-03-01 20:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.1053803563117981 norm:0.00012430475908331573 max memory_allocated 29274.81298828125 
[2025-03-01 20:36:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-01 20:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.12895619869232178 norm:0.0009181532077491283 max memory_allocated 29275.00048828125 
[2025-03-01 20:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.12269957363605499 norm:0.00044386176159605384 max memory_allocated 29275.00048828125 
[2025-03-01 20:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.11756930500268936 norm:0.00026301006437279284 max memory_allocated 29275.00048828125 
[2025-03-01 20:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.11622719466686249 norm:0.00019517203327268362 max memory_allocated 29275.00048828125 
[2025-03-01 20:40:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.1153077483177185 norm:0.0001609564496902749 max memory_allocated 29275.00048828125 
[2025-03-01 20:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.11461104452610016 norm:0.00014403981913346797 max memory_allocated 29275.00048828125 
[2025-03-01 20:42:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.11420153826475143 norm:0.00013424112694337964 max memory_allocated 29275.00048828125 
[2025-03-01 20:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.11399049311876297 norm:0.00012972332478966564 max memory_allocated 29275.00048828125 
[2025-03-01 20:43:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.11386274546384811 norm:0.0001326855708612129 max memory_allocated 29275.00048828125 
[2025-03-01 20:44:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.11376253515481949 norm:0.00012019172572763637 max memory_allocated 29275.00048828125 
[2025-03-01 20:45:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.11366411298513412 norm:0.00011745523806894198 max memory_allocated 29275.00048828125 
[2025-03-01 20:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.11358736455440521 norm:0.00011573558731470257 max memory_allocated 29275.00048828125 
[2025-03-01 20:47:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.11353360861539841 norm:0.00011564845044631511 max memory_allocated 29275.00048828125 
[2025-03-01 20:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.11349985003471375 norm:0.0001164154164143838 max memory_allocated 29275.00048828125 
[2025-03-01 20:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.11345405876636505 norm:0.00011510950571391732 max memory_allocated 29275.00048828125 
[2025-03-01 20:49:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.11341451853513718 norm:0.00011479204113129526 max memory_allocated 29275.00048828125 
[2025-03-01 20:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.11338864266872406 norm:0.00011316921154502779 max memory_allocated 29275.00048828125 
[2025-03-01 20:51:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.11336379498243332 norm:0.00011257273581577465 max memory_allocated 29275.00048828125 
[2025-03-01 20:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.11332660913467407 norm:0.0001130721066147089 max memory_allocated 29275.00048828125 
[2025-03-01 20:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.11330341547727585 norm:0.00011352734873071313 max memory_allocated 29275.00048828125 
[2025-03-01 20:53:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-01 20:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.13887673616409302 norm:0.0009445824543945491 max memory_allocated 29275.18798828125 
[2025-03-01 20:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.13240769505500793 norm:0.00047762630856595933 max memory_allocated 29275.18798828125 
[2025-03-01 20:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.12701745331287384 norm:0.00027399780810810626 max memory_allocated 29275.18798828125 
[2025-03-01 20:56:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.12566407024860382 norm:0.00020085839787498116 max memory_allocated 29275.18798828125 
[2025-03-01 20:57:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.12472686171531677 norm:0.00016422191401943564 max memory_allocated 29275.18798828125 
[2025-03-01 20:58:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.12396187335252762 norm:0.00014463005936704576 max memory_allocated 29275.18798828125 
[2025-03-01 20:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.12351572513580322 norm:0.0001311063242610544 max memory_allocated 29275.18798828125 
[2025-03-01 20:59:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.12327529489994049 norm:0.00012267021520528942 max memory_allocated 29275.18798828125 
[2025-03-01 21:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.12313593924045563 norm:0.00020318863971624523 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.1230209469795227 norm:0.00011553606600500643 max memory_allocated 29275.18798828125 
[2025-03-01 21:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.12293736636638641 norm:0.00011295126023469493 max memory_allocated 29275.18798828125 
[2025-03-01 21:03:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.12286754697561264 norm:0.00011022044054698199 max memory_allocated 29275.18798828125 
[2025-03-01 21:03:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.12279420346021652 norm:0.00011039564560633153 max memory_allocated 29275.18798828125 
[2025-03-01 21:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.12273374199867249 norm:0.0001108972355723381 max memory_allocated 29275.18798828125 
[2025-03-01 21:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.12267735600471497 norm:0.00010842300980584696 max memory_allocated 29275.18798828125 
[2025-03-01 21:06:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.12264305353164673 norm:0.00010875578300328925 max memory_allocated 29275.18798828125 
[2025-03-01 21:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.12260641157627106 norm:0.00010879324690904468 max memory_allocated 29275.18798828125 
[2025-03-01 21:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.12258043885231018 norm:0.00010792659304570407 max memory_allocated 29275.18798828125 
[2025-03-01 21:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.12255489081144333 norm:0.00010935078898910433 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.1225295290350914 norm:0.0001099734945455566 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-01 21:10:44 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.14928945899009705 norm:0.0008208684157580137 max memory_allocated 29275.37548828125 
[2025-03-01 21:11:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.14295373857021332 norm:0.0004073723393958062 max memory_allocated 29275.37548828125 
[2025-03-01 21:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.13753418624401093 norm:0.0002610289375297725 max memory_allocated 29275.37548828125 
[2025-03-01 21:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.1361512690782547 norm:0.00020454083278309554 max memory_allocated 29275.37548828125 
[2025-03-01 21:14:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.13514941930770874 norm:0.00017499482783023268 max memory_allocated 29275.37548828125 
[2025-03-01 21:14:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.13434621691703796 norm:0.00015429651830345392 max memory_allocated 29275.37548828125 
[2025-03-01 21:15:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.13395768404006958 norm:0.00014799972996115685 max memory_allocated 29275.37548828125 
[2025-03-01 21:16:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.13375774025917053 norm:0.00014531254419125617 max memory_allocated 29275.37548828125 
[2025-03-01 21:17:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.1336444467306137 norm:0.00014347465184982866 max memory_allocated 29275.37548828125 
[2025-03-01 21:18:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.13354478776454926 norm:0.00014599572750739753 max memory_allocated 29275.37548828125 
[2025-03-01 21:18:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.1334557831287384 norm:0.00013844284694641829 max memory_allocated 29275.37548828125 
[2025-03-01 21:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.13340269029140472 norm:0.00013274203229229897 max memory_allocated 29275.37548828125 
[2025-03-01 21:20:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.13333430886268616 norm:0.000132005283376202 max memory_allocated 29275.37548828125 
[2025-03-01 21:21:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.13328032195568085 norm:0.00014071840269025415 max memory_allocated 29275.37548828125 
[2025-03-01 21:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.13323161005973816 norm:0.0001327373320236802 max memory_allocated 29275.37548828125 
[2025-03-01 21:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.1331908255815506 norm:0.00012989409151487052 max memory_allocated 29275.37548828125 
[2025-03-01 21:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.13315695524215698 norm:0.00013390120875556022 max memory_allocated 29275.37548828125 
[2025-03-01 21:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.13313330709934235 norm:0.00014028015721123666 max memory_allocated 29275.37548828125 
[2025-03-01 21:25:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.13310804963111877 norm:0.0001323909527854994 max memory_allocated 29275.37548828125 
[2025-03-01 21:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.13306881487369537 norm:0.00013374598347581923 max memory_allocated 29275.37548828125 
[2025-03-01 21:26:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-01 21:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.16134725511074066 norm:0.0007790959207341075 max memory_allocated 29275.56298828125 
[2025-03-01 21:28:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.15488605201244354 norm:0.0003776167577598244 max memory_allocated 29275.56298828125 
[2025-03-01 21:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.14913153648376465 norm:0.0002406510029686615 max memory_allocated 29275.56298828125 
[2025-03-01 21:29:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.14771202206611633 norm:0.00018544431077316403 max memory_allocated 29275.56298828125 
[2025-03-01 21:30:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.14666786789894104 norm:0.00015514178085140884 max memory_allocated 29275.56298828125 
[2025-03-01 21:31:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.14587047696113586 norm:0.00013727674377150834 max memory_allocated 29275.56298828125 
[2025-03-01 21:32:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.14547944068908691 norm:0.00012642961519304663 max memory_allocated 29275.56298828125 
[2025-03-01 21:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.14526531100273132 norm:0.00011936805094592273 max memory_allocated 29275.56298828125 
[2025-03-01 21:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.14512686431407928 norm:0.00011448250734247267 max memory_allocated 29275.56298828125 
[2025-03-01 21:34:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.1450234353542328 norm:0.0001113434336730279 max memory_allocated 29275.56298828125 
[2025-03-01 21:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.1449344903230667 norm:0.00010958485654555261 max memory_allocated 29275.56298828125 
[2025-03-01 21:36:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.14484192430973053 norm:0.00010805523197632283 max memory_allocated 29275.56298828125 
[2025-03-01 21:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.14478519558906555 norm:0.0001085925250663422 max memory_allocated 29275.56298828125 
[2025-03-01 21:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.1447281390428543 norm:0.00010758910502772778 max memory_allocated 29275.56298828125 
[2025-03-01 21:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.14468108117580414 norm:0.0001075624895747751 max memory_allocated 29275.56298828125 
[2025-03-01 21:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.14462785422801971 norm:0.00011000483937095851 max memory_allocated 29275.56298828125 
[2025-03-01 21:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.144581139087677 norm:0.0001093404134735465 max memory_allocated 29275.56298828125 
[2025-03-01 21:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.14455360174179077 norm:0.00010793878027470782 max memory_allocated 29275.56298828125 
[2025-03-01 21:42:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.14452196657657623 norm:0.00010717234545154497 max memory_allocated 29275.56298828125 
[2025-03-01 21:43:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.14448341727256775 norm:0.00010594180639600381 max memory_allocated 29275.56298828125 
[2025-03-01 21:43:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-01 21:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.17651228606700897 norm:0.0008748509571887553 max memory_allocated 29275.75048828125 
[2025-03-01 21:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.16964468359947205 norm:0.00048751552822068334 max memory_allocated 29275.75048828125 
[2025-03-01 21:45:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.1634129285812378 norm:0.00031644722912460566 max memory_allocated 29275.75048828125 
[2025-03-01 21:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.16178861260414124 norm:0.0002424675039947033 max memory_allocated 29275.75048828125 
[2025-03-01 21:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.16057364642620087 norm:0.0002024970599450171 max memory_allocated 29275.75048828125 
[2025-03-01 21:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.15968374907970428 norm:0.00017761613707989454 max memory_allocated 29275.75048828125 
[2025-03-01 21:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.1592932492494583 norm:0.00015961391909513623 max memory_allocated 29275.75048828125 
[2025-03-01 21:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.15909768640995026 norm:0.00014979274419602007 max memory_allocated 29275.75048828125 
[2025-03-01 21:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.15895576775074005 norm:0.0001400921755703166 max memory_allocated 29275.75048828125 
[2025-03-01 21:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.15884582698345184 norm:0.00013639280223287642 max memory_allocated 29275.75048828125 
[2025-03-01 21:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.15875688195228577 norm:0.00013205347931943834 max memory_allocated 29275.75048828125 
[2025-03-01 21:53:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.15867328643798828 norm:0.0001277498813578859 max memory_allocated 29275.75048828125 
[2025-03-01 21:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.15859684348106384 norm:0.00012819655239582062 max memory_allocated 29275.75048828125 
[2025-03-01 21:54:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.1585286259651184 norm:0.00012555559806060046 max memory_allocated 29275.75048828125 
[2025-03-01 21:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.15846917033195496 norm:0.00012159618199802935 max memory_allocated 29275.75048828125 
[2025-03-01 21:56:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.15841975808143616 norm:0.00012218381743878126 max memory_allocated 29275.75048828125 
[2025-03-01 21:57:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.15837529301643372 norm:0.00012011499347863719 max memory_allocated 29275.75048828125 
[2025-03-01 21:58:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.1583356410264969 norm:0.00012111398245906457 max memory_allocated 29275.75048828125 
[2025-03-01 21:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.15829087793827057 norm:0.00012057351705152541 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.15825647115707397 norm:0.00012103559129172936 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-01 22:00:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.18967317044734955 norm:0.0006216589245013893 max memory_allocated 29275.93798828125 
[2025-03-01 22:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.18316681683063507 norm:0.0003555951116140932 max memory_allocated 29275.93798828125 
[2025-03-01 22:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.176975280046463 norm:0.00024139565357472748 max memory_allocated 29275.93798828125 
[2025-03-01 22:03:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.1754193753004074 norm:0.0001914700260385871 max memory_allocated 29275.93798828125 
[2025-03-01 22:04:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.17426754534244537 norm:0.0001647503231652081 max memory_allocated 29275.93798828125 
[2025-03-01 22:04:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.17348015308380127 norm:0.00017072426271624863 max memory_allocated 29275.93798828125 
[2025-03-01 22:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.1731274276971817 norm:0.00013662019046023488 max memory_allocated 29275.93798828125 
[2025-03-01 22:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.17291861772537231 norm:0.00012744139530695975 max memory_allocated 29275.93798828125 
[2025-03-01 22:07:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.17278075218200684 norm:0.00012322781549300998 max memory_allocated 29275.93798828125 
[2025-03-01 22:08:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.17265534400939941 norm:0.00012106358917662874 max memory_allocated 29275.93798828125 
[2025-03-01 22:09:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.1725504994392395 norm:0.00011749171244446188 max memory_allocated 29275.93798828125 
[2025-03-01 22:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.17246967554092407 norm:0.00011633656686171889 max memory_allocated 29275.93798828125 
[2025-03-01 22:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.17238058149814606 norm:0.00011734406143659726 max memory_allocated 29275.93798828125 
[2025-03-01 22:11:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.17231620848178864 norm:0.00011461881513241678 max memory_allocated 29275.93798828125 
[2025-03-01 22:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.17224527895450592 norm:0.0001146898721344769 max memory_allocated 29275.93798828125 
[2025-03-01 22:13:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.1721772998571396 norm:0.0001122451649280265 max memory_allocated 29275.93798828125 
[2025-03-01 22:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.17213505506515503 norm:0.00011326889944029972 max memory_allocated 29275.93798828125 
[2025-03-01 22:14:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.17209385335445404 norm:0.00011403067037463188 max memory_allocated 29275.93798828125 
[2025-03-01 22:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.1720540076494217 norm:0.00011184123286511749 max memory_allocated 29275.93798828125 
[2025-03-01 22:16:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.172017902135849 norm:0.00011103768338216469 max memory_allocated 29275.93798828125 
[2025-03-01 22:16:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-01 22:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.20845739543437958 norm:0.001175573910586536 max memory_allocated 29276.12548828125 
[2025-03-01 22:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.20100262761116028 norm:0.0006457933923229575 max memory_allocated 29276.12548828125 
[2025-03-01 22:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.19435939192771912 norm:0.0004099033831153065 max memory_allocated 29276.12548828125 
[2025-03-01 22:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.19250361621379852 norm:0.0003002376761287451 max memory_allocated 29276.12548828125 
[2025-03-01 22:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.19113558530807495 norm:0.0002397908829152584 max memory_allocated 29276.12548828125 
[2025-03-01 22:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.1902655065059662 norm:0.0002043962012976408 max memory_allocated 29276.12548828125 
[2025-03-01 22:22:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.1898956149816513 norm:0.0001893410662887618 max memory_allocated 29276.12548828125 
[2025-03-01 22:23:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.18969863653182983 norm:0.00017261828179471195 max memory_allocated 29276.12548828125 
[2025-03-01 22:24:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.18955925107002258 norm:0.00016378291184082627 max memory_allocated 29276.12548828125 
[2025-03-01 22:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.189418762922287 norm:0.00016410098760388792 max memory_allocated 29276.12548828125 
[2025-03-01 22:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.18931537866592407 norm:0.0001539324439363554 max memory_allocated 29276.12548828125 
[2025-03-01 22:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.18923260271549225 norm:0.00015118796727620065 max memory_allocated 29276.12548828125 
[2025-03-01 22:27:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.18914300203323364 norm:0.00014735027798451483 max memory_allocated 29276.12548828125 
[2025-03-01 22:28:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.18906715512275696 norm:0.0001518018398201093 max memory_allocated 29276.12548828125 
[2025-03-01 22:29:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.18900150060653687 norm:0.00013321808364707977 max memory_allocated 29276.12548828125 
[2025-03-01 22:29:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.18895316123962402 norm:0.00013512044097296894 max memory_allocated 29276.12548828125 
[2025-03-01 22:30:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.18890796601772308 norm:0.00013207081065047532 max memory_allocated 29276.12548828125 
[2025-03-01 22:31:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.18887950479984283 norm:0.0001316828274866566 max memory_allocated 29276.12548828125 
[2025-03-01 22:32:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.18883782625198364 norm:0.00013003026833757758 max memory_allocated 29276.12548828125 
[2025-03-01 22:33:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.18880102038383484 norm:0.0001372005935991183 max memory_allocated 29276.12548828125 
[2025-03-01 22:33:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-01 22:34:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.22586585581302643 norm:0.0009751345496624708 max memory_allocated 29276.31298828125 
[2025-03-01 22:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.21846602857112885 norm:0.0005417945794761181 max memory_allocated 29276.31298828125 
[2025-03-01 22:35:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.2116076499223709 norm:0.00035144988214597106 max memory_allocated 29276.31298828125 
[2025-03-01 22:36:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.20985467731952667 norm:0.0002640883903950453 max memory_allocated 29276.31298828125 
[2025-03-01 22:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.20853975415229797 norm:0.00021352223120629787 max memory_allocated 29276.31298828125 
[2025-03-01 22:38:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.2077600359916687 norm:0.00018017842376139015 max memory_allocated 29276.31298828125 
[2025-03-01 22:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.20742841064929962 norm:0.00015928516222629696 max memory_allocated 29276.31298828125 
[2025-03-01 22:40:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.20723432302474976 norm:0.0001457045436836779 max memory_allocated 29276.31298828125 
[2025-03-01 22:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.20707489550113678 norm:0.00013839246821589768 max memory_allocated 29276.31298828125 
[2025-03-01 22:41:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.20694643259048462 norm:0.00013020755432080477 max memory_allocated 29276.31298828125 
[2025-03-01 22:42:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.20683814585208893 norm:0.000125935286632739 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.2067599594593048 norm:0.00012271858577150851 max memory_allocated 29276.31298828125 
[2025-03-01 22:44:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.20666737854480743 norm:0.0001198092577396892 max memory_allocated 29276.31298828125 
[2025-03-01 22:44:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.2066030204296112 norm:0.00011785241076722741 max memory_allocated 29276.31298828125 
[2025-03-01 22:45:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.20654219388961792 norm:0.00011895787611138076 max memory_allocated 29276.31298828125 
[2025-03-01 22:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.20648181438446045 norm:0.00011883855040650815 max memory_allocated 29276.31298828125 
[2025-03-01 22:47:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.20642834901809692 norm:0.00011921692930627614 max memory_allocated 29276.31298828125 
[2025-03-01 22:48:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.20637668669223785 norm:0.00011621359590208158 max memory_allocated 29276.31298828125 
[2025-03-01 22:49:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.20633630454540253 norm:0.00011582525621633977 max memory_allocated 29276.31298828125 
[2025-03-01 22:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.2062993049621582 norm:0.00011588694906095043 max memory_allocated 29276.31298828125 
[2025-03-01 22:50:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-01 22:50:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.24891218543052673 norm:0.0010074208257719874 max memory_allocated 29276.50048828125 
[2025-03-01 22:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.23977167904376984 norm:0.0005155519465915859 max memory_allocated 29276.50048828125 
[2025-03-01 22:52:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.23168408870697021 norm:0.00031511191627942026 max memory_allocated 29276.50048828125 
[2025-03-01 22:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.22954419255256653 norm:0.00023532466730102897 max memory_allocated 29276.50048828125 
[2025-03-01 22:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.22809678316116333 norm:0.00019038995378650725 max memory_allocated 29276.50048828125 
[2025-03-01 22:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.22734896838665009 norm:0.00016491829592268914 max memory_allocated 29276.50048828125 
[2025-03-01 22:55:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.22704792022705078 norm:0.00015077424177434295 max memory_allocated 29276.50048828125 
[2025-03-01 22:56:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.22683343291282654 norm:0.00014802682562731206 max memory_allocated 29276.50048828125 
[2025-03-01 22:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.2266846001148224 norm:0.00013612784096039832 max memory_allocated 29276.50048828125 
[2025-03-01 22:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.22653807699680328 norm:0.00013104156823828816 max memory_allocated 29276.50048828125 
[2025-03-01 22:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.226420596241951 norm:0.00012684118701145053 max memory_allocated 29276.50048828125 
[2025-03-01 23:00:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.22632035613059998 norm:0.00012549858365673572 max memory_allocated 29276.50048828125 
[2025-03-01 23:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.22623753547668457 norm:0.0001248831977136433 max memory_allocated 29276.50048828125 
[2025-03-01 23:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.22615697979927063 norm:0.00012279603106435388 max memory_allocated 29276.50048828125 
[2025-03-01 23:02:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.22607693076133728 norm:0.00012394992518238723 max memory_allocated 29276.50048828125 
[2025-03-01 23:03:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.22601428627967834 norm:0.00012256404443178326 max memory_allocated 29276.50048828125 
[2025-03-01 23:04:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.22594952583312988 norm:0.00012078158761141822 max memory_allocated 29276.50048828125 
[2025-03-01 23:04:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.22590705752372742 norm:0.00012229755520820618 max memory_allocated 29276.50048828125 
[2025-03-01 23:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.22585314512252808 norm:0.00012195075396448374 max memory_allocated 29276.50048828125 
[2025-03-01 23:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.22580605745315552 norm:0.00012199024786241353 max memory_allocated 29276.50048828125 
[2025-03-01 23:06:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-01 23:07:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.2694489061832428 norm:0.0010656968224793673 max memory_allocated 29276.68798828125 
[2025-03-01 23:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.2606961131095886 norm:0.000539636064786464 max memory_allocated 29276.68798828125 
[2025-03-01 23:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.2525254786014557 norm:0.0003258208744227886 max memory_allocated 29276.68798828125 
[2025-03-01 23:10:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.2503245174884796 norm:0.00023959465033840388 max memory_allocated 29276.68798828125 
[2025-03-01 23:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.2489166259765625 norm:0.0001911750587169081 max memory_allocated 29276.68798828125 
[2025-03-01 23:11:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.24824535846710205 norm:0.0001653482613619417 max memory_allocated 29276.68798828125 
[2025-03-01 23:12:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.24800467491149902 norm:0.00015056246775202453 max memory_allocated 29276.68798828125 
[2025-03-01 23:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.24783487617969513 norm:0.0001415062288288027 max memory_allocated 29276.68798828125 
[2025-03-01 23:14:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.2476724088191986 norm:0.00014047948934603482 max memory_allocated 29276.68798828125 
[2025-03-01 23:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.24752898514270782 norm:0.0001379513560095802 max memory_allocated 29276.68798828125 
[2025-03-01 23:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.2474038153886795 norm:0.0001357180590275675 max memory_allocated 29276.68798828125 
[2025-03-01 23:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.24729040265083313 norm:0.00013196890358813107 max memory_allocated 29276.68798828125 
[2025-03-01 23:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.24719689786434174 norm:0.00013082424993626773 max memory_allocated 29276.68798828125 
[2025-03-01 23:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.2471131533384323 norm:0.00013036838208790869 max memory_allocated 29276.68798828125 
[2025-03-01 23:19:09 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.24704302847385406 norm:0.00013007152301725 max memory_allocated 29276.68798828125 
[2025-03-01 23:19:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.24697430431842804 norm:0.00012878414418082684 max memory_allocated 29276.68798828125 
[2025-03-01 23:20:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.24691146612167358 norm:0.00012940050510223955 max memory_allocated 29276.68798828125 
[2025-03-01 23:21:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.24685662984848022 norm:0.00012804877769667655 max memory_allocated 29276.68798828125 
[2025-03-01 23:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.24681569635868073 norm:0.00012795371003448963 max memory_allocated 29276.68798828125 
[2025-03-01 23:23:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.24676048755645752 norm:0.0001283105229958892 max memory_allocated 29276.68798828125 
[2025-03-01 23:23:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-01 23:24:23 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.2954871654510498 norm:0.0011858476791530848 max memory_allocated 29276.87548828125 
[2025-03-01 23:25:12 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.285600483417511 norm:0.000590809911955148 max memory_allocated 29276.87548828125 
[2025-03-01 23:26:01 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.27675873041152954 norm:0.00035242451122030616 max memory_allocated 29276.87548828125 
[2025-03-01 23:26:50 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.2742207944393158 norm:0.00025567712145857513 max memory_allocated 29276.87548828125 
[2025-03-01 23:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.27263790369033813 norm:0.00023047388822305948 max memory_allocated 29276.87548828125 
[2025-03-01 23:28:29 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.2719929814338684 norm:0.00018131120305042714 max memory_allocated 29276.87548828125 
[2025-03-01 23:29:18 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.27168458700180054 norm:0.0001676919055171311 max memory_allocated 29276.87548828125 
[2025-03-01 23:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.27142661809921265 norm:0.00015680688375141472 max memory_allocated 29276.87548828125 
[2025-03-01 23:30:56 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.2712385058403015 norm:0.0001487673434894532 max memory_allocated 29276.87548828125 
[2025-03-01 23:31:45 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.27111363410949707 norm:0.0001448645198252052 max memory_allocated 29276.87548828125 
[2025-03-01 23:32:35 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.27099281549453735 norm:0.00013879504695069045 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:24 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.2708624303340912 norm:0.00013635560753755271 max memory_allocated 29276.87548828125 
[2025-03-01 23:34:13 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.2707580626010895 norm:0.00013303889136295766 max memory_allocated 29276.87548828125 
[2025-03-01 23:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.2706731855869293 norm:0.00013165992277208716 max memory_allocated 29276.87548828125 
[2025-03-01 23:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.2706037163734436 norm:0.00013178089284338057 max memory_allocated 29276.87548828125 
[2025-03-01 23:36:41 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.2705247700214386 norm:0.0001300447911489755 max memory_allocated 29276.87548828125 
[2025-03-01 23:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.27046263217926025 norm:0.00012820513802580535 max memory_allocated 29276.87548828125 
[2025-03-01 23:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.2704128921031952 norm:0.00012755014176946133 max memory_allocated 29276.87548828125 
[2025-03-01 23:39:08 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.27035439014434814 norm:0.00012778137170244008 max memory_allocated 29276.87548828125 
[2025-03-01 23:39:57 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.2702978253364563 norm:0.00012740580132231116 max memory_allocated 29276.87548828125 
[2025-03-01 23:40:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-01 23:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.321603387594223 norm:0.0010141937527805567 max memory_allocated 29277.06298828125 
[2025-03-01 23:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.3112131953239441 norm:0.0005431992467492819 max memory_allocated 29277.06298828125 
[2025-03-01 23:42:43 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.3017955422401428 norm:0.0003246623673476279 max memory_allocated 29277.06298828125 
[2025-03-01 23:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.2991768717765808 norm:0.00023929680173750967 max memory_allocated 29277.06298828125 
[2025-03-01 23:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.29764524102211 norm:0.00020250616944395006 max memory_allocated 29277.06298828125 
[2025-03-01 23:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.29704028367996216 norm:0.00017969087639357895 max memory_allocated 29277.06298828125 
[2025-03-01 23:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.2967129349708557 norm:0.00017311023839283735 max memory_allocated 29277.06298828125 
[2025-03-01 23:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.29649412631988525 norm:0.00016572185268159956 max memory_allocated 29277.06298828125 
[2025-03-01 23:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.2963128983974457 norm:0.0001578873343532905 max memory_allocated 29277.06298828125 
[2025-03-01 23:48:27 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.29619142413139343 norm:0.00015386234736070037 max memory_allocated 29277.06298828125 
[2025-03-01 23:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.2960589528083801 norm:0.00015202764188870788 max memory_allocated 29277.06298828125 
[2025-03-01 23:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.2959202229976654 norm:0.00015016783436294645 max memory_allocated 29277.06298828125 
[2025-03-01 23:50:55 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.2958195209503174 norm:0.00014966021990403533 max memory_allocated 29277.06298828125 
[2025-03-01 23:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.2957276701927185 norm:0.00014821829972788692 max memory_allocated 29277.06298828125 
[2025-03-01 23:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.2956355810165405 norm:0.00014863081742078066 max memory_allocated 29277.06298828125 
[2025-03-01 23:53:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.2955671548843384 norm:0.00014742367784492671 max memory_allocated 29277.06298828125 
[2025-03-01 23:54:12 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.2955150604248047 norm:0.00014800543431192636 max memory_allocated 29277.06298828125 
[2025-03-01 23:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.29546916484832764 norm:0.00014944045688025653 max memory_allocated 29277.06298828125 
[2025-03-01 23:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.29540544748306274 norm:0.00014888039731886238 max memory_allocated 29277.06298828125 
[2025-03-01 23:56:40 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.2953574061393738 norm:0.00015063541650306433 max memory_allocated 29277.06298828125 
[2025-03-01 23:56:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-01 23:57:47 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.35428130626678467 norm:0.0010451561538502574 max memory_allocated 29277.25048828125 
[2025-03-01 23:58:36 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.3427378535270691 norm:0.0005226664943620563 max memory_allocated 29277.25048828125 
[2025-03-01 23:59:25 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.3330662250518799 norm:0.00032622148864902556 max memory_allocated 29277.25048828125 
[2025-03-02 00:00:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.33017683029174805 norm:0.00025147979613393545 max memory_allocated 29277.25048828125 
[2025-03-02 00:01:03 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.3284827470779419 norm:0.0002103901788359508 max memory_allocated 29277.25048828125 
[2025-03-02 00:01:53 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.3278387784957886 norm:0.00018989290401805192 max memory_allocated 29277.25048828125 
[2025-03-02 00:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.32744646072387695 norm:0.00017741197370924056 max memory_allocated 29277.25048828125 
[2025-03-02 00:03:31 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.3271544873714447 norm:0.00017077408847399056 max memory_allocated 29277.25048828125 
[2025-03-02 00:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.3269246816635132 norm:0.00016663456335663795 max memory_allocated 29277.25048828125 
[2025-03-02 00:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.32668811082839966 norm:0.00016005345969460905 max memory_allocated 29277.25048828125 
[2025-03-02 00:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.32651054859161377 norm:0.0001578951341798529 max memory_allocated 29277.25048828125 
[2025-03-02 00:06:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.3263753652572632 norm:0.00015575712313875556 max memory_allocated 29277.25048828125 
[2025-03-02 00:07:37 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.32624420523643494 norm:0.0001523340179119259 max memory_allocated 29277.25048828125 
[2025-03-02 00:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.3261167109012604 norm:0.00014983583241701126 max memory_allocated 29277.25048828125 
[2025-03-02 00:09:16 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.3260006904602051 norm:0.00014821335207670927 max memory_allocated 29277.25048828125 
[2025-03-02 00:10:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.3258885443210602 norm:0.00014647580974269658 max memory_allocated 29277.25048828125 
[2025-03-02 00:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.3258040249347687 norm:0.00014625221956521273 max memory_allocated 29277.25048828125 
[2025-03-02 00:11:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.3257298171520233 norm:0.00014366382674779743 max memory_allocated 29277.25048828125 
[2025-03-02 00:12:32 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.32567298412323 norm:0.00013894293806515634 max memory_allocated 29277.25048828125 
[2025-03-02 00:13:21 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.3256123960018158 norm:0.00013961319928057492 max memory_allocated 29277.25048828125 
[2025-03-02 00:13:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 00:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.3860780894756317 norm:0.0011222591856494546 max memory_allocated 29277.43798828125 
[2025-03-02 00:15:18 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.3746581971645355 norm:0.0005874030757695436 max memory_allocated 29277.43798828125 
[2025-03-02 00:16:07 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.3646058142185211 norm:0.0003596172318793833 max memory_allocated 29277.43798828125 
[2025-03-02 00:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.36145827174186707 norm:0.00026017893105745316 max memory_allocated 29277.43798828125 
[2025-03-02 00:17:46 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.35980698466300964 norm:0.00020797520119231194 max memory_allocated 29277.43798828125 
[2025-03-02 00:18:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.35921892523765564 norm:0.00018129125237464905 max memory_allocated 29277.43798828125 
[2025-03-02 00:19:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.35888129472732544 norm:0.00016684559523127973 max memory_allocated 29277.43798828125 
[2025-03-02 00:20:13 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.3586301803588867 norm:0.0001599150855327025 max memory_allocated 29277.43798828125 
[2025-03-02 00:21:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.3583904504776001 norm:0.00015351903857663274 max memory_allocated 29277.43798828125 
[2025-03-02 00:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.3581939935684204 norm:0.00014964796719141304 max memory_allocated 29277.43798828125 
[2025-03-02 00:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.35803183913230896 norm:0.00014902601833455265 max memory_allocated 29277.43798828125 
[2025-03-02 00:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.3578808307647705 norm:0.00014919257955625653 max memory_allocated 29277.43798828125 
[2025-03-02 00:24:20 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.3577566146850586 norm:0.00014742743223905563 max memory_allocated 29277.43798828125 
[2025-03-02 00:25:09 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.3576555550098419 norm:0.00014735464355908334 max memory_allocated 29277.43798828125 
[2025-03-02 00:25:58 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.3575473427772522 norm:0.00014688300143461674 max memory_allocated 29277.43798828125 
[2025-03-02 00:26:47 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.3574617803096771 norm:0.00014635373372584581 max memory_allocated 29277.43798828125 
[2025-03-02 00:27:37 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.35736826062202454 norm:0.00014586318866349757 max memory_allocated 29277.43798828125 
[2025-03-02 00:28:26 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.35730046033859253 norm:0.0001457004836993292 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.35722628235816956 norm:0.0001457079197280109 max memory_allocated 29277.43798828125 
[2025-03-02 00:30:04 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.35713982582092285 norm:0.00014419553917832673 max memory_allocated 29277.43798828125 
[2025-03-02 00:30:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 00:30:22 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:31:12 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.4351826310157776 norm:0.009353193454444408 max memory_allocated 29277.77001953125 
[2025-03-02 00:32:01 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.41945207118988037 norm:0.007175847422331572 max memory_allocated 29277.77001953125 
[2025-03-02 00:32:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.4069747030735016 norm:0.005358092486858368 max memory_allocated 29277.77001953125 
[2025-03-02 00:33:40 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.40288400650024414 norm:0.004438851960003376 max memory_allocated 29277.77001953125 
[2025-03-02 00:34:29 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.4008932411670685 norm:0.0036101751029491425 max memory_allocated 29277.77001953125 
[2025-03-02 00:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.40005433559417725 norm:0.0029924625996500254 max memory_allocated 29277.77001953125 
[2025-03-02 00:36:08 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.39955955743789673 norm:0.002670646645128727 max memory_allocated 29277.77001953125 
[2025-03-02 00:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.39926329255104065 norm:0.002661782782524824 max memory_allocated 29277.77001953125 
[2025-03-02 00:37:46 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.39900442957878113 norm:0.0025950935669243336 max memory_allocated 29277.77001953125 
[2025-03-02 00:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.39871251583099365 norm:0.0024818922393023968 max memory_allocated 29277.77001953125 
[2025-03-02 00:39:25 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.398385614156723 norm:0.002306789392605424 max memory_allocated 29277.77001953125 
[2025-03-02 00:40:15 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.3981737792491913 norm:0.0022261396516114473 max memory_allocated 29277.77001953125 
[2025-03-02 00:41:04 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.3980332612991333 norm:0.0022203782573342323 max memory_allocated 29277.77001953125 
[2025-03-02 00:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.3979397416114807 norm:0.0022294390946626663 max memory_allocated 29277.77001953125 
[2025-03-02 00:42:43 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.39771589636802673 norm:0.00215611862950027 max memory_allocated 29277.77001953125 
[2025-03-02 00:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.3975847363471985 norm:0.0020950976759195328 max memory_allocated 29277.77001953125 
[2025-03-02 00:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.39744657278060913 norm:0.002086675027385354 max memory_allocated 29277.77001953125 
[2025-03-02 00:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.39733704924583435 norm:0.0020603486336767673 max memory_allocated 29277.77001953125 
[2025-03-02 00:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.39718005061149597 norm:0.0019751177169382572 max memory_allocated 29277.77001953125 
[2025-03-02 00:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.39714235067367554 norm:0.0019909844268113375 max memory_allocated 29277.77001953125 
[2025-03-02 00:47:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 00:47:08 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.4882793724536896 norm:0.010317392647266388 max memory_allocated 29277.95751953125 
[2025-03-02 00:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.4689856767654419 norm:0.007984778843820095 max memory_allocated 29277.95751953125 
[2025-03-02 00:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.45331698656082153 norm:0.005692596081644297 max memory_allocated 29277.95751953125 
[2025-03-02 00:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.44816362857818604 norm:0.004710378125309944 max memory_allocated 29277.95751953125 
[2025-03-02 00:51:14 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.4459746181964874 norm:0.003882358083501458 max memory_allocated 29277.95751953125 
[2025-03-02 00:52:03 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.4449477195739746 norm:0.003237321740016341 max memory_allocated 29277.95751953125 
[2025-03-02 00:52:53 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.444277822971344 norm:0.002790331607684493 max memory_allocated 29277.95751953125 
[2025-03-02 00:53:42 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.44398215413093567 norm:0.002815352054312825 max memory_allocated 29277.95751953125 
[2025-03-02 00:54:31 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.4437262713909149 norm:0.0027736257761716843 max memory_allocated 29277.95751953125 
[2025-03-02 00:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.4434066116809845 norm:0.002516493434086442 max memory_allocated 29277.95751953125 
[2025-03-02 00:56:10 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.44307219982147217 norm:0.002398622687906027 max memory_allocated 29277.95751953125 
[2025-03-02 00:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.4429011642932892 norm:0.002382460283115506 max memory_allocated 29277.95751953125 
[2025-03-02 00:57:49 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.44269898533821106 norm:0.0023081544786691666 max memory_allocated 29277.95751953125 
[2025-03-02 00:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.44249141216278076 norm:0.002211986808106303 max memory_allocated 29277.95751953125 
[2025-03-02 00:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.44236302375793457 norm:0.0021668311674147844 max memory_allocated 29277.95751953125 
[2025-03-02 01:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.44224828481674194 norm:0.0022431325633078814 max memory_allocated 29277.95751953125 
[2025-03-02 01:01:06 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.4420666992664337 norm:0.0021597666200250387 max memory_allocated 29277.95751953125 
[2025-03-02 01:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.44206151366233826 norm:0.002250600839033723 max memory_allocated 29277.95751953125 
[2025-03-02 01:02:45 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.4419521987438202 norm:0.0021559102460741997 max memory_allocated 29277.95751953125 
[2025-03-02 01:03:34 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.4419019818305969 norm:0.0021251917351037264 max memory_allocated 29277.95751953125 
[2025-03-02 01:03:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 01:03:52 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.5727046132087708 norm:0.01354918722063303 max memory_allocated 29278.14501953125 
[2025-03-02 01:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.5501545667648315 norm:0.004809037782251835 max memory_allocated 29278.14501953125 
[2025-03-02 01:06:20 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.5295754075050354 norm:0.005083230324089527 max memory_allocated 29278.14501953125 
[2025-03-02 01:07:10 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.522826611995697 norm:0.005228640977293253 max memory_allocated 29278.14501953125 
[2025-03-02 01:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.5198090076446533 norm:0.005061074160039425 max memory_allocated 29278.14501953125 
[2025-03-02 01:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.5182463526725769 norm:0.004960852675139904 max memory_allocated 29278.14501953125 
[2025-03-02 01:09:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.5170772671699524 norm:0.006092894822359085 max memory_allocated 29278.14501953125 
[2025-03-02 01:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.5163941979408264 norm:0.007042418699711561 max memory_allocated 29278.14501953125 
[2025-03-02 01:11:16 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.5157800912857056 norm:0.006731375120580196 max memory_allocated 29278.14501953125 
[2025-03-02 01:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.5155627727508545 norm:0.006676687393337488 max memory_allocated 29278.14501953125 
[2025-03-02 01:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.5153360366821289 norm:0.006826319266110659 max memory_allocated 29278.14501953125 
[2025-03-02 01:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.5151357054710388 norm:0.0066176652908325195 max memory_allocated 29278.14501953125 
[2025-03-02 01:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.5151529312133789 norm:0.006594822742044926 max memory_allocated 29278.14501953125 
[2025-03-02 01:15:23 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.5152608752250671 norm:0.006242194212973118 max memory_allocated 29278.14501953125 
[2025-03-02 01:16:12 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.515678882598877 norm:0.006674505770206451 max memory_allocated 29278.14501953125 
[2025-03-02 01:17:02 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.5151005387306213 norm:0.005823779851198196 max memory_allocated 29278.14501953125 
[2025-03-02 01:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.5144802331924438 norm:0.005224964581429958 max memory_allocated 29278.14501953125 
[2025-03-02 01:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.5139644742012024 norm:0.0048906924203038216 max memory_allocated 29278.14501953125 
[2025-03-02 01:19:30 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.5137113332748413 norm:0.004698994103819132 max memory_allocated 29278.14501953125 
[2025-03-02 01:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.5135799646377563 norm:0.004421968478709459 max memory_allocated 29278.14501953125 
[2025-03-02 01:20:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 01:20:37 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.8204311728477478 norm:0.03924328833818436 max memory_allocated 29278.33251953125 
[2025-03-02 01:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.7461935877799988 norm:0.027942579239606857 max memory_allocated 29278.33251953125 
[2025-03-02 01:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.7025513052940369 norm:0.021115193143486977 max memory_allocated 29278.33251953125 
[2025-03-02 01:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.6871790885925293 norm:0.017221441492438316 max memory_allocated 29278.33251953125 
[2025-03-02 01:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.6796081066131592 norm:0.01537514291703701 max memory_allocated 29278.33251953125 
[2025-03-02 01:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.6751757264137268 norm:0.014323477633297443 max memory_allocated 29278.33251953125 
[2025-03-02 01:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.6723644733428955 norm:0.013576552271842957 max memory_allocated 29278.33251953125 
[2025-03-02 01:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.6702133417129517 norm:0.01310978177934885 max memory_allocated 29278.33251953125 
[2025-03-02 01:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.6682726144790649 norm:0.012448063120245934 max memory_allocated 29278.33251953125 
[2025-03-02 01:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.6667791604995728 norm:0.01184671651571989 max memory_allocated 29278.33251953125 
[2025-03-02 01:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.6655983924865723 norm:0.011979878880083561 max memory_allocated 29278.33251953125 
[2025-03-02 01:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.664531946182251 norm:0.011218680068850517 max memory_allocated 29278.33251953125 
[2025-03-02 01:31:18 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.6635305285453796 norm:0.011432413943111897 max memory_allocated 29278.33251953125 
[2025-03-02 01:32:08 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.663413405418396 norm:0.010942360386252403 max memory_allocated 29278.33251953125 
[2025-03-02 01:32:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.6632086634635925 norm:0.011490223929286003 max memory_allocated 29278.33251953125 
[2025-03-02 01:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.6622267961502075 norm:0.01099705696105957 max memory_allocated 29278.33251953125 
[2025-03-02 01:34:36 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.661609947681427 norm:0.010842633433640003 max memory_allocated 29278.33251953125 
[2025-03-02 01:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.6607269644737244 norm:0.010403377935290337 max memory_allocated 29278.33251953125 
[2025-03-02 01:36:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.660171389579773 norm:0.010351035743951797 max memory_allocated 29278.33251953125 
[2025-03-02 01:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.659662663936615 norm:0.009824237786233425 max memory_allocated 29278.33251953125 
[2025-03-02 01:37:18 root] (main_calib_config2.py 380): INFO 40135.66276502609
[2025-03-02 01:37:29 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-02 01:39:24 root] (main_calib_config2.py 159): INFO wikitext2 : 5.1630072593688965
[2025-03-02 01:39:24 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-02 01:42:22 root] (main_calib_config2.py 159): INFO c4 : 6.833564281463623
[2025-03-02 03:48:42 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.1630072593688965, 'c4': 6.833564281463623, 'results': {'piqa': {'acc': 0.7747551686615887, 'acc_stderr': 0.009746643471032147, 'acc_norm': 0.779651795429815, 'acc_norm_stderr': 0.009670535456853138}, 'boolq': {'acc': 0.6443425076452599, 'acc_stderr': 0.008372726639977393}, 'arc_challenge': {'acc': 0.42662116040955633, 'acc_stderr': 0.014453185592920293, 'acc_norm': 0.4283276450511945, 'acc_norm_stderr': 0.014460496367599013}, 'arc_easy': {'acc': 0.7095959595959596, 'acc_stderr': 0.009314833302936287, 'acc_norm': 0.563973063973064, 'acc_norm_stderr': 0.010175459582759732}, 'winogrande': {'acc': 0.6614048934490924, 'acc_stderr': 0.01330016986584241}, 'hellaswag': {'acc': 0.5818562039434375, 'acc_stderr': 0.004922459820434778, 'acc_norm': 0.747361083449512, 'acc_norm_stderr': 0.004336375492801798}}, 'versions': {'piqa': 0, 'boolq': 1, 'arc_challenge': 0, 'arc_easy': 0, 'winogrande': 0, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
