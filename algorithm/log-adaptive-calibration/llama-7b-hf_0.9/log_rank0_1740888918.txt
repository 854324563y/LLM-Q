[2025-03-02 04:15:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.9', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.9.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 04:16:52 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 04:16:52 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.9.pkl
[2025-03-02 04:16:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 04:16:57 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:17:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.0031088695395737886 norm:0.002690092660486698 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.001874260837212205 norm:0.0016375239938497543 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0015919094439595938 norm:0.0015175105072557926 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.001504550687968731 norm:0.00143649079836905 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0014467278961092234 norm:0.001424369285814464 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0013813989935442805 norm:0.0013088081032037735 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0013567015994340181 norm:0.001262114499695599 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.001327704987488687 norm:0.0011379625648260117 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0012987395748496056 norm:0.0010189791209995747 max memory_allocated 22559.10693359375 
[2025-03-02 04:22:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0012853782391175628 norm:0.0009136587614193559 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0012593193678185344 norm:0.0008232032996602356 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.001243233447894454 norm:0.0007718184497207403 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0012068561045452952 norm:0.0006804789300076663 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0011957616079598665 norm:0.00061737623764202 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001187480054795742 norm:0.0005752405850216746 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0011829185532405972 norm:0.0005445734714157879 max memory_allocated 22559.10693359375 
[2025-03-02 04:26:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.001176358899101615 norm:0.0005034827045165002 max memory_allocated 22559.10693359375 
[2025-03-02 04:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.001170051284134388 norm:0.00046955945435911417 max memory_allocated 22559.10693359375 
[2025-03-02 04:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0011628781212493777 norm:0.00041757262079045177 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0011596090625971556 norm:0.00041608454193919897 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 04:28:12 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.013075601309537888 norm:0.014453801326453686 max memory_allocated 22559.27880859375 
[2025-03-02 04:29:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.007108302786946297 norm:0.00884055346250534 max memory_allocated 22559.27880859375 
[2025-03-02 04:29:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.005804415792226791 norm:0.005277273245155811 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.0053633530624210835 norm:0.00433680135756731 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.0051406011916697025 norm:0.003926185425370932 max memory_allocated 22559.27880859375 
[2025-03-02 04:31:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.004958771169185638 norm:0.0034864521585404873 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.0048597571440041065 norm:0.0032191681675612926 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.0047790491953492165 norm:0.0029951566830277443 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.004692653194069862 norm:0.0027297413907945156 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.004605742637068033 norm:0.002501262119039893 max memory_allocated 22559.27880859375 
[2025-03-02 04:34:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.004589395597577095 norm:0.0022766778711229563 max memory_allocated 22559.27880859375 
[2025-03-02 04:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.004580260254442692 norm:0.0020250079687684774 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:24 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.004528909921646118 norm:0.0018106992356479168 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.00451483903452754 norm:0.0015939396107569337 max memory_allocated 22559.27880859375 
[2025-03-02 04:36:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.00448150560259819 norm:0.0014223578618839383 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.0044608754105865955 norm:0.0012107716174796224 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.004457434173673391 norm:0.0010406080400571227 max memory_allocated 22559.27880859375 
[2025-03-02 04:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.004450657404959202 norm:0.0009623878868296742 max memory_allocated 22559.27880859375 
[2025-03-02 04:38:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004456298425793648 norm:0.0010024880757555366 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.004449703264981508 norm:0.0010652132332324982 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 04:39:29 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:40:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.11810608208179474 norm:0.03388690575957298 max memory_allocated 22559.45068359375 
[2025-03-02 04:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.040326885879039764 norm:0.02107471227645874 max memory_allocated 22559.45068359375 
[2025-03-02 04:41:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.020331036299467087 norm:0.014155340380966663 max memory_allocated 22559.45068359375 
[2025-03-02 04:41:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.01481284573674202 norm:0.008462516590952873 max memory_allocated 22559.45068359375 
[2025-03-02 04:42:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.012712517753243446 norm:0.006203690078109503 max memory_allocated 22559.45068359375 
[2025-03-02 04:42:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.01114384364336729 norm:0.004743290599435568 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.010592147707939148 norm:0.004240807611495256 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.01002479251474142 norm:0.0038879113271832466 max memory_allocated 22559.45068359375 
[2025-03-02 04:44:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.009762312285602093 norm:0.003993789199739695 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.009542999789118767 norm:0.0035988264717161655 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.009383343160152435 norm:0.0036030884366482496 max memory_allocated 22559.45068359375 
[2025-03-02 04:46:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.008951600641012192 norm:0.003456421894952655 max memory_allocated 22559.45068359375 
[2025-03-02 04:46:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.008951857686042786 norm:0.003318286966532469 max memory_allocated 22559.45068359375 
[2025-03-02 04:47:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.008791047148406506 norm:0.0030077616684138775 max memory_allocated 22559.45068359375 
[2025-03-02 04:47:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.008739076554775238 norm:0.0029962370172142982 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.00851430930197239 norm:0.0027542689349502325 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.008359065279364586 norm:0.002522818511351943 max memory_allocated 22559.45068359375 
[2025-03-02 04:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.00820588693022728 norm:0.0022087227553129196 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.008130984380841255 norm:0.0021531907841563225 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.008148051798343658 norm:0.002046407898887992 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.013979893177747726 norm:0.0020740139298141003 max memory_allocated 22559.50732421875 
[2025-03-02 04:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.010988874360918999 norm:0.0008581228903494775 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.009923308156430721 norm:0.00043183009256608784 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.009351163171231747 norm:0.0002398372598690912 max memory_allocated 22559.50732421875 
[2025-03-02 04:53:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.009071793407201767 norm:0.00016774200776126236 max memory_allocated 22559.50732421875 
[2025-03-02 04:54:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.00889350101351738 norm:0.00012095591227989644 max memory_allocated 22559.50732421875 
[2025-03-02 04:54:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.008823120035231113 norm:0.00010185359860770404 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.008795853704214096 norm:0.00010247035970678553 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.008786054328083992 norm:9.538552694721147e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.008776171132922173 norm:9.353844507131726e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.008773631416261196 norm:9.313420741818845e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.008773257955908775 norm:9.51598776737228e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.008771429769694805 norm:9.402351861353964e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:58:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.008774390444159508 norm:8.930063631851226e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.008771602995693684 norm:9.841892460826784e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:59:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.00876743532717228 norm:9.458305430598557e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.008763973601162434 norm:9.762799163581803e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.008760552853345871 norm:9.104686614591628e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.008771437220275402 norm:9.523347398499027e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.008766328915953636 norm:8.920840627979487e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 05:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.017422115430235863 norm:0.001949495985172689 max memory_allocated 22559.67919921875 
[2025-03-02 05:03:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.014009721577167511 norm:0.0008567048935219646 max memory_allocated 22559.67919921875 
[2025-03-02 05:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.012589738704264164 norm:0.00044718896970152855 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.011899847537279129 norm:0.00024287213454954326 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.011593565344810486 norm:0.0001931142614921555 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.011444504372775555 norm:0.00017469184240326285 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:52 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.011387530714273453 norm:0.00016561771917622536 max memory_allocated 22559.67919921875 
[2025-03-02 05:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.011381086893379688 norm:0.00015750170859973878 max memory_allocated 22559.67919921875 
[2025-03-02 05:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.011358421295881271 norm:0.00015911659284029156 max memory_allocated 22559.67919921875 
[2025-03-02 05:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.011359989643096924 norm:0.000157089889398776 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.011362076736986637 norm:0.00015498367429245263 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.011350449174642563 norm:0.00014195762923918664 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.011342056095600128 norm:0.00011028633161913604 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.011340739205479622 norm:0.00013901974307373166 max memory_allocated 22559.67919921875 
[2025-03-02 05:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.011335918679833412 norm:0.00010521765943849459 max memory_allocated 22559.67919921875 
[2025-03-02 05:10:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.011331303976476192 norm:0.0001278910058317706 max memory_allocated 22559.67919921875 
[2025-03-02 05:11:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.011333080939948559 norm:0.00013452388520818204 max memory_allocated 22559.67919921875 
[2025-03-02 05:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.011326654814183712 norm:0.00013030412083026022 max memory_allocated 22559.67919921875 
[2025-03-02 05:12:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.011320538818836212 norm:0.0001464116940042004 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.011318233795464039 norm:0.00014012560131959617 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 05:13:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.019527025520801544 norm:0.0019095439929515123 max memory_allocated 22559.85107421875 
[2025-03-02 05:14:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.015967775136232376 norm:0.0008681885083205998 max memory_allocated 22559.85107421875 
[2025-03-02 05:14:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.014456314034759998 norm:0.0004481386858969927 max memory_allocated 22559.85107421875 
[2025-03-02 05:15:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.013658534735441208 norm:0.00024178074090741575 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.0132939163595438 norm:0.00014296243898570538 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.013134391978383064 norm:0.00010428298992337659 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.013068269938230515 norm:8.874905324773863e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.013043452985584736 norm:8.844608964864165e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:18:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.01300891488790512 norm:8.852787141222507e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:18:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.01300162635743618 norm:8.994711242849007e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.01298731192946434 norm:8.87936184881255e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.012986866757273674 norm:8.767612598603591e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.012968814000487328 norm:8.876348147168756e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:20:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.012950574047863483 norm:8.552692452212796e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:21:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.012939723208546638 norm:8.637999417260289e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.012932008132338524 norm:8.567860641051084e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:22:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.01293342188000679 norm:8.678600715938956e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.01293567568063736 norm:8.808157872408628e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:23:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.01292913407087326 norm:9.125081123784184e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.012925921939313412 norm:8.777770563028753e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 05:25:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.019280042499303818 norm:0.0010835016146302223 max memory_allocated 22560.02294921875 
[2025-03-02 05:25:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.017382459715008736 norm:0.00038334657438099384 max memory_allocated 22560.02294921875 
[2025-03-02 05:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.016547495499253273 norm:0.00020299288735259324 max memory_allocated 22560.02294921875 
[2025-03-02 05:26:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.01589510217308998 norm:0.00013792853860650212 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.015445184893906116 norm:0.00010781885066535324 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.01524078194051981 norm:9.213104203809053e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.015178324654698372 norm:7.601594552397728e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.015155680477619171 norm:7.332283712457865e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:29:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.015146293677389622 norm:6.969118840061128e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:30:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.01513606682419777 norm:6.696007767459378e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:30:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.015131961554288864 norm:6.565295916516334e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:31:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.0151250334456563 norm:6.481270247604698e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.01511965412646532 norm:6.439383287215605e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:32:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.015115117654204369 norm:6.568907701876014e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:32:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.015112994238734245 norm:6.526865035993978e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.015110436826944351 norm:6.433987437048927e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.015107588842511177 norm:6.180714990478009e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:34:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.015105130150914192 norm:6.14233358646743e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:34:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.015103175304830074 norm:6.123225466581061e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.015100863762199879 norm:6.0897615185240284e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:35:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 05:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.024368824437260628 norm:0.0011535726953297853 max memory_allocated 22560.19482421875 
[2025-03-02 05:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.02029435709118843 norm:0.0005509338807314634 max memory_allocated 22560.19482421875 
[2025-03-02 05:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.018805133178830147 norm:0.0003165309317409992 max memory_allocated 22560.19482421875 
[2025-03-02 05:37:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.018060682341456413 norm:0.00023029452131595463 max memory_allocated 22560.19482421875 
[2025-03-02 05:38:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.0176191795617342 norm:0.00018802890554070473 max memory_allocated 22560.19482421875 
[2025-03-02 05:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.017340118065476418 norm:0.00016395408601965755 max memory_allocated 22560.19482421875 
[2025-03-02 05:39:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.01722690463066101 norm:0.00017256982391700149 max memory_allocated 22560.19482421875 
[2025-03-02 05:40:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.017198767513036728 norm:0.00016116350889205933 max memory_allocated 22560.19482421875 
[2025-03-02 05:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.017088910564780235 norm:0.0001411691919201985 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.017040718346834183 norm:0.0001313394313910976 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.016986394301056862 norm:0.0001313631219090894 max memory_allocated 22560.19482421875 
[2025-03-02 05:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.01699215918779373 norm:0.00014032227045390755 max memory_allocated 22560.19482421875 
[2025-03-02 05:42:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.016974519938230515 norm:0.00013059792399872094 max memory_allocated 22560.19482421875 
[2025-03-02 05:43:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.01696602627635002 norm:0.00013581036182586104 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.016957568004727364 norm:0.0001326255005551502 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.016910549253225327 norm:0.0001257220865227282 max memory_allocated 22560.19482421875 
[2025-03-02 05:45:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.016886189579963684 norm:0.0001226141321239993 max memory_allocated 22560.19482421875 
[2025-03-02 05:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.01688796654343605 norm:0.00012712142779491842 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.01690440997481346 norm:0.0001243989245267585 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:47 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.016873477026820183 norm:0.0001254839589819312 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:47:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.025279521942138672 norm:0.0008578056585974991 max memory_allocated 22560.36669921875 
[2025-03-02 05:48:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.02154933661222458 norm:0.0003901065792888403 max memory_allocated 22560.36669921875 
[2025-03-02 05:48:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.020245157182216644 norm:0.0002579588908702135 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.01956808753311634 norm:0.00018246436957269907 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.019153892993927002 norm:0.00017055981152225286 max memory_allocated 22560.36669921875 
[2025-03-02 05:50:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.018887415528297424 norm:0.00016859386232681572 max memory_allocated 22560.36669921875 
[2025-03-02 05:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.018723653629422188 norm:0.00015362307021860033 max memory_allocated 22560.36669921875 
[2025-03-02 05:51:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.018626723438501358 norm:0.0001529423170723021 max memory_allocated 22560.36669921875 
[2025-03-02 05:51:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.0185677632689476 norm:0.0001474146411055699 max memory_allocated 22560.36669921875 
[2025-03-02 05:52:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.018517140299081802 norm:0.00014808661944698542 max memory_allocated 22560.36669921875 
[2025-03-02 05:53:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.018443947657942772 norm:0.00014439187361858785 max memory_allocated 22560.36669921875 
[2025-03-02 05:53:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.018433313816785812 norm:0.00015300934319384396 max memory_allocated 22560.36669921875 
[2025-03-02 05:54:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.018400952219963074 norm:0.0001459503691876307 max memory_allocated 22560.36669921875 
[2025-03-02 05:54:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.018403319641947746 norm:0.00013766283518634737 max memory_allocated 22560.36669921875 
[2025-03-02 05:55:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.018397238105535507 norm:0.00013097691407892853 max memory_allocated 22560.36669921875 
[2025-03-02 05:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.01840735226869583 norm:0.0001376137661281973 max memory_allocated 22560.36669921875 
[2025-03-02 05:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.018405407667160034 norm:0.0001412330602761358 max memory_allocated 22560.36669921875 
[2025-03-02 05:56:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.01838580146431923 norm:0.0001383479539072141 max memory_allocated 22560.36669921875 
[2025-03-02 05:57:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.018412834033370018 norm:0.0001452386350138113 max memory_allocated 22560.36669921875 
[2025-03-02 05:58:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.01839291676878929 norm:0.00014063470007386059 max memory_allocated 22560.36669921875 
[2025-03-02 05:58:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 05:58:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.029161881655454636 norm:0.0010927206603810191 max memory_allocated 22560.53857421875 
[2025-03-02 05:59:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.024528592824935913 norm:0.0005183186149224639 max memory_allocated 22560.53857421875 
[2025-03-02 05:59:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.02266075275838375 norm:0.00031210138695314527 max memory_allocated 22560.53857421875 
[2025-03-02 06:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.021819278597831726 norm:0.00022678592358715832 max memory_allocated 22560.53857421875 
[2025-03-02 06:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.021279877051711082 norm:0.000189884114661254 max memory_allocated 22560.53857421875 
[2025-03-02 06:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.02101641707122326 norm:0.00017048788140527904 max memory_allocated 22560.53857421875 
[2025-03-02 06:02:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.020808229222893715 norm:0.00016344433242920786 max memory_allocated 22560.53857421875 
[2025-03-02 06:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.020699843764305115 norm:0.0001486845430918038 max memory_allocated 22560.53857421875 
[2025-03-02 06:03:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.02060616761445999 norm:0.00014308297249954194 max memory_allocated 22560.53857421875 
[2025-03-02 06:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.020534658804535866 norm:0.0001426805683877319 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.020498670637607574 norm:0.00013435193977784365 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.020444834604859352 norm:0.0001257338299183175 max memory_allocated 22560.53857421875 
[2025-03-02 06:05:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.020428672432899475 norm:0.00012400221021380275 max memory_allocated 22560.53857421875 
[2025-03-02 06:05:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.02039639838039875 norm:0.00012039424473186955 max memory_allocated 22560.53857421875 
[2025-03-02 06:06:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.020359991118311882 norm:0.00012250905274413526 max memory_allocated 22560.53857421875 
[2025-03-02 06:07:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.020356016233563423 norm:0.00011913508933503181 max memory_allocated 22560.53857421875 
[2025-03-02 06:07:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.020349157974123955 norm:0.00012048862845404074 max memory_allocated 22560.53857421875 
[2025-03-02 06:08:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.020351115614175797 norm:0.00011841446394100785 max memory_allocated 22560.53857421875 
[2025-03-02 06:08:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.02040714956820011 norm:0.00013006551307626069 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.020355353131890297 norm:0.00011953765351790935 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 06:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.027275964617729187 norm:0.0007744351751171052 max memory_allocated 22560.71044921875 
[2025-03-02 06:10:36 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.02464122883975506 norm:0.0003673722967505455 max memory_allocated 22560.71044921875 
[2025-03-02 06:11:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.023509405553340912 norm:0.0002313095610588789 max memory_allocated 22560.71044921875 
[2025-03-02 06:11:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.022865615785121918 norm:0.00017529859906062484 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.022386647760868073 norm:0.00014558799739461392 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.02213704213500023 norm:0.00012634995800908655 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.02200971357524395 norm:0.00011631425149971619 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.021952804177999496 norm:0.00010692948126234114 max memory_allocated 22560.71044921875 
[2025-03-02 06:14:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.02189161255955696 norm:0.00010274584928993136 max memory_allocated 22560.71044921875 
[2025-03-02 06:15:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.02183511108160019 norm:9.977862646337599e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:15:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.021813662722706795 norm:0.0001023966251523234 max memory_allocated 22560.71044921875 
[2025-03-02 06:16:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.021784262731671333 norm:9.570230031386018e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:16:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.021757977083325386 norm:9.480487642576918e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.0217372328042984 norm:9.380580740980804e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.021731069311499596 norm:9.242982923751697e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.021722158417105675 norm:9.521716856397688e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:18:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.02170884981751442 norm:9.10487724468112e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.021704677492380142 norm:9.170854900730774e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:19:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.02169528417289257 norm:9.113369742408395e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.021693315356969833 norm:9.197547478834167e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 06:21:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.027881186455488205 norm:0.0008307840907946229 max memory_allocated 22560.88232421875 
[2025-03-02 06:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.025154083967208862 norm:0.00038270436925813556 max memory_allocated 22560.88232421875 
[2025-03-02 06:22:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.02411646395921707 norm:0.00023810358834452927 max memory_allocated 22560.88232421875 
[2025-03-02 06:22:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.023412518203258514 norm:0.00015246219118125737 max memory_allocated 22560.88232421875 
[2025-03-02 06:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.023006878793239594 norm:0.00012283393880352378 max memory_allocated 22560.88232421875 
[2025-03-02 06:24:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.022782329469919205 norm:0.00011400811490602791 max memory_allocated 22560.88232421875 
[2025-03-02 06:24:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.022665170952677727 norm:0.00010275850218022242 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.022611305117607117 norm:0.00010714024392655119 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.022526126354932785 norm:9.384662553202361e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:26:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.022476093843579292 norm:8.945321314968169e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:26:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.022461140528321266 norm:9.214348392561078e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:27:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.02244751527905464 norm:8.818299829727039e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:27:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.02243410050868988 norm:8.801525109447539e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:28:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.022433623671531677 norm:8.902465197024867e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.02242199331521988 norm:8.813995373202488e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.022396087646484375 norm:8.908491145120934e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.022373467683792114 norm:8.63621971802786e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.022395934909582138 norm:8.773486479185522e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.022387877106666565 norm:8.642178727313876e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.022399313747882843 norm:8.993798110168427e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 06:32:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.028730079531669617 norm:0.0005634478875435889 max memory_allocated 22561.05419921875 
[2025-03-02 06:33:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.026464346796274185 norm:0.0003058764850720763 max memory_allocated 22561.05419921875 
[2025-03-02 06:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.02534845843911171 norm:0.00020707820658572018 max memory_allocated 22561.05419921875 
[2025-03-02 06:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.024632180109620094 norm:0.0001673906372161582 max memory_allocated 22561.05419921875 
[2025-03-02 06:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.024208109825849533 norm:0.00014483449922408909 max memory_allocated 22561.05419921875 
[2025-03-02 06:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.02391928993165493 norm:0.00013169008889235556 max memory_allocated 22561.05419921875 
[2025-03-02 06:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.02372894063591957 norm:0.00011932521738344803 max memory_allocated 22561.05419921875 
[2025-03-02 06:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.023636646568775177 norm:0.00010923920490313321 max memory_allocated 22561.05419921875 
[2025-03-02 06:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.023611128330230713 norm:0.00010518466297071427 max memory_allocated 22561.05419921875 
[2025-03-02 06:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.023535149171948433 norm:9.612116264179349e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.02348673716187477 norm:8.801855437923223e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.02346675470471382 norm:8.595183317083865e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.02348337695002556 norm:8.396997873205692e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.0234631709754467 norm:8.058426465140656e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:40:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.023447811603546143 norm:8.291361154988408e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.02342943660914898 norm:8.17640102468431e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.023423172533512115 norm:8.301675552502275e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.02341081015765667 norm:8.21953872218728e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:42:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.023411188274621964 norm:8.303710637846962e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:43:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.023409025743603706 norm:8.376901678275317e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:43:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 06:43:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.02913215197622776 norm:0.0005384284304454923 max memory_allocated 22561.22607421875 
[2025-03-02 06:44:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.0271560437977314 norm:0.00027559458976611495 max memory_allocated 22561.22607421875 
[2025-03-02 06:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.026155054569244385 norm:0.0001841984922066331 max memory_allocated 22561.22607421875 
[2025-03-02 06:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.0256056971848011 norm:0.00015030044596642256 max memory_allocated 22561.22607421875 
[2025-03-02 06:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.025178276002407074 norm:0.00012981114559806883 max memory_allocated 22561.22607421875 
[2025-03-02 06:46:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.024890189990401268 norm:0.00011000248923664913 max memory_allocated 22561.22607421875 
[2025-03-02 06:47:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.024770744144916534 norm:0.00010101770021719858 max memory_allocated 22561.22607421875 
[2025-03-02 06:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.024698978289961815 norm:9.527298243483528e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.024649739265441895 norm:8.907095616450533e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.02459697797894478 norm:8.75570040079765e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.02455250173807144 norm:7.95762098277919e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.024546394124627113 norm:8.122158760670573e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.024537481367588043 norm:7.2783965151757e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.024522988125681877 norm:7.637021917616948e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:51:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.024495713412761688 norm:7.648614700883627e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:52:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.024482887238264084 norm:7.702951552346349e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:52:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.02448444627225399 norm:7.626192382303998e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:53:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.02447928674519062 norm:7.61270202929154e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:53:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.024474795907735825 norm:7.59144386393018e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.02446414902806282 norm:7.587531581521034e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:55:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.03285801410675049 norm:0.0009826227324083447 max memory_allocated 22561.39794921875 
[2025-03-02 06:55:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.029575854539871216 norm:0.0004559404915198684 max memory_allocated 22561.39794921875 
[2025-03-02 06:56:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.028172029182314873 norm:0.00027917034458369017 max memory_allocated 22561.39794921875 
[2025-03-02 06:56:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.027442246675491333 norm:0.00020172020595055073 max memory_allocated 22561.39794921875 
[2025-03-02 06:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.026973282918334007 norm:0.00016544344543945044 max memory_allocated 22561.39794921875 
[2025-03-02 06:57:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.026725392788648605 norm:0.00013987848069518805 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.026569359004497528 norm:0.00012298054934944957 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.0264500230550766 norm:0.00011541610001586378 max memory_allocated 22561.39794921875 
[2025-03-02 06:59:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.02636161632835865 norm:0.00010801008465932682 max memory_allocated 22561.39794921875 
[2025-03-02 07:00:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.02630254440009594 norm:0.00010640617256285623 max memory_allocated 22561.39794921875 
[2025-03-02 07:00:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.026260672137141228 norm:9.518650767859071e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:01:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.02622435986995697 norm:9.447170305065811e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:01:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.026200242340564728 norm:8.945423178374767e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.026210032403469086 norm:9.046056220540777e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.026188429445028305 norm:8.591439109295607e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:03:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.026207229122519493 norm:8.89988150447607e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:03:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.026196403428912163 norm:8.920059190131724e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:04:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.02615875005722046 norm:8.533953223377466e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:04:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.026151565834879875 norm:8.927988528739661e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.026138808578252792 norm:8.52361845318228e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 07:06:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.03257790580391884 norm:0.0006786926533095539 max memory_allocated 22561.56982421875 
[2025-03-02 07:06:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.03062427043914795 norm:0.0003353215579409152 max memory_allocated 22561.56982421875 
[2025-03-02 07:07:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.029567565768957138 norm:0.00020688274526037276 max memory_allocated 22561.56982421875 
[2025-03-02 07:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.02890210598707199 norm:0.00014977995306253433 max memory_allocated 22561.56982421875 
[2025-03-02 07:08:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.028484713286161423 norm:0.00013127124111633748 max memory_allocated 22561.56982421875 
[2025-03-02 07:09:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.028213389217853546 norm:0.00011181685840710998 max memory_allocated 22561.56982421875 
[2025-03-02 07:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.028108172118663788 norm:9.881755977403373e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.02800244279205799 norm:9.16603094083257e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.02798776887357235 norm:8.666539361001924e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:11:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.027969732880592346 norm:0.00010265043238177896 max memory_allocated 22561.56982421875 
[2025-03-02 07:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.027930885553359985 norm:8.55486432556063e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.02787560597062111 norm:8.150799112627283e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.027859490364789963 norm:7.755478873150423e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.02784774638712406 norm:7.622189878020436e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:14:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.027826450765132904 norm:7.784899207763374e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.027834737673401833 norm:8.539555710740387e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.027822116389870644 norm:8.154480019584298e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.027797773480415344 norm:7.712604565313086e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.027799248695373535 norm:7.44433855288662e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.027795981615781784 norm:7.387957157334313e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 07:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.037127554416656494 norm:0.0009575217845849693 max memory_allocated 22561.74169921875 
[2025-03-02 07:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.03380754962563515 norm:0.0003574363945517689 max memory_allocated 22561.74169921875 
[2025-03-02 07:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.03248270973563194 norm:0.00022149208234623075 max memory_allocated 22561.74169921875 
[2025-03-02 07:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.03169979900121689 norm:0.00018080364679917693 max memory_allocated 22561.74169921875 
[2025-03-02 07:19:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.03122338280081749 norm:0.00015633407747372985 max memory_allocated 22561.74169921875 
[2025-03-02 07:20:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.030942227691411972 norm:0.0001386022922815755 max memory_allocated 22561.74169921875 
[2025-03-02 07:20:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.03084499202668667 norm:0.0001294573157792911 max memory_allocated 22561.74169921875 
[2025-03-02 07:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.0307126734405756 norm:0.00010815711721079424 max memory_allocated 22561.74169921875 
[2025-03-02 07:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.03061717562377453 norm:0.0001041121722664684 max memory_allocated 22561.74169921875 
[2025-03-02 07:22:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.030553320422768593 norm:0.0001041824507410638 max memory_allocated 22561.74169921875 
[2025-03-02 07:23:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.03054322674870491 norm:9.921784658217803e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.03050874173641205 norm:0.00010110725997947156 max memory_allocated 22561.74169921875 
[2025-03-02 07:24:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.03046819567680359 norm:9.904017497319728e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.0304438266903162 norm:9.312478505307809e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.030434148386120796 norm:9.24295891309157e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.030434858053922653 norm:9.369959298055619e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:26:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.03042207658290863 norm:9.255114127881825e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.030404234305024147 norm:9.104367200052366e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.030376743525266647 norm:8.657041325932369e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.030365370213985443 norm:8.7996173533611e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:28:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 07:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.040488503873348236 norm:0.0011554511729627848 max memory_allocated 22561.91357421875 
[2025-03-02 07:29:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.037459537386894226 norm:0.00048175526899285614 max memory_allocated 22561.91357421875 
[2025-03-02 07:29:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.0359455831348896 norm:0.00027619872707873583 max memory_allocated 22561.91357421875 
[2025-03-02 07:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.03510862588882446 norm:0.00020413397578522563 max memory_allocated 22561.91357421875 
[2025-03-02 07:30:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.034555498510599136 norm:0.00015809861361049116 max memory_allocated 22561.91357421875 
[2025-03-02 07:31:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.03434596583247185 norm:0.00013708519691135734 max memory_allocated 22561.91357421875 
[2025-03-02 07:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.03421781212091446 norm:0.00012783557758666575 max memory_allocated 22561.91357421875 
[2025-03-02 07:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.03412289544939995 norm:0.00010638715320965275 max memory_allocated 22561.91357421875 
[2025-03-02 07:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.03404755890369415 norm:9.927438804879785e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.03400488197803497 norm:9.75889342953451e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:34:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.03397037461400032 norm:9.161638445220888e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:34:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.03396737203001976 norm:8.631443051854149e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.03394881263375282 norm:8.960620471043512e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:35:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.03393568471074104 norm:9.114446584135294e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:36:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.03391468524932861 norm:8.571979560656473e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.033904969692230225 norm:8.523338328814134e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:37:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.033895183354616165 norm:8.70659205247648e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.03386649489402771 norm:8.511218038620427e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.03385300189256668 norm:8.679166057845578e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.03383263573050499 norm:8.613428508397192e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 07:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.043744441121816635 norm:0.0005701953778043389 max memory_allocated 22562.08544921875 
[2025-03-02 07:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.041409578174352646 norm:0.0002612047246657312 max memory_allocated 22562.08544921875 
[2025-03-02 07:41:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.04041682183742523 norm:0.00019405008060857654 max memory_allocated 22562.08544921875 
[2025-03-02 07:41:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.03960103541612625 norm:0.0001543367252452299 max memory_allocated 22562.08544921875 
[2025-03-02 07:42:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.039148908108472824 norm:0.00013140865485183895 max memory_allocated 22562.08544921875 
[2025-03-02 07:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.03895147144794464 norm:0.00011857385106850415 max memory_allocated 22562.08544921875 
[2025-03-02 07:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.038832180202007294 norm:0.00010681770800147206 max memory_allocated 22562.08544921875 
[2025-03-02 07:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.03877825662493706 norm:0.00010042785288533196 max memory_allocated 22562.08544921875 
[2025-03-02 07:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.038709260523319244 norm:9.14629126782529e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.03865472599864006 norm:8.43777961563319e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.03862491995096207 norm:8.970021735876799e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.03860891982913017 norm:8.49762509460561e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.03857791796326637 norm:7.836187432985753e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.03857143595814705 norm:7.843091589165851e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.03855574131011963 norm:7.560876838397235e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:48:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.03854668512940407 norm:7.692835060879588e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.03852725028991699 norm:7.696420652791858e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:49:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.03853940963745117 norm:7.889256812632084e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.03853124752640724 norm:7.849809480831027e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.03851565718650818 norm:7.813796401023865e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:50:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.05044911801815033 norm:0.0008432819740846753 max memory_allocated 22562.25732421875 
[2025-03-02 07:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.04786333814263344 norm:0.0003362168208695948 max memory_allocated 22562.25732421875 
[2025-03-02 07:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.046659812331199646 norm:0.000223444658331573 max memory_allocated 22562.25732421875 
[2025-03-02 07:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.04580388590693474 norm:0.000173518608789891 max memory_allocated 22562.25732421875 
[2025-03-02 07:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.045340292155742645 norm:0.0001455411984352395 max memory_allocated 22562.25732421875 
[2025-03-02 07:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.04512473940849304 norm:0.00012513846741057932 max memory_allocated 22562.25732421875 
[2025-03-02 07:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.04501166567206383 norm:0.00011446492135291919 max memory_allocated 22562.25732421875 
[2025-03-02 07:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.04494444653391838 norm:0.0001194538053823635 max memory_allocated 22562.25732421875 
[2025-03-02 07:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.04488091915845871 norm:0.00011210022785235196 max memory_allocated 22562.25732421875 
[2025-03-02 07:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.04482179135084152 norm:9.848809713730589e-05 max memory_allocated 22562.25732421875 
[2025-03-02 07:56:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.0447809174656868 norm:0.00010178628872381523 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.04477299004793167 norm:0.00010485468374099582 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.044752705842256546 norm:9.695936751086265e-05 max memory_allocated 22562.25732421875 
[2025-03-02 07:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.04472443833947182 norm:9.885764302453026e-05 max memory_allocated 22562.25732421875 
[2025-03-02 07:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.04470766335725784 norm:9.65169892879203e-05 max memory_allocated 22562.25732421875 
[2025-03-02 07:59:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.04470212012529373 norm:9.347977174911648e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:00:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.044687479734420776 norm:9.574773139320314e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.04466893896460533 norm:9.382921416545287e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.04465843737125397 norm:9.383632277604192e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.04465930163860321 norm:9.604870137991384e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 08:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.06183767318725586 norm:0.0021365932188928127 max memory_allocated 22562.42919921875 
[2025-03-02 08:03:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.05753440782427788 norm:0.0006413851515389979 max memory_allocated 22562.42919921875 
[2025-03-02 08:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.055647656321525574 norm:0.00036242319038137794 max memory_allocated 22562.42919921875 
[2025-03-02 08:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.054467037320137024 norm:0.0002923729189205915 max memory_allocated 22562.42919921875 
[2025-03-02 08:04:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.05395640432834625 norm:0.0002509805781301111 max memory_allocated 22562.42919921875 
[2025-03-02 08:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.05368581414222717 norm:0.00020182774460408837 max memory_allocated 22562.42919921875 
[2025-03-02 08:05:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.0535418726503849 norm:0.00018571686814539135 max memory_allocated 22562.42919921875 
[2025-03-02 08:06:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.0534578338265419 norm:0.00017840217333287 max memory_allocated 22562.42919921875 
[2025-03-02 08:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.053338658064603806 norm:0.0001587384904269129 max memory_allocated 22562.42919921875 
[2025-03-02 08:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.05323527380824089 norm:0.00014297929010353982 max memory_allocated 22562.42919921875 
[2025-03-02 08:08:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.05318336933851242 norm:0.00013345789921004325 max memory_allocated 22562.42919921875 
[2025-03-02 08:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.05314365774393082 norm:0.00013006533845327795 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.05308643728494644 norm:0.00012654192687477916 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.05305873975157738 norm:0.00012657219485845417 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.05303669720888138 norm:0.00013108989514876157 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.053039055317640305 norm:0.00013234274229034781 max memory_allocated 22562.42919921875 
[2025-03-02 08:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.05300625041127205 norm:0.00013747029879596084 max memory_allocated 22562.42919921875 
[2025-03-02 08:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.052980173379182816 norm:0.0001264842867385596 max memory_allocated 22562.42919921875 
[2025-03-02 08:12:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.05295464023947716 norm:0.0001274441892746836 max memory_allocated 22562.42919921875 
[2025-03-02 08:12:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.05293693393468857 norm:0.00012760187382809818 max memory_allocated 22562.42919921875 
[2025-03-02 08:13:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 08:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.07029124349355698 norm:0.002231437712907791 max memory_allocated 22562.60107421875 
[2025-03-02 08:14:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.06732425093650818 norm:0.0007960700313560665 max memory_allocated 22562.60107421875 
[2025-03-02 08:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.06565695255994797 norm:0.00046581903006881475 max memory_allocated 22562.60107421875 
[2025-03-02 08:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.06449034065008163 norm:0.00036592164542526007 max memory_allocated 22562.60107421875 
[2025-03-02 08:15:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.06402556598186493 norm:0.00032309757079929113 max memory_allocated 22562.60107421875 
[2025-03-02 08:16:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.06381785869598389 norm:0.000275729747954756 max memory_allocated 22562.60107421875 
[2025-03-02 08:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.06368745863437653 norm:0.0002587147173471749 max memory_allocated 22562.60107421875 
[2025-03-02 08:17:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.0635528564453125 norm:0.00022103603987488896 max memory_allocated 22562.60107421875 
[2025-03-02 08:18:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.06347810477018356 norm:0.00020457296341191977 max memory_allocated 22562.60107421875 
[2025-03-02 08:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.06339608132839203 norm:0.0001858646865002811 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.0633627399802208 norm:0.00016745395259931684 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.06332365423440933 norm:0.00015849166084080935 max memory_allocated 22562.60107421875 
[2025-03-02 08:20:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.06328180432319641 norm:0.00014849271974526346 max memory_allocated 22562.60107421875 
[2025-03-02 08:20:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.06325788050889969 norm:0.00013595190830528736 max memory_allocated 22562.60107421875 
[2025-03-02 08:21:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.06322164088487625 norm:0.00012821456766687334 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.06320520490407944 norm:0.00012054125545546412 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:35 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.06317194551229477 norm:0.00013317006232682616 max memory_allocated 22562.60107421875 
[2025-03-02 08:23:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.06315376609563828 norm:0.00012489382061176002 max memory_allocated 22562.60107421875 
[2025-03-02 08:23:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.06314340978860855 norm:0.0001304501638514921 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.06313750147819519 norm:0.00013065760140307248 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 08:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.08087293058633804 norm:0.0013935634633526206 max memory_allocated 22562.77294921875 
[2025-03-02 08:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.07815651595592499 norm:0.0006182760698720813 max memory_allocated 22562.77294921875 
[2025-03-02 08:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.07642190158367157 norm:0.0003955377615056932 max memory_allocated 22562.77294921875 
[2025-03-02 08:26:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.07519032061100006 norm:0.0002827063435688615 max memory_allocated 22562.77294921875 
[2025-03-02 08:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.0748421922326088 norm:0.00022455293219536543 max memory_allocated 22562.77294921875 
[2025-03-02 08:27:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.07470571994781494 norm:0.0001888990227598697 max memory_allocated 22562.77294921875 
[2025-03-02 08:28:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.07461084425449371 norm:0.0001677313557593152 max memory_allocated 22562.77294921875 
[2025-03-02 08:28:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.07449957728385925 norm:0.00015522746252827346 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.07444549351930618 norm:0.0001371681282762438 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.07440900802612305 norm:0.00013358626165427268 max memory_allocated 22562.77294921875 
[2025-03-02 08:30:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.07438161969184875 norm:0.0001224283769261092 max memory_allocated 22562.77294921875 
[2025-03-02 08:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.07435213029384613 norm:0.00012153893476352096 max memory_allocated 22562.77294921875 
[2025-03-02 08:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.0743289366364479 norm:0.0001172867341665551 max memory_allocated 22562.77294921875 
[2025-03-02 08:32:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.07432630658149719 norm:0.000115662143798545 max memory_allocated 22562.77294921875 
[2025-03-02 08:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.07429562509059906 norm:0.00011292021372355521 max memory_allocated 22562.77294921875 
[2025-03-02 08:33:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.0742763951420784 norm:0.00011164056923007593 max memory_allocated 22562.77294921875 
[2025-03-02 08:33:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.07426416873931885 norm:0.00011548818292794749 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.07424619793891907 norm:0.00011705578799592331 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.07424268126487732 norm:0.00011494567297631875 max memory_allocated 22562.77294921875 
[2025-03-02 08:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.07424693554639816 norm:0.00011569645721465349 max memory_allocated 22562.77294921875 
[2025-03-02 08:35:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 08:36:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.09493163228034973 norm:0.001643689232878387 max memory_allocated 22562.94482421875 
[2025-03-02 08:36:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.09204013645648956 norm:0.0008626861381344497 max memory_allocated 22562.94482421875 
[2025-03-02 08:37:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.09027880430221558 norm:0.0005653267726302147 max memory_allocated 22562.94482421875 
[2025-03-02 08:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.0889519676566124 norm:0.000396952498704195 max memory_allocated 22562.94482421875 
[2025-03-02 08:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.08857984095811844 norm:0.00031082777422852814 max memory_allocated 22562.94482421875 
[2025-03-02 08:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.0883532464504242 norm:0.00026221081498079 max memory_allocated 22562.94482421875 
[2025-03-02 08:39:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.08811574429273605 norm:0.0002223574701929465 max memory_allocated 22562.94482421875 
[2025-03-02 08:40:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.08798497170209885 norm:0.00019858423911500722 max memory_allocated 22562.94482421875 
[2025-03-02 08:40:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.08787621557712555 norm:0.00018649183039087802 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.08784350752830505 norm:0.0001747707574395463 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.08774997293949127 norm:0.00016440136823803186 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.08767655491828918 norm:0.00015975878341123462 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.08763724565505981 norm:0.00015298821381293237 max memory_allocated 22562.94482421875 
[2025-03-02 08:43:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.08760149776935577 norm:0.0001588072336744517 max memory_allocated 22562.94482421875 
[2025-03-02 08:43:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.08758273720741272 norm:0.0001520360092399642 max memory_allocated 22562.94482421875 
[2025-03-02 08:44:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.08758775144815445 norm:0.0001565244747325778 max memory_allocated 22562.94482421875 
[2025-03-02 08:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.08760121464729309 norm:0.00015315113705582917 max memory_allocated 22562.94482421875 
[2025-03-02 08:45:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.08757569640874863 norm:0.00015486477059312165 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.08751939982175827 norm:0.00015003531007096171 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.08750686049461365 norm:0.00014907284639775753 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.10775348544120789 norm:0.0008503652643412352 max memory_allocated 22563.11669921875 
[2025-03-02 08:48:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.10552696883678436 norm:0.00046631222357973456 max memory_allocated 22563.11669921875 
[2025-03-02 08:48:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.1037413477897644 norm:0.00033881794661283493 max memory_allocated 22563.11669921875 
[2025-03-02 08:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.10254578292369843 norm:0.00026681169401854277 max memory_allocated 22563.11669921875 
[2025-03-02 08:49:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.10221567004919052 norm:0.00022433009871747345 max memory_allocated 22563.11669921875 
[2025-03-02 08:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.1019972562789917 norm:0.0001984703412745148 max memory_allocated 22563.11669921875 
[2025-03-02 08:50:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.10185221582651138 norm:0.00018407520838081837 max memory_allocated 22563.11669921875 
[2025-03-02 08:51:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.10175290703773499 norm:0.00016333848179783672 max memory_allocated 22563.11669921875 
[2025-03-02 08:51:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.10164406895637512 norm:0.0001526110718259588 max memory_allocated 22563.11669921875 
[2025-03-02 08:52:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.10155695676803589 norm:0.00014847677084617317 max memory_allocated 22563.11669921875 
[2025-03-02 08:53:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.10150612145662308 norm:0.0001426097733201459 max memory_allocated 22563.11669921875 
[2025-03-02 08:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.10145338624715805 norm:0.00013629093882627785 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.10143280029296875 norm:0.00013527984265238047 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.1013861894607544 norm:0.0001336315181106329 max memory_allocated 22563.11669921875 
[2025-03-02 08:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.1013578251004219 norm:0.00013043881335761398 max memory_allocated 22563.11669921875 
[2025-03-02 08:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.10134731233119965 norm:0.00012882845476269722 max memory_allocated 22563.11669921875 
[2025-03-02 08:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.10133592039346695 norm:0.00012718902144115418 max memory_allocated 22563.11669921875 
[2025-03-02 08:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.10132342576980591 norm:0.0001261061552213505 max memory_allocated 22563.11669921875 
[2025-03-02 08:57:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.10129273682832718 norm:0.0001268049527425319 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.10129700601100922 norm:0.0001303800381720066 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 08:58:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.12554873526096344 norm:0.0015040278667584062 max memory_allocated 22563.28857421875 
[2025-03-02 08:59:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.12275470793247223 norm:0.0007437618332915008 max memory_allocated 22563.28857421875 
[2025-03-02 08:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.12039221078157425 norm:0.00048610049998387694 max memory_allocated 22563.28857421875 
[2025-03-02 09:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.11901511996984482 norm:0.0003394452796783298 max memory_allocated 22563.28857421875 
[2025-03-02 09:00:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.11873903125524521 norm:0.0002622325555421412 max memory_allocated 22563.28857421875 
[2025-03-02 09:01:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.11861314624547958 norm:0.00022205720597412437 max memory_allocated 22563.28857421875 
[2025-03-02 09:02:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.11852667480707169 norm:0.00019384946790523827 max memory_allocated 22563.28857421875 
[2025-03-02 09:02:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.118441142141819 norm:0.00017292448319494724 max memory_allocated 22563.28857421875 
[2025-03-02 09:03:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.11840128153562546 norm:0.00016251797205768526 max memory_allocated 22563.28857421875 
[2025-03-02 09:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.11834423243999481 norm:0.00015230340068228543 max memory_allocated 22563.28857421875 
[2025-03-02 09:04:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.1183028370141983 norm:0.00014396898041013628 max memory_allocated 22563.28857421875 
[2025-03-02 09:04:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.11825360357761383 norm:0.00013849863898940384 max memory_allocated 22563.28857421875 
[2025-03-02 09:05:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.11823157221078873 norm:0.00013799310545437038 max memory_allocated 22563.28857421875 
[2025-03-02 09:05:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.11819908022880554 norm:0.00013415270950645208 max memory_allocated 22563.28857421875 
[2025-03-02 09:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.11818738281726837 norm:0.00012910088116768748 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.11817432940006256 norm:0.00012926680210512131 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.11815399676561356 norm:0.000127292238175869 max memory_allocated 22563.28857421875 
[2025-03-02 09:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.11813374608755112 norm:0.00012589487596414983 max memory_allocated 22563.28857421875 
[2025-03-02 09:08:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.118122398853302 norm:0.0001262767764274031 max memory_allocated 22563.28857421875 
[2025-03-02 09:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.11812584102153778 norm:0.00012648080883082002 max memory_allocated 22563.28857421875 
[2025-03-02 09:09:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 09:10:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.14843861758708954 norm:0.005088394042104483 max memory_allocated 22563.46044921875 
[2025-03-02 09:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.14333575963974 norm:0.0025636437349021435 max memory_allocated 22563.46044921875 
[2025-03-02 09:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.14004959166049957 norm:0.001549523207359016 max memory_allocated 22563.46044921875 
[2025-03-02 09:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.1383182406425476 norm:0.0010335722472518682 max memory_allocated 22563.46044921875 
[2025-03-02 09:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.1377059370279312 norm:0.0007427969248965383 max memory_allocated 22563.46044921875 
[2025-03-02 09:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.1373460590839386 norm:0.0005627509672194719 max memory_allocated 22563.46044921875 
[2025-03-02 09:13:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.13712908327579498 norm:0.00044561101822182536 max memory_allocated 22563.46044921875 
[2025-03-02 09:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.13701213896274567 norm:0.00036972793168388307 max memory_allocated 22563.46044921875 
[2025-03-02 09:14:25 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.1368807554244995 norm:0.0003220735816285014 max memory_allocated 22563.46044921875 
[2025-03-02 09:14:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.13677240908145905 norm:0.000283774541458115 max memory_allocated 22563.46044921875 
[2025-03-02 09:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.13668930530548096 norm:0.00025634627672843635 max memory_allocated 22563.46044921875 
[2025-03-02 09:16:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.13664832711219788 norm:0.00023702523321844637 max memory_allocated 22563.46044921875 
[2025-03-02 09:16:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.13658209145069122 norm:0.00022804528998676687 max memory_allocated 22563.46044921875 
[2025-03-02 09:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.13649754226207733 norm:0.0002127582993125543 max memory_allocated 22563.46044921875 
[2025-03-02 09:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.13646572828292847 norm:0.0002063913707388565 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.13642063736915588 norm:0.0002004999842029065 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.13637778162956238 norm:0.0001953839964699 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.1363508105278015 norm:0.00019398861331865191 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.13636818528175354 norm:0.00019832888210657984 max memory_allocated 22563.46044921875 
[2025-03-02 09:20:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.13637226819992065 norm:0.00019326581968925893 max memory_allocated 22563.46044921875 
[2025-03-02 09:20:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 09:21:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.16594204306602478 norm:0.0027906126342713833 max memory_allocated 22563.63232421875 
[2025-03-02 09:21:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.16196638345718384 norm:0.001387507189065218 max memory_allocated 22563.63232421875 
[2025-03-02 09:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.15889427065849304 norm:0.0008782442309893668 max memory_allocated 22563.63232421875 
[2025-03-02 09:22:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.15738767385482788 norm:0.0006248790887184441 max memory_allocated 22563.63232421875 
[2025-03-02 09:23:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.1570323407649994 norm:0.0004859544278588146 max memory_allocated 22563.63232421875 
[2025-03-02 09:24:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.15681056678295135 norm:0.00039380587986670434 max memory_allocated 22563.63232421875 
[2025-03-02 09:24:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.15663307905197144 norm:0.0003310560423415154 max memory_allocated 22563.63232421875 
[2025-03-02 09:25:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.15650247037410736 norm:0.0002882327826227993 max memory_allocated 22563.63232421875 
[2025-03-02 09:25:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.1564006805419922 norm:0.00025568765704520047 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.15634088218212128 norm:0.00023237749701365829 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.15628531575202942 norm:0.00021636327437590808 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.15622131526470184 norm:0.0002017623046413064 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.15616139769554138 norm:0.00019253636128269136 max memory_allocated 22563.63232421875 
[2025-03-02 09:28:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.15612958371639252 norm:0.00018515344709157944 max memory_allocated 22563.63232421875 
[2025-03-02 09:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.1561230719089508 norm:0.0001776126300683245 max memory_allocated 22563.63232421875 
[2025-03-02 09:29:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.15608267486095428 norm:0.00017710705287754536 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.15605726838111877 norm:0.0001740715524647385 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.15604227781295776 norm:0.00018733578326646239 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.15602928400039673 norm:0.00017962281708605587 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:46 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.15600474178791046 norm:0.00018815133080352098 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 09:31:58 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:32:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.19160720705986023 norm:0.004563384223729372 max memory_allocated 22563.91943359375 
[2025-03-02 09:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.18781733512878418 norm:0.004028987605124712 max memory_allocated 22563.91943359375 
[2025-03-02 09:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.18455447256565094 norm:0.003454578574746847 max memory_allocated 22563.91943359375 
[2025-03-02 09:34:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.1830257773399353 norm:0.002921036211773753 max memory_allocated 22563.91943359375 
[2025-03-02 09:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.18246030807495117 norm:0.0024256743490695953 max memory_allocated 22563.91943359375 
[2025-03-02 09:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.18216371536254883 norm:0.002155488124117255 max memory_allocated 22563.91943359375 
[2025-03-02 09:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.18199385702610016 norm:0.0020810579881072044 max memory_allocated 22563.91943359375 
[2025-03-02 09:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.1818465292453766 norm:0.0020500831305980682 max memory_allocated 22563.91943359375 
[2025-03-02 09:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.18167531490325928 norm:0.0018003284931182861 max memory_allocated 22563.91943359375 
[2025-03-02 09:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.18158216774463654 norm:0.0018259357893839478 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.18156127631664276 norm:0.0015933243557810783 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.18142610788345337 norm:0.0016785471234470606 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.18137270212173462 norm:0.0016363529721274972 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.18130789697170258 norm:0.001595415291376412 max memory_allocated 22563.91943359375 
[2025-03-02 09:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.18130022287368774 norm:0.0014365604147315025 max memory_allocated 22563.91943359375 
[2025-03-02 09:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.18132436275482178 norm:0.001661429414525628 max memory_allocated 22563.91943359375 
[2025-03-02 09:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.18145571649074554 norm:0.0014220294542610645 max memory_allocated 22563.91943359375 
[2025-03-02 09:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.18129853904247284 norm:0.0012654493330046535 max memory_allocated 22563.91943359375 
[2025-03-02 09:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.1811572015285492 norm:0.0012723704567179084 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.18113604187965393 norm:0.0013053903821855783 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 09:43:16 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.22525836527347565 norm:0.006192834582179785 max memory_allocated 22564.09130859375 
[2025-03-02 09:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.22009803354740143 norm:0.0046250298619270325 max memory_allocated 22564.09130859375 
[2025-03-02 09:44:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.21634025871753693 norm:0.0037757863756269217 max memory_allocated 22564.09130859375 
[2025-03-02 09:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.21472255885601044 norm:0.00325472722761333 max memory_allocated 22564.09130859375 
[2025-03-02 09:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.21419650316238403 norm:0.002809286117553711 max memory_allocated 22564.09130859375 
[2025-03-02 09:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.21375679969787598 norm:0.0024134430568665266 max memory_allocated 22564.09130859375 
[2025-03-02 09:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.21341580152511597 norm:0.0021308623254299164 max memory_allocated 22564.09130859375 
[2025-03-02 09:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.21325048804283142 norm:0.0021088512148708105 max memory_allocated 22564.09130859375 
[2025-03-02 09:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.21327102184295654 norm:0.001760059967637062 max memory_allocated 22564.09130859375 
[2025-03-02 09:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.21316245198249817 norm:0.002076259348541498 max memory_allocated 22564.09130859375 
[2025-03-02 09:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.21307596564292908 norm:0.0016575257759541273 max memory_allocated 22564.09130859375 
[2025-03-02 09:49:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.21277542412281036 norm:0.001675757928751409 max memory_allocated 22564.09130859375 
[2025-03-02 09:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.21267879009246826 norm:0.0016170837916433811 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.21262672543525696 norm:0.0017002937383949757 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.21268457174301147 norm:0.0016350101213902235 max memory_allocated 22564.09130859375 
[2025-03-02 09:52:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.21269409358501434 norm:0.001714340760372579 max memory_allocated 22564.09130859375 
[2025-03-02 09:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.21268558502197266 norm:0.001675205072388053 max memory_allocated 22564.09130859375 
[2025-03-02 09:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.21267077326774597 norm:0.001639381516724825 max memory_allocated 22564.09130859375 
[2025-03-02 09:53:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.21263279020786285 norm:0.001572993816807866 max memory_allocated 22564.09130859375 
[2025-03-02 09:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.2126609981060028 norm:0.0016086343675851822 max memory_allocated 22564.09130859375 
[2025-03-02 09:54:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:54:34 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.30322587490081787 norm:0.01665705069899559 max memory_allocated 22564.26318359375 
[2025-03-02 09:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.2874417304992676 norm:0.016885031014680862 max memory_allocated 22564.26318359375 
[2025-03-02 09:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.2802138924598694 norm:0.017517272382974625 max memory_allocated 22564.26318359375 
[2025-03-02 09:56:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.27689307928085327 norm:0.017056483775377274 max memory_allocated 22564.26318359375 
[2025-03-02 09:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.2753157317638397 norm:0.017100326716899872 max memory_allocated 22564.26318359375 
[2025-03-02 09:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.27423256635665894 norm:0.016856450587511063 max memory_allocated 22564.26318359375 
[2025-03-02 09:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.2732860743999481 norm:0.016409730538725853 max memory_allocated 22564.26318359375 
[2025-03-02 09:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.27277934551239014 norm:0.016772141680121422 max memory_allocated 22564.26318359375 
[2025-03-02 09:59:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.272275447845459 norm:0.015868227928876877 max memory_allocated 22564.26318359375 
[2025-03-02 10:00:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.27131980657577515 norm:0.014648118056356907 max memory_allocated 22564.26318359375 
[2025-03-02 10:00:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.2708562910556793 norm:0.013926692306995392 max memory_allocated 22564.26318359375 
[2025-03-02 10:01:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.27054882049560547 norm:0.013086449354887009 max memory_allocated 22564.26318359375 
[2025-03-02 10:01:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.27033090591430664 norm:0.012489504180848598 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.2701650857925415 norm:0.012255835346877575 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.26989471912384033 norm:0.011664289981126785 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.26979491114616394 norm:0.011554444208741188 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.26969581842422485 norm:0.011211005039513111 max memory_allocated 22564.26318359375 
[2025-03-02 10:04:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.2696641683578491 norm:0.010931456461548805 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.26958078145980835 norm:0.010808419436216354 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.2694723904132843 norm:0.010531815700232983 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 10:05:51 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 10:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.5506216883659363 norm:0.03958675265312195 max memory_allocated 22564.43505859375 
[2025-03-02 10:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.5092663764953613 norm:0.026889823377132416 max memory_allocated 22564.43505859375 
[2025-03-02 10:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.48563849925994873 norm:0.019335824996232986 max memory_allocated 22564.43505859375 
[2025-03-02 10:08:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.47296541929244995 norm:0.015660353004932404 max memory_allocated 22564.43505859375 
[2025-03-02 10:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.46545693278312683 norm:0.013985543511807919 max memory_allocated 22564.43505859375 
[2025-03-02 10:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.46024900674819946 norm:0.012433324009180069 max memory_allocated 22564.43505859375 
[2025-03-02 10:09:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.45720821619033813 norm:0.012270847335457802 max memory_allocated 22564.43505859375 
[2025-03-02 10:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.45509329438209534 norm:0.012099295854568481 max memory_allocated 22564.43505859375 
[2025-03-02 10:10:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.453220009803772 norm:0.011852935887873173 max memory_allocated 22564.43505859375 
[2025-03-02 10:11:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.451830118894577 norm:0.01213105395436287 max memory_allocated 22564.43505859375 
[2025-03-02 10:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.45059484243392944 norm:0.01182007696479559 max memory_allocated 22564.43505859375 
[2025-03-02 10:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.45021751523017883 norm:0.012338437139987946 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.44910934567451477 norm:0.010927979834377766 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.4483563005924225 norm:0.01094769686460495 max memory_allocated 22564.43505859375 
[2025-03-02 10:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.4473641514778137 norm:0.0101652592420578 max memory_allocated 22564.43505859375 
[2025-03-02 10:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.44696760177612305 norm:0.01072083879262209 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:17 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.4469771981239319 norm:0.010876287706196308 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.44652900099754333 norm:0.010427755303680897 max memory_allocated 22564.43505859375 
[2025-03-02 10:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.44641047716140747 norm:0.010390831157565117 max memory_allocated 22564.43505859375 
[2025-03-02 10:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.4463467299938202 norm:0.01057322509586811 max memory_allocated 22564.43505859375 
[2025-03-02 10:17:06 root] (main_calib_config2.py 372): INFO 21614.232793569565
[2025-03-02 10:17:12 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 10:18:22 root] (main_calib_config2.py 159): INFO wikitext2 : 5.795506954193115
[2025-03-02 10:18:22 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 10:20:10 root] (main_calib_config2.py 159): INFO c4 : 7.232795238494873
