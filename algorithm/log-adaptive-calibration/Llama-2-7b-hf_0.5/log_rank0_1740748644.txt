[2025-02-28 13:17:24 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-7b-hf_0.5', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.5.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:20:27 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:20:27 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.5.pkl
[2025-02-28 13:20:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:20:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:21:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.011123092845082283 norm:0.012887369841337204 max memory_allocated 22562.10693359375 
[2025-02-28 13:21:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.006428577471524477 norm:0.007884761318564415 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.004591180011630058 norm:0.005286278668791056 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.004026705864816904 norm:0.004164909478276968 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.003838381264358759 norm:0.0035627498291432858 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.003719455562531948 norm:0.003050491213798523 max memory_allocated 22562.10693359375 
[2025-02-28 13:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0036314106546342373 norm:0.0026624007150530815 max memory_allocated 22562.10693359375 
[2025-02-28 13:24:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0035098236985504627 norm:0.0023844665847718716 max memory_allocated 22562.10693359375 
[2025-02-28 13:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0034647155553102493 norm:0.002134509850293398 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.003465513000264764 norm:0.0018490003421902657 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0034546509850770235 norm:0.0016865802463144064 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.003371339524164796 norm:0.0013907793909311295 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0033648761454969645 norm:0.0013948570704087615 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0033128508366644382 norm:0.001271605840884149 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0032932970207184553 norm:0.0012270875740796328 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.003316088579595089 norm:0.001105508184991777 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0033198718447238207 norm:0.0010692582000046968 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0032121227122843266 norm:0.0009685424156486988 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0032668053172528744 norm:0.001111918012611568 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.003186226822435856 norm:0.0009281449019908905 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:31:47 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:32:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.0400506891310215 norm:0.02713756635785103 max memory_allocated 22562.27880859375 
[2025-02-28 13:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.02697112411260605 norm:0.011690720915794373 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.019867967814207077 norm:0.007801262196153402 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.018817223608493805 norm:0.010991770774126053 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.020849142223596573 norm:0.018452757969498634 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.016767580062150955 norm:0.01125525776296854 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.01643165573477745 norm:0.009899771772325039 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.016759924590587616 norm:0.009823061525821686 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.015881121158599854 norm:0.008288138546049595 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.015535349026322365 norm:0.007734578102827072 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.015669815242290497 norm:0.007337202318012714 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.01563652604818344 norm:0.007237361744046211 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.015177305787801743 norm:0.006859627552330494 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.015099995769560337 norm:0.006475929636508226 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.016354553401470184 norm:0.0069919670931994915 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.015773199498653412 norm:0.006976878270506859 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.015374411828815937 norm:0.005866914056241512 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.015851518139243126 norm:0.006358542945235968 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.01537284441292286 norm:0.006066800095140934 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.015455781482160091 norm:0.006050599738955498 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 13:43:05 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:43:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.032244227826595306 norm:0.007463888265192509 max memory_allocated 22562.45068359375 
[2025-02-28 13:44:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.023617295548319817 norm:0.005698685068637133 max memory_allocated 22562.45068359375 
[2025-02-28 13:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.020437495782971382 norm:0.003979765810072422 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.019378896802663803 norm:0.0031721428968012333 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.01874152012169361 norm:0.002582353074103594 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.018236935138702393 norm:0.0021299729123711586 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:59 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.01796048879623413 norm:0.0017681209137663245 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.017832089215517044 norm:0.0014394796453416348 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.01776176318526268 norm:0.0011805432150140405 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.017759421840310097 norm:0.0011268636444583535 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.017722055315971375 norm:0.00113530526868999 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.017653388902544975 norm:0.0010037543252110481 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.017655398696660995 norm:0.0010403742780908942 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.01769173890352249 norm:0.0010319155408069491 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.01768849603831768 norm:0.001011249260045588 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:59 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.01767188310623169 norm:0.0009515665005892515 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.017663387581706047 norm:0.0009017785778269172 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.01765463873744011 norm:0.0008596640545874834 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.01761879026889801 norm:0.0008144268067553639 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.01760847307741642 norm:0.0007871640846133232 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 13:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.044667407870292664 norm:0.005584435537457466 max memory_allocated 22562.50732421875 
[2025-02-28 13:55:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.03242722898721695 norm:0.0018568045925348997 max memory_allocated 22562.50732421875 
[2025-02-28 13:56:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.027265554293990135 norm:0.0010276446118950844 max memory_allocated 22562.50732421875 
[2025-02-28 13:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.025383051484823227 norm:0.000621004612185061 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.024402154609560966 norm:0.0005044305580668151 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.02393556386232376 norm:0.00041509896982461214 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.023774266242980957 norm:0.0003673512546811253 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.023671280592679977 norm:0.00033064140006899834 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.023617319762706757 norm:0.00029561942210420966 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.02358005754649639 norm:0.00027172916452400386 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.02355092763900757 norm:0.0002461984986439347 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.023490313440561295 norm:0.00022535699827130884 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.023455249145627022 norm:0.00021955544070806354 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.023449063301086426 norm:0.00020031421445310116 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.02343875542283058 norm:0.0001986432762350887 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.02343958616256714 norm:0.00018337809888180345 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.023436525836586952 norm:0.00019189665908925235 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.023456141352653503 norm:0.0001882671203929931 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.02346266433596611 norm:0.00017688704247120768 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.023434333503246307 norm:0.00016996503109112382 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:06:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.05218569189310074 norm:0.0025898071471601725 max memory_allocated 22562.67919921875 
[2025-02-28 14:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.03897584229707718 norm:0.0010195664362981915 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.03302831947803497 norm:0.0004984555998817086 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.030977020040154457 norm:0.00030511259683407843 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.030008094385266304 norm:0.0002253328129881993 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.029547639191150665 norm:0.0002073640062008053 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.029330050572752953 norm:0.00019156813505105674 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.029223300516605377 norm:0.00020652107195928693 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.029225340113043785 norm:0.00021933787502348423 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.0290658101439476 norm:0.00018601384363137186 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.029014918953180313 norm:0.00019037385936826468 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.028990520164370537 norm:0.00018141775217372924 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.02894572913646698 norm:0.00018340753740631044 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.028933223336935043 norm:0.00019937517936341465 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.028901251032948494 norm:0.00019253508071415126 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.028881244361400604 norm:0.00019202701514586806 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.028877651318907738 norm:0.00019204238196834922 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.028861533850431442 norm:0.00018861758871935308 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.02887428179383278 norm:0.00019198172958567739 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.028870966285467148 norm:0.00019422701734583825 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:17:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.05332706868648529 norm:0.0023659011349081993 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.042733944952487946 norm:0.001036384142935276 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.037125494331121445 norm:0.0005559183191508055 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.035165488719940186 norm:0.0003477068094071001 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.03422911837697029 norm:0.000250072218477726 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.033841900527477264 norm:0.0002079537371173501 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.0336993969976902 norm:0.00019674663781188428 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.033656273037195206 norm:0.000202410519705154 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.03357166796922684 norm:0.00020002902601845562 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.033489979803562164 norm:0.0001906336547108367 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.03351296856999397 norm:0.00020703264453914016 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.03342362120747566 norm:0.00018791761249303818 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.033373914659023285 norm:0.00018077640561386943 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.03334870934486389 norm:0.00018634437583386898 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.033323414623737335 norm:0.0001848188112489879 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.033326491713523865 norm:0.00018928734061773866 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.033346373587846756 norm:0.00019366851483937353 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.03333981707692146 norm:0.00018492911476641893 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.03333914279937744 norm:0.0001828526728786528 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.03333611041307449 norm:0.00018320661911275238 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 14:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.06470170617103577 norm:0.003323310986161232 max memory_allocated 22563.02294921875 
[2025-02-28 14:29:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.05105835944414139 norm:0.0014294454595074058 max memory_allocated 22563.02294921875 
[2025-02-28 14:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.044046975672245026 norm:0.0008018072694540024 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.04142454266548157 norm:0.0005068353493697941 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.04016703739762306 norm:0.0003619895433075726 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.03958677873015404 norm:0.0002862859982997179 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.039286620914936066 norm:0.0002355414180783555 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.03913450241088867 norm:0.00022284791339188814 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.03904020041227341 norm:0.00020601795404218137 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.03898027539253235 norm:0.00019464864453766495 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.03894219920039177 norm:0.0001888277765829116 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.038894910365343094 norm:0.000186465447768569 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.038846246898174286 norm:0.00019028729002457112 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.038834672421216965 norm:0.00018965042545460165 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.038813404738903046 norm:0.00019195109780412167 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.038790613412857056 norm:0.00019178919319529086 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.038759995251894 norm:0.00017918470257427543 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.03877045586705208 norm:0.00017573192599229515 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.038752175867557526 norm:0.00017240073066204786 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.038732852786779404 norm:0.00017750650295056403 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 14:40:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.08035656809806824 norm:0.004562187008559704 max memory_allocated 22563.19482421875 
[2025-02-28 14:40:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.062234263867139816 norm:0.0028736605308949947 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.05365081503987312 norm:0.0008490286418236792 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.05046767368912697 norm:0.000603198423050344 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.04894937574863434 norm:0.0004806682118214667 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.04821089655160904 norm:0.0004141383105888963 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.047795187681913376 norm:0.00035230416688136756 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.04747316241264343 norm:0.0003264961123932153 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.04729621112346649 norm:0.0003115486179012805 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.04714208096265793 norm:0.0002951805363409221 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.047017086297273636 norm:0.0002985660976264626 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.046898968517780304 norm:0.00027375295758247375 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.04682008922100067 norm:0.0002711785491555929 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.046775780618190765 norm:0.0002659316814970225 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.046724993735551834 norm:0.0002598909195512533 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.046752311289310455 norm:0.0002698429743759334 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.04672209918498993 norm:0.0002591339289210737 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.0467151403427124 norm:0.00025951783754862845 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.046674735844135284 norm:0.0002559252316132188 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.046624332666397095 norm:0.00025234423810616136 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 14:51:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.08146944642066956 norm:0.002844110829755664 max memory_allocated 22563.36669921875 
[2025-02-28 14:51:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.06779824197292328 norm:0.0011569284833967686 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.059940509498119354 norm:0.0006882983143441379 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.05704781413078308 norm:0.00048737594624981284 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.055718522518873215 norm:0.00039132111123763025 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.05504762381315231 norm:0.00035150416078977287 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.05473622679710388 norm:0.00033195922151207924 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.05449650436639786 norm:0.0003026753256563097 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.054324544966220856 norm:0.00029787200037389994 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.05419809743762016 norm:0.0002754963643383235 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.05406838282942772 norm:0.0002602090244181454 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.05398301035165787 norm:0.00025457353331148624 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.05390280485153198 norm:0.00025038080639205873 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.05385028198361397 norm:0.0002452528278809041 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.053807325661182404 norm:0.00024308280262630433 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.053797151893377304 norm:0.00024283459060825408 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.05376298353075981 norm:0.0002461330150254071 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.05373729020357132 norm:0.00024518006830476224 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.053740352392196655 norm:0.00023814072483219206 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.0537252202630043 norm:0.00024078440037555993 max memory_allocated 22563.36669921875 
[2025-02-28 15:02:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 15:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.08885425329208374 norm:0.0031460716854780912 max memory_allocated 22563.53857421875 
[2025-02-28 15:03:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.07373430579900742 norm:0.0011186840711161494 max memory_allocated 22563.53857421875 
[2025-02-28 15:03:47 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.06531815975904465 norm:0.000502716691698879 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.062201544642448425 norm:0.00032563030254095793 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.06086822226643562 norm:0.0002919088292401284 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.06026206165552139 norm:0.000262235727859661 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.05991097539663315 norm:0.00024733770987950265 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.059711016714572906 norm:0.00023536180378869176 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.05954404175281525 norm:0.00022359138529282063 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.059438757598400116 norm:0.00022015563445165753 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.05938297137618065 norm:0.00021702656522393227 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.059321220964193344 norm:0.00021782742987852544 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.05931742489337921 norm:0.00021802372066304088 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.059336937963962555 norm:0.0002166648773709312 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.05928638577461243 norm:0.00021286093397065997 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.059245578944683075 norm:0.00021406327141448855 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.05921398475766182 norm:0.00021681201178580523 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.059195540845394135 norm:0.00021710920555051416 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.05915264040231705 norm:0.000220710615394637 max memory_allocated 22563.53857421875 
[2025-02-28 15:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.05914682522416115 norm:0.00022097006149124354 max memory_allocated 22563.53857421875 
[2025-02-28 15:13:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 15:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.09400905668735504 norm:0.0021996782161295414 max memory_allocated 22563.71044921875 
[2025-02-28 15:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.07992283254861832 norm:0.0010731525253504515 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.07076463103294373 norm:0.0005900317919440567 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.06747300177812576 norm:0.00041132583282887936 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.0660679042339325 norm:0.00032893475145101547 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.06545691937208176 norm:0.0002959098492283374 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.06516379117965698 norm:0.0002833695034496486 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.06494751572608948 norm:0.00026293087285012007 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.06479667127132416 norm:0.000254826940363273 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.06471218168735504 norm:0.00024964858312159777 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.06463707983493805 norm:0.0002443301782477647 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.06456486135721207 norm:0.00024054921232163906 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:36 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.06451896578073502 norm:0.00023934787895996124 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.06442141532897949 norm:0.00023792852880433202 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.06439490616321564 norm:0.00023861015506554395 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.0643482506275177 norm:0.00023841969959903508 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.06430135667324066 norm:0.0002398463839199394 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.06428161263465881 norm:0.00024042773293331265 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.06426630169153214 norm:0.00023972945928107947 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.06424903124570847 norm:0.00023969562607817352 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 15:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.09896939992904663 norm:0.007243371102958918 max memory_allocated 22563.88232421875 
[2025-02-28 15:25:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.08330394327640533 norm:0.0032530263997614384 max memory_allocated 22563.88232421875 
[2025-02-28 15:26:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.07412570714950562 norm:0.001729324460029602 max memory_allocated 22563.88232421875 
[2025-02-28 15:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.07041328400373459 norm:0.0010518449125811458 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.06881816685199738 norm:0.0007233838550746441 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.06808549165725708 norm:0.0006529893144033849 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.0676530972123146 norm:0.0005116169340908527 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.06742793321609497 norm:0.00043297663796693087 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.06727589666843414 norm:0.00039137748535722494 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.06712204962968826 norm:0.00035102065885439515 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.06703191995620728 norm:0.00031873511034063995 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.06693703681230545 norm:0.0002881230611819774 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.06689955294132233 norm:0.0002756800677161664 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.06687086075544357 norm:0.0002672247064765543 max memory_allocated 22563.88232421875 
[2025-02-28 15:33:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.06682810932397842 norm:0.0002605750923976302 max memory_allocated 22563.88232421875 
[2025-02-28 15:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.06679430603981018 norm:0.00025831584935076535 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.06674614548683167 norm:0.00024911120999604464 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.06671792268753052 norm:0.00024223762738984078 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.06668810546398163 norm:0.00024243976804427803 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.06665874272584915 norm:0.00023790361592546105 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 15:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.08540479093790054 norm:0.0013196272775530815 max memory_allocated 22564.05419921875 
[2025-02-28 15:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.07602479308843613 norm:0.0006570198456756771 max memory_allocated 22564.05419921875 
[2025-02-28 15:37:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.07012525945901871 norm:0.00038335140561684966 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.0681319311261177 norm:0.00027633359422907233 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.06717447936534882 norm:0.00022863733465783298 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.06668368726968765 norm:0.0001964190450962633 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.06640958786010742 norm:0.00018208996334578842 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.06628751009702682 norm:0.00017656924319453537 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.06618820130825043 norm:0.00016875042638275772 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.06610520929098129 norm:0.00016883094212971628 max memory_allocated 22564.05419921875 
[2025-02-28 15:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.06604191660881042 norm:0.0001696698454907164 max memory_allocated 22564.05419921875 
[2025-02-28 15:42:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.0660107433795929 norm:0.00017649747314862907 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.06598120182752609 norm:0.00015790796896908432 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.06593728810548782 norm:0.00015770847676321864 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.0658964142203331 norm:0.0001612049381947145 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.06587943434715271 norm:0.0001657680404605344 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.06586432456970215 norm:0.00016850490646902472 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.0658397525548935 norm:0.00016895138833206147 max memory_allocated 22564.05419921875 
[2025-02-28 15:46:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.06582959741353989 norm:0.00016696605598554015 max memory_allocated 22564.05419921875 
[2025-02-28 15:47:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.06584266573190689 norm:0.00016734618111513555 max memory_allocated 22564.05419921875 
[2025-02-28 15:47:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 15:47:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.09015711396932602 norm:0.002112086396664381 max memory_allocated 22564.22607421875 
[2025-02-28 15:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.07957068085670471 norm:0.0010123325046151876 max memory_allocated 22564.22607421875 
[2025-02-28 15:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.07288557291030884 norm:0.0004893613513559103 max memory_allocated 22564.22607421875 
[2025-02-28 15:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.07033489644527435 norm:0.00035354806459508836 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.06917165219783783 norm:0.0002903063432313502 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.06855413317680359 norm:0.0002603773900773376 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.0681929737329483 norm:0.00023840474023018032 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.06800348311662674 norm:0.00022897102462593466 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.06783664226531982 norm:0.00022475773585028946 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.06773784011602402 norm:0.00021679345809388906 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:21 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.06765726208686829 norm:0.00021553342230618 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.0675768256187439 norm:0.0002058364188997075 max memory_allocated 22564.22607421875 
[2025-02-28 15:54:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.0675186738371849 norm:0.00020332421991042793 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.06747932732105255 norm:0.00020591687643900514 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.06745392084121704 norm:0.00020280481840018183 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.06742344051599503 norm:0.00019622966647148132 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.06741679459810257 norm:0.00019512920698616654 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.06740335375070572 norm:0.0001969181903405115 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.06739594042301178 norm:0.000197463552467525 max memory_allocated 22564.22607421875 
[2025-02-28 15:58:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.06735848635435104 norm:0.00019966336549259722 max memory_allocated 22564.22607421875 
[2025-02-28 15:58:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 15:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.0829855352640152 norm:0.0012537833536043763 max memory_allocated 22564.39794921875 
[2025-02-28 15:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.07494603097438812 norm:0.0005829576402902603 max memory_allocated 22564.39794921875 
[2025-02-28 16:00:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.06976395100355148 norm:0.0003385875024832785 max memory_allocated 22564.39794921875 
[2025-02-28 16:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.06800324469804764 norm:0.00024529796792194247 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.06711715459823608 norm:0.00019723581499420106 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.06662589311599731 norm:0.00017107161693274975 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.06636907905340195 norm:0.00015742419054731727 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.06619193404912949 norm:0.00014997797552496195 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.06605971604585648 norm:0.00014827675477135926 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.06596904993057251 norm:0.00014410445874091238 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.06589481234550476 norm:0.00013477403263095766 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.06585592031478882 norm:0.0001309620274696499 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.06581084430217743 norm:0.00013357757416088134 max memory_allocated 22564.39794921875 
[2025-02-28 16:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.06578966975212097 norm:0.00013703436707146466 max memory_allocated 22564.39794921875 
[2025-02-28 16:06:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.06575608998537064 norm:0.00012997997691854835 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.06573251634836197 norm:0.0001291401858907193 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.06572921574115753 norm:0.0001245364110218361 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.06572186946868896 norm:0.00012445921311154962 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.06570079922676086 norm:0.00012442030129022896 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.0657009556889534 norm:0.00012348947348073125 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 16:10:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.0852150097489357 norm:0.0016426027286797762 max memory_allocated 22564.56982421875 
[2025-02-28 16:10:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.07546781003475189 norm:0.0007853412535041571 max memory_allocated 22564.56982421875 
[2025-02-28 16:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.06958570331335068 norm:0.00045017580850981176 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.06759675592184067 norm:0.00030599042656831443 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.06657615303993225 norm:0.00023982279526535422 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.06602824479341507 norm:0.00020509070600382984 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.0657106339931488 norm:0.00018336727225687355 max memory_allocated 22564.56982421875 
[2025-02-28 16:14:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.06552502512931824 norm:0.00017164656310342252 max memory_allocated 22564.56982421875 
[2025-02-28 16:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.06539474427700043 norm:0.00016383769980166107 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.06526161730289459 norm:0.00015185691881924868 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.06517558544874191 norm:0.00015234418970067054 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.06509667634963989 norm:0.000146845166455023 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.06506014615297318 norm:0.00014509019092656672 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.06502071022987366 norm:0.000142149263410829 max memory_allocated 22564.56982421875 
[2025-02-28 16:18:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.06498690694570541 norm:0.00014368809934239835 max memory_allocated 22564.56982421875 
[2025-02-28 16:18:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.06493715196847916 norm:0.00013985068653710186 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.06490229070186615 norm:0.0001398591120960191 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.06487683951854706 norm:0.00013819750165566802 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.0648505687713623 norm:0.00013286320609040558 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.06483987718820572 norm:0.00013498350745067 max memory_allocated 22564.56982421875 
[2025-02-28 16:21:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 16:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.08443504571914673 norm:0.0015668816631659865 max memory_allocated 22564.74169921875 
[2025-02-28 16:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.07530412077903748 norm:0.0006676333723589778 max memory_allocated 22564.74169921875 
[2025-02-28 16:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.06938952207565308 norm:0.00037679250817745924 max memory_allocated 22564.74169921875 
[2025-02-28 16:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.06750988215208054 norm:0.0002700470795389265 max memory_allocated 22564.74169921875 
[2025-02-28 16:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.06652925908565521 norm:0.000220564630581066 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.0659341886639595 norm:0.00019120606884825975 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.06560957431793213 norm:0.00017436154303140938 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.06542519479990005 norm:0.00016244908329099417 max memory_allocated 22564.74169921875 
[2025-02-28 16:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.06527960300445557 norm:0.00015431668725796044 max memory_allocated 22564.74169921875 
[2025-02-28 16:26:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.06516298651695251 norm:0.00014926317089702934 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.06506962329149246 norm:0.00014441655366681516 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.06498998403549194 norm:0.00013841164764016867 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.06492198258638382 norm:0.0001355668209725991 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.06485699117183685 norm:0.00013496249448508024 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.0648123174905777 norm:0.00013192527694627643 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.06477975100278854 norm:0.0001328617217950523 max memory_allocated 22564.74169921875 
[2025-02-28 16:30:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.06473401188850403 norm:0.0001341309689451009 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.06470946967601776 norm:0.00013378699077293277 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.0646720752120018 norm:0.00012895865074824542 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.06463957577943802 norm:0.0001239597622770816 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 16:32:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.07954688370227814 norm:0.0007602464174851775 max memory_allocated 22564.91357421875 
[2025-02-28 16:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.07353553175926208 norm:0.00033174894633702934 max memory_allocated 22564.91357421875 
[2025-02-28 16:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.06925473362207413 norm:0.00021636366727761924 max memory_allocated 22564.91357421875 
[2025-02-28 16:34:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.06785784661769867 norm:0.0001778210571501404 max memory_allocated 22564.91357421875 
[2025-02-28 16:35:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.06699332594871521 norm:0.00014985633606556803 max memory_allocated 22564.91357421875 
[2025-02-28 16:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.06650244444608688 norm:0.0001312105596298352 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.06628180295228958 norm:0.00012287094432394952 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.06612341105937958 norm:0.00012148474343121052 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.06599348783493042 norm:0.00011659348092507571 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.06590913981199265 norm:0.00011022215039702132 max memory_allocated 22564.91357421875 
[2025-02-28 16:38:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.06582880765199661 norm:0.00010409295646240935 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.06577745825052261 norm:0.0001069821446435526 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.06574031710624695 norm:0.00010403305350337178 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.06571957468986511 norm:0.00010589715384412557 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.0656784325838089 norm:9.954207052942365e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.06567928194999695 norm:0.00010664010915206745 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.06567402929067612 norm:0.00010935506725218147 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.06563077121973038 norm:9.939705341821536e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.06562040746212006 norm:9.964065975509584e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.06561781466007233 norm:9.816689271247014e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:43:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 16:44:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.08767220377922058 norm:0.0019868488889187574 max memory_allocated 22565.08544921875 
[2025-02-28 16:44:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.07993844896554947 norm:0.0009185676462948322 max memory_allocated 22565.08544921875 
[2025-02-28 16:45:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.07447399944067001 norm:0.0005459462408907712 max memory_allocated 22565.08544921875 
[2025-02-28 16:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.07273630797863007 norm:0.000371042697224766 max memory_allocated 22565.08544921875 
[2025-02-28 16:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.07167766988277435 norm:0.0002948265755549073 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.07107863575220108 norm:0.00024439601111225784 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.07079130411148071 norm:0.00021380718681029975 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.07063230872154236 norm:0.0001880884956335649 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.07047378271818161 norm:0.0001726595510262996 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.07037171721458435 norm:0.00016067398246377707 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.07025905698537827 norm:0.00015050799993332475 max memory_allocated 22565.08544921875 
[2025-02-28 16:50:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.07019039243459702 norm:0.00014469024608843029 max memory_allocated 22565.08544921875 
[2025-02-28 16:50:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.07012757658958435 norm:0.00013713653606828302 max memory_allocated 22565.08544921875 
[2025-02-28 16:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.07006381452083588 norm:0.00013120676157996058 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.07001078128814697 norm:0.0001270295470021665 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.06997376680374146 norm:0.00012630666606128216 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.06994052976369858 norm:0.0001223890867549926 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.06989680230617523 norm:0.00011768138210754842 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.06986856460571289 norm:0.00011545246525201946 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.06983396410942078 norm:0.00011331286077620462 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 16:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.09106973558664322 norm:0.0014618788845837116 max memory_allocated 22565.25732421875 
[2025-02-28 16:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.08409792929887772 norm:0.0006330764153972268 max memory_allocated 22565.25732421875 
[2025-02-28 16:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.0791672021150589 norm:0.00035267879138700664 max memory_allocated 22565.25732421875 
[2025-02-28 16:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.07772591710090637 norm:0.00024239145568571985 max memory_allocated 22565.25732421875 
[2025-02-28 16:57:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.07677184790372849 norm:0.00019348744535818696 max memory_allocated 22565.25732421875 
[2025-02-28 16:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.07625092566013336 norm:0.00015816582890693098 max memory_allocated 22565.25732421875 
[2025-02-28 16:58:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.07600428909063339 norm:0.00013882336497772485 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.07587379962205887 norm:0.00012964964844286442 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.07575395703315735 norm:0.00012153130228398368 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.07565602660179138 norm:0.00012062236055498943 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.0755639374256134 norm:0.00011236697173444554 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.0754813402891159 norm:0.00010461114288773388 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.07543180882930756 norm:0.00010221184493275359 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.07537812739610672 norm:0.00010144096449948847 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.07534097880125046 norm:0.00010363056208007038 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.07529502362012863 norm:0.00010235293302685022 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.07526949048042297 norm:9.754300117492676e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.07523603737354279 norm:9.49152818066068e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.07521411031484604 norm:9.394675726071e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.07519909739494324 norm:9.422650327906013e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:06:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 17:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.0997171550989151 norm:0.0011748556280508637 max memory_allocated 22565.42919921875 
[2025-02-28 17:07:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.09214351326227188 norm:0.00045138190034776926 max memory_allocated 22565.42919921875 
[2025-02-28 17:07:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.0869385376572609 norm:0.00028607778949663043 max memory_allocated 22565.42919921875 
[2025-02-28 17:08:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.08540265262126923 norm:0.00021277798805385828 max memory_allocated 22565.42919921875 
[2025-02-28 17:09:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.08440402150154114 norm:0.00019061830244027078 max memory_allocated 22565.42919921875 
[2025-02-28 17:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.0837908461689949 norm:0.00017086371371988207 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.08350187540054321 norm:0.00015501634334214032 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.0833016037940979 norm:0.00015303175314329565 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.08315150439739227 norm:0.0001432388526154682 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.08305229246616364 norm:0.00013625198334921151 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.08296208083629608 norm:0.00013173204206395894 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.08286736160516739 norm:0.00013187572767492384 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.08279787749052048 norm:0.00013270002091303468 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.08272956311702728 norm:0.00012643121590372175 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.08267001062631607 norm:0.00012742483522742987 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.08261127024888992 norm:0.00012260593939572573 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.08255019783973694 norm:0.00012177512689959258 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.08251801878213882 norm:0.00012450847134459764 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.08247808367013931 norm:0.00012148160021752119 max memory_allocated 22565.42919921875 
[2025-02-28 17:17:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.0824580043554306 norm:0.00011872927279910073 max memory_allocated 22565.42919921875 
[2025-02-28 17:17:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 17:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.10664079338312149 norm:0.0006990020046941936 max memory_allocated 22565.60107421875 
[2025-02-28 17:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.10047535598278046 norm:0.00034638764918781817 max memory_allocated 22565.60107421875 
[2025-02-28 17:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.09554588794708252 norm:0.00022247225570026785 max memory_allocated 22565.60107421875 
[2025-02-28 17:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.09422148019075394 norm:0.00018339665257371962 max memory_allocated 22565.60107421875 
[2025-02-28 17:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.09319817274808884 norm:0.0001503245730418712 max memory_allocated 22565.60107421875 
[2025-02-28 17:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.0926196500658989 norm:0.0001426117232767865 max memory_allocated 22565.60107421875 
[2025-02-28 17:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.09238312393426895 norm:0.00013446864613797516 max memory_allocated 22565.60107421875 
[2025-02-28 17:21:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.09223532676696777 norm:0.00012587867968250066 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.0921119973063469 norm:0.00011987263133050874 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.09200363606214523 norm:0.00012012053048238158 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.09194111078977585 norm:0.00012248294660821557 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.09186485409736633 norm:0.0001171496624010615 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.09181004762649536 norm:0.00011756485764635727 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.09174278378486633 norm:0.0001119444495998323 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.09168145805597305 norm:0.00010942085646092892 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.09163175523281097 norm:0.00010802671022247523 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.09159095585346222 norm:0.00010834302520379424 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.09155003726482391 norm:0.0001070682774297893 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.09151076525449753 norm:0.00010505509271752089 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.09148409962654114 norm:0.00010466899402672425 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 17:29:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.12157028913497925 norm:0.0015861423453316092 max memory_allocated 22565.77294921875 
[2025-02-28 17:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.11405640840530396 norm:0.0006141050835140049 max memory_allocated 22565.77294921875 
[2025-02-28 17:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.10857544094324112 norm:0.0003673757310025394 max memory_allocated 22565.77294921875 
[2025-02-28 17:31:02 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.10681818425655365 norm:0.0002866981376428157 max memory_allocated 22565.77294921875 
[2025-02-28 17:31:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.10568312555551529 norm:0.00024313904577866197 max memory_allocated 22565.77294921875 
[2025-02-28 17:32:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.10507819056510925 norm:0.00021895072131883353 max memory_allocated 22565.77294921875 
[2025-02-28 17:32:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.10484323650598526 norm:0.00019556749612092972 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.10467952489852905 norm:0.00018778297817334533 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.10456350445747375 norm:0.0001739667059155181 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.10443433374166489 norm:0.00016274256631731987 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.10431577265262604 norm:0.000160405135829933 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.10422234237194061 norm:0.00015341480320785195 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:02 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.10414941608905792 norm:0.00014975547674112022 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.10406899452209473 norm:0.0001436707389075309 max memory_allocated 22565.77294921875 
[2025-02-28 17:37:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.10398468375205994 norm:0.0001342107425443828 max memory_allocated 22565.77294921875 
[2025-02-28 17:37:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.10392703115940094 norm:0.00014276969886850566 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.10387282818555832 norm:0.0001379426830681041 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.10381089150905609 norm:0.0001358416338916868 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.10376298427581787 norm:0.0001362494076602161 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.1037219762802124 norm:0.00012890696234535426 max memory_allocated 22565.77294921875 
[2025-02-28 17:40:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 17:40:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.1379794180393219 norm:0.002240553265437484 max memory_allocated 22565.94482421875 
[2025-02-28 17:41:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.1295696645975113 norm:0.001111702062189579 max memory_allocated 22565.94482421875 
[2025-02-28 17:41:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.12299780547618866 norm:0.0006573464488610625 max memory_allocated 22565.94482421875 
[2025-02-28 17:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.12103848159313202 norm:0.00047524168621748686 max memory_allocated 22565.94482421875 
[2025-02-28 17:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.11974671483039856 norm:0.0003602249489631504 max memory_allocated 22565.94482421875 
[2025-02-28 17:43:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.11915425211191177 norm:0.0002925584849435836 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.11888835579156876 norm:0.00024958481662906706 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.1186969131231308 norm:0.0002213213301729411 max memory_allocated 22565.94482421875 
[2025-02-28 17:45:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.1185387670993805 norm:0.00019776294357143342 max memory_allocated 22565.94482421875 
[2025-02-28 17:45:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.11841819435358047 norm:0.00017523767019156367 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.11830977350473404 norm:0.00016340677393600345 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.11821407824754715 norm:0.0001585806894581765 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.1181257888674736 norm:0.0001519214129075408 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.11803846806287766 norm:0.00014345457020681351 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.11796975135803223 norm:0.000137966446345672 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.11790791898965836 norm:0.0001339970767730847 max memory_allocated 22565.94482421875 
[2025-02-28 17:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.11787278950214386 norm:0.0001304413308389485 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.11782770603895187 norm:0.0001288945641135797 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.11778861284255981 norm:0.00012154258729424328 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.11775069683790207 norm:0.00011766340321628377 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 17:51:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.15398463606834412 norm:0.0023208819329738617 max memory_allocated 22566.11669921875 
[2025-02-28 17:52:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.14498689770698547 norm:0.0007001601625233889 max memory_allocated 22566.11669921875 
[2025-02-28 17:53:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.13846860826015472 norm:0.000448863604106009 max memory_allocated 22566.11669921875 
[2025-02-28 17:53:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.13640901446342468 norm:0.00034294152283109725 max memory_allocated 22566.11669921875 
[2025-02-28 17:54:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.1351202428340912 norm:0.00028979411581531167 max memory_allocated 22566.11669921875 
[2025-02-28 17:54:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.13458870351314545 norm:0.000246747542405501 max memory_allocated 22566.11669921875 
[2025-02-28 17:55:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.13433128595352173 norm:0.00021584689966402948 max memory_allocated 22566.11669921875 
[2025-02-28 17:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.13416767120361328 norm:0.0002078106626868248 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.13402242958545685 norm:0.00020681317255366594 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.13388149440288544 norm:0.0001975169579964131 max memory_allocated 22566.11669921875 
[2025-02-28 17:57:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.1337624490261078 norm:0.0001861864293459803 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.13367091119289398 norm:0.00017788152035791427 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.13357755541801453 norm:0.0001675316016189754 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.13349351286888123 norm:0.0001661243150010705 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.1334168016910553 norm:0.00016412542026955634 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.1333489716053009 norm:0.00015751647879369557 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.1332937479019165 norm:0.0001555643684696406 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.13322630524635315 norm:0.00015732568863313645 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.1331811100244522 norm:0.00015277601778507233 max memory_allocated 22566.11669921875 
[2025-02-28 18:02:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.13315150141716003 norm:0.00015668343985453248 max memory_allocated 22566.11669921875 
[2025-02-28 18:02:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 18:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.17540855705738068 norm:0.0015874742530286312 max memory_allocated 22566.28857421875 
[2025-02-28 18:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.166258305311203 norm:0.0008575993124395609 max memory_allocated 22566.28857421875 
[2025-02-28 18:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.15862390398979187 norm:0.0004953026073053479 max memory_allocated 22566.28857421875 
[2025-02-28 18:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.15626758337020874 norm:0.00035480555379763246 max memory_allocated 22566.28857421875 
[2025-02-28 18:05:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.15488052368164062 norm:0.0003041705349460244 max memory_allocated 22566.28857421875 
[2025-02-28 18:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.15433892607688904 norm:0.0002627794165164232 max memory_allocated 22566.28857421875 
[2025-02-28 18:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.15408477187156677 norm:0.0002378404460614547 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.15386135876178741 norm:0.00021586683578789234 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.15371254086494446 norm:0.00020426468108780682 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.1535799503326416 norm:0.00018883329175878316 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.15341000258922577 norm:0.00017782687791623175 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.1532987654209137 norm:0.00017224323528353125 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.15323014557361603 norm:0.0001650824269745499 max memory_allocated 22566.28857421875 
[2025-02-28 18:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.15312926471233368 norm:0.00015970745880622417 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.1530332714319229 norm:0.00015747024735901505 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.15297824144363403 norm:0.00015397918468806893 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.15291130542755127 norm:0.0001512049202574417 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.15286663174629211 norm:0.00015334878116846085 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.15281212329864502 norm:0.00014375857426784933 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.1527644395828247 norm:0.00014581238792743534 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 18:14:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.19624368846416473 norm:0.001784789958037436 max memory_allocated 22566.46044921875 
[2025-02-28 18:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.1869121938943863 norm:0.0008894568891264498 max memory_allocated 22566.46044921875 
[2025-02-28 18:15:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.17956794798374176 norm:0.00054778071353212 max memory_allocated 22566.46044921875 
[2025-02-28 18:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.17705465853214264 norm:0.0003876641858369112 max memory_allocated 22566.46044921875 
[2025-02-28 18:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.1757049262523651 norm:0.00030323141254484653 max memory_allocated 22566.46044921875 
[2025-02-28 18:17:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.17518918216228485 norm:0.0002552425139583647 max memory_allocated 22566.46044921875 
[2025-02-28 18:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.17487961053848267 norm:0.00022819133300799876 max memory_allocated 22566.46044921875 
[2025-02-28 18:18:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.1746213436126709 norm:0.00020724952628370374 max memory_allocated 22566.46044921875 
[2025-02-28 18:18:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.17442798614501953 norm:0.000194713516975753 max memory_allocated 22566.46044921875 
[2025-02-28 18:19:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.17424145340919495 norm:0.0001814438437577337 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.17410621047019958 norm:0.00017574384401086718 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.17396053671836853 norm:0.00016474747098982334 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.17388597130775452 norm:0.00015685788821429014 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.17380067706108093 norm:0.000162953365361318 max memory_allocated 22566.46044921875 
[2025-02-28 18:22:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.17371509969234467 norm:0.00016192352632060647 max memory_allocated 22566.46044921875 
[2025-02-28 18:22:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.173662468791008 norm:0.00016004611097741872 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.17361119389533997 norm:0.00015962874749675393 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.17356424033641815 norm:0.00015369280299637467 max memory_allocated 22566.46044921875 
[2025-02-28 18:24:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.17352214455604553 norm:0.00016050183330662549 max memory_allocated 22566.46044921875 
[2025-02-28 18:25:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.1735025942325592 norm:0.00015641986101400107 max memory_allocated 22566.46044921875 
[2025-02-28 18:25:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 18:25:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.2249099314212799 norm:0.0025596315972507 max memory_allocated 22566.63232421875 
[2025-02-28 18:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.2139490246772766 norm:0.0011397881899029016 max memory_allocated 22566.63232421875 
[2025-02-28 18:26:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.20533892512321472 norm:0.0005779987550340593 max memory_allocated 22566.63232421875 
[2025-02-28 18:27:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.20255357027053833 norm:0.00040830063517205417 max memory_allocated 22566.63232421875 
[2025-02-28 18:28:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.20122264325618744 norm:0.000333549891365692 max memory_allocated 22566.63232421875 
[2025-02-28 18:28:35 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.20073913037776947 norm:0.00028778184787370265 max memory_allocated 22566.63232421875 
[2025-02-28 18:29:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.20041565597057343 norm:0.0002570181677583605 max memory_allocated 22566.63232421875 
[2025-02-28 18:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.2001936137676239 norm:0.00023073704505804926 max memory_allocated 22566.63232421875 
[2025-02-28 18:30:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.20000970363616943 norm:0.00022328620252665132 max memory_allocated 22566.63232421875 
[2025-02-28 18:30:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.19983430206775665 norm:0.0002105963067151606 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.1996804177761078 norm:0.000199632573639974 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.19955866038799286 norm:0.00018673775775823742 max memory_allocated 22566.63232421875 
[2025-02-28 18:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.19944755733013153 norm:0.00018196988094132394 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.19933897256851196 norm:0.0001758128055371344 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.19925102591514587 norm:0.00017010066949296743 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.19919303059577942 norm:0.00016546848928555846 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.19912946224212646 norm:0.00016241244156844914 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.19906002283096313 norm:0.0001570667518535629 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.19901779294013977 norm:0.00015624829393345863 max memory_allocated 22566.63232421875 
[2025-02-28 18:36:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.1989700347185135 norm:0.00015567477385047823 max memory_allocated 22566.63232421875 
[2025-02-28 18:36:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 18:36:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:37:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.25548964738845825 norm:0.007731026504188776 max memory_allocated 22566.91943359375 
[2025-02-28 18:37:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.24490611255168915 norm:0.005871208850294352 max memory_allocated 22566.91943359375 
[2025-02-28 18:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.23613448441028595 norm:0.004351380281150341 max memory_allocated 22566.91943359375 
[2025-02-28 18:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.2330462634563446 norm:0.003554700640961528 max memory_allocated 22566.91943359375 
[2025-02-28 18:39:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.23168839514255524 norm:0.002892063232138753 max memory_allocated 22566.91943359375 
[2025-02-28 18:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.23113147914409637 norm:0.0023972713388502598 max memory_allocated 22566.91943359375 
[2025-02-28 18:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.23080074787139893 norm:0.0021971752867102623 max memory_allocated 22566.91943359375 
[2025-02-28 18:41:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.2305888831615448 norm:0.00220148591324687 max memory_allocated 22566.91943359375 
[2025-02-28 18:41:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.23046386241912842 norm:0.002142090816050768 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.2302728295326233 norm:0.0021624225191771984 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.23009128868579865 norm:0.001984403468668461 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.229966938495636 norm:0.0019035672303289175 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.22983570396900177 norm:0.0018643359653651714 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.22973042726516724 norm:0.0017708599334582686 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.22962714731693268 norm:0.0017010115552693605 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.22955010831356049 norm:0.0016399152809754014 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.22949278354644775 norm:0.00162443274166435 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.22943192720413208 norm:0.001596889109350741 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.22938087582588196 norm:0.0015188968973234296 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.22933736443519592 norm:0.0015285309636965394 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 18:47:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.3100079298019409 norm:0.014610957354307175 max memory_allocated 22567.09130859375 
[2025-02-28 18:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.2903822660446167 norm:0.009889373555779457 max memory_allocated 22567.09130859375 
[2025-02-28 18:49:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.27692314982414246 norm:0.006501317024230957 max memory_allocated 22567.09130859375 
[2025-02-28 18:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.27247321605682373 norm:0.005405799485743046 max memory_allocated 22567.09130859375 
[2025-02-28 18:50:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.2706186771392822 norm:0.0045287469401955605 max memory_allocated 22567.09130859375 
[2025-02-28 18:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.26979073882102966 norm:0.0038431554567068815 max memory_allocated 22567.09130859375 
[2025-02-28 18:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.2691834568977356 norm:0.0031919856555759907 max memory_allocated 22567.09130859375 
[2025-02-28 18:52:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.268779456615448 norm:0.0028493113350123167 max memory_allocated 22567.09130859375 
[2025-02-28 18:52:53 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.2683742344379425 norm:0.0026381348725408316 max memory_allocated 22567.09130859375 
[2025-02-28 18:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.2681048810482025 norm:0.0024474975652992725 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.26796525716781616 norm:0.002532076323404908 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.26784181594848633 norm:0.0023881159722805023 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.2676827907562256 norm:0.002366904402151704 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.26760315895080566 norm:0.002224823459982872 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.2675417363643646 norm:0.002207808196544647 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.2674926519393921 norm:0.0020345693919807673 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.26740509271621704 norm:0.001960861962288618 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.26739728450775146 norm:0.001893466804176569 max memory_allocated 22567.09130859375 
[2025-02-28 18:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.2674195468425751 norm:0.0019487414974719286 max memory_allocated 22567.09130859375 
[2025-02-28 18:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.267433762550354 norm:0.001800447702407837 max memory_allocated 22567.09130859375 
[2025-02-28 18:59:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 18:59:13 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:59:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.2149176597595215 norm:0.144320547580719 max memory_allocated 22567.26318359375 
[2025-02-28 19:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.9804468154907227 norm:0.12341662496328354 max memory_allocated 22567.26318359375 
[2025-02-28 19:00:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.6568605899810791 norm:0.07215117663145065 max memory_allocated 22567.26318359375 
[2025-02-28 19:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.5454051494598389 norm:0.03905313462018967 max memory_allocated 22567.26318359375 
[2025-02-28 19:02:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.5134388208389282 norm:0.042917400598526 max memory_allocated 22567.26318359375 
[2025-02-28 19:02:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.4878699779510498 norm:0.04281127452850342 max memory_allocated 22567.26318359375 
[2025-02-28 19:03:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.4682033061981201 norm:0.03596702590584755 max memory_allocated 22567.26318359375 
[2025-02-28 19:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.4594552516937256 norm:0.04006266966462135 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.46142256259918213 norm:0.0427204966545105 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.43451982736587524 norm:0.03291536122560501 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.4341011047363281 norm:0.036954015493392944 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.4364272356033325 norm:0.04165844991803169 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.43337857723236084 norm:0.04232709854841232 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.4389524757862091 norm:0.04762221872806549 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.4184824228286743 norm:0.03897477686405182 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.41093748807907104 norm:0.03574501350522041 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.40989911556243896 norm:0.0357661247253418 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.4068642854690552 norm:0.03409574553370476 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.4079074263572693 norm:0.0342867411673069 max memory_allocated 22567.26318359375 
[2025-02-28 19:10:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.40351951122283936 norm:0.03106519766151905 max memory_allocated 22567.26318359375 
[2025-02-28 19:10:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 19:10:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:11:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.8827722668647766 norm:0.0627884566783905 max memory_allocated 22567.43505859375 
[2025-02-28 19:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.8114796280860901 norm:0.04281950742006302 max memory_allocated 22567.43505859375 
[2025-02-28 19:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.7666289806365967 norm:0.0316166952252388 max memory_allocated 22567.43505859375 
[2025-02-28 19:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.743889331817627 norm:0.024791652336716652 max memory_allocated 22567.43505859375 
[2025-02-28 19:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.7299368381500244 norm:0.021250415593385696 max memory_allocated 22567.43505859375 
[2025-02-28 19:13:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.7235404849052429 norm:0.01628343015909195 max memory_allocated 22567.43505859375 
[2025-02-28 19:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.7167137265205383 norm:0.01659824699163437 max memory_allocated 22567.43505859375 
[2025-02-28 19:15:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.7107090353965759 norm:0.01725822128355503 max memory_allocated 22567.43505859375 
[2025-02-28 19:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.7071206569671631 norm:0.0184229277074337 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.7041839361190796 norm:0.016521569341421127 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.7017166614532471 norm:0.01602019928395748 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.7015476822853088 norm:0.014311768114566803 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.6994529962539673 norm:0.015574931167066097 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.6987302303314209 norm:0.013294686563313007 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.6970440745353699 norm:0.015157967805862427 max memory_allocated 22567.43505859375 
[2025-02-28 19:19:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.6962147951126099 norm:0.013289334252476692 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.6946768760681152 norm:0.013062280602753162 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.6950409412384033 norm:0.012136579491198063 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.6928097605705261 norm:0.013036412186920643 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.6926692724227905 norm:0.011940984055399895 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:50 root] (main_calib_config2.py 380): INFO 21682.770383119583
[2025-02-28 19:21:55 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 19:23:05 root] (main_calib_config2.py 159): INFO wikitext2 : 5.878398895263672
[2025-02-28 19:23:05 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 19:24:53 root] (main_calib_config2.py 159): INFO c4 : 7.481871128082275
[2025-02-28 21:09:19 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.878398895263672, 'c4': 7.481871128082275, 'results': {'hellaswag': {'acc': 0.5435172276438957, 'acc_stderr': 0.0049708466975523094, 'acc_norm': 0.7023501294562836, 'acc_norm_stderr': 0.004562902604938726}, 'winogrande': {'acc': 0.6464088397790055, 'acc_stderr': 0.013436541262599959}, 'boolq': {'acc': 0.671559633027523, 'acc_stderr': 0.008214158819582625}, 'arc_easy': {'acc': 0.6679292929292929, 'acc_stderr': 0.009663817543072701, 'acc_norm': 0.5033670033670034, 'acc_norm_stderr': 0.01025955089379893}, 'arc_challenge': {'acc': 0.3856655290102389, 'acc_stderr': 0.01422425097325717, 'acc_norm': 0.3848122866894198, 'acc_norm_stderr': 0.014218371065251107}, 'piqa': {'acc': 0.7763873775843307, 'acc_stderr': 0.009721489519176302, 'acc_norm': 0.7682263329706203, 'acc_norm_stderr': 0.009845143772794034}}, 'versions': {'hellaswag': 0, 'winogrande': 0, 'boolq': 1, 'arc_easy': 0, 'arc_challenge': 0, 'piqa': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
