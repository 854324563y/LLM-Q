[2025-03-01 14:29:16 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.9', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.9.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-01 14:29:21 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-01 14:29:21 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-01 14:29:21 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-01 14:29:21 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.9.pkl
[2025-03-01 14:29:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-01 14:29:44 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.006509814877063036 norm:0.01168204564601183 max memory_allocated 29271.02001953125 
[2025-03-01 14:31:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.003579376731067896 norm:0.006682621780782938 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0029958924278616905 norm:0.005195687524974346 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.00269558047875762 norm:0.004146229475736618 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.002493839943781495 norm:0.0034108080435544252 max memory_allocated 29271.02001953125 
[2025-03-01 14:34:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.002383796265348792 norm:0.002825790084898472 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0022070189006626606 norm:0.0022159649524837732 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.002154208952561021 norm:0.001996826846152544 max memory_allocated 29271.02001953125 
[2025-03-01 14:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.002218365203589201 norm:0.0018851794302463531 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.002118071774020791 norm:0.001612937543541193 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0020931661128997803 norm:0.001412676996551454 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.002091404516249895 norm:0.0014193210517987609 max memory_allocated 29271.02001953125 
[2025-03-01 14:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0019615450873970985 norm:0.0011253771372139454 max memory_allocated 29271.02001953125 
[2025-03-01 14:40:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.001980625791475177 norm:0.0010509464191272855 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001983711263164878 norm:0.0010247613536193967 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.001959980931133032 norm:0.0009997168090194464 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.00192761211656034 norm:0.000930356327444315 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.00194416637532413 norm:0.0009498932049609721 max memory_allocated 29271.02001953125 
[2025-03-01 14:44:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0020899823866784573 norm:0.0010334181133657694 max memory_allocated 29271.02001953125 
[2025-03-01 14:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0020113401114940643 norm:0.0009914740221574903 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-01 14:45:23 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:46:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.006264457479119301 norm:0.003255182644352317 max memory_allocated 29271.02001953125 
[2025-03-01 14:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.0048708561807870865 norm:0.0018892728257924318 max memory_allocated 29271.02001953125 
[2025-03-01 14:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.004516002722084522 norm:0.0019437045557424426 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.0042928289622068405 norm:0.001777508994564414 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.004164206329733133 norm:0.001835124334320426 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.0040768408216536045 norm:0.0017724386416375637 max memory_allocated 29271.02001953125 
[2025-03-01 14:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.004006465431302786 norm:0.0016544717364013195 max memory_allocated 29271.02001953125 
[2025-03-01 14:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.003937909379601479 norm:0.0016062946524471045 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.003877772483974695 norm:0.0015777992084622383 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.0038261900190263987 norm:0.0015479065477848053 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.0037760245613753796 norm:0.0014503035927191377 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.0037263587582856417 norm:0.0013098395429551601 max memory_allocated 29271.02001953125 
[2025-03-01 14:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.003682935144752264 norm:0.0012605201918631792 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.003643728792667389 norm:0.0012159151956439018 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.003610694082453847 norm:0.0011098870309069753 max memory_allocated 29271.02001953125 
[2025-03-01 14:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.0035782575141638517 norm:0.0010135656921193004 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.003549514338374138 norm:0.0008875031489878893 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.0035221269354224205 norm:0.0007894244627095759 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.003502190113067627 norm:0.0007392658153548837 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.0034884107299149036 norm:0.0007245885790325701 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-01 15:01:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 15:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.011529828421771526 norm:0.006532018072903156 max memory_allocated 29271.39501953125 
[2025-03-01 15:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.009846053086221218 norm:0.005768522620201111 max memory_allocated 29271.39501953125 
[2025-03-01 15:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.009231403470039368 norm:0.0045803263783454895 max memory_allocated 29271.39501953125 
[2025-03-01 15:04:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.008868015371263027 norm:0.003726289374753833 max memory_allocated 29271.39501953125 
[2025-03-01 15:04:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.008576150983572006 norm:0.003073668573051691 max memory_allocated 29271.39501953125 
[2025-03-01 15:05:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.008294668048620224 norm:0.00255329511128366 max memory_allocated 29271.39501953125 
[2025-03-01 15:06:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.008037802763283253 norm:0.0021869754418730736 max memory_allocated 29271.39501953125 
[2025-03-01 15:07:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.007840437814593315 norm:0.0019528211560100317 max memory_allocated 29271.39501953125 
[2025-03-01 15:07:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.007701334543526173 norm:0.0017491767648607492 max memory_allocated 29271.39501953125 
[2025-03-01 15:08:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.007595375645905733 norm:0.0015694060130044818 max memory_allocated 29271.39501953125 
[2025-03-01 15:09:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.007528773043304682 norm:0.001447850838303566 max memory_allocated 29271.39501953125 
[2025-03-01 15:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.007508036680519581 norm:0.0014077029190957546 max memory_allocated 29271.39501953125 
[2025-03-01 15:10:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.007512093987315893 norm:0.0014360276982188225 max memory_allocated 29271.39501953125 
[2025-03-01 15:11:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.007544474210590124 norm:0.0013844650238752365 max memory_allocated 29271.39501953125 
[2025-03-01 15:12:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.007509014569222927 norm:0.0013519935309886932 max memory_allocated 29271.39501953125 
[2025-03-01 15:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.007471427787095308 norm:0.0012410302879288793 max memory_allocated 29271.39501953125 
[2025-03-01 15:13:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.007471855729818344 norm:0.0012803522404283285 max memory_allocated 29271.39501953125 
[2025-03-01 15:14:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.00745575875043869 norm:0.0011741244234144688 max memory_allocated 29271.39501953125 
[2025-03-01 15:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.0074442168697714806 norm:0.0011528813047334552 max memory_allocated 29271.39501953125 
[2025-03-01 15:16:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.007425123825669289 norm:0.0010460944613441825 max memory_allocated 29271.39501953125 
[2025-03-01 15:16:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-01 15:17:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.10722609609365463 norm:0.016948185861110687 max memory_allocated 29271.39501953125 
[2025-03-01 15:18:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.09516782313585281 norm:0.046256519854068756 max memory_allocated 29271.39501953125 
[2025-03-01 15:18:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.07589752972126007 norm:0.04637006297707558 max memory_allocated 29271.39501953125 
[2025-03-01 15:19:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.0678936019539833 norm:0.03940439596772194 max memory_allocated 29271.39501953125 
[2025-03-01 15:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.05935423821210861 norm:0.03158014640212059 max memory_allocated 29271.39501953125 
[2025-03-01 15:21:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.05444885790348053 norm:0.025528226047754288 max memory_allocated 29271.39501953125 
[2025-03-01 15:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.052250321954488754 norm:0.010010950267314911 max memory_allocated 29271.39501953125 
[2025-03-01 15:22:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.047151219099760056 norm:0.008071564137935638 max memory_allocated 29271.39501953125 
[2025-03-01 15:23:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.04766850173473358 norm:0.007798394653946161 max memory_allocated 29271.39501953125 
[2025-03-01 15:24:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.047152332961559296 norm:0.008046038448810577 max memory_allocated 29271.39501953125 
[2025-03-01 15:24:59 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.054773490875959396 norm:0.009173902682960033 max memory_allocated 29271.39501953125 
[2025-03-01 15:25:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.04755169153213501 norm:0.008014789782464504 max memory_allocated 29271.39501953125 
[2025-03-01 15:26:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.04929165542125702 norm:0.007952970452606678 max memory_allocated 29271.39501953125 
[2025-03-01 15:27:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.05506789684295654 norm:0.008875038474798203 max memory_allocated 29271.39501953125 
[2025-03-01 15:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.052313171327114105 norm:0.008313177153468132 max memory_allocated 29271.39501953125 
[2025-03-01 15:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.05572046339511871 norm:0.008940272964537144 max memory_allocated 29271.39501953125 
[2025-03-01 15:29:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.057695429772138596 norm:0.008710159920156002 max memory_allocated 29271.39501953125 
[2025-03-01 15:30:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.05993032455444336 norm:0.008896616287529469 max memory_allocated 29271.39501953125 
[2025-03-01 15:31:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.06319329142570496 norm:0.009397861547768116 max memory_allocated 29271.39501953125 
[2025-03-01 15:31:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.057805031538009644 norm:0.008483375422656536 max memory_allocated 29271.39501953125 
[2025-03-01 15:31:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-01 15:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.04453063756227493 norm:0.0005582957528531551 max memory_allocated 29271.39501953125 
[2025-03-01 15:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.0432005450129509 norm:0.00023835951287765056 max memory_allocated 29271.39501953125 
[2025-03-01 15:34:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.04255378991365433 norm:0.0001415405422449112 max memory_allocated 29271.39501953125 
[2025-03-01 15:35:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.04212236404418945 norm:0.00010714471864048392 max memory_allocated 29271.39501953125 
[2025-03-01 15:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.04171239212155342 norm:9.464636241318658e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.04137151688337326 norm:9.227547707268968e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:37:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.041149720549583435 norm:8.934342622524127e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:38:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.04103811830282211 norm:8.944408182287589e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:39:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.040999166667461395 norm:9.351996413897723e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.040979139506816864 norm:9.201966167893261e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:40:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.04096557945013046 norm:9.298812801716849e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.04095200076699257 norm:9.59077660809271e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:42:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.04094436764717102 norm:9.595821757102385e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:42:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.04093271121382713 norm:9.463704918744043e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:43:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.04092205688357353 norm:9.295066411141306e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.04091918468475342 norm:9.546964429318905e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.04091309756040573 norm:9.40676691243425e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.040905844420194626 norm:9.773318015504628e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:46:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.040901102125644684 norm:9.807737660594285e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:47:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.040890853852033615 norm:9.738194785313681e-05 max memory_allocated 29271.39501953125 
[2025-03-01 15:47:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-01 15:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.04963991791009903 norm:0.0010714794043451548 max memory_allocated 29271.81298828125 
[2025-03-01 15:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.04412354528903961 norm:0.0004493791493587196 max memory_allocated 29271.81298828125 
[2025-03-01 15:50:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.04245269298553467 norm:0.0002292401622980833 max memory_allocated 29271.81298828125 
[2025-03-01 15:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.04183867573738098 norm:0.00017089798348024487 max memory_allocated 29271.81298828125 
[2025-03-01 15:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.041449740529060364 norm:0.00014642922906205058 max memory_allocated 29271.81298828125 
[2025-03-01 15:52:29 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.04113691672682762 norm:0.00013109546853229403 max memory_allocated 29271.81298828125 
[2025-03-01 15:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.0408867672085762 norm:0.0001176984078483656 max memory_allocated 29271.81298828125 
[2025-03-01 15:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.040743373334407806 norm:0.00010992117313435301 max memory_allocated 29271.81298828125 
[2025-03-01 15:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.04066430777311325 norm:0.0001064645912265405 max memory_allocated 29271.81298828125 
[2025-03-01 15:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.040583088994026184 norm:0.00010391218529548496 max memory_allocated 29271.81298828125 
[2025-03-01 15:56:16 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.04052203148603439 norm:0.0001004278237815015 max memory_allocated 29271.81298828125 
[2025-03-01 15:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.04048321023583412 norm:9.776958904694766e-05 max memory_allocated 29271.81298828125 
[2025-03-01 15:57:47 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.0404619462788105 norm:9.842459257924929e-05 max memory_allocated 29271.81298828125 
[2025-03-01 15:58:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.040444515645504 norm:9.705583215691149e-05 max memory_allocated 29271.81298828125 
[2025-03-01 15:59:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.0404168963432312 norm:9.636326285544783e-05 max memory_allocated 29271.81298828125 
[2025-03-01 16:00:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.040408216416835785 norm:0.00010011033737100661 max memory_allocated 29271.81298828125 
[2025-03-01 16:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.040375128388404846 norm:9.768952440936118e-05 max memory_allocated 29271.81298828125 
[2025-03-01 16:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.040359221398830414 norm:0.00010429288522573188 max memory_allocated 29271.81298828125 
[2025-03-01 16:02:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.040336303412914276 norm:0.00010410081449663267 max memory_allocated 29271.81298828125 
[2025-03-01 16:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.04032158851623535 norm:9.726925054565072e-05 max memory_allocated 29271.81298828125 
[2025-03-01 16:03:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-01 16:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.05069678649306297 norm:0.0012870405334979296 max memory_allocated 29271.81298828125 
[2025-03-01 16:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.04501722753047943 norm:0.0005297047318890691 max memory_allocated 29271.81298828125 
[2025-03-01 16:05:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.04316844791173935 norm:0.0003055404231417924 max memory_allocated 29271.81298828125 
[2025-03-01 16:06:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.04236747324466705 norm:0.00021272386948112398 max memory_allocated 29271.81298828125 
[2025-03-01 16:07:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.04187340289354324 norm:0.0001718629355309531 max memory_allocated 29271.81298828125 
[2025-03-01 16:08:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.041479792445898056 norm:0.0001500064245192334 max memory_allocated 29271.81298828125 
[2025-03-01 16:08:52 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.041231803596019745 norm:0.00013381868484430015 max memory_allocated 29271.81298828125 
[2025-03-01 16:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.04107958450913429 norm:0.00013357990246731788 max memory_allocated 29271.81298828125 
[2025-03-01 16:10:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.04100433737039566 norm:0.00012797066301573068 max memory_allocated 29271.81298828125 
[2025-03-01 16:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.040948398411273956 norm:0.0001275343238376081 max memory_allocated 29271.81298828125 
[2025-03-01 16:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.04087986424565315 norm:0.00011905302380910143 max memory_allocated 29271.81298828125 
[2025-03-01 16:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.04085812345147133 norm:0.00012187372340122238 max memory_allocated 29271.81298828125 
[2025-03-01 16:13:24 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.04082414507865906 norm:0.00012515655544120818 max memory_allocated 29271.81298828125 
[2025-03-01 16:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.04079996794462204 norm:0.0001173920973087661 max memory_allocated 29271.81298828125 
[2025-03-01 16:14:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.04079257324337959 norm:0.0001319552247878164 max memory_allocated 29271.81298828125 
[2025-03-01 16:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.040783219039440155 norm:0.00013251788914203644 max memory_allocated 29271.81298828125 
[2025-03-01 16:16:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.04075245559215546 norm:0.00012149273243267089 max memory_allocated 29271.81298828125 
[2025-03-01 16:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.040739189833402634 norm:0.00012510210217442364 max memory_allocated 29271.81298828125 
[2025-03-01 16:17:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.04073124751448631 norm:0.0001307705679209903 max memory_allocated 29271.81298828125 
[2025-03-01 16:18:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.04072265699505806 norm:0.00013346917694434524 max memory_allocated 29271.81298828125 
[2025-03-01 16:18:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-01 16:19:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.05749216303229332 norm:0.0013368700165301561 max memory_allocated 29271.81298828125 
[2025-03-01 16:20:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.04952489957213402 norm:0.0005868388107046485 max memory_allocated 29271.81298828125 
[2025-03-01 16:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.04690125957131386 norm:0.00035687879426404834 max memory_allocated 29271.81298828125 
[2025-03-01 16:22:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.04590617120265961 norm:0.0002698955941013992 max memory_allocated 29271.81298828125 
[2025-03-01 16:22:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.04536457359790802 norm:0.00025076663587242365 max memory_allocated 29271.81298828125 
[2025-03-01 16:23:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.044931408017873764 norm:0.00023264912306331098 max memory_allocated 29271.81298828125 
[2025-03-01 16:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.04465498402714729 norm:0.00022342943702824414 max memory_allocated 29271.81298828125 
[2025-03-01 16:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.04443861171603203 norm:0.0002184197655878961 max memory_allocated 29271.81298828125 
[2025-03-01 16:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.044322509318590164 norm:0.000203928560949862 max memory_allocated 29271.81298828125 
[2025-03-01 16:26:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.044213760644197464 norm:0.00019963682279922068 max memory_allocated 29271.81298828125 
[2025-03-01 16:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.04415740817785263 norm:0.00019350330694578588 max memory_allocated 29271.81298828125 
[2025-03-01 16:28:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.04410967230796814 norm:0.00019455244182609022 max memory_allocated 29271.81298828125 
[2025-03-01 16:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.04405788332223892 norm:0.00019333748787175864 max memory_allocated 29271.81298828125 
[2025-03-01 16:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.04401444271206856 norm:0.00018482455925550312 max memory_allocated 29271.81298828125 
[2025-03-01 16:30:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.04396848753094673 norm:0.00018533624825067818 max memory_allocated 29271.81298828125 
[2025-03-01 16:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.04392843693494797 norm:0.00017492505139671266 max memory_allocated 29271.81298828125 
[2025-03-01 16:31:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.04391252249479294 norm:0.0001761432213243097 max memory_allocated 29271.81298828125 
[2025-03-01 16:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.04387623816728592 norm:0.00016847671940922737 max memory_allocated 29271.81298828125 
[2025-03-01 16:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.04385332763195038 norm:0.000170242550666444 max memory_allocated 29271.81298828125 
[2025-03-01 16:34:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.043828532099723816 norm:0.00017557392129674554 max memory_allocated 29271.81298828125 
[2025-03-01 16:34:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-01 16:35:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.05642659589648247 norm:0.001278189243748784 max memory_allocated 29272.37548828125 
[2025-03-01 16:36:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.05011521279811859 norm:0.0005966440076008439 max memory_allocated 29272.37548828125 
[2025-03-01 16:36:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.047736089676618576 norm:0.0003474601253401488 max memory_allocated 29272.37548828125 
[2025-03-01 16:37:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.04676268994808197 norm:0.000244391179876402 max memory_allocated 29272.37548828125 
[2025-03-01 16:38:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.04617716372013092 norm:0.00019607471767812967 max memory_allocated 29272.37548828125 
[2025-03-01 16:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.04579482972621918 norm:0.00016686832532286644 max memory_allocated 29272.37548828125 
[2025-03-01 16:39:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.04550643265247345 norm:0.00015419707051478326 max memory_allocated 29272.37548828125 
[2025-03-01 16:40:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.04533284157514572 norm:0.00013933531590737402 max memory_allocated 29272.37548828125 
[2025-03-01 16:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.04522731527686119 norm:0.00013771269004791975 max memory_allocated 29272.37548828125 
[2025-03-01 16:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.04514963924884796 norm:0.00013093849702272564 max memory_allocated 29272.37548828125 
[2025-03-01 16:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.04510001838207245 norm:0.00013452130951918662 max memory_allocated 29272.37548828125 
[2025-03-01 16:43:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.04503399506211281 norm:0.0001251704088645056 max memory_allocated 29272.37548828125 
[2025-03-01 16:44:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.04499724134802818 norm:0.00012705230619758368 max memory_allocated 29272.37548828125 
[2025-03-01 16:45:14 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.04496924579143524 norm:0.00012277830683160573 max memory_allocated 29272.37548828125 
[2025-03-01 16:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.04495088383555412 norm:0.0001236020470969379 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.0449235737323761 norm:0.00012638664338737726 max memory_allocated 29272.37548828125 
[2025-03-01 16:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.04489695653319359 norm:0.00012309938028920442 max memory_allocated 29272.37548828125 
[2025-03-01 16:48:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.04487369954586029 norm:0.00011911871115444228 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.04485928267240524 norm:0.00012092390534235165 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.044848937541246414 norm:0.00011792236909968778 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-01 16:50:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.07475833594799042 norm:0.0028299717232584953 max memory_allocated 29272.56298828125 
[2025-03-01 16:51:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.058467525988817215 norm:0.001189981121569872 max memory_allocated 29272.56298828125 
[2025-03-01 16:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.05255794897675514 norm:0.0005940370610915124 max memory_allocated 29272.56298828125 
[2025-03-01 16:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.0507221594452858 norm:0.00041019124910235405 max memory_allocated 29272.56298828125 
[2025-03-01 16:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.04971325770020485 norm:0.0003239137295167893 max memory_allocated 29272.56298828125 
[2025-03-01 16:54:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.04908221960067749 norm:0.0002808387216646224 max memory_allocated 29272.56298828125 
[2025-03-01 16:55:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.04871761053800583 norm:0.00026064744452014565 max memory_allocated 29272.56298828125 
[2025-03-01 16:56:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.04848720133304596 norm:0.00024538792786188424 max memory_allocated 29272.56298828125 
[2025-03-01 16:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.04832635074853897 norm:0.00024201872292906046 max memory_allocated 29272.56298828125 
[2025-03-01 16:57:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.048173099756240845 norm:0.00023196055553853512 max memory_allocated 29272.56298828125 
[2025-03-01 16:58:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.048031728714704514 norm:0.00021420494886115193 max memory_allocated 29272.56298828125 
[2025-03-01 16:59:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.04791703075170517 norm:0.0002197131689172238 max memory_allocated 29272.56298828125 
[2025-03-01 16:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.04779936745762825 norm:0.00021569806267507374 max memory_allocated 29272.56298828125 
[2025-03-01 17:00:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.04770516976714134 norm:0.0002069117035716772 max memory_allocated 29272.56298828125 
[2025-03-01 17:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.04761997237801552 norm:0.00019914946460630745 max memory_allocated 29272.56298828125 
[2025-03-01 17:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.0475788414478302 norm:0.00020361554925329983 max memory_allocated 29272.56298828125 
[2025-03-01 17:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.04751596599817276 norm:0.00019526267715264112 max memory_allocated 29272.56298828125 
[2025-03-01 17:03:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.047479402273893356 norm:0.00019767426420003176 max memory_allocated 29272.56298828125 
[2025-03-01 17:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.047444380819797516 norm:0.00020001914526801556 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.04738173633813858 norm:0.00018540408927947283 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-01 17:06:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.06342267990112305 norm:0.0014594532549381256 max memory_allocated 29272.75048828125 
[2025-03-01 17:07:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.05570385977625847 norm:0.0007242184365168214 max memory_allocated 29272.75048828125 
[2025-03-01 17:07:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.05283939838409424 norm:0.00042194881825707853 max memory_allocated 29272.75048828125 
[2025-03-01 17:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.05158950388431549 norm:0.00030234165024012327 max memory_allocated 29272.75048828125 
[2025-03-01 17:09:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.050798770040273666 norm:0.0002409120206721127 max memory_allocated 29272.75048828125 
[2025-03-01 17:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.050317324697971344 norm:0.00021357418154366314 max memory_allocated 29272.75048828125 
[2025-03-01 17:10:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.04999260604381561 norm:0.00019145850092172623 max memory_allocated 29272.75048828125 
[2025-03-01 17:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.04978419840335846 norm:0.0001748251379467547 max memory_allocated 29272.75048828125 
[2025-03-01 17:12:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.04966101422905922 norm:0.000165314253536053 max memory_allocated 29272.75048828125 
[2025-03-01 17:13:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.049544256180524826 norm:0.00016273949586320668 max memory_allocated 29272.75048828125 
[2025-03-01 17:13:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.04943274334073067 norm:0.00015427304606419057 max memory_allocated 29272.75048828125 
[2025-03-01 17:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.04936674237251282 norm:0.00015057883865665644 max memory_allocated 29272.75048828125 
[2025-03-01 17:15:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.04931185767054558 norm:0.00015091609384398907 max memory_allocated 29272.75048828125 
[2025-03-01 17:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.049268465489149094 norm:0.0001448021939722821 max memory_allocated 29272.75048828125 
[2025-03-01 17:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.04925413429737091 norm:0.00013968134589958936 max memory_allocated 29272.75048828125 
[2025-03-01 17:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.04919857159256935 norm:0.00013055610179435462 max memory_allocated 29272.75048828125 
[2025-03-01 17:18:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.04915546998381615 norm:0.00012078916188329458 max memory_allocated 29272.75048828125 
[2025-03-01 17:19:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.04911172017455101 norm:0.000118119984108489 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.049099572002887726 norm:0.00011958108370890841 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.049106307327747345 norm:0.00011494656064314768 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-01 17:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.06330234557390213 norm:0.0010822465410456061 max memory_allocated 29272.93798828125 
[2025-03-01 17:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.056375645101070404 norm:0.0004911862197332084 max memory_allocated 29272.93798828125 
[2025-03-01 17:23:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.0539703369140625 norm:0.0002870133612304926 max memory_allocated 29272.93798828125 
[2025-03-01 17:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.052973128855228424 norm:0.000216593369259499 max memory_allocated 29272.93798828125 
[2025-03-01 17:24:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.052386440336704254 norm:0.0001823792263166979 max memory_allocated 29272.93798828125 
[2025-03-01 17:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.05201558768749237 norm:0.00016712301294319332 max memory_allocated 29272.93798828125 
[2025-03-01 17:26:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.05174876004457474 norm:0.00015686794358771294 max memory_allocated 29272.93798828125 
[2025-03-01 17:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.05157950520515442 norm:0.00014386298425961286 max memory_allocated 29272.93798828125 
[2025-03-01 17:27:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.051462866365909576 norm:0.00013834945275448263 max memory_allocated 29272.93798828125 
[2025-03-01 17:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.0514037124812603 norm:0.00013733765808865428 max memory_allocated 29272.93798828125 
[2025-03-01 17:29:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.05133768916130066 norm:0.00013442222552839667 max memory_allocated 29272.93798828125 
[2025-03-01 17:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.05127048119902611 norm:0.00012933523976244032 max memory_allocated 29272.93798828125 
[2025-03-01 17:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.05121535062789917 norm:0.00012386537855491042 max memory_allocated 29272.93798828125 
[2025-03-01 17:31:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.0511864572763443 norm:0.00012080956366844475 max memory_allocated 29272.93798828125 
[2025-03-01 17:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.051145076751708984 norm:0.00011996466491837054 max memory_allocated 29272.93798828125 
[2025-03-01 17:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.05111587420105934 norm:0.00011511846969369799 max memory_allocated 29272.93798828125 
[2025-03-01 17:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.05108406022191048 norm:0.0001162870685220696 max memory_allocated 29272.93798828125 
[2025-03-01 17:34:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.05105234310030937 norm:0.00011466648720670491 max memory_allocated 29272.93798828125 
[2025-03-01 17:35:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.05103074386715889 norm:0.00011464376439107582 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.05100631341338158 norm:0.00011915543291252106 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-01 17:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.06545224785804749 norm:0.0010026618838310242 max memory_allocated 29273.12548828125 
[2025-03-01 17:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.057940736413002014 norm:0.0004899868508800864 max memory_allocated 29273.12548828125 
[2025-03-01 17:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.055292289704084396 norm:0.0002779181522782892 max memory_allocated 29273.12548828125 
[2025-03-01 17:39:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.05434345453977585 norm:0.00021860268316231668 max memory_allocated 29273.12548828125 
[2025-03-01 17:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.05376151576638222 norm:0.00019094182061962783 max memory_allocated 29273.12548828125 
[2025-03-01 17:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.053350288420915604 norm:0.00016990682343021035 max memory_allocated 29273.12548828125 
[2025-03-01 17:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.05307520925998688 norm:0.000157397793373093 max memory_allocated 29273.12548828125 
[2025-03-01 17:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.052856650203466415 norm:0.00014815556642133743 max memory_allocated 29273.12548828125 
[2025-03-01 17:43:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.0527140349149704 norm:0.0001402469933964312 max memory_allocated 29273.12548828125 
[2025-03-01 17:44:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.05261620134115219 norm:0.00013031061098445207 max memory_allocated 29273.12548828125 
[2025-03-01 17:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.052543021738529205 norm:0.00012872586376033723 max memory_allocated 29273.12548828125 
[2025-03-01 17:45:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.0524679534137249 norm:0.00012885333853773773 max memory_allocated 29273.12548828125 
[2025-03-01 17:46:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.052421122789382935 norm:0.0001276794500881806 max memory_allocated 29273.12548828125 
[2025-03-01 17:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.05235336348414421 norm:0.00012082749890396371 max memory_allocated 29273.12548828125 
[2025-03-01 17:47:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.052337102591991425 norm:0.00011663133045658469 max memory_allocated 29273.12548828125 
[2025-03-01 17:48:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.05230884253978729 norm:0.00010679077968234196 max memory_allocated 29273.12548828125 
[2025-03-01 17:49:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.052290961146354675 norm:0.00010412967822048813 max memory_allocated 29273.12548828125 
[2025-03-01 17:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.05225663259625435 norm:0.00010059260966954753 max memory_allocated 29273.12548828125 
[2025-03-01 17:50:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.052236407995224 norm:0.00010364766058046371 max memory_allocated 29273.12548828125 
[2025-03-01 17:51:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.05220121890306473 norm:0.0001047603291226551 max memory_allocated 29273.12548828125 
[2025-03-01 17:51:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-01 17:52:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.06576796621084213 norm:0.0011128319893032312 max memory_allocated 29273.31298828125 
[2025-03-01 17:53:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.05937500298023224 norm:0.0005441409884952009 max memory_allocated 29273.31298828125 
[2025-03-01 17:54:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.05702522024512291 norm:0.00034146051621064544 max memory_allocated 29273.31298828125 
[2025-03-01 17:55:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.055919039994478226 norm:0.000260132277617231 max memory_allocated 29273.31298828125 
[2025-03-01 17:55:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.055202774703502655 norm:0.00021618130267597735 max memory_allocated 29273.31298828125 
[2025-03-01 17:56:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.0547652468085289 norm:0.00019256304949522018 max memory_allocated 29273.31298828125 
[2025-03-01 17:57:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.054469574242830276 norm:0.0001757227146299556 max memory_allocated 29273.31298828125 
[2025-03-01 17:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.054255411028862 norm:0.00016663860878907144 max memory_allocated 29273.31298828125 
[2025-03-01 17:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.0541321225464344 norm:0.0001583108096383512 max memory_allocated 29273.31298828125 
[2025-03-01 17:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.05403008684515953 norm:0.0001523258542874828 max memory_allocated 29273.31298828125 
[2025-03-01 18:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.05391966179013252 norm:0.00014658214058727026 max memory_allocated 29273.31298828125 
[2025-03-01 18:01:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.05383111536502838 norm:0.00013733934611082077 max memory_allocated 29273.31298828125 
[2025-03-01 18:01:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.05376867204904556 norm:0.0001331655657850206 max memory_allocated 29273.31298828125 
[2025-03-01 18:02:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.05371522530913353 norm:0.00012521962344180793 max memory_allocated 29273.31298828125 
[2025-03-01 18:03:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.05367846414446831 norm:0.00012447407061699778 max memory_allocated 29273.31298828125 
[2025-03-01 18:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.05363542586565018 norm:0.00011988652840955183 max memory_allocated 29273.31298828125 
[2025-03-01 18:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.05359875038266182 norm:0.00011586134496610612 max memory_allocated 29273.31298828125 
[2025-03-01 18:05:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.05356172099709511 norm:0.00011534288933034986 max memory_allocated 29273.31298828125 
[2025-03-01 18:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.05352328345179558 norm:0.00011023323895642534 max memory_allocated 29273.31298828125 
[2025-03-01 18:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.05348711460828781 norm:0.00010802564793266356 max memory_allocated 29273.31298828125 
[2025-03-01 18:07:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-01 18:08:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.06534289568662643 norm:0.0009585696388967335 max memory_allocated 29273.50048828125 
[2025-03-01 18:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.05973351374268532 norm:0.0004842288908548653 max memory_allocated 29273.50048828125 
[2025-03-01 18:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.057648882269859314 norm:0.0003087775257881731 max memory_allocated 29273.50048828125 
[2025-03-01 18:10:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.05669097602367401 norm:0.00023060078092385083 max memory_allocated 29273.50048828125 
[2025-03-01 18:11:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.05608689412474632 norm:0.00019468777463771403 max memory_allocated 29273.50048828125 
[2025-03-01 18:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.05567936971783638 norm:0.00017169299826491624 max memory_allocated 29273.50048828125 
[2025-03-01 18:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.05541915446519852 norm:0.00015662581427022815 max memory_allocated 29273.50048828125 
[2025-03-01 18:13:40 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.055200960487127304 norm:0.00014393038873095065 max memory_allocated 29273.50048828125 
[2025-03-01 18:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.055051468312740326 norm:0.00013451928680296987 max memory_allocated 29273.50048828125 
[2025-03-01 18:15:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.054959140717983246 norm:0.00012983310443814844 max memory_allocated 29273.50048828125 
[2025-03-01 18:15:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.05488893389701843 norm:0.00012420318671502173 max memory_allocated 29273.50048828125 
[2025-03-01 18:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.05478787049651146 norm:0.00011558423284441233 max memory_allocated 29273.50048828125 
[2025-03-01 18:17:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.05473116785287857 norm:0.0001130068048951216 max memory_allocated 29273.50048828125 
[2025-03-01 18:18:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.05468577891588211 norm:0.00010817083966685459 max memory_allocated 29273.50048828125 
[2025-03-01 18:18:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.05467013642191887 norm:0.00010338289575884119 max memory_allocated 29273.50048828125 
[2025-03-01 18:19:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.054633356630802155 norm:0.00010147540888283402 max memory_allocated 29273.50048828125 
[2025-03-01 18:20:29 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.054605137556791306 norm:9.90451080724597e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:21:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.054601408541202545 norm:9.95002337731421e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:22:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.054581642150878906 norm:0.00010004716023104265 max memory_allocated 29273.50048828125 
[2025-03-01 18:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.05456355959177017 norm:9.82260680757463e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:22:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-01 18:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.06186112016439438 norm:0.000629593909252435 max memory_allocated 29273.68798828125 
[2025-03-01 18:24:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.05833526700735092 norm:0.0003326652804389596 max memory_allocated 29273.68798828125 
[2025-03-01 18:25:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.0568542554974556 norm:0.00021957118588034064 max memory_allocated 29273.68798828125 
[2025-03-01 18:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.05608701705932617 norm:0.00017267957446165383 max memory_allocated 29273.68798828125 
[2025-03-01 18:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.055645979940891266 norm:0.00015256914775818586 max memory_allocated 29273.68798828125 
[2025-03-01 18:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.05527408793568611 norm:0.00013600209786091 max memory_allocated 29273.68798828125 
[2025-03-01 18:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.05504141002893448 norm:0.00012612903083208948 max memory_allocated 29273.68798828125 
[2025-03-01 18:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.05486401915550232 norm:0.00011539828847162426 max memory_allocated 29273.68798828125 
[2025-03-01 18:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.05475189909338951 norm:0.00010956819460261613 max memory_allocated 29273.68798828125 
[2025-03-01 18:30:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.0546761229634285 norm:0.00010377396392868832 max memory_allocated 29273.68798828125 
[2025-03-01 18:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.05462177097797394 norm:0.00010026340169133618 max memory_allocated 29273.68798828125 
[2025-03-01 18:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.054566364735364914 norm:9.660436626290902e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:32:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.05451897904276848 norm:9.102164767682552e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.054466746747493744 norm:8.834253821987659e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:34:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.054456546902656555 norm:8.705937943886966e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.054433856159448624 norm:8.549584890715778e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.05440298467874527 norm:7.950861618155614e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:36:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.05437833443284035 norm:7.757999264867976e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.05435803532600403 norm:7.644521974725649e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:38:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.054337501525878906 norm:7.637672388227656e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:38:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-01 18:39:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.06607422977685928 norm:0.001026045298203826 max memory_allocated 29273.87548828125 
[2025-03-01 18:40:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.06057383865118027 norm:0.0005035324720665812 max memory_allocated 29273.87548828125 
[2025-03-01 18:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.05844432860612869 norm:0.00032755243591964245 max memory_allocated 29273.87548828125 
[2025-03-01 18:41:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.05737653002142906 norm:0.00023692123068030924 max memory_allocated 29273.87548828125 
[2025-03-01 18:42:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.05676676332950592 norm:0.00019553293532226235 max memory_allocated 29273.87548828125 
[2025-03-01 18:43:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.05634995549917221 norm:0.00017750755068846047 max memory_allocated 29273.87548828125 
[2025-03-01 18:43:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.05604567378759384 norm:0.00016011523257475346 max memory_allocated 29273.87548828125 
[2025-03-01 18:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.05583224445581436 norm:0.00015033467207103968 max memory_allocated 29273.87548828125 
[2025-03-01 18:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.055669426918029785 norm:0.00014000084775034338 max memory_allocated 29273.87548828125 
[2025-03-01 18:46:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.055573273450136185 norm:0.0001397402520524338 max memory_allocated 29273.87548828125 
[2025-03-01 18:46:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.0554826445877552 norm:0.00013102867524139583 max memory_allocated 29273.87548828125 
[2025-03-01 18:47:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.05538661777973175 norm:0.00012266031990293413 max memory_allocated 29273.87548828125 
[2025-03-01 18:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.05531363934278488 norm:0.00012067625357303768 max memory_allocated 29273.87548828125 
[2025-03-01 18:49:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.05527013540267944 norm:0.00011957310198340565 max memory_allocated 29273.87548828125 
[2025-03-01 18:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.05523015558719635 norm:0.00011701293988153338 max memory_allocated 29273.87548828125 
[2025-03-01 18:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.05517764762043953 norm:0.00011416725465096533 max memory_allocated 29273.87548828125 
[2025-03-01 18:51:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.05511315539479256 norm:0.00010826763173099607 max memory_allocated 29273.87548828125 
[2025-03-01 18:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.055070873349905014 norm:0.00010373756231274456 max memory_allocated 29273.87548828125 
[2025-03-01 18:53:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.055052172392606735 norm:0.00010002206545323133 max memory_allocated 29273.87548828125 
[2025-03-01 18:53:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.05502849072217941 norm:9.932686225511134e-05 max memory_allocated 29273.87548828125 
[2025-03-01 18:53:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-01 18:54:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.06228137016296387 norm:0.0010219106916338205 max memory_allocated 29274.06298828125 
[2025-03-01 18:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.05894405394792557 norm:0.000497691857162863 max memory_allocated 29274.06298828125 
[2025-03-01 18:56:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.05760343745350838 norm:0.00031654007034376264 max memory_allocated 29274.06298828125 
[2025-03-01 18:57:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.056871168315410614 norm:0.00022745232854504138 max memory_allocated 29274.06298828125 
[2025-03-01 18:57:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.05641552060842514 norm:0.00018504766921978444 max memory_allocated 29274.06298828125 
[2025-03-01 18:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.05607089027762413 norm:0.00016147198039107025 max memory_allocated 29274.06298828125 
[2025-03-01 18:59:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.05580974742770195 norm:0.00014235182607080787 max memory_allocated 29274.06298828125 
[2025-03-01 19:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.055648092180490494 norm:0.00013104788376949728 max memory_allocated 29274.06298828125 
[2025-03-01 19:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.055556029081344604 norm:0.00012217447510920465 max memory_allocated 29274.06298828125 
[2025-03-01 19:01:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.05545464903116226 norm:0.00011305163206998259 max memory_allocated 29274.06298828125 
[2025-03-01 19:02:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.0553806908428669 norm:0.00010630513861542568 max memory_allocated 29274.06298828125 
[2025-03-01 19:03:13 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.05533574894070625 norm:0.00010274085070705041 max memory_allocated 29274.06298828125 
[2025-03-01 19:03:58 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.055297642946243286 norm:9.848544141277671e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:04:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.05525645986199379 norm:9.686284465715289e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:05:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.0552118718624115 norm:9.14522388484329e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:06:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.05518118292093277 norm:8.971685019787401e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.05517120659351349 norm:8.518431422999129e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:07:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.0551329180598259 norm:8.066660666372627e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.05510585010051727 norm:7.889779953984544e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:09:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.05509869381785393 norm:7.798334991093725e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:09:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-01 19:10:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.06243177503347397 norm:0.0007227829191833735 max memory_allocated 29274.25048828125 
[2025-03-01 19:11:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.058989692479372025 norm:0.0003360381815582514 max memory_allocated 29274.25048828125 
[2025-03-01 19:11:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.05783568695187569 norm:0.0002172462409362197 max memory_allocated 29274.25048828125 
[2025-03-01 19:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.05726452171802521 norm:0.00017192329687532037 max memory_allocated 29274.25048828125 
[2025-03-01 19:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.05681711435317993 norm:0.00014275034482125193 max memory_allocated 29274.25048828125 
[2025-03-01 19:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.05647874251008034 norm:0.00012447434710338712 max memory_allocated 29274.25048828125 
[2025-03-01 19:14:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.05623118579387665 norm:0.00011191298108315095 max memory_allocated 29274.25048828125 
[2025-03-01 19:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.05609209090471268 norm:0.00010238264803774655 max memory_allocated 29274.25048828125 
[2025-03-01 19:16:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.05601296201348305 norm:9.824027074500918e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:17:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.05593385547399521 norm:9.209312702296302e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.05587470531463623 norm:8.662201435072348e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.055829621851444244 norm:8.493413042742759e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.05578252673149109 norm:8.205181802622974e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:20:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.055752988904714584 norm:7.977430504979566e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:20:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.05572910234332085 norm:7.837079465389252e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:21:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.05570470914244652 norm:7.354353874688968e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.05568348243832588 norm:7.143591938074678e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.055653590708971024 norm:6.904250039951876e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:24:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.05563215911388397 norm:6.670867878710851e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:24:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.055612992495298386 norm:6.47462293272838e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:24:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-01 19:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.06323380768299103 norm:0.0005796649493277073 max memory_allocated 29274.43798828125 
[2025-03-01 19:26:41 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.060539282858371735 norm:0.00029672079836018384 max memory_allocated 29274.43798828125 
[2025-03-01 19:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.05944851413369179 norm:0.0001962863461812958 max memory_allocated 29274.43798828125 
[2025-03-01 19:28:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.05887795612215996 norm:0.00014981556159909815 max memory_allocated 29274.43798828125 
[2025-03-01 19:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.05846257507801056 norm:0.000127368577523157 max memory_allocated 29274.43798828125 
[2025-03-01 19:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.05817584693431854 norm:0.0001193766511278227 max memory_allocated 29274.43798828125 
[2025-03-01 19:30:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.05795779079198837 norm:0.00011051686306018382 max memory_allocated 29274.43798828125 
[2025-03-01 19:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.05781532824039459 norm:0.00010091318836202845 max memory_allocated 29274.43798828125 
[2025-03-01 19:31:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.057697031646966934 norm:9.41217367653735e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.05761389434337616 norm:8.878128573996946e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.05755912512540817 norm:8.314233855344355e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:34:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.05751979351043701 norm:8.121811697492376e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.05747052654623985 norm:7.853835995774716e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.05744696035981178 norm:7.673390064155683e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.057417720556259155 norm:7.216337689897045e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.05739165097475052 norm:7.135394844226539e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.05736153572797775 norm:6.862053123768419e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.057347048074007034 norm:6.809188926126808e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.05733293294906616 norm:6.85853956383653e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.05731363222002983 norm:6.730166205670685e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:40:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-01 19:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.06439286470413208 norm:0.0005128666525706649 max memory_allocated 29274.62548828125 
[2025-03-01 19:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.06205292418599129 norm:0.0002547528420109302 max memory_allocated 29274.62548828125 
[2025-03-01 19:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.061171937733888626 norm:0.00017274438869208097 max memory_allocated 29274.62548828125 
[2025-03-01 19:43:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.06063670665025711 norm:0.00013369263615459204 max memory_allocated 29274.62548828125 
[2025-03-01 19:44:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.060234442353248596 norm:0.00011127531615784392 max memory_allocated 29274.62548828125 
[2025-03-01 19:45:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.059946056455373764 norm:9.730387682793662e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.059733498841524124 norm:9.411892824573442e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:46:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.05958973988890648 norm:8.631190576124936e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.05950736999511719 norm:8.348513802047819e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:48:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.059446100145578384 norm:7.704753807047382e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:49:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.05939115211367607 norm:7.286207983270288e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:49:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.0593552440404892 norm:7.09045707480982e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:50:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.0593181848526001 norm:6.976611621212214e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.05930234491825104 norm:6.613183359149843e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:52:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.05927782133221626 norm:6.332092743832618e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.05926160141825676 norm:6.315608334261924e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.05924633890390396 norm:6.388413748936728e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.05923892930150032 norm:6.327441951725632e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.05921647697687149 norm:6.034360922058113e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.05920339748263359 norm:5.9254743973724544e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:56:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-01 19:56:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.06892845034599304 norm:0.0007250168127939105 max memory_allocated 29274.81298828125 
[2025-03-01 19:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.06590054929256439 norm:0.00038007512921467423 max memory_allocated 29274.81298828125 
[2025-03-01 19:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.0645613893866539 norm:0.00023600940767209977 max memory_allocated 29274.81298828125 
[2025-03-01 19:59:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.06390773504972458 norm:0.0001778833830030635 max memory_allocated 29274.81298828125 
[2025-03-01 19:59:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.06348521262407303 norm:0.0001510036236140877 max memory_allocated 29274.81298828125 
[2025-03-01 20:00:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.06310751289129257 norm:0.00013209097960498184 max memory_allocated 29274.81298828125 
[2025-03-01 20:01:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.06285758316516876 norm:0.00012059831351507455 max memory_allocated 29274.81298828125 
[2025-03-01 20:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.06270010769367218 norm:0.00011168217315571383 max memory_allocated 29274.81298828125 
[2025-03-01 20:03:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.06261385232210159 norm:0.00010786839993670583 max memory_allocated 29274.81298828125 
[2025-03-01 20:03:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.06253992021083832 norm:0.00010344598558731377 max memory_allocated 29274.81298828125 
[2025-03-01 20:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.06246864050626755 norm:9.820476407185197e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.06241907551884651 norm:9.346150181954727e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.062382906675338745 norm:9.192676952807233e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.062341559678316116 norm:8.875899948179722e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.06230297312140465 norm:8.548456389689818e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.0622696578502655 norm:8.227426587836817e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.062250759452581406 norm:7.834818825358525e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.06222469359636307 norm:7.629248284501955e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.062211234122514725 norm:7.620167889399454e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.06219010800123215 norm:7.450397970387712e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:11:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-01 20:12:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.06967221945524216 norm:0.0004663137369789183 max memory_allocated 29275.00048828125 
[2025-03-01 20:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.06785444170236588 norm:0.0002264528739033267 max memory_allocated 29275.00048828125 
[2025-03-01 20:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.0671672374010086 norm:0.00015193747822195292 max memory_allocated 29275.00048828125 
[2025-03-01 20:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.06671425700187683 norm:0.00011313254799460992 max memory_allocated 29275.00048828125 
[2025-03-01 20:15:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.06636407971382141 norm:9.57357551669702e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.06607440114021301 norm:8.844485273584723e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:16:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.06590040028095245 norm:8.643657201901078e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:17:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.06578138470649719 norm:8.100515697151423e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:18:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.06569673866033554 norm:7.558315701317042e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:19:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.06563995778560638 norm:7.242937863338739e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.06560782343149185 norm:6.947088695596904e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:20:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.06556273996829987 norm:6.653027230640873e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:21:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.06553618609905243 norm:7.551483577117324e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:22:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.06551028788089752 norm:6.318220403045416e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:23:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.06549128890037537 norm:6.59369325148873e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.06546338647603989 norm:6.717096403008327e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:24:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.06545060873031616 norm:6.482364551629871e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:25:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.06544522941112518 norm:6.466371269198135e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:26:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.06544683873653412 norm:6.205932731973007e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:26:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.06544027477502823 norm:6.235206819837913e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:27:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-01 20:27:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.07410062849521637 norm:0.0005105691961944103 max memory_allocated 29275.18798828125 
[2025-03-01 20:28:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.07230640202760696 norm:0.0002664851490408182 max memory_allocated 29275.18798828125 
[2025-03-01 20:29:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.07151816785335541 norm:0.00016976200276985765 max memory_allocated 29275.18798828125 
[2025-03-01 20:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.07102049887180328 norm:0.00012901269656140357 max memory_allocated 29275.18798828125 
[2025-03-01 20:30:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.07061915099620819 norm:0.00010879527690121904 max memory_allocated 29275.18798828125 
[2025-03-01 20:31:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.07029137015342712 norm:9.723611583467573e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.07008364051580429 norm:8.67888011271134e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.06997784972190857 norm:8.14555460237898e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.0699143335223198 norm:7.658274262212217e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.0698520690202713 norm:7.303792517632246e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.06980596482753754 norm:7.11796892574057e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:36:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.06976625323295593 norm:6.94950285833329e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.06973256170749664 norm:6.33636154816486e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:37:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.06971004605293274 norm:6.193431909196079e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.06968599557876587 norm:5.9453537687659264e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:39:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.06965619325637817 norm:5.635255729430355e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:40:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.0696408748626709 norm:5.627921564155258e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:40:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.06963425874710083 norm:5.3854440920986235e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:41:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.06962096691131592 norm:5.390502337832004e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:42:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.06960539519786835 norm:5.26254007127136e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:42:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-01 20:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.07817018032073975 norm:0.0004654427757486701 max memory_allocated 29275.37548828125 
[2025-03-01 20:44:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.07686867564916611 norm:0.00024471909273415804 max memory_allocated 29275.37548828125 
[2025-03-01 20:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.07618788629770279 norm:0.00015935039846226573 max memory_allocated 29275.37548828125 
[2025-03-01 20:45:44 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.07571321725845337 norm:0.00011903564154636115 max memory_allocated 29275.37548828125 
[2025-03-01 20:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.0753059834241867 norm:9.617716568754986e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:47:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.07496875524520874 norm:8.28260017442517e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.07480380684137344 norm:7.69263060647063e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:48:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.07471670210361481 norm:7.14222333044745e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:49:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.07465985417366028 norm:6.603718065889552e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.07461927086114883 norm:6.100605969550088e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.07458770275115967 norm:6.087493966333568e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.07456718385219574 norm:6.207035767147318e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.07455118745565414 norm:6.012677840772085e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:53:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.0745314210653305 norm:5.462530316435732e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:54:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.07452289760112762 norm:5.283814971335232e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:54:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.07451660186052322 norm:5.461289038066752e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.07450718432664871 norm:5.32765916432254e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.07451518625020981 norm:5.3801690228283405e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:57:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.07449616491794586 norm:5.291978959576227e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.07449707388877869 norm:5.353304004529491e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:58:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-01 20:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.08328145742416382 norm:0.0004014743899460882 max memory_allocated 29275.56298828125 
[2025-03-01 20:59:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.08200100809335709 norm:0.0002031669282587245 max memory_allocated 29275.56298828125 
[2025-03-01 21:00:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.08142699301242828 norm:0.0001394897699356079 max memory_allocated 29275.56298828125 
[2025-03-01 21:01:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.0810055211186409 norm:0.00011218143481528386 max memory_allocated 29275.56298828125 
[2025-03-01 21:02:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.08058878779411316 norm:9.541640611132607e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:02:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.08025845885276794 norm:8.731899288250133e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:03:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.08009856194257736 norm:8.01433197921142e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:04:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.0800221636891365 norm:7.554392504971474e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:05:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.07997234165668488 norm:7.115100015653297e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:05:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.07992030680179596 norm:6.623508670600131e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.0798797756433487 norm:6.267798016779125e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:07:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.07983953505754471 norm:6.060791201889515e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:08:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.07981669157743454 norm:6.051484160707332e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.0798058956861496 norm:6.038958963472396e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.07978464663028717 norm:5.935245644650422e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:10:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.07976163178682327 norm:5.568627966567874e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:11:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.07974980026483536 norm:5.3586634749080986e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:11:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.07974113523960114 norm:5.4543786973226815e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:12:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.07974085211753845 norm:5.258233431959525e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.07973770797252655 norm:5.277027594274841e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:13:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-01 21:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.0898841917514801 norm:0.0004918197519145906 max memory_allocated 29275.75048828125 
[2025-03-01 21:15:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.08865943551063538 norm:0.00027711864095181227 max memory_allocated 29275.75048828125 
[2025-03-01 21:16:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.08798545598983765 norm:0.00019143984536640346 max memory_allocated 29275.75048828125 
[2025-03-01 21:16:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.08740821480751038 norm:0.00013819972809869796 max memory_allocated 29275.75048828125 
[2025-03-01 21:17:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.08689068257808685 norm:0.00011596029798965901 max memory_allocated 29275.75048828125 
[2025-03-01 21:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.08653195947408676 norm:0.000104128172097262 max memory_allocated 29275.75048828125 
[2025-03-01 21:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.08636456727981567 norm:9.426171891391277e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.08627739548683167 norm:8.659587911097333e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:20:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.08621755242347717 norm:8.368047565454617e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:21:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.08618299663066864 norm:8.147318294504657e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.08615492284297943 norm:7.88451507105492e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:22:53 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.08613450825214386 norm:7.751306111458689e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.08610913157463074 norm:7.719594577793032e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.08609367161989212 norm:7.456589810317382e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:25:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.0860799178481102 norm:7.321847806451842e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.0860707089304924 norm:7.234398071886972e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.08606302738189697 norm:7.298956188606098e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.08604663610458374 norm:7.478598126908764e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:28:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.08604231476783752 norm:6.977675366215408e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.0860317200422287 norm:6.758628296665847e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:29:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-01 21:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.09551871567964554 norm:0.0003150268457829952 max memory_allocated 29275.93798828125 
[2025-03-01 21:30:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.09442029893398285 norm:0.00018947443459182978 max memory_allocated 29275.93798828125 
[2025-03-01 21:31:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.093903087079525 norm:0.00014068059681449085 max memory_allocated 29275.93798828125 
[2025-03-01 21:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.09342551231384277 norm:0.00011259810707997531 max memory_allocated 29275.93798828125 
[2025-03-01 21:33:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.09296494722366333 norm:9.84763537417166e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.09264995902776718 norm:8.673845150042325e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.09251289814710617 norm:7.78703106334433e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.09244781732559204 norm:7.512838783441111e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.09239067137241364 norm:7.055889000184834e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:36:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.09234966337680817 norm:6.541442417073995e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.0923207551240921 norm:6.080326784285717e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.0923038125038147 norm:6.082405161578208e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.09228204935789108 norm:6.220446084626019e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:39:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.09225349128246307 norm:5.813032475998625e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:40:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.09223194420337677 norm:5.6807944929460064e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.09222646057605743 norm:5.6447144743287936e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:42:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.09220902621746063 norm:5.662637704517692e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:42:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.09219624102115631 norm:5.5665670515736565e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:43:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.09218813478946686 norm:5.505624721990898e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:44:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.09217854589223862 norm:5.3269046475179493e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:44:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-01 21:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.1045704036951065 norm:0.0005550540518015623 max memory_allocated 29276.12548828125 
[2025-03-01 21:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.10302393138408661 norm:0.00032758325687609613 max memory_allocated 29276.12548828125 
[2025-03-01 21:47:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.10213052481412888 norm:0.00022818018624093384 max memory_allocated 29276.12548828125 
[2025-03-01 21:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.10150101035833359 norm:0.00017760152695700526 max memory_allocated 29276.12548828125 
[2025-03-01 21:48:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.10089412331581116 norm:0.00015292991884052753 max memory_allocated 29276.12548828125 
[2025-03-01 21:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.10051761567592621 norm:0.00013430793478619307 max memory_allocated 29276.12548828125 
[2025-03-01 21:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.1003730297088623 norm:0.00012209823762532324 max memory_allocated 29276.12548828125 
[2025-03-01 21:50:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.10029131174087524 norm:0.00011383200762793422 max memory_allocated 29276.12548828125 
[2025-03-01 21:51:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.1002357080578804 norm:0.00010679036495275795 max memory_allocated 29276.12548828125 
[2025-03-01 21:52:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.10019271075725555 norm:0.00010693358490243554 max memory_allocated 29276.12548828125 
[2025-03-01 21:53:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.1001635193824768 norm:0.00010253261280013248 max memory_allocated 29276.12548828125 
[2025-03-01 21:53:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.10012108832597733 norm:0.00010027865937445313 max memory_allocated 29276.12548828125 
[2025-03-01 21:54:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.10009291768074036 norm:0.0001007543396553956 max memory_allocated 29276.12548828125 
[2025-03-01 21:55:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.10007408261299133 norm:0.00010415977885713801 max memory_allocated 29276.12548828125 
[2025-03-01 21:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.10005737841129303 norm:9.056323324330151e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:56:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.10004205256700516 norm:8.602195885032415e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:57:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.10003504157066345 norm:8.601605077274144e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.1000307947397232 norm:8.341918874066323e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.10002141445875168 norm:8.290765254059806e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:59:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.10001638531684875 norm:7.87244935054332e-05 max memory_allocated 29276.12548828125 
[2025-03-01 22:00:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-01 22:01:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.11123267561197281 norm:0.0004314135294407606 max memory_allocated 29276.31298828125 
[2025-03-01 22:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.11009979993104935 norm:0.00024296974879689515 max memory_allocated 29276.31298828125 
[2025-03-01 22:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.10952173173427582 norm:0.0001735730329528451 max memory_allocated 29276.31298828125 
[2025-03-01 22:03:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.10900288075208664 norm:0.0001383860217174515 max memory_allocated 29276.31298828125 
[2025-03-01 22:04:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.1084710955619812 norm:0.00011722102499334142 max memory_allocated 29276.31298828125 
[2025-03-01 22:04:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.10818502306938171 norm:0.0001004877412924543 max memory_allocated 29276.31298828125 
[2025-03-01 22:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.10808118432760239 norm:9.110317478189245e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.10801829397678375 norm:8.6870881204959e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:07:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.10796388238668442 norm:8.103914296953008e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:08:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.10793954133987427 norm:7.807828660588712e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:08:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.10790933668613434 norm:7.323513273149729e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:09:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.10786350071430206 norm:7.265775639098138e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.10785438865423203 norm:7.551309681730345e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:11:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.10782429575920105 norm:6.988279346842319e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:11:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.10781175643205643 norm:6.901347660459578e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:12:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.10780546069145203 norm:6.914435653015971e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:13:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.10779733955860138 norm:6.812961510149762e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.10779450088739395 norm:6.81833626003936e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.10778730362653732 norm:7.290983921848238e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:15:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.10778012871742249 norm:7.068859122227877e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:15:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-01 22:16:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.12096673250198364 norm:0.0004718251002486795 max memory_allocated 29276.50048828125 
[2025-03-01 22:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.11938925087451935 norm:0.00025691339396871626 max memory_allocated 29276.50048828125 
[2025-03-01 22:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.118571937084198 norm:0.00017692892288323492 max memory_allocated 29276.50048828125 
[2025-03-01 22:18:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.11790167540311813 norm:0.00014261523028835654 max memory_allocated 29276.50048828125 
[2025-03-01 22:19:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.11728901416063309 norm:0.00012010405043838546 max memory_allocated 29276.50048828125 
[2025-03-01 22:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.11702714115381241 norm:0.00010664087312761694 max memory_allocated 29276.50048828125 
[2025-03-01 22:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.11692294478416443 norm:9.768435847945511e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.1168474406003952 norm:8.978402911452577e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.11677106469869614 norm:8.243017509812489e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.11672639101743698 norm:8.105071174213663e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:24:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.11669133603572845 norm:7.75978114688769e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:25:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.1166621670126915 norm:7.404784264508635e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.11662802845239639 norm:7.416738662868738e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:26:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.11659867316484451 norm:7.129500590963289e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:27:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.11658354103565216 norm:7.066735997796059e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:28:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.11656904965639114 norm:6.951943214517087e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.11655215919017792 norm:7.204324356280267e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:29:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.11654680967330933 norm:7.250378985190764e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:30:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.11652463674545288 norm:7.070548599585891e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:31:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.1165207251906395 norm:7.073608867358416e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:31:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-01 22:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.1295911818742752 norm:0.0004238886758685112 max memory_allocated 29276.68798828125 
[2025-03-01 22:32:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.12845361232757568 norm:0.00022764920140616596 max memory_allocated 29276.68798828125 
[2025-03-01 22:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.12783634662628174 norm:0.00015544862253591418 max memory_allocated 29276.68798828125 
[2025-03-01 22:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.12718358635902405 norm:0.0001234693918377161 max memory_allocated 29276.68798828125 
[2025-03-01 22:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.12660302221775055 norm:0.00010667122842278332 max memory_allocated 29276.68798828125 
[2025-03-01 22:35:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.12640340626239777 norm:9.693493484519422e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:36:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.1263149082660675 norm:8.841734234010801e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.12625913321971893 norm:8.316520688822493e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.1262199729681015 norm:8.171740046236664e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.12618418037891388 norm:7.893313886597753e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:39:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.12616345286369324 norm:7.767275383230299e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:40:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.1261400580406189 norm:7.796855788910761e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.12612779438495636 norm:7.338064460782334e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:42:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.1261097490787506 norm:7.290137000381947e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.12609504163265228 norm:7.381614705082029e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.12607233226299286 norm:7.31762484065257e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.12605023384094238 norm:7.331191591219977e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.12603294849395752 norm:7.489301060559228e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:45:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.12601852416992188 norm:7.322589954128489e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.12600505352020264 norm:7.303325401153415e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:46:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-01 22:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.14140939712524414 norm:0.0005521818529814482 max memory_allocated 29276.87548828125 
[2025-03-01 22:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.13978491723537445 norm:0.0002954078372567892 max memory_allocated 29276.87548828125 
[2025-03-01 22:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.13889360427856445 norm:0.0002060622937278822 max memory_allocated 29276.87548828125 
[2025-03-01 22:49:57 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.13801702857017517 norm:0.0001582887052791193 max memory_allocated 29276.87548828125 
[2025-03-01 22:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.13738836348056793 norm:0.0001356923021376133 max memory_allocated 29276.87548828125 
[2025-03-01 22:51:28 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.13716615736484528 norm:0.0001201555787702091 max memory_allocated 29276.87548828125 
[2025-03-01 22:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.13705211877822876 norm:0.000108951106085442 max memory_allocated 29276.87548828125 
[2025-03-01 22:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.13694921135902405 norm:0.0001034145025187172 max memory_allocated 29276.87548828125 
[2025-03-01 22:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.13688138127326965 norm:9.750566823640838e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.13684117794036865 norm:9.381925337947905e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.13680635392665863 norm:8.758412150200456e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:56:01 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.13676020503044128 norm:8.558688568882644e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.13674025237560272 norm:8.319193148054183e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.13672122359275818 norm:8.188028732547536e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:58:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.1367078721523285 norm:8.061458356678486e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.1366814374923706 norm:7.692293729633093e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:59:48 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.13665777444839478 norm:7.91039492469281e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.13664081692695618 norm:7.654198998352513e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.13663582503795624 norm:8.013007027329877e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:02:04 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.1366337686777115 norm:7.971689774421975e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:02:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-01 23:03:18 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.15201716125011444 norm:0.00045763037633150816 max memory_allocated 29277.06298828125 
[2025-03-01 23:04:03 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.15044847130775452 norm:0.0002478595415595919 max memory_allocated 29277.06298828125 
[2025-03-01 23:04:48 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.1495928019285202 norm:0.00016991622396744788 max memory_allocated 29277.06298828125 
[2025-03-01 23:05:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.1487380713224411 norm:0.00013141350063961 max memory_allocated 29277.06298828125 
[2025-03-01 23:06:19 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.14816083014011383 norm:0.00011077060480602086 max memory_allocated 29277.06298828125 
[2025-03-01 23:07:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.14799462258815765 norm:9.967833466362208e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:07:50 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.14792029559612274 norm:9.053089161170647e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.14784663915634155 norm:8.424889529123902e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.14779028296470642 norm:8.116337266983464e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:10:06 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.14774517714977264 norm:7.80883856350556e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:10:52 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.14770714938640594 norm:7.702219591010362e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:11:37 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.14768213033676147 norm:7.463410292984918e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.14766225218772888 norm:7.180850661825389e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.14764752984046936 norm:7.182496483437717e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.14763203263282776 norm:7.006350642768666e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:14:39 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.14761313796043396 norm:7.05424536135979e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:15:25 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.14759153127670288 norm:7.087634003255516e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.14757278561592102 norm:6.988840323174372e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:16:55 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.14756052196025848 norm:7.083876698743552e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:17:41 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.14755317568778992 norm:7.13816043571569e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:17:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-01 23:18:46 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.16711413860321045 norm:0.0005552360671572387 max memory_allocated 29277.25048828125 
[2025-03-01 23:19:31 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.16496871411800385 norm:0.0002898626553360373 max memory_allocated 29277.25048828125 
[2025-03-01 23:20:16 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.16380448639392853 norm:0.0001991065073525533 max memory_allocated 29277.25048828125 
[2025-03-01 23:21:02 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.16274695098400116 norm:0.00015747394354548305 max memory_allocated 29277.25048828125 
[2025-03-01 23:21:47 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.16213315725326538 norm:0.00013716159446630627 max memory_allocated 29277.25048828125 
[2025-03-01 23:22:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.16193009912967682 norm:0.00012293990585021675 max memory_allocated 29277.25048828125 
[2025-03-01 23:23:18 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.16180026531219482 norm:0.00011442268441896886 max memory_allocated 29277.25048828125 
[2025-03-01 23:24:04 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.16169732809066772 norm:0.00010693921649362892 max memory_allocated 29277.25048828125 
[2025-03-01 23:24:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.16162598133087158 norm:0.0001024476223392412 max memory_allocated 29277.25048828125 
[2025-03-01 23:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.16156251728534698 norm:9.649239655118436e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.16150955855846405 norm:9.183933434542269e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:27:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.1614580601453781 norm:9.048387437360361e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:27:51 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.16144047677516937 norm:9.381608833791688e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:28:36 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.16141000390052795 norm:8.54119352879934e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.1613803207874298 norm:8.264324424089864e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.16135205328464508 norm:8.173855894710869e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:30:53 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.16134534776210785 norm:8.131936192512512e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.16132913529872894 norm:8.16860847407952e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.16131488978862762 norm:8.022812835406512e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:33:09 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.1613120287656784 norm:8.00986381364055e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:33:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-01 23:34:13 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.18235957622528076 norm:0.0009657807531766593 max memory_allocated 29277.43798828125 
[2025-03-01 23:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.18006159365177155 norm:0.0005069937324151397 max memory_allocated 29277.43798828125 
[2025-03-01 23:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.1786772906780243 norm:0.0003185285604558885 max memory_allocated 29277.43798828125 
[2025-03-01 23:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.17747628688812256 norm:0.0002293774887220934 max memory_allocated 29277.43798828125 
[2025-03-01 23:37:15 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.17691484093666077 norm:0.00017755432054400444 max memory_allocated 29277.43798828125 
[2025-03-01 23:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.17671632766723633 norm:0.00014911829202901572 max memory_allocated 29277.43798828125 
[2025-03-01 23:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.1765897274017334 norm:0.00013046199455857277 max memory_allocated 29277.43798828125 
[2025-03-01 23:39:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.17650555074214935 norm:0.00011738016473827884 max memory_allocated 29277.43798828125 
[2025-03-01 23:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.17643041908740997 norm:0.00010950121213681996 max memory_allocated 29277.43798828125 
[2025-03-01 23:41:02 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.17636609077453613 norm:0.00010535706678638235 max memory_allocated 29277.43798828125 
[2025-03-01 23:41:48 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.17632362246513367 norm:0.00010061160719487816 max memory_allocated 29277.43798828125 
[2025-03-01 23:42:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.17628444731235504 norm:9.477997809881344e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.17624643445014954 norm:9.192765719490126e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:44:04 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.1762198805809021 norm:9.043861791724339e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.17619724571704865 norm:9.047183266375214e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.1761751025915146 norm:9.023975871969014e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.17617742717266083 norm:8.806087134871632e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:47:06 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.17615161836147308 norm:8.522276766598225e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:47:51 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.17613323032855988 norm:8.682306361151859e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:48:37 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.17612022161483765 norm:8.558545232517645e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:48:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-01 23:48:59 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 23:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.20315425097942352 norm:0.004948904272168875 max memory_allocated 29277.77001953125 
[2025-03-01 23:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.1993488073348999 norm:0.003966961521655321 max memory_allocated 29277.77001953125 
[2025-03-01 23:51:16 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.19729921221733093 norm:0.0032415222376585007 max memory_allocated 29277.77001953125 
[2025-03-01 23:52:01 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.1957390159368515 norm:0.0026548432651907206 max memory_allocated 29277.77001953125 
[2025-03-01 23:52:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.19501984119415283 norm:0.0021857023239135742 max memory_allocated 29277.77001953125 
[2025-03-01 23:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.19467993080615997 norm:0.00182588049210608 max memory_allocated 29277.77001953125 
[2025-03-01 23:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.19443872570991516 norm:0.0016485245432704687 max memory_allocated 29277.77001953125 
[2025-03-01 23:55:04 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.19429880380630493 norm:0.0015907809138298035 max memory_allocated 29277.77001953125 
[2025-03-01 23:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.19421574473381042 norm:0.001553052687086165 max memory_allocated 29277.77001953125 
[2025-03-01 23:56:35 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.1940758228302002 norm:0.0014831441221758723 max memory_allocated 29277.77001953125 
[2025-03-01 23:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.19399143755435944 norm:0.0014026951976120472 max memory_allocated 29277.77001953125 
[2025-03-01 23:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.19391557574272156 norm:0.0013298459816724062 max memory_allocated 29277.77001953125 
[2025-03-01 23:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.1938929706811905 norm:0.0013586472487077117 max memory_allocated 29277.77001953125 
[2025-03-01 23:59:38 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.19387303292751312 norm:0.001372376806102693 max memory_allocated 29277.77001953125 
[2025-03-02 00:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.19384346902370453 norm:0.001433951547369361 max memory_allocated 29277.77001953125 
[2025-03-02 00:01:09 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.19391870498657227 norm:0.0012357737869024277 max memory_allocated 29277.77001953125 
[2025-03-02 00:01:55 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.19380585849285126 norm:0.0013757279375568032 max memory_allocated 29277.77001953125 
[2025-03-02 00:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.19391418993473053 norm:0.0010452208807691932 max memory_allocated 29277.77001953125 
[2025-03-02 00:03:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.1938769519329071 norm:0.0010398332960903645 max memory_allocated 29277.77001953125 
[2025-03-02 00:04:12 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.19372162222862244 norm:0.0012291049351915717 max memory_allocated 29277.77001953125 
[2025-03-02 00:04:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 00:04:31 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.22617945075035095 norm:0.004308032803237438 max memory_allocated 29277.95751953125 
[2025-03-02 00:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.2196180522441864 norm:0.0023792393039911985 max memory_allocated 29277.95751953125 
[2025-03-02 00:06:48 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.2134840190410614 norm:0.012385748326778412 max memory_allocated 29277.95751953125 
[2025-03-02 00:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.21192023158073425 norm:0.011488142423331738 max memory_allocated 29277.95751953125 
[2025-03-02 00:08:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.21027131378650665 norm:0.006810643244534731 max memory_allocated 29277.95751953125 
[2025-03-02 00:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.20980307459831238 norm:0.006374446675181389 max memory_allocated 29277.95751953125 
[2025-03-02 00:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.20939376950263977 norm:0.0058873794041574 max memory_allocated 29277.95751953125 
[2025-03-02 00:10:36 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.20903821289539337 norm:0.005920137744396925 max memory_allocated 29277.95751953125 
[2025-03-02 00:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.2086775004863739 norm:0.005765196867287159 max memory_allocated 29277.95751953125 
[2025-03-02 00:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.2083662450313568 norm:0.005315071903169155 max memory_allocated 29277.95751953125 
[2025-03-02 00:12:53 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.20820368826389313 norm:0.00507611408829689 max memory_allocated 29277.95751953125 
[2025-03-02 00:13:38 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.2080424278974533 norm:0.005389129742980003 max memory_allocated 29277.95751953125 
[2025-03-02 00:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.20794448256492615 norm:0.0053658513352274895 max memory_allocated 29277.95751953125 
[2025-03-02 00:15:10 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.20784592628479004 norm:0.005142013542354107 max memory_allocated 29277.95751953125 
[2025-03-02 00:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.20749789476394653 norm:0.005651485174894333 max memory_allocated 29277.95751953125 
[2025-03-02 00:16:41 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.2074301540851593 norm:0.005956776440143585 max memory_allocated 29277.95751953125 
[2025-03-02 00:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.20744532346725464 norm:0.006202765740454197 max memory_allocated 29277.95751953125 
[2025-03-02 00:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.20737136900424957 norm:0.006718849763274193 max memory_allocated 29277.95751953125 
[2025-03-02 00:18:58 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.20730172097682953 norm:0.006689124274998903 max memory_allocated 29277.95751953125 
[2025-03-02 00:19:44 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.20719818770885468 norm:0.006564875598996878 max memory_allocated 29277.95751953125 
[2025-03-02 00:19:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 00:20:03 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.25691333413124084 norm:0.006255232263356447 max memory_allocated 29278.14501953125 
[2025-03-02 00:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.24835528433322906 norm:0.0038851737044751644 max memory_allocated 29278.14501953125 
[2025-03-02 00:22:20 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.24073952436447144 norm:0.004248573444783688 max memory_allocated 29278.14501953125 
[2025-03-02 00:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.2377316951751709 norm:0.0043389685451984406 max memory_allocated 29278.14501953125 
[2025-03-02 00:23:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.23659935593605042 norm:0.004326316993683577 max memory_allocated 29278.14501953125 
[2025-03-02 00:24:37 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.2357386201620102 norm:0.004184012301266193 max memory_allocated 29278.14501953125 
[2025-03-02 00:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.23517301678657532 norm:0.004116227384656668 max memory_allocated 29278.14501953125 
[2025-03-02 00:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.23485685884952545 norm:0.004067039582878351 max memory_allocated 29278.14501953125 
[2025-03-02 00:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.2346738874912262 norm:0.003957266919314861 max memory_allocated 29278.14501953125 
[2025-03-02 00:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.23450452089309692 norm:0.0038672788068652153 max memory_allocated 29278.14501953125 
[2025-03-02 00:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.23435907065868378 norm:0.003829769790172577 max memory_allocated 29278.14501953125 
[2025-03-02 00:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.2342563271522522 norm:0.0038576810620725155 max memory_allocated 29278.14501953125 
[2025-03-02 00:29:57 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.2342446893453598 norm:0.003936013672500849 max memory_allocated 29278.14501953125 
[2025-03-02 00:30:42 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.23416537046432495 norm:0.003958096727728844 max memory_allocated 29278.14501953125 
[2025-03-02 00:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.23414339125156403 norm:0.004052461124956608 max memory_allocated 29278.14501953125 
[2025-03-02 00:32:14 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.2340579330921173 norm:0.0040047382935881615 max memory_allocated 29278.14501953125 
[2025-03-02 00:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.23395520448684692 norm:0.003957722801715136 max memory_allocated 29278.14501953125 
[2025-03-02 00:33:45 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.23392587900161743 norm:0.0040367366746068 max memory_allocated 29278.14501953125 
[2025-03-02 00:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.2340066134929657 norm:0.004196635447442532 max memory_allocated 29278.14501953125 
[2025-03-02 00:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.2339625507593155 norm:0.004172688350081444 max memory_allocated 29278.14501953125 
[2025-03-02 00:35:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 00:35:36 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:36:21 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.3511905074119568 norm:0.021231340244412422 max memory_allocated 29278.33251953125 
[2025-03-02 00:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.3345421850681305 norm:0.016336113214492798 max memory_allocated 29278.33251953125 
[2025-03-02 00:37:52 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.32638683915138245 norm:0.013778572902083397 max memory_allocated 29278.33251953125 
[2025-03-02 00:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.32120585441589355 norm:0.011840152554214 max memory_allocated 29278.33251953125 
[2025-03-02 00:39:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.3182947337627411 norm:0.010767193511128426 max memory_allocated 29278.33251953125 
[2025-03-02 00:40:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.316304087638855 norm:0.009480029344558716 max memory_allocated 29278.33251953125 
[2025-03-02 00:40:55 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.3148181736469269 norm:0.008938801474869251 max memory_allocated 29278.33251953125 
[2025-03-02 00:41:41 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.3136855959892273 norm:0.008508066646754742 max memory_allocated 29278.33251953125 
[2025-03-02 00:42:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.3130453824996948 norm:0.008168644271790981 max memory_allocated 29278.33251953125 
[2025-03-02 00:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.31227612495422363 norm:0.008077429607510567 max memory_allocated 29278.33251953125 
[2025-03-02 00:43:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.3118436932563782 norm:0.007851814851164818 max memory_allocated 29278.33251953125 
[2025-03-02 00:44:43 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.3116843104362488 norm:0.0078914575278759 max memory_allocated 29278.33251953125 
[2025-03-02 00:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.31127649545669556 norm:0.007642220705747604 max memory_allocated 29278.33251953125 
[2025-03-02 00:46:15 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.3113349676132202 norm:0.00808147992938757 max memory_allocated 29278.33251953125 
[2025-03-02 00:47:00 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.3114018738269806 norm:0.008295825682580471 max memory_allocated 29278.33251953125 
[2025-03-02 00:47:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.3108687698841095 norm:0.007522893138229847 max memory_allocated 29278.33251953125 
[2025-03-02 00:48:32 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.3107711970806122 norm:0.007443161215633154 max memory_allocated 29278.33251953125 
[2025-03-02 00:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.3104555010795593 norm:0.007332759443670511 max memory_allocated 29278.33251953125 
[2025-03-02 00:50:03 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.31007036566734314 norm:0.006971130147576332 max memory_allocated 29278.33251953125 
[2025-03-02 00:50:49 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.30971893668174744 norm:0.006725601386278868 max memory_allocated 29278.33251953125 
[2025-03-02 00:51:01 root] (main_calib_config2.py 380): INFO 37300.32748389244
[2025-03-02 00:51:12 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-02 00:52:55 root] (main_calib_config2.py 159): INFO wikitext2 : 4.99989128112793
[2025-03-02 00:52:56 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-02 00:55:35 root] (main_calib_config2.py 159): INFO c4 : 6.6224894523620605
[2025-03-02 02:56:05 root] (main_calib_config2.py 170): INFO {'wikitext2': 4.99989128112793, 'c4': 6.6224894523620605, 'results': {'hellaswag': {'acc': 0.5899223262298346, 'acc_stderr': 0.004908423147162022, 'acc_norm': 0.7574188408683529, 'acc_norm_stderr': 0.004277678115910419}, 'piqa': {'acc': 0.7829162132752993, 'acc_stderr': 0.00961870841575678, 'acc_norm': 0.7883569096844396, 'acc_norm_stderr': 0.009530351270479393}, 'arc_easy': {'acc': 0.7205387205387206, 'acc_stderr': 0.009207838142597237, 'acc_norm': 0.571969696969697, 'acc_norm_stderr': 0.01015294331642627}, 'boolq': {'acc': 0.6896024464831805, 'acc_stderr': 0.008091910698229255}, 'arc_challenge': {'acc': 0.4453924914675768, 'acc_stderr': 0.014523987638344078, 'acc_norm': 0.4249146757679181, 'acc_norm_stderr': 0.01444569896852077}, 'winogrande': {'acc': 0.6764009471191792, 'acc_stderr': 0.01314888332092315}}, 'versions': {'hellaswag': 0, 'piqa': 0, 'arc_easy': 0, 'boolq': 1, 'arc_challenge': 0, 'winogrande': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
