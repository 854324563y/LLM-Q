[2025-03-02 12:48:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.4', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.4.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.4.pkl
[2025-03-02 12:52:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.026945993304252625 norm:0.016359709203243256 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.01518326811492443 norm:0.0075239576399326324 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.01080455631017685 norm:0.004779906012117863 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.00939139723777771 norm:0.003906083991751075 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.008754215203225613 norm:0.003175223246216774 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.008293447084724903 norm:0.0026276640128344297 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.008071686141192913 norm:0.0022942502982914448 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.007869417779147625 norm:0.002143498044461012 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.007764357607811689 norm:0.001973487203940749 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.007737553212791681 norm:0.0017620575381442904 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.007586694788187742 norm:0.0015965127386152744 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.007527364883571863 norm:0.0014844948891550303 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.007495869882404804 norm:0.0016458664322271943 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.007409526966512203 norm:0.001323689240962267 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0074507067911326885 norm:0.0012783714337274432 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.007378450129181147 norm:0.001213853363879025 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.007295483257621527 norm:0.0011218423023819923 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.007413134444504976 norm:0.0012189947301521897 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.007364978548139334 norm:0.0013956845505163074 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.007282836362719536 norm:0.0011356413597241044 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:14 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.0775119960308075 norm:0.023030374199151993 max memory_allocated 29268.02001953125 
[2025-03-02 13:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.06002597510814667 norm:0.013167603872716427 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:42 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.05245290696620941 norm:0.009663807228207588 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.049754343926906586 norm:0.007820644415915012 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.04860970377922058 norm:0.006818875204771757 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.047782719135284424 norm:0.005845115520060062 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.04718005657196045 norm:0.005069836508482695 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.04666939377784729 norm:0.00433679623529315 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.04629773274064064 norm:0.0036440405528992414 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.046022988855838776 norm:0.0032049906440079212 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.045844074338674545 norm:0.003142537781968713 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.045716799795627594 norm:0.0031550624407827854 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.04563266783952713 norm:0.0030951143708080053 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.0456109382212162 norm:0.002927366876974702 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.04540722072124481 norm:0.0028543565422296524 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.04534332826733589 norm:0.002693361369892955 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.04528995230793953 norm:0.0027852202765643597 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.04518967121839523 norm:0.0025754538364708424 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.04514788091182709 norm:0.0026908768340945244 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.045091282576322556 norm:0.0025592963211238384 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:25:52 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:26:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.14824676513671875 norm:0.021525435149669647 max memory_allocated 29268.02001953125 
[2025-03-02 13:27:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.12539441883563995 norm:0.015015712007880211 max memory_allocated 29268.02001953125 
[2025-03-02 13:28:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.11104957014322281 norm:0.010350150987505913 max memory_allocated 29268.02001953125 
[2025-03-02 13:29:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.1035904809832573 norm:0.007790594827383757 max memory_allocated 29268.02001953125 
[2025-03-02 13:29:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.09935297816991806 norm:0.00680357962846756 max memory_allocated 29268.02001953125 
[2025-03-02 13:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.0968247726559639 norm:0.006183065474033356 max memory_allocated 29268.02001953125 
[2025-03-02 13:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.09487170726060867 norm:0.006441842298954725 max memory_allocated 29268.02001953125 
[2025-03-02 13:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.09341369569301605 norm:0.005915840156376362 max memory_allocated 29268.02001953125 
[2025-03-02 13:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.09272702038288116 norm:0.005554715637117624 max memory_allocated 29268.02001953125 
[2025-03-02 13:34:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.09224927425384521 norm:0.005560403689742088 max memory_allocated 29268.02001953125 
[2025-03-02 13:34:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.09190064668655396 norm:0.005298146512359381 max memory_allocated 29268.02001953125 
[2025-03-02 13:35:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.09118504822254181 norm:0.005020691081881523 max memory_allocated 29268.02001953125 
[2025-03-02 13:36:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.09072235971689224 norm:0.004776704125106335 max memory_allocated 29268.02001953125 
[2025-03-02 13:37:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.09069827198982239 norm:0.004929262213408947 max memory_allocated 29268.02001953125 
[2025-03-02 13:38:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.09081169217824936 norm:0.004892745520919561 max memory_allocated 29268.02001953125 
[2025-03-02 13:38:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.09001483023166656 norm:0.004630631767213345 max memory_allocated 29268.02001953125 
[2025-03-02 13:39:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.09003117680549622 norm:0.004628057591617107 max memory_allocated 29268.02001953125 
[2025-03-02 13:40:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.09020102769136429 norm:0.004875950515270233 max memory_allocated 29268.02001953125 
[2025-03-02 13:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.09024621546268463 norm:0.004836029373109341 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.09059140831232071 norm:0.004949134774506092 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:43:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.15223228931427002 norm:0.007454457227140665 max memory_allocated 29268.02001953125 
[2025-03-02 13:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.13306781649589539 norm:0.0031485576182603836 max memory_allocated 29268.02001953125 
[2025-03-02 13:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.121989406645298 norm:0.0018301164964213967 max memory_allocated 29268.02001953125 
[2025-03-02 13:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.11785459518432617 norm:0.001208313973620534 max memory_allocated 29268.02001953125 
[2025-03-02 13:46:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.11568823456764221 norm:0.0009753546910360456 max memory_allocated 29268.02001953125 
[2025-03-02 13:47:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.11420924961566925 norm:0.0008679080056026578 max memory_allocated 29268.02001953125 
[2025-03-02 13:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.11307039111852646 norm:0.000792215927504003 max memory_allocated 29268.02001953125 
[2025-03-02 13:49:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.11230434477329254 norm:0.0007702246075496078 max memory_allocated 29268.02001953125 
[2025-03-02 13:49:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.11170728504657745 norm:0.0007604556740261614 max memory_allocated 29268.02001953125 
[2025-03-02 13:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.11127018928527832 norm:0.0007468070252798498 max memory_allocated 29268.02001953125 
[2025-03-02 13:51:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.11093924939632416 norm:0.0007452829740941525 max memory_allocated 29268.02001953125 
[2025-03-02 13:52:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.11072196811437607 norm:0.0007547852583229542 max memory_allocated 29268.02001953125 
[2025-03-02 13:53:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.1105048879981041 norm:0.0007522303494624794 max memory_allocated 29268.02001953125 
[2025-03-02 13:53:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.11034524440765381 norm:0.0007560375961475074 max memory_allocated 29268.02001953125 
[2025-03-02 13:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.11023788154125214 norm:0.0007500973879359663 max memory_allocated 29268.02001953125 
[2025-03-02 13:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.11012283712625504 norm:0.0007431672420352697 max memory_allocated 29268.02001953125 
[2025-03-02 13:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.11004181206226349 norm:0.0007502512307837605 max memory_allocated 29268.02001953125 
[2025-03-02 13:57:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.10997068136930466 norm:0.0007454590522684157 max memory_allocated 29268.02001953125 
[2025-03-02 13:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.10991771519184113 norm:0.000746993871871382 max memory_allocated 29268.02001953125 
[2025-03-02 13:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.10985434055328369 norm:0.0007624787394888699 max memory_allocated 29268.02001953125 
[2025-03-02 13:59:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 13:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.15954120457172394 norm:0.0220332071185112 max memory_allocated 29268.02001953125 
[2025-03-02 14:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.12732192873954773 norm:0.005078489892184734 max memory_allocated 29268.02001953125 
[2025-03-02 14:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.11327192187309265 norm:0.0023086818400770426 max memory_allocated 29268.02001953125 
[2025-03-02 14:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.10899122059345245 norm:0.0015677165938541293 max memory_allocated 29268.02001953125 
[2025-03-02 14:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.10681383311748505 norm:0.001333277323283255 max memory_allocated 29268.02001953125 
[2025-03-02 14:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.10541477799415588 norm:0.0011668797815218568 max memory_allocated 29268.02001953125 
[2025-03-02 14:04:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.10442554205656052 norm:0.000984231592155993 max memory_allocated 29268.02001953125 
[2025-03-02 14:05:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.10397067666053772 norm:0.000848731491714716 max memory_allocated 29268.02001953125 
[2025-03-02 14:06:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.10374988615512848 norm:0.0008332181605510414 max memory_allocated 29268.02001953125 
[2025-03-02 14:07:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.10382198542356491 norm:0.000863598077557981 max memory_allocated 29268.02001953125 
[2025-03-02 14:08:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.10362914204597473 norm:0.0008150535868480802 max memory_allocated 29268.02001953125 
[2025-03-02 14:08:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.10331488400697708 norm:0.0007278864504769444 max memory_allocated 29268.02001953125 
[2025-03-02 14:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.1034950539469719 norm:0.0007639082032255828 max memory_allocated 29268.02001953125 
[2025-03-02 14:10:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.1032419502735138 norm:0.0006553188432008028 max memory_allocated 29268.02001953125 
[2025-03-02 14:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.10306774824857712 norm:0.000657453085295856 max memory_allocated 29268.02001953125 
[2025-03-02 14:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.1031554713845253 norm:0.0006467192433774471 max memory_allocated 29268.02001953125 
[2025-03-02 14:12:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.10315171629190445 norm:0.0006374443764798343 max memory_allocated 29268.02001953125 
[2025-03-02 14:13:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.10320860892534256 norm:0.0006610995042137802 max memory_allocated 29268.02001953125 
[2025-03-02 14:14:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.10307220369577408 norm:0.0006405788590200245 max memory_allocated 29268.02001953125 
[2025-03-02 14:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.10308462381362915 norm:0.0006719015655107796 max memory_allocated 29268.02001953125 
[2025-03-02 14:15:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.1712212711572647 norm:0.023461539298295975 max memory_allocated 29268.02001953125 
[2025-03-02 14:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.13665610551834106 norm:0.007349715102463961 max memory_allocated 29268.02001953125 
[2025-03-02 14:18:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.1199868768453598 norm:0.0030576300341635942 max memory_allocated 29268.02001953125 
[2025-03-02 14:18:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.11438962072134018 norm:0.00199443893507123 max memory_allocated 29268.02001953125 
[2025-03-02 14:19:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.11154228448867798 norm:0.00147485441993922 max memory_allocated 29268.02001953125 
[2025-03-02 14:20:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.1099369153380394 norm:0.0012727597495540977 max memory_allocated 29268.02001953125 
[2025-03-02 14:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.10895135998725891 norm:0.0010483409278094769 max memory_allocated 29268.02001953125 
[2025-03-02 14:22:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.108448326587677 norm:0.0009411389473825693 max memory_allocated 29268.02001953125 
[2025-03-02 14:23:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.10821636021137238 norm:0.0008727612439543009 max memory_allocated 29268.02001953125 
[2025-03-02 14:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.10796486586332321 norm:0.0008402199018746614 max memory_allocated 29268.02001953125 
[2025-03-02 14:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.10784260928630829 norm:0.0007839095196686685 max memory_allocated 29268.02001953125 
[2025-03-02 14:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.10773567855358124 norm:0.0007863424834795296 max memory_allocated 29268.02001953125 
[2025-03-02 14:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.10763875395059586 norm:0.0007574862102046609 max memory_allocated 29268.02001953125 
[2025-03-02 14:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.1076124981045723 norm:0.0007371691754087806 max memory_allocated 29268.02001953125 
[2025-03-02 14:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.1075834259390831 norm:0.0007134220795705914 max memory_allocated 29268.02001953125 
[2025-03-02 14:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.10750027000904083 norm:0.0006569977849721909 max memory_allocated 29268.02001953125 
[2025-03-02 14:29:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.10753972828388214 norm:0.000644730229396373 max memory_allocated 29268.02001953125 
[2025-03-02 14:30:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.10764960944652557 norm:0.0006251563900150359 max memory_allocated 29268.02001953125 
[2025-03-02 14:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.10767056047916412 norm:0.0006434157839976251 max memory_allocated 29268.02001953125 
[2025-03-02 14:32:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.10766574740409851 norm:0.0005877931835129857 max memory_allocated 29268.02001953125 
[2025-03-02 14:32:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.19716638326644897 norm:0.012327673844993114 max memory_allocated 29269.00048828125 
[2025-03-02 14:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.15984410047531128 norm:0.0060337623581290245 max memory_allocated 29269.00048828125 
[2025-03-02 14:34:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.13525745272636414 norm:0.0029675683472305536 max memory_allocated 29269.00048828125 
[2025-03-02 14:35:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.12882448732852936 norm:0.0020001099910587072 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.12549152970314026 norm:0.0016475286101922393 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.12162980437278748 norm:0.0013881860068067908 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.11970888078212738 norm:0.0012378495885059237 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.11868609488010406 norm:0.0011301122140139341 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.11780810356140137 norm:0.0010383045300841331 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:31 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.11724136024713516 norm:0.0010521466610953212 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.11691482365131378 norm:0.001084652147255838 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.11663459241390228 norm:0.0011412089224904776 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.11628540605306625 norm:0.0011269551469013095 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.11620275676250458 norm:0.0011887922883033752 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.11604814231395721 norm:0.0011222531320527196 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.11590062826871872 norm:0.0011194213293492794 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.11595857888460159 norm:0.0011337731266394258 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.11589107662439346 norm:0.0011342433281242847 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.11593320220708847 norm:0.0011164777679368854 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.1159689649939537 norm:0.0011483749840408564 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:49:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.1883658468723297 norm:0.011627664789557457 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.15596778690814972 norm:0.005477713420987129 max memory_allocated 29269.00048828125 
[2025-03-02 14:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.13248926401138306 norm:0.0017895980272442102 max memory_allocated 29269.00048828125 
[2025-03-02 14:52:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.12571001052856445 norm:0.0009605790255591273 max memory_allocated 29269.00048828125 
[2025-03-02 14:53:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.12274675816297531 norm:0.0007271809154190123 max memory_allocated 29269.00048828125 
[2025-03-02 14:53:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.1210436001420021 norm:0.000618660997133702 max memory_allocated 29269.00048828125 
[2025-03-02 14:54:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.12001339346170425 norm:0.000599000311922282 max memory_allocated 29269.00048828125 
[2025-03-02 14:55:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.11940809339284897 norm:0.0005651198443956673 max memory_allocated 29269.00048828125 
[2025-03-02 14:56:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.11898313462734222 norm:0.0005422649555839598 max memory_allocated 29269.00048828125 
[2025-03-02 14:57:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.11865723133087158 norm:0.0005240699974820018 max memory_allocated 29269.00048828125 
[2025-03-02 14:57:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.11842338740825653 norm:0.0005026170983910561 max memory_allocated 29269.00048828125 
[2025-03-02 14:58:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.11827680468559265 norm:0.0004816974396817386 max memory_allocated 29269.00048828125 
[2025-03-02 14:59:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.11816485226154327 norm:0.00047887465916574 max memory_allocated 29269.00048828125 
[2025-03-02 15:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.11809056997299194 norm:0.0004832100821658969 max memory_allocated 29269.00048828125 
[2025-03-02 15:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.11796724796295166 norm:0.00047087925486266613 max memory_allocated 29269.00048828125 
[2025-03-02 15:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.11792104691267014 norm:0.00045218196464702487 max memory_allocated 29269.00048828125 
[2025-03-02 15:02:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.11791273951530457 norm:0.0004472406581044197 max memory_allocated 29269.00048828125 
[2025-03-02 15:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.1179041638970375 norm:0.00042952963849529624 max memory_allocated 29269.00048828125 
[2025-03-02 15:04:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.11793404817581177 norm:0.0004243901348672807 max memory_allocated 29269.00048828125 
[2025-03-02 15:05:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.11784045398235321 norm:0.00041270945803262293 max memory_allocated 29269.00048828125 
[2025-03-02 15:05:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:06:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.17338615655899048 norm:0.0061852652579545975 max memory_allocated 29269.37548828125 
[2025-03-02 15:07:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.1484512984752655 norm:0.002607992384582758 max memory_allocated 29269.37548828125 
[2025-03-02 15:08:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.13506007194519043 norm:0.0011874386109411716 max memory_allocated 29269.37548828125 
[2025-03-02 15:08:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.13020358979701996 norm:0.0006785211153328419 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.1278894543647766 norm:0.0005020556272938848 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.12652641534805298 norm:0.0004184465215075761 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.1257767230272293 norm:0.0003936492430511862 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.12541304528713226 norm:0.0003819440898951143 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.12515461444854736 norm:0.00038647293695248663 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.12495788931846619 norm:0.0003625197277870029 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.12479795515537262 norm:0.0003508864319883287 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.12469367682933807 norm:0.00034403736935928464 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.1245911493897438 norm:0.00034186439006589353 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.1245448961853981 norm:0.0003468227223493159 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.1245134100317955 norm:0.00034748652251437306 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.12453684955835342 norm:0.0003458562714513391 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.12453822791576385 norm:0.0003406231408007443 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.12453046441078186 norm:0.00034045541542582214 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.12454117834568024 norm:0.000341278500854969 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.1245836615562439 norm:0.000348203640896827 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.20239956676959991 norm:0.010695567354559898 max memory_allocated 29269.56298828125 
[2025-03-02 15:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.1686026155948639 norm:0.00461471825838089 max memory_allocated 29269.56298828125 
[2025-03-02 15:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.14514338970184326 norm:0.0016415724530816078 max memory_allocated 29269.56298828125 
[2025-03-02 15:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.13836297392845154 norm:0.0008612943347543478 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.1355324387550354 norm:0.0006546066142618656 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.13400273025035858 norm:0.0005942674470134079 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.1331396847963333 norm:0.0005492850323207676 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.13249839842319489 norm:0.0005056325462646782 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.1321532428264618 norm:0.0004989691078662872 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.13195088505744934 norm:0.0004912057192996144 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.13181358575820923 norm:0.00046800466952845454 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:06 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.1316913515329361 norm:0.0004591818724293262 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.13153059780597687 norm:0.000440069823525846 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.1314244568347931 norm:0.0004245261661708355 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.13146379590034485 norm:0.00042355203186161816 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:22 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.13142581284046173 norm:0.0004253024817444384 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.13125424087047577 norm:0.00040542747592553496 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.1311064064502716 norm:0.00037555594462901354 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.13101693987846375 norm:0.00037524205981753767 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.13102559745311737 norm:0.0003762700653169304 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.1749514639377594 norm:0.004090756643563509 max memory_allocated 29269.75048828125 
[2025-03-02 15:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.1568676233291626 norm:0.0016690490301698446 max memory_allocated 29269.75048828125 
[2025-03-02 15:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.1463741809129715 norm:0.0008164204191416502 max memory_allocated 29269.75048828125 
[2025-03-02 15:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.14258411526679993 norm:0.0005359509377740324 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.14068248867988586 norm:0.00041338297887705266 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.1397123485803604 norm:0.00036214670399203897 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.13919717073440552 norm:0.0003409324854146689 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.13887248933315277 norm:0.00032225309405475855 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.13871526718139648 norm:0.0003130931581836194 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.13863608241081238 norm:0.0003109081299044192 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.1384943276643753 norm:0.00030030618654564023 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.13848450779914856 norm:0.0002968517947010696 max memory_allocated 29269.75048828125 
[2025-03-02 15:49:33 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.1384819895029068 norm:0.0002948804176412523 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.1384495347738266 norm:0.0002945926389656961 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.13845349848270416 norm:0.00029468623688444495 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.13845252990722656 norm:0.00029557099333032966 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.13846208155155182 norm:0.0002957490796688944 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.13848242163658142 norm:0.0002978895790874958 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.1384897083044052 norm:0.00029577311943285167 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.1384824514389038 norm:0.00029529223684221506 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:56:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.20727601647377014 norm:0.007196982856839895 max memory_allocated 29269.93798828125 
[2025-03-02 15:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.18352103233337402 norm:0.004117710515856743 max memory_allocated 29269.93798828125 
[2025-03-02 15:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.16056127846240997 norm:0.0015194113366305828 max memory_allocated 29269.93798828125 
[2025-03-02 15:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.1529708057641983 norm:0.0007250092457979918 max memory_allocated 29269.93798828125 
[2025-03-02 15:59:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.15046755969524384 norm:0.0005769405979663134 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.14910845458507538 norm:0.000524441129527986 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.14839330315589905 norm:0.0004730954533442855 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.14796635508537292 norm:0.00044542382238432765 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.14768698811531067 norm:0.00042588889482431114 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.14754603803157806 norm:0.0004177456139586866 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.14749616384506226 norm:0.00042184285121038556 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.14741146564483643 norm:0.0004089060821570456 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.14721769094467163 norm:0.0003903217730112374 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.14727583527565002 norm:0.0003969298559240997 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.14724551141262054 norm:0.00039603703771717846 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.14713943004608154 norm:0.0003769156173802912 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.14709161221981049 norm:0.0003572753048501909 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.14725114405155182 norm:0.00036935671232640743 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.1472790539264679 norm:0.0003670729056466371 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.14731839299201965 norm:0.00036700157215818763 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:13:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.20834282040596008 norm:0.006386928725987673 max memory_allocated 29270.12548828125 
[2025-03-02 16:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.18668821454048157 norm:0.0037016707938164473 max memory_allocated 29270.12548828125 
[2025-03-02 16:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.1674928218126297 norm:0.0014519237447530031 max memory_allocated 29270.12548828125 
[2025-03-02 16:15:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.16018837690353394 norm:0.000716757436748594 max memory_allocated 29270.12548828125 
[2025-03-02 16:16:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.1573403775691986 norm:0.000551144010387361 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.15591171383857727 norm:0.0004889186238870025 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.15514816343784332 norm:0.00046589371049776673 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.15475913882255554 norm:0.0004409178509376943 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.15448153018951416 norm:0.0004281486617401242 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.15435850620269775 norm:0.00041856380994431674 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.1542566567659378 norm:0.00041188523755408823 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.15424709022045135 norm:0.00041446942486800253 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.15419769287109375 norm:0.0004090939764864743 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.15411387383937836 norm:0.0003919730079360306 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.1540502905845642 norm:0.0003874130779877305 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.1538902223110199 norm:0.00037516828160732985 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.15378525853157043 norm:0.0003730635216925293 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.15369215607643127 norm:0.0003679039073176682 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.15362274646759033 norm:0.0003577216120902449 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.15353256464004517 norm:0.00034464552300050855 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.1911385953426361 norm:0.0024250950664281845 max memory_allocated 29270.31298828125 
[2025-03-02 16:30:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.1776307374238968 norm:0.0012658159248530865 max memory_allocated 29270.31298828125 
[2025-03-02 16:31:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.16786281764507294 norm:0.0007292289519682527 max memory_allocated 29270.31298828125 
[2025-03-02 16:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.1641678810119629 norm:0.0005223255138844252 max memory_allocated 29270.31298828125 
[2025-03-02 16:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.1623387336730957 norm:0.00043028980144299567 max memory_allocated 29270.31298828125 
[2025-03-02 16:33:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.1611434519290924 norm:0.0003751017793547362 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.16044165194034576 norm:0.00034725500154308975 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.16005109250545502 norm:0.0003324422286823392 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.15983067452907562 norm:0.0003208225825801492 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.1597241908311844 norm:0.00031464683706872165 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.15967656672000885 norm:0.00031363428570330143 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.15962015092372894 norm:0.00030729256104677916 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.1595517247915268 norm:0.0003058153379242867 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.15943825244903564 norm:0.00030412900377996266 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.15940485894680023 norm:0.000302163913147524 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.15939517319202423 norm:0.00030213690479286015 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.15937526524066925 norm:0.00030329322908073664 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.15935346484184265 norm:0.00030330504523590207 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.1593325138092041 norm:0.00030255888123065233 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.15933723747730255 norm:0.000300600629998371 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:46:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.20036454498767853 norm:0.003401806578040123 max memory_allocated 29270.50048828125 
[2025-03-02 16:47:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.18440598249435425 norm:0.001590583473443985 max memory_allocated 29270.50048828125 
[2025-03-02 16:47:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.17430084943771362 norm:0.0009055726695805788 max memory_allocated 29270.50048828125 
[2025-03-02 16:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.17066839337348938 norm:0.0006123705534264445 max memory_allocated 29270.50048828125 
[2025-03-02 16:49:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.16872888803482056 norm:0.000473462714580819 max memory_allocated 29270.50048828125 
[2025-03-02 16:50:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.16756708920001984 norm:0.0003964520583394915 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.16692377626895905 norm:0.00035073840990662575 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.16658014059066772 norm:0.0003285401326138526 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.1663733720779419 norm:0.0003125826478935778 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:36 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.1662432998418808 norm:0.00030396762304008007 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.16616633534431458 norm:0.000298102357191965 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.16611601412296295 norm:0.000293122255243361 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.16601236164569855 norm:0.0002898781967815012 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.16595357656478882 norm:0.00028744342853315175 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.16594329476356506 norm:0.00028678704984486103 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.1659277230501175 norm:0.0002879635721910745 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.16589094698429108 norm:0.00028958855546079576 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.16584789752960205 norm:0.00028963846853002906 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.16574952006340027 norm:0.0002847748401109129 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.16572162508964539 norm:0.0002820843074005097 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:02:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.20915333926677704 norm:0.0048074983060359955 max memory_allocated 29270.68798828125 
[2025-03-02 17:03:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.1976803094148636 norm:0.0027931134682148695 max memory_allocated 29270.68798828125 
[2025-03-02 17:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.1871359944343567 norm:0.0014446990098804235 max memory_allocated 29270.68798828125 
[2025-03-02 17:05:19 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.18291768431663513 norm:0.0008766957325860858 max memory_allocated 29270.68798828125 
[2025-03-02 17:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.1807764172554016 norm:0.0006671645096503198 max memory_allocated 29270.68798828125 
[2025-03-02 17:06:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.17938272655010223 norm:0.0005441257380880415 max memory_allocated 29270.68798828125 
[2025-03-02 17:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.17855039238929749 norm:0.0004908610717393458 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.17809687554836273 norm:0.0004662038409151137 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.17786109447479248 norm:0.00045448244782164693 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.17780278623104095 norm:0.00045415075146593153 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.1777208000421524 norm:0.00043121783528476954 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.1777375489473343 norm:0.00042803274118341506 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.17757920920848846 norm:0.0004168124869465828 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.17760705947875977 norm:0.00041799547034315765 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.17771069705486298 norm:0.00040952570270746946 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.17775015532970428 norm:0.00041637461981736124 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.177812397480011 norm:0.0004169107705820352 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.17759540677070618 norm:0.0003820197598543018 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.17752814292907715 norm:0.00036660899058915675 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.17741401493549347 norm:0.00036374860792420805 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:19:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.21440836787223816 norm:0.0034050217363983393 max memory_allocated 29270.87548828125 
[2025-03-02 17:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.20301564037799835 norm:0.001604848774150014 max memory_allocated 29270.87548828125 
[2025-03-02 17:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.1949235498905182 norm:0.0009303726255893707 max memory_allocated 29270.87548828125 
[2025-03-02 17:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.19202809035778046 norm:0.0006731465109623969 max memory_allocated 29270.87548828125 
[2025-03-02 17:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.19033996760845184 norm:0.0005265632644295692 max memory_allocated 29270.87548828125 
[2025-03-02 17:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.18931081891059875 norm:0.0004395440046209842 max memory_allocated 29270.87548828125 
[2025-03-02 17:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.188836932182312 norm:0.00040640035877004266 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.18860185146331787 norm:0.0003759190731216222 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.18840864300727844 norm:0.0003524917992763221 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.18829293549060822 norm:0.0003391984209883958 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.18820852041244507 norm:0.0003280445234850049 max memory_allocated 29270.87548828125 
[2025-03-02 17:28:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.18824848532676697 norm:0.00033300439827144146 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.18825820088386536 norm:0.0003323287528473884 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.1882326304912567 norm:0.0003291413886472583 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.18819430470466614 norm:0.0003244987456128001 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.18821753561496735 norm:0.00031725113512948155 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.18810611963272095 norm:0.00030993513064458966 max memory_allocated 29270.87548828125 
[2025-03-02 17:33:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.18808244168758392 norm:0.00030880438862368464 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.1881689876317978 norm:0.0003126603551208973 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.1882392317056656 norm:0.0003209818387404084 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:36:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.23240607976913452 norm:0.004037198144942522 max memory_allocated 29271.06298828125 
[2025-03-02 17:36:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.21990764141082764 norm:0.0018310756422579288 max memory_allocated 29271.06298828125 
[2025-03-02 17:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.2104625701904297 norm:0.0010557936038821936 max memory_allocated 29271.06298828125 
[2025-03-02 17:38:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.20706366002559662 norm:0.0007334193796850741 max memory_allocated 29271.06298828125 
[2025-03-02 17:39:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.20542943477630615 norm:0.0005877232179045677 max memory_allocated 29271.06298828125 
[2025-03-02 17:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.2044801414012909 norm:0.0004985996638424695 max memory_allocated 29271.06298828125 
[2025-03-02 17:41:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.20385245978832245 norm:0.0004246910393703729 max memory_allocated 29271.06298828125 
[2025-03-02 17:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.2033824622631073 norm:0.00038586382288485765 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.203142911195755 norm:0.0003629373386502266 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:28 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.20302818715572357 norm:0.0003478372818790376 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.20297162234783173 norm:0.00033977165003307164 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.2029048055410385 norm:0.0003321908297948539 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.2028639018535614 norm:0.00032850014395080507 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.20281334221363068 norm:0.00032489997101947665 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.20276892185211182 norm:0.0003202447260264307 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.20269766449928284 norm:0.0003168510738760233 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.2026214450597763 norm:0.00031437730649486184 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.20255900919437408 norm:0.00030961973243393004 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.20254027843475342 norm:0.00030979939037933946 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.20252738893032074 norm:0.0003085124772042036 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.2534666955471039 norm:0.004065948538482189 max memory_allocated 29271.25048828125 
[2025-03-02 17:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.23965010046958923 norm:0.0017915236530825496 max memory_allocated 29271.25048828125 
[2025-03-02 17:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.22978854179382324 norm:0.0009759941603988409 max memory_allocated 29271.25048828125 
[2025-03-02 17:55:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.22642162442207336 norm:0.0006919237202964723 max memory_allocated 29271.25048828125 
[2025-03-02 17:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.22461852431297302 norm:0.0005600894219242036 max memory_allocated 29271.25048828125 
[2025-03-02 17:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.2236698716878891 norm:0.00048094987869262695 max memory_allocated 29271.25048828125 
[2025-03-02 17:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.22313104569911957 norm:0.00044497079215943813 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.22285494208335876 norm:0.00041892239823937416 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.2227228581905365 norm:0.00040586412069387734 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.22251984477043152 norm:0.000385794963221997 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.22237887978553772 norm:0.00036511378129944205 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.22238458693027496 norm:0.0003694462648127228 max memory_allocated 29271.25048828125 
[2025-03-02 18:02:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.22243855893611908 norm:0.0003715447965078056 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.2223910093307495 norm:0.00036607167567126453 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.22229664027690887 norm:0.0003583438228815794 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.2223028540611267 norm:0.000359599944204092 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.22224721312522888 norm:0.00035296916030347347 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.22221504151821136 norm:0.0003489904338493943 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.22223709523677826 norm:0.00034976901952177286 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.22227266430854797 norm:0.00035431989817880094 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.2736969590187073 norm:0.0027560931630432606 max memory_allocated 29271.43798828125 
[2025-03-02 18:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.2621360719203949 norm:0.0013366850325837731 max memory_allocated 29271.43798828125 
[2025-03-02 18:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.25313010811805725 norm:0.00084236531984061 max memory_allocated 29271.43798828125 
[2025-03-02 18:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.2494996190071106 norm:0.0005969724734313786 max memory_allocated 29271.43798828125 
[2025-03-02 18:12:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.2476833462715149 norm:0.00048759725177660584 max memory_allocated 29271.43798828125 
[2025-03-02 18:13:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.24691949784755707 norm:0.000444111879914999 max memory_allocated 29271.43798828125 
[2025-03-02 18:14:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.24657654762268066 norm:0.0004204131255391985 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.2464209496974945 norm:0.00040595614700578153 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.24616879224777222 norm:0.00039890233892947435 max memory_allocated 29271.43798828125 
[2025-03-02 18:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.24591577053070068 norm:0.0003773828793782741 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.24586427211761475 norm:0.0003760025720112026 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.24576246738433838 norm:0.0003704820410348475 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.24579861760139465 norm:0.00036768883001059294 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.24579846858978271 norm:0.00035854990710504353 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.24566835165023804 norm:0.00035463369567878544 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.245553657412529 norm:0.0003418565320316702 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.24550271034240723 norm:0.0003448684001341462 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.2455507218837738 norm:0.0003453718964010477 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.24563083052635193 norm:0.00035799798206426203 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.24569912254810333 norm:0.00035596280940808356 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:25:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.2955797612667084 norm:0.001948299934156239 max memory_allocated 29271.62548828125 
[2025-03-02 18:26:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.28332334756851196 norm:0.0009196666651405394 max memory_allocated 29271.62548828125 
[2025-03-02 18:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.274154394865036 norm:0.0005691707483492792 max memory_allocated 29271.62548828125 
[2025-03-02 18:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.2708772122859955 norm:0.00042860000394284725 max memory_allocated 29271.62548828125 
[2025-03-02 18:29:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.26911091804504395 norm:0.00035435540485195816 max memory_allocated 29271.62548828125 
[2025-03-02 18:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.26831379532814026 norm:0.0003129602409899235 max memory_allocated 29271.62548828125 
[2025-03-02 18:30:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.2679624557495117 norm:0.000291134201688692 max memory_allocated 29271.62548828125 
[2025-03-02 18:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.26768094301223755 norm:0.00028150889556854963 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.2674344778060913 norm:0.0002742950455285609 max memory_allocated 29271.62548828125 
[2025-03-02 18:33:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.26728737354278564 norm:0.0002675920841284096 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.26714131236076355 norm:0.00026388364494778216 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.2670228183269501 norm:0.00025825953343883157 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.2669346034526825 norm:0.00025629973970353603 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.2668604552745819 norm:0.0002565580070950091 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.2667926251888275 norm:0.0002555052633397281 max memory_allocated 29271.62548828125 
[2025-03-02 18:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.2667444944381714 norm:0.0002564488095231354 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.2667161226272583 norm:0.00025614904006943107 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.2666662633419037 norm:0.0002558099804446101 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.2666285037994385 norm:0.00025477504823356867 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.266593873500824 norm:0.00025499099865555763 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.33073076605796814 norm:0.002495269291102886 max memory_allocated 29271.81298828125 
[2025-03-02 18:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.3174562454223633 norm:0.0013092688750475645 max memory_allocated 29271.81298828125 
[2025-03-02 18:44:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.30710747838020325 norm:0.0008223578915931284 max memory_allocated 29271.81298828125 
[2025-03-02 18:45:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.3036160469055176 norm:0.0005992096266709268 max memory_allocated 29271.81298828125 
[2025-03-02 18:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.30172425508499146 norm:0.000483009876916185 max memory_allocated 29271.81298828125 
[2025-03-02 18:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.30096912384033203 norm:0.00042405413114465773 max memory_allocated 29271.81298828125 
[2025-03-02 18:47:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.30054396390914917 norm:0.0003821540158241987 max memory_allocated 29271.81298828125 
[2025-03-02 18:48:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.30024364590644836 norm:0.00036125784390605986 max memory_allocated 29271.81298828125 
[2025-03-02 18:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.30003467202186584 norm:0.00034253750345669687 max memory_allocated 29271.81298828125 
[2025-03-02 18:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.29985737800598145 norm:0.0003309615422040224 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.2996910512447357 norm:0.0003239524376112968 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.2995629906654358 norm:0.00032042787643149495 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.2994430959224701 norm:0.0003154797595925629 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.2993656098842621 norm:0.00031290421611629426 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.2992761433124542 norm:0.00031153965392149985 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.2992345094680786 norm:0.0003122507478110492 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.2991503179073334 norm:0.000306903850287199 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.29911234974861145 norm:0.0003074959968216717 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.29907962679862976 norm:0.0003072670951951295 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.29900893568992615 norm:0.00030640611657872796 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 18:59:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.37036076188087463 norm:0.002414669608697295 max memory_allocated 29272.00048828125 
[2025-03-02 19:00:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.35712775588035583 norm:0.0012553466949611902 max memory_allocated 29272.00048828125 
[2025-03-02 19:00:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.34629905223846436 norm:0.0008082882268354297 max memory_allocated 29272.00048828125 
[2025-03-02 19:01:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.34264907240867615 norm:0.0006149193504825234 max memory_allocated 29272.00048828125 
[2025-03-02 19:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.3406440317630768 norm:0.0005131945945322514 max memory_allocated 29272.00048828125 
[2025-03-02 19:03:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.33981630206108093 norm:0.00045432214392349124 max memory_allocated 29272.00048828125 
[2025-03-02 19:04:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.3394497036933899 norm:0.00042383166146464646 max memory_allocated 29272.00048828125 
[2025-03-02 19:04:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.3391605615615845 norm:0.00040554540464654565 max memory_allocated 29272.00048828125 
[2025-03-02 19:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.3389071524143219 norm:0.0003971537225879729 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.3387026786804199 norm:0.00038768138620071113 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.3385712206363678 norm:0.0003813209477812052 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.33844301104545593 norm:0.00037577206967398524 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.33828651905059814 norm:0.00037240193341858685 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.33820775151252747 norm:0.0003664063406176865 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.3381305932998657 norm:0.0003624800592660904 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.33799827098846436 norm:0.00035824283258989453 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.33793240785598755 norm:0.0003558627504389733 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.33790504932403564 norm:0.0003525410720612854 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.3378055691719055 norm:0.0003490902599878609 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.33772674202919006 norm:0.00034840701846405864 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:15:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.4149317443370819 norm:0.002681744983419776 max memory_allocated 29272.18798828125 
[2025-03-02 19:16:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.401484876871109 norm:0.0013458511093631387 max memory_allocated 29272.18798828125 
[2025-03-02 19:17:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.3905373811721802 norm:0.0008263666532002389 max memory_allocated 29272.18798828125 
[2025-03-02 19:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.38688594102859497 norm:0.0006109597161412239 max memory_allocated 29272.18798828125 
[2025-03-02 19:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.38497358560562134 norm:0.0005080074770376086 max memory_allocated 29272.18798828125 
[2025-03-02 19:19:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.384218692779541 norm:0.0004566154384519905 max memory_allocated 29272.18798828125 
[2025-03-02 19:20:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.38379254937171936 norm:0.00042446181760169566 max memory_allocated 29272.18798828125 
[2025-03-02 19:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.3834567666053772 norm:0.0004043632361572236 max memory_allocated 29272.18798828125 
[2025-03-02 19:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.38323238492012024 norm:0.0003927561629097909 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.3830072283744812 norm:0.00038520380621775985 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.3828658163547516 norm:0.00037844767211936414 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.3827110230922699 norm:0.00037557698669843376 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.3825760781764984 norm:0.00037268921732902527 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.38245493173599243 norm:0.0003692171012517065 max memory_allocated 29272.18798828125 
[2025-03-02 19:27:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.3823469281196594 norm:0.00036966014886274934 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.38225826621055603 norm:0.0003652376472018659 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.3821890950202942 norm:0.0003637117915786803 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.3821166753768921 norm:0.0003624485107138753 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.3820667862892151 norm:0.0003638788766693324 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.3819890022277832 norm:0.0003602057113312185 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.46226567029953003 norm:0.0033657324966043234 max memory_allocated 29272.37548828125 
[2025-03-02 19:33:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.4479445815086365 norm:0.0016843474004417658 max memory_allocated 29272.37548828125 
[2025-03-02 19:34:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.4362269937992096 norm:0.0010330078657716513 max memory_allocated 29272.37548828125 
[2025-03-02 19:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.4322001039981842 norm:0.0007392163970507681 max memory_allocated 29272.37548828125 
[2025-03-02 19:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.43024805188179016 norm:0.0005800500512123108 max memory_allocated 29272.37548828125 
[2025-03-02 19:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.42948585748672485 norm:0.00048564106691628695 max memory_allocated 29272.37548828125 
[2025-03-02 19:37:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.4290342926979065 norm:0.0004403449420351535 max memory_allocated 29272.37548828125 
[2025-03-02 19:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.4286934733390808 norm:0.0004077622143086046 max memory_allocated 29272.37548828125 
[2025-03-02 19:38:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.4284299910068512 norm:0.00038569499156437814 max memory_allocated 29272.37548828125 
[2025-03-02 19:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.42818501591682434 norm:0.00037005715421400964 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.42801031470298767 norm:0.00036500912392511964 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.4279043674468994 norm:0.00036023769644089043 max memory_allocated 29272.37548828125 
[2025-03-02 19:42:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.4277477264404297 norm:0.0003570937260519713 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.4276295602321625 norm:0.0003549106768332422 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.4275127947330475 norm:0.00035300530726090074 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.42740488052368164 norm:0.00034915891592390835 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.42729705572128296 norm:0.00034498650347813964 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.42720651626586914 norm:0.0003411720972508192 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.42713791131973267 norm:0.0003369355690665543 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.42705780267715454 norm:0.0003342790005262941 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.5131720304489136 norm:0.0025016418658196926 max memory_allocated 29272.56298828125 
[2025-03-02 19:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.4987442195415497 norm:0.0013977143680676818 max memory_allocated 29272.56298828125 
[2025-03-02 19:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.48608162999153137 norm:0.0009681527735665441 max memory_allocated 29272.56298828125 
[2025-03-02 19:51:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.48178452253341675 norm:0.0007431026315316558 max memory_allocated 29272.56298828125 
[2025-03-02 19:52:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.4797801971435547 norm:0.0006189120467752218 max memory_allocated 29272.56298828125 
[2025-03-02 19:53:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.4792024493217468 norm:0.0006067032809369266 max memory_allocated 29272.56298828125 
[2025-03-02 19:53:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.47884857654571533 norm:0.0005826172418892384 max memory_allocated 29272.56298828125 
[2025-03-02 19:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.47842201590538025 norm:0.0005237971199676394 max memory_allocated 29272.56298828125 
[2025-03-02 19:55:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.47804540395736694 norm:0.00048697798047214746 max memory_allocated 29272.56298828125 
[2025-03-02 19:56:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.4778793454170227 norm:0.00048326340038329363 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.4778355062007904 norm:0.0004832430277019739 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.47778230905532837 norm:0.0004884320660494268 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.4775766432285309 norm:0.00046889367513358593 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.4773443341255188 norm:0.0004467502294573933 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.47705361247062683 norm:0.00042594075785018504 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.4770403802394867 norm:0.0004429803229868412 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.4769195020198822 norm:0.00043094504508189857 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.4769035875797272 norm:0.0004280445573385805 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.4768355190753937 norm:0.0004262202710378915 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.47675490379333496 norm:0.0004235647793393582 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.5636289715766907 norm:0.0029305722564458847 max memory_allocated 29272.75048828125 
[2025-03-02 20:06:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.5489356517791748 norm:0.0013650987530127168 max memory_allocated 29272.75048828125 
[2025-03-02 20:07:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.5360190868377686 norm:0.0009156069136224687 max memory_allocated 29272.75048828125 
[2025-03-02 20:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.5316734313964844 norm:0.000713802408427 max memory_allocated 29272.75048828125 
[2025-03-02 20:08:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.5295759439468384 norm:0.000590011477470398 max memory_allocated 29272.75048828125 
[2025-03-02 20:09:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.5287600755691528 norm:0.0005254029529169202 max memory_allocated 29272.75048828125 
[2025-03-02 20:10:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.5285772085189819 norm:0.0005246088840067387 max memory_allocated 29272.75048828125 
[2025-03-02 20:11:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.5283777117729187 norm:0.0005073981010355055 max memory_allocated 29272.75048828125 
[2025-03-02 20:12:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.5282531976699829 norm:0.0005000247620046139 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.5281683802604675 norm:0.0004872491117566824 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:53 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.5279661417007446 norm:0.00046231012674979866 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.5278393626213074 norm:0.0004476086760405451 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.5277045965194702 norm:0.00043579531484283507 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.5275141596794128 norm:0.00041885790415108204 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.5273337960243225 norm:0.0004012296558357775 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.5270724892616272 norm:0.000385475781513378 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.5269593596458435 norm:0.00038573762867599726 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.5269156694412231 norm:0.0003840657591354102 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:25 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.5269210338592529 norm:0.0003797917743213475 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.5268195271492004 norm:0.0003747460141312331 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.626331627368927 norm:0.0021256250329315662 max memory_allocated 29272.93798828125 
[2025-03-02 20:23:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.6103368997573853 norm:0.0011179334251210093 max memory_allocated 29272.93798828125 
[2025-03-02 20:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.5952198505401611 norm:0.0007517951307818294 max memory_allocated 29272.93798828125 
[2025-03-02 20:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.5905865430831909 norm:0.0005838557844981551 max memory_allocated 29272.93798828125 
[2025-03-02 20:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.5885974168777466 norm:0.0005108685581944883 max memory_allocated 29272.93798828125 
[2025-03-02 20:26:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.5879486203193665 norm:0.0004887163522653282 max memory_allocated 29272.93798828125 
[2025-03-02 20:27:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.5874558091163635 norm:0.00044446581159718335 max memory_allocated 29272.93798828125 
[2025-03-02 20:28:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.5872148871421814 norm:0.00043307215673848987 max memory_allocated 29272.93798828125 
[2025-03-02 20:28:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.5869036912918091 norm:0.0004136329225730151 max memory_allocated 29272.93798828125 
[2025-03-02 20:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.5867607593536377 norm:0.0004057014302816242 max memory_allocated 29272.93798828125 
[2025-03-02 20:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.5865616798400879 norm:0.0003973755519837141 max memory_allocated 29272.93798828125 
[2025-03-02 20:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.5864286422729492 norm:0.0003972729900851846 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.5862926840782166 norm:0.0003941076865885407 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.5861504673957825 norm:0.0003931850951630622 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.5860685110092163 norm:0.0003890812222380191 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.5860194563865662 norm:0.0003868189232889563 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.585976243019104 norm:0.00038237127591855824 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.5858228206634521 norm:0.00037716483348049223 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.5857092142105103 norm:0.00037496769800782204 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.585620105266571 norm:0.0003732686454895884 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:38:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.6924599409103394 norm:0.003321576863527298 max memory_allocated 29273.12548828125 
[2025-03-02 20:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.6752031445503235 norm:0.001783290645107627 max memory_allocated 29273.12548828125 
[2025-03-02 20:40:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.66024249792099 norm:0.0014615145046263933 max memory_allocated 29273.12548828125 
[2025-03-02 20:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.6548799872398376 norm:0.0011091125197708607 max memory_allocated 29273.12548828125 
[2025-03-02 20:42:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.6529689431190491 norm:0.001018567942082882 max memory_allocated 29273.12548828125 
[2025-03-02 20:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.6521043181419373 norm:0.0009074867703020573 max memory_allocated 29273.12548828125 
[2025-03-02 20:43:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.651699423789978 norm:0.0008547609904780984 max memory_allocated 29273.12548828125 
[2025-03-02 20:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.6513093113899231 norm:0.0008776889881119132 max memory_allocated 29273.12548828125 
[2025-03-02 20:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.6505107879638672 norm:0.0008767262916080654 max memory_allocated 29273.12548828125 
[2025-03-02 20:46:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.6502882242202759 norm:0.0007679884438402951 max memory_allocated 29273.12548828125 
[2025-03-02 20:47:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.6505646705627441 norm:0.0007360014715231955 max memory_allocated 29273.12548828125 
[2025-03-02 20:47:58 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.6505619287490845 norm:0.000771426479332149 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.6506288647651672 norm:0.0008011030731722713 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.6503562331199646 norm:0.0007145754061639309 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.6497093439102173 norm:0.0007602736004628241 max memory_allocated 29273.12548828125 
[2025-03-02 20:51:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.6493440866470337 norm:0.0007374636479653418 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.649691104888916 norm:0.0007314960821531713 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.6495983004570007 norm:0.000652642163913697 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.6494815945625305 norm:0.000666024861857295 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.6491045355796814 norm:0.0006509605445899069 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 20:55:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.751382052898407 norm:0.0038588973693549633 max memory_allocated 29273.31298828125 
[2025-03-02 20:56:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.7341909408569336 norm:0.0019279905827715993 max memory_allocated 29273.31298828125 
[2025-03-02 20:57:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.7182630896568298 norm:0.0011487305164337158 max memory_allocated 29273.31298828125 
[2025-03-02 20:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.7133288383483887 norm:0.0007908911793492734 max memory_allocated 29273.31298828125 
[2025-03-02 20:58:53 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.7114787101745605 norm:0.0006096138968132436 max memory_allocated 29273.31298828125 
[2025-03-02 20:59:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.7107371687889099 norm:0.0005118447006680071 max memory_allocated 29273.31298828125 
[2025-03-02 21:00:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.7103210687637329 norm:0.0004513069288805127 max memory_allocated 29273.31298828125 
[2025-03-02 21:01:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.7100090980529785 norm:0.0004128940054215491 max memory_allocated 29273.31298828125 
[2025-03-02 21:02:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.7097101211547852 norm:0.00038903573295101523 max memory_allocated 29273.31298828125 
[2025-03-02 21:02:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.7094752788543701 norm:0.000372451264411211 max memory_allocated 29273.31298828125 
[2025-03-02 21:03:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.7092860341072083 norm:0.0003605484962463379 max memory_allocated 29273.31298828125 
[2025-03-02 21:04:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.709101676940918 norm:0.0003539184108376503 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.7089317440986633 norm:0.0003497868019621819 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.70878666639328 norm:0.0003472222888376564 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.7086547613143921 norm:0.00034497579326853156 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.7085356116294861 norm:0.00034111528657376766 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.7084059715270996 norm:0.0003377826069481671 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.7083160877227783 norm:0.00033940107095986605 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.7082133889198303 norm:0.00033831712789833546 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.7081245183944702 norm:0.00033496812102384865 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:12:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.8212506771087646 norm:0.00362706882879138 max memory_allocated 29273.50048828125 
[2025-03-02 21:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.8027433753013611 norm:0.0017984678270295262 max memory_allocated 29273.50048828125 
[2025-03-02 21:13:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.7856970429420471 norm:0.0011072091292589903 max memory_allocated 29273.50048828125 
[2025-03-02 21:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.7802872657775879 norm:0.0008025260176509619 max memory_allocated 29273.50048828125 
[2025-03-02 21:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.7781635522842407 norm:0.0006469264626502991 max memory_allocated 29273.50048828125 
[2025-03-02 21:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.7772946357727051 norm:0.0005619547446258366 max memory_allocated 29273.50048828125 
[2025-03-02 21:17:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.7767179012298584 norm:0.000517622975166887 max memory_allocated 29273.50048828125 
[2025-03-02 21:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.7762944102287292 norm:0.0004874125588685274 max memory_allocated 29273.50048828125 
[2025-03-02 21:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.7759754657745361 norm:0.00046700602979399264 max memory_allocated 29273.50048828125 
[2025-03-02 21:19:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.7757149934768677 norm:0.000452605338068679 max memory_allocated 29273.50048828125 
[2025-03-02 21:20:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.7754189372062683 norm:0.00044677694677375257 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.7752104997634888 norm:0.0004418180324137211 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.7750070095062256 norm:0.00043014000402763486 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.7748550772666931 norm:0.00043057085713371634 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:42 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.7747002243995667 norm:0.0004254719824530184 max memory_allocated 29273.50048828125 
[2025-03-02 21:24:31 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.7746357917785645 norm:0.00042290633427910507 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.7744455337524414 norm:0.00044460431672632694 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.7742428183555603 norm:0.00042484671575948596 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.7741706967353821 norm:0.0004239367845002562 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.7741299271583557 norm:0.0004213119391351938 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:28:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.8932013511657715 norm:0.004231683909893036 max memory_allocated 29273.68798828125 
[2025-03-02 21:29:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.8732908964157104 norm:0.0019972980953752995 max memory_allocated 29273.68798828125 
[2025-03-02 21:30:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.855543315410614 norm:0.0012290008598938584 max memory_allocated 29273.68798828125 
[2025-03-02 21:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.8497304916381836 norm:0.0008891148027032614 max memory_allocated 29273.68798828125 
[2025-03-02 21:32:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.847661018371582 norm:0.0006964156054891646 max memory_allocated 29273.68798828125 
[2025-03-02 21:33:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.8466458916664124 norm:0.0005956010427325964 max memory_allocated 29273.68798828125 
[2025-03-02 21:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.8460519313812256 norm:0.000544331967830658 max memory_allocated 29273.68798828125 
[2025-03-02 21:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.8456906676292419 norm:0.0005120301502756774 max memory_allocated 29273.68798828125 
[2025-03-02 21:35:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.8453572988510132 norm:0.0004885958624072373 max memory_allocated 29273.68798828125 
[2025-03-02 21:36:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.8451601266860962 norm:0.0004756663111038506 max memory_allocated 29273.68798828125 
[2025-03-02 21:37:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.8448928594589233 norm:0.0004539082874543965 max memory_allocated 29273.68798828125 
[2025-03-02 21:37:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.8446717262268066 norm:0.00045109845814295113 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.8444541096687317 norm:0.0004500259237829596 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.8443044424057007 norm:0.0004465133242774755 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.8441460132598877 norm:0.0004448456456884742 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.8440455794334412 norm:0.0004435637383721769 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.8438712358474731 norm:0.0004361392930150032 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.8437204957008362 norm:0.0004372556577436626 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.8436938524246216 norm:0.0004434493603184819 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.8436094522476196 norm:0.00043730661855079234 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:45:34 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.9645395874977112 norm:0.005126108415424824 max memory_allocated 29273.87548828125 
[2025-03-02 21:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.944934070110321 norm:0.002490776591002941 max memory_allocated 29273.87548828125 
[2025-03-02 21:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.926931619644165 norm:0.0014586691977456212 max memory_allocated 29273.87548828125 
[2025-03-02 21:48:01 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.9211110472679138 norm:0.000990180647931993 max memory_allocated 29273.87548828125 
[2025-03-02 21:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.9191550016403198 norm:0.0007484256639145315 max memory_allocated 29273.87548828125 
[2025-03-02 21:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.9183428883552551 norm:0.0006277349311858416 max memory_allocated 29273.87548828125 
[2025-03-02 21:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.9178192615509033 norm:0.00054494000505656 max memory_allocated 29273.87548828125 
[2025-03-02 21:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.917391836643219 norm:0.0004924077657051384 max memory_allocated 29273.87548828125 
[2025-03-02 21:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.9170421361923218 norm:0.0004534499894361943 max memory_allocated 29273.87548828125 
[2025-03-02 21:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.9167436957359314 norm:0.0004291687801014632 max memory_allocated 29273.87548828125 
[2025-03-02 21:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.9164894223213196 norm:0.00041271757800132036 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.9162359833717346 norm:0.0004021526547148824 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.9160327315330505 norm:0.00039192073745653033 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.9158509373664856 norm:0.0003861473232973367 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:00 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.9156791567802429 norm:0.0003813343064393848 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:49 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.9155635833740234 norm:0.00037691928446292877 max memory_allocated 29273.87548828125 
[2025-03-02 21:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.9154302477836609 norm:0.0003747937735170126 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:27 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.9153255224227905 norm:0.0003732049954123795 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:16 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.9152151942253113 norm:0.0003743249108083546 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:05 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.9151215553283691 norm:0.0003715042257681489 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:1.0488109588623047 norm:0.002823798218742013 max memory_allocated 29274.06298828125 
[2025-03-02 22:03:01 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:1.027906060218811 norm:0.0015049227513372898 max memory_allocated 29274.06298828125 
[2025-03-02 22:03:50 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:1.0086753368377686 norm:0.000977679854258895 max memory_allocated 29274.06298828125 
[2025-03-02 22:04:39 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:1.0026551485061646 norm:0.00072831055149436 max memory_allocated 29274.06298828125 
[2025-03-02 22:05:28 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:1.000746488571167 norm:0.0006259282818064094 max memory_allocated 29274.06298828125 
[2025-03-02 22:06:17 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.9997657537460327 norm:0.0005678398301824927 max memory_allocated 29274.06298828125 
[2025-03-02 22:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.9990733861923218 norm:0.0005296344752423465 max memory_allocated 29274.06298828125 
[2025-03-02 22:07:55 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.9985966086387634 norm:0.0005075345980003476 max memory_allocated 29274.06298828125 
[2025-03-02 22:08:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.9982360005378723 norm:0.0004961189115419984 max memory_allocated 29274.06298828125 
[2025-03-02 22:09:33 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.9979109764099121 norm:0.0004929019487462938 max memory_allocated 29274.06298828125 
[2025-03-02 22:10:22 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.9976349472999573 norm:0.0004825211362913251 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:11 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.9974961280822754 norm:0.0004913695738650858 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:00 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.9973854422569275 norm:0.0005005121929571033 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:49 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.9972168207168579 norm:0.0005076242960058153 max memory_allocated 29274.06298828125 
[2025-03-02 22:13:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.9971860647201538 norm:0.000511716993059963 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:27 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.9970307350158691 norm:0.00050656299572438 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.9968308210372925 norm:0.0005108342738822103 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.9967352151870728 norm:0.0005314740119501948 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.9965642094612122 norm:0.0005033077322877944 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.9964501261711121 norm:0.0004985931445844471 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:1.153883934020996 norm:0.003989128861576319 max memory_allocated 29274.25048828125 
[2025-03-02 22:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:1.1296488046646118 norm:0.002159022493287921 max memory_allocated 29274.25048828125 
[2025-03-02 22:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:1.107296347618103 norm:0.0013949726708233356 max memory_allocated 29274.25048828125 
[2025-03-02 22:21:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:1.1006567478179932 norm:0.0011060277465730906 max memory_allocated 29274.25048828125 
[2025-03-02 22:22:06 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:1.098569393157959 norm:0.0009506550268270075 max memory_allocated 29274.25048828125 
[2025-03-02 22:22:55 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:1.0975985527038574 norm:0.0008604194154031575 max memory_allocated 29274.25048828125 
[2025-03-02 22:23:44 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:1.096872091293335 norm:0.0007981046801432967 max memory_allocated 29274.25048828125 
[2025-03-02 22:24:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:1.0964787006378174 norm:0.0007642507553100586 max memory_allocated 29274.25048828125 
[2025-03-02 22:25:22 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:1.0961623191833496 norm:0.0007465315866284072 max memory_allocated 29274.25048828125 
[2025-03-02 22:26:11 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:1.0958619117736816 norm:0.0007267569890245795 max memory_allocated 29274.25048828125 
[2025-03-02 22:27:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:1.0957026481628418 norm:0.0007087181438691914 max memory_allocated 29274.25048828125 
[2025-03-02 22:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:1.0953606367111206 norm:0.0006933337426744401 max memory_allocated 29274.25048828125 
[2025-03-02 22:28:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:1.095245599746704 norm:0.0006941361352801323 max memory_allocated 29274.25048828125 
[2025-03-02 22:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:1.0950978994369507 norm:0.000674667302519083 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:16 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:1.094908356666565 norm:0.0006608401890844107 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:1.0947153568267822 norm:0.000651875336188823 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:1.0945191383361816 norm:0.0006431927322410047 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:1.0943315029144287 norm:0.0006332977209240198 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:32 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:1.0941108465194702 norm:0.0006200665957294405 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:21 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:1.093902587890625 norm:0.0006070854724384844 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:1.26410973072052 norm:0.0069548082537949085 max memory_allocated 29274.43798828125 
[2025-03-02 22:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:1.236112117767334 norm:0.0036426910664886236 max memory_allocated 29274.43798828125 
[2025-03-02 22:37:06 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:1.2108968496322632 norm:0.0022030354011803865 max memory_allocated 29274.43798828125 
[2025-03-02 22:37:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:1.2028361558914185 norm:0.0015503349713981152 max memory_allocated 29274.43798828125 
[2025-03-02 22:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:1.200445294380188 norm:0.0012190815759822726 max memory_allocated 29274.43798828125 
[2025-03-02 22:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:1.1992838382720947 norm:0.0010454553412273526 max memory_allocated 29274.43798828125 
[2025-03-02 22:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:1.198455572128296 norm:0.0009387954487465322 max memory_allocated 29274.43798828125 
[2025-03-02 22:41:11 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:1.1979079246520996 norm:0.0008835724438540637 max memory_allocated 29274.43798828125 
[2025-03-02 22:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:1.1975550651550293 norm:0.0008580537396483123 max memory_allocated 29274.43798828125 
[2025-03-02 22:42:49 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:1.1971904039382935 norm:0.0008201850578188896 max memory_allocated 29274.43798828125 
[2025-03-02 22:43:38 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:1.1967915296554565 norm:0.0007967522833496332 max memory_allocated 29274.43798828125 
[2025-03-02 22:44:27 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:1.196067452430725 norm:0.0007461031782440841 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:16 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:1.195752739906311 norm:0.0007323366589844227 max memory_allocated 29274.43798828125 
[2025-03-02 22:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:1.1956442594528198 norm:0.0007446472882293165 max memory_allocated 29274.43798828125 
[2025-03-02 22:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:1.195245623588562 norm:0.000755720364395529 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:1.1948695182800293 norm:0.0007331609376706183 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:32 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:1.1947433948516846 norm:0.0007366728386841714 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:21 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:1.1945666074752808 norm:0.0007230486953631043 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:10 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:1.1942987442016602 norm:0.0007281452999450266 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:59 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:1.1942356824874878 norm:0.000732779037207365 max memory_allocated 29274.43798828125 
[2025-03-02 22:51:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 22:51:17 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 22:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:1.3823517560958862 norm:0.020255057141184807 max memory_allocated 29274.77001953125 
[2025-03-02 22:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:1.3506672382354736 norm:0.016732698306441307 max memory_allocated 29274.77001953125 
[2025-03-02 22:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:1.3225319385528564 norm:0.012865766882896423 max memory_allocated 29274.77001953125 
[2025-03-02 22:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:1.3137503862380981 norm:0.011081190779805183 max memory_allocated 29274.77001953125 
[2025-03-02 22:55:23 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:1.3105672597885132 norm:0.009599443525075912 max memory_allocated 29274.77001953125 
[2025-03-02 22:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:1.3088905811309814 norm:0.008613582700490952 max memory_allocated 29274.77001953125 
[2025-03-02 22:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:1.3076285123825073 norm:0.007888339459896088 max memory_allocated 29274.77001953125 
[2025-03-02 22:57:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:1.3069332838058472 norm:0.007410387508571148 max memory_allocated 29274.77001953125 
[2025-03-02 22:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:1.3061821460723877 norm:0.0071532512083649635 max memory_allocated 29274.77001953125 
[2025-03-02 22:59:29 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:1.3056589365005493 norm:0.0067123291082680225 max memory_allocated 29274.77001953125 
[2025-03-02 23:00:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:1.3051178455352783 norm:0.006412663962692022 max memory_allocated 29274.77001953125 
[2025-03-02 23:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:1.3046746253967285 norm:0.006104636937379837 max memory_allocated 29274.77001953125 
[2025-03-02 23:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:1.3043123483657837 norm:0.0058814347721636295 max memory_allocated 29274.77001953125 
[2025-03-02 23:02:46 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:1.3039443492889404 norm:0.005718003958463669 max memory_allocated 29274.77001953125 
[2025-03-02 23:03:35 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:1.3034640550613403 norm:0.005491537041962147 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:24 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:1.3032290935516357 norm:0.00535788806155324 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:1.3030494451522827 norm:0.005223345942795277 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:1.3028712272644043 norm:0.005103603936731815 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:1.3026304244995117 norm:0.005108283367007971 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:41 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:1.302463412284851 norm:0.005021026358008385 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:07:59 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:1.5623289346694946 norm:0.026294339448213577 max memory_allocated 29274.95751953125 
[2025-03-02 23:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:1.5169332027435303 norm:0.017046207562088966 max memory_allocated 29274.95751953125 
[2025-03-02 23:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:1.4762074947357178 norm:0.014490463770925999 max memory_allocated 29274.95751953125 
[2025-03-02 23:11:16 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:1.4647600650787354 norm:0.01349762361496687 max memory_allocated 29274.95751953125 
[2025-03-02 23:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:1.46059250831604 norm:0.013152457773685455 max memory_allocated 29274.95751953125 
[2025-03-02 23:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:1.4585214853286743 norm:0.012121528387069702 max memory_allocated 29274.95751953125 
[2025-03-02 23:13:43 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:1.457329273223877 norm:0.011278443969786167 max memory_allocated 29274.95751953125 
[2025-03-02 23:14:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:1.4562437534332275 norm:0.010098733007907867 max memory_allocated 29274.95751953125 
[2025-03-02 23:15:21 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:1.4553515911102295 norm:0.009401020593941212 max memory_allocated 29274.95751953125 
[2025-03-02 23:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:1.4548308849334717 norm:0.008715704083442688 max memory_allocated 29274.95751953125 
[2025-03-02 23:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:1.4544591903686523 norm:0.00859967153519392 max memory_allocated 29274.95751953125 
[2025-03-02 23:17:49 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:1.4535043239593506 norm:0.008150116540491581 max memory_allocated 29274.95751953125 
[2025-03-02 23:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:1.4531989097595215 norm:0.007829020731151104 max memory_allocated 29274.95751953125 
[2025-03-02 23:19:27 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:1.4533226490020752 norm:0.007744905073195696 max memory_allocated 29274.95751953125 
[2025-03-02 23:20:17 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:1.4534380435943604 norm:0.008191716857254505 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:1.4523110389709473 norm:0.007613652385771275 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:1.4520074129104614 norm:0.007607735227793455 max memory_allocated 29274.95751953125 
[2025-03-02 23:22:44 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:1.4519906044006348 norm:0.007596815936267376 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:1.4524747133255005 norm:0.008044879883527756 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:1.4521398544311523 norm:0.0076835001818835735 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:24:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:25:30 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:1.9855329990386963 norm:0.06889628618955612 max memory_allocated 29275.14501953125 
[2025-03-02 23:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:1.8857169151306152 norm:0.047796256840229034 max memory_allocated 29275.14501953125 
[2025-03-02 23:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:1.817954182624817 norm:0.03458070755004883 max memory_allocated 29275.14501953125 
[2025-03-02 23:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:1.7906160354614258 norm:0.0292449202388525 max memory_allocated 29275.14501953125 
[2025-03-02 23:28:47 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:1.7764605283737183 norm:0.02550678700208664 max memory_allocated 29275.14501953125 
[2025-03-02 23:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:1.7673003673553467 norm:0.024112194776535034 max memory_allocated 29275.14501953125 
[2025-03-02 23:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:1.7617946863174438 norm:0.022677505388855934 max memory_allocated 29275.14501953125 
[2025-03-02 23:31:14 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:1.7573750019073486 norm:0.021508732810616493 max memory_allocated 29275.14501953125 
[2025-03-02 23:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:1.7538225650787354 norm:0.02020859532058239 max memory_allocated 29275.14501953125 
[2025-03-02 23:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:1.7511881589889526 norm:0.01894685998558998 max memory_allocated 29275.14501953125 
[2025-03-02 23:33:42 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:1.7493908405303955 norm:0.018512949347496033 max memory_allocated 29275.14501953125 
[2025-03-02 23:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:1.7486618757247925 norm:0.018303781747817993 max memory_allocated 29275.14501953125 
[2025-03-02 23:35:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:1.7477988004684448 norm:0.018396493047475815 max memory_allocated 29275.14501953125 
[2025-03-02 23:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:1.746773600578308 norm:0.017285959795117378 max memory_allocated 29275.14501953125 
[2025-03-02 23:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:1.7451640367507935 norm:0.016461621969938278 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:48 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:1.7440857887268066 norm:0.016346409916877747 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:1.743934154510498 norm:0.01612526923418045 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:27 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:1.743375539779663 norm:0.0159885473549366 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:16 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:1.7423231601715088 norm:0.015534836798906326 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:1.7417120933532715 norm:0.015248830430209637 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:41:23 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:3.1600732803344727 norm:0.12961876392364502 max memory_allocated 29275.33251953125 
[2025-03-02 23:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:3.007681369781494 norm:0.08875183761119843 max memory_allocated 29275.33251953125 
[2025-03-02 23:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:2.8956587314605713 norm:0.058221884071826935 max memory_allocated 29275.33251953125 
[2025-03-02 23:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:2.8508217334747314 norm:0.06231362372636795 max memory_allocated 29275.33251953125 
[2025-03-02 23:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:2.825122833251953 norm:0.057707205414772034 max memory_allocated 29275.33251953125 
[2025-03-02 23:46:18 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:2.8089373111724854 norm:0.055438075214624405 max memory_allocated 29275.33251953125 
[2025-03-02 23:47:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:2.798408031463623 norm:0.05300549790263176 max memory_allocated 29275.33251953125 
[2025-03-02 23:47:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:2.7911829948425293 norm:0.054138753563165665 max memory_allocated 29275.33251953125 
[2025-03-02 23:48:45 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:2.784334421157837 norm:0.05221887305378914 max memory_allocated 29275.33251953125 
[2025-03-02 23:49:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:2.779365062713623 norm:0.05162973329424858 max memory_allocated 29275.33251953125 
[2025-03-02 23:50:23 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:2.7781589031219482 norm:0.052867405116558075 max memory_allocated 29275.33251953125 
[2025-03-02 23:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:2.7787303924560547 norm:0.05371090769767761 max memory_allocated 29275.33251953125 
[2025-03-02 23:52:02 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:2.7743608951568604 norm:0.05472097173333168 max memory_allocated 29275.33251953125 
[2025-03-02 23:52:51 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:2.7702796459198 norm:0.0524410605430603 max memory_allocated 29275.33251953125 
[2025-03-02 23:53:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:2.7671854496002197 norm:0.052080102264881134 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:29 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:2.7636361122131348 norm:0.04982007294893265 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:2.759674549102783 norm:0.04717130959033966 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:08 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:2.759674549102783 norm:0.048421651124954224 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:2.7552919387817383 norm:0.04603184014558792 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:2.7562148571014404 norm:0.047422006726264954 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:00 root] (main_calib_config2.py 372): INFO 39929.991708517075
[2025-03-02 23:58:10 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:00:06 root] (main_calib_config2.py 159): INFO wikitext2 : 5.585859298706055
[2025-03-03 00:00:06 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:03:03 root] (main_calib_config2.py 159): INFO c4 : 7.282980442047119
[2025-03-03 02:01:59 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.585859298706055, 'c4': 7.282980442047119, 'results': {'arc_challenge': {'acc': 0.39078498293515357, 'acc_stderr': 0.014258563880513778, 'acc_norm': 0.40102389078498296, 'acc_norm_stderr': 0.014322255790719867}, 'arc_easy': {'acc': 0.6973905723905723, 'acc_stderr': 0.009426434542371222, 'acc_norm': 0.5576599326599326, 'acc_norm_stderr': 0.01019133444422085}, 'piqa': {'acc': 0.779107725788901, 'acc_stderr': 0.009679088048842216, 'acc_norm': 0.779107725788901, 'acc_norm_stderr': 0.00967908804884221}, 'winogrande': {'acc': 0.6606156274664562, 'acc_stderr': 0.01330771492894175}, 'boolq': {'acc': 0.6694189602446483, 'acc_stderr': 0.008227739156121636}, 'hellaswag': {'acc': 0.563433578968333, 'acc_stderr': 0.004949462563681333, 'acc_norm': 0.7351125273849831, 'acc_norm_stderr': 0.0044037143273799005}}, 'versions': {'arc_challenge': 0, 'arc_easy': 0, 'piqa': 0, 'winogrande': 0, 'boolq': 1, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
