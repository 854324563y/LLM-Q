[2025-03-02 12:48:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.45', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.45.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.45.pkl
[2025-03-02 12:52:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.024447519332170486 norm:0.0158870667219162 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.014155922457575798 norm:0.0073551698587834835 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.010202638804912567 norm:0.004777687601745129 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.008917007595300674 norm:0.003891754662618041 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.008262635208666325 norm:0.0030858367681503296 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.007921414449810982 norm:0.0025842436589300632 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.007703352253884077 norm:0.0031449361704289913 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0075849671848118305 norm:0.0020935696084052324 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.007495431695133448 norm:0.0019277733517810702 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.007396467961370945 norm:0.0017183213494718075 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.00731839332729578 norm:0.001554653630591929 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.007293009664863348 norm:0.0014723754720762372 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.007200098130851984 norm:0.0013623139820992947 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.007205679547041655 norm:0.0035459683276712894 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.007063373923301697 norm:0.0011573286028578877 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.007020591292530298 norm:0.0011529778130352497 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.006998669356107712 norm:0.0011304132640361786 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.006998253520578146 norm:0.001093343598768115 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.006969792302697897 norm:0.0011077283415943384 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.007066184654831886 norm:0.0012125916546210647 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:31 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.03483955189585686 norm:0.01764560490846634 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.020253121852874756 norm:0.00929858349263668 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.01488258596509695 norm:0.005970725789666176 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.013315971940755844 norm:0.004942521918565035 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.012735994532704353 norm:0.004367014393210411 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.012372876517474651 norm:0.003871757071465254 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.012090860866010189 norm:0.003578658914193511 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.01188668143004179 norm:0.0033068798948079348 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.011751984246075153 norm:0.003067981218919158 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.011586584150791168 norm:0.00275911926291883 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.011412996798753738 norm:0.0025428426451981068 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.011305755004286766 norm:0.0023575634695589542 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.011209756135940552 norm:0.0021672765724360943 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.011140859685838223 norm:0.0020071440376341343 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.011069894768297672 norm:0.0018300757510587573 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.011028958484530449 norm:0.0016676444793120027 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.011018052697181702 norm:0.001631374703720212 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.01109619252383709 norm:0.0016669242177158594 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.011138192377984524 norm:0.0015077056596055627 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.01098790392279625 norm:0.0014183956664055586 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:28 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:27:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.09166364371776581 norm:0.01592751033604145 max memory_allocated 29268.02001953125 
[2025-03-02 13:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.07761672139167786 norm:0.01183179672807455 max memory_allocated 29268.02001953125 
[2025-03-02 13:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.06920239329338074 norm:0.009058618918061256 max memory_allocated 29268.02001953125 
[2025-03-02 13:29:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.06589006632566452 norm:0.007484987378120422 max memory_allocated 29268.02001953125 
[2025-03-02 13:30:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.06448685377836227 norm:0.006918960716575384 max memory_allocated 29268.02001953125 
[2025-03-02 13:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.06312543153762817 norm:0.006886499933898449 max memory_allocated 29268.02001953125 
[2025-03-02 13:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.06200537458062172 norm:0.007082866504788399 max memory_allocated 29268.02001953125 
[2025-03-02 13:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.06130245700478554 norm:0.00675217853859067 max memory_allocated 29268.02001953125 
[2025-03-02 13:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.06072493642568588 norm:0.006493452005088329 max memory_allocated 29268.02001953125 
[2025-03-02 13:34:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.06009270250797272 norm:0.0063000814989209175 max memory_allocated 29268.02001953125 
[2025-03-02 13:35:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.059927649796009064 norm:0.006275658495724201 max memory_allocated 29268.02001953125 
[2025-03-02 13:36:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.05976840853691101 norm:0.006210540421307087 max memory_allocated 29268.02001953125 
[2025-03-02 13:37:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.059469521045684814 norm:0.006205942016094923 max memory_allocated 29268.02001953125 
[2025-03-02 13:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.059131380170583725 norm:0.006193001754581928 max memory_allocated 29268.02001953125 
[2025-03-02 13:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.059025298804044724 norm:0.006042602472007275 max memory_allocated 29268.02001953125 
[2025-03-02 13:39:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.05917283520102501 norm:0.00600027060136199 max memory_allocated 29268.02001953125 
[2025-03-02 13:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.05861259251832962 norm:0.0058465152978897095 max memory_allocated 29268.02001953125 
[2025-03-02 13:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.05865941196680069 norm:0.006010027602314949 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.05863397568464279 norm:0.006214476656168699 max memory_allocated 29268.02001953125 
[2025-03-02 13:43:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.058899886906147 norm:0.006457051727920771 max memory_allocated 29268.02001953125 
[2025-03-02 13:43:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:44:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.0649128332734108 norm:0.005324835889041424 max memory_allocated 29268.02001953125 
[2025-03-02 13:45:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.05162283778190613 norm:0.001896406291052699 max memory_allocated 29268.02001953125 
[2025-03-02 13:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.04585647955536842 norm:0.0009809215553104877 max memory_allocated 29268.02001953125 
[2025-03-02 13:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.04384639859199524 norm:0.0005890465108677745 max memory_allocated 29268.02001953125 
[2025-03-02 13:47:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.04278523102402687 norm:0.000454259425168857 max memory_allocated 29268.02001953125 
[2025-03-02 13:48:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.042113494127988815 norm:0.0003604841185733676 max memory_allocated 29268.02001953125 
[2025-03-02 13:49:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.041620928794145584 norm:0.00027016663807444274 max memory_allocated 29268.02001953125 
[2025-03-02 13:50:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.04136941581964493 norm:0.00025478628231212497 max memory_allocated 29268.02001953125 
[2025-03-02 13:50:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.04123927280306816 norm:0.0002726169768720865 max memory_allocated 29268.02001953125 
[2025-03-02 13:51:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.041183069348335266 norm:0.0002817079075612128 max memory_allocated 29268.02001953125 
[2025-03-02 13:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.041097454726696014 norm:0.00025382693274877965 max memory_allocated 29268.02001953125 
[2025-03-02 13:53:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.04104885458946228 norm:0.00026307840016670525 max memory_allocated 29268.02001953125 
[2025-03-02 13:54:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.04099585860967636 norm:0.00024423046852461994 max memory_allocated 29268.02001953125 
[2025-03-02 13:55:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.04095085710287094 norm:0.0002470047911629081 max memory_allocated 29268.02001953125 
[2025-03-02 13:55:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.04092776030302048 norm:0.00025107013061642647 max memory_allocated 29268.02001953125 
[2025-03-02 13:56:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.04090268909931183 norm:0.0002488085883669555 max memory_allocated 29268.02001953125 
[2025-03-02 13:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.04088331013917923 norm:0.0002507259196136147 max memory_allocated 29268.02001953125 
[2025-03-02 13:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.040899112820625305 norm:0.0002550183853600174 max memory_allocated 29268.02001953125 
[2025-03-02 13:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.04090556502342224 norm:0.0002568043128121644 max memory_allocated 29268.02001953125 
[2025-03-02 14:00:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.04089439660310745 norm:0.0002540845889598131 max memory_allocated 29268.02001953125 
[2025-03-02 14:00:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.07741455733776093 norm:0.008603949099779129 max memory_allocated 29268.02001953125 
[2025-03-02 14:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.06008658930659294 norm:0.0025683920830488205 max memory_allocated 29268.02001953125 
[2025-03-02 14:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.05297907814383507 norm:0.0014169290661811829 max memory_allocated 29268.02001953125 
[2025-03-02 14:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.05044165253639221 norm:0.0009417996043339372 max memory_allocated 29268.02001953125 
[2025-03-02 14:04:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.048974376171827316 norm:0.0007401033071801066 max memory_allocated 29268.02001953125 
[2025-03-02 14:05:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.0480625294148922 norm:0.0006034011021256447 max memory_allocated 29268.02001953125 
[2025-03-02 14:06:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.047588370740413666 norm:0.0005431284662336111 max memory_allocated 29268.02001953125 
[2025-03-02 14:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.04735196381807327 norm:0.00042702245991677046 max memory_allocated 29268.02001953125 
[2025-03-02 14:07:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.0471852645277977 norm:0.0004157061339356005 max memory_allocated 29268.02001953125 
[2025-03-02 14:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.047096122056245804 norm:0.000393200054531917 max memory_allocated 29268.02001953125 
[2025-03-02 14:09:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.0470210537314415 norm:0.0003893871034961194 max memory_allocated 29268.02001953125 
[2025-03-02 14:10:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.0469277985394001 norm:0.00033528340281918645 max memory_allocated 29268.02001953125 
[2025-03-02 14:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.046848878264427185 norm:0.00032102057593874633 max memory_allocated 29268.02001953125 
[2025-03-02 14:11:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.046852730214595795 norm:0.0003367853641975671 max memory_allocated 29268.02001953125 
[2025-03-02 14:12:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.04680009186267853 norm:0.00030962354503571987 max memory_allocated 29268.02001953125 
[2025-03-02 14:13:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.046772174537181854 norm:0.0003333096101414412 max memory_allocated 29268.02001953125 
[2025-03-02 14:14:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.04684879258275032 norm:0.0003778991522267461 max memory_allocated 29268.02001953125 
[2025-03-02 14:15:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.04678601771593094 norm:0.00030548928771167994 max memory_allocated 29268.02001953125 
[2025-03-02 14:16:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.04676145687699318 norm:0.00030884065199643373 max memory_allocated 29268.02001953125 
[2025-03-02 14:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.04675644263625145 norm:0.00031866724020801485 max memory_allocated 29268.02001953125 
[2025-03-02 14:17:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:18:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.0897613912820816 norm:0.009152374230325222 max memory_allocated 29268.02001953125 
[2025-03-02 14:18:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.0670216828584671 norm:0.0031375607941299677 max memory_allocated 29268.02001953125 
[2025-03-02 14:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.057804882526397705 norm:0.0015796056250110269 max memory_allocated 29268.02001953125 
[2025-03-02 14:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.05440707877278328 norm:0.0009402188588865101 max memory_allocated 29268.02001953125 
[2025-03-02 14:21:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.05263444408774376 norm:0.0006514012929983437 max memory_allocated 29268.02001953125 
[2025-03-02 14:22:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.05154601112008095 norm:0.00047480338253080845 max memory_allocated 29268.02001953125 
[2025-03-02 14:23:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.05099814385175705 norm:0.00041162644629366696 max memory_allocated 29268.02001953125 
[2025-03-02 14:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.05069243535399437 norm:0.0003648186393547803 max memory_allocated 29268.02001953125 
[2025-03-02 14:24:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.050484295934438705 norm:0.0003492367686703801 max memory_allocated 29268.02001953125 
[2025-03-02 14:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.050353895872831345 norm:0.0003002798475790769 max memory_allocated 29268.02001953125 
[2025-03-02 14:26:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.05024097487330437 norm:0.0002883287670556456 max memory_allocated 29268.02001953125 
[2025-03-02 14:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.05016357824206352 norm:0.00028039549943059683 max memory_allocated 29268.02001953125 
[2025-03-02 14:28:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.050122566521167755 norm:0.00028931081760674715 max memory_allocated 29268.02001953125 
[2025-03-02 14:28:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.05007171630859375 norm:0.00027327146381139755 max memory_allocated 29268.02001953125 
[2025-03-02 14:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.05001357942819595 norm:0.0003004804311785847 max memory_allocated 29268.02001953125 
[2025-03-02 14:30:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.04999728500843048 norm:0.00031477404991164804 max memory_allocated 29268.02001953125 
[2025-03-02 14:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.04993332177400589 norm:0.00027175561990588903 max memory_allocated 29268.02001953125 
[2025-03-02 14:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.04989638552069664 norm:0.0002735326997935772 max memory_allocated 29268.02001953125 
[2025-03-02 14:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.04987776279449463 norm:0.00028723228024318814 max memory_allocated 29268.02001953125 
[2025-03-02 14:33:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.049886446446180344 norm:0.0002935425436589867 max memory_allocated 29268.02001953125 
[2025-03-02 14:34:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.10428252816200256 norm:0.006252195220440626 max memory_allocated 29269.00048828125 
[2025-03-02 14:35:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.0818474218249321 norm:0.0035612157080322504 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.06993703544139862 norm:0.0024536747951060534 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.0666147843003273 norm:0.0017184576718136668 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.06510641425848007 norm:0.0018594382563605905 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.061625510454177856 norm:0.0013646058505401015 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.06038060039281845 norm:0.0012584261130541563 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.05961451679468155 norm:0.0012739180820062757 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.059245526790618896 norm:0.0012582826893776655 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.06151067465543747 norm:0.0014164566528052092 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.059819724410772324 norm:0.001644918113015592 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.05914369598031044 norm:0.0009466595947742462 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.05962818115949631 norm:0.001782552688382566 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.058440856635570526 norm:0.0007603438571095467 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.05821918696165085 norm:0.0007558739744126797 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.058133695274591446 norm:0.0008199494332075119 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.05808869004249573 norm:0.000805059855338186 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.058020949363708496 norm:0.0007655142107978463 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.05799125134944916 norm:0.0007668454782105982 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.05804220587015152 norm:0.0007795365527272224 max memory_allocated 29269.00048828125 
[2025-03-02 14:51:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:51:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.0898667722940445 norm:0.004016058053821325 max memory_allocated 29269.00048828125 
[2025-03-02 14:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.07476430386304855 norm:0.0018429596675559878 max memory_allocated 29269.00048828125 
[2025-03-02 14:53:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.06678903102874756 norm:0.0009372112108394504 max memory_allocated 29269.00048828125 
[2025-03-02 14:54:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.06383594870567322 norm:0.0005290734115988016 max memory_allocated 29269.00048828125 
[2025-03-02 14:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.06243262067437172 norm:0.00034919314202852547 max memory_allocated 29269.00048828125 
[2025-03-02 14:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.061639994382858276 norm:0.00026987993624061346 max memory_allocated 29269.00048828125 
[2025-03-02 14:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.061213355511426926 norm:0.00023794193111825734 max memory_allocated 29269.00048828125 
[2025-03-02 14:57:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.06098012626171112 norm:0.0002228449156973511 max memory_allocated 29269.00048828125 
[2025-03-02 14:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.060869596898555756 norm:0.00021433067740872502 max memory_allocated 29269.00048828125 
[2025-03-02 14:59:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.060815855860710144 norm:0.00021429764456115663 max memory_allocated 29269.00048828125 
[2025-03-02 15:00:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.06075802817940712 norm:0.00021208880934864283 max memory_allocated 29269.00048828125 
[2025-03-02 15:01:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.06070154532790184 norm:0.00021001322602387518 max memory_allocated 29269.00048828125 
[2025-03-02 15:01:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.06064702570438385 norm:0.00021052641386631876 max memory_allocated 29269.00048828125 
[2025-03-02 15:02:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.06063095107674599 norm:0.00021251419093459845 max memory_allocated 29269.00048828125 
[2025-03-02 15:03:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.060609087347984314 norm:0.0002123077429132536 max memory_allocated 29269.00048828125 
[2025-03-02 15:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.06057345122098923 norm:0.0002124498860212043 max memory_allocated 29269.00048828125 
[2025-03-02 15:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.060589518398046494 norm:0.00022416180581785738 max memory_allocated 29269.00048828125 
[2025-03-02 15:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.0605616569519043 norm:0.00022327291662804782 max memory_allocated 29269.00048828125 
[2025-03-02 15:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.060554176568984985 norm:0.00022349705977831036 max memory_allocated 29269.00048828125 
[2025-03-02 15:07:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.060542166233062744 norm:0.00022225987049750984 max memory_allocated 29269.00048828125 
[2025-03-02 15:07:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.09435632079839706 norm:0.0044197868555784225 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.07886297255754471 norm:0.0017013631295412779 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.0713256448507309 norm:0.0008000463130883873 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.06843749433755875 norm:0.0004495245811995119 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.06700000166893005 norm:0.00031714115175418556 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.06618678569793701 norm:0.00026620482094585896 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.06576716899871826 norm:0.00023757493181619793 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.0655251070857048 norm:0.00022473250282928348 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.06539928168058395 norm:0.00022185167472343892 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.06534461677074432 norm:0.00022212367912288755 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.06525255739688873 norm:0.0002172992826672271 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.06521036475896835 norm:0.00023342811618931592 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.06518521159887314 norm:0.0002294527366757393 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.06514719128608704 norm:0.00022478471510112286 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.06513284146785736 norm:0.0002240989269921556 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.0651327595114708 norm:0.00022743923182133585 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.06510753184556961 norm:0.00022595467453356832 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.06509044021368027 norm:0.00022831988462712616 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.06506228446960449 norm:0.0002324756351299584 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.06503302603960037 norm:0.0002258672029711306 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.09635411947965622 norm:0.0036515959072858095 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.08253106474876404 norm:0.0015384508296847343 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.07506656646728516 norm:0.0007580120000056922 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.07225209474563599 norm:0.0004322723252698779 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.07089737802743912 norm:0.0002920017286669463 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.07016626000404358 norm:0.00023457086354028434 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.06980208307504654 norm:0.00021040230058133602 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.06961756199598312 norm:0.00020125693117734045 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.06949730217456818 norm:0.0001901134819490835 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.06944135576486588 norm:0.0001874949230113998 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.06940959393978119 norm:0.00018819210526999086 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.06935480982065201 norm:0.0001845629303716123 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.0693202018737793 norm:0.00018438967526890337 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.06929700076580048 norm:0.00018792999617289752 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.06928028166294098 norm:0.0001846580853452906 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.06929182261228561 norm:0.0001869110856205225 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.06929498165845871 norm:0.00018432005890645087 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.06928060948848724 norm:0.0001849143300205469 max memory_allocated 29269.56298828125 
[2025-03-02 15:40:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.0692741870880127 norm:0.0001855525915743783 max memory_allocated 29269.56298828125 
[2025-03-02 15:41:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.0692557692527771 norm:0.00018526420171838254 max memory_allocated 29269.56298828125 
[2025-03-02 15:41:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:42:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.09792926907539368 norm:0.0029347825329750776 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.08555199205875397 norm:0.0011843015672639012 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.07871324568986893 norm:0.0005857541691511869 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.07611056417226791 norm:0.0003471269446890801 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.07490183413028717 norm:0.00025019337772391737 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.07423567771911621 norm:0.00020601703727152199 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.07390226423740387 norm:0.00018407858442515135 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.07376233488321304 norm:0.0001742078020470217 max memory_allocated 29269.75048828125 
[2025-03-02 15:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.07367689907550812 norm:0.00017076829681172967 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.07362478971481323 norm:0.0001692309306235984 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.07357732206583023 norm:0.00016443942149635404 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.07353475689888 norm:0.000162368145538494 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.07351740449666977 norm:0.00016201594553422183 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.07350972294807434 norm:0.0001628825266379863 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.07348154485225677 norm:0.0001599851530045271 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.07347593456506729 norm:0.0001616260560695082 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.07346189022064209 norm:0.00016031715495046228 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.07345099747180939 norm:0.0001613819767953828 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.07344795763492584 norm:0.00016059949120972306 max memory_allocated 29269.75048828125 
[2025-03-02 15:58:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.07343809306621552 norm:0.0001608419988770038 max memory_allocated 29269.75048828125 
[2025-03-02 15:58:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:59:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.10524678230285645 norm:0.0031884079799056053 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.09179196506738663 norm:0.0013445084914565086 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.0840500146150589 norm:0.0006548522505909204 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.0813307985663414 norm:0.0003754179342649877 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.08010666072368622 norm:0.0002606896741781384 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.07939687371253967 norm:0.00020849045540671796 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.07905776798725128 norm:0.000186339661013335 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.07891866564750671 norm:0.0001770679373294115 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.07882227003574371 norm:0.00017245428171008825 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.07874706387519836 norm:0.00017024166299961507 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.07870633155107498 norm:0.0001674894301686436 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.07868637144565582 norm:0.00016666576266288757 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.0786602795124054 norm:0.00016595999477431178 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.07861732691526413 norm:0.00016599110676907003 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.07859963923692703 norm:0.0001648907345952466 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.07858733087778091 norm:0.00016460171900689602 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.07856941968202591 norm:0.0001656807871768251 max memory_allocated 29269.93798828125 
[2025-03-02 16:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.07855043560266495 norm:0.00016486624372191727 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.0785464346408844 norm:0.00016196495562326163 max memory_allocated 29269.93798828125 
[2025-03-02 16:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.0785445049405098 norm:0.00016355342813767493 max memory_allocated 29269.93798828125 
[2025-03-02 16:15:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:16:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.10659030824899673 norm:0.0024935253895819187 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.09527416527271271 norm:0.001038871007040143 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.08812777698040009 norm:0.0005512688658200204 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.08560538291931152 norm:0.0003568201791495085 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.08439314365386963 norm:0.0002660395111888647 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.0837160274386406 norm:0.00022153748432174325 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.08334177732467651 norm:0.00019271128985565156 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.08318836987018585 norm:0.00018403871217742562 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.08308248221874237 norm:0.00017634060350246727 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.08301732689142227 norm:0.00017461723473388702 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.0829644650220871 norm:0.00017282132466789335 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.08292000740766525 norm:0.00017032469622790813 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.08289775997400284 norm:0.00016806401254143566 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.08287426829338074 norm:0.00016671634512022138 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.08284389972686768 norm:0.0001662732829572633 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.08282775431871414 norm:0.00016568097635172307 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.08280720561742783 norm:0.00016440835315734148 max memory_allocated 29270.12548828125 
[2025-03-02 16:30:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.08278840035200119 norm:0.00016559433424845338 max memory_allocated 29270.12548828125 
[2025-03-02 16:31:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.08277441561222076 norm:0.00016456734738312662 max memory_allocated 29270.12548828125 
[2025-03-02 16:32:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.08277224004268646 norm:0.00016507826512679458 max memory_allocated 29270.12548828125 
[2025-03-02 16:32:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.10859048366546631 norm:0.001788433874025941 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.09872452914714813 norm:0.0008329149568453431 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.09211072325706482 norm:0.0004793494299519807 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.08970418572425842 norm:0.0003283527330495417 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.0884302631020546 norm:0.0002526671742089093 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.08770248293876648 norm:0.00020998390391469002 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.08731506019830704 norm:0.0001878500188468024 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.08710946142673492 norm:0.00017653148097451776 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.08697259426116943 norm:0.0001683256559772417 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.08688578754663467 norm:0.00016381009481847286 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.08680914342403412 norm:0.00016019157192204148 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.0867583155632019 norm:0.0001599666429683566 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.08671452850103378 norm:0.00015866727335378528 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.08668147027492523 norm:0.00015678504132665694 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.08665579557418823 norm:0.0001546335406601429 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.08664955198764801 norm:0.00015368421736638993 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.0866352766752243 norm:0.0001534986076876521 max memory_allocated 29270.31298828125 
[2025-03-02 16:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.08662334829568863 norm:0.00015467625053133816 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.08661932498216629 norm:0.00015459123824257404 max memory_allocated 29270.31298828125 
[2025-03-02 16:49:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.08660981059074402 norm:0.0001532397436676547 max memory_allocated 29270.31298828125 
[2025-03-02 16:49:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:50:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.11617039144039154 norm:0.002891792915761471 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.10467824339866638 norm:0.0013182985130697489 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.09716031700372696 norm:0.0007213123026303947 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.09450708329677582 norm:0.0004689176275860518 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.0931624174118042 norm:0.0003440511063672602 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.09240025281906128 norm:0.0002725957310758531 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.09200979769229889 norm:0.00023299839813262224 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.09178857505321503 norm:0.0002091731585096568 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.09167377650737762 norm:0.00019608177535701543 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.0915900468826294 norm:0.0001886466925498098 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.09150156378746033 norm:0.00018100197485182434 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.09144333004951477 norm:0.00017950123583432287 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.09139227867126465 norm:0.00017608269990887493 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.09135717153549194 norm:0.00017332575225736946 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.09132862091064453 norm:0.00017246083007194102 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.09130317717790604 norm:0.00017080162069760263 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.09126462042331696 norm:0.0001688621996436268 max memory_allocated 29270.50048828125 
[2025-03-02 17:04:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.09123776108026505 norm:0.00016784537001512945 max memory_allocated 29270.50048828125 
[2025-03-02 17:05:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.09122858941555023 norm:0.00016775143740233034 max memory_allocated 29270.50048828125 
[2025-03-02 17:06:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.09121060371398926 norm:0.0001663556759012863 max memory_allocated 29270.50048828125 
[2025-03-02 17:06:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.11706791818141937 norm:0.0016089245909824967 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.1085662767291069 norm:0.0006412703660316765 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.10283677279949188 norm:0.00038332189433276653 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.10059129446744919 norm:0.0002782955707516521 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:39 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.0992869958281517 norm:0.00022763402375858277 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.09853015094995499 norm:0.0001986895513255149 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:19 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.09814700484275818 norm:0.00018006499158218503 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.0979199931025505 norm:0.00016928801778703928 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.0977901816368103 norm:0.00016037997556850314 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.09770838916301727 norm:0.00015783366688992828 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.09764561057090759 norm:0.00015439096023328602 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.09757441282272339 norm:0.00015141624317038804 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.0975252315402031 norm:0.00015110158710740507 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.09747810661792755 norm:0.00014949662727303803 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.09745410084724426 norm:0.00014882272807881236 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.09745822846889496 norm:0.0001489942951593548 max memory_allocated 29270.68798828125 
[2025-03-02 17:20:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.09743784368038177 norm:0.00014825662947259843 max memory_allocated 29270.68798828125 
[2025-03-02 17:21:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.0974196270108223 norm:0.0001490801660111174 max memory_allocated 29270.68798828125 
[2025-03-02 17:22:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.09740971028804779 norm:0.00014876449131406844 max memory_allocated 29270.68798828125 
[2025-03-02 17:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.09739807993173599 norm:0.0001483961386838928 max memory_allocated 29270.68798828125 
[2025-03-02 17:23:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.12392424046993256 norm:0.0027220379561185837 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.11539764702320099 norm:0.00123136630281806 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.10947065055370331 norm:0.0007168217562139034 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.10726164281368256 norm:0.0004834067076444626 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.10593222081661224 norm:0.0003557637974154204 max memory_allocated 29270.87548828125 
[2025-03-02 17:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.1051914170384407 norm:0.0002785376855172217 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.104849673807621 norm:0.0002327423426322639 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.10469705611467361 norm:0.00020517251687124372 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.10457602888345718 norm:0.00018812515190802515 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.10448320209980011 norm:0.0001754682307364419 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.10443306714296341 norm:0.00016644212882965803 max memory_allocated 29270.87548828125 
[2025-03-02 17:33:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.10438641160726547 norm:0.00016140486695803702 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.10434386134147644 norm:0.00015713383618276566 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.10431353747844696 norm:0.0001547603460494429 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.10428868979215622 norm:0.0001524556428194046 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.10425680875778198 norm:0.00015006557805463672 max memory_allocated 29270.87548828125 
[2025-03-02 17:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.10423856973648071 norm:0.00014981214189901948 max memory_allocated 29270.87548828125 
[2025-03-02 17:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.10421067476272583 norm:0.000148661871207878 max memory_allocated 29270.87548828125 
[2025-03-02 17:39:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.10420060157775879 norm:0.0001491325965616852 max memory_allocated 29270.87548828125 
[2025-03-02 17:40:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.10419279336929321 norm:0.0001490224531153217 max memory_allocated 29270.87548828125 
[2025-03-02 17:40:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:41:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.1352493017911911 norm:0.003732998389750719 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.12505534291267395 norm:0.0015742691466584802 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.11807414144277573 norm:0.0008774880552664399 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.1155967265367508 norm:0.0005793590098619461 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.11417076736688614 norm:0.00041917554335668683 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.11339379847049713 norm:0.00032463454408571124 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.11305643618106842 norm:0.0002669318637344986 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.11285308003425598 norm:0.0002304004447069019 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.11272677034139633 norm:0.00020563867292366922 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.11261779069900513 norm:0.0001900553615996614 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.11255595833063126 norm:0.0001800868776626885 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.11249518394470215 norm:0.00017302237392868847 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.11244640499353409 norm:0.00016786111518740654 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.11239711940288544 norm:0.00016322296869475394 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.11236051470041275 norm:0.00016097232582978904 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.1123272106051445 norm:0.00015922513557597995 max memory_allocated 29271.06298828125 
[2025-03-02 17:54:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.11229664087295532 norm:0.00015755150525365025 max memory_allocated 29271.06298828125 
[2025-03-02 17:55:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.11227426677942276 norm:0.0001563076802995056 max memory_allocated 29271.06298828125 
[2025-03-02 17:56:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.11224547028541565 norm:0.00015536873252131045 max memory_allocated 29271.06298828125 
[2025-03-02 17:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.11221928894519806 norm:0.00015448904014192522 max memory_allocated 29271.06298828125 
[2025-03-02 17:57:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.14787623286247253 norm:0.0032969440799206495 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.13726988434791565 norm:0.0012846008175984025 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.12992188334465027 norm:0.0006883068708702922 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.12738502025604248 norm:0.0004561646783258766 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.12596403062343597 norm:0.00033567805076017976 max memory_allocated 29271.25048828125 
[2025-03-02 18:02:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.12524732947349548 norm:0.0002704873331822455 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.12492601573467255 norm:0.0002332211151951924 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.12471318989992142 norm:0.00021144218044355512 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.1245836466550827 norm:0.00019896947196684778 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.12446679174900055 norm:0.0001888039114419371 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.12436435371637344 norm:0.0001824453502194956 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.12429358065128326 norm:0.00017929953173734248 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.12423014640808105 norm:0.00017477970686741173 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.12418113648891449 norm:0.00017418838979210705 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.12414929270744324 norm:0.00017290969844907522 max memory_allocated 29271.25048828125 
[2025-03-02 18:10:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.12412382662296295 norm:0.00017101087723858654 max memory_allocated 29271.25048828125 
[2025-03-02 18:11:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.12408246099948883 norm:0.0001707057817839086 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.1240566223859787 norm:0.0001725773181533441 max memory_allocated 29271.25048828125 
[2025-03-02 18:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.12402629107236862 norm:0.00017101045523304492 max memory_allocated 29271.25048828125 
[2025-03-02 18:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.12402021139860153 norm:0.0001707277406239882 max memory_allocated 29271.25048828125 
[2025-03-02 18:14:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:15:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.16044338047504425 norm:0.0020615800749510527 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.15081413090229034 norm:0.0008795243920758367 max memory_allocated 29271.43798828125 
[2025-03-02 18:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.1432977020740509 norm:0.0005156262777745724 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.14068210124969482 norm:0.0003575667506083846 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.13927382230758667 norm:0.0002776203618850559 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.13863885402679443 norm:0.00023198018607217818 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.13831429183483124 norm:0.00020506669534370303 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.1381220817565918 norm:0.00018826089217327535 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.13799601793289185 norm:0.00017799358465708792 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.13788765668869019 norm:0.00017158214177470654 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.13781410455703735 norm:0.0001688296761130914 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.13775873184204102 norm:0.000165730292792432 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.13769331574440002 norm:0.00016402220353484154 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.13767150044441223 norm:0.0001623752759769559 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:41 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.1376153975725174 norm:0.0001611628249520436 max memory_allocated 29271.43798828125 
[2025-03-02 18:27:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.13757972419261932 norm:0.00015967863146215677 max memory_allocated 29271.43798828125 
[2025-03-02 18:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.1375529170036316 norm:0.00015831827477086335 max memory_allocated 29271.43798828125 
[2025-03-02 18:29:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.13753141462802887 norm:0.00015800626715645194 max memory_allocated 29271.43798828125 
[2025-03-02 18:30:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.1375216394662857 norm:0.00015812709170859307 max memory_allocated 29271.43798828125 
[2025-03-02 18:30:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.13749785721302032 norm:0.0001578307565068826 max memory_allocated 29271.43798828125 
[2025-03-02 18:31:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.1771443486213684 norm:0.0018081035232171416 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.16629311442375183 norm:0.0008084386354312301 max memory_allocated 29271.62548828125 
[2025-03-02 18:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.15788209438323975 norm:0.0004799846210516989 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.15510818362236023 norm:0.0003447582421358675 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.15364569425582886 norm:0.00027353569748811424 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.15303052961826324 norm:0.00023197013069875538 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.15271934866905212 norm:0.0002091522328555584 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.15251506865024567 norm:0.00019424395577516407 max memory_allocated 29271.62548828125 
[2025-03-02 18:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.1523510068655014 norm:0.00018313205509912223 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.15222032368183136 norm:0.00017760702758096159 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.15209689736366272 norm:0.0001721489243209362 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.152005136013031 norm:0.00017048198787961155 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.15194228291511536 norm:0.0001665518357185647 max memory_allocated 29271.62548828125 
[2025-03-02 18:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.15188564360141754 norm:0.00016409243107773364 max memory_allocated 29271.62548828125 
[2025-03-02 18:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.15183408558368683 norm:0.00016352902457583696 max memory_allocated 29271.62548828125 
[2025-03-02 18:44:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.15179215371608734 norm:0.00016169570153579116 max memory_allocated 29271.62548828125 
[2025-03-02 18:45:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.15175579488277435 norm:0.00016274751396849751 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.1517183631658554 norm:0.00016109220450744033 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.15169329941272736 norm:0.0001627199089853093 max memory_allocated 29271.62548828125 
[2025-03-02 18:47:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.15168234705924988 norm:0.0001618677342776209 max memory_allocated 29271.62548828125 
[2025-03-02 18:48:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.20075397193431854 norm:0.002351321280002594 max memory_allocated 29271.81298828125 
[2025-03-02 18:49:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.18808263540267944 norm:0.0011930865002796054 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.17828193306922913 norm:0.0007146002608351409 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.17514564096927643 norm:0.0004935034085065126 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.1735190451145172 norm:0.0003677232889458537 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.17285025119781494 norm:0.0002967991749756038 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.17251740396022797 norm:0.0002568244526628405 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.17228057980537415 norm:0.0002349648711970076 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.17211538553237915 norm:0.00022047795937396586 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.17195573449134827 norm:0.0002074615185847506 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.17184320092201233 norm:0.00020037655485793948 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.17175817489624023 norm:0.000196432854863815 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.17169076204299927 norm:0.0001927857956616208 max memory_allocated 29271.81298828125 
[2025-03-02 18:59:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.17160938680171967 norm:0.00019090130808763206 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.17156729102134705 norm:0.00018981787434313446 max memory_allocated 29271.81298828125 
[2025-03-02 19:01:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.17150190472602844 norm:0.00018761304090730846 max memory_allocated 29271.81298828125 
[2025-03-02 19:02:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.17143407464027405 norm:0.00018596512381918728 max memory_allocated 29271.81298828125 
[2025-03-02 19:03:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.17139585316181183 norm:0.00018699129577726126 max memory_allocated 29271.81298828125 
[2025-03-02 19:03:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.17136569321155548 norm:0.00018742418615147471 max memory_allocated 29271.81298828125 
[2025-03-02 19:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.17133478820323944 norm:0.00018582120537757874 max memory_allocated 29271.81298828125 
[2025-03-02 19:04:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:05:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.22482210397720337 norm:0.0022169388830661774 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.21215632557868958 norm:0.0010911707067862153 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.20200538635253906 norm:0.0006592873833142221 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.19877615571022034 norm:0.00047345474013127387 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.1971641480922699 norm:0.0003707607102114707 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.19652684032917023 norm:0.0003164064255543053 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.19619742035865784 norm:0.00028429008671082556 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.1959610879421234 norm:0.0002666702202986926 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.19575411081314087 norm:0.0002535885141696781 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.1956152617931366 norm:0.0002467750455252826 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.19546779990196228 norm:0.00023896056518424302 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.19534578919410706 norm:0.00023793386935722083 max memory_allocated 29272.00048828125 
[2025-03-02 19:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.19525501132011414 norm:0.00023321672051679343 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.1951497495174408 norm:0.00023111049085855484 max memory_allocated 29272.00048828125 
[2025-03-02 19:17:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.19506698846817017 norm:0.00022852422262076288 max memory_allocated 29272.00048828125 
[2025-03-02 19:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.19501765072345734 norm:0.0002233581617474556 max memory_allocated 29272.00048828125 
[2025-03-02 19:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.1949746310710907 norm:0.00022479210747405887 max memory_allocated 29272.00048828125 
[2025-03-02 19:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.19490273296833038 norm:0.00022420576715376228 max memory_allocated 29272.00048828125 
[2025-03-02 19:20:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.1948591023683548 norm:0.00022606420679949224 max memory_allocated 29272.00048828125 
[2025-03-02 19:21:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.19479526579380035 norm:0.00022115849424153566 max memory_allocated 29272.00048828125 
[2025-03-02 19:21:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.2541079521179199 norm:0.0025296194944530725 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.2407492995262146 norm:0.001236991723999381 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.22998198866844177 norm:0.0007321425364352763 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.2265373319387436 norm:0.0005195370176807046 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.22478364408016205 norm:0.0004064832755830139 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.22418759763240814 norm:0.0003456476842984557 max memory_allocated 29272.18798828125 
[2025-03-02 19:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.2238215059041977 norm:0.0003109183453489095 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.22353126108646393 norm:0.0002884210553020239 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.22329488396644592 norm:0.0002701130579225719 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.22309903800487518 norm:0.0002617173013277352 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.22294703125953674 norm:0.00025151026784442365 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.22280822694301605 norm:0.00024432357167825103 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.22270086407661438 norm:0.00024041280266828835 max memory_allocated 29272.18798828125 
[2025-03-02 19:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.22262629866600037 norm:0.0002351728326175362 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.22254586219787598 norm:0.00023013452300801873 max memory_allocated 29272.18798828125 
[2025-03-02 19:35:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.222455233335495 norm:0.00023050060553941876 max memory_allocated 29272.18798828125 
[2025-03-02 19:36:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.22238337993621826 norm:0.00022862269543111324 max memory_allocated 29272.18798828125 
[2025-03-02 19:36:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.22232235968112946 norm:0.00022664613788947463 max memory_allocated 29272.18798828125 
[2025-03-02 19:37:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.22229529917240143 norm:0.0002228788216598332 max memory_allocated 29272.18798828125 
[2025-03-02 19:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.22223018109798431 norm:0.00022442470071837306 max memory_allocated 29272.18798828125 
[2025-03-02 19:38:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:39:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.2835751473903656 norm:0.0031311954371631145 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.2700127065181732 norm:0.001550155458971858 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.2587816119194031 norm:0.0009403173462487757 max memory_allocated 29272.37548828125 
[2025-03-02 19:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.25505706667900085 norm:0.0006577664171345532 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.2532980740070343 norm:0.0004972193273715675 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.2526656985282898 norm:0.0004092220333404839 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.25226935744285583 norm:0.0003471772652119398 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.2520023584365845 norm:0.00031767290784046054 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.25180330872535706 norm:0.00029547486337833107 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.2516094446182251 norm:0.0002766879624687135 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.2514178454875946 norm:0.00025902880588546395 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.25127941370010376 norm:0.00024977538851089776 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.2511777877807617 norm:0.0002467203594278544 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.25110477209091187 norm:0.0002422077232040465 max memory_allocated 29272.37548828125 
[2025-03-02 19:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.2510130703449249 norm:0.0002384625986451283 max memory_allocated 29272.37548828125 
[2025-03-02 19:52:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.2509308159351349 norm:0.00023682905884925276 max memory_allocated 29272.37548828125 
[2025-03-02 19:52:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.25085484981536865 norm:0.00023462760145775974 max memory_allocated 29272.37548828125 
[2025-03-02 19:53:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.2507924735546112 norm:0.00023612788936588913 max memory_allocated 29272.37548828125 
[2025-03-02 19:54:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.2507244944572449 norm:0.00023503287229686975 max memory_allocated 29272.37548828125 
[2025-03-02 19:55:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.25067561864852905 norm:0.00023402681108564138 max memory_allocated 29272.37548828125 
[2025-03-02 19:55:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:56:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.3174784183502197 norm:0.002011564327403903 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.3036665916442871 norm:0.0010531629668548703 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.2913634777069092 norm:0.0006560581969097257 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.2875203788280487 norm:0.00048042129492387176 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.2858997583389282 norm:0.00038451518048532307 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.28530532121658325 norm:0.00033322416129522026 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.2849384546279907 norm:0.0003086488286498934 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.28461119532585144 norm:0.0002882335684262216 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.28439024090766907 norm:0.0002709037798922509 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.2841915488243103 norm:0.00026046542916446924 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.2840190529823303 norm:0.00025292212376371026 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.2838398218154907 norm:0.0002475869841873646 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.2837212383747101 norm:0.00024382738047279418 max memory_allocated 29272.56298828125 
[2025-03-02 20:07:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.28359729051589966 norm:0.00023839286586735398 max memory_allocated 29272.56298828125 
[2025-03-02 20:08:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.2835012972354889 norm:0.00023570969642605633 max memory_allocated 29272.56298828125 
[2025-03-02 20:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.2833870053291321 norm:0.00023613077064510435 max memory_allocated 29272.56298828125 
[2025-03-02 20:09:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.28329533338546753 norm:0.00023358772159554064 max memory_allocated 29272.56298828125 
[2025-03-02 20:10:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.2832111120223999 norm:0.00023419316858053207 max memory_allocated 29272.56298828125 
[2025-03-02 20:11:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.2831454277038574 norm:0.0002321021311217919 max memory_allocated 29272.56298828125 
[2025-03-02 20:12:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.2830943465232849 norm:0.0002336817851755768 max memory_allocated 29272.56298828125 
[2025-03-02 20:12:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:13:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.3519216477870941 norm:0.002568044699728489 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.33730173110961914 norm:0.0010633035562932491 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:12 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.32444965839385986 norm:0.0006064759800210595 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.32050007581710815 norm:0.0004333714605309069 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.3188970983028412 norm:0.0003470827650744468 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.31833964586257935 norm:0.0003030049556400627 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.3180394172668457 norm:0.0002780675422400236 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.31777921319007874 norm:0.00026319283642806113 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:12 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.3175574541091919 norm:0.00025347096379846334 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.3173755705356598 norm:0.000246543058892712 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.3172055184841156 norm:0.00024065299658104777 max memory_allocated 29272.75048828125 
[2025-03-02 20:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.31705573201179504 norm:0.0002371156879235059 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.3169420063495636 norm:0.0002357461053179577 max memory_allocated 29272.75048828125 
[2025-03-02 20:24:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.31682273745536804 norm:0.0002328506379853934 max memory_allocated 29272.75048828125 
[2025-03-02 20:25:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.316732257604599 norm:0.00023190111096482724 max memory_allocated 29272.75048828125 
[2025-03-02 20:26:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.3166435658931732 norm:0.00023027679708320647 max memory_allocated 29272.75048828125 
[2025-03-02 20:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.3165680468082428 norm:0.0002293624565936625 max memory_allocated 29272.75048828125 
[2025-03-02 20:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.3164750039577484 norm:0.0002274288999615237 max memory_allocated 29272.75048828125 
[2025-03-02 20:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.3163786232471466 norm:0.00022538157645612955 max memory_allocated 29272.75048828125 
[2025-03-02 20:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.3163076639175415 norm:0.00022635413915850222 max memory_allocated 29272.75048828125 
[2025-03-02 20:29:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.3948410153388977 norm:0.0018558319425210357 max memory_allocated 29272.93798828125 
[2025-03-02 20:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.3786500096321106 norm:0.0008997037657536566 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.3638656437397003 norm:0.0005530625930987298 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.3594930171966553 norm:0.000410337233915925 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.3577952980995178 norm:0.000341281876899302 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.3571963906288147 norm:0.00030426785815507174 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.3568049669265747 norm:0.000285824469756335 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.35647061467170715 norm:0.000273885641945526 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.3562382757663727 norm:0.0002672568371053785 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.3560171127319336 norm:0.00026035812334157526 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.35581016540527344 norm:0.00025540683418512344 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.3556334674358368 norm:0.00025195139460265636 max memory_allocated 29272.93798828125 
[2025-03-02 20:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.35546839237213135 norm:0.0002504513249732554 max memory_allocated 29272.93798828125 
[2025-03-02 20:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.355339914560318 norm:0.00025020819157361984 max memory_allocated 29272.93798828125 
[2025-03-02 20:42:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.3552272617816925 norm:0.0002510335179977119 max memory_allocated 29272.93798828125 
[2025-03-02 20:42:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.35512033104896545 norm:0.0002499279216863215 max memory_allocated 29272.93798828125 
[2025-03-02 20:43:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.3550414443016052 norm:0.00024771192693151534 max memory_allocated 29272.93798828125 
[2025-03-02 20:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.3549492061138153 norm:0.0002483141142874956 max memory_allocated 29272.93798828125 
[2025-03-02 20:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.3548766076564789 norm:0.0002481276751495898 max memory_allocated 29272.93798828125 
[2025-03-02 20:46:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.3548054099082947 norm:0.00024789743474684656 max memory_allocated 29272.93798828125 
[2025-03-02 20:46:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:47:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.43685513734817505 norm:0.002077822806313634 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.4197671711444855 norm:0.0010191815672442317 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.4043409526348114 norm:0.0006664395914413035 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.39966607093811035 norm:0.0005176177946850657 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.398002564907074 norm:0.00047108245780691504 max memory_allocated 29273.12548828125 
[2025-03-02 20:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.397344172000885 norm:0.00040684142732061446 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.396918386220932 norm:0.0003735105856321752 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.39659926295280457 norm:0.0003600257041398436 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.3963274657726288 norm:0.00035251484951004386 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.3961353003978729 norm:0.0003791193012148142 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.3959497809410095 norm:0.00039924378506839275 max memory_allocated 29273.12548828125 
[2025-03-02 20:56:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.39581674337387085 norm:0.0004034049925394356 max memory_allocated 29273.12548828125 
[2025-03-02 20:57:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.3956390619277954 norm:0.00039244251092895865 max memory_allocated 29273.12548828125 
[2025-03-02 20:58:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.39550065994262695 norm:0.00035058424691669643 max memory_allocated 29273.12548828125 
[2025-03-02 20:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.39535248279571533 norm:0.0003379271365702152 max memory_allocated 29273.12548828125 
[2025-03-02 20:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.3952074348926544 norm:0.00035507467691786587 max memory_allocated 29273.12548828125 
[2025-03-02 21:00:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.39510443806648254 norm:0.00035816061426885426 max memory_allocated 29273.12548828125 
[2025-03-02 21:01:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.3950439691543579 norm:0.0003588235704228282 max memory_allocated 29273.12548828125 
[2025-03-02 21:02:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.39500388503074646 norm:0.0003312244080007076 max memory_allocated 29273.12548828125 
[2025-03-02 21:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.39493030309677124 norm:0.00034821091685444117 max memory_allocated 29273.12548828125 
[2025-03-02 21:03:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 21:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.47838807106018066 norm:0.003734316909685731 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.46064677834510803 norm:0.0018502427265048027 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.4444159269332886 norm:0.0010812354739755392 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.4395609200000763 norm:0.0007314487593248487 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.4379485249519348 norm:0.0005538485129363835 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.4373914301395416 norm:0.00045582721941173077 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.4370107054710388 norm:0.0003922843898180872 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.4366830289363861 norm:0.00034987321123480797 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.43639642000198364 norm:0.0003222080413252115 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.43616384267807007 norm:0.00030460685957223177 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.43596920371055603 norm:0.00029169931076467037 max memory_allocated 29273.31298828125 
[2025-03-02 21:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.43579038977622986 norm:0.0002828218857757747 max memory_allocated 29273.31298828125 
[2025-03-02 21:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.43563321232795715 norm:0.00027729885187000036 max memory_allocated 29273.31298828125 
[2025-03-02 21:15:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.4354906976222992 norm:0.0002697669551707804 max memory_allocated 29273.31298828125 
[2025-03-02 21:15:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.4353742003440857 norm:0.00026588825858198106 max memory_allocated 29273.31298828125 
[2025-03-02 21:16:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.4352690279483795 norm:0.00026326585793867707 max memory_allocated 29273.31298828125 
[2025-03-02 21:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.4351557195186615 norm:0.00026445792173035443 max memory_allocated 29273.31298828125 
[2025-03-02 21:18:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.4350585639476776 norm:0.00026084130513481796 max memory_allocated 29273.31298828125 
[2025-03-02 21:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.4349709153175354 norm:0.00025886320509016514 max memory_allocated 29273.31298828125 
[2025-03-02 21:20:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.4348868429660797 norm:0.00025844393530860543 max memory_allocated 29273.31298828125 
[2025-03-02 21:20:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:21:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.5259683132171631 norm:0.0035176523961126804 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.5073539018630981 norm:0.0016941437497735023 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.49059733748435974 norm:0.0009943611221387982 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.48549211025238037 norm:0.0006823425064794719 max memory_allocated 29273.50048828125 
[2025-03-02 21:24:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.48382994532585144 norm:0.0005332877626642585 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.4831176996231079 norm:0.0004667123139370233 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.482660174369812 norm:0.0004091238952241838 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.48228058218955994 norm:0.0003799211117438972 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.4820087254047394 norm:0.00034899587626568973 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.481718510389328 norm:0.00033074425300583243 max memory_allocated 29273.50048828125 
[2025-03-02 21:29:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.48148977756500244 norm:0.00031921110348775983 max memory_allocated 29273.50048828125 
[2025-03-02 21:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.4813169240951538 norm:0.0003141702036373317 max memory_allocated 29273.50048828125 
[2025-03-02 21:31:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.4811581075191498 norm:0.00030963041353970766 max memory_allocated 29273.50048828125 
[2025-03-02 21:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.48104703426361084 norm:0.0003052526735700667 max memory_allocated 29273.50048828125 
[2025-03-02 21:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.4809194803237915 norm:0.00030294357566162944 max memory_allocated 29273.50048828125 
[2025-03-02 21:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.48074862360954285 norm:0.00029791114502586424 max memory_allocated 29273.50048828125 
[2025-03-02 21:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.4806414842605591 norm:0.0002969707129523158 max memory_allocated 29273.50048828125 
[2025-03-02 21:35:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.4805346429347992 norm:0.00029784662183374166 max memory_allocated 29273.50048828125 
[2025-03-02 21:36:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.48043733835220337 norm:0.0002975371608044952 max memory_allocated 29273.50048828125 
[2025-03-02 21:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.48033520579338074 norm:0.0002961269346997142 max memory_allocated 29273.50048828125 
[2025-03-02 21:37:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.5762715339660645 norm:0.004086342640221119 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.5562382936477661 norm:0.0018704668618738651 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.538574755191803 norm:0.0010707331821322441 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.5331071615219116 norm:0.0007180677494034171 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.5314460396766663 norm:0.0005455379141494632 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.5307720899581909 norm:0.00045454391511157155 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.530273973941803 norm:0.0004005837254226208 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.5299485921859741 norm:0.000365866522770375 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.52965247631073 norm:0.0003394294180907309 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.5293570756912231 norm:0.00032316287979483604 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.5291031002998352 norm:0.00031393778044730425 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.5289081335067749 norm:0.000306945905322209 max memory_allocated 29273.68798828125 
[2025-03-02 21:48:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.5287167429924011 norm:0.0003020543954335153 max memory_allocated 29273.68798828125 
[2025-03-02 21:49:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.5285496711730957 norm:0.0003002688172273338 max memory_allocated 29273.68798828125 
[2025-03-02 21:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.5284183025360107 norm:0.00029877296765334904 max memory_allocated 29273.68798828125 
[2025-03-02 21:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.5282773971557617 norm:0.00029789109248667955 max memory_allocated 29273.68798828125 
[2025-03-02 21:51:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.5281693339347839 norm:0.00029228441417217255 max memory_allocated 29273.68798828125 
[2025-03-02 21:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.528084933757782 norm:0.00028867044602520764 max memory_allocated 29273.68798828125 
[2025-03-02 21:53:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.5280193090438843 norm:0.0002897010708693415 max memory_allocated 29273.68798828125 
[2025-03-02 21:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.5279484987258911 norm:0.0002900090184994042 max memory_allocated 29273.68798828125 
[2025-03-02 21:54:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.6220806837081909 norm:0.0025695241056382656 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.6039196848869324 norm:0.0013187095755711198 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.5864291787147522 norm:0.0008093697833828628 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.5812985301017761 norm:0.0005744646769016981 max memory_allocated 29273.87548828125 
[2025-03-02 21:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.5798792839050293 norm:0.0004591515171341598 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:18 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.5792707204818726 norm:0.0003998854081146419 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:08 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.5787566900253296 norm:0.0003622239164542407 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.5783894658088684 norm:0.0003388563927728683 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:48 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.5780895948410034 norm:0.00032207363983616233 max memory_allocated 29273.87548828125 
[2025-03-02 22:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.5777663588523865 norm:0.0003090295649599284 max memory_allocated 29273.87548828125 
[2025-03-02 22:03:27 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.5775387287139893 norm:0.0002986099570989609 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.5773676037788391 norm:0.0002930588088929653 max memory_allocated 29273.87548828125 
[2025-03-02 22:05:07 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.5771746635437012 norm:0.0002894043573178351 max memory_allocated 29273.87548828125 
[2025-03-02 22:05:57 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.5770180225372314 norm:0.0002853069454431534 max memory_allocated 29273.87548828125 
[2025-03-02 22:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.5768351554870605 norm:0.00028174949693493545 max memory_allocated 29273.87548828125 
[2025-03-02 22:07:37 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.5766994953155518 norm:0.0002768418053165078 max memory_allocated 29273.87548828125 
[2025-03-02 22:08:27 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.5764710903167725 norm:0.00027909589698538184 max memory_allocated 29273.87548828125 
[2025-03-02 22:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.5764326453208923 norm:0.000276699080131948 max memory_allocated 29273.87548828125 
[2025-03-02 22:10:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.5763307809829712 norm:0.00027280367794446647 max memory_allocated 29273.87548828125 
[2025-03-02 22:10:56 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.576224148273468 norm:0.0002718182513490319 max memory_allocated 29273.87548828125 
[2025-03-02 22:11:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:12:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.6853595972061157 norm:0.0027021323330700397 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.6641703248023987 norm:0.001377993612550199 max memory_allocated 29274.06298828125 
[2025-03-02 22:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.6449814438819885 norm:0.0008441016543656588 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.6392635107040405 norm:0.0006033561658114195 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.6376333236694336 norm:0.0004899017512798309 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.6369122862815857 norm:0.0004271404177416116 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.636374831199646 norm:0.0003925226628780365 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.6359704732894897 norm:0.00036986602935940027 max memory_allocated 29274.06298828125 
[2025-03-02 22:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.6356277465820312 norm:0.0003550345718394965 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:33 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.6353682279586792 norm:0.00034691489418037236 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:22 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.6351419687271118 norm:0.0003375588566996157 max memory_allocated 29274.06298828125 
[2025-03-02 22:21:12 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.6348878145217896 norm:0.0003362715942785144 max memory_allocated 29274.06298828125 
[2025-03-02 22:22:02 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.6346871852874756 norm:0.0003315129433758557 max memory_allocated 29274.06298828125 
[2025-03-02 22:22:52 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.6344989538192749 norm:0.0003278774383943528 max memory_allocated 29274.06298828125 
[2025-03-02 22:23:41 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.6343742609024048 norm:0.0003319582901895046 max memory_allocated 29274.06298828125 
[2025-03-02 22:24:31 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.6342117190361023 norm:0.0003365529701113701 max memory_allocated 29274.06298828125 
[2025-03-02 22:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.6341031789779663 norm:0.00034321725252084434 max memory_allocated 29274.06298828125 
[2025-03-02 22:26:11 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.6339820623397827 norm:0.0003445864131208509 max memory_allocated 29274.06298828125 
[2025-03-02 22:27:01 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.6338714957237244 norm:0.00034935539588332176 max memory_allocated 29274.06298828125 
[2025-03-02 22:27:51 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.6337771415710449 norm:0.00034432276152074337 max memory_allocated 29274.06298828125 
[2025-03-02 22:28:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:28:59 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.7588255405426025 norm:0.003598479088395834 max memory_allocated 29274.25048828125 
[2025-03-02 22:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.7346569299697876 norm:0.0017333942232653499 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.712626576423645 norm:0.0010121299419552088 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.7064062356948853 norm:0.0007082195952534676 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:18 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.7047961354255676 norm:0.0005685457726940513 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:08 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.7040651440620422 norm:0.0004967133281752467 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:58 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.7035132050514221 norm:0.0004482124641072005 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:47 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.7030506730079651 norm:0.0004143807746004313 max memory_allocated 29274.25048828125 
[2025-03-02 22:35:37 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.7027058601379395 norm:0.0003967236843891442 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:27 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.7023566961288452 norm:0.00038525121635757387 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.7020529508590698 norm:0.00037677871296182275 max memory_allocated 29274.25048828125 
[2025-03-02 22:38:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.7018045783042908 norm:0.00036648244713433087 max memory_allocated 29274.25048828125 
[2025-03-02 22:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.7016283869743347 norm:0.0003580742923077196 max memory_allocated 29274.25048828125 
[2025-03-02 22:39:46 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.7014380693435669 norm:0.00035415607271716 max memory_allocated 29274.25048828125 
[2025-03-02 22:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.7012507915496826 norm:0.0003544374485500157 max memory_allocated 29274.25048828125 
[2025-03-02 22:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.7010974884033203 norm:0.00034960859920829535 max memory_allocated 29274.25048828125 
[2025-03-02 22:42:16 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.7009158134460449 norm:0.0003477716527413577 max memory_allocated 29274.25048828125 
[2025-03-02 22:43:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.7007572054862976 norm:0.00034849278745241463 max memory_allocated 29274.25048828125 
[2025-03-02 22:43:55 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.7006217241287231 norm:0.0003481572202872485 max memory_allocated 29274.25048828125 
[2025-03-02 22:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.7005120515823364 norm:0.00034435177803970873 max memory_allocated 29274.25048828125 
[2025-03-02 22:45:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:45:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.8384634256362915 norm:0.006695908959954977 max memory_allocated 29274.43798828125 
[2025-03-02 22:46:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.8097859025001526 norm:0.003390854923054576 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.7854235768318176 norm:0.0020104667637497187 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:23 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.7787835001945496 norm:0.0013607244472950697 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:13 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.7768286466598511 norm:0.001023309538140893 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.7759151458740234 norm:0.0008310548146255314 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.7751618027687073 norm:0.0007078171474859118 max memory_allocated 29274.43798828125 
[2025-03-02 22:51:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.7745336890220642 norm:0.0006225283723324537 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:32 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.7740800976753235 norm:0.0005764384986832738 max memory_allocated 29274.43798828125 
[2025-03-02 22:53:22 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.773766040802002 norm:0.0005308565450832248 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:12 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.773501992225647 norm:0.0005128644406795502 max memory_allocated 29274.43798828125 
[2025-03-02 22:55:02 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.773187518119812 norm:0.0004958714707754552 max memory_allocated 29274.43798828125 
[2025-03-02 22:55:52 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.7728743553161621 norm:0.00048122642328962684 max memory_allocated 29274.43798828125 
[2025-03-02 22:56:42 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.7726261615753174 norm:0.0004708153719548136 max memory_allocated 29274.43798828125 
[2025-03-02 22:57:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.7724224925041199 norm:0.0004677542601712048 max memory_allocated 29274.43798828125 
[2025-03-02 22:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.7722552418708801 norm:0.0004558655491564423 max memory_allocated 29274.43798828125 
[2025-03-02 22:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.7721235752105713 norm:0.00045134275569580495 max memory_allocated 29274.43798828125 
[2025-03-02 23:00:01 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.771915853023529 norm:0.00045260824845172465 max memory_allocated 29274.43798828125 
[2025-03-02 23:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.7717262506484985 norm:0.00044576876098290086 max memory_allocated 29274.43798828125 
[2025-03-02 23:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.77165687084198 norm:0.00044379231985658407 max memory_allocated 29274.43798828125 
[2025-03-02 23:01:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 23:01:59 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.9145729541778564 norm:0.017740923911333084 max memory_allocated 29274.77001953125 
[2025-03-02 23:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.8858963847160339 norm:0.01428178045898676 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:29 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.8595930933952332 norm:0.010917449370026588 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:19 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.8530862331390381 norm:0.009335008449852467 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.8511085510253906 norm:0.007791934534907341 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.8496530055999756 norm:0.0066565717570483685 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.8487339019775391 norm:0.005865694954991341 max memory_allocated 29274.77001953125 
[2025-03-02 23:08:40 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.8481330871582031 norm:0.005363765638321638 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:30 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.8474701046943665 norm:0.005080658942461014 max memory_allocated 29274.77001953125 
[2025-03-02 23:10:20 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.8470396995544434 norm:0.004938589408993721 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.8467366695404053 norm:0.004928498528897762 max memory_allocated 29274.77001953125 
[2025-03-02 23:12:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.8461779356002808 norm:0.005081991199404001 max memory_allocated 29274.77001953125 
[2025-03-02 23:12:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.8455525636672974 norm:0.004760353825986385 max memory_allocated 29274.77001953125 
[2025-03-02 23:13:40 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.8451980948448181 norm:0.0045169624499976635 max memory_allocated 29274.77001953125 
[2025-03-02 23:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.8450101613998413 norm:0.004445802420377731 max memory_allocated 29274.77001953125 
[2025-03-02 23:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.8447182178497314 norm:0.004575266037136316 max memory_allocated 29274.77001953125 
[2025-03-02 23:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.844541609287262 norm:0.004409980960190296 max memory_allocated 29274.77001953125 
[2025-03-02 23:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.8441833257675171 norm:0.004377426113933325 max memory_allocated 29274.77001953125 
[2025-03-02 23:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.8442636132240295 norm:0.004309173673391342 max memory_allocated 29274.77001953125 
[2025-03-02 23:18:41 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.8441014885902405 norm:0.004575878847390413 max memory_allocated 29274.77001953125 
[2025-03-02 23:18:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:18:59 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:19:49 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:1.0578569173812866 norm:0.02267148159444332 max memory_allocated 29274.95751953125 
[2025-03-02 23:20:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:1.012959599494934 norm:0.012059985660016537 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.9740067720413208 norm:0.011788709089159966 max memory_allocated 29274.95751953125 
[2025-03-02 23:22:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.9651365280151367 norm:0.011800497770309448 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.9620978832244873 norm:0.011435197666287422 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.960425615310669 norm:0.010240375995635986 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:49 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.9590352773666382 norm:0.009153343737125397 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.9580104947090149 norm:0.008189631626009941 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:30 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.9572219848632812 norm:0.007796776480972767 max memory_allocated 29274.95751953125 
[2025-03-02 23:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.9565797448158264 norm:0.007289030123502016 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.9560443758964539 norm:0.006650341209024191 max memory_allocated 29274.95751953125 
[2025-03-02 23:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.9556028246879578 norm:0.006397007964551449 max memory_allocated 29274.95751953125 
[2025-03-02 23:29:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.95514976978302 norm:0.006090245209634304 max memory_allocated 29274.95751953125 
[2025-03-02 23:30:40 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.955346405506134 norm:0.006246879231184721 max memory_allocated 29274.95751953125 
[2025-03-02 23:31:30 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.9547135829925537 norm:0.006300618872046471 max memory_allocated 29274.95751953125 
[2025-03-02 23:32:20 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.9541492462158203 norm:0.00646257447078824 max memory_allocated 29274.95751953125 
[2025-03-02 23:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.9540363550186157 norm:0.00644560344517231 max memory_allocated 29274.95751953125 
[2025-03-02 23:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.9536033272743225 norm:0.006360478699207306 max memory_allocated 29274.95751953125 
[2025-03-02 23:34:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.9535444378852844 norm:0.006428932771086693 max memory_allocated 29274.95751953125 
[2025-03-02 23:35:40 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.9533360004425049 norm:0.006261696573346853 max memory_allocated 29274.95751953125 
[2025-03-02 23:35:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:35:59 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:1.3570244312286377 norm:0.058147672563791275 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:1.2794804573059082 norm:0.0399593748152256 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:29 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:1.2239043712615967 norm:0.028768766671419144 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:1.2034893035888672 norm:0.024464668706059456 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:1.1929696798324585 norm:0.021532326936721802 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:1.185487985610962 norm:0.01895143836736679 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:1.1799449920654297 norm:0.017500920221209526 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:1.176555871963501 norm:0.016776418313384056 max memory_allocated 29275.14501953125 
[2025-03-02 23:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:1.1733222007751465 norm:0.015656445175409317 max memory_allocated 29275.14501953125 
[2025-03-02 23:44:18 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:1.170845627784729 norm:0.015289047732949257 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:1.1694234609603882 norm:0.01498761959373951 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:1.1677371263504028 norm:0.014211864210665226 max memory_allocated 29275.14501953125 
[2025-03-02 23:46:48 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:1.166806936264038 norm:0.014059223234653473 max memory_allocated 29275.14501953125 
[2025-03-02 23:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:1.166239857673645 norm:0.013834428042173386 max memory_allocated 29275.14501953125 
[2025-03-02 23:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:1.1657776832580566 norm:0.013572180643677711 max memory_allocated 29275.14501953125 
[2025-03-02 23:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:1.1653320789337158 norm:0.013411767780780792 max memory_allocated 29275.14501953125 
[2025-03-02 23:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:1.1645219326019287 norm:0.013282515108585358 max memory_allocated 29275.14501953125 
[2025-03-02 23:50:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:1.16343355178833 norm:0.01228038314729929 max memory_allocated 29275.14501953125 
[2025-03-02 23:51:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:1.162517786026001 norm:0.011409612372517586 max memory_allocated 29275.14501953125 
[2025-03-02 23:52:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:1.1624146699905396 norm:0.011914324015378952 max memory_allocated 29275.14501953125 
[2025-03-02 23:52:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:52:57 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:2.19608473777771 norm:0.11694642901420593 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:2.0525529384613037 norm:0.07534544914960861 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:1.9484564065933228 norm:0.04342805594205856 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:17 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:1.918019413948059 norm:0.03918202221393585 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:1.900748372077942 norm:0.03812125697731972 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:1.890323281288147 norm:0.03858555853366852 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:47 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:1.880104422569275 norm:0.037589818239212036 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:1.8687721490859985 norm:0.03892172500491142 max memory_allocated 29275.33251953125 
[2025-03-03 00:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:1.860827088356018 norm:0.03908659517765045 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:17 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:1.856293797492981 norm:0.03936149924993515 max memory_allocated 29275.33251953125 
[2025-03-03 00:02:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:1.8558034896850586 norm:0.04215935617685318 max memory_allocated 29275.33251953125 
[2025-03-03 00:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:1.8540680408477783 norm:0.04234742745757103 max memory_allocated 29275.33251953125 
[2025-03-03 00:03:47 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:1.8505765199661255 norm:0.03907668963074684 max memory_allocated 29275.33251953125 
[2025-03-03 00:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:1.8460670709609985 norm:0.03700563311576843 max memory_allocated 29275.33251953125 
[2025-03-03 00:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:1.8431127071380615 norm:0.03754754364490509 max memory_allocated 29275.33251953125 
[2025-03-03 00:06:17 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:1.8417997360229492 norm:0.0367518849670887 max memory_allocated 29275.33251953125 
[2025-03-03 00:07:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:1.8401037454605103 norm:0.03705539181828499 max memory_allocated 29275.33251953125 
[2025-03-03 00:07:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:1.8404207229614258 norm:0.03753960132598877 max memory_allocated 29275.33251953125 
[2025-03-03 00:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:1.8384751081466675 norm:0.03664201498031616 max memory_allocated 29275.33251953125 
[2025-03-03 00:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:1.8382599353790283 norm:0.037945643067359924 max memory_allocated 29275.33251953125 
[2025-03-03 00:09:52 root] (main_calib_config2.py 372): INFO 40641.305314302444
[2025-03-03 00:10:02 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:11:59 root] (main_calib_config2.py 159): INFO wikitext2 : 5.368282794952393
[2025-03-03 00:11:59 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:15:00 root] (main_calib_config2.py 159): INFO c4 : 6.9527201652526855
[2025-03-03 02:15:32 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.368282794952393, 'c4': 6.9527201652526855, 'results': {'boolq': {'acc': 0.6642201834862386, 'acc_stderr': 0.008259920504139576}, 'piqa': {'acc': 0.7780195865070729, 'acc_stderr': 0.009696120744662026, 'acc_norm': 0.7899891186071817, 'acc_norm_stderr': 0.00950335330581858}, 'arc_easy': {'acc': 0.726010101010101, 'acc_stderr': 0.009151805901544017, 'acc_norm': 0.5858585858585859, 'acc_norm_stderr': 0.010107387673002515}, 'hellaswag': {'acc': 0.5765783708424617, 'acc_stderr': 0.004930911515084789, 'acc_norm': 0.7475602469627565, 'acc_norm_stderr': 0.0043352434344868275}, 'arc_challenge': {'acc': 0.4308873720136519, 'acc_stderr': 0.014471133392642471, 'acc_norm': 0.4334470989761092, 'acc_norm_stderr': 0.014481376224558896}, 'winogrande': {'acc': 0.6827150749802684, 'acc_stderr': 0.013080598411332125}}, 'versions': {'boolq': 1, 'piqa': 0, 'arc_easy': 0, 'hellaswag': 0, 'arc_challenge': 0, 'winogrande': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
