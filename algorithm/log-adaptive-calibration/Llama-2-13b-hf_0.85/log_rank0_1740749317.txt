[2025-02-28 13:28:37 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.85', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.85.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:28:46 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:28:46 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:28:47 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:28:47 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.85.pkl
[2025-02-28 13:28:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:29:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.006509814877063036 norm:0.01168204564601183 max memory_allocated 29271.02001953125 
[2025-02-28 13:30:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.003579376731067896 norm:0.006682621780782938 max memory_allocated 29271.02001953125 
[2025-02-28 13:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0029958924278616905 norm:0.005195687524974346 max memory_allocated 29271.02001953125 
[2025-02-28 13:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.00269558047875762 norm:0.004146229475736618 max memory_allocated 29271.02001953125 
[2025-02-28 13:32:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.002493839943781495 norm:0.0034108080435544252 max memory_allocated 29271.02001953125 
[2025-02-28 13:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.002383796265348792 norm:0.002825790084898472 max memory_allocated 29271.02001953125 
[2025-02-28 13:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0022070189006626606 norm:0.0022159649524837732 max memory_allocated 29271.02001953125 
[2025-02-28 13:35:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.002154208952561021 norm:0.001996826846152544 max memory_allocated 29271.02001953125 
[2025-02-28 13:35:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.002218365203589201 norm:0.0018851794302463531 max memory_allocated 29271.02001953125 
[2025-02-28 13:36:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.002118071774020791 norm:0.001612937543541193 max memory_allocated 29271.02001953125 
[2025-02-28 13:37:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0020931661128997803 norm:0.001412676996551454 max memory_allocated 29271.02001953125 
[2025-02-28 13:38:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.002091404516249895 norm:0.0014193210517987609 max memory_allocated 29271.02001953125 
[2025-02-28 13:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0019615450873970985 norm:0.0011253771372139454 max memory_allocated 29271.02001953125 
[2025-02-28 13:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.001980625791475177 norm:0.0010509464191272855 max memory_allocated 29271.02001953125 
[2025-02-28 13:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001983711263164878 norm:0.0010247613536193967 max memory_allocated 29271.02001953125 
[2025-02-28 13:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.001959980931133032 norm:0.0009997168090194464 max memory_allocated 29271.02001953125 
[2025-02-28 13:42:01 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.00192761211656034 norm:0.000930356327444315 max memory_allocated 29271.02001953125 
[2025-02-28 13:42:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.00194416637532413 norm:0.0009498932049609721 max memory_allocated 29271.02001953125 
[2025-02-28 13:43:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0020899823866784573 norm:0.0010334181133657694 max memory_allocated 29271.02001953125 
[2025-02-28 13:44:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0020113401114940643 norm:0.0009914740221574903 max memory_allocated 29271.02001953125 
[2025-02-28 13:44:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:44:35 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:45:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.008301641792058945 norm:0.0041242302395403385 max memory_allocated 29271.02001953125 
[2025-02-28 13:46:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.006071345414966345 norm:0.004085123538970947 max memory_allocated 29271.02001953125 
[2025-02-28 13:46:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.005439251195639372 norm:0.0030466995667666197 max memory_allocated 29271.02001953125 
[2025-02-28 13:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.0051492610946297646 norm:0.002609172835946083 max memory_allocated 29271.02001953125 
[2025-02-28 13:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.004958005156368017 norm:0.0022585687693208456 max memory_allocated 29271.02001953125 
[2025-02-28 13:49:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.004848896525800228 norm:0.002051673596724868 max memory_allocated 29271.02001953125 
[2025-02-28 13:49:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.00475055817514658 norm:0.0018359513487666845 max memory_allocated 29271.02001953125 
[2025-02-28 13:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.00467668054625392 norm:0.0016073313308879733 max memory_allocated 29271.02001953125 
[2025-02-28 13:51:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.004607570823282003 norm:0.0013913585571572185 max memory_allocated 29271.02001953125 
[2025-02-28 13:52:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.004544162657111883 norm:0.001286470564082265 max memory_allocated 29271.02001953125 
[2025-02-28 13:53:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.0044643571600317955 norm:0.0011151251383125782 max memory_allocated 29271.02001953125 
[2025-02-28 13:53:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.004402650520205498 norm:0.0009542736224830151 max memory_allocated 29271.02001953125 
[2025-02-28 13:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.004334632307291031 norm:0.0008211296517401934 max memory_allocated 29271.02001953125 
[2025-02-28 13:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.004278413485735655 norm:0.0006615142337977886 max memory_allocated 29271.02001953125 
[2025-02-28 13:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.004255416337400675 norm:0.0008049131138250232 max memory_allocated 29271.02001953125 
[2025-02-28 13:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.004222103860229254 norm:0.0008497701492160559 max memory_allocated 29271.02001953125 
[2025-02-28 13:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.0042144423350691795 norm:0.0008586436160840094 max memory_allocated 29271.02001953125 
[2025-02-28 13:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.0042273555882275105 norm:0.0008637916180305183 max memory_allocated 29271.02001953125 
[2025-02-28 13:59:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004200785420835018 norm:0.0008365375106222928 max memory_allocated 29271.02001953125 
[2025-02-28 13:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.004165647551417351 norm:0.0007736781262792647 max memory_allocated 29271.02001953125 
[2025-02-28 14:00:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 14:00:10 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 14:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.01548723503947258 norm:0.009122041054069996 max memory_allocated 29271.02001953125 
[2025-02-28 14:01:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.012817583978176117 norm:0.00779127050191164 max memory_allocated 29271.02001953125 
[2025-02-28 14:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.011810557916760445 norm:0.005932345055043697 max memory_allocated 29271.02001953125 
[2025-02-28 14:03:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.011228188872337341 norm:0.004697462543845177 max memory_allocated 29271.02001953125 
[2025-02-28 14:04:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.010783043690025806 norm:0.003819132223725319 max memory_allocated 29271.02001953125 
[2025-02-28 14:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.010460983030498028 norm:0.003125375136733055 max memory_allocated 29271.02001953125 
[2025-02-28 14:05:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.010136449709534645 norm:0.002616330748423934 max memory_allocated 29271.02001953125 
[2025-02-28 14:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.009922404773533344 norm:0.002404286991804838 max memory_allocated 29271.02001953125 
[2025-02-28 14:07:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.009723708033561707 norm:0.0021314523182809353 max memory_allocated 29271.02001953125 
[2025-02-28 14:07:50 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.009596279822289944 norm:0.0019073435105383396 max memory_allocated 29271.02001953125 
[2025-02-28 14:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.009522635489702225 norm:0.0017693605041131377 max memory_allocated 29271.02001953125 
[2025-02-28 14:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.009495016187429428 norm:0.0017709636595100164 max memory_allocated 29271.02001953125 
[2025-02-28 14:10:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.009515066631138325 norm:0.001804587198421359 max memory_allocated 29271.02001953125 
[2025-02-28 14:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.009515992365777493 norm:0.001704629510641098 max memory_allocated 29271.02001953125 
[2025-02-28 14:11:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.0095040462911129 norm:0.001661614398472011 max memory_allocated 29271.02001953125 
[2025-02-28 14:12:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.009476397186517715 norm:0.0016106701223179698 max memory_allocated 29271.02001953125 
[2025-02-28 14:13:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.009465445764362812 norm:0.0015806324081495404 max memory_allocated 29271.02001953125 
[2025-02-28 14:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.009471254423260689 norm:0.0015485372859984636 max memory_allocated 29271.02001953125 
[2025-02-28 14:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.009420068003237247 norm:0.001434121048077941 max memory_allocated 29271.02001953125 
[2025-02-28 14:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.009396681562066078 norm:0.0013182739494368434 max memory_allocated 29271.02001953125 
[2025-02-28 14:15:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 14:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.11283297091722488 norm:0.01750127598643303 max memory_allocated 29271.43798828125 
[2025-02-28 14:17:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.08039596676826477 norm:0.012197963893413544 max memory_allocated 29271.43798828125 
[2025-02-28 14:18:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.06186504289507866 norm:0.011473397724330425 max memory_allocated 29271.43798828125 
[2025-02-28 14:18:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.05622866004705429 norm:0.010946070775389671 max memory_allocated 29271.43798828125 
[2025-02-28 14:19:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.05492089316248894 norm:0.008824080228805542 max memory_allocated 29271.43798828125 
[2025-02-28 14:20:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.05028223991394043 norm:0.0075691454112529755 max memory_allocated 29271.43798828125 
[2025-02-28 14:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.0483805388212204 norm:0.006729931570589542 max memory_allocated 29271.43798828125 
[2025-02-28 14:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.04843427613377571 norm:0.006798082031309605 max memory_allocated 29271.43798828125 
[2025-02-28 14:22:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.0509767010807991 norm:0.007945527322590351 max memory_allocated 29271.43798828125 
[2025-02-28 14:23:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.043841492384672165 norm:0.00551868649199605 max memory_allocated 29271.43798828125 
[2025-02-28 14:24:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.03393638879060745 norm:0.003859246149659157 max memory_allocated 29271.43798828125 
[2025-02-28 14:24:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.03192785754799843 norm:0.0033087264746427536 max memory_allocated 29271.43798828125 
[2025-02-28 14:25:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.03296040743589401 norm:0.0034083568025380373 max memory_allocated 29271.43798828125 
[2025-02-28 14:26:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.031518809497356415 norm:0.002886103466153145 max memory_allocated 29271.43798828125 
[2025-02-28 14:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.030387381091713905 norm:0.0026217414997518063 max memory_allocated 29271.43798828125 
[2025-02-28 14:27:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.031158916652202606 norm:0.0030849818140268326 max memory_allocated 29271.43798828125 
[2025-02-28 14:28:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.031979240477085114 norm:0.0035771189723163843 max memory_allocated 29271.43798828125 
[2025-02-28 14:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.033405549824237823 norm:0.004024614579975605 max memory_allocated 29271.43798828125 
[2025-02-28 14:30:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.035773009061813354 norm:0.004495784640312195 max memory_allocated 29271.43798828125 
[2025-02-28 14:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.036234721541404724 norm:0.004748824518173933 max memory_allocated 29271.43798828125 
[2025-02-28 14:31:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.028951089829206467 norm:0.0006110936519689858 max memory_allocated 29271.43798828125 
[2025-02-28 14:32:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.02643684856593609 norm:0.00026086880825459957 max memory_allocated 29271.43798828125 
[2025-02-28 14:33:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.02547367662191391 norm:0.00014719425234943628 max memory_allocated 29271.43798828125 
[2025-02-28 14:34:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.024956881999969482 norm:0.00011442464892752469 max memory_allocated 29271.43798828125 
[2025-02-28 14:35:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.02449692226946354 norm:9.768197924131528e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:35:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.024121146649122238 norm:8.883928239811212e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:36:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.02387397363781929 norm:8.50851574796252e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.023746130988001823 norm:8.562739822082222e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.02368323504924774 norm:8.569395868107677e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.023648833855986595 norm:8.8162072643172e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.02362382598221302 norm:8.573237573727965e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.023609314113855362 norm:8.577849803259596e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:41:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.023597219958901405 norm:8.775032620178536e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:41:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.023576250299811363 norm:9.499862062511966e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:42:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.023572508245706558 norm:9.763790149008855e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:43:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.02357575297355652 norm:9.547441732138395e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.023568853735923767 norm:9.709299774840474e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:45:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.023551208898425102 norm:9.563273488311097e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:45:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.023539243265986443 norm:9.521080937702209e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.023536209017038345 norm:9.528313239570707e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:46:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.029800914227962494 norm:0.0007692184299230576 max memory_allocated 29271.43798828125 
[2025-02-28 14:48:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.02724742889404297 norm:0.00031612772727385163 max memory_allocated 29271.43798828125 
[2025-02-28 14:49:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.026353873312473297 norm:0.00019733249791897833 max memory_allocated 29271.43798828125 
[2025-02-28 14:49:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.02572261542081833 norm:0.0001461529900552705 max memory_allocated 29271.43798828125 
[2025-02-28 14:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.025173775851726532 norm:0.00011903446284122765 max memory_allocated 29271.43798828125 
[2025-02-28 14:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.02478039264678955 norm:0.00011391491716494784 max memory_allocated 29271.43798828125 
[2025-02-28 14:52:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.02454523742198944 norm:9.955069253919646e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:52:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.024445442482829094 norm:9.920904267346486e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.024399815127253532 norm:9.324894199380651e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.024356171488761902 norm:9.421009599464014e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:55:16 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.024321377277374268 norm:9.018218406708911e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.02430562861263752 norm:9.366870654048398e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:56:47 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.02428402192890644 norm:9.042176679940894e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.02427229844033718 norm:9.423730080015957e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:58:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.024267414584755898 norm:8.907169103622437e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:59:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.024261044338345528 norm:9.000621503219008e-05 max memory_allocated 29271.43798828125 
[2025-02-28 14:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.024250244721770287 norm:9.14237170945853e-05 max memory_allocated 29271.43798828125 
[2025-02-28 15:00:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.0242439117282629 norm:9.38966404646635e-05 max memory_allocated 29271.43798828125 
[2025-02-28 15:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.024233007803559303 norm:9.588142711436376e-05 max memory_allocated 29271.43798828125 
[2025-02-28 15:02:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.024253766983747482 norm:0.00011628828360699117 max memory_allocated 29271.43798828125 
[2025-02-28 15:02:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 15:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.03284279257059097 norm:0.0011306230444461107 max memory_allocated 29272.00048828125 
[2025-02-28 15:03:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.02929317206144333 norm:0.000486302247736603 max memory_allocated 29272.00048828125 
[2025-02-28 15:04:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.027964599430561066 norm:0.0002784044772852212 max memory_allocated 29272.00048828125 
[2025-02-28 15:05:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.02709675393998623 norm:0.0001896163448691368 max memory_allocated 29272.00048828125 
[2025-02-28 15:06:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.026450777426362038 norm:0.0001441158528905362 max memory_allocated 29272.00048828125 
[2025-02-28 15:07:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.026035893708467484 norm:0.00012056808918714523 max memory_allocated 29272.00048828125 
[2025-02-28 15:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.025833364576101303 norm:0.00011567614274099469 max memory_allocated 29272.00048828125 
[2025-02-28 15:08:33 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.02572004310786724 norm:0.00010824869968928397 max memory_allocated 29272.00048828125 
[2025-02-28 15:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.025658603757619858 norm:0.000108638996607624 max memory_allocated 29272.00048828125 
[2025-02-28 15:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.025607556104660034 norm:0.00010032720456365496 max memory_allocated 29272.00048828125 
[2025-02-28 15:10:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.025576574727892876 norm:0.00010759124415926635 max memory_allocated 29272.00048828125 
[2025-02-28 15:11:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.02555151842534542 norm:0.0001013852161122486 max memory_allocated 29272.00048828125 
[2025-02-28 15:12:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.025531234219670296 norm:0.00010321258014300838 max memory_allocated 29272.00048828125 
[2025-02-28 15:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.02552146278321743 norm:0.00011037163494620472 max memory_allocated 29272.00048828125 
[2025-02-28 15:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.025512494146823883 norm:0.00010739410936366767 max memory_allocated 29272.00048828125 
[2025-02-28 15:14:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.025508716702461243 norm:0.00011068857565987855 max memory_allocated 29272.00048828125 
[2025-02-28 15:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.025506440550088882 norm:0.00011996497778454795 max memory_allocated 29272.00048828125 
[2025-02-28 15:16:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.025487670674920082 norm:0.00011167299817316234 max memory_allocated 29272.00048828125 
[2025-02-28 15:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.0254860520362854 norm:0.00012103524204576388 max memory_allocated 29272.00048828125 
[2025-02-28 15:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.025481346994638443 norm:0.00011829975119326264 max memory_allocated 29272.00048828125 
[2025-02-28 15:17:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 15:18:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.03603195399045944 norm:0.0009928802028298378 max memory_allocated 29272.18798828125 
[2025-02-28 15:19:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.0324242040514946 norm:0.0004714207607321441 max memory_allocated 29272.18798828125 
[2025-02-28 15:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.031056836247444153 norm:0.00029883981915190816 max memory_allocated 29272.18798828125 
[2025-02-28 15:21:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.0300491563975811 norm:0.00022182746033649892 max memory_allocated 29272.18798828125 
[2025-02-28 15:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.029390297830104828 norm:0.00019353037350811064 max memory_allocated 29272.18798828125 
[2025-02-28 15:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.02895273081958294 norm:0.0001675684325164184 max memory_allocated 29272.18798828125 
[2025-02-28 15:23:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.028748733922839165 norm:0.0001554550399305299 max memory_allocated 29272.18798828125 
[2025-02-28 15:24:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.02857803925871849 norm:0.0001407774689141661 max memory_allocated 29272.18798828125 
[2025-02-28 15:24:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.02849534898996353 norm:0.00014332619321066886 max memory_allocated 29272.18798828125 
[2025-02-28 15:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.028450321406126022 norm:0.0001418338797520846 max memory_allocated 29272.18798828125 
[2025-02-28 15:26:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.02840915322303772 norm:0.00013321872393134981 max memory_allocated 29272.18798828125 
[2025-02-28 15:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.02840767800807953 norm:0.00014125571760814637 max memory_allocated 29272.18798828125 
[2025-02-28 15:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.02839820273220539 norm:0.00014215699047781527 max memory_allocated 29272.18798828125 
[2025-02-28 15:28:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.02839687466621399 norm:0.00014220421144273132 max memory_allocated 29272.18798828125 
[2025-02-28 15:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.02838396653532982 norm:0.00014451189781539142 max memory_allocated 29272.18798828125 
[2025-02-28 15:30:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.028361186385154724 norm:0.00014133928925730288 max memory_allocated 29272.18798828125 
[2025-02-28 15:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.02835075557231903 norm:0.000136281581944786 max memory_allocated 29272.18798828125 
[2025-02-28 15:31:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.02835347130894661 norm:0.00013479881454259157 max memory_allocated 29272.18798828125 
[2025-02-28 15:32:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.02834577113389969 norm:0.00014056573854759336 max memory_allocated 29272.18798828125 
[2025-02-28 15:33:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.02833934687077999 norm:0.00014077928790356964 max memory_allocated 29272.18798828125 
[2025-02-28 15:33:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 15:34:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.042969003319740295 norm:0.0013116899644955993 max memory_allocated 29272.37548828125 
[2025-02-28 15:35:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.03577110543847084 norm:0.0006114402203820646 max memory_allocated 29272.37548828125 
[2025-02-28 15:35:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.03287515044212341 norm:0.0003574614820536226 max memory_allocated 29272.37548828125 
[2025-02-28 15:36:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.031569432467222214 norm:0.00024866615422070026 max memory_allocated 29272.37548828125 
[2025-02-28 15:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.030861226841807365 norm:0.00019965162209700793 max memory_allocated 29272.37548828125 
[2025-02-28 15:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.030437279492616653 norm:0.00017241929890587926 max memory_allocated 29272.37548828125 
[2025-02-28 15:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.030139900743961334 norm:0.0001557784271426499 max memory_allocated 29272.37548828125 
[2025-02-28 15:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.029967408627271652 norm:0.00015117487055249512 max memory_allocated 29272.37548828125 
[2025-02-28 15:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.029853031039237976 norm:0.00014036562060937285 max memory_allocated 29272.37548828125 
[2025-02-28 15:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.02977505885064602 norm:0.00013410963583737612 max memory_allocated 29272.37548828125 
[2025-02-28 15:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.02970224805176258 norm:0.00012998125748708844 max memory_allocated 29272.37548828125 
[2025-02-28 15:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.029633549973368645 norm:0.00012797018280252814 max memory_allocated 29272.37548828125 
[2025-02-28 15:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.029593680053949356 norm:0.00012243739911355078 max memory_allocated 29272.37548828125 
[2025-02-28 15:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.02959006279706955 norm:0.0001299712312174961 max memory_allocated 29272.37548828125 
[2025-02-28 15:45:03 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.029569953680038452 norm:0.00012097517173970118 max memory_allocated 29272.37548828125 
[2025-02-28 15:45:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.02953976020216942 norm:0.00011956609523622319 max memory_allocated 29272.37548828125 
[2025-02-28 15:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.029518460854887962 norm:0.00011804020323324949 max memory_allocated 29272.37548828125 
[2025-02-28 15:47:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.029493706300854683 norm:0.00011594132229220122 max memory_allocated 29272.37548828125 
[2025-02-28 15:48:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.02947409078478813 norm:0.00011502864072099328 max memory_allocated 29272.37548828125 
[2025-02-28 15:48:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.02945978194475174 norm:0.00011552211799426004 max memory_allocated 29272.37548828125 
[2025-02-28 15:49:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 15:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.0430602952837944 norm:0.0011226224014535546 max memory_allocated 29272.56298828125 
[2025-02-28 15:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.038477443158626556 norm:0.0005837087519466877 max memory_allocated 29272.56298828125 
[2025-02-28 15:51:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.036374740302562714 norm:0.0003711589379236102 max memory_allocated 29272.56298828125 
[2025-02-28 15:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.03501508757472038 norm:0.0002569273638073355 max memory_allocated 29272.56298828125 
[2025-02-28 15:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.0341167114675045 norm:0.00019772986706811935 max memory_allocated 29272.56298828125 
[2025-02-28 15:53:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.033609963953495026 norm:0.00016927512479014695 max memory_allocated 29272.56298828125 
[2025-02-28 15:54:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.03335563465952873 norm:0.00015558526501990855 max memory_allocated 29272.56298828125 
[2025-02-28 15:55:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.033230192959308624 norm:0.00015726203855592757 max memory_allocated 29272.56298828125 
[2025-02-28 15:56:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.033146005123853683 norm:0.00014713936252519488 max memory_allocated 29272.56298828125 
[2025-02-28 15:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.0331011638045311 norm:0.0001477127952966839 max memory_allocated 29272.56298828125 
[2025-02-28 15:57:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.033046334981918335 norm:0.00014040389214642346 max memory_allocated 29272.56298828125 
[2025-02-28 15:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.03300526365637779 norm:0.00014260537864174694 max memory_allocated 29272.56298828125 
[2025-02-28 15:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.03297337517142296 norm:0.000137072303914465 max memory_allocated 29272.56298828125 
[2025-02-28 15:59:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.032978300005197525 norm:0.00015322776744142175 max memory_allocated 29272.56298828125 
[2025-02-28 16:00:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.03294519707560539 norm:0.00013612238399218768 max memory_allocated 29272.56298828125 
[2025-02-28 16:01:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.03293915092945099 norm:0.00013872042472939938 max memory_allocated 29272.56298828125 
[2025-02-28 16:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.03294375166296959 norm:0.00013793969992548227 max memory_allocated 29272.56298828125 
[2025-02-28 16:02:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.03295522928237915 norm:0.0001357342698611319 max memory_allocated 29272.56298828125 
[2025-02-28 16:03:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.03294499218463898 norm:0.00014481125981546938 max memory_allocated 29272.56298828125 
[2025-02-28 16:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.03293493390083313 norm:0.00014052607002668083 max memory_allocated 29272.56298828125 
[2025-02-28 16:04:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 16:05:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.0457032211124897 norm:0.0013075221795588732 max memory_allocated 29272.75048828125 
[2025-02-28 16:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.04062793031334877 norm:0.0006577665917575359 max memory_allocated 29272.75048828125 
[2025-02-28 16:07:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.03842346370220184 norm:0.00039131048833951354 max memory_allocated 29272.75048828125 
[2025-02-28 16:07:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.03713442385196686 norm:0.0002684566716197878 max memory_allocated 29272.75048828125 
[2025-02-28 16:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.03627358376979828 norm:0.00020144792506471276 max memory_allocated 29272.75048828125 
[2025-02-28 16:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.035814665257930756 norm:0.00016804529877845198 max memory_allocated 29272.75048828125 
[2025-02-28 16:10:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.035576216876506805 norm:0.00015470932703465223 max memory_allocated 29272.75048828125 
[2025-02-28 16:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.03541624918580055 norm:0.0001395656290696934 max memory_allocated 29272.75048828125 
[2025-02-28 16:11:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.03532521426677704 norm:0.00013074997696094215 max memory_allocated 29272.75048828125 
[2025-02-28 16:12:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.03525156155228615 norm:0.00012550523388199508 max memory_allocated 29272.75048828125 
[2025-02-28 16:13:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.03520365059375763 norm:0.00012242696539033204 max memory_allocated 29272.75048828125 
[2025-02-28 16:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.035166140645742416 norm:0.00011742196511477232 max memory_allocated 29272.75048828125 
[2025-02-28 16:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.035137519240379333 norm:0.00011753025319194421 max memory_allocated 29272.75048828125 
[2025-02-28 16:15:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.03510195389389992 norm:0.00011379145871615037 max memory_allocated 29272.75048828125 
[2025-02-28 16:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.03508402034640312 norm:0.00010996755008818582 max memory_allocated 29272.75048828125 
[2025-02-28 16:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.03506023436784744 norm:0.00010882822971325368 max memory_allocated 29272.75048828125 
[2025-02-28 16:17:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.03503813594579697 norm:0.00010518066119402647 max memory_allocated 29272.75048828125 
[2025-02-28 16:18:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.03502829372882843 norm:0.00010561027011135593 max memory_allocated 29272.75048828125 
[2025-02-28 16:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.03502635657787323 norm:0.00010461249621585011 max memory_allocated 29272.75048828125 
[2025-02-28 16:20:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.03502148762345314 norm:0.0001071380393113941 max memory_allocated 29272.75048828125 
[2025-02-28 16:20:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 16:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.046829111874103546 norm:0.000859718129504472 max memory_allocated 29272.93798828125 
[2025-02-28 16:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.0423160120844841 norm:0.00041757948929443955 max memory_allocated 29272.93798828125 
[2025-02-28 16:22:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.04037335515022278 norm:0.0002539047272875905 max memory_allocated 29272.93798828125 
[2025-02-28 16:23:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.03928479552268982 norm:0.0001775867713149637 max memory_allocated 29272.93798828125 
[2025-02-28 16:24:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.03856837376952171 norm:0.00014259056479204446 max memory_allocated 29272.93798828125 
[2025-02-28 16:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.03813779726624489 norm:0.0001249122287845239 max memory_allocated 29272.93798828125 
[2025-02-28 16:25:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.03790663555264473 norm:0.00011765532690333202 max memory_allocated 29272.93798828125 
[2025-02-28 16:26:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.03778973966836929 norm:0.00011503166751936078 max memory_allocated 29272.93798828125 
[2025-02-28 16:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.0377131849527359 norm:0.00011305155931040645 max memory_allocated 29272.93798828125 
[2025-02-28 16:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.037669990211725235 norm:0.00010947056580334902 max memory_allocated 29272.93798828125 
[2025-02-28 16:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.03763560950756073 norm:0.00010538796777836978 max memory_allocated 29272.93798828125 
[2025-02-28 16:29:31 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.037589989602565765 norm:0.00010455377196194604 max memory_allocated 29272.93798828125 
[2025-02-28 16:30:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.03755682334303856 norm:0.0001029006380122155 max memory_allocated 29272.93798828125 
[2025-02-28 16:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.03753075748682022 norm:0.00010191135515924543 max memory_allocated 29272.93798828125 
[2025-02-28 16:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.037501633167266846 norm:0.0001003231736831367 max memory_allocated 29272.93798828125 
[2025-02-28 16:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.03748590126633644 norm:0.00010203114652540535 max memory_allocated 29272.93798828125 
[2025-02-28 16:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.03747928887605667 norm:9.913161193253472e-05 max memory_allocated 29272.93798828125 
[2025-02-28 16:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.03747529536485672 norm:0.00010202790872426704 max memory_allocated 29272.93798828125 
[2025-02-28 16:34:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.03747006505727768 norm:9.510610107099637e-05 max memory_allocated 29272.93798828125 
[2025-02-28 16:35:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.03744468837976456 norm:9.267764835385606e-05 max memory_allocated 29272.93798828125 
[2025-02-28 16:35:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 16:36:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.04865793138742447 norm:0.0008148349588736892 max memory_allocated 29273.12548828125 
[2025-02-28 16:37:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.0437290295958519 norm:0.0003884101170115173 max memory_allocated 29273.12548828125 
[2025-02-28 16:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.041884277015924454 norm:0.00024990487145259976 max memory_allocated 29273.12548828125 
[2025-02-28 16:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.04080141708254814 norm:0.00018629386613611132 max memory_allocated 29273.12548828125 
[2025-02-28 16:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.040078964084386826 norm:0.00014955358346924186 max memory_allocated 29273.12548828125 
[2025-02-28 16:40:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.03963099792599678 norm:0.00013164467236492783 max memory_allocated 29273.12548828125 
[2025-02-28 16:41:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.03939744085073471 norm:0.00011992373765679076 max memory_allocated 29273.12548828125 
[2025-02-28 16:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.03926806151866913 norm:0.00011346190149197355 max memory_allocated 29273.12548828125 
[2025-02-28 16:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.0391821451485157 norm:0.00011158006964251399 max memory_allocated 29273.12548828125 
[2025-02-28 16:43:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.039129987359046936 norm:0.00010523837408982217 max memory_allocated 29273.12548828125 
[2025-02-28 16:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.03908611834049225 norm:0.00010288351040799171 max memory_allocated 29273.12548828125 
[2025-02-28 16:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.0390474759042263 norm:0.00010189101158175617 max memory_allocated 29273.12548828125 
[2025-02-28 16:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.039023153483867645 norm:0.00010073035809909925 max memory_allocated 29273.12548828125 
[2025-02-28 16:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.03899332880973816 norm:9.574665455147624e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:47:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.038971226662397385 norm:9.354986104881391e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.038943998515605927 norm:9.301461250288412e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.03893107920885086 norm:9.198740735882893e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.038907092064619064 norm:8.898939267965034e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:50:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.03890157863497734 norm:8.925810834625736e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.038893237709999084 norm:8.85474873939529e-05 max memory_allocated 29273.12548828125 
[2025-02-28 16:51:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 16:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.049805521965026855 norm:0.0008651690441183746 max memory_allocated 29273.31298828125 
[2025-02-28 16:53:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.045597538352012634 norm:0.0004602147964760661 max memory_allocated 29273.31298828125 
[2025-02-28 16:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.04364597052335739 norm:0.0002961579884868115 max memory_allocated 29273.31298828125 
[2025-02-28 16:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.042507294565439224 norm:0.00022036118025425822 max memory_allocated 29273.31298828125 
[2025-02-28 16:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.04175495728850365 norm:0.00017785961972549558 max memory_allocated 29273.31298828125 
[2025-02-28 16:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.041293032467365265 norm:0.0001607052399776876 max memory_allocated 29273.31298828125 
[2025-02-28 16:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.04103399068117142 norm:0.0001379596214974299 max memory_allocated 29273.31298828125 
[2025-02-28 16:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.040871817618608475 norm:0.00012880531721748412 max memory_allocated 29273.31298828125 
[2025-02-28 16:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.04077766835689545 norm:0.00012590858386829495 max memory_allocated 29273.31298828125 
[2025-02-28 16:59:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.040696561336517334 norm:0.00011770220589824021 max memory_allocated 29273.31298828125 
[2025-02-28 16:59:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.04064604640007019 norm:0.00011399583308957517 max memory_allocated 29273.31298828125 
[2025-02-28 17:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.040601909160614014 norm:0.00011440330126788467 max memory_allocated 29273.31298828125 
[2025-02-28 17:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.04055606946349144 norm:0.00010737049888120964 max memory_allocated 29273.31298828125 
[2025-02-28 17:02:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.040527984499931335 norm:0.00010365814523538575 max memory_allocated 29273.31298828125 
[2025-02-28 17:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.04050207883119583 norm:0.00010007053788285702 max memory_allocated 29273.31298828125 
[2025-02-28 17:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.04047726094722748 norm:9.842984582064673e-05 max memory_allocated 29273.31298828125 
[2025-02-28 17:04:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.04044702649116516 norm:9.186012175632641e-05 max memory_allocated 29273.31298828125 
[2025-02-28 17:05:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.04043210297822952 norm:8.983620500657707e-05 max memory_allocated 29273.31298828125 
[2025-02-28 17:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.04041747748851776 norm:8.768159023020416e-05 max memory_allocated 29273.31298828125 
[2025-02-28 17:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.040403757244348526 norm:8.772263390710577e-05 max memory_allocated 29273.31298828125 
[2025-02-28 17:07:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 17:07:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.05068911612033844 norm:0.0008554690866731107 max memory_allocated 29273.50048828125 
[2025-02-28 17:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.04659341275691986 norm:0.00043734227074310184 max memory_allocated 29273.50048828125 
[2025-02-28 17:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.04482272267341614 norm:0.0002719628973864019 max memory_allocated 29273.50048828125 
[2025-02-28 17:10:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.04382902383804321 norm:0.0001971041492652148 max memory_allocated 29273.50048828125 
[2025-02-28 17:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.04314481467008591 norm:0.00016435621364507824 max memory_allocated 29273.50048828125 
[2025-02-28 17:11:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.04269014298915863 norm:0.00014302930503617972 max memory_allocated 29273.50048828125 
[2025-02-28 17:12:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.04241553694009781 norm:0.00013276909885462373 max memory_allocated 29273.50048828125 
[2025-02-28 17:13:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.042269881814718246 norm:0.0001274122332688421 max memory_allocated 29273.50048828125 
[2025-02-28 17:13:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.04216460511088371 norm:0.0001225099404109642 max memory_allocated 29273.50048828125 
[2025-02-28 17:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.04210078716278076 norm:0.00011858902871608734 max memory_allocated 29273.50048828125 
[2025-02-28 17:15:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.04203573241829872 norm:0.00011081373668275774 max memory_allocated 29273.50048828125 
[2025-02-28 17:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.0419924221932888 norm:0.00010665586160030216 max memory_allocated 29273.50048828125 
[2025-02-28 17:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.04194580763578415 norm:0.00010377804574090987 max memory_allocated 29273.50048828125 
[2025-02-28 17:17:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.041917718946933746 norm:0.00010379969171481207 max memory_allocated 29273.50048828125 
[2025-02-28 17:18:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.0418953076004982 norm:9.837793186306953e-05 max memory_allocated 29273.50048828125 
[2025-02-28 17:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.04187137633562088 norm:9.490119555266574e-05 max memory_allocated 29273.50048828125 
[2025-02-28 17:20:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.04184870049357414 norm:9.278230572817847e-05 max memory_allocated 29273.50048828125 
[2025-02-28 17:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.04183496907353401 norm:9.270115697290748e-05 max memory_allocated 29273.50048828125 
[2025-02-28 17:21:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.04182293638586998 norm:9.141620830632746e-05 max memory_allocated 29273.50048828125 
[2025-02-28 17:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.04181919991970062 norm:9.256656630896032e-05 max memory_allocated 29273.50048828125 
[2025-02-28 17:22:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 17:23:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.04888707771897316 norm:0.0005951251368969679 max memory_allocated 29273.68798828125 
[2025-02-28 17:24:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.04593629390001297 norm:0.00030831602634862065 max memory_allocated 29273.68798828125 
[2025-02-28 17:24:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.044501323252916336 norm:0.00019747583428397775 max memory_allocated 29273.68798828125 
[2025-02-28 17:25:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.04364452883601189 norm:0.00015260577492881566 max memory_allocated 29273.68798828125 
[2025-02-28 17:26:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.043016012758016586 norm:0.0001286127808270976 max memory_allocated 29273.68798828125 
[2025-02-28 17:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.04259863123297691 norm:0.00011646311759250239 max memory_allocated 29273.68798828125 
[2025-02-28 17:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.04235636442899704 norm:0.00010686829045880586 max memory_allocated 29273.68798828125 
[2025-02-28 17:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.04220292344689369 norm:9.84424987109378e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:29:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.04211917147040367 norm:9.450349898543209e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:30:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.04205988347530365 norm:9.142354247160256e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:31:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.042013004422187805 norm:8.850049925968051e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.04198193550109863 norm:8.603125752415508e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.04195050895214081 norm:8.317681204061955e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.0419214703142643 norm:7.942490628920496e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.04189782962203026 norm:7.762894529150799e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.04187814146280289 norm:7.478040060959756e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:35:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.04187501221895218 norm:7.397626177407801e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:36:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.0418609082698822 norm:7.245194137794897e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:37:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.04185152426362038 norm:7.082088268361986e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:37:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.04184526205062866 norm:7.164119597291574e-05 max memory_allocated 29273.68798828125 
[2025-02-28 17:38:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 17:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.05284646898508072 norm:0.0009678432834334671 max memory_allocated 29273.87548828125 
[2025-02-28 17:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.048250604420900345 norm:0.0004722179437521845 max memory_allocated 29273.87548828125 
[2025-02-28 17:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.046138785779476166 norm:0.0002879102830775082 max memory_allocated 29273.87548828125 
[2025-02-28 17:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.04503779485821724 norm:0.00020342011703178287 max memory_allocated 29273.87548828125 
[2025-02-28 17:42:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.04433254152536392 norm:0.00016958326159510761 max memory_allocated 29273.87548828125 
[2025-02-28 17:42:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.04382305219769478 norm:0.00014878108049742877 max memory_allocated 29273.87548828125 
[2025-02-28 17:43:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.04352786764502525 norm:0.00013299958663992584 max memory_allocated 29273.87548828125 
[2025-02-28 17:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.04336421191692352 norm:0.0001245370804099366 max memory_allocated 29273.87548828125 
[2025-02-28 17:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.043231647461652756 norm:0.00011714351421687752 max memory_allocated 29273.87548828125 
[2025-02-28 17:45:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.04315267503261566 norm:0.00011181039735674858 max memory_allocated 29273.87548828125 
[2025-02-28 17:46:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.043100692331790924 norm:0.00011243732296861708 max memory_allocated 29273.87548828125 
[2025-02-28 17:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.04303745925426483 norm:0.00010695178934838623 max memory_allocated 29273.87548828125 
[2025-02-28 17:48:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.04299497976899147 norm:0.0001048356934916228 max memory_allocated 29273.87548828125 
[2025-02-28 17:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.04295598343014717 norm:0.00010152204049518332 max memory_allocated 29273.87548828125 
[2025-02-28 17:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.04293644428253174 norm:0.00010061314242193475 max memory_allocated 29273.87548828125 
[2025-02-28 17:50:26 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.042911045253276825 norm:0.0001016624883050099 max memory_allocated 29273.87548828125 
[2025-02-28 17:51:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.04288072511553764 norm:9.951762331184e-05 max memory_allocated 29273.87548828125 
[2025-02-28 17:51:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.04284047335386276 norm:9.497202700003982e-05 max memory_allocated 29273.87548828125 
[2025-02-28 17:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.04281504452228546 norm:9.160505578620359e-05 max memory_allocated 29273.87548828125 
[2025-02-28 17:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.04279104992747307 norm:9.025955660035834e-05 max memory_allocated 29273.87548828125 
[2025-02-28 17:53:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 17:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.05167495459318161 norm:0.0010785243939608335 max memory_allocated 29274.06298828125 
[2025-02-28 17:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.04767122119665146 norm:0.0005236676661297679 max memory_allocated 29274.06298828125 
[2025-02-28 17:56:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.045888446271419525 norm:0.0003319049719721079 max memory_allocated 29274.06298828125 
[2025-02-28 17:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.04480382427573204 norm:0.0002371905866311863 max memory_allocated 29274.06298828125 
[2025-02-28 17:57:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.044287122786045074 norm:0.00019409830565564334 max memory_allocated 29274.06298828125 
[2025-02-28 17:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.04392695426940918 norm:0.00016804321785457432 max memory_allocated 29274.06298828125 
[2025-02-28 17:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.043662600219249725 norm:0.0001499755890108645 max memory_allocated 29274.06298828125 
[2025-02-28 17:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.04346199333667755 norm:0.00013489332923199981 max memory_allocated 29274.06298828125 
[2025-02-28 18:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.04335261136293411 norm:0.0001266284816665575 max memory_allocated 29274.06298828125 
[2025-02-28 18:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.04327017813920975 norm:0.00011883985280292109 max memory_allocated 29274.06298828125 
[2025-02-28 18:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.04320477694272995 norm:0.0001114632686949335 max memory_allocated 29274.06298828125 
[2025-02-28 18:02:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.04315739497542381 norm:0.0001062888914020732 max memory_allocated 29274.06298828125 
[2025-02-28 18:03:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.043116386979818344 norm:0.0001032517320709303 max memory_allocated 29274.06298828125 
[2025-02-28 18:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.04306376725435257 norm:9.97199458652176e-05 max memory_allocated 29274.06298828125 
[2025-02-28 18:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.0430387482047081 norm:9.65825529419817e-05 max memory_allocated 29274.06298828125 
[2025-02-28 18:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.0429995022714138 norm:9.253584721591324e-05 max memory_allocated 29274.06298828125 
[2025-02-28 18:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.04299351945519447 norm:9.27931978367269e-05 max memory_allocated 29274.06298828125 
[2025-02-28 18:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.042957790195941925 norm:8.685173816047609e-05 max memory_allocated 29274.06298828125 
[2025-02-28 18:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.042933717370033264 norm:8.20920176920481e-05 max memory_allocated 29274.06298828125 
[2025-02-28 18:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.04292694106698036 norm:8.11105128377676e-05 max memory_allocated 29274.06298828125 
[2025-02-28 18:09:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 18:10:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.050007425248622894 norm:0.0006375660304911435 max memory_allocated 29274.25048828125 
[2025-02-28 18:10:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.04738610237836838 norm:0.0003083559568040073 max memory_allocated 29274.25048828125 
[2025-02-28 18:11:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.04628496244549751 norm:0.0001994750928133726 max memory_allocated 29274.25048828125 
[2025-02-28 18:12:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.045583680272102356 norm:0.00014613110397476703 max memory_allocated 29274.25048828125 
[2025-02-28 18:13:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.04501791670918465 norm:0.00012020115536870435 max memory_allocated 29274.25048828125 
[2025-02-28 18:13:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.04456251114606857 norm:0.00010360485612181947 max memory_allocated 29274.25048828125 
[2025-02-28 18:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.04428859055042267 norm:9.22154140425846e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:15:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.04415033385157585 norm:8.66010450408794e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.044092368334531784 norm:8.216565038310364e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:16:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.04404514282941818 norm:7.810409442754462e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:17:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.044004589319229126 norm:7.491461292374879e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:18:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.043977536261081696 norm:7.28459854144603e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.04394586384296417 norm:7.06052451278083e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:20:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.0439157634973526 norm:6.734444468747824e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.04389405623078346 norm:6.643831147812307e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.04387772083282471 norm:6.540444155689329e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:22:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.04386015236377716 norm:6.415871757781133e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.043852388858795166 norm:6.445301551138982e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.043836016207933426 norm:6.331694748951122e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:24:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.043825045228004456 norm:6.100020982557908e-05 max memory_allocated 29274.25048828125 
[2025-02-28 18:24:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 18:25:41 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.05146164074540138 norm:0.0005388067802414298 max memory_allocated 29274.43798828125 
[2025-02-28 18:26:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.049367327243089676 norm:0.00027492395020090044 max memory_allocated 29274.43798828125 
[2025-02-28 18:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.04829578846693039 norm:0.0001728562783682719 max memory_allocated 29274.43798828125 
[2025-02-28 18:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.047627344727516174 norm:0.00012864414020441473 max memory_allocated 29274.43798828125 
[2025-02-28 18:28:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.04707973450422287 norm:0.00010692100477172062 max memory_allocated 29274.43798828125 
[2025-02-28 18:29:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.04665730521082878 norm:9.678940841695294e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:30:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.04639125242829323 norm:8.894697384675965e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:31:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.04625483602285385 norm:8.295703446492553e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.04618142917752266 norm:7.707603799644858e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.046127431094646454 norm:7.369225204456598e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.04609232395887375 norm:7.015457231318578e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.0460597388446331 norm:6.802737334510311e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:34:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.04602871090173721 norm:6.571812264155596e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:35:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.04600901156663895 norm:6.660085637122393e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:36:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.04598381370306015 norm:6.335331272566691e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:37:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.045969944447278976 norm:6.272246537264436e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:37:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.045971788465976715 norm:6.239356298465282e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.04596337303519249 norm:6.321573164314032e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:39:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.04595233127474785 norm:6.061427484382875e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.04593611881136894 norm:5.935195804340765e-05 max memory_allocated 29274.43798828125 
[2025-02-28 18:40:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 18:41:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.05365634709596634 norm:0.0004785629571415484 max memory_allocated 29274.62548828125 
[2025-02-28 18:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.05161050707101822 norm:0.0002432703913655132 max memory_allocated 29274.62548828125 
[2025-02-28 18:42:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.05063310265541077 norm:0.00015671949950046837 max memory_allocated 29274.62548828125 
[2025-02-28 18:43:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.049982115626335144 norm:0.00011837000056402758 max memory_allocated 29274.62548828125 
[2025-02-28 18:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.04942416399717331 norm:9.86802187981084e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.04898673668503761 norm:8.646796777611598e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.04872637987136841 norm:8.05340678198263e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.048607293516397476 norm:7.55583168938756e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.04854419082403183 norm:7.045708480291069e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:48:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.048517126590013504 norm:6.962625775486231e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.048477478325366974 norm:6.646822293987498e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.04844776540994644 norm:6.310231401585042e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:50:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.048414330929517746 norm:6.217001646291465e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.04839157313108444 norm:5.987445547361858e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:51:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.04838383197784424 norm:5.806199988001026e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.04837680980563164 norm:5.8914873079629615e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.0483662411570549 norm:5.7824538089334965e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.04834520071744919 norm:5.7017819926841184e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.04834531992673874 norm:5.670547398040071e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.04833228513598442 norm:5.5795913795009255e-05 max memory_allocated 29274.62548828125 
[2025-02-28 18:56:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 18:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.058432403951883316 norm:0.0006913784891366959 max memory_allocated 29274.81298828125 
[2025-02-28 18:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.05566536635160446 norm:0.0003527250373736024 max memory_allocated 29274.81298828125 
[2025-02-28 18:58:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.05445804446935654 norm:0.0002215568529209122 max memory_allocated 29274.81298828125 
[2025-02-28 18:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.053718071430921555 norm:0.00016306358156725764 max memory_allocated 29274.81298828125 
[2025-02-28 18:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.05309399589896202 norm:0.0001353828120045364 max memory_allocated 29274.81298828125 
[2025-02-28 19:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.05260167270898819 norm:0.00011846921552205458 max memory_allocated 29274.81298828125 
[2025-02-28 19:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.05231289938092232 norm:0.00010858486348297447 max memory_allocated 29274.81298828125 
[2025-02-28 19:02:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.052155204117298126 norm:0.00010015197767643258 max memory_allocated 29274.81298828125 
[2025-02-28 19:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.05206867679953575 norm:9.396434325026348e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:03:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.052011433988809586 norm:9.007303742691875e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.051957935094833374 norm:8.565702592022717e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.05191429331898689 norm:8.297017484437674e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.05187702551484108 norm:8.007639553397894e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.05185043066740036 norm:7.616579387104139e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.05182548612356186 norm:7.64517899369821e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.05179893225431442 norm:7.227002060972154e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.0517822802066803 norm:6.984344508964568e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.05175720527768135 norm:6.737710646120831e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:10:35 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.05175141245126724 norm:6.591927376575768e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.0517425537109375 norm:6.524830678245053e-05 max memory_allocated 29274.81298828125 
[2025-02-28 19:11:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 19:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.0596214234828949 norm:0.0004911947762593627 max memory_allocated 29275.00048828125 
[2025-02-28 19:13:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.05781492590904236 norm:0.0002485554141458124 max memory_allocated 29275.00048828125 
[2025-02-28 19:13:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.057010307908058167 norm:0.00016270604101009667 max memory_allocated 29275.00048828125 
[2025-02-28 19:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.056416090577840805 norm:0.0001218953839270398 max memory_allocated 29275.00048828125 
[2025-02-28 19:15:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.055961184203624725 norm:0.00010025085794040933 max memory_allocated 29275.00048828125 
[2025-02-28 19:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.05562242120504379 norm:8.853626059135422e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.05541282892227173 norm:8.223089389503002e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.05529208108782768 norm:7.866177475079894e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:18:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.05521237105131149 norm:7.326512422878295e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:19:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.05515735223889351 norm:7.041255594231188e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:20:02 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.05511438474059105 norm:6.720677629346028e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:20:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.055089060217142105 norm:6.641695654252544e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.05505857616662979 norm:7.260862912517041e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:22:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.05503598600625992 norm:6.324987043626606e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.05501919984817505 norm:6.176249007694423e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:23:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.055009812116622925 norm:6.644918903475627e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:24:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.05500100180506706 norm:6.294331251410767e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.05499379336833954 norm:6.309385207714513e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.05499880760908127 norm:6.302604015218094e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.05499313026666641 norm:6.220245995791629e-05 max memory_allocated 29275.00048828125 
[2025-02-28 19:27:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 19:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.06409283727407455 norm:0.0004890481359325349 max memory_allocated 29275.18798828125 
[2025-02-28 19:28:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.062459610402584076 norm:0.0002588176284916699 max memory_allocated 29275.18798828125 
[2025-02-28 19:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.06164504587650299 norm:0.00016889165272004902 max memory_allocated 29275.18798828125 
[2025-02-28 19:30:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.061058640480041504 norm:0.00012646857067011297 max memory_allocated 29275.18798828125 
[2025-02-28 19:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.06059950217604637 norm:0.00010577026114333421 max memory_allocated 29275.18798828125 
[2025-02-28 19:31:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.06022243574261665 norm:9.211395808961242e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:32:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.05999281629920006 norm:8.463759149890393e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:33:18 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.05988225340843201 norm:7.912178989499807e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.05981706082820892 norm:7.512049342039973e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:34:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.059772834181785583 norm:0.00015210334095172584 max memory_allocated 29275.18798828125 
[2025-02-28 19:35:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.059720754623413086 norm:6.635401950916275e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.05968509986996651 norm:6.381898856488988e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:37:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.059663672000169754 norm:6.185364327393472e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.05963596701622009 norm:6.114255666034296e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:38:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.059618327766656876 norm:6.0941609262954444e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:39:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.05961625277996063 norm:6.11661744187586e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.0596044547855854 norm:5.956428140052594e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.059587132185697556 norm:5.960162525298074e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:41:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.05957673490047455 norm:5.926891753915697e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:42:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.05956156551837921 norm:5.998888082103804e-05 max memory_allocated 29275.18798828125 
[2025-02-28 19:42:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 19:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.06912387907505035 norm:0.0004890466807410121 max memory_allocated 29275.37548828125 
[2025-02-28 19:44:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.06763656437397003 norm:0.0002517894608899951 max memory_allocated 29275.37548828125 
[2025-02-28 19:45:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.06683008372783661 norm:0.0001647774042794481 max memory_allocated 29275.37548828125 
[2025-02-28 19:45:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.06623485684394836 norm:0.0001214107614941895 max memory_allocated 29275.37548828125 
[2025-02-28 19:46:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.06569796055555344 norm:9.696545748738572e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.06534015387296677 norm:8.498508395859972e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:48:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.0651705265045166 norm:8.015662024263293e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:48:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.0650918185710907 norm:7.400920003419742e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.06503692269325256 norm:6.754323112545535e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.06500545889139175 norm:6.45291293039918e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:51:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.0649678036570549 norm:6.392500654328614e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:51:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.06495475769042969 norm:6.292365287663415e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.06493618339300156 norm:5.9296333347447217e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.06492042541503906 norm:6.048247087164782e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.0649164542555809 norm:6.077621947042644e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.06492029875516891 norm:6.168769323267043e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.06492514163255692 norm:6.282299000304192e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:56:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.06491461396217346 norm:6.211672007339075e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:57:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.0649045780301094 norm:6.360824772855267e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.06489545106887817 norm:6.446828774642199e-05 max memory_allocated 29275.37548828125 
[2025-02-28 19:58:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 19:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.07455967366695404 norm:0.0004643012653104961 max memory_allocated 29275.56298828125 
[2025-02-28 19:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.07323404401540756 norm:0.000252842582995072 max memory_allocated 29275.56298828125 
[2025-02-28 20:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.07255038619041443 norm:0.0001670618075877428 max memory_allocated 29275.56298828125 
[2025-02-28 20:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.07201199978590012 norm:0.00012488641368690878 max memory_allocated 29275.56298828125 
[2025-02-28 20:02:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.07150474190711975 norm:0.00010309980279998854 max memory_allocated 29275.56298828125 
[2025-02-28 20:02:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.07111212611198425 norm:9.181875793728977e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:03:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.07092178612947464 norm:8.170187356881797e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.070834219455719 norm:7.418420136673376e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.07076312601566315 norm:7.068305421853438e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.0707290917634964 norm:6.902785389684141e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.0707046166062355 norm:6.552379636559635e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.0706772431731224 norm:6.145478982944041e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.07065707445144653 norm:6.0724865761585534e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:09:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.07063527405261993 norm:5.836664786329493e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.0706196054816246 norm:5.833071918459609e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:10:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.07060321420431137 norm:5.7836907217279077e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.07059882581233978 norm:5.703650458599441e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.07058941572904587 norm:5.581270670518279e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:12:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.0705796629190445 norm:5.532325303647667e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:13:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.07057464122772217 norm:5.610460721072741e-05 max memory_allocated 29275.56298828125 
[2025-02-28 20:13:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 20:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.08211648464202881 norm:0.000486631179228425 max memory_allocated 29275.75048828125 
[2025-02-28 20:15:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.0806775763630867 norm:0.0002812347956933081 max memory_allocated 29275.75048828125 
[2025-02-28 20:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.07979881018400192 norm:0.0001914449967443943 max memory_allocated 29275.75048828125 
[2025-02-28 20:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.07904113829135895 norm:0.00013880300684832036 max memory_allocated 29275.75048828125 
[2025-02-28 20:17:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.07838106155395508 norm:0.00011463496775832027 max memory_allocated 29275.75048828125 
[2025-02-28 20:18:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.0779823362827301 norm:0.00010128068242920563 max memory_allocated 29275.75048828125 
[2025-02-28 20:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.07782302051782608 norm:9.275534830521792e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:20:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.07772459089756012 norm:8.514709770679474e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.07767342776060104 norm:8.166744373738766e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:21:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.07763102650642395 norm:7.873341382946819e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.07760221511125565 norm:7.534210453741252e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.0775744840502739 norm:7.166232535382733e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.07755021005868912 norm:7.018022733973339e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:24:39 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.07753878831863403 norm:6.969313835725188e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:25:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.07752493023872375 norm:6.708304135827348e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:26:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.07751055061817169 norm:6.731571193085983e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:26:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.07749908417463303 norm:6.644026871072128e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.07749740034341812 norm:6.82019890518859e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:28:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.07749257981777191 norm:6.64575636619702e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:29:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.07748899608850479 norm:6.682633829768747e-05 max memory_allocated 29275.75048828125 
[2025-02-28 20:29:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 20:30:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.08783121407032013 norm:0.0003161004569847137 max memory_allocated 29275.93798828125 
[2025-02-28 20:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.0867471769452095 norm:0.00018842401914298534 max memory_allocated 29275.93798828125 
[2025-02-28 20:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.08616575598716736 norm:0.0001364148047287017 max memory_allocated 29275.93798828125 
[2025-02-28 20:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.0856262743473053 norm:0.00011132981308037415 max memory_allocated 29275.93798828125 
[2025-02-28 20:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.08506520092487335 norm:9.548088564770296e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.08468564599752426 norm:8.675205026520416e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:34:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.0845225378870964 norm:8.203791367122903e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:35:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.0844336748123169 norm:7.331052620429546e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.08437789976596832 norm:6.829213089076802e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:37:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.0843430608510971 norm:6.773749919375405e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:37:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.08431631326675415 norm:6.449773354688659e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.08429495245218277 norm:6.156973540782928e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:39:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.08427558839321136 norm:6.308250885922462e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.08426007628440857 norm:9.212987060891464e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.08424229174852371 norm:6.0287049564067274e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:41:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.08423393219709396 norm:5.935045919613913e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.08422784507274628 norm:5.9918544138781726e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:43:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.08421411365270615 norm:5.82044267503079e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.08420612663030624 norm:5.8461708249524236e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:44:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.08420497179031372 norm:5.7734261645236984e-05 max memory_allocated 29275.93798828125 
[2025-02-28 20:45:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 20:45:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.09775364398956299 norm:0.0005640624440275133 max memory_allocated 29276.12548828125 
[2025-02-28 20:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.09607051312923431 norm:0.00033181245089508593 max memory_allocated 29276.12548828125 
[2025-02-28 20:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.09507124125957489 norm:0.0002273416321258992 max memory_allocated 29276.12548828125 
[2025-02-28 20:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.09431666880846024 norm:0.00017418006609659642 max memory_allocated 29276.12548828125 
[2025-02-28 20:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.09358412027359009 norm:0.0001405596121912822 max memory_allocated 29276.12548828125 
[2025-02-28 20:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.09320766478776932 norm:0.00012024208263028413 max memory_allocated 29276.12548828125 
[2025-02-28 20:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.0930546373128891 norm:0.00011422540410421789 max memory_allocated 29276.12548828125 
[2025-02-28 20:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.09296442568302155 norm:0.00010625793947838247 max memory_allocated 29276.12548828125 
[2025-02-28 20:51:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.09290468692779541 norm:0.00010018348984885961 max memory_allocated 29276.12548828125 
[2025-02-28 20:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.09286711364984512 norm:0.00010211447806796059 max memory_allocated 29276.12548828125 
[2025-02-28 20:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.09282515943050385 norm:9.354548819828779e-05 max memory_allocated 29276.12548828125 
[2025-02-28 20:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.09278927743434906 norm:9.120568574871868e-05 max memory_allocated 29276.12548828125 
[2025-02-28 20:55:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.09276572614908218 norm:8.747304673306644e-05 max memory_allocated 29276.12548828125 
[2025-02-28 20:55:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.09274821728467941 norm:9.143070201389492e-05 max memory_allocated 29276.12548828125 
[2025-02-28 20:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.09274221211671829 norm:8.685536158736795e-05 max memory_allocated 29276.12548828125 
[2025-02-28 20:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.09273263812065125 norm:8.298535976791754e-05 max memory_allocated 29276.12548828125 
[2025-02-28 20:58:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.09272737801074982 norm:8.565094321966171e-05 max memory_allocated 29276.12548828125 
[2025-02-28 20:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.09270910173654556 norm:7.429628749378026e-05 max memory_allocated 29276.12548828125 
[2025-02-28 20:59:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.09270349144935608 norm:7.42081756470725e-05 max memory_allocated 29276.12548828125 
[2025-02-28 21:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.0927106961607933 norm:7.5802810897585e-05 max memory_allocated 29276.12548828125 
[2025-02-28 21:00:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 21:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.10485275089740753 norm:0.00044029817217960954 max memory_allocated 29276.31298828125 
[2025-02-28 21:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.10373840481042862 norm:0.0002534542581997812 max memory_allocated 29276.31298828125 
[2025-02-28 21:02:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.10313315689563751 norm:0.00017752806888893247 max memory_allocated 29276.31298828125 
[2025-02-28 21:03:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.10249625146389008 norm:0.000138121671625413 max memory_allocated 29276.31298828125 
[2025-02-28 21:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.10188139975070953 norm:0.00011522603745106608 max memory_allocated 29276.31298828125 
[2025-02-28 21:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.10154752433300018 norm:9.896015399135649e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.10141053795814514 norm:8.912139310268685e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.10132889449596405 norm:8.290748519357294e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.10128241777420044 norm:8.047877054195851e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:08:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.10123571008443832 norm:7.503398228436708e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.10120716691017151 norm:6.988932727836072e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:09:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.10119780898094177 norm:6.807785393903032e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:10:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.10118095576763153 norm:6.771851622033864e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:11:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.10116437077522278 norm:6.635751196881756e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.10115230083465576 norm:6.603475776501e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.1011495441198349 norm:6.511583342216909e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:13:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.10114523768424988 norm:6.362018029903993e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.10113652050495148 norm:6.393153307726607e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:15:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.10111856460571289 norm:6.430270877899602e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:15:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.1011047512292862 norm:6.31954608252272e-05 max memory_allocated 29276.31298828125 
[2025-02-28 21:16:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 21:17:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.11561380326747894 norm:0.0004868806281592697 max memory_allocated 29276.50048828125 
[2025-02-28 21:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.11398238688707352 norm:0.0002674568968359381 max memory_allocated 29276.50048828125 
[2025-02-28 21:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.11304354667663574 norm:0.00018010097846854478 max memory_allocated 29276.50048828125 
[2025-02-28 21:19:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.11226576566696167 norm:0.00014210518565960228 max memory_allocated 29276.50048828125 
[2025-02-28 21:20:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.1115654706954956 norm:0.00011718870518961921 max memory_allocated 29276.50048828125 
[2025-02-28 21:20:50 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.11124077439308167 norm:0.00011634396651061252 max memory_allocated 29276.50048828125 
[2025-02-28 21:21:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.11110419034957886 norm:9.311423491453752e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.11102882772684097 norm:8.735513256397098e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:23:08 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.1109672263264656 norm:8.163721940945834e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.11092111468315125 norm:7.932564767543226e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:24:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.11088092625141144 norm:7.522423402406275e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:25:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.11085227131843567 norm:7.232323696371168e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:26:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.11083178222179413 norm:7.116361666703597e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:26:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.11081446707248688 norm:7.039058255031705e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.11079709231853485 norm:7.143928087316453e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:28:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.11078205704689026 norm:7.019933400442824e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.11077620089054108 norm:7.202575943665579e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:30:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.11077062785625458 norm:7.000420009717345e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.11076158285140991 norm:6.940173625480384e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:31:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.11074312031269073 norm:6.830289930803701e-05 max memory_allocated 29276.50048828125 
[2025-02-28 21:31:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 21:32:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.12511688470840454 norm:0.0004349607334006578 max memory_allocated 29276.68798828125 
[2025-02-28 21:33:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.12393145263195038 norm:0.0002313338773092255 max memory_allocated 29276.68798828125 
[2025-02-28 21:34:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.12321488559246063 norm:0.00015588253154419363 max memory_allocated 29276.68798828125 
[2025-02-28 21:34:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.12244170904159546 norm:0.00012256289483048022 max memory_allocated 29276.68798828125 
[2025-02-28 21:35:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.12178205698728561 norm:0.0001040748247760348 max memory_allocated 29276.68798828125 
[2025-02-28 21:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.12154297530651093 norm:9.297319047618657e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:37:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.12143509835004807 norm:8.530111517757177e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:37:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.12137119472026825 norm:8.007798896869645e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.12132170051336288 norm:7.738603744655848e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:39:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.1212901622056961 norm:7.807703514117748e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.12126287072896957 norm:7.602235564263538e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.121233731508255 norm:7.383666525129229e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:41:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.12121356278657913 norm:7.296779949683696e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.12119699269533157 norm:7.286916661541909e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:43:17 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.12119230628013611 norm:7.123616524040699e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.1211763471364975 norm:7.359704613918439e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:44:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.1211625188589096 norm:7.302188168978319e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:45:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.12116199731826782 norm:7.496800390072167e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:46:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.12115153670310974 norm:7.331370579777285e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:47:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.1211429014801979 norm:7.429571269312873e-05 max memory_allocated 29276.68798828125 
[2025-02-28 21:47:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-02-28 21:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.13808394968509674 norm:0.0005458862287923694 max memory_allocated 29276.87548828125 
[2025-02-28 21:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.13641409575939178 norm:0.0002942608261946589 max memory_allocated 29276.87548828125 
[2025-02-28 21:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.13541236519813538 norm:0.000203803283511661 max memory_allocated 29276.87548828125 
[2025-02-28 21:50:26 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.1344401240348816 norm:0.00015615264419466257 max memory_allocated 29276.87548828125 
[2025-02-28 21:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.13370494544506073 norm:0.0001277495757676661 max memory_allocated 29276.87548828125 
[2025-02-28 21:51:58 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.13344940543174744 norm:0.00011572442599572241 max memory_allocated 29276.87548828125 
[2025-02-28 21:52:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.13329726457595825 norm:0.00010584856499917805 max memory_allocated 29276.87548828125 
[2025-02-28 21:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.1332014501094818 norm:0.00015027662448119372 max memory_allocated 29276.87548828125 
[2025-02-28 21:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.13314130902290344 norm:9.558554302202538e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.13310226798057556 norm:9.036373376147822e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.13306187093257904 norm:8.426466956734657e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:56:33 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.1330356001853943 norm:8.131105278152972e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:57:19 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.13301491737365723 norm:7.932505832286552e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.13299313187599182 norm:7.914610614534467e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:58:50 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.13297337293624878 norm:7.917958282632753e-05 max memory_allocated 29276.87548828125 
[2025-02-28 21:59:36 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.13298358023166656 norm:7.835802534827963e-05 max memory_allocated 29276.87548828125 
[2025-02-28 22:00:22 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.1329580545425415 norm:7.653798093087971e-05 max memory_allocated 29276.87548828125 
[2025-02-28 22:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.1329445242881775 norm:7.490870484616607e-05 max memory_allocated 29276.87548828125 
[2025-02-28 22:01:53 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.13293682038784027 norm:7.592364272568375e-05 max memory_allocated 29276.87548828125 
[2025-02-28 22:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.132928267121315 norm:7.748025382170454e-05 max memory_allocated 29276.87548828125 
[2025-02-28 22:02:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-02-28 22:03:42 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.1496846228837967 norm:0.0004807573859579861 max memory_allocated 29277.06298828125 
[2025-02-28 22:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.1481011062860489 norm:0.00026637405971996486 max memory_allocated 29277.06298828125 
[2025-02-28 22:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.14715458452701569 norm:0.00018152600387111306 max memory_allocated 29277.06298828125 
[2025-02-28 22:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.14616759121418 norm:0.0001379533059662208 max memory_allocated 29277.06298828125 
[2025-02-28 22:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.14551308751106262 norm:0.00011148665362270549 max memory_allocated 29277.06298828125 
[2025-02-28 22:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.14528121054172516 norm:9.899155702441931e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.14517776668071747 norm:9.191154094878584e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.145127072930336 norm:8.745421655476093e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.14506776630878448 norm:8.316263119922951e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:10:35 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.14501699805259705 norm:7.953448221087456e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.14500120282173157 norm:7.840680336812511e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.1449689269065857 norm:7.647686288692057e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:12:52 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.14495140314102173 norm:7.534971518907696e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:13:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.1449260413646698 norm:7.411972910631448e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.14491048455238342 norm:7.309038483072072e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:15:10 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.14490634202957153 norm:7.58529276936315e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:15:56 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.1449025720357895 norm:7.217288657557219e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:16:41 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.14488206803798676 norm:7.190139149315655e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:17:27 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.1448705494403839 norm:7.055370952002704e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:18:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.14487296342849731 norm:7.15693095116876e-05 max memory_allocated 29277.06298828125 
[2025-02-28 22:18:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-02-28 22:19:16 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.16630564630031586 norm:0.0005394306499511003 max memory_allocated 29277.25048828125 
[2025-02-28 22:20:02 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.16408559679985046 norm:0.0002838277432601899 max memory_allocated 29277.25048828125 
[2025-02-28 22:20:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.16277293860912323 norm:0.00019656156655400991 max memory_allocated 29277.25048828125 
[2025-02-28 22:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.161598801612854 norm:0.00015338935190811753 max memory_allocated 29277.25048828125 
[2025-02-28 22:22:19 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.16092494130134583 norm:0.00013394971028901637 max memory_allocated 29277.25048828125 
[2025-02-28 22:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.1606597751379013 norm:0.00012057113781338558 max memory_allocated 29277.25048828125 
[2025-02-28 22:23:51 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.16050608456134796 norm:0.00011193166574230418 max memory_allocated 29277.25048828125 
[2025-02-28 22:24:37 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.1604001522064209 norm:0.00010398036101832986 max memory_allocated 29277.25048828125 
[2025-02-28 22:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.16031649708747864 norm:9.87088424153626e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.16026932001113892 norm:9.633628360461444e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.16022510826587677 norm:9.3601513071917e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.16019871830940247 norm:9.125233191298321e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:28:26 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.16018079221248627 norm:8.834835898596793e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:29:12 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.16016125679016113 norm:8.481214172206819e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:29:58 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.1601446568965912 norm:8.519476978108287e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:30:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.1601269543170929 norm:8.13001679489389e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:31:29 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.16011160612106323 norm:8.0309429904446e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:32:15 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.160103440284729 norm:8.025430724956095e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:33:01 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.16009312868118286 norm:8.020416862564161e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:33:47 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.16009312868118286 norm:8.08418626547791e-05 max memory_allocated 29277.25048828125 
[2025-02-28 22:34:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-02-28 22:34:50 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.18287542462348938 norm:0.0009756548097357154 max memory_allocated 29277.43798828125 
[2025-02-28 22:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.18055348098278046 norm:0.0005123420269228518 max memory_allocated 29277.43798828125 
[2025-02-28 22:36:21 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.17906475067138672 norm:0.0003233386087231338 max memory_allocated 29277.43798828125 
[2025-02-28 22:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.1777295023202896 norm:0.00022971675207372755 max memory_allocated 29277.43798828125 
[2025-02-28 22:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.1770496666431427 norm:0.00017902819672599435 max memory_allocated 29277.43798828125 
[2025-02-28 22:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.17679615318775177 norm:0.0001485101820435375 max memory_allocated 29277.43798828125 
[2025-02-28 22:39:25 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.17665517330169678 norm:0.00012906559277325869 max memory_allocated 29277.43798828125 
[2025-02-28 22:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.1765659600496292 norm:0.00011572607763810083 max memory_allocated 29277.43798828125 
[2025-02-28 22:40:56 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.1764938235282898 norm:0.00010742832091636956 max memory_allocated 29277.43798828125 
[2025-02-28 22:41:42 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.17645226418972015 norm:0.000101917699794285 max memory_allocated 29277.43798828125 
[2025-02-28 22:42:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.17640744149684906 norm:9.757610678207129e-05 max memory_allocated 29277.43798828125 
[2025-02-28 22:43:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.17637604475021362 norm:9.507084905635566e-05 max memory_allocated 29277.43798828125 
[2025-02-28 22:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.176350399851799 norm:9.168176620732993e-05 max memory_allocated 29277.43798828125 
[2025-02-28 22:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.17631925642490387 norm:9.020764264278114e-05 max memory_allocated 29277.43798828125 
[2025-02-28 22:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.17631125450134277 norm:8.930124022299424e-05 max memory_allocated 29277.43798828125 
[2025-02-28 22:46:17 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.17629021406173706 norm:8.932931814342737e-05 max memory_allocated 29277.43798828125 
[2025-02-28 22:47:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.17627300322055817 norm:8.796209294814616e-05 max memory_allocated 29277.43798828125 
[2025-02-28 22:47:49 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.17626246809959412 norm:8.732055721338838e-05 max memory_allocated 29277.43798828125 
[2025-02-28 22:48:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.17625311017036438 norm:8.707772212801501e-05 max memory_allocated 29277.43798828125 
[2025-02-28 22:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.1762404441833496 norm:8.683515625307336e-05 max memory_allocated 29277.43798828125 
[2025-02-28 22:49:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-02-28 22:49:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 22:50:24 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.20637574791908264 norm:0.0059156822971999645 max memory_allocated 29277.77001953125 
[2025-02-28 22:51:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.20222817361354828 norm:0.0045248232781887054 max memory_allocated 29277.77001953125 
[2025-02-28 22:51:55 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.19993650913238525 norm:0.003626876277849078 max memory_allocated 29277.77001953125 
[2025-02-28 22:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.1981460303068161 norm:0.0029059972148388624 max memory_allocated 29277.77001953125 
[2025-02-28 22:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.19725243747234344 norm:0.002360245678573847 max memory_allocated 29277.77001953125 
[2025-02-28 22:54:13 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.19686266779899597 norm:0.001946542295627296 max memory_allocated 29277.77001953125 
[2025-02-28 22:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.19667528569698334 norm:0.0018240842036902905 max memory_allocated 29277.77001953125 
[2025-02-28 22:55:45 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.19652710855007172 norm:0.0017552259378135204 max memory_allocated 29277.77001953125 
[2025-02-28 22:56:31 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.1963505893945694 norm:0.0016476210439577699 max memory_allocated 29277.77001953125 
[2025-02-28 22:57:17 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.19627705216407776 norm:0.0015959664015099406 max memory_allocated 29277.77001953125 
[2025-02-28 22:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.1962561309337616 norm:0.0016114546451717615 max memory_allocated 29277.77001953125 
[2025-02-28 22:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.19626972079277039 norm:0.0013006272492930293 max memory_allocated 29277.77001953125 
[2025-02-28 22:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.19607269763946533 norm:0.0013873996213078499 max memory_allocated 29277.77001953125 
[2025-02-28 23:00:21 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.19607797265052795 norm:0.0014545745216310024 max memory_allocated 29277.77001953125 
[2025-02-28 23:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.19611133635044098 norm:0.0013593592448160052 max memory_allocated 29277.77001953125 
[2025-02-28 23:01:54 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.19604475796222687 norm:0.0014710951363667846 max memory_allocated 29277.77001953125 
[2025-02-28 23:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.1960001140832901 norm:0.0013395596761256456 max memory_allocated 29277.77001953125 
[2025-02-28 23:03:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.19596752524375916 norm:0.0013504441594704986 max memory_allocated 29277.77001953125 
[2025-02-28 23:04:12 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.19593694806098938 norm:0.001263883663341403 max memory_allocated 29277.77001953125 
[2025-02-28 23:04:58 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.19589541852474213 norm:0.0012419227277860045 max memory_allocated 29277.77001953125 
[2025-02-28 23:05:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-02-28 23:05:15 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 23:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.2319633662700653 norm:0.005749299190938473 max memory_allocated 29277.95751953125 
[2025-02-28 23:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.22671383619308472 norm:0.004661110229790211 max memory_allocated 29277.95751953125 
[2025-02-28 23:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.22310376167297363 norm:0.0035735529381781816 max memory_allocated 29277.95751953125 
[2025-02-28 23:08:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.22080469131469727 norm:0.002860515844076872 max memory_allocated 29277.95751953125 
[2025-02-28 23:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.21981042623519897 norm:0.002379557816311717 max memory_allocated 29277.95751953125 
[2025-02-28 23:09:51 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.21932382881641388 norm:0.0019863895140588284 max memory_allocated 29277.95751953125 
[2025-02-28 23:10:37 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.21900418400764465 norm:0.0017555167432874441 max memory_allocated 29277.95751953125 
[2025-02-28 23:11:23 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.2188190221786499 norm:0.001686142641119659 max memory_allocated 29277.95751953125 
[2025-02-28 23:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.2187347263097763 norm:0.0016726249596104026 max memory_allocated 29277.95751953125 
[2025-02-28 23:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.2187480926513672 norm:0.0014379279455170035 max memory_allocated 29277.95751953125 
[2025-02-28 23:13:41 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.21850831806659698 norm:0.0015406584134325385 max memory_allocated 29277.95751953125 
[2025-02-28 23:14:27 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.21841663122177124 norm:0.001438526320271194 max memory_allocated 29277.95751953125 
[2025-02-28 23:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.21837736666202545 norm:0.0014502708800137043 max memory_allocated 29277.95751953125 
[2025-02-28 23:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.21831020712852478 norm:0.001386597752571106 max memory_allocated 29277.95751953125 
[2025-02-28 23:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.21830588579177856 norm:0.0014565144665539265 max memory_allocated 29277.95751953125 
[2025-02-28 23:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.21826863288879395 norm:0.001382567104883492 max memory_allocated 29277.95751953125 
[2025-02-28 23:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.21830019354820251 norm:0.0014473740011453629 max memory_allocated 29277.95751953125 
[2025-02-28 23:19:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.21847057342529297 norm:0.0014578960835933685 max memory_allocated 29277.95751953125 
[2025-02-28 23:19:48 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.21884596347808838 norm:0.0019013750134035945 max memory_allocated 29277.95751953125 
[2025-02-28 23:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.21841128170490265 norm:0.001480316510424018 max memory_allocated 29277.95751953125 
[2025-02-28 23:20:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-02-28 23:20:52 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 23:21:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.2780429720878601 norm:0.007572579197585583 max memory_allocated 29278.14501953125 
[2025-02-28 23:22:24 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.26808962225914 norm:0.0034731877967715263 max memory_allocated 29278.14501953125 
[2025-02-28 23:23:10 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.26011669635772705 norm:0.0036319324281066656 max memory_allocated 29278.14501953125 
[2025-02-28 23:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.25695276260375977 norm:0.0036108694039285183 max memory_allocated 29278.14501953125 
[2025-02-28 23:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.2556886374950409 norm:0.0034830491058528423 max memory_allocated 29278.14501953125 
[2025-02-28 23:25:27 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.25481709837913513 norm:0.0033261552453041077 max memory_allocated 29278.14501953125 
[2025-02-28 23:26:13 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.2542647123336792 norm:0.0032338551245629787 max memory_allocated 29278.14501953125 
[2025-02-28 23:26:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.2539093792438507 norm:0.00305609917268157 max memory_allocated 29278.14501953125 
[2025-02-28 23:27:45 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.25363948941230774 norm:0.002994703594595194 max memory_allocated 29278.14501953125 
[2025-02-28 23:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.2534100115299225 norm:0.0027990045491605997 max memory_allocated 29278.14501953125 
[2025-02-28 23:29:17 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.2532172203063965 norm:0.002647524932399392 max memory_allocated 29278.14501953125 
[2025-02-28 23:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.2531055212020874 norm:0.0026793768629431725 max memory_allocated 29278.14501953125 
[2025-02-28 23:30:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.25295794010162354 norm:0.0026386878453195095 max memory_allocated 29278.14501953125 
[2025-02-28 23:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.2528342306613922 norm:0.0026822825893759727 max memory_allocated 29278.14501953125 
[2025-02-28 23:32:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.25297731161117554 norm:0.0031113815493881702 max memory_allocated 29278.14501953125 
[2025-02-28 23:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.25294229388237 norm:0.003085619769990444 max memory_allocated 29278.14501953125 
[2025-02-28 23:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.2526891231536865 norm:0.002695875009521842 max memory_allocated 29278.14501953125 
[2025-02-28 23:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.2525782883167267 norm:0.002586173824965954 max memory_allocated 29278.14501953125 
[2025-02-28 23:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.25258123874664307 norm:0.0027714732568711042 max memory_allocated 29278.14501953125 
[2025-02-28 23:36:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.25265198945999146 norm:0.0027727168053388596 max memory_allocated 29278.14501953125 
[2025-02-28 23:36:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-02-28 23:36:28 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 23:37:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.38790637254714966 norm:0.0343291237950325 max memory_allocated 29278.33251953125 
[2025-02-28 23:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.3606180250644684 norm:0.018874026834964752 max memory_allocated 29278.33251953125 
[2025-02-28 23:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.3488990366458893 norm:0.012977845966815948 max memory_allocated 29278.33251953125 
[2025-02-28 23:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.34193968772888184 norm:0.009747819043695927 max memory_allocated 29278.33251953125 
[2025-02-28 23:40:18 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.33765313029289246 norm:0.007634443696588278 max memory_allocated 29278.33251953125 
[2025-02-28 23:41:04 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.3348705768585205 norm:0.007597658317536116 max memory_allocated 29278.33251953125 
[2025-02-28 23:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.33327779173851013 norm:0.007320762146264315 max memory_allocated 29278.33251953125 
[2025-02-28 23:42:36 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.33170560002326965 norm:0.007068193517625332 max memory_allocated 29278.33251953125 
[2025-02-28 23:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.3305945098400116 norm:0.006662953644990921 max memory_allocated 29278.33251953125 
[2025-02-28 23:44:08 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.3297121226787567 norm:0.006256597116589546 max memory_allocated 29278.33251953125 
[2025-02-28 23:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.32903003692626953 norm:0.006494221743196249 max memory_allocated 29278.33251953125 
[2025-02-28 23:45:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.32848799228668213 norm:0.00640201335772872 max memory_allocated 29278.33251953125 
[2025-02-28 23:46:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.32810503244400024 norm:0.0061594778671860695 max memory_allocated 29278.33251953125 
[2025-02-28 23:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.32798606157302856 norm:0.006430333014577627 max memory_allocated 29278.33251953125 
[2025-02-28 23:47:58 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.3277569115161896 norm:0.006162735633552074 max memory_allocated 29278.33251953125 
[2025-02-28 23:48:44 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.3275737166404724 norm:0.00606020400300622 max memory_allocated 29278.33251953125 
[2025-02-28 23:49:30 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.32725006341934204 norm:0.005820975638926029 max memory_allocated 29278.33251953125 
[2025-02-28 23:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.3269686698913574 norm:0.005673255771398544 max memory_allocated 29278.33251953125 
[2025-02-28 23:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.3269067108631134 norm:0.005918100010603666 max memory_allocated 29278.33251953125 
[2025-02-28 23:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.32662588357925415 norm:0.005633090157061815 max memory_allocated 29278.33251953125 
[2025-02-28 23:52:02 root] (main_calib_config2.py 380): INFO 37395.635043144226
[2025-02-28 23:52:12 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 23:53:59 root] (main_calib_config2.py 159): INFO wikitext2 : 5.014575481414795
[2025-02-28 23:53:59 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 23:56:45 root] (main_calib_config2.py 159): INFO c4 : 6.640017509460449
[2025-03-01 01:59:59 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.014575481414795, 'c4': 6.640017509460449, 'results': {'winogrande': {'acc': 0.6795580110497238, 'acc_stderr': 0.01311508545768171}, 'boolq': {'acc': 0.6886850152905198, 'acc_stderr': 0.008098467975107415}, 'piqa': {'acc': 0.780195865070729, 'acc_stderr': 0.009661958616651766, 'acc_norm': 0.7878128400435256, 'acc_norm_stderr': 0.009539299828174048}, 'arc_easy': {'acc': 0.7276936026936027, 'acc_stderr': 0.009134218447652673, 'acc_norm': 0.569023569023569, 'acc_norm_stderr': 0.010161552863493746}, 'hellaswag': {'acc': 0.5888269269069907, 'acc_stderr': 0.004910409150135491, 'acc_norm': 0.7582154949213304, 'acc_norm_stderr': 0.004272893583742266}, 'arc_challenge': {'acc': 0.4496587030716723, 'acc_stderr': 0.01453714444428474, 'acc_norm': 0.44283276450511944, 'acc_norm_stderr': 0.014515573873348904}}, 'versions': {'winogrande': 0, 'boolq': 1, 'piqa': 0, 'arc_easy': 0, 'hellaswag': 0, 'arc_challenge': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
