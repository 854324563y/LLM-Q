[2025-03-02 04:15:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.7', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.7.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 04:16:52 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 04:16:52 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.7.pkl
[2025-03-02 04:16:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 04:16:57 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.005621978081762791 norm:0.005251022987067699 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0031344490125775337 norm:0.00364376581273973 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0025778368581086397 norm:0.0029785246588289738 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.002280476037412882 norm:0.0023300331085920334 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.002180541167035699 norm:0.0020334997680038214 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0020672138780355453 norm:0.0016281462740153074 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0019957502372562885 norm:0.001400164095684886 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.00195784168317914 norm:0.001203290419653058 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0019365588668733835 norm:0.001083624316379428 max memory_allocated 22559.10693359375 
[2025-03-02 04:22:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.001890184823423624 norm:0.0009388824691995978 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0018653281731531024 norm:0.0008690785616636276 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0018590232357382774 norm:0.0008026625728234649 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0018408834002912045 norm:0.0006858757697045803 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0018430536147207022 norm:0.0006875846302136779 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001826657447963953 norm:0.0006255570915527642 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0018190281698480248 norm:0.0006091829854995012 max memory_allocated 22559.10693359375 
[2025-03-02 04:26:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.001806521904654801 norm:0.0005834816256538033 max memory_allocated 22559.10693359375 
[2025-03-02 04:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.001807140070013702 norm:0.0005806525005027652 max memory_allocated 22559.10693359375 
[2025-03-02 04:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0018032817170023918 norm:0.0005450258031487465 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0017915255157276988 norm:0.0005191367235966027 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 04:28:22 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.01495771761983633 norm:0.01674366556107998 max memory_allocated 22559.27880859375 
[2025-03-02 04:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.00850051362067461 norm:0.012026544660329819 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.0067173754796385765 norm:0.007324653677642345 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.006110344547778368 norm:0.0051015280187129974 max memory_allocated 22559.27880859375 
[2025-03-02 04:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.005758570972830057 norm:0.0043951524421572685 max memory_allocated 22559.27880859375 
[2025-03-02 04:31:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.005562109407037497 norm:0.003973172977566719 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.005378473084419966 norm:0.003555930219590664 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.005256872624158859 norm:0.003241350408643484 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.005133713595569134 norm:0.0029551854822784662 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.005088123958557844 norm:0.0028158712666481733 max memory_allocated 22559.27880859375 
[2025-03-02 04:34:32 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.0049874624237418175 norm:0.0025673580821603537 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.004927514586597681 norm:0.002305242232978344 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.004879281390458345 norm:0.002121256897225976 max memory_allocated 22559.27880859375 
[2025-03-02 04:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.004853139165788889 norm:0.001925404416397214 max memory_allocated 22559.27880859375 
[2025-03-02 04:36:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.004822002723813057 norm:0.0017492619808763266 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.0047865817323327065 norm:0.0015852372162044048 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.004772168584167957 norm:0.0014096045633777976 max memory_allocated 22559.27880859375 
[2025-03-02 04:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.004737561568617821 norm:0.0012464085593819618 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004719469230622053 norm:0.0011029161978513002 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.004722699988633394 norm:0.0010925910901278257 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 04:39:47 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.12376847118139267 norm:0.03371843695640564 max memory_allocated 22559.45068359375 
[2025-03-02 04:40:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.05055136978626251 norm:0.023466981947422028 max memory_allocated 22559.45068359375 
[2025-03-02 04:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.02578500472009182 norm:0.017065128311514854 max memory_allocated 22559.45068359375 
[2025-03-02 04:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.01732482947409153 norm:0.008425522595643997 max memory_allocated 22559.45068359375 
[2025-03-02 04:42:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.015478546731173992 norm:0.006912194192409515 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.014098103158175945 norm:0.0060371775180101395 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.012798677198588848 norm:0.0043536024168133736 max memory_allocated 22559.45068359375 
[2025-03-02 04:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.012116910889744759 norm:0.003960655070841312 max memory_allocated 22559.45068359375 
[2025-03-02 04:44:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.011756607331335545 norm:0.003564781043678522 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.011375545524060726 norm:0.0032953754998743534 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.011429640464484692 norm:0.0035669568460434675 max memory_allocated 22559.45068359375 
[2025-03-02 04:46:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.011080746538937092 norm:0.0029218753334134817 max memory_allocated 22559.45068359375 
[2025-03-02 04:47:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.011014720425009727 norm:0.003100768895819783 max memory_allocated 22559.45068359375 
[2025-03-02 04:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.010677778162062168 norm:0.0026489554438740015 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.01061386801302433 norm:0.0027986769564449787 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.010681740939617157 norm:0.0029029278084635735 max memory_allocated 22559.45068359375 
[2025-03-02 04:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.010612723417580128 norm:0.002859519561752677 max memory_allocated 22559.45068359375 
[2025-03-02 04:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.010607998818159103 norm:0.0028357338160276413 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.010432005859911442 norm:0.0027279327623546124 max memory_allocated 22559.45068359375 
[2025-03-02 04:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.010383512824773788 norm:0.00264821108430624 max memory_allocated 22559.45068359375 
[2025-03-02 04:51:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.018049761652946472 norm:0.002063510473817587 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.014630558900535107 norm:0.0008525568409822881 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.013323472812771797 norm:0.00041906157275661826 max memory_allocated 22559.50732421875 
[2025-03-02 04:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.012526880949735641 norm:0.00023118923127185553 max memory_allocated 22559.50732421875 
[2025-03-02 04:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.011989956721663475 norm:0.00014502141857519746 max memory_allocated 22559.50732421875 
[2025-03-02 04:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.011670826002955437 norm:0.00011111563071608543 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.011526962742209435 norm:0.00010214162466581911 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.01150763500481844 norm:9.939857409335673e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.011475124396383762 norm:9.806584421312436e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.011494294740259647 norm:9.682091331342235e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.011467506177723408 norm:9.301958198193461e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.011450471356511116 norm:9.559150203131139e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:58:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.011444510892033577 norm:9.32691982598044e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.011438174173235893 norm:9.52590344240889e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:59:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.01143711805343628 norm:9.617850446375087e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.01145442295819521 norm:0.00010305713658453897 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.011456778272986412 norm:0.00010488959378562868 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.011449059471487999 norm:9.761391265783459e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.011453021317720413 norm:9.688703721622005e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:02:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.011443140916526318 norm:0.00010354951518820599 max memory_allocated 22559.50732421875 
[2025-03-02 05:02:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 05:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.028825271874666214 norm:0.002138460287824273 max memory_allocated 22559.67919921875 
[2025-03-02 05:03:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.02195417881011963 norm:0.000948433531448245 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.018356993794441223 norm:0.0004574475169647485 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.017320306971669197 norm:0.00027230067644268274 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.016718637198209763 norm:0.000190923034097068 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.016425712034106255 norm:0.00015958381118252873 max memory_allocated 22559.67919921875 
[2025-03-02 05:06:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.01630810648202896 norm:0.0001410663826391101 max memory_allocated 22559.67919921875 
[2025-03-02 05:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.01623576693236828 norm:0.0001408094831276685 max memory_allocated 22559.67919921875 
[2025-03-02 05:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.01619110256433487 norm:0.0001317580754403025 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.01615840569138527 norm:0.00012591046106535941 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.016136378049850464 norm:0.00012894156679976732 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.016120903193950653 norm:0.0001477525511290878 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.016097422689199448 norm:0.00014261165051721036 max memory_allocated 22559.67919921875 
[2025-03-02 05:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.01608269102871418 norm:0.00012370276090223342 max memory_allocated 22559.67919921875 
[2025-03-02 05:11:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.0160797368735075 norm:0.00012838411203119904 max memory_allocated 22559.67919921875 
[2025-03-02 05:11:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.016060635447502136 norm:0.00012303686526138335 max memory_allocated 22559.67919921875 
[2025-03-02 05:12:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.01605169102549553 norm:0.00013359849981497973 max memory_allocated 22559.67919921875 
[2025-03-02 05:12:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.0160337183624506 norm:0.0001371885882690549 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:15 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.016024082899093628 norm:0.00013903235958423465 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.016024647280573845 norm:0.00012719302321784198 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 05:14:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.027124755084514618 norm:0.0019268320174887776 max memory_allocated 22559.85107421875 
[2025-03-02 05:15:08 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.022812101989984512 norm:0.0009048184147104621 max memory_allocated 22559.85107421875 
[2025-03-02 05:15:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.020714720711112022 norm:0.0004665296874009073 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:16 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.01945701241493225 norm:0.0002603052998892963 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.018769124522805214 norm:0.00017028278671205044 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.018474837765097618 norm:0.00014517012459691614 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.018329959362745285 norm:0.00013141479576006532 max memory_allocated 22559.85107421875 
[2025-03-02 05:18:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.018244119361042976 norm:0.0001248498010681942 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.01820286735892296 norm:0.00012661814980674535 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.01815415546298027 norm:0.00013295814278535545 max memory_allocated 22559.85107421875 
[2025-03-02 05:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.01811794564127922 norm:0.0001302729215240106 max memory_allocated 22559.85107421875 
[2025-03-02 05:20:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.01813158392906189 norm:0.00016242940910160542 max memory_allocated 22559.85107421875 
[2025-03-02 05:21:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.01808765158057213 norm:0.00012943471665494144 max memory_allocated 22559.85107421875 
[2025-03-02 05:21:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.01808428019285202 norm:0.00013865495566278696 max memory_allocated 22559.85107421875 
[2025-03-02 05:22:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.01805407926440239 norm:0.00013266457244753838 max memory_allocated 22559.85107421875 
[2025-03-02 05:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.018033765256404877 norm:0.00013043644139543176 max memory_allocated 22559.85107421875 
[2025-03-02 05:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.018026812002062798 norm:0.0001293190143769607 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.01801713928580284 norm:0.0001264110760530457 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.01801041141152382 norm:0.00012785539729520679 max memory_allocated 22559.85107421875 
[2025-03-02 05:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.018028277903795242 norm:0.00012702916865237057 max memory_allocated 22559.85107421875 
[2025-03-02 05:25:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 05:25:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.033648233860731125 norm:0.0012464986648410559 max memory_allocated 22560.02294921875 
[2025-03-02 05:26:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.027483506128191948 norm:0.0004801171598955989 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.023946469649672508 norm:0.000280514796031639 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.022987861186265945 norm:0.00017762690549716353 max memory_allocated 22560.02294921875 
[2025-03-02 05:28:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.022381311282515526 norm:0.00013854223652742803 max memory_allocated 22560.02294921875 
[2025-03-02 05:28:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.022088821977376938 norm:0.00011849254224216565 max memory_allocated 22560.02294921875 
[2025-03-02 05:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.02196652442216873 norm:0.00010029241821030155 max memory_allocated 22560.02294921875 
[2025-03-02 05:29:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.021912842988967896 norm:9.553363634040579e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:30:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.021849755197763443 norm:9.228850103681907e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.02179378643631935 norm:9.046590275829658e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.02176419086754322 norm:8.763786900090054e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:32:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.021746262907981873 norm:8.820291259326041e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:32:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.02172749862074852 norm:8.975684613687918e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.02171783521771431 norm:9.618300828151405e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.02170954830944538 norm:8.962831634562463e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.02170579507946968 norm:8.74650722835213e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.021687481552362442 norm:8.703290950506926e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.02167901024222374 norm:8.660370076540858e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.021681059151887894 norm:8.62755550770089e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:36:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.02167922630906105 norm:8.689068636158481e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:36:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 05:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.03457510843873024 norm:0.0012189883273094893 max memory_allocated 22560.19482421875 
[2025-03-02 05:37:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.02977350726723671 norm:0.0006120078032836318 max memory_allocated 22560.19482421875 
[2025-03-02 05:38:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.02734980918467045 norm:0.0003577105235308409 max memory_allocated 22560.19482421875 
[2025-03-02 05:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.02604018896818161 norm:0.00024259576457552612 max memory_allocated 22560.19482421875 
[2025-03-02 05:39:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.025347577407956123 norm:0.00022939921473152936 max memory_allocated 22560.19482421875 
[2025-03-02 05:40:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.024937154725193977 norm:0.00017285541980527341 max memory_allocated 22560.19482421875 
[2025-03-02 05:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.024811552837491035 norm:0.000179734401172027 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.024767760187387466 norm:0.0001665848249103874 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.02472279779613018 norm:0.00015869255003053695 max memory_allocated 22560.19482421875 
[2025-03-02 05:42:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.02465016581118107 norm:0.00015704527322668582 max memory_allocated 22560.19482421875 
[2025-03-02 05:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.02456679195165634 norm:0.00015125387290026993 max memory_allocated 22560.19482421875 
[2025-03-02 05:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.02456272393465042 norm:0.00015756273933220655 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.024587199091911316 norm:0.0001618344831513241 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.024573910981416702 norm:0.00014607433695346117 max memory_allocated 22560.19482421875 
[2025-03-02 05:45:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.02453562058508396 norm:0.0001415551669197157 max memory_allocated 22560.19482421875 
[2025-03-02 05:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.024531984701752663 norm:0.00014620617730543017 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.024492787197232246 norm:0.00014889601152390242 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.024498745799064636 norm:0.00015027288463898003 max memory_allocated 22560.19482421875 
[2025-03-02 05:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.02449420467019081 norm:0.00015017655096016824 max memory_allocated 22560.19482421875 
[2025-03-02 05:48:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.024503450840711594 norm:0.0001562686957186088 max memory_allocated 22560.19482421875 
[2025-03-02 05:48:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.036594558507204056 norm:0.000891368486918509 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.031945738941431046 norm:0.0004136155766900629 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.02968653291463852 norm:0.0002696607552934438 max memory_allocated 22560.36669921875 
[2025-03-02 05:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.028377685695886612 norm:0.0001955046463990584 max memory_allocated 22560.36669921875 
[2025-03-02 05:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.027709465473890305 norm:0.00017040350940078497 max memory_allocated 22560.36669921875 
[2025-03-02 05:51:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.02737283520400524 norm:0.00017328845569863915 max memory_allocated 22560.36669921875 
[2025-03-02 05:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.02718568779528141 norm:0.0001629291073186323 max memory_allocated 22560.36669921875 
[2025-03-02 05:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.027106715366244316 norm:0.0001586429716553539 max memory_allocated 22560.36669921875 
[2025-03-02 05:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.027051769196987152 norm:0.0001451333228033036 max memory_allocated 22560.36669921875 
[2025-03-02 05:53:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.027004489675164223 norm:0.00015311167226172984 max memory_allocated 22560.36669921875 
[2025-03-02 05:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.02693670615553856 norm:0.00015135077410377562 max memory_allocated 22560.36669921875 
[2025-03-02 05:54:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.026887893676757812 norm:0.00015172352141235024 max memory_allocated 22560.36669921875 
[2025-03-02 05:55:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.02689170278608799 norm:0.0001429113617632538 max memory_allocated 22560.36669921875 
[2025-03-02 05:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.02685556374490261 norm:0.00013850984396412969 max memory_allocated 22560.36669921875 
[2025-03-02 05:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.026841498911380768 norm:0.00014761310012545437 max memory_allocated 22560.36669921875 
[2025-03-02 05:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.026842670515179634 norm:0.0001442648790543899 max memory_allocated 22560.36669921875 
[2025-03-02 05:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.026840005069971085 norm:0.000141413533128798 max memory_allocated 22560.36669921875 
[2025-03-02 05:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.026881320402026176 norm:0.0001538518408779055 max memory_allocated 22560.36669921875 
[2025-03-02 05:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.02685820497572422 norm:0.00015157286543399096 max memory_allocated 22560.36669921875 
[2025-03-02 05:59:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.02684832736849785 norm:0.00014244143676478416 max memory_allocated 22560.36669921875 
[2025-03-02 05:59:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 06:00:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.04188549146056175 norm:0.0011784433154389262 max memory_allocated 22560.53857421875 
[2025-03-02 06:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.03613600507378578 norm:0.0005678167217411101 max memory_allocated 22560.53857421875 
[2025-03-02 06:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.033227354288101196 norm:0.0003444966278038919 max memory_allocated 22560.53857421875 
[2025-03-02 06:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.031829167157411575 norm:0.0002485006407368928 max memory_allocated 22560.53857421875 
[2025-03-02 06:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.031004758551716805 norm:0.00019790965598076582 max memory_allocated 22560.53857421875 
[2025-03-02 06:02:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.030652951449155807 norm:0.0001831765694078058 max memory_allocated 22560.53857421875 
[2025-03-02 06:03:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.030448991805315018 norm:0.0001746701600495726 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.030315812677145004 norm:0.00015880413411650807 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.030243568122386932 norm:0.00015186742530204356 max memory_allocated 22560.53857421875 
[2025-03-02 06:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.03014295920729637 norm:0.0001436323072994128 max memory_allocated 22560.53857421875 
[2025-03-02 06:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.03011271543800831 norm:0.00014215498231351376 max memory_allocated 22560.53857421875 
[2025-03-02 06:06:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.030092306435108185 norm:0.0001391729456372559 max memory_allocated 22560.53857421875 
[2025-03-02 06:06:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.03007114864885807 norm:0.00013936529285274446 max memory_allocated 22560.53857421875 
[2025-03-02 06:07:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.03004705347120762 norm:0.000137422262923792 max memory_allocated 22560.53857421875 
[2025-03-02 06:08:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.030034618452191353 norm:0.00013586622662842274 max memory_allocated 22560.53857421875 
[2025-03-02 06:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.02999994158744812 norm:0.00013299720012582839 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.03004320338368416 norm:0.0001357350847683847 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.03000491112470627 norm:0.00012911845988128334 max memory_allocated 22560.53857421875 
[2025-03-02 06:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.02997615933418274 norm:0.00012970087118446827 max memory_allocated 22560.53857421875 
[2025-03-02 06:10:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.02997293695807457 norm:0.00012970819079782814 max memory_allocated 22560.53857421875 
[2025-03-02 06:10:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 06:11:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.04441069811582565 norm:0.0010049088159576058 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.03853613883256912 norm:0.00043537531746551394 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.03493962436914444 norm:0.00026062404504045844 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.03383757919073105 norm:0.00018590915715321898 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.033227235078811646 norm:0.00014476824435405433 max memory_allocated 22560.71044921875 
[2025-03-02 06:14:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.0329073965549469 norm:0.0001246213068952784 max memory_allocated 22560.71044921875 
[2025-03-02 06:14:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.03272576630115509 norm:0.00010410361574031413 max memory_allocated 22560.71044921875 
[2025-03-02 06:15:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.03263229504227638 norm:0.0001004713267320767 max memory_allocated 22560.71044921875 
[2025-03-02 06:16:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.03257112577557564 norm:9.078482253244147e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:16:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.032518308609724045 norm:8.572451042709872e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.03248440846800804 norm:8.16013925941661e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.03243687376379967 norm:7.816655124770477e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:18:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.032414354383945465 norm:7.566342537757009e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.03240262344479561 norm:7.627380546182394e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.03240051120519638 norm:7.576949428766966e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:19:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.03240485489368439 norm:7.737954001640901e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:33 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.0323956198990345 norm:7.398665184155107e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.03236791864037514 norm:7.234016811707988e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.03236314654350281 norm:7.162350811995566e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.03236773610115051 norm:7.163483678596094e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:22:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 06:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.04241880774497986 norm:0.0008896971703507006 max memory_allocated 22560.88232421875 
[2025-03-02 06:23:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.038616713136434555 norm:0.0004052569856867194 max memory_allocated 22560.88232421875 
[2025-03-02 06:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.0364622101187706 norm:0.00025502435164526105 max memory_allocated 22560.88232421875 
[2025-03-02 06:24:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.03529965505003929 norm:0.00016687263268977404 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.03466195985674858 norm:0.0001347024372080341 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.03432655334472656 norm:0.00012256311310920864 max memory_allocated 22560.88232421875 
[2025-03-02 06:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.034178249537944794 norm:0.00011649587395368144 max memory_allocated 22560.88232421875 
[2025-03-02 06:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.034082066267728806 norm:0.00010728922643465921 max memory_allocated 22560.88232421875 
[2025-03-02 06:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.034062594175338745 norm:0.00010840546747203916 max memory_allocated 22560.88232421875 
[2025-03-02 06:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.03400099650025368 norm:0.00010289518104400486 max memory_allocated 22560.88232421875 
[2025-03-02 06:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.03397732600569725 norm:0.0001038724003592506 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.03396065533161163 norm:0.00010255043162032962 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.0339529924094677 norm:0.0001015318775898777 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.033940140157938004 norm:0.00010026768723037094 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.03392563760280609 norm:9.814512304728851e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.03392094373703003 norm:0.00010004780779127032 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.03393387421965599 norm:9.933759429259226e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:32:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.03392511606216431 norm:0.00010006793309003115 max memory_allocated 22560.88232421875 
[2025-03-02 06:33:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.03392673283815384 norm:0.00010340282460674644 max memory_allocated 22560.88232421875 
[2025-03-02 06:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.03392012417316437 norm:0.00010500175994820893 max memory_allocated 22560.88232421875 
[2025-03-02 06:33:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 06:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.04352722689509392 norm:0.000590340350754559 max memory_allocated 22561.05419921875 
[2025-03-02 06:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.04046718776226044 norm:0.00032167855533771217 max memory_allocated 22561.05419921875 
[2025-03-02 06:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.03837597370147705 norm:0.00022232031915336847 max memory_allocated 22561.05419921875 
[2025-03-02 06:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.037089645862579346 norm:0.0001753320248099044 max memory_allocated 22561.05419921875 
[2025-03-02 06:36:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.03642768785357475 norm:0.00015630584675818682 max memory_allocated 22561.05419921875 
[2025-03-02 06:37:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.0360342338681221 norm:0.0001375348656438291 max memory_allocated 22561.05419921875 
[2025-03-02 06:37:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.03581356257200241 norm:0.00012797399540431798 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.03570824861526489 norm:0.00011669326340779662 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.035637274384498596 norm:0.00011295163130853325 max memory_allocated 22561.05419921875 
[2025-03-02 06:39:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.03558574244379997 norm:0.0001014518566080369 max memory_allocated 22561.05419921875 
[2025-03-02 06:39:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.035567332059144974 norm:0.00010203952842857689 max memory_allocated 22561.05419921875 
[2025-03-02 06:40:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.03555261343717575 norm:9.522320760879666e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:41:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.035530757158994675 norm:9.578600293025374e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:41:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.035496871918439865 norm:9.175790910376236e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:42:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.035494185984134674 norm:9.139590838458389e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:42:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.035492733120918274 norm:9.287981083616614e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:43:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.03547858074307442 norm:9.189055708702654e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:43:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.03547756373882294 norm:9.168484393740073e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:44:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.03547074645757675 norm:9.221323125530034e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:45:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.035479992628097534 norm:9.525078348815441e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:45:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 06:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.044381678104400635 norm:0.0005642500473186374 max memory_allocated 22561.22607421875 
[2025-03-02 06:46:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.041603341698646545 norm:0.00029166441527195275 max memory_allocated 22561.22607421875 
[2025-03-02 06:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.039793480187654495 norm:0.0001938079367391765 max memory_allocated 22561.22607421875 
[2025-03-02 06:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.0386313870549202 norm:0.00015212048310786486 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.03798918426036835 norm:0.0001388047239743173 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.03759930282831192 norm:0.00011819848441518843 max memory_allocated 22561.22607421875 
[2025-03-02 06:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.03744082897901535 norm:0.00011236820137128234 max memory_allocated 22561.22607421875 
[2025-03-02 06:49:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.0373750776052475 norm:0.00010579853551462293 max memory_allocated 22561.22607421875 
[2025-03-02 06:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.03733391687273979 norm:9.952420077752322e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:50:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.03728753700852394 norm:9.84127982519567e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:51:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.03727316856384277 norm:9.422154835192487e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:51:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.037234727293252945 norm:8.841722592478618e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:52:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.03720748797059059 norm:8.454037015326321e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:53:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.03720688074827194 norm:8.38251507957466e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:53:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.03720429912209511 norm:8.75266850925982e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.03719278424978256 norm:8.663801418151706e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.037186115980148315 norm:8.790352148935199e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:55:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.03717224299907684 norm:8.720245386939496e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.0371723547577858 norm:8.970816270448267e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.03717692196369171 norm:8.855214400682598e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:56:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.04944581910967827 norm:0.00104792439378798 max memory_allocated 22561.39794921875 
[2025-03-02 06:57:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.04529319331049919 norm:0.0004954257165081799 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.04299091920256615 norm:0.0003089743258897215 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.04167135804891586 norm:0.0002210162056144327 max memory_allocated 22561.39794921875 
[2025-03-02 06:59:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.04094988480210304 norm:0.0001766975037753582 max memory_allocated 22561.39794921875 
[2025-03-02 06:59:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.04056437686085701 norm:0.0001501243095844984 max memory_allocated 22561.39794921875 
[2025-03-02 07:00:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.04040862247347832 norm:0.00013505257084034383 max memory_allocated 22561.39794921875 
[2025-03-02 07:01:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.04030831530690193 norm:0.00012868971680290997 max memory_allocated 22561.39794921875 
[2025-03-02 07:01:40 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.04018297791481018 norm:0.00011977102985838428 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.040126021951436996 norm:0.00011617803829722106 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.040069036185741425 norm:0.00010869940888369456 max memory_allocated 22561.39794921875 
[2025-03-02 07:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.04006917029619217 norm:0.00010135765478480607 max memory_allocated 22561.39794921875 
[2025-03-02 07:03:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.04005211219191551 norm:0.00010199727694271132 max memory_allocated 22561.39794921875 
[2025-03-02 07:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.04004499316215515 norm:0.00010001310147345066 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.040037866681814194 norm:0.00010206948354607448 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.040053728967905045 norm:9.924237383529544e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.04002190753817558 norm:9.884225437417626e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:06:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.04002175107598305 norm:9.989062527893111e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:07:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.04001081362366676 norm:9.882033191388473e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:07:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.039990611374378204 norm:9.891639638226479e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:07:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 07:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.05016946792602539 norm:0.0007149451994337142 max memory_allocated 22561.56982421875 
[2025-03-02 07:09:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.04733112454414368 norm:0.00035640253918245435 max memory_allocated 22561.56982421875 
[2025-03-02 07:09:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.045441050082445145 norm:0.00022588398132938892 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.04411855340003967 norm:0.0001626174052944407 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.043416690081357956 norm:0.00014085890143178403 max memory_allocated 22561.56982421875 
[2025-03-02 07:11:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.04308479279279709 norm:0.00012334799976088107 max memory_allocated 22561.56982421875 
[2025-03-02 07:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.04294856637716293 norm:0.00011364270903868601 max memory_allocated 22561.56982421875 
[2025-03-02 07:12:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.04284156858921051 norm:0.00010082662629429251 max memory_allocated 22561.56982421875 
[2025-03-02 07:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.042797792702913284 norm:9.447640331927687e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:13:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.04276430979371071 norm:9.30850874283351e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:14:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.04275614395737648 norm:0.00010964816465275362 max memory_allocated 22561.56982421875 
[2025-03-02 07:14:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.04273007810115814 norm:9.383793076267466e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:15:19 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.04268401488661766 norm:8.616934792371467e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:15:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.04266456514596939 norm:8.928668103180826e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.04265208914875984 norm:8.953334327088669e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.042639683932065964 norm:8.844427793519571e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:17:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.04266509413719177 norm:0.00010204440332017839 max memory_allocated 22561.56982421875 
[2025-03-02 07:18:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.04267149418592453 norm:9.929152292897925e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.04264546185731888 norm:8.415991760557517e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:19:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.04265190660953522 norm:8.695684664417058e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:19:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 07:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.055869534611701965 norm:0.0009677635971456766 max memory_allocated 22561.74169921875 
[2025-03-02 07:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.05178613215684891 norm:0.00037754938239231706 max memory_allocated 22561.74169921875 
[2025-03-02 07:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.04951440170407295 norm:0.00023211668303702027 max memory_allocated 22561.74169921875 
[2025-03-02 07:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.04807450249791145 norm:0.00018146823276765645 max memory_allocated 22561.74169921875 
[2025-03-02 07:22:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.04735736548900604 norm:0.0001622210693312809 max memory_allocated 22561.74169921875 
[2025-03-02 07:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.04704032838344574 norm:0.00014129976625554264 max memory_allocated 22561.74169921875 
[2025-03-02 07:23:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.04692821204662323 norm:0.00013516165199689567 max memory_allocated 22561.74169921875 
[2025-03-02 07:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.04681144654750824 norm:0.00011739660112652928 max memory_allocated 22561.74169921875 
[2025-03-02 07:24:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.04672954976558685 norm:0.00011472833284642547 max memory_allocated 22561.74169921875 
[2025-03-02 07:25:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.04665948078036308 norm:0.00010723527520895004 max memory_allocated 22561.74169921875 
[2025-03-02 07:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.046632181853055954 norm:0.00010810699313879013 max memory_allocated 22561.74169921875 
[2025-03-02 07:26:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.04661747068166733 norm:0.00011086004815297201 max memory_allocated 22561.74169921875 
[2025-03-02 07:26:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.04659511148929596 norm:0.00010639859101502225 max memory_allocated 22561.74169921875 
[2025-03-02 07:27:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.0465552918612957 norm:0.00010443654900882393 max memory_allocated 22561.74169921875 
[2025-03-02 07:27:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.04653755575418472 norm:9.863585000857711e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.04652652144432068 norm:9.674228931544349e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.04652315378189087 norm:9.75348157226108e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:29:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.04653123766183853 norm:0.00010075822501676157 max memory_allocated 22561.74169921875 
[2025-03-02 07:30:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.046499066054821014 norm:9.938541916199028e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:30:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.04648387059569359 norm:9.736000356497243e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:30:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 07:31:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.06167757138609886 norm:0.001186555135063827 max memory_allocated 22561.91357421875 
[2025-03-02 07:31:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.05764954164624214 norm:0.000494777166750282 max memory_allocated 22561.91357421875 
[2025-03-02 07:32:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.055066801607608795 norm:0.0002951557980850339 max memory_allocated 22561.91357421875 
[2025-03-02 07:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.05348460003733635 norm:0.0002132146037183702 max memory_allocated 22561.91357421875 
[2025-03-02 07:33:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.05269705131649971 norm:0.0001676873507676646 max memory_allocated 22561.91357421875 
[2025-03-02 07:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.0524074025452137 norm:0.0001414209691574797 max memory_allocated 22561.91357421875 
[2025-03-02 07:34:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.05226127803325653 norm:0.00013514948659576476 max memory_allocated 22561.91357421875 
[2025-03-02 07:35:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.05216069519519806 norm:0.00012317782966420054 max memory_allocated 22561.91357421875 
[2025-03-02 07:35:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.052123237401247025 norm:0.0001165476642199792 max memory_allocated 22561.91357421875 
[2025-03-02 07:36:28 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.05208771675825119 norm:0.00011153398372698575 max memory_allocated 22561.91357421875 
[2025-03-02 07:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.05199979618191719 norm:0.0001054033637046814 max memory_allocated 22561.91357421875 
[2025-03-02 07:37:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.05198359861969948 norm:0.00010282243601977825 max memory_allocated 22561.91357421875 
[2025-03-02 07:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.05196695402264595 norm:0.00010042315989267081 max memory_allocated 22561.91357421875 
[2025-03-02 07:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.05196047201752663 norm:0.00010141755774384364 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.051965028047561646 norm:0.00010020443733083084 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.051960527896881104 norm:0.00010005930380430073 max memory_allocated 22561.91357421875 
[2025-03-02 07:40:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.05194234475493431 norm:0.00010264977754559368 max memory_allocated 22561.91357421875 
[2025-03-02 07:40:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.05191744863986969 norm:9.961535397451371e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:41:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.05191747844219208 norm:9.931977547239512e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.051895253360271454 norm:0.00010003449278883636 max memory_allocated 22561.91357421875 
[2025-03-02 07:42:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 07:42:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.06682725995779037 norm:0.0005828319699503481 max memory_allocated 22562.08544921875 
[2025-03-02 07:43:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.06376640498638153 norm:0.00027994034462608397 max memory_allocated 22562.08544921875 
[2025-03-02 07:43:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.06182634085416794 norm:0.00020110691548325121 max memory_allocated 22562.08544921875 
[2025-03-02 07:44:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.06034184247255325 norm:0.0001694164820946753 max memory_allocated 22562.08544921875 
[2025-03-02 07:45:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.059643521904945374 norm:0.00013824010966345668 max memory_allocated 22562.08544921875 
[2025-03-02 07:45:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.05942560359835625 norm:0.00012169182446086779 max memory_allocated 22562.08544921875 
[2025-03-02 07:46:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.05930917710065842 norm:0.00011568678746698424 max memory_allocated 22562.08544921875 
[2025-03-02 07:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.05922972783446312 norm:0.00010545289114816114 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.05915949493646622 norm:0.00010007049422711134 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.0591067299246788 norm:9.8416545370128e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.05910762399435043 norm:9.534004493616521e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.05907046049833298 norm:9.410228085471317e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:49:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.059040095657110214 norm:9.080155723495409e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.05902790278196335 norm:8.732284186407924e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:50:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.05901119485497475 norm:8.7380685727112e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.05900416150689125 norm:8.699242607690394e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.05900350213050842 norm:8.797689224593341e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.05901249125599861 norm:8.611974772065878e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.059011198580265045 norm:8.859203808242455e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.05901513248682022 norm:8.905761205824092e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:53:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:54:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.07700416445732117 norm:0.0008937141392379999 max memory_allocated 22562.25732421875 
[2025-03-02 07:54:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.0735589787364006 norm:0.0003612387808971107 max memory_allocated 22562.25732421875 
[2025-03-02 07:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.07129458338022232 norm:0.00023478160437662154 max memory_allocated 22562.25732421875 
[2025-03-02 07:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.06958194822072983 norm:0.00018684373935684562 max memory_allocated 22562.25732421875 
[2025-03-02 07:56:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.06888995319604874 norm:0.0001612438354641199 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.06866491585969925 norm:0.00014148697664495558 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.06854721903800964 norm:0.00012972662807442248 max memory_allocated 22562.25732421875 
[2025-03-02 07:58:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.068476602435112 norm:0.00013028498506173491 max memory_allocated 22562.25732421875 
[2025-03-02 07:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.06840098649263382 norm:0.0001204575746669434 max memory_allocated 22562.25732421875 
[2025-03-02 07:59:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.06835146248340607 norm:0.00011272692063357681 max memory_allocated 22562.25732421875 
[2025-03-02 07:59:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.06830672174692154 norm:0.00010853304411284626 max memory_allocated 22562.25732421875 
[2025-03-02 08:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.068288154900074 norm:0.00010540430957917124 max memory_allocated 22562.25732421875 
[2025-03-02 08:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.06829994916915894 norm:0.00011714271386153996 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.06825709342956543 norm:0.0001080373112927191 max memory_allocated 22562.25732421875 
[2025-03-02 08:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.0682513415813446 norm:0.00010621129331411794 max memory_allocated 22562.25732421875 
[2025-03-02 08:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.068252794444561 norm:0.00010990780720021576 max memory_allocated 22562.25732421875 
[2025-03-02 08:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.06823620945215225 norm:0.00010491580178495497 max memory_allocated 22562.25732421875 
[2025-03-02 08:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.06823758780956268 norm:0.00011046359577449039 max memory_allocated 22562.25732421875 
[2025-03-02 08:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.06823334097862244 norm:0.00011127500329166651 max memory_allocated 22562.25732421875 
[2025-03-02 08:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.0682072713971138 norm:0.00010955695324810222 max memory_allocated 22562.25732421875 
[2025-03-02 08:05:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 08:05:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.09277281165122986 norm:0.0021491381339728832 max memory_allocated 22562.42919921875 
[2025-03-02 08:06:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.08754539489746094 norm:0.0006513958214782178 max memory_allocated 22562.42919921875 
[2025-03-02 08:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.08449282497167587 norm:0.00038521509850397706 max memory_allocated 22562.42919921875 
[2025-03-02 08:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.08244907855987549 norm:0.00029053736943751574 max memory_allocated 22562.42919921875 
[2025-03-02 08:07:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.08175577223300934 norm:0.0002665393112692982 max memory_allocated 22562.42919921875 
[2025-03-02 08:08:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.08145914226770401 norm:0.00021124081104062498 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.08129500597715378 norm:0.00019824408809654415 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.08119374513626099 norm:0.00017386311083100736 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.08107787370681763 norm:0.0001575002825120464 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.08099910616874695 norm:0.00015137250011321157 max memory_allocated 22562.42919921875 
[2025-03-02 08:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.08094292134046555 norm:0.00015867459296714514 max memory_allocated 22562.42919921875 
[2025-03-02 08:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.08087204396724701 norm:0.00014375083264894783 max memory_allocated 22562.42919921875 
[2025-03-02 08:12:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.08083222806453705 norm:0.00014091988850850612 max memory_allocated 22562.42919921875 
[2025-03-02 08:12:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.08080706000328064 norm:0.0001374407729599625 max memory_allocated 22562.42919921875 
[2025-03-02 08:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.08079204708337784 norm:0.00014011292660143226 max memory_allocated 22562.42919921875 
[2025-03-02 08:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.08074989914894104 norm:0.00014084810391068459 max memory_allocated 22562.42919921875 
[2025-03-02 08:14:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.08073092252016068 norm:0.00013681757263839245 max memory_allocated 22562.42919921875 
[2025-03-02 08:15:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.08072545379400253 norm:0.0001349435915471986 max memory_allocated 22562.42919921875 
[2025-03-02 08:15:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.0807352215051651 norm:0.00014604354510083795 max memory_allocated 22562.42919921875 
[2025-03-02 08:16:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.08075615018606186 norm:0.00013623115955851972 max memory_allocated 22562.42919921875 
[2025-03-02 08:16:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 08:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.105949267745018 norm:0.002212913939729333 max memory_allocated 22562.60107421875 
[2025-03-02 08:17:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.10217570513486862 norm:0.0007967085111886263 max memory_allocated 22562.60107421875 
[2025-03-02 08:18:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.09943798929452896 norm:0.0004372653493192047 max memory_allocated 22562.60107421875 
[2025-03-02 08:18:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.09729347378015518 norm:0.0003457586281001568 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.09660575538873672 norm:0.00031181873055174947 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.0963524580001831 norm:0.00026601715944707394 max memory_allocated 22562.60107421875 
[2025-03-02 08:20:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.09624672681093216 norm:0.00025734788505360484 max memory_allocated 22562.60107421875 
[2025-03-02 08:20:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.09610658884048462 norm:0.00022823308245278895 max memory_allocated 22562.60107421875 
[2025-03-02 08:21:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.09601444005966187 norm:0.00021555651619564742 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.09595175087451935 norm:0.00019775680266320705 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.09589525312185287 norm:0.00017825045506469905 max memory_allocated 22562.60107421875 
[2025-03-02 08:23:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.09584249556064606 norm:0.0001644169824430719 max memory_allocated 22562.60107421875 
[2025-03-02 08:23:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.09581653028726578 norm:0.00015647934924345464 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.09577110409736633 norm:0.0001525192055851221 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.09574590623378754 norm:0.00014061699039302766 max memory_allocated 22562.60107421875 
[2025-03-02 08:25:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.0957217589020729 norm:0.00013985551777295768 max memory_allocated 22562.60107421875 
[2025-03-02 08:26:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.09568998962640762 norm:0.00013340514851734042 max memory_allocated 22562.60107421875 
[2025-03-02 08:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.09569081664085388 norm:0.00013710910570807755 max memory_allocated 22562.60107421875 
[2025-03-02 08:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.09569008648395538 norm:0.00014239609299693257 max memory_allocated 22562.60107421875 
[2025-03-02 08:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.09569193422794342 norm:0.00014372647274285555 max memory_allocated 22562.60107421875 
[2025-03-02 08:27:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 08:28:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.1208864152431488 norm:0.0011823070235550404 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.1176387220621109 norm:0.0006100576720200479 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.1149926409125328 norm:0.00040301235276274383 max memory_allocated 22562.77294921875 
[2025-03-02 08:30:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.11291760206222534 norm:0.00030381756369024515 max memory_allocated 22562.77294921875 
[2025-03-02 08:30:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.11239012330770493 norm:0.0002392447495367378 max memory_allocated 22562.77294921875 
[2025-03-02 08:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.1121349185705185 norm:0.00019492967112455517 max memory_allocated 22562.77294921875 
[2025-03-02 08:31:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.11202552169561386 norm:0.00017495712381787598 max memory_allocated 22562.77294921875 
[2025-03-02 08:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.11189086735248566 norm:0.00016282530850730836 max memory_allocated 22562.77294921875 
[2025-03-02 08:32:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.1117931455373764 norm:0.00016188685549423099 max memory_allocated 22562.77294921875 
[2025-03-02 08:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.11179816722869873 norm:0.00016029493417590857 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.11177193373441696 norm:0.00015524741320405155 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.11176010966300964 norm:0.00015276475460268557 max memory_allocated 22562.77294921875 
[2025-03-02 08:35:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.11173342168331146 norm:0.00015394133515655994 max memory_allocated 22562.77294921875 
[2025-03-02 08:35:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.1117003858089447 norm:0.00015250506112352014 max memory_allocated 22562.77294921875 
[2025-03-02 08:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.11167015880346298 norm:0.00014906807336956263 max memory_allocated 22562.77294921875 
[2025-03-02 08:36:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.11166945099830627 norm:0.00015047001943457872 max memory_allocated 22562.77294921875 
[2025-03-02 08:37:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.11162567138671875 norm:0.00015234063903335482 max memory_allocated 22562.77294921875 
[2025-03-02 08:37:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.11167582869529724 norm:0.00014997228572610766 max memory_allocated 22562.77294921875 
[2025-03-02 08:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.1117168664932251 norm:0.00016094124293886125 max memory_allocated 22562.77294921875 
[2025-03-02 08:39:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.11166366189718246 norm:0.00015506520867347717 max memory_allocated 22562.77294921875 
[2025-03-02 08:39:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 08:39:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.14251293241977692 norm:0.0018693911843001842 max memory_allocated 22562.94482421875 
[2025-03-02 08:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.13892504572868347 norm:0.0009837733814492822 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.1358853280544281 norm:0.0006253293249756098 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.13350838422775269 norm:0.0004547778517007828 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.13279759883880615 norm:0.0003464712353888899 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.13249485194683075 norm:0.0002797892957460135 max memory_allocated 22562.94482421875 
[2025-03-02 08:43:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.1323293149471283 norm:0.0002505831071175635 max memory_allocated 22562.94482421875 
[2025-03-02 08:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.13225841522216797 norm:0.00023555375810246915 max memory_allocated 22562.94482421875 
[2025-03-02 08:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.13214044272899628 norm:0.00021538366854656488 max memory_allocated 22562.94482421875 
[2025-03-02 08:44:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.13208457827568054 norm:0.00020043387485202402 max memory_allocated 22562.94482421875 
[2025-03-02 08:45:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.13204669952392578 norm:0.00020165680325590074 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.13200025260448456 norm:0.00019598845392465591 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.13196465373039246 norm:0.0001950877922354266 max memory_allocated 22562.94482421875 
[2025-03-02 08:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.13195040822029114 norm:0.00019087926193606108 max memory_allocated 22562.94482421875 
[2025-03-02 08:47:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.13189488649368286 norm:0.00018273723253514618 max memory_allocated 22562.94482421875 
[2025-03-02 08:48:18 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.13188830018043518 norm:0.00018774118507280946 max memory_allocated 22562.94482421875 
[2025-03-02 08:48:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.13190005719661713 norm:0.0001824581268010661 max memory_allocated 22562.94482421875 
[2025-03-02 08:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.13188594579696655 norm:0.0001834344438975677 max memory_allocated 22562.94482421875 
[2025-03-02 08:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.13184688985347748 norm:0.00018409878248348832 max memory_allocated 22562.94482421875 
[2025-03-02 08:50:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.13184240460395813 norm:0.00018134484707843512 max memory_allocated 22562.94482421875 
[2025-03-02 08:50:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:51:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.16211754083633423 norm:0.0009097917354665697 max memory_allocated 22563.11669921875 
[2025-03-02 08:51:52 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.158983513712883 norm:0.0005104094743728638 max memory_allocated 22563.11669921875 
[2025-03-02 08:52:25 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.15575262904167175 norm:0.00036930645001120865 max memory_allocated 22563.11669921875 
[2025-03-02 08:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.153329998254776 norm:0.0002936622768174857 max memory_allocated 22563.11669921875 
[2025-03-02 08:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.1528300940990448 norm:0.00025223870761692524 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.15257392823696136 norm:0.0002249757235404104 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.15246781706809998 norm:0.0002058039972325787 max memory_allocated 22563.11669921875 
[2025-03-02 08:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.1523425430059433 norm:0.00019137002527713776 max memory_allocated 22563.11669921875 
[2025-03-02 08:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.15227745473384857 norm:0.0001820050529204309 max memory_allocated 22563.11669921875 
[2025-03-02 08:56:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.1522027850151062 norm:0.00017845589900389314 max memory_allocated 22563.11669921875 
[2025-03-02 08:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.15215237438678741 norm:0.00017591322830412537 max memory_allocated 22563.11669921875 
[2025-03-02 08:57:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.15209278464317322 norm:0.00017107496387325227 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.15205687284469604 norm:0.0001688011980149895 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.15203432738780975 norm:0.00016669309115968645 max memory_allocated 22563.11669921875 
[2025-03-02 08:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.1520279347896576 norm:0.00016381641034968197 max memory_allocated 22563.11669921875 
[2025-03-02 08:59:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.15199892222881317 norm:0.00016536773182451725 max memory_allocated 22563.11669921875 
[2025-03-02 09:00:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.15200626850128174 norm:0.0001629845646675676 max memory_allocated 22563.11669921875 
[2025-03-02 09:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.15199095010757446 norm:0.0001609912287676707 max memory_allocated 22563.11669921875 
[2025-03-02 09:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.15196411311626434 norm:0.00016168919682968408 max memory_allocated 22563.11669921875 
[2025-03-02 09:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.15197749435901642 norm:0.0001621783885639161 max memory_allocated 22563.11669921875 
[2025-03-02 09:02:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 09:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.18699559569358826 norm:0.001310644089244306 max memory_allocated 22563.28857421875 
[2025-03-02 09:03:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.1833343356847763 norm:0.0007566968561150134 max memory_allocated 22563.28857421875 
[2025-03-02 09:03:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.1796654909849167 norm:0.0005157622508704662 max memory_allocated 22563.28857421875 
[2025-03-02 09:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.1771654337644577 norm:0.0003794083895627409 max memory_allocated 22563.28857421875 
[2025-03-02 09:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.17670170962810516 norm:0.00031253433553501964 max memory_allocated 22563.28857421875 
[2025-03-02 09:05:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.17643806338310242 norm:0.00024913312518037856 max memory_allocated 22563.28857421875 
[2025-03-02 09:06:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.17634324729442596 norm:0.00022434955462813377 max memory_allocated 22563.28857421875 
[2025-03-02 09:06:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.1762067973613739 norm:0.00020302031771279871 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.17608441412448883 norm:0.0001862883218564093 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.17602023482322693 norm:0.00017526157898828387 max memory_allocated 22563.28857421875 
[2025-03-02 09:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.1760178953409195 norm:0.00017430467414669693 max memory_allocated 22563.28857421875 
[2025-03-02 09:08:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.17599906027317047 norm:0.00017007076530717313 max memory_allocated 22563.28857421875 
[2025-03-02 09:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.17598113417625427 norm:0.00016471229901071638 max memory_allocated 22563.28857421875 
[2025-03-02 09:09:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.17593231797218323 norm:0.00016240448167081922 max memory_allocated 22563.28857421875 
[2025-03-02 09:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.17590372264385223 norm:0.00015841939602978528 max memory_allocated 22563.28857421875 
[2025-03-02 09:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.17589882016181946 norm:0.00015927449567243457 max memory_allocated 22563.28857421875 
[2025-03-02 09:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.17588351666927338 norm:0.00016156367200892419 max memory_allocated 22563.28857421875 
[2025-03-02 09:12:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.17586685717105865 norm:0.00016300496645271778 max memory_allocated 22563.28857421875 
[2025-03-02 09:12:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.17584851384162903 norm:0.00016068914555944502 max memory_allocated 22563.28857421875 
[2025-03-02 09:13:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.17582909762859344 norm:0.00016185248387046158 max memory_allocated 22563.28857421875 
[2025-03-02 09:13:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 09:14:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.21901044249534607 norm:0.005322712939232588 max memory_allocated 22563.46044921875 
[2025-03-02 09:14:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.21266955137252808 norm:0.002734176116064191 max memory_allocated 22563.46044921875 
[2025-03-02 09:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.20749759674072266 norm:0.0016584288096055388 max memory_allocated 22563.46044921875 
[2025-03-02 09:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.20446081459522247 norm:0.001100796042010188 max memory_allocated 22563.46044921875 
[2025-03-02 09:16:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.20372995734214783 norm:0.0007972557796165347 max memory_allocated 22563.46044921875 
[2025-03-02 09:16:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.20339800417423248 norm:0.0006116105359978974 max memory_allocated 22563.46044921875 
[2025-03-02 09:17:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.20315337181091309 norm:0.0004820306203328073 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.2029392272233963 norm:0.00039679722976870835 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.202833354473114 norm:0.0003433546226006001 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.20272764563560486 norm:0.00030238175531849265 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.2026480734348297 norm:0.0002756962494459003 max memory_allocated 22563.46044921875 
[2025-03-02 09:20:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.20256169140338898 norm:0.0002567836781963706 max memory_allocated 22563.46044921875 
[2025-03-02 09:20:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.20252929627895355 norm:0.00024140803725458682 max memory_allocated 22563.46044921875 
[2025-03-02 09:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.2024683952331543 norm:0.00023054159828461707 max memory_allocated 22563.46044921875 
[2025-03-02 09:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.20244351029396057 norm:0.0002208903169957921 max memory_allocated 22563.46044921875 
[2025-03-02 09:22:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.2024507224559784 norm:0.00021990595269016922 max memory_allocated 22563.46044921875 
[2025-03-02 09:23:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.20242977142333984 norm:0.00021445000311359763 max memory_allocated 22563.46044921875 
[2025-03-02 09:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.20239709317684174 norm:0.0002077217068290338 max memory_allocated 22563.46044921875 
[2025-03-02 09:24:12 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.20236480236053467 norm:0.00020484387641772628 max memory_allocated 22563.46044921875 
[2025-03-02 09:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.20234936475753784 norm:0.00020408109412528574 max memory_allocated 22563.46044921875 
[2025-03-02 09:24:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 09:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.24506856501102448 norm:0.0030828441958874464 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.23997481167316437 norm:0.0016012905398383737 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.235063374042511 norm:0.001021272619254887 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.23223468661308289 norm:0.0007101246737875044 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:46 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.23164813220500946 norm:0.0005526296445168555 max memory_allocated 22563.63232421875 
[2025-03-02 09:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.23140791058540344 norm:0.00046598081826232374 max memory_allocated 22563.63232421875 
[2025-03-02 09:28:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.23121707141399384 norm:0.00038599828258156776 max memory_allocated 22563.63232421875 
[2025-03-02 09:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.23106642067432404 norm:0.00033155782148241997 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.23093512654304504 norm:0.00029181165155023336 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.23085200786590576 norm:0.0002754228189587593 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.23078171908855438 norm:0.00025884321075864136 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.23070305585861206 norm:0.00024041827418841422 max memory_allocated 22563.63232421875 
[2025-03-02 09:32:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.23067422211170197 norm:0.00022646700381301343 max memory_allocated 22563.63232421875 
[2025-03-02 09:32:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.23063617944717407 norm:0.00021213432773947716 max memory_allocated 22563.63232421875 
[2025-03-02 09:33:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.23060843348503113 norm:0.00020899437367916107 max memory_allocated 22563.63232421875 
[2025-03-02 09:33:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.23058462142944336 norm:0.00020864055841229856 max memory_allocated 22563.63232421875 
[2025-03-02 09:34:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.230568528175354 norm:0.00021289514552336186 max memory_allocated 22563.63232421875 
[2025-03-02 09:35:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.2305375635623932 norm:0.00020332392887212336 max memory_allocated 22563.63232421875 
[2025-03-02 09:35:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.23053346574306488 norm:0.00019719019473996013 max memory_allocated 22563.63232421875 
[2025-03-02 09:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.23051027953624725 norm:0.0001913102896651253 max memory_allocated 22563.63232421875 
[2025-03-02 09:36:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 09:36:23 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.2838233411312103 norm:0.008221090771257877 max memory_allocated 22563.91943359375 
[2025-03-02 09:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.2779649496078491 norm:0.006899310741573572 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.272060751914978 norm:0.005412195809185505 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.2692217230796814 norm:0.004705425817519426 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.2685752213001251 norm:0.004145818296819925 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.268123596906662 norm:0.00362629652954638 max memory_allocated 22563.91943359375 
[2025-03-02 09:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.2678982615470886 norm:0.003432461293414235 max memory_allocated 22563.91943359375 
[2025-03-02 09:40:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.2678038477897644 norm:0.003105258336290717 max memory_allocated 22563.91943359375 
[2025-03-02 09:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.26764702796936035 norm:0.003195446217432618 max memory_allocated 22563.91943359375 
[2025-03-02 09:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.26759645342826843 norm:0.0027205205988138914 max memory_allocated 22563.91943359375 
[2025-03-02 09:42:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.26736968755722046 norm:0.0028108542319387197 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.26732081174850464 norm:0.0026557804085314274 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.2672649621963501 norm:0.0026739067398011684 max memory_allocated 22563.91943359375 
[2025-03-02 09:44:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.26714885234832764 norm:0.0025050227995961905 max memory_allocated 22563.91943359375 
[2025-03-02 09:44:49 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.2671293318271637 norm:0.0025318069383502007 max memory_allocated 22563.91943359375 
[2025-03-02 09:45:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.26711151003837585 norm:0.002415830735117197 max memory_allocated 22563.91943359375 
[2025-03-02 09:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.26708680391311646 norm:0.0024913791567087173 max memory_allocated 22563.91943359375 
[2025-03-02 09:46:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.2671053409576416 norm:0.002354722237214446 max memory_allocated 22563.91943359375 
[2025-03-02 09:47:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.26705676317214966 norm:0.002436222042888403 max memory_allocated 22563.91943359375 
[2025-03-02 09:47:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.2670121192932129 norm:0.0023063127882778645 max memory_allocated 22563.91943359375 
[2025-03-02 09:47:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 09:47:50 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:48:24 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.33094632625579834 norm:0.008523614145815372 max memory_allocated 22564.09130859375 
[2025-03-02 09:48:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.3239279091358185 norm:0.006508790422230959 max memory_allocated 22564.09130859375 
[2025-03-02 09:49:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.31747889518737793 norm:0.005320260766893625 max memory_allocated 22564.09130859375 
[2025-03-02 09:50:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.3145381808280945 norm:0.004381069913506508 max memory_allocated 22564.09130859375 
[2025-03-02 09:50:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.31382301449775696 norm:0.0037927774246782064 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.31328198313713074 norm:0.003223226871341467 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.3130589723587036 norm:0.0030123351607471704 max memory_allocated 22564.09130859375 
[2025-03-02 09:52:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.31293901801109314 norm:0.003014520974829793 max memory_allocated 22564.09130859375 
[2025-03-02 09:52:53 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.3127553462982178 norm:0.002828961703926325 max memory_allocated 22564.09130859375 
[2025-03-02 09:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.3126026391983032 norm:0.0026436762418597937 max memory_allocated 22564.09130859375 
[2025-03-02 09:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.31251004338264465 norm:0.0027689021080732346 max memory_allocated 22564.09130859375 
[2025-03-02 09:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.31255900859832764 norm:0.0025696558877825737 max memory_allocated 22564.09130859375 
[2025-03-02 09:55:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.3125056028366089 norm:0.0028080909978598356 max memory_allocated 22564.09130859375 
[2025-03-02 09:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.31250953674316406 norm:0.0024520880542695522 max memory_allocated 22564.09130859375 
[2025-03-02 09:56:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.31235575675964355 norm:0.0025749679189175367 max memory_allocated 22564.09130859375 
[2025-03-02 09:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.3122941553592682 norm:0.002358516212552786 max memory_allocated 22564.09130859375 
[2025-03-02 09:57:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.3122331500053406 norm:0.0024592678528279066 max memory_allocated 22564.09130859375 
[2025-03-02 09:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.31230491399765015 norm:0.002327031223103404 max memory_allocated 22564.09130859375 
[2025-03-02 09:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.3122946321964264 norm:0.0024063093587756157 max memory_allocated 22564.09130859375 
[2025-03-02 09:59:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.3122561573982239 norm:0.002313995035365224 max memory_allocated 22564.09130859375 
[2025-03-02 09:59:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:59:18 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.44094589352607727 norm:0.017315082252025604 max memory_allocated 22564.26318359375 
[2025-03-02 10:00:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.42031729221343994 norm:0.017995379865169525 max memory_allocated 22564.26318359375 
[2025-03-02 10:00:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.4092952013015747 norm:0.018522951751947403 max memory_allocated 22564.26318359375 
[2025-03-02 10:01:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.40463772416114807 norm:0.018905624747276306 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.4019959270954132 norm:0.0188539307564497 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.4005584120750427 norm:0.019538775086402893 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.3994362950325012 norm:0.018254168331623077 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.3987734615802765 norm:0.017101628705859184 max memory_allocated 22564.26318359375 
[2025-03-02 10:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.3982819616794586 norm:0.016977135092020035 max memory_allocated 22564.26318359375 
[2025-03-02 10:04:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.3978194296360016 norm:0.016505850479006767 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.3975299000740051 norm:0.016107235103845596 max memory_allocated 22564.26318359375 
[2025-03-02 10:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.3972378075122833 norm:0.015171276405453682 max memory_allocated 22564.26318359375 
[2025-03-02 10:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.39692217111587524 norm:0.015154056251049042 max memory_allocated 22564.26318359375 
[2025-03-02 10:07:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.3966673016548157 norm:0.014717262238264084 max memory_allocated 22564.26318359375 
[2025-03-02 10:07:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.39662495255470276 norm:0.014099529944360256 max memory_allocated 22564.26318359375 
[2025-03-02 10:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.3967195749282837 norm:0.014058073051273823 max memory_allocated 22564.26318359375 
[2025-03-02 10:08:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.396330863237381 norm:0.013514840975403786 max memory_allocated 22564.26318359375 
[2025-03-02 10:09:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.3962586224079132 norm:0.013271637260913849 max memory_allocated 22564.26318359375 
[2025-03-02 10:09:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.39620697498321533 norm:0.012871106155216694 max memory_allocated 22564.26318359375 
[2025-03-02 10:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.39606359601020813 norm:0.012655389495193958 max memory_allocated 22564.26318359375 
[2025-03-02 10:10:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 10:10:45 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 10:11:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.7928640246391296 norm:0.04723823815584183 max memory_allocated 22564.43505859375 
[2025-03-02 10:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.7458211779594421 norm:0.03419789671897888 max memory_allocated 22564.43505859375 
[2025-03-02 10:12:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.7196177244186401 norm:0.030663106590509415 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.7035036683082581 norm:0.029250897467136383 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.6954566836357117 norm:0.02953823283314705 max memory_allocated 22564.43505859375 
[2025-03-02 10:14:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.6894035935401917 norm:0.02837539091706276 max memory_allocated 22564.43505859375 
[2025-03-02 10:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.685070812702179 norm:0.02688835933804512 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.6829163432121277 norm:0.027935393154621124 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.6815093755722046 norm:0.02860945276916027 max memory_allocated 22564.43505859375 
[2025-03-02 10:16:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.6800380945205688 norm:0.029660217463970184 max memory_allocated 22564.43505859375 
[2025-03-02 10:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.6769011616706848 norm:0.024944065138697624 max memory_allocated 22564.43505859375 
[2025-03-02 10:17:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.6763274669647217 norm:0.027354560792446136 max memory_allocated 22564.43505859375 
[2025-03-02 10:18:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.6749205589294434 norm:0.024817902594804764 max memory_allocated 22564.43505859375 
[2025-03-02 10:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.6739127039909363 norm:0.024226047098636627 max memory_allocated 22564.43505859375 
[2025-03-02 10:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.6728862524032593 norm:0.02334148995578289 max memory_allocated 22564.43505859375 
[2025-03-02 10:19:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.6731974482536316 norm:0.025067199021577835 max memory_allocated 22564.43505859375 
[2025-03-02 10:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.6723796129226685 norm:0.024243200197815895 max memory_allocated 22564.43505859375 
[2025-03-02 10:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.6727439761161804 norm:0.02628576010465622 max memory_allocated 22564.43505859375 
[2025-03-02 10:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.6723235845565796 norm:0.025807898491621017 max memory_allocated 22564.43505859375 
[2025-03-02 10:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.6715396046638489 norm:0.02371804043650627 max memory_allocated 22564.43505859375 
[2025-03-02 10:22:09 root] (main_calib_config2.py 372): INFO 21917.23425912857
[2025-03-02 10:22:14 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 10:23:26 root] (main_calib_config2.py 159): INFO wikitext2 : 5.832823276519775
[2025-03-02 10:23:26 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 10:25:16 root] (main_calib_config2.py 159): INFO c4 : 7.313431262969971
[2025-03-02 12:06:42 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.832823276519775, 'c4': 7.313431262969971, 'results': {'arc_challenge': {'acc': 0.378839590443686, 'acc_stderr': 0.014175915490000324, 'acc_norm': 0.3967576791808874, 'acc_norm_stderr': 0.014296513020180646}, 'hellaswag': {'acc': 0.5525791674965146, 'acc_stderr': 0.00496211552601429, 'acc_norm': 0.7130053774148576, 'acc_norm_stderr': 0.004514345547780337}, 'piqa': {'acc': 0.7769314472252449, 'acc_stderr': 0.009713057213018511, 'acc_norm': 0.7731229597388466, 'acc_norm_stderr': 0.00977158425921518}, 'boolq': {'acc': 0.7223241590214067, 'acc_stderr': 0.0078329915483772}, 'winogrande': {'acc': 0.6535122336227308, 'acc_stderr': 0.013373773411685655}, 'arc_easy': {'acc': 0.664983164983165, 'acc_stderr': 0.00968516076593236, 'acc_norm': 0.523989898989899, 'acc_norm_stderr': 0.010247967392742684}}, 'versions': {'arc_challenge': 0, 'hellaswag': 0, 'piqa': 0, 'boolq': 1, 'winogrande': 0, 'arc_easy': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
