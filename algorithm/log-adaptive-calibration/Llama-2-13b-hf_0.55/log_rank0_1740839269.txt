[2025-03-01 14:27:49 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.55', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.55.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-01 14:28:23 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-01 14:28:23 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.55.pkl
[2025-03-01 14:28:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-01 14:29:00 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.013788344338536263 norm:0.016590088605880737 max memory_allocated 29271.02001953125 
[2025-03-01 14:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.007747837342321873 norm:0.008269916288554668 max memory_allocated 29271.02001953125 
[2025-03-01 14:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.005609479732811451 norm:0.005865301005542278 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.004803291987627745 norm:0.004668018314987421 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.004556412808597088 norm:0.0038916971534490585 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.004357188008725643 norm:0.003155992366373539 max memory_allocated 29271.02001953125 
[2025-03-01 14:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.004266036674380302 norm:0.00269662169739604 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.00404999777674675 norm:0.002324407920241356 max memory_allocated 29271.02001953125 
[2025-03-01 14:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.004004024434834719 norm:0.0021165332291275263 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.003973326180130243 norm:0.0019939334597438574 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.003936002030968666 norm:0.0017515665385872126 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.003968134522438049 norm:0.00166421290487051 max memory_allocated 29271.02001953125 
[2025-03-01 14:39:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.003931125160306692 norm:0.0014818442286923528 max memory_allocated 29271.02001953125 
[2025-03-01 14:40:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.003931928891688585 norm:0.0013099678326398134 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.003913183696568012 norm:0.001319801202043891 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.003823232837021351 norm:0.0011634663678705692 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0038368385285139084 norm:0.001223841798491776 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0038157606031745672 norm:0.001092154416255653 max memory_allocated 29271.02001953125 
[2025-03-01 14:44:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0038137349765747786 norm:0.001140850712545216 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0037982335779815912 norm:0.0009465180337429047 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-01 14:45:45 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.025338558480143547 norm:0.01213961374014616 max memory_allocated 29271.02001953125 
[2025-03-01 14:47:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.01580520160496235 norm:0.006960094906389713 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.012033241800963879 norm:0.004633600823581219 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.011091604828834534 norm:0.0037661753594875336 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.01067335158586502 norm:0.00330949854105711 max memory_allocated 29271.02001953125 
[2025-03-01 14:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.01041707769036293 norm:0.0028768491465598345 max memory_allocated 29271.02001953125 
[2025-03-01 14:51:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.01019006222486496 norm:0.0025303654838353395 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.010042456910014153 norm:0.0022785565815865993 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.009917296469211578 norm:0.002019896637648344 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.009805533103644848 norm:0.0017999591073021293 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.009718867018818855 norm:0.0016165247652679682 max memory_allocated 29271.02001953125 
[2025-03-01 14:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.009651457890868187 norm:0.001420438289642334 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.009592504240572453 norm:0.001307309721596539 max memory_allocated 29271.02001953125 
[2025-03-01 14:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.009554974734783173 norm:0.0012864461168646812 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.009582221508026123 norm:0.00132271449547261 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.009550146758556366 norm:0.0012169311521574855 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.009512154385447502 norm:0.0012200386263430119 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.009539616294205189 norm:0.0011585134780034423 max memory_allocated 29271.02001953125 
[2025-03-01 15:01:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.00949917733669281 norm:0.0011278231395408511 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.009554380550980568 norm:0.0010484060039743781 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-01 15:02:35 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 15:03:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.027488701045513153 norm:0.007490771356970072 max memory_allocated 29271.02001953125 
[2025-03-01 15:04:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.020982978865504265 norm:0.005760758649557829 max memory_allocated 29271.02001953125 
[2025-03-01 15:05:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.01780487410724163 norm:0.004235820844769478 max memory_allocated 29271.02001953125 
[2025-03-01 15:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.01678989641368389 norm:0.003356096101924777 max memory_allocated 29271.02001953125 
[2025-03-01 15:06:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.016297664493322372 norm:0.002752330619841814 max memory_allocated 29271.02001953125 
[2025-03-01 15:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.01593061350286007 norm:0.0023087882436811924 max memory_allocated 29271.02001953125 
[2025-03-01 15:08:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.01561061106622219 norm:0.0019493435975164175 max memory_allocated 29271.02001953125 
[2025-03-01 15:09:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.015405317768454552 norm:0.0017712207045406103 max memory_allocated 29271.02001953125 
[2025-03-01 15:10:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.015255331993103027 norm:0.0016424250788986683 max memory_allocated 29271.02001953125 
[2025-03-01 15:10:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.015139657072722912 norm:0.0015471914084628224 max memory_allocated 29271.02001953125 
[2025-03-01 15:11:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.015080921351909637 norm:0.0014560455456376076 max memory_allocated 29271.02001953125 
[2025-03-01 15:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.01508164033293724 norm:0.0014525074511766434 max memory_allocated 29271.02001953125 
[2025-03-01 15:13:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.015072370879352093 norm:0.0013740998692810535 max memory_allocated 29271.02001953125 
[2025-03-01 15:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.01506203506141901 norm:0.001313514425419271 max memory_allocated 29271.02001953125 
[2025-03-01 15:15:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.01501441840082407 norm:0.001257428084500134 max memory_allocated 29271.02001953125 
[2025-03-01 15:15:50 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.014995332807302475 norm:0.0012324133422225714 max memory_allocated 29271.02001953125 
[2025-03-01 15:16:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.014981238171458244 norm:0.0011880717938765883 max memory_allocated 29271.02001953125 
[2025-03-01 15:17:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.014994713477790356 norm:0.0011818292550742626 max memory_allocated 29271.02001953125 
[2025-03-01 15:18:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.014989037998020649 norm:0.0011416706256568432 max memory_allocated 29271.02001953125 
[2025-03-01 15:19:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.014991121366620064 norm:0.0011288684327155352 max memory_allocated 29271.02001953125 
[2025-03-01 15:19:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-01 15:20:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.1583629846572876 norm:0.01759938895702362 max memory_allocated 29271.43798828125 
[2025-03-01 15:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.11881157010793686 norm:0.010197504423558712 max memory_allocated 29271.43798828125 
[2025-03-01 15:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.08903291076421738 norm:0.007964469492435455 max memory_allocated 29271.43798828125 
[2025-03-01 15:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.08018968254327774 norm:0.007547758519649506 max memory_allocated 29271.43798828125 
[2025-03-01 15:23:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.0744953602552414 norm:0.006442627403885126 max memory_allocated 29271.43798828125 
[2025-03-01 15:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.06717196106910706 norm:0.006984390784054995 max memory_allocated 29271.43798828125 
[2025-03-01 15:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.05711572244763374 norm:0.004917963407933712 max memory_allocated 29271.43798828125 
[2025-03-01 15:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.05366985872387886 norm:0.003834286704659462 max memory_allocated 29271.43798828125 
[2025-03-01 15:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.05300150066614151 norm:0.0038779904134571552 max memory_allocated 29271.43798828125 
[2025-03-01 15:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.052530355751514435 norm:0.004031979478895664 max memory_allocated 29271.43798828125 
[2025-03-01 15:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.05129329487681389 norm:0.00404173182323575 max memory_allocated 29271.43798828125 
[2025-03-01 15:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.050567567348480225 norm:0.0036468326579779387 max memory_allocated 29271.43798828125 
[2025-03-01 15:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.0509859062731266 norm:0.0035623395815491676 max memory_allocated 29271.43798828125 
[2025-03-01 15:30:59 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.05091017857193947 norm:0.003853745758533478 max memory_allocated 29271.43798828125 
[2025-03-01 15:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.050130877643823624 norm:0.003678149776533246 max memory_allocated 29271.43798828125 
[2025-03-01 15:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.05036104843020439 norm:0.004064541310071945 max memory_allocated 29271.43798828125 
[2025-03-01 15:33:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.05126343294978142 norm:0.003967332188040018 max memory_allocated 29271.43798828125 
[2025-03-01 15:34:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.0519331693649292 norm:0.0043784575536847115 max memory_allocated 29271.43798828125 
[2025-03-01 15:35:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.051295943558216095 norm:0.0038100099191069603 max memory_allocated 29271.43798828125 
[2025-03-01 15:35:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.0518881119787693 norm:0.004145149607211351 max memory_allocated 29271.43798828125 
[2025-03-01 15:36:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-01 15:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.05509691685438156 norm:0.0007685057353228331 max memory_allocated 29271.43798828125 
[2025-03-01 15:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.04787874221801758 norm:0.00032916065538302064 max memory_allocated 29271.43798828125 
[2025-03-01 15:38:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.043834950774908066 norm:0.00020100586698390543 max memory_allocated 29271.43798828125 
[2025-03-01 15:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.04232407733798027 norm:0.00017572152137290686 max memory_allocated 29271.43798828125 
[2025-03-01 15:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.041526906192302704 norm:0.0001690185017650947 max memory_allocated 29271.43798828125 
[2025-03-01 15:41:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.040948234498500824 norm:0.0001633091305848211 max memory_allocated 29271.43798828125 
[2025-03-01 15:42:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.04058195650577545 norm:0.0001631418999750167 max memory_allocated 29271.43798828125 
[2025-03-01 15:42:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.040403399616479874 norm:0.00016451493138447404 max memory_allocated 29271.43798828125 
[2025-03-01 15:43:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.04030299931764603 norm:0.00016503172810189426 max memory_allocated 29271.43798828125 
[2025-03-01 15:44:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.040252164006233215 norm:0.0001655798841966316 max memory_allocated 29271.43798828125 
[2025-03-01 15:45:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.04023514315485954 norm:0.00017431378364562988 max memory_allocated 29271.43798828125 
[2025-03-01 15:46:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.040207669138908386 norm:0.00017134811787400395 max memory_allocated 29271.43798828125 
[2025-03-01 15:46:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.04019739478826523 norm:0.00017704365018289536 max memory_allocated 29271.43798828125 
[2025-03-01 15:47:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.04018748924136162 norm:0.0001766914501786232 max memory_allocated 29271.43798828125 
[2025-03-01 15:48:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.04016890376806259 norm:0.00016435523866675794 max memory_allocated 29271.43798828125 
[2025-03-01 15:49:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.040172360837459564 norm:0.00017061927064787596 max memory_allocated 29271.43798828125 
[2025-03-01 15:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.04016837850213051 norm:0.0001767879439285025 max memory_allocated 29271.43798828125 
[2025-03-01 15:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.04012993350625038 norm:0.00017662433674558997 max memory_allocated 29271.43798828125 
[2025-03-01 15:51:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.040133219212293625 norm:0.00017465680139139295 max memory_allocated 29271.43798828125 
[2025-03-01 15:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.04013753682374954 norm:0.00018152041593566537 max memory_allocated 29271.43798828125 
[2025-03-01 15:52:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-01 15:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.05888460576534271 norm:0.0011800522916018963 max memory_allocated 29271.43798828125 
[2025-03-01 15:54:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.049568869173526764 norm:0.0004828278033528477 max memory_allocated 29271.43798828125 
[2025-03-01 15:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.044841740280389786 norm:0.0002659488236531615 max memory_allocated 29271.43798828125 
[2025-03-01 15:56:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.0431424155831337 norm:0.00019198139489162713 max memory_allocated 29271.43798828125 
[2025-03-01 15:57:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.04213883355259895 norm:0.00015693511522840708 max memory_allocated 29271.43798828125 
[2025-03-01 15:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.041526611894369125 norm:0.00014405749971047044 max memory_allocated 29271.43798828125 
[2025-03-01 15:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.04117586091160774 norm:0.00013739534188061953 max memory_allocated 29271.43798828125 
[2025-03-01 15:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.04100240394473076 norm:0.0001289469510084018 max memory_allocated 29271.43798828125 
[2025-03-01 16:00:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.040894076228141785 norm:0.00012603096547536552 max memory_allocated 29271.43798828125 
[2025-03-01 16:01:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.040811728686094284 norm:0.00012357764353509992 max memory_allocated 29271.43798828125 
[2025-03-01 16:02:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.04075103625655174 norm:0.00012592031271196902 max memory_allocated 29271.43798828125 
[2025-03-01 16:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.040705494582653046 norm:0.00011971461935900152 max memory_allocated 29271.43798828125 
[2025-03-01 16:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.04066704213619232 norm:0.00012563532800413668 max memory_allocated 29271.43798828125 
[2025-03-01 16:04:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.0406525693833828 norm:0.00012784963473677635 max memory_allocated 29271.43798828125 
[2025-03-01 16:05:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.04063151776790619 norm:0.00013126220437698066 max memory_allocated 29271.43798828125 
[2025-03-01 16:06:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.04060506448149681 norm:0.0001319127477472648 max memory_allocated 29271.43798828125 
[2025-03-01 16:07:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.04059474915266037 norm:0.00012849949416704476 max memory_allocated 29271.43798828125 
[2025-03-01 16:07:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.040591057389974594 norm:0.00013607046275865287 max memory_allocated 29271.43798828125 
[2025-03-01 16:08:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.04056158661842346 norm:0.00013344158651307225 max memory_allocated 29271.43798828125 
[2025-03-01 16:09:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.04055846855044365 norm:0.00013515155296772718 max memory_allocated 29271.43798828125 
[2025-03-01 16:09:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-01 16:10:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.06369216740131378 norm:0.001546080457046628 max memory_allocated 29272.00048828125 
[2025-03-01 16:11:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.05311879888176918 norm:0.0006448426283895969 max memory_allocated 29272.00048828125 
[2025-03-01 16:12:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.047385167330503464 norm:0.00036530086072161794 max memory_allocated 29272.00048828125 
[2025-03-01 16:13:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.04546517878770828 norm:0.00024677126202732325 max memory_allocated 29272.00048828125 
[2025-03-01 16:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.04432172700762749 norm:0.00020464685803744942 max memory_allocated 29272.00048828125 
[2025-03-01 16:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.04362601786851883 norm:0.00017991819186136127 max memory_allocated 29272.00048828125 
[2025-03-01 16:15:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.043228864669799805 norm:0.00016092092846520245 max memory_allocated 29272.00048828125 
[2025-03-01 16:16:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.043016113340854645 norm:0.00015860082930885255 max memory_allocated 29272.00048828125 
[2025-03-01 16:17:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.04285094514489174 norm:0.00015306135173887014 max memory_allocated 29272.00048828125 
[2025-03-01 16:18:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.0427776575088501 norm:0.00015081491437740624 max memory_allocated 29272.00048828125 
[2025-03-01 16:18:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.042738139629364014 norm:0.00015308253932744265 max memory_allocated 29272.00048828125 
[2025-03-01 16:19:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.04267062619328499 norm:0.00014218781143426895 max memory_allocated 29272.00048828125 
[2025-03-01 16:20:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.042639248073101044 norm:0.00014081181143410504 max memory_allocated 29272.00048828125 
[2025-03-01 16:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.04260686784982681 norm:0.00014719912724103779 max memory_allocated 29272.00048828125 
[2025-03-01 16:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.042580850422382355 norm:0.00012914043327327818 max memory_allocated 29272.00048828125 
[2025-03-01 16:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.04255151003599167 norm:0.00012783423881046474 max memory_allocated 29272.00048828125 
[2025-03-01 16:23:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.0425262451171875 norm:0.00013018331083003432 max memory_allocated 29272.00048828125 
[2025-03-01 16:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.04252328723669052 norm:0.00013078557094559073 max memory_allocated 29272.00048828125 
[2025-03-01 16:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.0425243005156517 norm:0.00013421944458968937 max memory_allocated 29272.00048828125 
[2025-03-01 16:26:24 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.04251909255981445 norm:0.00013888518151361495 max memory_allocated 29272.00048828125 
[2025-03-01 16:26:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-01 16:27:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.07366600632667542 norm:0.0016249071341007948 max memory_allocated 29272.18798828125 
[2025-03-01 16:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.060023218393325806 norm:0.000679032935295254 max memory_allocated 29272.18798828125 
[2025-03-01 16:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.05335726588964462 norm:0.00040772196371108294 max memory_allocated 29272.18798828125 
[2025-03-01 16:30:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.05114210024476051 norm:0.0003112049598712474 max memory_allocated 29272.18798828125 
[2025-03-01 16:30:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.04992319270968437 norm:0.00026911633904092014 max memory_allocated 29272.18798828125 
[2025-03-01 16:31:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.049162857234478 norm:0.00024824863066896796 max memory_allocated 29272.18798828125 
[2025-03-01 16:32:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.048789698630571365 norm:0.0002327226393390447 max memory_allocated 29272.18798828125 
[2025-03-01 16:33:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.04851091280579567 norm:0.0002289077383466065 max memory_allocated 29272.18798828125 
[2025-03-01 16:34:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.04832431301474571 norm:0.00023056456120684743 max memory_allocated 29272.18798828125 
[2025-03-01 16:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.048182372003793716 norm:0.0002256319421576336 max memory_allocated 29272.18798828125 
[2025-03-01 16:35:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.04806414619088173 norm:0.00021913165983278304 max memory_allocated 29272.18798828125 
[2025-03-01 16:36:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.048004522919654846 norm:0.00021559234301093966 max memory_allocated 29272.18798828125 
[2025-03-01 16:37:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.04793918877840042 norm:0.00021641825151164085 max memory_allocated 29272.18798828125 
[2025-03-01 16:38:17 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.047879815101623535 norm:0.00020198742276988924 max memory_allocated 29272.18798828125 
[2025-03-01 16:39:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.047832928597927094 norm:0.0002075696538668126 max memory_allocated 29272.18798828125 
[2025-03-01 16:39:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.04782906547188759 norm:0.0002004058624152094 max memory_allocated 29272.18798828125 
[2025-03-01 16:40:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.04781697317957878 norm:0.00020241644233465195 max memory_allocated 29272.18798828125 
[2025-03-01 16:41:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.04777594283223152 norm:0.00020017851784359664 max memory_allocated 29272.18798828125 
[2025-03-01 16:42:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.047716088593006134 norm:0.0001977054780581966 max memory_allocated 29272.18798828125 
[2025-03-01 16:43:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.04771251976490021 norm:0.00020471382595133036 max memory_allocated 29272.18798828125 
[2025-03-01 16:43:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-01 16:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.0756458193063736 norm:0.0017206731718033552 max memory_allocated 29272.37548828125 
[2025-03-01 16:45:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.06300578266382217 norm:0.0007605991559103131 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.05638977512717247 norm:0.0004355912678875029 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.05405278503894806 norm:0.00030806902213953435 max memory_allocated 29272.37548828125 
[2025-03-01 16:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.05273420736193657 norm:0.00024600402684882283 max memory_allocated 29272.37548828125 
[2025-03-01 16:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.05195905268192291 norm:0.00021158065646886826 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.05149369686841965 norm:0.00018944112525787205 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.051242925226688385 norm:0.00018281085067428648 max memory_allocated 29272.37548828125 
[2025-03-01 16:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.05104377493262291 norm:0.00017676563584245741 max memory_allocated 29272.37548828125 
[2025-03-01 16:51:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.050921108573675156 norm:0.00016558436618652195 max memory_allocated 29272.37548828125 
[2025-03-01 16:52:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.05083509534597397 norm:0.00016011302068363875 max memory_allocated 29272.37548828125 
[2025-03-01 16:53:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.050750914961099625 norm:0.00015882911975495517 max memory_allocated 29272.37548828125 
[2025-03-01 16:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.05069046467542648 norm:0.00015587576490361243 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.05064774304628372 norm:0.0001582739205332473 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.050622500479221344 norm:0.00015862718282733113 max memory_allocated 29272.37548828125 
[2025-03-01 16:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.05059181526303291 norm:0.0001549248700030148 max memory_allocated 29272.37548828125 
[2025-03-01 16:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.0505695603787899 norm:0.0001526589912828058 max memory_allocated 29272.37548828125 
[2025-03-01 16:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.05053642392158508 norm:0.00015054452524054796 max memory_allocated 29272.37548828125 
[2025-03-01 16:59:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.05052362009882927 norm:0.0001515033218311146 max memory_allocated 29272.37548828125 
[2025-03-01 17:00:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.05051793158054352 norm:0.0001555279886815697 max memory_allocated 29272.37548828125 
[2025-03-01 17:00:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-01 17:01:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.09934975206851959 norm:0.003348585683852434 max memory_allocated 29272.56298828125 
[2025-03-01 17:02:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.07530911266803741 norm:0.0013557731872424483 max memory_allocated 29272.56298828125 
[2025-03-01 17:02:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.0641876757144928 norm:0.0006530172540806234 max memory_allocated 29272.56298828125 
[2025-03-01 17:03:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.06076652556657791 norm:0.00045004679122939706 max memory_allocated 29272.56298828125 
[2025-03-01 17:04:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.05903291329741478 norm:0.000362314167432487 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.057912178337574005 norm:0.000307657930534333 max memory_allocated 29272.56298828125 
[2025-03-01 17:06:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.057250138372182846 norm:0.00028455679421313107 max memory_allocated 29272.56298828125 
[2025-03-01 17:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.056876834481954575 norm:0.00026964276912622154 max memory_allocated 29272.56298828125 
[2025-03-01 17:07:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.05657366290688515 norm:0.00025669843307696283 max memory_allocated 29272.56298828125 
[2025-03-01 17:08:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.05633927136659622 norm:0.0002552315127104521 max memory_allocated 29272.56298828125 
[2025-03-01 17:09:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.05618761479854584 norm:0.00024526429479010403 max memory_allocated 29272.56298828125 
[2025-03-01 17:10:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.05605020746588707 norm:0.00022080984490457922 max memory_allocated 29272.56298828125 
[2025-03-01 17:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.05595283955335617 norm:0.00021767620637547225 max memory_allocated 29272.56298828125 
[2025-03-01 17:12:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.055852267891168594 norm:0.00021232801373116672 max memory_allocated 29272.56298828125 
[2025-03-01 17:12:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.05576946958899498 norm:0.00021443060541059822 max memory_allocated 29272.56298828125 
[2025-03-01 17:13:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.05570882186293602 norm:0.0002203650656156242 max memory_allocated 29272.56298828125 
[2025-03-01 17:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.055636294186115265 norm:0.00022408386575989425 max memory_allocated 29272.56298828125 
[2025-03-01 17:15:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.055564381182193756 norm:0.00020863433019258082 max memory_allocated 29272.56298828125 
[2025-03-01 17:16:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.05550989881157875 norm:0.000211392150959 max memory_allocated 29272.56298828125 
[2025-03-01 17:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.05552452802658081 norm:0.00024002180725801736 max memory_allocated 29272.56298828125 
[2025-03-01 17:17:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-01 17:18:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.08761649578809738 norm:0.001800099853426218 max memory_allocated 29272.75048828125 
[2025-03-01 17:18:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.07340151071548462 norm:0.0008798828930594027 max memory_allocated 29272.75048828125 
[2025-03-01 17:19:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.06578879803419113 norm:0.000507594901137054 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.06280070543289185 norm:0.0003476687998045236 max memory_allocated 29272.75048828125 
[2025-03-01 17:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.061332542449235916 norm:0.0002683714556042105 max memory_allocated 29272.75048828125 
[2025-03-01 17:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.06052396446466446 norm:0.00022607512073591352 max memory_allocated 29272.75048828125 
[2025-03-01 17:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.06007739529013634 norm:0.00019994181639049202 max memory_allocated 29272.75048828125 
[2025-03-01 17:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.05983385071158409 norm:0.0001881625212263316 max memory_allocated 29272.75048828125 
[2025-03-01 17:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.05968061462044716 norm:0.0001763827312970534 max memory_allocated 29272.75048828125 
[2025-03-01 17:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.05955444276332855 norm:0.00016694293299224228 max memory_allocated 29272.75048828125 
[2025-03-01 17:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.05948033183813095 norm:0.0001636554952710867 max memory_allocated 29272.75048828125 
[2025-03-01 17:27:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.05938033014535904 norm:0.0001582390395924449 max memory_allocated 29272.75048828125 
[2025-03-01 17:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.05931374430656433 norm:0.00016079741180874407 max memory_allocated 29272.75048828125 
[2025-03-01 17:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.05928654968738556 norm:0.0001576161157572642 max memory_allocated 29272.75048828125 
[2025-03-01 17:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.059238433837890625 norm:0.00015868741320446134 max memory_allocated 29272.75048828125 
[2025-03-01 17:30:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.059185825288295746 norm:0.00014999225095380098 max memory_allocated 29272.75048828125 
[2025-03-01 17:31:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.05914856493473053 norm:0.00015158404130488634 max memory_allocated 29272.75048828125 
[2025-03-01 17:32:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.05912812426686287 norm:0.00015000501298345625 max memory_allocated 29272.75048828125 
[2025-03-01 17:32:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.059104375541210175 norm:0.00015025140601210296 max memory_allocated 29272.75048828125 
[2025-03-01 17:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.05909634754061699 norm:0.00014836368791293353 max memory_allocated 29272.75048828125 
[2025-03-01 17:34:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-01 17:34:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.08828569203615189 norm:0.0013009716058149934 max memory_allocated 29272.93798828125 
[2025-03-01 17:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.07555362582206726 norm:0.0006105296779423952 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.06851229816675186 norm:0.00035391090204939246 max memory_allocated 29272.93798828125 
[2025-03-01 17:37:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.06588186323642731 norm:0.00024846906308084726 max memory_allocated 29272.93798828125 
[2025-03-01 17:38:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.06461283564567566 norm:0.00019900384359061718 max memory_allocated 29272.93798828125 
[2025-03-01 17:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.06389617919921875 norm:0.0001769996015354991 max memory_allocated 29272.93798828125 
[2025-03-01 17:39:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.06352762132883072 norm:0.00016885885270312428 max memory_allocated 29272.93798828125 
[2025-03-01 17:40:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.06332676857709885 norm:0.00016442834748886526 max memory_allocated 29272.93798828125 
[2025-03-01 17:41:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.06320612132549286 norm:0.0001530517329229042 max memory_allocated 29272.93798828125 
[2025-03-01 17:42:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.06311412155628204 norm:0.00015286446432583034 max memory_allocated 29272.93798828125 
[2025-03-01 17:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.06303711980581284 norm:0.00015009779599495232 max memory_allocated 29272.93798828125 
[2025-03-01 17:43:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.06295779347419739 norm:0.0001448486582376063 max memory_allocated 29272.93798828125 
[2025-03-01 17:44:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.062896229326725 norm:0.00014341500354930758 max memory_allocated 29272.93798828125 
[2025-03-01 17:45:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.06285611540079117 norm:0.00014410958101507276 max memory_allocated 29272.93798828125 
[2025-03-01 17:46:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.06283476203680038 norm:0.00014205936167854816 max memory_allocated 29272.93798828125 
[2025-03-01 17:47:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.06279634684324265 norm:0.00014413773897103965 max memory_allocated 29272.93798828125 
[2025-03-01 17:48:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.06276688724756241 norm:0.00014690188982058316 max memory_allocated 29272.93798828125 
[2025-03-01 17:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.06273750215768814 norm:0.00013959532952867448 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.06270589679479599 norm:0.0001362545444862917 max memory_allocated 29272.93798828125 
[2025-03-01 17:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.06268522143363953 norm:0.00013764540199190378 max memory_allocated 29272.93798828125 
[2025-03-01 17:50:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-01 17:51:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.09352126717567444 norm:0.0014866519486531615 max memory_allocated 29273.12548828125 
[2025-03-01 17:52:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.0791315883398056 norm:0.0006719108787365258 max memory_allocated 29273.12548828125 
[2025-03-01 17:53:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.07125481963157654 norm:0.00036718702176585793 max memory_allocated 29273.12548828125 
[2025-03-01 17:54:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.06852530688047409 norm:0.00025331004871986806 max memory_allocated 29273.12548828125 
[2025-03-01 17:55:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.06723583489656448 norm:0.0002055206714430824 max memory_allocated 29273.12548828125 
[2025-03-01 17:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.06651392579078674 norm:0.00018149353854823858 max memory_allocated 29273.12548828125 
[2025-03-01 17:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.06610431522130966 norm:0.00016618931840639561 max memory_allocated 29273.12548828125 
[2025-03-01 17:57:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.06585470587015152 norm:0.00015664330567233264 max memory_allocated 29273.12548828125 
[2025-03-01 17:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.06568238139152527 norm:0.00015061382146086544 max memory_allocated 29273.12548828125 
[2025-03-01 17:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.06556706130504608 norm:0.00014326894597616047 max memory_allocated 29273.12548828125 
[2025-03-01 17:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.06547096371650696 norm:0.00013998753274790943 max memory_allocated 29273.12548828125 
[2025-03-01 18:00:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.06539586931467056 norm:0.00013915594900026917 max memory_allocated 29273.12548828125 
[2025-03-01 18:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.06533674895763397 norm:0.00013414566637948155 max memory_allocated 29273.12548828125 
[2025-03-01 18:02:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.06530402600765228 norm:0.00013241960550658405 max memory_allocated 29273.12548828125 
[2025-03-01 18:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.06525357067584991 norm:0.0001284911559196189 max memory_allocated 29273.12548828125 
[2025-03-01 18:04:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.06519974768161774 norm:0.00012202469224575907 max memory_allocated 29273.12548828125 
[2025-03-01 18:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.06516945362091064 norm:0.00012156466254964471 max memory_allocated 29273.12548828125 
[2025-03-01 18:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.0651460662484169 norm:0.00011877169163199142 max memory_allocated 29273.12548828125 
[2025-03-01 18:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.06512128561735153 norm:0.00011853105388581753 max memory_allocated 29273.12548828125 
[2025-03-01 18:07:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.06509602814912796 norm:0.00011953581997659057 max memory_allocated 29273.12548828125 
[2025-03-01 18:07:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-01 18:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.09244033694267273 norm:0.001383470487780869 max memory_allocated 29273.31298828125 
[2025-03-01 18:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.08032269775867462 norm:0.0006617680774070323 max memory_allocated 29273.31298828125 
[2025-03-01 18:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.07357639819383621 norm:0.0003980114124715328 max memory_allocated 29273.31298828125 
[2025-03-01 18:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.07090117037296295 norm:0.00028686682344414294 max memory_allocated 29273.31298828125 
[2025-03-01 18:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.069561667740345 norm:0.0002332525618840009 max memory_allocated 29273.31298828125 
[2025-03-01 18:12:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.06879766285419464 norm:0.0002017082879319787 max memory_allocated 29273.31298828125 
[2025-03-01 18:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.06832808256149292 norm:0.00018398246902506799 max memory_allocated 29273.31298828125 
[2025-03-01 18:14:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.06806057691574097 norm:0.0001760047598509118 max memory_allocated 29273.31298828125 
[2025-03-01 18:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.06789365410804749 norm:0.00016491823771502823 max memory_allocated 29273.31298828125 
[2025-03-01 18:15:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.06778787076473236 norm:0.0001558997028041631 max memory_allocated 29273.31298828125 
[2025-03-01 18:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.06768441945314407 norm:0.00014881811512168497 max memory_allocated 29273.31298828125 
[2025-03-01 18:17:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.06758777052164078 norm:0.000144557241583243 max memory_allocated 29273.31298828125 
[2025-03-01 18:18:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.06752791255712509 norm:0.00014340878988150507 max memory_allocated 29273.31298828125 
[2025-03-01 18:19:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.06748485565185547 norm:0.0001453734003007412 max memory_allocated 29273.31298828125 
[2025-03-01 18:20:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.06744349002838135 norm:0.00014240707969292998 max memory_allocated 29273.31298828125 
[2025-03-01 18:20:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.06741610914468765 norm:0.00013620204117614776 max memory_allocated 29273.31298828125 
[2025-03-01 18:21:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.06737823784351349 norm:0.00013823664630763233 max memory_allocated 29273.31298828125 
[2025-03-01 18:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.06735576689243317 norm:0.00013918416516389698 max memory_allocated 29273.31298828125 
[2025-03-01 18:23:21 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.06731508672237396 norm:0.00013836202560923994 max memory_allocated 29273.31298828125 
[2025-03-01 18:24:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.06730613857507706 norm:0.00013650799519382417 max memory_allocated 29273.31298828125 
[2025-03-01 18:24:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-01 18:25:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.0952606126666069 norm:0.0013326021144166589 max memory_allocated 29273.50048828125 
[2025-03-01 18:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.08343145996332169 norm:0.0006745687569491565 max memory_allocated 29273.50048828125 
[2025-03-01 18:26:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.07627956569194794 norm:0.000381207384634763 max memory_allocated 29273.50048828125 
[2025-03-01 18:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.07343737035989761 norm:0.0002524377778172493 max memory_allocated 29273.50048828125 
[2025-03-01 18:28:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.07224355638027191 norm:0.00020744360517710447 max memory_allocated 29273.50048828125 
[2025-03-01 18:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.07154257595539093 norm:0.00018384552095085382 max memory_allocated 29273.50048828125 
[2025-03-01 18:30:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.07111524045467377 norm:0.00016992780729196966 max memory_allocated 29273.50048828125 
[2025-03-01 18:31:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.07085134088993073 norm:0.0001589725143276155 max memory_allocated 29273.50048828125 
[2025-03-01 18:31:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.07068667560815811 norm:0.00015204577357508242 max memory_allocated 29273.50048828125 
[2025-03-01 18:32:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.07054528594017029 norm:0.000141576660098508 max memory_allocated 29273.50048828125 
[2025-03-01 18:33:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.0704459473490715 norm:0.0001365556672681123 max memory_allocated 29273.50048828125 
[2025-03-01 18:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.07036248594522476 norm:0.00013159317313693464 max memory_allocated 29273.50048828125 
[2025-03-01 18:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.07028606534004211 norm:0.00012826155580114573 max memory_allocated 29273.50048828125 
[2025-03-01 18:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.07023674249649048 norm:0.000129372114315629 max memory_allocated 29273.50048828125 
[2025-03-01 18:36:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.07019912451505661 norm:0.00012842111755162477 max memory_allocated 29273.50048828125 
[2025-03-01 18:37:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.07016202807426453 norm:0.00012514345871750265 max memory_allocated 29273.50048828125 
[2025-03-01 18:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.07013902813196182 norm:0.0001270178472623229 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.0701076090335846 norm:0.0001275857794098556 max memory_allocated 29273.50048828125 
[2025-03-01 18:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.07008099555969238 norm:0.0001277709088753909 max memory_allocated 29273.50048828125 
[2025-03-01 18:41:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.0700472816824913 norm:0.00012504871119745076 max memory_allocated 29273.50048828125 
[2025-03-01 18:41:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-01 18:42:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.09093144536018372 norm:0.0009416104294359684 max memory_allocated 29273.68798828125 
[2025-03-01 18:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.08190961927175522 norm:0.00045866682194173336 max memory_allocated 29273.68798828125 
[2025-03-01 18:43:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.07570135593414307 norm:0.0002762522199191153 max memory_allocated 29273.68798828125 
[2025-03-01 18:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.07344241440296173 norm:0.00020073997438885272 max memory_allocated 29273.68798828125 
[2025-03-01 18:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.07236960530281067 norm:0.00016979806241579354 max memory_allocated 29273.68798828125 
[2025-03-01 18:46:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.07171447575092316 norm:0.00015094985428731889 max memory_allocated 29273.68798828125 
[2025-03-01 18:47:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.07131075859069824 norm:0.00013637784286402166 max memory_allocated 29273.68798828125 
[2025-03-01 18:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.07109209150075912 norm:0.00012980755127500743 max memory_allocated 29273.68798828125 
[2025-03-01 18:48:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.07095551490783691 norm:0.0001258328411495313 max memory_allocated 29273.68798828125 
[2025-03-01 18:49:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.07084579020738602 norm:0.00012207466352265328 max memory_allocated 29273.68798828125 
[2025-03-01 18:50:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.07076014578342438 norm:0.00011903538688784465 max memory_allocated 29273.68798828125 
[2025-03-01 18:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.0706804022192955 norm:0.0001127873983932659 max memory_allocated 29273.68798828125 
[2025-03-01 18:52:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.07063473761081696 norm:0.00011044136772397906 max memory_allocated 29273.68798828125 
[2025-03-01 18:52:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.07059427350759506 norm:0.0001084485775209032 max memory_allocated 29273.68798828125 
[2025-03-01 18:53:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.07054555416107178 norm:0.00010606048454064876 max memory_allocated 29273.68798828125 
[2025-03-01 18:54:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.07051333785057068 norm:0.00010552271851338446 max memory_allocated 29273.68798828125 
[2025-03-01 18:55:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.07048246264457703 norm:0.00010419634054414928 max memory_allocated 29273.68798828125 
[2025-03-01 18:56:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.07046239823102951 norm:0.00010298348206561059 max memory_allocated 29273.68798828125 
[2025-03-01 18:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.07045945525169373 norm:0.00010289305646438152 max memory_allocated 29273.68798828125 
[2025-03-01 18:57:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.07043695449829102 norm:0.00010265780292684212 max memory_allocated 29273.68798828125 
[2025-03-01 18:58:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-01 18:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.09534470736980438 norm:0.0013506475370377302 max memory_allocated 29273.87548828125 
[2025-03-01 18:59:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.08493164926767349 norm:0.000619602098595351 max memory_allocated 29273.87548828125 
[2025-03-01 19:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.07806530594825745 norm:0.0003635098983068019 max memory_allocated 29273.87548828125 
[2025-03-01 19:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.07558204978704453 norm:0.00025318749248981476 max memory_allocated 29273.87548828125 
[2025-03-01 19:02:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.07434198260307312 norm:0.00021460768766701221 max memory_allocated 29273.87548828125 
[2025-03-01 19:03:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.07359299063682556 norm:0.00019372023234609514 max memory_allocated 29273.87548828125 
[2025-03-01 19:03:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.0731351375579834 norm:0.00017812338774092495 max memory_allocated 29273.87548828125 
[2025-03-01 19:04:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.07282006740570068 norm:0.00017071646288968623 max memory_allocated 29273.87548828125 
[2025-03-01 19:05:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.07262872159481049 norm:0.00016349719953723252 max memory_allocated 29273.87548828125 
[2025-03-01 19:06:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.07247736304998398 norm:0.00015761677059344947 max memory_allocated 29273.87548828125 
[2025-03-01 19:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.07238008826971054 norm:0.00015548137889709324 max memory_allocated 29273.87548828125 
[2025-03-01 19:08:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.0722816064953804 norm:0.00014578417176380754 max memory_allocated 29273.87548828125 
[2025-03-01 19:08:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.07220692187547684 norm:0.00014296607696451247 max memory_allocated 29273.87548828125 
[2025-03-01 19:09:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.07214446365833282 norm:0.0001382028276566416 max memory_allocated 29273.87548828125 
[2025-03-01 19:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.07209114730358124 norm:0.00013847224181517959 max memory_allocated 29273.87548828125 
[2025-03-01 19:11:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.07202759385108948 norm:0.0001359198649879545 max memory_allocated 29273.87548828125 
[2025-03-01 19:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.07198963314294815 norm:0.00013311866496223956 max memory_allocated 29273.87548828125 
[2025-03-01 19:12:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.0719391480088234 norm:0.0001283479214180261 max memory_allocated 29273.87548828125 
[2025-03-01 19:13:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.07191798090934753 norm:0.00012834806693717837 max memory_allocated 29273.87548828125 
[2025-03-01 19:14:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.07188484817743301 norm:0.00012166813394287601 max memory_allocated 29273.87548828125 
[2025-03-01 19:14:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-01 19:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.09057677537202835 norm:0.001148877083323896 max memory_allocated 29274.06298828125 
[2025-03-01 19:16:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.08282168209552765 norm:0.0005961245624348521 max memory_allocated 29274.06298828125 
[2025-03-01 19:17:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.07748372107744217 norm:0.0003810219350270927 max memory_allocated 29274.06298828125 
[2025-03-01 19:18:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.07545234262943268 norm:0.0002752135042101145 max memory_allocated 29274.06298828125 
[2025-03-01 19:19:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.07441657781600952 norm:0.00022879404423292726 max memory_allocated 29274.06298828125 
[2025-03-01 19:19:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.0737544521689415 norm:0.00019742667791433632 max memory_allocated 29274.06298828125 
[2025-03-01 19:20:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.07335447520017624 norm:0.00017639111320022494 max memory_allocated 29274.06298828125 
[2025-03-01 19:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.07309557497501373 norm:0.00016104703536257148 max memory_allocated 29274.06298828125 
[2025-03-01 19:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.07293146103620529 norm:0.00015345752763096243 max memory_allocated 29274.06298828125 
[2025-03-01 19:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.07281330972909927 norm:0.00014672509860247374 max memory_allocated 29274.06298828125 
[2025-03-01 19:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.07273498177528381 norm:0.0001471339346608147 max memory_allocated 29274.06298828125 
[2025-03-01 19:24:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.07265091687440872 norm:0.00013721924915444106 max memory_allocated 29274.06298828125 
[2025-03-01 19:25:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.07258416712284088 norm:0.00013657081581186503 max memory_allocated 29274.06298828125 
[2025-03-01 19:26:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.07254358381032944 norm:0.00013190523895900697 max memory_allocated 29274.06298828125 
[2025-03-01 19:27:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.07250739634037018 norm:0.00012917390267830342 max memory_allocated 29274.06298828125 
[2025-03-01 19:28:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.07248368859291077 norm:0.00013222990673966706 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.07245932519435883 norm:0.00013052042049821466 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.07242528349161148 norm:0.0001302184391533956 max memory_allocated 29274.06298828125 
[2025-03-01 19:30:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.07240147888660431 norm:0.0001254704693565145 max memory_allocated 29274.06298828125 
[2025-03-01 19:31:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.0723859965801239 norm:0.00012307958968449384 max memory_allocated 29274.06298828125 
[2025-03-01 19:31:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-01 19:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.0899694412946701 norm:0.0008494899957440794 max memory_allocated 29274.25048828125 
[2025-03-01 19:33:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.0828041210770607 norm:0.0003947623772546649 max memory_allocated 29274.25048828125 
[2025-03-01 19:34:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.07806849479675293 norm:0.0002561649598646909 max memory_allocated 29274.25048828125 
[2025-03-01 19:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.07640194892883301 norm:0.00019335522665642202 max memory_allocated 29274.25048828125 
[2025-03-01 19:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.07536260038614273 norm:0.0001578918454470113 max memory_allocated 29274.25048828125 
[2025-03-01 19:36:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.07469405233860016 norm:0.00013736990513280034 max memory_allocated 29274.25048828125 
[2025-03-01 19:37:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.0742814838886261 norm:0.0001249307388206944 max memory_allocated 29274.25048828125 
[2025-03-01 19:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.07404632121324539 norm:0.00011650961823761463 max memory_allocated 29274.25048828125 
[2025-03-01 19:39:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.0739225372672081 norm:0.00011122832802357152 max memory_allocated 29274.25048828125 
[2025-03-01 19:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.07381338626146317 norm:0.00010540257062530145 max memory_allocated 29274.25048828125 
[2025-03-01 19:40:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.07374054193496704 norm:0.00010236506204819307 max memory_allocated 29274.25048828125 
[2025-03-01 19:41:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.07366814464330673 norm:0.00010005474177887663 max memory_allocated 29274.25048828125 
[2025-03-01 19:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.07359400391578674 norm:9.51659312704578e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:43:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.0735534131526947 norm:9.262004459742457e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:44:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.0735214501619339 norm:8.878167864168063e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.07349985092878342 norm:8.817894558887929e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:45:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.07346610724925995 norm:8.788327249931172e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.07344605028629303 norm:8.650450763525441e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.07341524958610535 norm:8.465773134957999e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:48:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.07339741289615631 norm:8.479894313495606e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:48:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-01 19:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.09237794578075409 norm:0.0006961447652429342 max memory_allocated 29274.43798828125 
[2025-03-01 19:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.08581522852182388 norm:0.0003425837494432926 max memory_allocated 29274.43798828125 
[2025-03-01 19:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.08100073039531708 norm:0.00021951163944322616 max memory_allocated 29274.43798828125 
[2025-03-01 19:51:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.07941257953643799 norm:0.0001658050750847906 max memory_allocated 29274.43798828125 
[2025-03-01 19:52:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.07842227816581726 norm:0.0001391853584209457 max memory_allocated 29274.43798828125 
[2025-03-01 19:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.07779692858457565 norm:0.00012523768236860633 max memory_allocated 29274.43798828125 
[2025-03-01 19:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.07740923017263412 norm:0.00011731110134860501 max memory_allocated 29274.43798828125 
[2025-03-01 19:55:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.07718050479888916 norm:0.00010886511881835759 max memory_allocated 29274.43798828125 
[2025-03-01 19:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.0770416110754013 norm:0.00010258321708533913 max memory_allocated 29274.43798828125 
[2025-03-01 19:56:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.07693738490343094 norm:9.737347136251628e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:57:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.07686231285333633 norm:9.427057375432923e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.07681143283843994 norm:9.454695100430399e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:59:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.07676468044519424 norm:9.136500739259645e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.07671637088060379 norm:8.859193621901795e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.07667803764343262 norm:8.656025602249429e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.07663377374410629 norm:8.563448500353843e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.0765983834862709 norm:8.391569281229749e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:03:29 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.07657843083143234 norm:8.293252903968096e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.07655593752861023 norm:8.442983380518854e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.07655602693557739 norm:8.554697706131265e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:05:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-01 20:06:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.09590277820825577 norm:0.0006392651121132076 max memory_allocated 29274.62548828125 
[2025-03-01 20:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.08951449394226074 norm:0.000314206670736894 max memory_allocated 29274.62548828125 
[2025-03-01 20:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.08463609963655472 norm:0.00020284306083340198 max memory_allocated 29274.62548828125 
[2025-03-01 20:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.08301590383052826 norm:0.0001537277566967532 max memory_allocated 29274.62548828125 
[2025-03-01 20:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.08208631724119186 norm:0.0001301923330174759 max memory_allocated 29274.62548828125 
[2025-03-01 20:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.08146600425243378 norm:0.00011604779137996957 max memory_allocated 29274.62548828125 
[2025-03-01 20:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.08107651025056839 norm:0.00010763815953396261 max memory_allocated 29274.62548828125 
[2025-03-01 20:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.08086363226175308 norm:0.00010168827429879457 max memory_allocated 29274.62548828125 
[2025-03-01 20:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.08072769641876221 norm:9.580951154930517e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.08064665645360947 norm:9.344835416413844e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.08057315647602081 norm:9.030923683894798e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:15:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.08050281554460526 norm:8.725281804800034e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.08046016097068787 norm:8.716183219803497e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.08041920512914658 norm:8.646837522974238e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:17:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.08038128912448883 norm:8.257388981292024e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:18:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.08035623282194138 norm:8.298345346702263e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.08032134175300598 norm:8.162302401615307e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:20:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.080291748046875 norm:8.18100743344985e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:21:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.08027712255716324 norm:8.359158528037369e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:22:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.08026310056447983 norm:8.367380360141397e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:22:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-01 20:23:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.10443591326475143 norm:0.0008359825005754828 max memory_allocated 29274.81298828125 
[2025-03-01 20:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.09671313315629959 norm:0.00041337322909384966 max memory_allocated 29274.81298828125 
[2025-03-01 20:24:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.09115119278430939 norm:0.00026904893456958234 max memory_allocated 29274.81298828125 
[2025-03-01 20:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.08930321037769318 norm:0.00020054943161085248 max memory_allocated 29274.81298828125 
[2025-03-01 20:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.0882824957370758 norm:0.00016947391850408167 max memory_allocated 29274.81298828125 
[2025-03-01 20:27:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.08757291734218597 norm:0.00015109902597032487 max memory_allocated 29274.81298828125 
[2025-03-01 20:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.08711863309144974 norm:0.00014046946307644248 max memory_allocated 29274.81298828125 
[2025-03-01 20:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.08686898648738861 norm:0.0001346264616586268 max memory_allocated 29274.81298828125 
[2025-03-01 20:29:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.08669085055589676 norm:0.00012643482477869838 max memory_allocated 29274.81298828125 
[2025-03-01 20:30:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.08657630532979965 norm:0.00012324395356699824 max memory_allocated 29274.81298828125 
[2025-03-01 20:31:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.08648139983415604 norm:0.00011891953181475401 max memory_allocated 29274.81298828125 
[2025-03-01 20:32:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.0864190012216568 norm:0.0001147548173321411 max memory_allocated 29274.81298828125 
[2025-03-01 20:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.08633952587842941 norm:0.00011322716454742476 max memory_allocated 29274.81298828125 
[2025-03-01 20:33:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.08626247942447662 norm:0.00010892507998505607 max memory_allocated 29274.81298828125 
[2025-03-01 20:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.08619564026594162 norm:0.00010453019785927609 max memory_allocated 29274.81298828125 
[2025-03-01 20:35:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.08615967631340027 norm:0.00010178676166106015 max memory_allocated 29274.81298828125 
[2025-03-01 20:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.08612851053476334 norm:0.00010412845585960895 max memory_allocated 29274.81298828125 
[2025-03-01 20:37:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.0861041396856308 norm:0.00010145598207600415 max memory_allocated 29274.81298828125 
[2025-03-01 20:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.08608431369066238 norm:9.832279465626925e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:38:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.08606576174497604 norm:9.748044976731762e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:39:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-01 20:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.10711118578910828 norm:0.0005456279614008963 max memory_allocated 29275.00048828125 
[2025-03-01 20:40:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.10130968689918518 norm:0.00028234662022441626 max memory_allocated 29275.00048828125 
[2025-03-01 20:41:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.09639450162649155 norm:0.0001746547786751762 max memory_allocated 29275.00048828125 
[2025-03-01 20:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.09506899863481522 norm:0.0001375605061184615 max memory_allocated 29275.00048828125 
[2025-03-01 20:43:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.09409651905298233 norm:0.00011913620983250439 max memory_allocated 29275.00048828125 
[2025-03-01 20:44:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.09342023730278015 norm:0.00011020471720257774 max memory_allocated 29275.00048828125 
[2025-03-01 20:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.09304887056350708 norm:0.00010424060019431636 max memory_allocated 29275.00048828125 
[2025-03-01 20:45:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.0928453728556633 norm:9.994552237913013e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:46:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.0927189365029335 norm:9.721673995954916e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.09260820597410202 norm:9.390103514306247e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:48:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.09253547340631485 norm:9.225970279658213e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.09247315675020218 norm:9.141438931692392e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:49:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.09242106974124908 norm:0.00010500042117200792 max memory_allocated 29275.00048828125 
[2025-03-01 20:50:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.09236939996480942 norm:8.777248149272054e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.09232200682163239 norm:8.91384479473345e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:52:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.0922875851392746 norm:8.562073344364762e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.09224431216716766 norm:8.316622552229092e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.09222202003002167 norm:8.470412285532802e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:54:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.09219805896282196 norm:8.351953874807805e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:55:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.09216858446598053 norm:8.24704475235194e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:56:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-01 20:56:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.11574778705835342 norm:0.0006265311385504901 max memory_allocated 29275.18798828125 
[2025-03-01 20:57:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.109632708132267 norm:0.0003409438068047166 max memory_allocated 29275.18798828125 
[2025-03-01 20:58:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.10435845702886581 norm:0.0001942198141478002 max memory_allocated 29275.18798828125 
[2025-03-01 20:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.1029345765709877 norm:0.00015398376854136586 max memory_allocated 29275.18798828125 
[2025-03-01 21:00:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.10195183008909225 norm:0.00013213561032898724 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.10123222321271896 norm:0.00011870705202454701 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.10083511471748352 norm:0.00011050377361243591 max memory_allocated 29275.18798828125 
[2025-03-01 21:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.10062231868505478 norm:0.00010384187044110149 max memory_allocated 29275.18798828125 
[2025-03-01 21:03:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.10048949718475342 norm:9.846527245827019e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.10038013756275177 norm:9.672633314039558e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:05:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.10027285665273666 norm:9.151724952971563e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.10020086169242859 norm:8.94234181032516e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.10014287382364273 norm:8.713507122593e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.10007213056087494 norm:8.658167644171044e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:08:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.10002101957798004 norm:8.543626609025523e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:18 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.09997773915529251 norm:8.270938269561157e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:10:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.09994351118803024 norm:8.20956047391519e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.0999159961938858 norm:8.234316192101687e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:11:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.09988965839147568 norm:8.307232928927988e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:12:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.09986105561256409 norm:8.571427315473557e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:12:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-01 21:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.12380025535821915 norm:0.0005397317581810057 max memory_allocated 29275.37548828125 
[2025-03-01 21:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.11785821616649628 norm:0.0002963186416309327 max memory_allocated 29275.37548828125 
[2025-03-01 21:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.11265774071216583 norm:0.00019269959011580795 max memory_allocated 29275.37548828125 
[2025-03-01 21:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.11137586832046509 norm:0.0001609930768609047 max memory_allocated 29275.37548828125 
[2025-03-01 21:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.11037107557058334 norm:0.00013790992670692503 max memory_allocated 29275.37548828125 
[2025-03-01 21:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.10962994396686554 norm:0.0001259175915038213 max memory_allocated 29275.37548828125 
[2025-03-01 21:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.10925522446632385 norm:0.00012202453945064917 max memory_allocated 29275.37548828125 
[2025-03-01 21:19:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.10905049741268158 norm:0.00011596531112445518 max memory_allocated 29275.37548828125 
[2025-03-01 21:20:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.10891443490982056 norm:0.00011260116298217326 max memory_allocated 29275.37548828125 
[2025-03-01 21:21:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.10881658643484116 norm:0.00011114953667856753 max memory_allocated 29275.37548828125 
[2025-03-01 21:22:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.10873377323150635 norm:0.00011023172555724159 max memory_allocated 29275.37548828125 
[2025-03-01 21:22:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.10864295810461044 norm:0.00010623602429404855 max memory_allocated 29275.37548828125 
[2025-03-01 21:23:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.10857909917831421 norm:0.00011349831038387492 max memory_allocated 29275.37548828125 
[2025-03-01 21:24:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.10853458940982819 norm:0.000119864045700524 max memory_allocated 29275.37548828125 
[2025-03-01 21:25:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.1084921583533287 norm:0.00011837335478048772 max memory_allocated 29275.37548828125 
[2025-03-01 21:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.10846307873725891 norm:0.00011954802903346717 max memory_allocated 29275.37548828125 
[2025-03-01 21:26:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.10840769857168198 norm:0.00012240347859915346 max memory_allocated 29275.37548828125 
[2025-03-01 21:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.10838022083044052 norm:0.00012798618990927935 max memory_allocated 29275.37548828125 
[2025-03-01 21:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.1083468645811081 norm:0.00013033150753472 max memory_allocated 29275.37548828125 
[2025-03-01 21:29:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.10831595212221146 norm:0.0001242677099071443 max memory_allocated 29275.37548828125 
[2025-03-01 21:29:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-01 21:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.13448241353034973 norm:0.0005389144644141197 max memory_allocated 29275.56298828125 
[2025-03-01 21:31:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.1282443404197693 norm:0.0002871095493901521 max memory_allocated 29275.56298828125 
[2025-03-01 21:32:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.12260468304157257 norm:0.00018660342902876437 max memory_allocated 29275.56298828125 
[2025-03-01 21:33:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.12115329504013062 norm:0.00014533103967551142 max memory_allocated 29275.56298828125 
[2025-03-01 21:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.12009153515100479 norm:0.00012488012725953013 max memory_allocated 29275.56298828125 
[2025-03-01 21:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.11931664496660233 norm:0.00011348006955813617 max memory_allocated 29275.56298828125 
[2025-03-01 21:35:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.11893457919359207 norm:0.00010382716573076323 max memory_allocated 29275.56298828125 
[2025-03-01 21:36:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.11875505745410919 norm:9.891729860100895e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:37:12 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.11862097680568695 norm:9.329050953965634e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.11852065473794937 norm:0.00010187429143115878 max memory_allocated 29275.56298828125 
[2025-03-01 21:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.11844132095575333 norm:9.0674904640764e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:39:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.11835268884897232 norm:8.567724580643699e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:40:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.11828914284706116 norm:8.535459346603602e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.11823654919862747 norm:8.459143282379955e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.11818023771047592 norm:8.303009963128716e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:43:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.11812900751829147 norm:7.899582851678133e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.1180894672870636 norm:7.825425564078614e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.11806190013885498 norm:7.686964090680704e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.11803493648767471 norm:7.638965325895697e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:46:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.117999367415905 norm:7.801539322827011e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:46:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-01 21:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.14832884073257446 norm:0.0008762789657339454 max memory_allocated 29275.75048828125 
[2025-03-01 21:48:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.14175041019916534 norm:0.0004896732862107456 max memory_allocated 29275.75048828125 
[2025-03-01 21:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.1357012689113617 norm:0.0003159974585287273 max memory_allocated 29275.75048828125 
[2025-03-01 21:49:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.134247288107872 norm:0.00024185764777939767 max memory_allocated 29275.75048828125 
[2025-03-01 21:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.1331750601530075 norm:0.0001988024596357718 max memory_allocated 29275.75048828125 
[2025-03-01 21:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.13237512111663818 norm:0.00017369617125950754 max memory_allocated 29275.75048828125 
[2025-03-01 21:52:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.132009819149971 norm:0.00015720778901595622 max memory_allocated 29275.75048828125 
[2025-03-01 21:53:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.13181287050247192 norm:0.0001451236312277615 max memory_allocated 29275.75048828125 
[2025-03-01 21:54:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.1316661834716797 norm:0.00013619042874779552 max memory_allocated 29275.75048828125 
[2025-03-01 21:54:53 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.13154949247837067 norm:0.00013177053187973797 max memory_allocated 29275.75048828125 
[2025-03-01 21:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.13146354258060455 norm:0.00012709290604107082 max memory_allocated 29275.75048828125 
[2025-03-01 21:56:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.13138005137443542 norm:0.00012616770982276648 max memory_allocated 29275.75048828125 
[2025-03-01 21:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.13130523264408112 norm:0.0001227361208293587 max memory_allocated 29275.75048828125 
[2025-03-01 21:58:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.13124330341815948 norm:0.00011950314365094528 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.13117416203022003 norm:0.0001169932511402294 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.13112662732601166 norm:0.00011471394100226462 max memory_allocated 29275.75048828125 
[2025-03-01 22:00:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.13108278810977936 norm:0.00011526479647727683 max memory_allocated 29275.75048828125 
[2025-03-01 22:01:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.1310434639453888 norm:0.00011174372775712982 max memory_allocated 29275.75048828125 
[2025-03-01 22:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.1310039907693863 norm:0.00011108611215604469 max memory_allocated 29275.75048828125 
[2025-03-01 22:03:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.13097479939460754 norm:0.00011155608808621764 max memory_allocated 29275.75048828125 
[2025-03-01 22:03:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-01 22:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.1583828628063202 norm:0.0003668678691610694 max memory_allocated 29275.93798828125 
[2025-03-01 22:05:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.1522035151720047 norm:0.00022095392341725528 max memory_allocated 29275.93798828125 
[2025-03-01 22:05:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.14626814424991608 norm:0.00015305636043194681 max memory_allocated 29275.93798828125 
[2025-03-01 22:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.14479637145996094 norm:0.00012769793102052063 max memory_allocated 29275.93798828125 
[2025-03-01 22:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.1436530202627182 norm:0.0001165089852293022 max memory_allocated 29275.93798828125 
[2025-03-01 22:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.14287696778774261 norm:0.00010655671212589368 max memory_allocated 29275.93798828125 
[2025-03-01 22:09:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.14253966510295868 norm:0.00010333234968129545 max memory_allocated 29275.93798828125 
[2025-03-01 22:10:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.1423688381910324 norm:9.633501758798957e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:10:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.14222075045108795 norm:9.352900815429166e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:11:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.14210399985313416 norm:9.054764814209193e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.14199814200401306 norm:9.174531442113221e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:13:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.14192861318588257 norm:8.883627015165985e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:14:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.14185816049575806 norm:8.95125194801949e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:15:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.14179161190986633 norm:8.783081284491345e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.14173465967178345 norm:8.781286305747926e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:16:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.14169320464134216 norm:8.477593655698001e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:17:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.1416463851928711 norm:8.457939838990569e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:18:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.14159342646598816 norm:8.244617492891848e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.1415535807609558 norm:8.277630695374683e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.14151805639266968 norm:8.220344898290932e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:20:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-01 22:21:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.17401564121246338 norm:0.0007054579327814281 max memory_allocated 29276.12548828125 
[2025-03-01 22:22:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.16702423989772797 norm:0.0004319053259678185 max memory_allocated 29276.12548828125 
[2025-03-01 22:22:49 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.16062501072883606 norm:0.00029464185354299843 max memory_allocated 29276.12548828125 
[2025-03-01 22:23:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.15892431139945984 norm:0.0002461439580656588 max memory_allocated 29276.12548828125 
[2025-03-01 22:24:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.15760989487171173 norm:0.0002093644143315032 max memory_allocated 29276.12548828125 
[2025-03-01 22:25:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.15678748488426208 norm:0.0002012626064242795 max memory_allocated 29276.12548828125 
[2025-03-01 22:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.15644104778766632 norm:0.00019120480283163488 max memory_allocated 29276.12548828125 
[2025-03-01 22:26:58 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.15623675286769867 norm:0.00018783337145578116 max memory_allocated 29276.12548828125 
[2025-03-01 22:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.15607041120529175 norm:0.00017764719086699188 max memory_allocated 29276.12548828125 
[2025-03-01 22:28:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.1559412181377411 norm:0.00018604985962156206 max memory_allocated 29276.12548828125 
[2025-03-01 22:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.15579691529273987 norm:0.00017208285862579942 max memory_allocated 29276.12548828125 
[2025-03-01 22:30:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.15571226179599762 norm:0.00019119316129945219 max memory_allocated 29276.12548828125 
[2025-03-01 22:31:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.1556214988231659 norm:0.00018663970695342869 max memory_allocated 29276.12548828125 
[2025-03-01 22:31:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.15556108951568604 norm:0.00019544476526789367 max memory_allocated 29276.12548828125 
[2025-03-01 22:32:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.15549863874912262 norm:0.0001931893202709034 max memory_allocated 29276.12548828125 
[2025-03-01 22:33:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.1554218828678131 norm:0.000173675172845833 max memory_allocated 29276.12548828125 
[2025-03-01 22:34:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.1553732305765152 norm:0.00019019618048332632 max memory_allocated 29276.12548828125 
[2025-03-01 22:35:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.1553044468164444 norm:0.00019431859254837036 max memory_allocated 29276.12548828125 
[2025-03-01 22:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.15523752570152283 norm:0.00018757254292722791 max memory_allocated 29276.12548828125 
[2025-03-01 22:36:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.15520139038562775 norm:0.00018475489923730493 max memory_allocated 29276.12548828125 
[2025-03-01 22:37:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-01 22:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.18801842629909515 norm:0.0005076712695881724 max memory_allocated 29276.31298828125 
[2025-03-01 22:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.1811678409576416 norm:0.0002947330067399889 max memory_allocated 29276.31298828125 
[2025-03-01 22:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.1746751219034195 norm:0.0001943955139722675 max memory_allocated 29276.31298828125 
[2025-03-01 22:40:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.17302606999874115 norm:0.00015321894898079336 max memory_allocated 29276.31298828125 
[2025-03-01 22:41:21 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.17171712219715118 norm:0.00013121914525981992 max memory_allocated 29276.31298828125 
[2025-03-01 22:42:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.17096355557441711 norm:0.00011724489741027355 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.17064109444618225 norm:0.00011075201473431662 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.1704532951116562 norm:0.0001027151956805028 max memory_allocated 29276.31298828125 
[2025-03-01 22:44:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.17031262814998627 norm:9.738659719005227e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:45:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.17019712924957275 norm:9.502802276983857e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:46:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.17009970545768738 norm:8.993017399916425e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:47:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.17001895606517792 norm:8.83585016708821e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:47:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.16994251310825348 norm:8.907521987566724e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:48:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.16988027095794678 norm:8.869914745446295e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:49:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.16982737183570862 norm:8.702997001819313e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.16976714134216309 norm:8.592108497396111e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:51:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.16972173750400543 norm:8.640567102702335e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.16968145966529846 norm:8.720880578039214e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:52:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.16963019967079163 norm:8.470285683870316e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.16959233582019806 norm:8.420684025622904e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:54:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-01 22:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.20768311619758606 norm:0.0006264515104703605 max memory_allocated 29276.50048828125 
[2025-03-01 22:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.19922888278961182 norm:0.00033521789009682834 max memory_allocated 29276.50048828125 
[2025-03-01 22:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.1914736032485962 norm:0.00020464521367102861 max memory_allocated 29276.50048828125 
[2025-03-01 22:57:23 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.18939745426177979 norm:0.00015947046631481498 max memory_allocated 29276.50048828125 
[2025-03-01 22:58:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.18798747658729553 norm:0.0001370837853755802 max memory_allocated 29276.50048828125 
[2025-03-01 22:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.18726149201393127 norm:0.00012306275311857462 max memory_allocated 29276.50048828125 
[2025-03-01 22:59:52 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.18698681890964508 norm:0.0001160331885330379 max memory_allocated 29276.50048828125 
[2025-03-01 23:00:42 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.18679001927375793 norm:0.00010906014358624816 max memory_allocated 29276.50048828125 
[2025-03-01 23:01:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.1866403967142105 norm:0.00010374916018918157 max memory_allocated 29276.50048828125 
[2025-03-01 23:02:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.18651387095451355 norm:0.00010284629388479516 max memory_allocated 29276.50048828125 
[2025-03-01 23:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.18638843297958374 norm:9.894267714116722e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.18629714846611023 norm:9.751926700118929e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:04:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.18620148301124573 norm:9.479853906668723e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.1861175149679184 norm:9.317236253991723e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:06:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.1860606074333191 norm:9.418509580427781e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.1859956681728363 norm:9.358611714560539e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:08:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.18593378365039825 norm:9.321869583800435e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:08:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.1858864426612854 norm:9.299820521846414e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.18585076928138733 norm:9.214639430865645e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:10:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.1858000010251999 norm:9.224687528330833e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:10:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-01 23:11:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.2247038632631302 norm:0.0006013870588503778 max memory_allocated 29276.68798828125 
[2025-03-01 23:12:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.21650494635105133 norm:0.00033292200532741845 max memory_allocated 29276.68798828125 
[2025-03-01 23:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.20862285792827606 norm:0.00019726867321878672 max memory_allocated 29276.68798828125 
[2025-03-01 23:14:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.20645304024219513 norm:0.0001546153798699379 max memory_allocated 29276.68798828125 
[2025-03-01 23:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.20504862070083618 norm:0.00013267893518786877 max memory_allocated 29276.68798828125 
[2025-03-01 23:15:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.20445866882801056 norm:0.00011935373913729563 max memory_allocated 29276.68798828125 
[2025-03-01 23:16:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.20422670245170593 norm:0.000112377259938512 max memory_allocated 29276.68798828125 
[2025-03-01 23:17:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.20406508445739746 norm:0.00010755108087323606 max memory_allocated 29276.68798828125 
[2025-03-01 23:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.20394004881381989 norm:0.00010487245890544727 max memory_allocated 29276.68798828125 
[2025-03-01 23:19:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.20383413136005402 norm:0.00010390375246061012 max memory_allocated 29276.68798828125 
[2025-03-01 23:20:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.20372727513313293 norm:0.00010345736518502235 max memory_allocated 29276.68798828125 
[2025-03-01 23:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.20361799001693726 norm:0.00010262733121635392 max memory_allocated 29276.68798828125 
[2025-03-01 23:21:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.2035285383462906 norm:9.971193503588438e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:22:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.2034451812505722 norm:9.865570609690621e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:23:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.2033786177635193 norm:9.775230137165636e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:24:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.20332449674606323 norm:0.00010095065226778388 max memory_allocated 29276.68798828125 
[2025-03-01 23:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.20326749980449677 norm:0.00010067699622595683 max memory_allocated 29276.68798828125 
[2025-03-01 23:25:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.20321744680404663 norm:0.00010188543819822371 max memory_allocated 29276.68798828125 
[2025-03-01 23:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.20316481590270996 norm:0.00010132347233593464 max memory_allocated 29276.68798828125 
[2025-03-01 23:27:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.2031204253435135 norm:0.00010398250014986843 max memory_allocated 29276.68798828125 
[2025-03-01 23:27:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-01 23:28:37 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.24654912948608398 norm:0.0007239504484459758 max memory_allocated 29276.87548828125 
[2025-03-01 23:29:27 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.23735183477401733 norm:0.0003840759745799005 max memory_allocated 29276.87548828125 
[2025-03-01 23:30:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.22884118556976318 norm:0.00023178811534307897 max memory_allocated 29276.87548828125 
[2025-03-01 23:31:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.22637102007865906 norm:0.00017975244554691017 max memory_allocated 29276.87548828125 
[2025-03-01 23:31:56 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.224824458360672 norm:0.00015214973245747387 max memory_allocated 29276.87548828125 
[2025-03-01 23:32:45 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.22421230375766754 norm:0.0001367315708193928 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:35 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.22392775118350983 norm:0.00013006009976379573 max memory_allocated 29276.87548828125 
[2025-03-01 23:34:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.22370733320713043 norm:0.00012289368896745145 max memory_allocated 29276.87548828125 
[2025-03-01 23:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.22353869676589966 norm:0.0001358258305117488 max memory_allocated 29276.87548828125 
[2025-03-01 23:36:04 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.22338661551475525 norm:0.00011203466419829056 max memory_allocated 29276.87548828125 
[2025-03-01 23:36:54 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.223285511136055 norm:0.00011014900519512594 max memory_allocated 29276.87548828125 
[2025-03-01 23:37:43 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.22317418456077576 norm:0.00010438352910568938 max memory_allocated 29276.87548828125 
[2025-03-01 23:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.22306987643241882 norm:0.00010240746632916853 max memory_allocated 29276.87548828125 
[2025-03-01 23:39:23 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.22297106683254242 norm:0.00010150406887987629 max memory_allocated 29276.87548828125 
[2025-03-01 23:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.22290289402008057 norm:9.864765888778493e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:41:02 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.22283054888248444 norm:9.921178570948541e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.22277456521987915 norm:0.00010028783435700461 max memory_allocated 29276.87548828125 
[2025-03-01 23:42:41 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.22273699939250946 norm:9.932801185641438e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:43:31 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.22266921401023865 norm:9.766102448338643e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.22261911630630493 norm:9.798281826078892e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:44:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-01 23:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.2680053412914276 norm:0.0006038792780600488 max memory_allocated 29277.06298828125 
[2025-03-01 23:46:18 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.25833937525749207 norm:0.0003505389904603362 max memory_allocated 29277.06298828125 
[2025-03-01 23:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.24931785464286804 norm:0.00021148718951735646 max memory_allocated 29277.06298828125 
[2025-03-01 23:47:58 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.24685755372047424 norm:0.00017879919323604554 max memory_allocated 29277.06298828125 
[2025-03-01 23:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.2453441321849823 norm:0.00014234079571906477 max memory_allocated 29277.06298828125 
[2025-03-01 23:49:37 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.244770348072052 norm:0.0001336674758931622 max memory_allocated 29277.06298828125 
[2025-03-01 23:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.24442267417907715 norm:0.00012728066940326244 max memory_allocated 29277.06298828125 
[2025-03-01 23:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.24422171711921692 norm:0.00012016787513857707 max memory_allocated 29277.06298828125 
[2025-03-01 23:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.24409101903438568 norm:0.00011753798753488809 max memory_allocated 29277.06298828125 
[2025-03-01 23:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.24393925070762634 norm:0.00011451653699623421 max memory_allocated 29277.06298828125 
[2025-03-01 23:53:46 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.2438173145055771 norm:0.00011339409684296697 max memory_allocated 29277.06298828125 
[2025-03-01 23:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.24371446669101715 norm:0.00011329486733302474 max memory_allocated 29277.06298828125 
[2025-03-01 23:55:25 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.24360987544059753 norm:0.0001113463076762855 max memory_allocated 29277.06298828125 
[2025-03-01 23:56:15 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.24351811408996582 norm:0.0001105407573049888 max memory_allocated 29277.06298828125 
[2025-03-01 23:57:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.24345628917217255 norm:0.0001096078340196982 max memory_allocated 29277.06298828125 
[2025-03-01 23:57:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.24339546263217926 norm:0.00010907224350376055 max memory_allocated 29277.06298828125 
[2025-03-01 23:58:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.24334701895713806 norm:0.00010981652303598821 max memory_allocated 29277.06298828125 
[2025-03-01 23:59:33 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.24330425262451172 norm:0.00011221155000384897 max memory_allocated 29277.06298828125 
[2025-03-02 00:00:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.2432423084974289 norm:0.00011157253902638331 max memory_allocated 29277.06298828125 
[2025-03-02 00:01:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.2431873083114624 norm:0.00011015292693627998 max memory_allocated 29277.06298828125 
[2025-03-02 00:01:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 00:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.29568761587142944 norm:0.0006801083800382912 max memory_allocated 29277.25048828125 
[2025-03-02 00:03:10 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.28493478894233704 norm:0.0003617964393924922 max memory_allocated 29277.25048828125 
[2025-03-02 00:04:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.2756199240684509 norm:0.00023379606136586517 max memory_allocated 29277.25048828125 
[2025-03-02 00:04:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.2727730870246887 norm:0.0001888131519081071 max memory_allocated 29277.25048828125 
[2025-03-02 00:05:39 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.27118638157844543 norm:0.00016424719069618732 max memory_allocated 29277.25048828125 
[2025-03-02 00:06:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.2705831229686737 norm:0.00015275043551810086 max memory_allocated 29277.25048828125 
[2025-03-02 00:07:18 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.27023330330848694 norm:0.0001431823766324669 max memory_allocated 29277.25048828125 
[2025-03-02 00:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.269978791475296 norm:0.00013777916319668293 max memory_allocated 29277.25048828125 
[2025-03-02 00:08:57 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.26973262429237366 norm:0.00013351853704079986 max memory_allocated 29277.25048828125 
[2025-03-02 00:09:47 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.26953426003456116 norm:0.00012951884127687663 max memory_allocated 29277.25048828125 
[2025-03-02 00:10:36 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.26936379075050354 norm:0.00012694948236458004 max memory_allocated 29277.25048828125 
[2025-03-02 00:11:26 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.26922106742858887 norm:0.00012363085988909006 max memory_allocated 29277.25048828125 
[2025-03-02 00:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.26909732818603516 norm:0.00012134747521486133 max memory_allocated 29277.25048828125 
[2025-03-02 00:13:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.26898595690727234 norm:0.00012095048441551626 max memory_allocated 29277.25048828125 
[2025-03-02 00:13:55 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.2688966691493988 norm:0.0001273057860089466 max memory_allocated 29277.25048828125 
[2025-03-02 00:14:45 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.26878687739372253 norm:0.00011590415670070797 max memory_allocated 29277.25048828125 
[2025-03-02 00:15:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.2687111794948578 norm:0.0001134780322900042 max memory_allocated 29277.25048828125 
[2025-03-02 00:16:24 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.2686416506767273 norm:0.00011419980728533119 max memory_allocated 29277.25048828125 
[2025-03-02 00:17:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.2685776948928833 norm:0.00010825063509400934 max memory_allocated 29277.25048828125 
[2025-03-02 00:18:03 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.2685219645500183 norm:0.00010821439354913309 max memory_allocated 29277.25048828125 
[2025-03-02 00:18:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 00:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.32498931884765625 norm:0.0011313774157315493 max memory_allocated 29277.43798828125 
[2025-03-02 00:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.31329748034477234 norm:0.0005975838284939528 max memory_allocated 29277.43798828125 
[2025-03-02 00:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.3031950891017914 norm:0.00036774022737517953 max memory_allocated 29277.43798828125 
[2025-03-02 00:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.3000621199607849 norm:0.00026197638362646103 max memory_allocated 29277.43798828125 
[2025-03-02 00:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.29847803711891174 norm:0.00020780102931894362 max memory_allocated 29277.43798828125 
[2025-03-02 00:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.2978903353214264 norm:0.0001773555122781545 max memory_allocated 29277.43798828125 
[2025-03-02 00:24:10 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.2975422739982605 norm:0.00015868412447161973 max memory_allocated 29277.43798828125 
[2025-03-02 00:24:59 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.29727286100387573 norm:0.00014668374205939472 max memory_allocated 29277.43798828125 
[2025-03-02 00:25:49 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.2970612049102783 norm:0.00013827763905283064 max memory_allocated 29277.43798828125 
[2025-03-02 00:26:39 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.29687443375587463 norm:0.00013200813555158675 max memory_allocated 29277.43798828125 
[2025-03-02 00:27:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.2967214286327362 norm:0.00012701880768872797 max memory_allocated 29277.43798828125 
[2025-03-02 00:28:18 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.2965901494026184 norm:0.00012462552695069462 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:08 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.2964646518230438 norm:0.0001222205610247329 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:58 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.2963583171367645 norm:0.00012046339543303475 max memory_allocated 29277.43798828125 
[2025-03-02 00:30:47 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.29624611139297485 norm:0.00011832381278509274 max memory_allocated 29277.43798828125 
[2025-03-02 00:31:37 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.2961503565311432 norm:0.00011794949386967346 max memory_allocated 29277.43798828125 
[2025-03-02 00:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.2960560619831085 norm:0.00011690329120028764 max memory_allocated 29277.43798828125 
[2025-03-02 00:33:16 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.29598352313041687 norm:0.00011659882875392213 max memory_allocated 29277.43798828125 
[2025-03-02 00:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.29590827226638794 norm:0.00011621546582318842 max memory_allocated 29277.43798828125 
[2025-03-02 00:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.29584550857543945 norm:0.00011613778042374179 max memory_allocated 29277.43798828125 
[2025-03-02 00:35:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 00:35:14 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:36:04 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.3651449680328369 norm:0.009697562083601952 max memory_allocated 29277.77001953125 
[2025-03-02 00:36:54 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.35031163692474365 norm:0.007295142859220505 max memory_allocated 29277.77001953125 
[2025-03-02 00:37:43 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.3382698893547058 norm:0.005367957055568695 max memory_allocated 29277.77001953125 
[2025-03-02 00:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.33427467942237854 norm:0.004384898580610752 max memory_allocated 29277.77001953125 
[2025-03-02 00:39:23 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.332405686378479 norm:0.0035870461724698544 max memory_allocated 29277.77001953125 
[2025-03-02 00:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.3316469192504883 norm:0.002935593482106924 max memory_allocated 29277.77001953125 
[2025-03-02 00:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.3311750888824463 norm:0.002604349050670862 max memory_allocated 29277.77001953125 
[2025-03-02 00:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.33087706565856934 norm:0.0025805016048252583 max memory_allocated 29277.77001953125 
[2025-03-02 00:42:43 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.330584853887558 norm:0.002480521099641919 max memory_allocated 29277.77001953125 
[2025-03-02 00:43:33 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.3302997946739197 norm:0.002324300119653344 max memory_allocated 29277.77001953125 
[2025-03-02 00:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.3300513029098511 norm:0.002196729648858309 max memory_allocated 29277.77001953125 
[2025-03-02 00:45:13 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.3298718333244324 norm:0.0020943954586982727 max memory_allocated 29277.77001953125 
[2025-03-02 00:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.3296884298324585 norm:0.002065439708530903 max memory_allocated 29277.77001953125 
[2025-03-02 00:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.3295454680919647 norm:0.0020118083339184523 max memory_allocated 29277.77001953125 
[2025-03-02 00:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.32937929034233093 norm:0.0020038518123328686 max memory_allocated 29277.77001953125 
[2025-03-02 00:48:32 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.3292683959007263 norm:0.0019568130373954773 max memory_allocated 29277.77001953125 
[2025-03-02 00:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.32911816239356995 norm:0.0019485463853925467 max memory_allocated 29277.77001953125 
[2025-03-02 00:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.3290346562862396 norm:0.0018940467853099108 max memory_allocated 29277.77001953125 
[2025-03-02 00:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.32888850569725037 norm:0.0018174444558098912 max memory_allocated 29277.77001953125 
[2025-03-02 00:51:52 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.328815221786499 norm:0.0018289369763806462 max memory_allocated 29277.77001953125 
[2025-03-02 00:52:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 00:52:10 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:53:00 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.40751421451568604 norm:0.01048471499234438 max memory_allocated 29277.95751953125 
[2025-03-02 00:53:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.39072751998901367 norm:0.008270300924777985 max memory_allocated 29277.95751953125 
[2025-03-02 00:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.3762865960597992 norm:0.005830221343785524 max memory_allocated 29277.95751953125 
[2025-03-02 00:55:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.3715416193008423 norm:0.004805855918675661 max memory_allocated 29277.95751953125 
[2025-03-02 00:56:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.36961615085601807 norm:0.00398633349686861 max memory_allocated 29277.95751953125 
[2025-03-02 00:57:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.36877262592315674 norm:0.003376305801793933 max memory_allocated 29277.95751953125 
[2025-03-02 00:57:59 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.3681560158729553 norm:0.0029078423976898193 max memory_allocated 29277.95751953125 
[2025-03-02 00:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.3678210973739624 norm:0.002740434603765607 max memory_allocated 29277.95751953125 
[2025-03-02 00:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.36756840348243713 norm:0.002684285631403327 max memory_allocated 29277.95751953125 
[2025-03-02 01:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.3673988878726959 norm:0.0026698734145611525 max memory_allocated 29277.95751953125 
[2025-03-02 01:01:18 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.36713236570358276 norm:0.0024761310778558254 max memory_allocated 29277.95751953125 
[2025-03-02 01:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.3669241666793823 norm:0.0024739974178373814 max memory_allocated 29277.95751953125 
[2025-03-02 01:02:58 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.3667885363101959 norm:0.0024606729857623577 max memory_allocated 29277.95751953125 
[2025-03-02 01:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.36665886640548706 norm:0.0023635132238268852 max memory_allocated 29277.95751953125 
[2025-03-02 01:04:38 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.366424560546875 norm:0.002244549337774515 max memory_allocated 29277.95751953125 
[2025-03-02 01:05:28 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.3663199543952942 norm:0.0022447791416198015 max memory_allocated 29277.95751953125 
[2025-03-02 01:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.3662843108177185 norm:0.0022880586329847574 max memory_allocated 29277.95751953125 
[2025-03-02 01:07:08 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.3662281036376953 norm:0.0022835968993604183 max memory_allocated 29277.95751953125 
[2025-03-02 01:07:57 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.36607497930526733 norm:0.0021514862310141325 max memory_allocated 29277.95751953125 
[2025-03-02 01:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.3660208284854889 norm:0.0022049262188374996 max memory_allocated 29277.95751953125 
[2025-03-02 01:09:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 01:09:06 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:09:56 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.4771065413951874 norm:0.015405126847326756 max memory_allocated 29278.14501953125 
[2025-03-02 01:10:45 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.45632702112197876 norm:0.008739789947867393 max memory_allocated 29278.14501953125 
[2025-03-02 01:11:35 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.4382779896259308 norm:0.005147804506123066 max memory_allocated 29278.14501953125 
[2025-03-02 01:12:25 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.432228684425354 norm:0.004938340280205011 max memory_allocated 29278.14501953125 
[2025-03-02 01:13:15 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.42994242906570435 norm:0.004525960423052311 max memory_allocated 29278.14501953125 
[2025-03-02 01:14:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.42888161540031433 norm:0.003902602940797806 max memory_allocated 29278.14501953125 
[2025-03-02 01:14:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.42818576097488403 norm:0.003930433187633753 max memory_allocated 29278.14501953125 
[2025-03-02 01:15:44 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.42765969038009644 norm:0.003746811533346772 max memory_allocated 29278.14501953125 
[2025-03-02 01:16:34 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.42729756236076355 norm:0.003667025826871395 max memory_allocated 29278.14501953125 
[2025-03-02 01:17:24 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.4270249903202057 norm:0.0037478841841220856 max memory_allocated 29278.14501953125 
[2025-03-02 01:18:14 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.42658984661102295 norm:0.00385127286426723 max memory_allocated 29278.14501953125 
[2025-03-02 01:19:04 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.42628464102745056 norm:0.003749100025743246 max memory_allocated 29278.14501953125 
[2025-03-02 01:19:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.42607831954956055 norm:0.0038832281716167927 max memory_allocated 29278.14501953125 
[2025-03-02 01:20:44 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.42582178115844727 norm:0.003907396923750639 max memory_allocated 29278.14501953125 
[2025-03-02 01:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.4257464110851288 norm:0.004053518641740084 max memory_allocated 29278.14501953125 
[2025-03-02 01:22:24 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.42561283707618713 norm:0.004173037130385637 max memory_allocated 29278.14501953125 
[2025-03-02 01:23:13 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.42549726366996765 norm:0.004050709772855043 max memory_allocated 29278.14501953125 
[2025-03-02 01:24:03 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.425374835729599 norm:0.004093157593160868 max memory_allocated 29278.14501953125 
[2025-03-02 01:24:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.42516881227493286 norm:0.004172041546553373 max memory_allocated 29278.14501953125 
[2025-03-02 01:25:43 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.4251530170440674 norm:0.004288727417588234 max memory_allocated 29278.14501953125 
[2025-03-02 01:25:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 01:26:02 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.6822843551635742 norm:0.03894682228565216 max memory_allocated 29278.33251953125 
[2025-03-02 01:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.6221033930778503 norm:0.026699122041463852 max memory_allocated 29278.33251953125 
[2025-03-02 01:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.5830734968185425 norm:0.018905192613601685 max memory_allocated 29278.33251953125 
[2025-03-02 01:29:21 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.570520281791687 norm:0.016031472012400627 max memory_allocated 29278.33251953125 
[2025-03-02 01:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.5638712048530579 norm:0.014145524241030216 max memory_allocated 29278.33251953125 
[2025-03-02 01:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.5606858134269714 norm:0.012877916917204857 max memory_allocated 29278.33251953125 
[2025-03-02 01:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.5576708316802979 norm:0.012143646366894245 max memory_allocated 29278.33251953125 
[2025-03-02 01:32:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.5563696622848511 norm:0.01144922710955143 max memory_allocated 29278.33251953125 
[2025-03-02 01:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.5543277263641357 norm:0.011538989841938019 max memory_allocated 29278.33251953125 
[2025-03-02 01:34:20 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.5535469651222229 norm:0.011122670024633408 max memory_allocated 29278.33251953125 
[2025-03-02 01:35:10 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.5524295568466187 norm:0.011096008121967316 max memory_allocated 29278.33251953125 
[2025-03-02 01:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.5518297553062439 norm:0.01068984903395176 max memory_allocated 29278.33251953125 
[2025-03-02 01:36:50 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.5514670014381409 norm:0.010752169415354729 max memory_allocated 29278.33251953125 
[2025-03-02 01:37:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.5514466166496277 norm:0.011545378714799881 max memory_allocated 29278.33251953125 
[2025-03-02 01:38:29 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.5510925054550171 norm:0.011122992262244225 max memory_allocated 29278.33251953125 
[2025-03-02 01:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.5500810742378235 norm:0.010785816237330437 max memory_allocated 29278.33251953125 
[2025-03-02 01:40:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.5491818189620972 norm:0.009910548105835915 max memory_allocated 29278.33251953125 
[2025-03-02 01:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.5487787127494812 norm:0.009951074607670307 max memory_allocated 29278.33251953125 
[2025-03-02 01:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.5491565465927124 norm:0.009759063832461834 max memory_allocated 29278.33251953125 
[2025-03-02 01:42:38 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.5480523705482483 norm:0.009597979485988617 max memory_allocated 29278.33251953125 
[2025-03-02 01:42:53 root] (main_calib_config2.py 380): INFO 40470.501895427704
[2025-03-02 01:43:02 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-02 01:45:00 root] (main_calib_config2.py 159): INFO wikitext2 : 5.089664459228516
[2025-03-02 01:45:00 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-02 01:47:59 root] (main_calib_config2.py 159): INFO c4 : 6.754901885986328
[2025-03-02 03:51:02 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.089664459228516, 'c4': 6.754901885986328, 'results': {'winogrande': {'acc': 0.6677190213101816, 'acc_stderr': 0.013238316554236528}, 'boolq': {'acc': 0.6633027522935779, 'acc_stderr': 0.008265482725061708}, 'arc_challenge': {'acc': 0.4257679180887372, 'acc_stderr': 0.014449464278868805, 'acc_norm': 0.4325938566552901, 'acc_norm_stderr': 0.014478005694182531}, 'hellaswag': {'acc': 0.5877315275841466, 'acc_stderr': 0.004912370023913015, 'acc_norm': 0.752141007767377, 'acc_norm_stderr': 0.0043088709782104105}, 'arc_easy': {'acc': 0.7125420875420876, 'acc_stderr': 0.009286682281593399, 'acc_norm': 0.5660774410774411, 'acc_norm_stderr': 0.010169795770462101}, 'piqa': {'acc': 0.7769314472252449, 'acc_stderr': 0.009713057213018522, 'acc_norm': 0.7834602829162133, 'acc_norm_stderr': 0.009609984714384599}}, 'versions': {'winogrande': 0, 'boolq': 1, 'arc_challenge': 0, 'hellaswag': 0, 'arc_easy': 0, 'piqa': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
