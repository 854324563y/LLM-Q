[2025-03-02 12:49:23 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.7', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.7.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.7.pkl
[2025-03-02 12:52:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.007206388749182224 norm:0.00952675100415945 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0037940465845167637 norm:0.003951892256736755 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0031129021663218737 norm:0.003109193639829755 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0027610519900918007 norm:0.0027041740249842405 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0025531412102282047 norm:0.0022903860080987215 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0024443005677312613 norm:0.0019691968336701393 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.002314987825229764 norm:0.0016999649815261364 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.002263743430376053 norm:0.0015674738679081202 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.002163158031180501 norm:0.0014034751802682877 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.002163731725886464 norm:0.0013288147747516632 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0020954017527401447 norm:0.0012097982689738274 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.002086241729557514 norm:0.001162022235803306 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.002058804966509342 norm:0.0010591794271022081 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0020534279756247997 norm:0.001050432212650776 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0020320359617471695 norm:0.0009446909534744918 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.001981245819479227 norm:0.0008537778630852699 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:50 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0020174956880509853 norm:0.0008649852825328708 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.002005240647122264 norm:0.0008515699300915003 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.002040640916675329 norm:0.0008695450378581882 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0019864363130182028 norm:0.0007771439268253744 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:39 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.016790544614195824 norm:0.01438076514750719 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.009208681993186474 norm:0.008291198872029781 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.007149835117161274 norm:0.005383031442761421 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.0063903434202075005 norm:0.00454286765307188 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.006100645288825035 norm:0.004093875177204609 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.005913115106523037 norm:0.003675102721899748 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.005757802631705999 norm:0.0034616971388459206 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.005595679860562086 norm:0.0031247904989868402 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.005453727673739195 norm:0.0029119914397597313 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.005341320298612118 norm:0.0026907080318778753 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.005217421799898148 norm:0.00245701614767313 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.0051380665972828865 norm:0.002308377530425787 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.0050689117051661015 norm:0.0021383329294621944 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.004989395383745432 norm:0.00191393680870533 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.004936574026942253 norm:0.0017595796380192041 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.0048935022205114365 norm:0.0015736425993964076 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.004860944580286741 norm:0.0014195770490914583 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.00484091741964221 norm:0.0012975342106074095 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:32 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004829127341508865 norm:0.0012243790552020073 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.004811338614672422 norm:0.0012815388618037105 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:27:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.027980417013168335 norm:0.01139005459845066 max memory_allocated 29268.39501953125 
[2025-03-02 13:28:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.019419686868786812 norm:0.007476605474948883 max memory_allocated 29268.39501953125 
[2025-03-02 13:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.016876932233572006 norm:0.006849074736237526 max memory_allocated 29268.39501953125 
[2025-03-02 13:30:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.015290886163711548 norm:0.006054271943867207 max memory_allocated 29268.39501953125 
[2025-03-02 13:30:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.014347604475915432 norm:0.005875838920474052 max memory_allocated 29268.39501953125 
[2025-03-02 13:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.013505439274013042 norm:0.005149376578629017 max memory_allocated 29268.39501953125 
[2025-03-02 13:32:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.012561975978314877 norm:0.004006667993962765 max memory_allocated 29268.39501953125 
[2025-03-02 13:33:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.0121438167989254 norm:0.003789217211306095 max memory_allocated 29268.39501953125 
[2025-03-02 13:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.011780154891312122 norm:0.0035921167582273483 max memory_allocated 29268.39501953125 
[2025-03-02 13:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.01158724632114172 norm:0.0033475763630121946 max memory_allocated 29268.39501953125 
[2025-03-02 13:35:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.011661131866276264 norm:0.003739428473636508 max memory_allocated 29268.39501953125 
[2025-03-02 13:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.011458300985395908 norm:0.003300595795735717 max memory_allocated 29268.39501953125 
[2025-03-02 13:37:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.011305910535156727 norm:0.00269431178458035 max memory_allocated 29268.39501953125 
[2025-03-02 13:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.011287568137049675 norm:0.002944136504083872 max memory_allocated 29268.39501953125 
[2025-03-02 13:39:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.011125730350613594 norm:0.0027853345964103937 max memory_allocated 29268.39501953125 
[2025-03-02 13:40:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.011128791607916355 norm:0.0027162942569702864 max memory_allocated 29268.39501953125 
[2025-03-02 13:40:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.01115792989730835 norm:0.002849014475941658 max memory_allocated 29268.39501953125 
[2025-03-02 13:41:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.011054877191781998 norm:0.002777746645733714 max memory_allocated 29268.39501953125 
[2025-03-02 13:42:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.010953735560178757 norm:0.0025476242881268263 max memory_allocated 29268.39501953125 
[2025-03-02 13:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.010894568637013435 norm:0.0023009045980870724 max memory_allocated 29268.39501953125 
[2025-03-02 13:43:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:44:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.02059098705649376 norm:0.0016145455883815885 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.01644546166062355 norm:0.0006647617556154728 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.014980306848883629 norm:0.0003394261875655502 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.014174140989780426 norm:0.000243156508076936 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.013687320984899998 norm:0.00014521008415613323 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.013291386887431145 norm:0.00012957716535311192 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.013046790845692158 norm:0.0001424117072019726 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.012893685139715672 norm:0.00012892702943645418 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.012848109006881714 norm:0.00014285063662100583 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.01280337292701006 norm:0.00012157546734670177 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.01281802635639906 norm:0.0001542173995403573 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.012810511514544487 norm:0.00012712868920061737 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.012761653400957584 norm:0.00010811544780153781 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.012744623236358166 norm:0.00011039125820389017 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.012768634594976902 norm:0.00012328290904406458 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.01273844949901104 norm:0.00012170287664048374 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.012722901999950409 norm:0.00012789668107870966 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.012715445831418037 norm:0.00014301906048785895 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:33 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.012715373188257217 norm:0.00012375014193821698 max memory_allocated 29268.43798828125 
[2025-03-02 14:00:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.012703176587820053 norm:0.00013278490223456174 max memory_allocated 29268.43798828125 
[2025-03-02 14:00:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.02808704599738121 norm:0.0032734840642660856 max memory_allocated 29268.43798828125 
[2025-03-02 14:02:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.02186242677271366 norm:0.0009498565923422575 max memory_allocated 29268.43798828125 
[2025-03-02 14:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.019653428345918655 norm:0.0005833827890455723 max memory_allocated 29268.43798828125 
[2025-03-02 14:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.01849704422056675 norm:0.000453696382464841 max memory_allocated 29268.43798828125 
[2025-03-02 14:04:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.017763974145054817 norm:0.000338544137775898 max memory_allocated 29268.43798828125 
[2025-03-02 14:05:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.017267853021621704 norm:0.00028225232381373644 max memory_allocated 29268.43798828125 
[2025-03-02 14:06:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.017040487378835678 norm:0.0002373507886659354 max memory_allocated 29268.43798828125 
[2025-03-02 14:07:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.016941023990511894 norm:0.00021922617452219129 max memory_allocated 29268.43798828125 
[2025-03-02 14:08:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.016889333724975586 norm:0.00019362667808309197 max memory_allocated 29268.43798828125 
[2025-03-02 14:09:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.01685425080358982 norm:0.0001778464502422139 max memory_allocated 29268.43798828125 
[2025-03-02 14:09:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.01684367097914219 norm:0.0001472898293286562 max memory_allocated 29268.43798828125 
[2025-03-02 14:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.01678127981722355 norm:0.00013648608000949025 max memory_allocated 29268.43798828125 
[2025-03-02 14:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.01681693084537983 norm:0.0002116973337251693 max memory_allocated 29268.43798828125 
[2025-03-02 14:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.016727421432733536 norm:0.0001410125696565956 max memory_allocated 29268.43798828125 
[2025-03-02 14:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.01671459525823593 norm:0.00012734814663417637 max memory_allocated 29268.43798828125 
[2025-03-02 14:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.016689026728272438 norm:0.00011744260700652376 max memory_allocated 29268.43798828125 
[2025-03-02 14:14:52 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.01668516732752323 norm:0.00011946571612497792 max memory_allocated 29268.43798828125 
[2025-03-02 14:15:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.016679568216204643 norm:0.00012757138756569475 max memory_allocated 29268.43798828125 
[2025-03-02 14:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.016744162887334824 norm:0.00014887977158650756 max memory_allocated 29268.43798828125 
[2025-03-02 14:17:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.016730187460780144 norm:0.00013328433851711452 max memory_allocated 29268.43798828125 
[2025-03-02 14:17:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:18:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.03525182604789734 norm:0.0033994291443377733 max memory_allocated 29268.81298828125 
[2025-03-02 14:19:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.026132073253393173 norm:0.0010688849724829197 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.023342613130807877 norm:0.0006010598735883832 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.021915137767791748 norm:0.0003994263825006783 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.021028202027082443 norm:0.0003097960143350065 max memory_allocated 29268.81298828125 
[2025-03-02 14:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.02049240656197071 norm:0.00026386507670395076 max memory_allocated 29268.81298828125 
[2025-03-02 14:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.02023981511592865 norm:0.00024461111752316356 max memory_allocated 29268.81298828125 
[2025-03-02 14:24:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.020105455070734024 norm:0.00020325594232417643 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.020021148025989532 norm:0.00019994573085568845 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.01995950937271118 norm:0.0001784894848242402 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.019914554432034492 norm:0.00017545235459692776 max memory_allocated 29268.81298828125 
[2025-03-02 14:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.019902193918824196 norm:0.0002000193198909983 max memory_allocated 29268.81298828125 
[2025-03-02 14:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.019852029159665108 norm:0.00016475564916618168 max memory_allocated 29268.81298828125 
[2025-03-02 14:29:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.01983567886054516 norm:0.00015525688650086522 max memory_allocated 29268.81298828125 
[2025-03-02 14:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.019786009564995766 norm:0.0001566902210470289 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.01978648640215397 norm:0.00015818377141840756 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.019772643223404884 norm:0.0001642515999265015 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.01973254606127739 norm:0.0001545492559671402 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.019741741940379143 norm:0.00015174235159065574 max memory_allocated 29268.81298828125 
[2025-03-02 14:34:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.0197155699133873 norm:0.000145423982758075 max memory_allocated 29268.81298828125 
[2025-03-02 14:34:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.040717337280511856 norm:0.0021268429700285196 max memory_allocated 29268.81298828125 
[2025-03-02 14:36:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.03312418982386589 norm:0.0012540745083242655 max memory_allocated 29268.81298828125 
[2025-03-02 14:37:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.029731279239058495 norm:0.0008562793955206871 max memory_allocated 29268.81298828125 
[2025-03-02 14:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.027472781017422676 norm:0.000707854051142931 max memory_allocated 29268.81298828125 
[2025-03-02 14:38:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.02618943341076374 norm:0.0006246660486795008 max memory_allocated 29268.81298828125 
[2025-03-02 14:39:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.025480452924966812 norm:0.0005413647159002721 max memory_allocated 29268.81298828125 
[2025-03-02 14:40:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.025051238015294075 norm:0.0004623371351044625 max memory_allocated 29268.81298828125 
[2025-03-02 14:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.024828683584928513 norm:0.0004289515782147646 max memory_allocated 29268.81298828125 
[2025-03-02 14:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.024693990126252174 norm:0.0003959560126531869 max memory_allocated 29268.81298828125 
[2025-03-02 14:43:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.02473430708050728 norm:0.00047452657599933445 max memory_allocated 29268.81298828125 
[2025-03-02 14:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.024583034217357635 norm:0.0004051628930028528 max memory_allocated 29268.81298828125 
[2025-03-02 14:44:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.024545416235923767 norm:0.0003886499034706503 max memory_allocated 29268.81298828125 
[2025-03-02 14:45:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.024494709447026253 norm:0.0003837125259451568 max memory_allocated 29268.81298828125 
[2025-03-02 14:46:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.024456288665533066 norm:0.00036785894189961255 max memory_allocated 29268.81298828125 
[2025-03-02 14:47:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.02440047264099121 norm:0.00036601556348614395 max memory_allocated 29268.81298828125 
[2025-03-02 14:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.02439669333398342 norm:0.0003627105033956468 max memory_allocated 29268.81298828125 
[2025-03-02 14:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.0243674386292696 norm:0.0003500167513266206 max memory_allocated 29268.81298828125 
[2025-03-02 14:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.02436051145195961 norm:0.00035328156081959605 max memory_allocated 29268.81298828125 
[2025-03-02 14:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.024356933310627937 norm:0.00036969452048651874 max memory_allocated 29268.81298828125 
[2025-03-02 14:51:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.02435927465558052 norm:0.00035087051219306886 max memory_allocated 29268.81298828125 
[2025-03-02 14:51:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:52:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.03824456036090851 norm:0.0013695370871573687 max memory_allocated 29268.81298828125 
[2025-03-02 14:53:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.03244250640273094 norm:0.0006336353253573179 max memory_allocated 29268.81298828125 
[2025-03-02 14:54:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.0300751905888319 norm:0.0003384039446245879 max memory_allocated 29268.81298828125 
[2025-03-02 14:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.028725311160087585 norm:0.00022262003039941192 max memory_allocated 29268.81298828125 
[2025-03-02 14:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.027964452281594276 norm:0.00017881588428281248 max memory_allocated 29268.81298828125 
[2025-03-02 14:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.027524953708052635 norm:0.0001606241858098656 max memory_allocated 29268.81298828125 
[2025-03-02 14:57:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.027292290702462196 norm:0.000154160923557356 max memory_allocated 29268.81298828125 
[2025-03-02 14:58:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.027178505435585976 norm:0.00014296626613941044 max memory_allocated 29268.81298828125 
[2025-03-02 14:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.02712075598537922 norm:0.00014178593119140714 max memory_allocated 29268.81298828125 
[2025-03-02 14:59:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.02708328887820244 norm:0.0001427493552910164 max memory_allocated 29268.81298828125 
[2025-03-02 15:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.027058830484747887 norm:0.000165337638463825 max memory_allocated 29268.81298828125 
[2025-03-02 15:01:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.027012381702661514 norm:0.0001441447384422645 max memory_allocated 29268.81298828125 
[2025-03-02 15:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.026973240077495575 norm:0.00014584990276489407 max memory_allocated 29268.81298828125 
[2025-03-02 15:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.026949787512421608 norm:0.00014331402780953795 max memory_allocated 29268.81298828125 
[2025-03-02 15:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.026943877339363098 norm:0.00014059318345971406 max memory_allocated 29268.81298828125 
[2025-03-02 15:05:00 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.026951279491186142 norm:0.00014459851081483066 max memory_allocated 29268.81298828125 
[2025-03-02 15:05:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.0269677322357893 norm:0.0001511521404609084 max memory_allocated 29268.81298828125 
[2025-03-02 15:06:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.026956036686897278 norm:0.00014791794819757342 max memory_allocated 29268.81298828125 
[2025-03-02 15:07:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.026949061080813408 norm:0.00014503028069157153 max memory_allocated 29268.81298828125 
[2025-03-02 15:08:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.026944614946842194 norm:0.00014276467845775187 max memory_allocated 29268.81298828125 
[2025-03-02 15:08:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:09:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.042824000120162964 norm:0.0015417113900184631 max memory_allocated 29268.81298828125 
[2025-03-02 15:10:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.03628458082675934 norm:0.0006424717721529305 max memory_allocated 29268.81298828125 
[2025-03-02 15:11:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.03380178287625313 norm:0.0003524096100591123 max memory_allocated 29268.81298828125 
[2025-03-02 15:11:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.03233736753463745 norm:0.00024923335877247155 max memory_allocated 29268.81298828125 
[2025-03-02 15:12:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.0315219946205616 norm:0.00020381479407660663 max memory_allocated 29268.81298828125 
[2025-03-02 15:13:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.031025979667901993 norm:0.00018111037206836045 max memory_allocated 29268.81298828125 
[2025-03-02 15:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.030741406604647636 norm:0.00016573886387050152 max memory_allocated 29268.81298828125 
[2025-03-02 15:15:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.030575314536690712 norm:0.00015755603089928627 max memory_allocated 29268.81298828125 
[2025-03-02 15:16:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.030486375093460083 norm:0.00014841674419585615 max memory_allocated 29268.81298828125 
[2025-03-02 15:16:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.030426518991589546 norm:0.00014401937369257212 max memory_allocated 29268.81298828125 
[2025-03-02 15:17:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.03039376437664032 norm:0.00014948884199839085 max memory_allocated 29268.81298828125 
[2025-03-02 15:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.030384132638573647 norm:0.00014615482359658927 max memory_allocated 29268.81298828125 
[2025-03-02 15:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.030373867601156235 norm:0.00014479139645118266 max memory_allocated 29268.81298828125 
[2025-03-02 15:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.03034917823970318 norm:0.0001411338453181088 max memory_allocated 29268.81298828125 
[2025-03-02 15:21:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.030339010059833527 norm:0.00014090609329286963 max memory_allocated 29268.81298828125 
[2025-03-02 15:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.030324649065732956 norm:0.00014073317288421094 max memory_allocated 29268.81298828125 
[2025-03-02 15:22:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.030329782515764236 norm:0.00013653736095875502 max memory_allocated 29268.81298828125 
[2025-03-02 15:23:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.030305318534374237 norm:0.00013719334674533457 max memory_allocated 29268.81298828125 
[2025-03-02 15:24:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.030291834846138954 norm:0.00013661119737662375 max memory_allocated 29268.81298828125 
[2025-03-02 15:25:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.03025185875594616 norm:0.00013709921040572226 max memory_allocated 29268.81298828125 
[2025-03-02 15:25:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.043656300753355026 norm:0.0012437034165486693 max memory_allocated 29268.81298828125 
[2025-03-02 15:27:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.038440026342868805 norm:0.0005404155235737562 max memory_allocated 29268.81298828125 
[2025-03-02 15:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.036148473620414734 norm:0.0002907817834056914 max memory_allocated 29268.81298828125 
[2025-03-02 15:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.03487520292401314 norm:0.00020149463671259582 max memory_allocated 29268.81298828125 
[2025-03-02 15:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.03416464850306511 norm:0.0001638400717638433 max memory_allocated 29268.81298828125 
[2025-03-02 15:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.03371867164969444 norm:0.00014785399253014475 max memory_allocated 29268.81298828125 
[2025-03-02 15:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.033480238169431686 norm:0.00013832772674504668 max memory_allocated 29268.81298828125 
[2025-03-02 15:32:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.03335880488157272 norm:0.00013660572585649788 max memory_allocated 29268.81298828125 
[2025-03-02 15:33:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.03331078961491585 norm:0.00013041007332503796 max memory_allocated 29268.81298828125 
[2025-03-02 15:33:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.033261626958847046 norm:0.00012787326704710722 max memory_allocated 29268.81298828125 
[2025-03-02 15:34:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.03324298560619354 norm:0.00012880154827143997 max memory_allocated 29268.81298828125 
[2025-03-02 15:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.033223144710063934 norm:0.0001270452339667827 max memory_allocated 29268.81298828125 
[2025-03-02 15:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.03318850323557854 norm:0.00013084473903290927 max memory_allocated 29268.81298828125 
[2025-03-02 15:37:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.03318610042333603 norm:0.00013142495299689472 max memory_allocated 29268.81298828125 
[2025-03-02 15:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.03317074477672577 norm:0.00013064815721008927 max memory_allocated 29268.81298828125 
[2025-03-02 15:38:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.03316734358668327 norm:0.00013032634160481393 max memory_allocated 29268.81298828125 
[2025-03-02 15:39:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.03315110504627228 norm:0.0001290084037464112 max memory_allocated 29268.81298828125 
[2025-03-02 15:40:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.03313615918159485 norm:0.00012710651208180934 max memory_allocated 29268.81298828125 
[2025-03-02 15:41:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.03313201665878296 norm:0.00012671417789533734 max memory_allocated 29268.81298828125 
[2025-03-02 15:42:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.03312431648373604 norm:0.00012468453496694565 max memory_allocated 29268.81298828125 
[2025-03-02 15:42:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.04582091420888901 norm:0.0010387898655608296 max memory_allocated 29268.81298828125 
[2025-03-02 15:44:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.04113626852631569 norm:0.00041958593646995723 max memory_allocated 29268.81298828125 
[2025-03-02 15:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.039052121341228485 norm:0.0002415836788713932 max memory_allocated 29268.81298828125 
[2025-03-02 15:45:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.03782924637198448 norm:0.00017949289758689702 max memory_allocated 29268.81298828125 
[2025-03-02 15:46:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.03717059642076492 norm:0.0001563474943395704 max memory_allocated 29268.81298828125 
[2025-03-02 15:47:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.0367557555437088 norm:0.00013868059613741934 max memory_allocated 29268.81298828125 
[2025-03-02 15:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.03649679198861122 norm:0.00012786559818778187 max memory_allocated 29268.81298828125 
[2025-03-02 15:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.03636595606803894 norm:0.00012486721971072257 max memory_allocated 29268.81298828125 
[2025-03-02 15:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.036308348178863525 norm:0.00012041013542329893 max memory_allocated 29268.81298828125 
[2025-03-02 15:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.036269042640924454 norm:0.00011943854042328894 max memory_allocated 29268.81298828125 
[2025-03-02 15:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.03622370585799217 norm:0.00011437559442128986 max memory_allocated 29268.81298828125 
[2025-03-02 15:52:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.0361761674284935 norm:0.00011303914652671665 max memory_allocated 29268.81298828125 
[2025-03-02 15:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.03616168722510338 norm:0.00011508178431540728 max memory_allocated 29268.81298828125 
[2025-03-02 15:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.03616545721888542 norm:0.00011579812417039648 max memory_allocated 29268.81298828125 
[2025-03-02 15:55:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.03614351525902748 norm:0.00011159737186972052 max memory_allocated 29268.81298828125 
[2025-03-02 15:55:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.036151111125946045 norm:0.00011175152030773461 max memory_allocated 29268.81298828125 
[2025-03-02 15:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.036151088774204254 norm:0.00011316162999719381 max memory_allocated 29268.81298828125 
[2025-03-02 15:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.03617089241743088 norm:0.00011318241013213992 max memory_allocated 29268.81298828125 
[2025-03-02 15:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.03616459667682648 norm:0.00011451174941612408 max memory_allocated 29268.81298828125 
[2025-03-02 15:59:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.036149464547634125 norm:0.00011346402607159689 max memory_allocated 29268.81298828125 
[2025-03-02 15:59:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 16:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.0498870424926281 norm:0.0011030255118384957 max memory_allocated 29268.81298828125 
[2025-03-02 16:01:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.04514363035559654 norm:0.0004842140479013324 max memory_allocated 29268.81298828125 
[2025-03-02 16:02:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.04254009202122688 norm:0.00026371906278654933 max memory_allocated 29268.81298828125 
[2025-03-02 16:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.041273970156908035 norm:0.00018102176545653492 max memory_allocated 29268.81298828125 
[2025-03-02 16:03:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.04056846350431442 norm:0.00015118950977921486 max memory_allocated 29268.81298828125 
[2025-03-02 16:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.040102362632751465 norm:0.00013172256876714528 max memory_allocated 29268.81298828125 
[2025-03-02 16:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.03987210988998413 norm:0.00012582795170601457 max memory_allocated 29268.81298828125 
[2025-03-02 16:06:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.03973705694079399 norm:0.0001205804364872165 max memory_allocated 29268.81298828125 
[2025-03-02 16:07:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.03967251628637314 norm:0.00011980537965428084 max memory_allocated 29268.81298828125 
[2025-03-02 16:07:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.03961731866002083 norm:0.00011707300291163847 max memory_allocated 29268.81298828125 
[2025-03-02 16:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.039560798555612564 norm:0.00011633830581558868 max memory_allocated 29268.81298828125 
[2025-03-02 16:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.03953215852379799 norm:0.00011210866796318442 max memory_allocated 29268.81298828125 
[2025-03-02 16:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.03951795771718025 norm:0.0001120250453823246 max memory_allocated 29268.81298828125 
[2025-03-02 16:11:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.039495449513196945 norm:0.0001112649479182437 max memory_allocated 29268.81298828125 
[2025-03-02 16:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.039485763758420944 norm:0.00010868513345485553 max memory_allocated 29268.81298828125 
[2025-03-02 16:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.03947684168815613 norm:0.00010980237129842862 max memory_allocated 29268.81298828125 
[2025-03-02 16:13:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.03947092965245247 norm:0.00010973786993417889 max memory_allocated 29268.81298828125 
[2025-03-02 16:14:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.03948533162474632 norm:0.00011156254913657904 max memory_allocated 29268.81298828125 
[2025-03-02 16:15:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.039505381137132645 norm:0.00011196850391570479 max memory_allocated 29268.81298828125 
[2025-03-02 16:16:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.03950732201337814 norm:0.00011157101835124195 max memory_allocated 29268.81298828125 
[2025-03-02 16:16:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.05040682107210159 norm:0.0009068450890481472 max memory_allocated 29268.81298828125 
[2025-03-02 16:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.04685801640152931 norm:0.0004167939769104123 max memory_allocated 29268.81298828125 
[2025-03-02 16:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.044787824153900146 norm:0.00024983054026961327 max memory_allocated 29268.81298828125 
[2025-03-02 16:19:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.043463077396154404 norm:0.00017449830193072557 max memory_allocated 29268.81298828125 
[2025-03-02 16:20:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.042698025703430176 norm:0.00014796775940340012 max memory_allocated 29268.81298828125 
[2025-03-02 16:21:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.042243171483278275 norm:0.0001305156183661893 max memory_allocated 29268.81298828125 
[2025-03-02 16:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.04201246425509453 norm:0.00011596512922551483 max memory_allocated 29268.81298828125 
[2025-03-02 16:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.0419008694589138 norm:0.00011111270578112453 max memory_allocated 29268.81298828125 
[2025-03-02 16:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.04185499623417854 norm:0.00010950263094855472 max memory_allocated 29268.81298828125 
[2025-03-02 16:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.041835200041532516 norm:0.00010808688239194453 max memory_allocated 29268.81298828125 
[2025-03-02 16:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.041799694299697876 norm:0.00010575292981229722 max memory_allocated 29268.81298828125 
[2025-03-02 16:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.04177214577794075 norm:0.0001016306850942783 max memory_allocated 29268.81298828125 
[2025-03-02 16:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.04175598919391632 norm:0.00010061349166790023 max memory_allocated 29268.81298828125 
[2025-03-02 16:28:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.04173482209444046 norm:0.00010112267773365602 max memory_allocated 29268.81298828125 
[2025-03-02 16:29:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.041726790368556976 norm:0.00010114143515238538 max memory_allocated 29268.81298828125 
[2025-03-02 16:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.041726741939783096 norm:0.00010276219109073281 max memory_allocated 29268.81298828125 
[2025-03-02 16:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.041717447340488434 norm:0.00010207531886408105 max memory_allocated 29268.81298828125 
[2025-03-02 16:31:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.04170912131667137 norm:0.00010008415119955316 max memory_allocated 29268.81298828125 
[2025-03-02 16:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.041707396507263184 norm:0.00010150345042347908 max memory_allocated 29268.81298828125 
[2025-03-02 16:33:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.04169550910592079 norm:0.00010009649849962443 max memory_allocated 29268.81298828125 
[2025-03-02 16:33:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:34:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.05219860002398491 norm:0.0006909024668857455 max memory_allocated 29268.81298828125 
[2025-03-02 16:35:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.04900829866528511 norm:0.00035492604365572333 max memory_allocated 29268.81298828125 
[2025-03-02 16:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.04709833860397339 norm:0.00022745173191651702 max memory_allocated 29268.81298828125 
[2025-03-02 16:36:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.04578477144241333 norm:0.00017051718896254897 max memory_allocated 29268.81298828125 
[2025-03-02 16:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.04489743337035179 norm:0.00014197675045579672 max memory_allocated 29268.81298828125 
[2025-03-02 16:38:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.04440692067146301 norm:0.00012419954873621464 max memory_allocated 29268.81298828125 
[2025-03-02 16:39:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.04415944218635559 norm:0.00011593682575039566 max memory_allocated 29268.81298828125 
[2025-03-02 16:40:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.04404632747173309 norm:0.00011059034295612946 max memory_allocated 29268.81298828125 
[2025-03-02 16:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.04397299140691757 norm:0.00010772391397040337 max memory_allocated 29268.81298828125 
[2025-03-02 16:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.04393278807401657 norm:0.00010540020593907684 max memory_allocated 29268.81298828125 
[2025-03-02 16:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.0439017079770565 norm:0.0001046716861310415 max memory_allocated 29268.81298828125 
[2025-03-02 16:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.04388146474957466 norm:0.00010316368570784107 max memory_allocated 29268.81298828125 
[2025-03-02 16:44:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.04386144503951073 norm:0.00010471574933035299 max memory_allocated 29268.81298828125 
[2025-03-02 16:45:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.043834980577230453 norm:0.00010087790724355727 max memory_allocated 29268.81298828125 
[2025-03-02 16:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.04382345452904701 norm:0.00010022608330473304 max memory_allocated 29268.81298828125 
[2025-03-02 16:46:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.04382632300257683 norm:0.0001007788087008521 max memory_allocated 29268.81298828125 
[2025-03-02 16:47:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.04383361339569092 norm:0.00010047939576907083 max memory_allocated 29268.81298828125 
[2025-03-02 16:48:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.043823111802339554 norm:0.00010205658327322453 max memory_allocated 29268.81298828125 
[2025-03-02 16:49:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.043812450021505356 norm:0.00010063577792607248 max memory_allocated 29268.81298828125 
[2025-03-02 16:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.043810002505779266 norm:0.00010021181515185162 max memory_allocated 29268.81298828125 
[2025-03-02 16:50:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:51:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.056452468037605286 norm:0.001030461397022009 max memory_allocated 29269.50048828125 
[2025-03-02 16:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.052373431622982025 norm:0.0005099970730952919 max memory_allocated 29269.50048828125 
[2025-03-02 16:53:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.050045304000377655 norm:0.00031179547659121454 max memory_allocated 29269.50048828125 
[2025-03-02 16:53:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.04865812137722969 norm:0.0002230374957434833 max memory_allocated 29269.50048828125 
[2025-03-02 16:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.04786268621683121 norm:0.00017429015133529902 max memory_allocated 29269.50048828125 
[2025-03-02 16:55:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.04737193137407303 norm:0.00014843032113276422 max memory_allocated 29269.50048828125 
[2025-03-02 16:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.04712667316198349 norm:0.00013827180373482406 max memory_allocated 29269.50048828125 
[2025-03-02 16:57:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.04696904122829437 norm:0.0001270876673515886 max memory_allocated 29269.50048828125 
[2025-03-02 16:58:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.04687384516000748 norm:0.0001185097498819232 max memory_allocated 29269.50048828125 
[2025-03-02 16:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.04685065150260925 norm:0.00012157063611084595 max memory_allocated 29269.50048828125 
[2025-03-02 16:59:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.046810511499643326 norm:0.00011475058272480965 max memory_allocated 29269.50048828125 
[2025-03-02 17:00:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.04680071398615837 norm:0.00011310474656056613 max memory_allocated 29269.50048828125 
[2025-03-02 17:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.04677785187959671 norm:0.00010981313971569762 max memory_allocated 29269.50048828125 
[2025-03-02 17:02:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.046756207942962646 norm:0.00010922311776084825 max memory_allocated 29269.50048828125 
[2025-03-02 17:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.04674238711595535 norm:0.00011100341362180188 max memory_allocated 29269.50048828125 
[2025-03-02 17:03:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.04672090336680412 norm:0.0001124166083172895 max memory_allocated 29269.50048828125 
[2025-03-02 17:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.04671746864914894 norm:0.00011039678065571934 max memory_allocated 29269.50048828125 
[2025-03-02 17:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.046701543033123016 norm:0.0001095439656637609 max memory_allocated 29269.50048828125 
[2025-03-02 17:06:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.04670829325914383 norm:0.00011181236914126202 max memory_allocated 29269.50048828125 
[2025-03-02 17:07:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.04669395089149475 norm:0.00010981142258970067 max memory_allocated 29269.50048828125 
[2025-03-02 17:07:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:08:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.058664146810770035 norm:0.0009041427401825786 max memory_allocated 29269.50048828125 
[2025-03-02 17:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.055127620697021484 norm:0.0003681774833239615 max memory_allocated 29269.50048828125 
[2025-03-02 17:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.05341137573122978 norm:0.000248110038228333 max memory_allocated 29269.50048828125 
[2025-03-02 17:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.05205841735005379 norm:0.00019183177209924906 max memory_allocated 29269.50048828125 
[2025-03-02 17:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.05112076178193092 norm:0.00015928623906802386 max memory_allocated 29269.50048828125 
[2025-03-02 17:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.05055762454867363 norm:0.0001385873183608055 max memory_allocated 29269.50048828125 
[2025-03-02 17:13:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.05028875917196274 norm:0.00012766096915584058 max memory_allocated 29269.50048828125 
[2025-03-02 17:14:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.05015350505709648 norm:0.00011769145203288645 max memory_allocated 29269.50048828125 
[2025-03-02 17:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.050073400139808655 norm:0.00010794501577038318 max memory_allocated 29269.50048828125 
[2025-03-02 17:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.05004284530878067 norm:0.000102681340649724 max memory_allocated 29269.50048828125 
[2025-03-02 17:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.05000616982579231 norm:9.87493694992736e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:17:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.04998137801885605 norm:9.253260941477492e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:18:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.04995886981487274 norm:8.968202018877491e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:19:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.049941688776016235 norm:9.014205716084689e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:20:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.049912579357624054 norm:9.041905286721885e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:20:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.04990947246551514 norm:9.043358295457438e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:21:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.0499015636742115 norm:8.922363485908136e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:22:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.04989936575293541 norm:8.748130494495854e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:23:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.04988878592848778 norm:8.80516308825463e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:24:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.049875419586896896 norm:8.703651838004589e-05 max memory_allocated 29269.50048828125 
[2025-03-02 17:24:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:25:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.06120670214295387 norm:0.001081498572602868 max memory_allocated 29269.87548828125 
[2025-03-02 17:26:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.05847759172320366 norm:0.0005289793480187654 max memory_allocated 29269.87548828125 
[2025-03-02 17:27:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.056934695690870285 norm:0.0003293079789727926 max memory_allocated 29269.87548828125 
[2025-03-02 17:27:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.05565729737281799 norm:0.00023147604952100664 max memory_allocated 29269.87548828125 
[2025-03-02 17:28:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.05481436848640442 norm:0.00017816164472606033 max memory_allocated 29269.87548828125 
[2025-03-02 17:29:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.05432676896452904 norm:0.00014641151938121766 max memory_allocated 29269.87548828125 
[2025-03-02 17:30:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.05414358526468277 norm:0.00012864456220995635 max memory_allocated 29269.87548828125 
[2025-03-02 17:31:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.05405312404036522 norm:0.00011887023720191792 max memory_allocated 29269.87548828125 
[2025-03-02 17:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.05401983857154846 norm:0.00011453918705228716 max memory_allocated 29269.87548828125 
[2025-03-02 17:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.05397064983844757 norm:0.00010759854194475338 max memory_allocated 29269.87548828125 
[2025-03-02 17:33:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.05393264442682266 norm:0.00010447957902215421 max memory_allocated 29269.87548828125 
[2025-03-02 17:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.05391566455364227 norm:0.00010491730063222349 max memory_allocated 29269.87548828125 
[2025-03-02 17:35:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.05390545353293419 norm:0.00010376919817645103 max memory_allocated 29269.87548828125 
[2025-03-02 17:36:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.053899288177490234 norm:0.00010272590589011088 max memory_allocated 29269.87548828125 
[2025-03-02 17:37:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.05387874320149422 norm:0.00010279750858899206 max memory_allocated 29269.87548828125 
[2025-03-02 17:37:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.05387096479535103 norm:0.00010454619041411206 max memory_allocated 29269.87548828125 
[2025-03-02 17:38:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.053873829543590546 norm:0.00010454045695951208 max memory_allocated 29269.87548828125 
[2025-03-02 17:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.05385256186127663 norm:0.00010348143405281007 max memory_allocated 29269.87548828125 
[2025-03-02 17:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.053845468908548355 norm:0.00010286609176546335 max memory_allocated 29269.87548828125 
[2025-03-02 17:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.053835224360227585 norm:0.00010406582441646606 max memory_allocated 29269.87548828125 
[2025-03-02 17:41:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:42:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.06650027632713318 norm:0.0014382866211235523 max memory_allocated 29269.87548828125 
[2025-03-02 17:43:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.06335806101560593 norm:0.000653256312943995 max memory_allocated 29269.87548828125 
[2025-03-02 17:44:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.06152466684579849 norm:0.00039215615834109485 max memory_allocated 29269.87548828125 
[2025-03-02 17:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.060091473162174225 norm:0.0002682290505617857 max memory_allocated 29269.87548828125 
[2025-03-02 17:45:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.05907353013753891 norm:0.0001988730946322903 max memory_allocated 29269.87548828125 
[2025-03-02 17:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.05858760327100754 norm:0.0001594997593201697 max memory_allocated 29269.87548828125 
[2025-03-02 17:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.05839467793703079 norm:0.00013525522081181407 max memory_allocated 29269.87548828125 
[2025-03-02 17:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.05829877778887749 norm:0.00011991037172265351 max memory_allocated 29269.87548828125 
[2025-03-02 17:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.058234430849552155 norm:0.00010669691255316138 max memory_allocated 29269.87548828125 
[2025-03-02 17:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.058194417506456375 norm:0.00010099089558934793 max memory_allocated 29269.87548828125 
[2025-03-02 17:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.05817432701587677 norm:9.614571172278374e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.05815057083964348 norm:9.326411236543208e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:52:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.058131035417318344 norm:9.089679952012375e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.05811981111764908 norm:8.89432049007155e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.058117542415857315 norm:8.857306238496676e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.05810796096920967 norm:8.830121805658564e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.058098889887332916 norm:8.756184979574755e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.0580892413854599 norm:8.75067780725658e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.058100633323192596 norm:8.845287084113806e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:58:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.05808945745229721 norm:8.733447612030432e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:58:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.0733037143945694 norm:0.001319976057857275 max memory_allocated 29270.25048828125 
[2025-03-02 18:00:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.06992675364017487 norm:0.0005583631573244929 max memory_allocated 29270.25048828125 
[2025-03-02 18:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.06802991032600403 norm:0.0003278775839135051 max memory_allocated 29270.25048828125 
[2025-03-02 18:01:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.06651194393634796 norm:0.00023050029994919896 max memory_allocated 29270.25048828125 
[2025-03-02 18:02:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.06546751409769058 norm:0.0001763267646310851 max memory_allocated 29270.25048828125 
[2025-03-02 18:03:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.06498610228300095 norm:0.00014692028344143182 max memory_allocated 29270.25048828125 
[2025-03-02 18:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.06481333076953888 norm:0.00013139820657670498 max memory_allocated 29270.25048828125 
[2025-03-02 18:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.06472741067409515 norm:0.00012181622150819749 max memory_allocated 29270.25048828125 
[2025-03-02 18:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.06464545428752899 norm:0.00011261265899520367 max memory_allocated 29270.25048828125 
[2025-03-02 18:06:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.06460192054510117 norm:0.00010851564002223313 max memory_allocated 29270.25048828125 
[2025-03-02 18:07:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.0645608976483345 norm:0.00010431611735839397 max memory_allocated 29270.25048828125 
[2025-03-02 18:08:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.06452497839927673 norm:0.0001025787933031097 max memory_allocated 29270.25048828125 
[2025-03-02 18:09:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.0644935593008995 norm:0.00010416729492135346 max memory_allocated 29270.25048828125 
[2025-03-02 18:10:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.06448457390069962 norm:0.00010217437375104055 max memory_allocated 29270.25048828125 
[2025-03-02 18:11:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.06448329240083694 norm:0.00010045230737887323 max memory_allocated 29270.25048828125 
[2025-03-02 18:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.06447583436965942 norm:9.792091441340744e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:12:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.06447087973356247 norm:0.00010056349856313318 max memory_allocated 29270.25048828125 
[2025-03-02 18:13:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.06445709615945816 norm:9.909287473419681e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:14:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.0644574910402298 norm:0.00010066856339108199 max memory_allocated 29270.25048828125 
[2025-03-02 18:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.06444334238767624 norm:9.963354386854917e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:15:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:16:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.0791667029261589 norm:0.0008951457566581666 max memory_allocated 29270.43798828125 
[2025-03-02 18:17:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.076841339468956 norm:0.00041320404852740467 max memory_allocated 29270.43798828125 
[2025-03-02 18:18:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.07503646612167358 norm:0.00026076764333993196 max memory_allocated 29270.43798828125 
[2025-03-02 18:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.07346910238265991 norm:0.00018577702576294541 max memory_allocated 29270.43798828125 
[2025-03-02 18:19:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.07245314121246338 norm:0.00014977026148699224 max memory_allocated 29270.43798828125 
[2025-03-02 18:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.07206991314888 norm:0.0001273335365112871 max memory_allocated 29270.43798828125 
[2025-03-02 18:21:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.07192957401275635 norm:0.00011331052519381046 max memory_allocated 29270.43798828125 
[2025-03-02 18:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.07185710221529007 norm:0.00011073231871705502 max memory_allocated 29270.43798828125 
[2025-03-02 18:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.07180368155241013 norm:0.00010744921746663749 max memory_allocated 29270.43798828125 
[2025-03-02 18:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.07175968587398529 norm:0.00010351467062719166 max memory_allocated 29270.43798828125 
[2025-03-02 18:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.07172910124063492 norm:9.97790921246633e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:25:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.0717179924249649 norm:9.734809282235801e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.07170501351356506 norm:9.59719909587875e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.0716971606016159 norm:9.712261817185208e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:28:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.07169493287801743 norm:9.578400204190984e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:28:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.07168528437614441 norm:9.477604180574417e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.07167427986860275 norm:9.684231918072328e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:30:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.07167346775531769 norm:9.681827941676602e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.07166171818971634 norm:9.567341476213187e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.07165699452161789 norm:9.61997575359419e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:32:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:33:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.08774807304143906 norm:0.0008497133385390043 max memory_allocated 29270.43798828125 
[2025-03-02 18:34:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.08471876382827759 norm:0.0003906574274878949 max memory_allocated 29270.43798828125 
[2025-03-02 18:35:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.08266526460647583 norm:0.0002596488920971751 max memory_allocated 29270.43798828125 
[2025-03-02 18:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.08092606067657471 norm:0.00019193979096598923 max memory_allocated 29270.43798828125 
[2025-03-02 18:36:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.07986733317375183 norm:0.00015776733926031739 max memory_allocated 29270.43798828125 
[2025-03-02 18:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.0795038491487503 norm:0.00013605010462924838 max memory_allocated 29270.43798828125 
[2025-03-02 18:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.0793597549200058 norm:0.00012340612011030316 max memory_allocated 29270.43798828125 
[2025-03-02 18:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.07929530739784241 norm:0.00011522719432832673 max memory_allocated 29270.43798828125 
[2025-03-02 18:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.07921084761619568 norm:0.00011062195699196309 max memory_allocated 29270.43798828125 
[2025-03-02 18:40:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.07914240658283234 norm:0.00010709606431191787 max memory_allocated 29270.43798828125 
[2025-03-02 18:41:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.07909681648015976 norm:0.00010487485997145995 max memory_allocated 29270.43798828125 
[2025-03-02 18:42:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.07906355708837509 norm:9.82750061666593e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.07905441522598267 norm:9.638867049943656e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:44:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.07903534173965454 norm:9.479328582528979e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:45:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.07903267443180084 norm:9.696932829683647e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:45:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.07900718599557877 norm:9.72064008237794e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:46:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.07900424301624298 norm:9.613354632165283e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:47:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.07898689061403275 norm:9.396339009981602e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.07896867394447327 norm:9.300102101406083e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.07895252108573914 norm:9.403828153153881e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:49:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:50:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.09935957938432693 norm:0.0011511498596519232 max memory_allocated 29270.81298828125 
[2025-03-02 18:51:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.09573706239461899 norm:0.0005727962125092745 max memory_allocated 29270.81298828125 
[2025-03-02 18:52:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.09340682625770569 norm:0.00037702443660236895 max memory_allocated 29270.81298828125 
[2025-03-02 18:52:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.09149773418903351 norm:0.00027136330027133226 max memory_allocated 29270.81298828125 
[2025-03-02 18:53:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.09034506976604462 norm:0.00021383971034083515 max memory_allocated 29270.81298828125 
[2025-03-02 18:54:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.08995001763105392 norm:0.00017849572759587318 max memory_allocated 29270.81298828125 
[2025-03-02 18:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.08980588614940643 norm:0.00015701352094765753 max memory_allocated 29270.81298828125 
[2025-03-02 18:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.08969254791736603 norm:0.00014375572209246457 max memory_allocated 29270.81298828125 
[2025-03-02 18:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.0896306186914444 norm:0.00013530596334021538 max memory_allocated 29270.81298828125 
[2025-03-02 18:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.08956366032361984 norm:0.00013020049664191902 max memory_allocated 29270.81298828125 
[2025-03-02 18:58:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.08952329307794571 norm:0.0001236411917489022 max memory_allocated 29270.81298828125 
[2025-03-02 18:59:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.08948994427919388 norm:0.00011808570707216859 max memory_allocated 29270.81298828125 
[2025-03-02 19:00:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.08947733044624329 norm:0.0001159374151029624 max memory_allocated 29270.81298828125 
[2025-03-02 19:01:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.08946509659290314 norm:0.00011489821918075904 max memory_allocated 29270.81298828125 
[2025-03-02 19:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.08944879472255707 norm:0.000116087103378959 max memory_allocated 29270.81298828125 
[2025-03-02 19:02:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.08943196386098862 norm:0.00011436860222602263 max memory_allocated 29270.81298828125 
[2025-03-02 19:03:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.08942188322544098 norm:0.00011376244219718501 max memory_allocated 29270.81298828125 
[2025-03-02 19:04:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.08940332382917404 norm:0.00011258335143793374 max memory_allocated 29270.81298828125 
[2025-03-02 19:05:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.08940770477056503 norm:0.00011406796693336219 max memory_allocated 29270.81298828125 
[2025-03-02 19:06:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.08940668404102325 norm:0.00011410428851377219 max memory_allocated 29270.81298828125 
[2025-03-02 19:06:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.11009318381547928 norm:0.0009458842687308788 max memory_allocated 29270.81298828125 
[2025-03-02 19:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.10742586106061935 norm:0.0004973068716935813 max memory_allocated 29270.81298828125 
[2025-03-02 19:09:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.10522584617137909 norm:0.0003188251284882426 max memory_allocated 29270.81298828125 
[2025-03-02 19:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.10328030586242676 norm:0.0002273401478305459 max memory_allocated 29270.81298828125 
[2025-03-02 19:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.10226401686668396 norm:0.00018086345517076552 max memory_allocated 29270.81298828125 
[2025-03-02 19:11:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.10195846855640411 norm:0.00015817520034033805 max memory_allocated 29270.81298828125 
[2025-03-02 19:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.10180523246526718 norm:0.00014404689136426896 max memory_allocated 29270.81298828125 
[2025-03-02 19:13:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.10170949995517731 norm:0.0001344743650406599 max memory_allocated 29270.81298828125 
[2025-03-02 19:14:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.1016552746295929 norm:0.00012941478053107858 max memory_allocated 29270.81298828125 
[2025-03-02 19:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.10161864012479782 norm:0.0001282284501940012 max memory_allocated 29270.81298828125 
[2025-03-02 19:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.10158907622098923 norm:0.00012485432671383023 max memory_allocated 29270.81298828125 
[2025-03-02 19:16:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.10155187547206879 norm:0.00012103225162718445 max memory_allocated 29270.81298828125 
[2025-03-02 19:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.10153781622648239 norm:0.00012226645776536316 max memory_allocated 29270.81298828125 
[2025-03-02 19:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.10154255479574203 norm:0.00011780888598877937 max memory_allocated 29270.81298828125 
[2025-03-02 19:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.10150666534900665 norm:0.00011656284186756238 max memory_allocated 29270.81298828125 
[2025-03-02 19:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.10148217529058456 norm:0.000120012708066497 max memory_allocated 29270.81298828125 
[2025-03-02 19:20:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.10148439556360245 norm:0.00012175703886896372 max memory_allocated 29270.81298828125 
[2025-03-02 19:21:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.10147614777088165 norm:0.000118992269563023 max memory_allocated 29270.81298828125 
[2025-03-02 19:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.10148057341575623 norm:0.00011831609299406409 max memory_allocated 29270.81298828125 
[2025-03-02 19:23:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.10148341953754425 norm:0.00011731081758625805 max memory_allocated 29270.81298828125 
[2025-03-02 19:23:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:24:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.12604185938835144 norm:0.0011953681241720915 max memory_allocated 29271.18798828125 
[2025-03-02 19:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.12289049476385117 norm:0.0006105085485614836 max memory_allocated 29271.18798828125 
[2025-03-02 19:26:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.12041379511356354 norm:0.00038280372973531485 max memory_allocated 29271.18798828125 
[2025-03-02 19:26:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.11814447492361069 norm:0.0002733486471697688 max memory_allocated 29271.18798828125 
[2025-03-02 19:27:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.11707325279712677 norm:0.00021396594820544124 max memory_allocated 29271.18798828125 
[2025-03-02 19:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.11677750945091248 norm:0.00018227662076242268 max memory_allocated 29271.18798828125 
[2025-03-02 19:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.11664589494466782 norm:0.00016559037612751126 max memory_allocated 29271.18798828125 
[2025-03-02 19:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.11655661463737488 norm:0.0001556232600705698 max memory_allocated 29271.18798828125 
[2025-03-02 19:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.11649029701948166 norm:0.00014775677118450403 max memory_allocated 29271.18798828125 
[2025-03-02 19:31:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.11644187569618225 norm:0.0001412835845258087 max memory_allocated 29271.18798828125 
[2025-03-02 19:32:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.11640844494104385 norm:0.00013691751519218087 max memory_allocated 29271.18798828125 
[2025-03-02 19:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.11638353765010834 norm:0.0001342418690910563 max memory_allocated 29271.18798828125 
[2025-03-02 19:34:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.11634676158428192 norm:0.00013332779053598642 max memory_allocated 29271.18798828125 
[2025-03-02 19:35:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.11634312570095062 norm:0.00013173880870454013 max memory_allocated 29271.18798828125 
[2025-03-02 19:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.11632727086544037 norm:0.00013010919792577624 max memory_allocated 29271.18798828125 
[2025-03-02 19:36:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.11631032079458237 norm:0.00012953644909430295 max memory_allocated 29271.18798828125 
[2025-03-02 19:37:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.11629282683134079 norm:0.00012928666546940804 max memory_allocated 29271.18798828125 
[2025-03-02 19:38:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.11628122627735138 norm:0.00012886062904726714 max memory_allocated 29271.18798828125 
[2025-03-02 19:39:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.11628497391939163 norm:0.00012969179078936577 max memory_allocated 29271.18798828125 
[2025-03-02 19:40:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.11627395451068878 norm:0.00012939912267029285 max memory_allocated 29271.18798828125 
[2025-03-02 19:40:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:41:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.13982757925987244 norm:0.0013639101525768638 max memory_allocated 29271.18798828125 
[2025-03-02 19:42:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.13735559582710266 norm:0.0007051931461319327 max memory_allocated 29271.18798828125 
[2025-03-02 19:42:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.13510024547576904 norm:0.0004532708553597331 max memory_allocated 29271.18798828125 
[2025-03-02 19:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.132822185754776 norm:0.0003181857173331082 max memory_allocated 29271.18798828125 
[2025-03-02 19:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.13181307911872864 norm:0.00023727747611701488 max memory_allocated 29271.18798828125 
[2025-03-02 19:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.1315441131591797 norm:0.0001976634666789323 max memory_allocated 29271.18798828125 
[2025-03-02 19:46:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.13141921162605286 norm:0.00017258636944461614 max memory_allocated 29271.18798828125 
[2025-03-02 19:47:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.1313658058643341 norm:0.00016210025933105499 max memory_allocated 29271.18798828125 
[2025-03-02 19:47:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.13130560517311096 norm:0.0001482595835113898 max memory_allocated 29271.18798828125 
[2025-03-02 19:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.13124807178974152 norm:0.00013900687918066978 max memory_allocated 29271.18798828125 
[2025-03-02 19:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.1312030404806137 norm:0.00013411836698651314 max memory_allocated 29271.18798828125 
[2025-03-02 19:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.13118648529052734 norm:0.00013284338638186455 max memory_allocated 29271.18798828125 
[2025-03-02 19:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.13117128610610962 norm:0.00013042092905379832 max memory_allocated 29271.18798828125 
[2025-03-02 19:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.13115888833999634 norm:0.00012916432751808316 max memory_allocated 29271.18798828125 
[2025-03-02 19:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.1311473697423935 norm:0.00012906374468002468 max memory_allocated 29271.18798828125 
[2025-03-02 19:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.13114222884178162 norm:0.00012790245818905532 max memory_allocated 29271.18798828125 
[2025-03-02 19:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.13112899661064148 norm:0.00012643101217690855 max memory_allocated 29271.18798828125 
[2025-03-02 19:55:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.13112607598304749 norm:0.0001256794494111091 max memory_allocated 29271.18798828125 
[2025-03-02 19:56:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.13111519813537598 norm:0.0001247269829036668 max memory_allocated 29271.18798828125 
[2025-03-02 19:57:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.1311080902814865 norm:0.0001253026130143553 max memory_allocated 29271.18798828125 
[2025-03-02 19:57:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.1569311022758484 norm:0.0009289117297157645 max memory_allocated 29271.18798828125 
[2025-03-02 19:59:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.1545097827911377 norm:0.0005028972518630326 max memory_allocated 29271.18798828125 
[2025-03-02 19:59:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.15213553607463837 norm:0.000336197845172137 max memory_allocated 29271.18798828125 
[2025-03-02 20:00:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.14977003633975983 norm:0.0002475936780683696 max memory_allocated 29271.18798828125 
[2025-03-02 20:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.14881959557533264 norm:0.00019911433628294617 max memory_allocated 29271.18798828125 
[2025-03-02 20:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.14854247868061066 norm:0.0001745302288327366 max memory_allocated 29271.18798828125 
[2025-03-02 20:03:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.14841455221176147 norm:0.00016188864537980407 max memory_allocated 29271.18798828125 
[2025-03-02 20:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.14834532141685486 norm:0.000150829364429228 max memory_allocated 29271.18798828125 
[2025-03-02 20:04:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.148280531167984 norm:0.0001425028603989631 max memory_allocated 29271.18798828125 
[2025-03-02 20:05:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.14821574091911316 norm:0.00013589310401584953 max memory_allocated 29271.18798828125 
[2025-03-02 20:06:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.14816255867481232 norm:0.00013244958245195448 max memory_allocated 29271.18798828125 
[2025-03-02 20:07:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.14813199639320374 norm:0.00013252970529720187 max memory_allocated 29271.18798828125 
[2025-03-02 20:08:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.14812079071998596 norm:0.00013241222768556327 max memory_allocated 29271.18798828125 
[2025-03-02 20:09:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.14811022579669952 norm:0.00013280918938107789 max memory_allocated 29271.18798828125 
[2025-03-02 20:09:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.1481078714132309 norm:0.00012841173156630248 max memory_allocated 29271.18798828125 
[2025-03-02 20:10:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.14809583127498627 norm:0.0001295882830163464 max memory_allocated 29271.18798828125 
[2025-03-02 20:11:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.14808525145053864 norm:0.00013172482431400567 max memory_allocated 29271.18798828125 
[2025-03-02 20:12:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.14808234572410583 norm:0.0001331671664956957 max memory_allocated 29271.18798828125 
[2025-03-02 20:13:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.1481013000011444 norm:0.000134641450131312 max memory_allocated 29271.18798828125 
[2025-03-02 20:14:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.1480807363986969 norm:0.00013213719648774713 max memory_allocated 29271.18798828125 
[2025-03-02 20:14:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:15:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.1747032254934311 norm:0.0010937569895759225 max memory_allocated 29271.75048828125 
[2025-03-02 20:16:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.17221206426620483 norm:0.00048061806592158973 max memory_allocated 29271.75048828125 
[2025-03-02 20:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.1697349101305008 norm:0.0003011550579685718 max memory_allocated 29271.75048828125 
[2025-03-02 20:17:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.16727076470851898 norm:0.00022159384388942271 max memory_allocated 29271.75048828125 
[2025-03-02 20:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.16642454266548157 norm:0.00017877186473924667 max memory_allocated 29271.75048828125 
[2025-03-02 20:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.1662132740020752 norm:0.00015885013272054493 max memory_allocated 29271.75048828125 
[2025-03-02 20:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.1661064475774765 norm:0.00014563875447493047 max memory_allocated 29271.75048828125 
[2025-03-02 20:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.16601568460464478 norm:0.0001374131243210286 max memory_allocated 29271.75048828125 
[2025-03-02 20:21:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.1659444272518158 norm:0.00013295249664224684 max memory_allocated 29271.75048828125 
[2025-03-02 20:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.16590389609336853 norm:0.00012843776494264603 max memory_allocated 29271.75048828125 
[2025-03-02 20:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.16588479280471802 norm:0.0001257628173334524 max memory_allocated 29271.75048828125 
[2025-03-02 20:24:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.16586637496948242 norm:0.0001269566419068724 max memory_allocated 29271.75048828125 
[2025-03-02 20:25:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.16587752103805542 norm:0.00012529206287581474 max memory_allocated 29271.75048828125 
[2025-03-02 20:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.16585859656333923 norm:0.00012586374941747636 max memory_allocated 29271.75048828125 
[2025-03-02 20:26:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.1658460795879364 norm:0.0001247131294803694 max memory_allocated 29271.75048828125 
[2025-03-02 20:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.1658189296722412 norm:0.0001244925515493378 max memory_allocated 29271.75048828125 
[2025-03-02 20:28:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.16581615805625916 norm:0.0001239089178852737 max memory_allocated 29271.75048828125 
[2025-03-02 20:29:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.16582192480564117 norm:0.0001244236482307315 max memory_allocated 29271.75048828125 
[2025-03-02 20:30:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.1658356636762619 norm:0.00012514698028098792 max memory_allocated 29271.75048828125 
[2025-03-02 20:31:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.1658356487751007 norm:0.0001258732081623748 max memory_allocated 29271.75048828125 
[2025-03-02 20:31:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.19582107663154602 norm:0.0008748280815780163 max memory_allocated 29271.93798828125 
[2025-03-02 20:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.19322286546230316 norm:0.000451204483397305 max memory_allocated 29271.93798828125 
[2025-03-02 20:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.19057287275791168 norm:0.0003098753222730011 max memory_allocated 29271.93798828125 
[2025-03-02 20:34:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.18785488605499268 norm:0.00023503892589360476 max memory_allocated 29271.93798828125 
[2025-03-02 20:35:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.18698656558990479 norm:0.00019839787273667753 max memory_allocated 29271.93798828125 
[2025-03-02 20:36:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.18670488893985748 norm:0.00017664942424744368 max memory_allocated 29271.93798828125 
[2025-03-02 20:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.18657247722148895 norm:0.00016639982641208917 max memory_allocated 29271.93798828125 
[2025-03-02 20:38:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.1864730417728424 norm:0.00015631785208825022 max memory_allocated 29271.93798828125 
[2025-03-02 20:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.18640786409378052 norm:0.00015052031085360795 max memory_allocated 29271.93798828125 
[2025-03-02 20:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.1863451600074768 norm:0.00014770907000638545 max memory_allocated 29271.93798828125 
[2025-03-02 20:40:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.18628624081611633 norm:0.0001463800435885787 max memory_allocated 29271.93798828125 
[2025-03-02 20:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.18624408543109894 norm:0.00014223650214262307 max memory_allocated 29271.93798828125 
[2025-03-02 20:42:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.18622161448001862 norm:0.00013946875697001815 max memory_allocated 29271.93798828125 
[2025-03-02 20:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.186216801404953 norm:0.00014307943638414145 max memory_allocated 29271.93798828125 
[2025-03-02 20:43:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.18623264133930206 norm:0.00014556004316546023 max memory_allocated 29271.93798828125 
[2025-03-02 20:44:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.1862066686153412 norm:0.00014236592687666416 max memory_allocated 29271.93798828125 
[2025-03-02 20:45:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.1862146556377411 norm:0.0001416523300576955 max memory_allocated 29271.93798828125 
[2025-03-02 20:46:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.18620793521404266 norm:0.00014499205281026661 max memory_allocated 29271.93798828125 
[2025-03-02 20:47:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.18619093298912048 norm:0.00014506174193229526 max memory_allocated 29271.93798828125 
[2025-03-02 20:48:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.1861894130706787 norm:0.0001450058480259031 max memory_allocated 29271.93798828125 
[2025-03-02 20:48:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.21803459525108337 norm:0.0011427775025367737 max memory_allocated 29271.93798828125 
[2025-03-02 20:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.215239018201828 norm:0.0006046696216799319 max memory_allocated 29271.93798828125 
[2025-03-02 20:50:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.2122589349746704 norm:0.00043268309673294425 max memory_allocated 29271.93798828125 
[2025-03-02 20:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.20938794314861298 norm:0.00037938012974336743 max memory_allocated 29271.93798828125 
[2025-03-02 20:52:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.20858393609523773 norm:0.00032203379669226706 max memory_allocated 29271.93798828125 
[2025-03-02 20:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.20836278796195984 norm:0.0002740846830420196 max memory_allocated 29271.93798828125 
[2025-03-02 20:54:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.2082238793373108 norm:0.0002499041147530079 max memory_allocated 29271.93798828125 
[2025-03-02 20:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.20813700556755066 norm:0.00024507916532456875 max memory_allocated 29271.93798828125 
[2025-03-02 20:55:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.2080674171447754 norm:0.00024367234436795115 max memory_allocated 29271.93798828125 
[2025-03-02 20:56:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.20805126428604126 norm:0.0002510429476387799 max memory_allocated 29271.93798828125 
[2025-03-02 20:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.2080293595790863 norm:0.00024603164638392627 max memory_allocated 29271.93798828125 
[2025-03-02 20:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.20800131559371948 norm:0.0002374540490563959 max memory_allocated 29271.93798828125 
[2025-03-02 20:59:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.20798438787460327 norm:0.00023346487432718277 max memory_allocated 29271.93798828125 
[2025-03-02 21:00:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.20796097815036774 norm:0.00023503396369051188 max memory_allocated 29271.93798828125 
[2025-03-02 21:00:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.2079571932554245 norm:0.0002447728475090116 max memory_allocated 29271.93798828125 
[2025-03-02 21:01:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.20798231661319733 norm:0.00024488382041454315 max memory_allocated 29271.93798828125 
[2025-03-02 21:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.20797356963157654 norm:0.00023732552654109895 max memory_allocated 29271.93798828125 
[2025-03-02 21:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.20795868337154388 norm:0.00023443088866770267 max memory_allocated 29271.93798828125 
[2025-03-02 21:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.20795458555221558 norm:0.00021842378191649914 max memory_allocated 29271.93798828125 
[2025-03-02 21:05:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.207966148853302 norm:0.00023623145534656942 max memory_allocated 29271.93798828125 
[2025-03-02 21:05:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 21:06:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.24024342000484467 norm:0.001666076947003603 max memory_allocated 29271.93798828125 
[2025-03-02 21:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.23717153072357178 norm:0.0008669376256875694 max memory_allocated 29271.93798828125 
[2025-03-02 21:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.233940988779068 norm:0.0005349558196030557 max memory_allocated 29271.93798828125 
[2025-03-02 21:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.2309180498123169 norm:0.00036137824645265937 max memory_allocated 29271.93798828125 
[2025-03-02 21:09:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.23014141619205475 norm:0.0002734513545874506 max memory_allocated 29271.93798828125 
[2025-03-02 21:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.22994156181812286 norm:0.0002244446222903207 max memory_allocated 29271.93798828125 
[2025-03-02 21:11:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.22984227538108826 norm:0.0001940445799846202 max memory_allocated 29271.93798828125 
[2025-03-02 21:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.22975990176200867 norm:0.0001742781896609813 max memory_allocated 29271.93798828125 
[2025-03-02 21:12:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.22972959280014038 norm:0.0001613082567928359 max memory_allocated 29271.93798828125 
[2025-03-02 21:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.22968874871730804 norm:0.00015219731722027063 max memory_allocated 29271.93798828125 
[2025-03-02 21:14:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.22965393960475922 norm:0.00014736535376869142 max memory_allocated 29271.93798828125 
[2025-03-02 21:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.229636088013649 norm:0.0001453028089599684 max memory_allocated 29271.93798828125 
[2025-03-02 21:16:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.2296198606491089 norm:0.0001396738807670772 max memory_allocated 29271.93798828125 
[2025-03-02 21:17:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.22959725558757782 norm:0.00013870389375369996 max memory_allocated 29271.93798828125 
[2025-03-02 21:17:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.22958022356033325 norm:0.0001360008172923699 max memory_allocated 29271.93798828125 
[2025-03-02 21:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.22957107424736023 norm:0.00013501272769644856 max memory_allocated 29271.93798828125 
[2025-03-02 21:19:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.22956836223602295 norm:0.0001362744951620698 max memory_allocated 29271.93798828125 
[2025-03-02 21:20:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.22955867648124695 norm:0.00013501453213393688 max memory_allocated 29271.93798828125 
[2025-03-02 21:21:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.2295556515455246 norm:0.00013545190449804068 max memory_allocated 29271.93798828125 
[2025-03-02 21:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.229549378156662 norm:0.00013514531019609421 max memory_allocated 29271.93798828125 
[2025-03-02 21:22:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.26500004529953003 norm:0.0015575295547023416 max memory_allocated 29272.50048828125 
[2025-03-02 21:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.26194196939468384 norm:0.0007882305071689188 max memory_allocated 29272.50048828125 
[2025-03-02 21:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.25844424962997437 norm:0.0004934978787787259 max memory_allocated 29272.50048828125 
[2025-03-02 21:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.2555001378059387 norm:0.00034555044840089977 max memory_allocated 29272.50048828125 
[2025-03-02 21:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.25478431582450867 norm:0.0002750235435087234 max memory_allocated 29272.50048828125 
[2025-03-02 21:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.25449591875076294 norm:0.0002323129738215357 max memory_allocated 29272.50048828125 
[2025-03-02 21:28:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.254373162984848 norm:0.00022044112847652286 max memory_allocated 29272.50048828125 
[2025-03-02 21:29:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.2542588412761688 norm:0.00020439694344531745 max memory_allocated 29272.50048828125 
[2025-03-02 21:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.2541535496711731 norm:0.0001903298107208684 max memory_allocated 29272.50048828125 
[2025-03-02 21:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.2540777325630188 norm:0.0001749681105138734 max memory_allocated 29272.50048828125 
[2025-03-02 21:31:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.25403690338134766 norm:0.00017160916468128562 max memory_allocated 29272.50048828125 
[2025-03-02 21:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.25400853157043457 norm:0.00016504732775501907 max memory_allocated 29272.50048828125 
[2025-03-02 21:33:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.25399625301361084 norm:0.0001648462493903935 max memory_allocated 29272.50048828125 
[2025-03-02 21:34:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.25397056341171265 norm:0.00016407275688834488 max memory_allocated 29272.50048828125 
[2025-03-02 21:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.2539447546005249 norm:0.00016253383364528418 max memory_allocated 29272.50048828125 
[2025-03-02 21:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.25394392013549805 norm:0.00016565716941840947 max memory_allocated 29272.50048828125 
[2025-03-02 21:36:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.2539210021495819 norm:0.00016786660125944763 max memory_allocated 29272.50048828125 
[2025-03-02 21:37:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.25392699241638184 norm:0.00017302189371548593 max memory_allocated 29272.50048828125 
[2025-03-02 21:38:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.2539111375808716 norm:0.0001704123424133286 max memory_allocated 29272.50048828125 
[2025-03-02 21:39:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.2539144456386566 norm:0.00017227094213012606 max memory_allocated 29272.50048828125 
[2025-03-02 21:39:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:40:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.29267802834510803 norm:0.0018783019622787833 max memory_allocated 29272.50048828125 
[2025-03-02 21:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.28883159160614014 norm:0.000916801393032074 max memory_allocated 29272.50048828125 
[2025-03-02 21:41:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.28477537631988525 norm:0.0005586943589150906 max memory_allocated 29272.50048828125 
[2025-03-02 21:42:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.28151509165763855 norm:0.0003794163349084556 max memory_allocated 29272.50048828125 
[2025-03-02 21:43:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.28084057569503784 norm:0.00029238572460599244 max memory_allocated 29272.50048828125 
[2025-03-02 21:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.28061383962631226 norm:0.0002445253194309771 max memory_allocated 29272.50048828125 
[2025-03-02 21:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.2804897129535675 norm:0.00021437997929751873 max memory_allocated 29272.50048828125 
[2025-03-02 21:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.2803977131843567 norm:0.00019625332788564265 max memory_allocated 29272.50048828125 
[2025-03-02 21:46:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.28035837411880493 norm:0.0001861841301433742 max memory_allocated 29272.50048828125 
[2025-03-02 21:47:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.2803175747394562 norm:0.00017527546151541173 max memory_allocated 29272.50048828125 
[2025-03-02 21:48:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.28028392791748047 norm:0.00016878292080946267 max memory_allocated 29272.50048828125 
[2025-03-02 21:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.28026413917541504 norm:0.0001685144379734993 max memory_allocated 29272.50048828125 
[2025-03-02 21:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.28024783730506897 norm:0.00016461261839140207 max memory_allocated 29272.50048828125 
[2025-03-02 21:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.2802281081676483 norm:0.00016354549734387547 max memory_allocated 29272.50048828125 
[2025-03-02 21:51:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.28022149205207825 norm:0.00016554219473619014 max memory_allocated 29272.50048828125 
[2025-03-02 21:52:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.28023383021354675 norm:0.00016837088332977146 max memory_allocated 29272.50048828125 
[2025-03-02 21:53:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.2801772654056549 norm:0.00017042257240973413 max memory_allocated 29272.50048828125 
[2025-03-02 21:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.28017476201057434 norm:0.0001665177842369303 max memory_allocated 29272.50048828125 
[2025-03-02 21:55:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.2801639139652252 norm:0.0001654198276810348 max memory_allocated 29272.50048828125 
[2025-03-02 21:56:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.2801550328731537 norm:0.0001683948648860678 max memory_allocated 29272.50048828125 
[2025-03-02 21:56:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.31852519512176514 norm:0.002281883032992482 max memory_allocated 29272.50048828125 
[2025-03-02 21:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.31510835886001587 norm:0.00115726119838655 max memory_allocated 29272.50048828125 
[2025-03-02 21:58:54 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.3111606240272522 norm:0.0007059043273329735 max memory_allocated 29272.50048828125 
[2025-03-02 21:59:45 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.30801454186439514 norm:0.00047150059253908694 max memory_allocated 29272.50048828125 
[2025-03-02 22:00:35 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.30733680725097656 norm:0.00035528140142560005 max memory_allocated 29272.50048828125 
[2025-03-02 22:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.30709320306777954 norm:0.0002927746973000467 max memory_allocated 29272.50048828125 
[2025-03-02 22:02:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.30695632100105286 norm:0.00024963830946944654 max memory_allocated 29272.50048828125 
[2025-03-02 22:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.30683985352516174 norm:0.0002226306969532743 max memory_allocated 29272.50048828125 
[2025-03-02 22:03:55 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.30678027868270874 norm:0.00020489798043854535 max memory_allocated 29272.50048828125 
[2025-03-02 22:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.30673450231552124 norm:0.00019389617955312133 max memory_allocated 29272.50048828125 
[2025-03-02 22:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.3066909909248352 norm:0.00018572297994978726 max memory_allocated 29272.50048828125 
[2025-03-02 22:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.306670218706131 norm:0.00017850057338364422 max memory_allocated 29272.50048828125 
[2025-03-02 22:07:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.3066546618938446 norm:0.00017428156570531428 max memory_allocated 29272.50048828125 
[2025-03-02 22:08:05 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.3066401779651642 norm:0.0001735592377372086 max memory_allocated 29272.50048828125 
[2025-03-02 22:08:55 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.30661705136299133 norm:0.00016791067901067436 max memory_allocated 29272.50048828125 
[2025-03-02 22:09:45 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.30660730600357056 norm:0.00016520223289262503 max memory_allocated 29272.50048828125 
[2025-03-02 22:10:35 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.30659201741218567 norm:0.00016553005843888968 max memory_allocated 29272.50048828125 
[2025-03-02 22:11:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.306591272354126 norm:0.0001644559670239687 max memory_allocated 29272.50048828125 
[2025-03-02 22:12:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.3065824508666992 norm:0.00016313299420289695 max memory_allocated 29272.50048828125 
[2025-03-02 22:13:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.3065754473209381 norm:0.00016366377531085163 max memory_allocated 29272.50048828125 
[2025-03-02 22:13:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:14:14 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.35092878341674805 norm:0.0012682239757850766 max memory_allocated 29273.06298828125 
[2025-03-02 22:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.3470454812049866 norm:0.0006874594837427139 max memory_allocated 29273.06298828125 
[2025-03-02 22:15:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.34242814779281616 norm:0.0004598704690579325 max memory_allocated 29273.06298828125 
[2025-03-02 22:16:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.3393329679965973 norm:0.0003352925123181194 max memory_allocated 29273.06298828125 
[2025-03-02 22:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.3387037515640259 norm:0.00027913966914638877 max memory_allocated 29273.06298828125 
[2025-03-02 22:18:24 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.33844178915023804 norm:0.00024972151732072234 max memory_allocated 29273.06298828125 
[2025-03-02 22:19:14 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.33826953172683716 norm:0.00022741542488802224 max memory_allocated 29273.06298828125 
[2025-03-02 22:20:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.3381326198577881 norm:0.00021656558965332806 max memory_allocated 29273.06298828125 
[2025-03-02 22:20:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.33801019191741943 norm:0.0002080569538520649 max memory_allocated 29273.06298828125 
[2025-03-02 22:21:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.33791983127593994 norm:0.00020263456099200994 max memory_allocated 29273.06298828125 
[2025-03-02 22:22:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.3378622531890869 norm:0.0002011775504797697 max memory_allocated 29273.06298828125 
[2025-03-02 22:23:24 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.3378300666809082 norm:0.00019435242575127631 max memory_allocated 29273.06298828125 
[2025-03-02 22:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.3378056287765503 norm:0.00019688578322529793 max memory_allocated 29273.06298828125 
[2025-03-02 22:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.3377843499183655 norm:0.00019834106205962598 max memory_allocated 29273.06298828125 
[2025-03-02 22:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.3377709984779358 norm:0.00019470573170110583 max memory_allocated 29273.06298828125 
[2025-03-02 22:26:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.33775851130485535 norm:0.00019425532082095742 max memory_allocated 29273.06298828125 
[2025-03-02 22:27:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.33775532245635986 norm:0.00019221661204937845 max memory_allocated 29273.06298828125 
[2025-03-02 22:28:24 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.3377491235733032 norm:0.00019203958800062537 max memory_allocated 29273.06298828125 
[2025-03-02 22:29:14 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.3377317786216736 norm:0.0001901071227621287 max memory_allocated 29273.06298828125 
[2025-03-02 22:30:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.3377430737018585 norm:0.0001918578054755926 max memory_allocated 29273.06298828125 
[2025-03-02 22:30:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.3895578384399414 norm:0.0016590626910328865 max memory_allocated 29273.25048828125 
[2025-03-02 22:32:03 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.38483619689941406 norm:0.0008403905667364597 max memory_allocated 29273.25048828125 
[2025-03-02 22:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.379428505897522 norm:0.0005351799190975726 max memory_allocated 29273.25048828125 
[2025-03-02 22:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.37622374296188354 norm:0.00038342445623129606 max memory_allocated 29273.25048828125 
[2025-03-02 22:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.37568235397338867 norm:0.0003106858057435602 max memory_allocated 29273.25048828125 
[2025-03-02 22:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.3754270076751709 norm:0.00027088087517768145 max memory_allocated 29273.25048828125 
[2025-03-02 22:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.37527817487716675 norm:0.0002481804694980383 max memory_allocated 29273.25048828125 
[2025-03-02 22:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.3751576244831085 norm:0.00023497242364101112 max memory_allocated 29273.25048828125 
[2025-03-02 22:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.3750529885292053 norm:0.00022598930809181184 max memory_allocated 29273.25048828125 
[2025-03-02 22:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.37497633695602417 norm:0.00021670997375622392 max memory_allocated 29273.25048828125 
[2025-03-02 22:39:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.3749208152294159 norm:0.000209862002520822 max memory_allocated 29273.25048828125 
[2025-03-02 22:40:24 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.37486734986305237 norm:0.00020759213657584041 max memory_allocated 29273.25048828125 
[2025-03-02 22:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.3748599886894226 norm:0.0002046670560957864 max memory_allocated 29273.25048828125 
[2025-03-02 22:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.37483707070350647 norm:0.00020444738038349897 max memory_allocated 29273.25048828125 
[2025-03-02 22:42:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.37479114532470703 norm:0.0002020207030000165 max memory_allocated 29273.25048828125 
[2025-03-02 22:43:44 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.3747701942920685 norm:0.00020386467804200947 max memory_allocated 29273.25048828125 
[2025-03-02 22:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.3747413158416748 norm:0.0002039797545876354 max memory_allocated 29273.25048828125 
[2025-03-02 22:45:24 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.37473419308662415 norm:0.00020669637888204306 max memory_allocated 29273.25048828125 
[2025-03-02 22:46:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.3747076988220215 norm:0.0002077987155644223 max memory_allocated 29273.25048828125 
[2025-03-02 22:47:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.37471166253089905 norm:0.00020940553804393858 max memory_allocated 29273.25048828125 
[2025-03-02 22:47:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:48:13 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.43085986375808716 norm:0.0031338133849203587 max memory_allocated 29273.25048828125 
[2025-03-02 22:49:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.42498669028282166 norm:0.0016719123814255 max memory_allocated 29273.25048828125 
[2025-03-02 22:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.4186975359916687 norm:0.0010425144573673606 max memory_allocated 29273.25048828125 
[2025-03-02 22:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.4154321253299713 norm:0.0007147752912715077 max memory_allocated 29273.25048828125 
[2025-03-02 22:51:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.4145934581756592 norm:0.0005525830201804638 max memory_allocated 29273.25048828125 
[2025-03-02 22:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.41406184434890747 norm:0.00045361468801274896 max memory_allocated 29273.25048828125 
[2025-03-02 22:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.4137207865715027 norm:0.00038556172512471676 max memory_allocated 29273.25048828125 
[2025-03-02 22:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.41350236535072327 norm:0.00033915037056431174 max memory_allocated 29273.25048828125 
[2025-03-02 22:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.4133542776107788 norm:0.000312864372972399 max memory_allocated 29273.25048828125 
[2025-03-02 22:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.41335824131965637 norm:0.00029307641671039164 max memory_allocated 29273.25048828125 
[2025-03-02 22:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.4133715331554413 norm:0.00028160595684312284 max memory_allocated 29273.25048828125 
[2025-03-02 22:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.41331493854522705 norm:0.00027593012782745063 max memory_allocated 29273.25048828125 
[2025-03-02 22:58:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.41324320435523987 norm:0.00026660633739084005 max memory_allocated 29273.25048828125 
[2025-03-02 22:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.41315966844558716 norm:0.000264690606854856 max memory_allocated 29273.25048828125 
[2025-03-02 22:59:54 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.4131380617618561 norm:0.0002609212533570826 max memory_allocated 29273.25048828125 
[2025-03-02 23:00:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.41310933232307434 norm:0.0002591065422166139 max memory_allocated 29273.25048828125 
[2025-03-02 23:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.41305553913116455 norm:0.00025732623180374503 max memory_allocated 29273.25048828125 
[2025-03-02 23:02:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.4130437970161438 norm:0.00025756374816410244 max memory_allocated 29273.25048828125 
[2025-03-02 23:03:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.4130241274833679 norm:0.00026003667153418064 max memory_allocated 29273.25048828125 
[2025-03-02 23:04:05 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.41298937797546387 norm:0.00025682244449853897 max memory_allocated 29273.25048828125 
[2025-03-02 23:04:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 23:04:23 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.4756166636943817 norm:0.007605064660310745 max memory_allocated 29273.25048828125 
[2025-03-02 23:06:04 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.4695057272911072 norm:0.006343527231365442 max memory_allocated 29273.25048828125 
[2025-03-02 23:06:54 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.4626581072807312 norm:0.00511590763926506 max memory_allocated 29273.25048828125 
[2025-03-02 23:07:44 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.45940104126930237 norm:0.004204372875392437 max memory_allocated 29273.25048828125 
[2025-03-02 23:08:34 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.45852839946746826 norm:0.0035100053064525127 max memory_allocated 29273.25048828125 
[2025-03-02 23:09:24 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.4579238295555115 norm:0.0030413763597607613 max memory_allocated 29273.25048828125 
[2025-03-02 23:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.4576214551925659 norm:0.0028090549167245626 max memory_allocated 29273.25048828125 
[2025-03-02 23:11:05 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.45744606852531433 norm:0.0026178588159382343 max memory_allocated 29273.25048828125 
[2025-03-02 23:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.45728960633277893 norm:0.0024334012996405363 max memory_allocated 29273.25048828125 
[2025-03-02 23:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.4571654498577118 norm:0.002604523440822959 max memory_allocated 29273.25048828125 
[2025-03-02 23:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.4569617509841919 norm:0.002424619859084487 max memory_allocated 29273.25048828125 
[2025-03-02 23:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.45683830976486206 norm:0.0024226706009358168 max memory_allocated 29273.25048828125 
[2025-03-02 23:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.45662498474121094 norm:0.002293922007083893 max memory_allocated 29273.25048828125 
[2025-03-02 23:16:06 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.45650941133499146 norm:0.002316249767318368 max memory_allocated 29273.25048828125 
[2025-03-02 23:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.4564661383628845 norm:0.002240855013951659 max memory_allocated 29273.25048828125 
[2025-03-02 23:17:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.4564497470855713 norm:0.002294081263244152 max memory_allocated 29273.25048828125 
[2025-03-02 23:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.45651349425315857 norm:0.0021620348561555147 max memory_allocated 29273.25048828125 
[2025-03-02 23:19:27 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.4564247131347656 norm:0.002194441156461835 max memory_allocated 29273.25048828125 
[2025-03-02 23:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.45642536878585815 norm:0.0020687594078481197 max memory_allocated 29273.25048828125 
[2025-03-02 23:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.4563530683517456 norm:0.0021221975330263376 max memory_allocated 29273.25048828125 
[2025-03-02 23:21:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:21:26 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:22:17 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.5407270789146423 norm:0.009461507201194763 max memory_allocated 29273.25048828125 
[2025-03-02 23:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.5307502746582031 norm:0.0061153145506978035 max memory_allocated 29273.25048828125 
[2025-03-02 23:23:57 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.5215853452682495 norm:0.0071242316626012325 max memory_allocated 29273.25048828125 
[2025-03-02 23:24:47 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.5174336433410645 norm:0.006512733176350594 max memory_allocated 29273.25048828125 
[2025-03-02 23:25:38 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.5163044333457947 norm:0.006181937642395496 max memory_allocated 29273.25048828125 
[2025-03-02 23:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.5157912969589233 norm:0.006073506083339453 max memory_allocated 29273.25048828125 
[2025-03-02 23:27:18 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.5154013633728027 norm:0.00579792307689786 max memory_allocated 29273.25048828125 
[2025-03-02 23:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.5149540305137634 norm:0.005263033322989941 max memory_allocated 29273.25048828125 
[2025-03-02 23:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.5147227048873901 norm:0.005033573601394892 max memory_allocated 29273.25048828125 
[2025-03-02 23:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.5145581960678101 norm:0.004994782619178295 max memory_allocated 29273.25048828125 
[2025-03-02 23:30:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.5143858790397644 norm:0.004862167406827211 max memory_allocated 29273.25048828125 
[2025-03-02 23:31:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.5143258571624756 norm:0.00458882050588727 max memory_allocated 29273.25048828125 
[2025-03-02 23:32:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.5142714977264404 norm:0.004370152018964291 max memory_allocated 29273.25048828125 
[2025-03-02 23:33:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.5143800973892212 norm:0.004188036546111107 max memory_allocated 29273.25048828125 
[2025-03-02 23:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.5145735144615173 norm:0.00425685616210103 max memory_allocated 29273.25048828125 
[2025-03-02 23:34:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.5145888328552246 norm:0.004214406944811344 max memory_allocated 29273.25048828125 
[2025-03-02 23:35:40 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.5145341157913208 norm:0.004126399289816618 max memory_allocated 29273.25048828125 
[2025-03-02 23:36:30 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.5144003629684448 norm:0.004051774274557829 max memory_allocated 29273.25048828125 
[2025-03-02 23:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.5144115686416626 norm:0.004037587903439999 max memory_allocated 29273.25048828125 
[2025-03-02 23:38:11 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.514359176158905 norm:0.0040618013590574265 max memory_allocated 29273.25048828125 
[2025-03-02 23:38:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:38:29 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:39:20 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.7197206020355225 norm:0.03768152743577957 max memory_allocated 29273.25048828125 
[2025-03-02 23:40:10 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.6863023638725281 norm:0.027785180136561394 max memory_allocated 29273.25048828125 
[2025-03-02 23:41:00 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.662212073802948 norm:0.021788397803902626 max memory_allocated 29273.25048828125 
[2025-03-02 23:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.6497001051902771 norm:0.018892941996455193 max memory_allocated 29273.25048828125 
[2025-03-02 23:42:40 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.6449896097183228 norm:0.01714864932000637 max memory_allocated 29273.25048828125 
[2025-03-02 23:43:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.6418006420135498 norm:0.014843253418803215 max memory_allocated 29273.25048828125 
[2025-03-02 23:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.6393767595291138 norm:0.013519695028662682 max memory_allocated 29273.25048828125 
[2025-03-02 23:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.6381303071975708 norm:0.013266760855913162 max memory_allocated 29273.25048828125 
[2025-03-02 23:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.6367995142936707 norm:0.012819400057196617 max memory_allocated 29273.25048828125 
[2025-03-02 23:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.6358394622802734 norm:0.011842614971101284 max memory_allocated 29273.25048828125 
[2025-03-02 23:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.6348126530647278 norm:0.011187629774212837 max memory_allocated 29273.25048828125 
[2025-03-02 23:48:32 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.6342290043830872 norm:0.011279634200036526 max memory_allocated 29273.25048828125 
[2025-03-02 23:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.6337543725967407 norm:0.010375508107244968 max memory_allocated 29273.25048828125 
[2025-03-02 23:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.633034884929657 norm:0.009986378252506256 max memory_allocated 29273.25048828125 
[2025-03-02 23:51:03 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.6324884295463562 norm:0.009755932725965977 max memory_allocated 29273.25048828125 
[2025-03-02 23:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.6323884129524231 norm:0.009561275132000446 max memory_allocated 29273.25048828125 
[2025-03-02 23:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.6317786574363708 norm:0.009144618175923824 max memory_allocated 29273.25048828125 
[2025-03-02 23:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.6318174004554749 norm:0.009226115420460701 max memory_allocated 29273.25048828125 
[2025-03-02 23:54:24 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.6318337917327881 norm:0.009055621922016144 max memory_allocated 29273.25048828125 
[2025-03-02 23:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.6317622065544128 norm:0.009217843413352966 max memory_allocated 29273.25048828125 
[2025-03-02 23:55:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:55:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:1.20110285282135 norm:0.06088922545313835 max memory_allocated 29273.25048828125 
[2025-03-02 23:57:13 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:1.1363108158111572 norm:0.04059408977627754 max memory_allocated 29273.25048828125 
[2025-03-02 23:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:1.1026660203933716 norm:0.03270192816853523 max memory_allocated 29273.25048828125 
[2025-03-02 23:58:53 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:1.081197738647461 norm:0.03001224622130394 max memory_allocated 29273.25048828125 
[2025-03-02 23:59:43 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:1.0689173936843872 norm:0.028816422447562218 max memory_allocated 29273.25048828125 
[2025-03-03 00:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:1.0625721216201782 norm:0.03105318360030651 max memory_allocated 29273.25048828125 
[2025-03-03 00:01:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:1.057629942893982 norm:0.03105272725224495 max memory_allocated 29273.25048828125 
[2025-03-03 00:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:1.0539541244506836 norm:0.0297512449324131 max memory_allocated 29273.25048828125 
[2025-03-03 00:03:04 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:1.0512688159942627 norm:0.02990664169192314 max memory_allocated 29273.25048828125 
[2025-03-03 00:03:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:1.0481246709823608 norm:0.027184678241610527 max memory_allocated 29273.25048828125 
[2025-03-03 00:04:44 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:1.0455485582351685 norm:0.02678949572145939 max memory_allocated 29273.25048828125 
[2025-03-03 00:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:1.0425695180892944 norm:0.02571777068078518 max memory_allocated 29273.25048828125 
[2025-03-03 00:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:1.0406557321548462 norm:0.025204788893461227 max memory_allocated 29273.25048828125 
[2025-03-03 00:07:15 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:1.0403478145599365 norm:0.02439013496041298 max memory_allocated 29273.25048828125 
[2025-03-03 00:08:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:1.0370783805847168 norm:0.023206371814012527 max memory_allocated 29273.25048828125 
[2025-03-03 00:08:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:1.0369867086410522 norm:0.02442515268921852 max memory_allocated 29273.25048828125 
[2025-03-03 00:09:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:1.0372107028961182 norm:0.024247346445918083 max memory_allocated 29273.25048828125 
[2025-03-03 00:10:36 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:1.036429762840271 norm:0.02686414122581482 max memory_allocated 29273.25048828125 
[2025-03-03 00:11:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:1.0348906517028809 norm:0.023038286715745926 max memory_allocated 29273.25048828125 
[2025-03-03 00:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:1.034433126449585 norm:0.024807294830679893 max memory_allocated 29273.25048828125 
[2025-03-03 00:12:31 root] (main_calib_config2.py 372): INFO 40801.089908123016
[2025-03-03 00:12:41 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:14:40 root] (main_calib_config2.py 159): INFO wikitext2 : 5.230647563934326
[2025-03-03 00:14:40 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:17:42 root] (main_calib_config2.py 159): INFO c4 : 6.7900495529174805
[2025-03-03 02:17:07 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.230647563934326, 'c4': 6.7900495529174805, 'results': {'arc_easy': {'acc': 0.7264309764309764, 'acc_stderr': 0.009147424438490736, 'acc_norm': 0.5787037037037037, 'acc_norm_stderr': 0.010131882498193126}, 'arc_challenge': {'acc': 0.4206484641638225, 'acc_stderr': 0.014426211252508401, 'acc_norm': 0.4300341296928328, 'acc_norm_stderr': 0.014467631559137994}, 'winogrande': {'acc': 0.6874506708760852, 'acc_stderr': 0.013027563620748838}, 'hellaswag': {'acc': 0.581557458673571, 'acc_stderr': 0.004922953651577684, 'acc_norm': 0.7543318064130651, 'acc_norm_stderr': 0.004296028885089461}, 'boolq': {'acc': 0.6844036697247706, 'acc_stderr': 0.0081285798587859}, 'piqa': {'acc': 0.7818280739934712, 'acc_stderr': 0.009636081958374381, 'acc_norm': 0.7840043525571273, 'acc_norm_stderr': 0.009601236303553544}}, 'versions': {'arc_easy': 0, 'arc_challenge': 0, 'winogrande': 0, 'hellaswag': 0, 'boolq': 1, 'piqa': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
