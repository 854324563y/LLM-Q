[2025-03-02 12:48:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.35', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.35.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.35.pkl
[2025-03-02 12:52:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.05319688469171524 norm:0.025971511378884315 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.03864812105894089 norm:0.01609867438673973 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.03230295330286026 norm:0.012822638265788555 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.03030235879123211 norm:0.010676741600036621 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.029256226494908333 norm:0.008593730628490448 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.028614455834031105 norm:0.007318685296922922 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.028235645964741707 norm:0.006197751499712467 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.027920491993427277 norm:0.005342856980860233 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.02769475057721138 norm:0.004621883854269981 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.027668513357639313 norm:0.004685895051807165 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.027577882632613182 norm:0.0038588426541537046 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.027446286752820015 norm:0.0034789112396538258 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.02744138613343239 norm:0.003430478274822235 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.027337508276104927 norm:0.003359252354130149 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.02740335837006569 norm:0.0033766243141144514 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:50 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.027282612398266792 norm:0.003146962495520711 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.027273910120129585 norm:0.003062825882807374 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.027223333716392517 norm:0.0030856074299663305 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.027254661545157433 norm:0.003107640892267227 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.027230428531765938 norm:0.0029444298706948757 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:28 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.11667660623788834 norm:0.03464319929480553 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.08548425137996674 norm:0.016878582537174225 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.07470294833183289 norm:0.011561988852918148 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.07096698880195618 norm:0.009635044261813164 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.06926960498094559 norm:0.008387268520891666 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.06811198592185974 norm:0.007468570955097675 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.06728316098451614 norm:0.006559144239872694 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.06667807698249817 norm:0.005729549564421177 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.06617172807455063 norm:0.005027793347835541 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.06580962240695953 norm:0.00441597169265151 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.0655348151922226 norm:0.00391461281105876 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:24 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.06531625241041183 norm:0.0035972169134765863 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.06515604257583618 norm:0.003491286188364029 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.06505237519741058 norm:0.003459283849224448 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.06504958868026733 norm:0.003508314723148942 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:42 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.06506073474884033 norm:0.003237576689571142 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.0648362785577774 norm:0.0031612669117748737 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.06483225524425507 norm:0.0029954230412840843 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.06475771963596344 norm:0.0031010292004793882 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.06482488662004471 norm:0.0029232988599687815 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:19 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:27:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.20017297565937042 norm:0.03079509548842907 max memory_allocated 29268.02001953125 
[2025-03-02 13:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.1719413697719574 norm:0.022012043744325638 max memory_allocated 29268.02001953125 
[2025-03-02 13:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.15186235308647156 norm:0.014403872191905975 max memory_allocated 29268.02001953125 
[2025-03-02 13:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.14184968173503876 norm:0.011862434446811676 max memory_allocated 29268.02001953125 
[2025-03-02 13:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.1380675584077835 norm:0.010854202322661877 max memory_allocated 29268.02001953125 
[2025-03-02 13:31:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.13438446819782257 norm:0.009673355147242546 max memory_allocated 29268.02001953125 
[2025-03-02 13:32:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.1324821412563324 norm:0.009909526444971561 max memory_allocated 29268.02001953125 
[2025-03-02 13:32:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.13009467720985413 norm:0.010258246213197708 max memory_allocated 29268.02001953125 
[2025-03-02 13:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.12910884618759155 norm:0.00960603915154934 max memory_allocated 29268.02001953125 
[2025-03-02 13:34:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.12837804853916168 norm:0.010033356957137585 max memory_allocated 29268.02001953125 
[2025-03-02 13:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.12678149342536926 norm:0.010284577496349812 max memory_allocated 29268.02001953125 
[2025-03-02 13:36:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.12660926580429077 norm:0.009647205471992493 max memory_allocated 29268.02001953125 
[2025-03-02 13:37:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.1253739446401596 norm:0.009624602273106575 max memory_allocated 29268.02001953125 
[2025-03-02 13:37:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.12488052248954773 norm:0.009434016421437263 max memory_allocated 29268.02001953125 
[2025-03-02 13:38:45 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.12458069622516632 norm:0.00948757492005825 max memory_allocated 29268.02001953125 
[2025-03-02 13:39:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.12433312833309174 norm:0.009543420746922493 max memory_allocated 29268.02001953125 
[2025-03-02 13:40:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.12458691000938416 norm:0.008837581612169743 max memory_allocated 29268.02001953125 
[2025-03-02 13:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.12291033565998077 norm:0.008734984323382378 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.12398301064968109 norm:0.008395671844482422 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.1246904656291008 norm:0.009104078635573387 max memory_allocated 29268.02001953125 
[2025-03-02 13:43:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:44:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.194413423538208 norm:0.009472772479057312 max memory_allocated 29268.43798828125 
[2025-03-02 13:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.17057238519191742 norm:0.0041296761482954025 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:40 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.15630368888378143 norm:0.002532023936510086 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.15100619196891785 norm:0.0017395790200680494 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.14818067848682404 norm:0.0013312898809090257 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.1462479829788208 norm:0.001175039797089994 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.14491035044193268 norm:0.0010937913320958614 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.14392471313476562 norm:0.0010356499115005136 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:37 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.14326176047325134 norm:0.001012451946735382 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.1427919715642929 norm:0.0009891969384625554 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.14233896136283875 norm:0.0009811606723815203 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.1420360803604126 norm:0.0009896806441247463 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.14184176921844482 norm:0.0009931782260537148 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.14155606925487518 norm:0.0009333592606708407 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.1413920670747757 norm:0.0009456505649723113 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.14122730493545532 norm:0.0009725160198286176 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.14111045002937317 norm:0.0009969458915293217 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.14099234342575073 norm:0.001005538972094655 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.14091302454471588 norm:0.0009833400836214423 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.1408696472644806 norm:0.0010360127780586481 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.23808653652668 norm:0.020487552508711815 max memory_allocated 29268.62548828125 
[2025-03-02 14:01:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.21053200960159302 norm:0.005611761007457972 max memory_allocated 29268.62548828125 
[2025-03-02 14:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.19299732148647308 norm:0.0032143837306648493 max memory_allocated 29268.62548828125 
[2025-03-02 14:03:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.18695057928562164 norm:0.0023545785807073116 max memory_allocated 29268.62548828125 
[2025-03-02 14:04:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.18343588709831238 norm:0.0018021733267232776 max memory_allocated 29268.62548828125 
[2025-03-02 14:04:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.18101544678211212 norm:0.0015198306646198034 max memory_allocated 29268.62548828125 
[2025-03-02 14:05:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.17932406067848206 norm:0.0014089837204664946 max memory_allocated 29268.62548828125 
[2025-03-02 14:06:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.1781807392835617 norm:0.001345871714875102 max memory_allocated 29268.62548828125 
[2025-03-02 14:07:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.17736396193504333 norm:0.0012419424019753933 max memory_allocated 29268.62548828125 
[2025-03-02 14:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.17681586742401123 norm:0.001179058337584138 max memory_allocated 29268.62548828125 
[2025-03-02 14:09:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.1763819456100464 norm:0.001161815831437707 max memory_allocated 29268.62548828125 
[2025-03-02 14:09:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.176036536693573 norm:0.001167386770248413 max memory_allocated 29268.62548828125 
[2025-03-02 14:10:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.17577652633190155 norm:0.0011543820146471262 max memory_allocated 29268.62548828125 
[2025-03-02 14:11:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.17551346123218536 norm:0.0010307321790605783 max memory_allocated 29268.62548828125 
[2025-03-02 14:12:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.1753307580947876 norm:0.0010397008154541254 max memory_allocated 29268.62548828125 
[2025-03-02 14:13:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.1751541793346405 norm:0.0010421781335026026 max memory_allocated 29268.62548828125 
[2025-03-02 14:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.17500263452529907 norm:0.0010869466932490468 max memory_allocated 29268.62548828125 
[2025-03-02 14:14:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.1749282032251358 norm:0.00112171471118927 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.1748371571302414 norm:0.0011195779079571366 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.17475232481956482 norm:0.001204483793117106 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:17:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.26901257038116455 norm:0.013962524011731148 max memory_allocated 29268.81298828125 
[2025-03-02 14:18:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.23793332278728485 norm:0.005160780157893896 max memory_allocated 29268.81298828125 
[2025-03-02 14:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.21933601796627045 norm:0.0027600035537034273 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.21204163134098053 norm:0.0019310263451188803 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.20824450254440308 norm:0.001526742009446025 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.20561543107032776 norm:0.0013170157326385379 max memory_allocated 29268.81298828125 
[2025-03-02 14:22:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.20378939807415009 norm:0.0012004546588286757 max memory_allocated 29268.81298828125 
[2025-03-02 14:23:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.20243433117866516 norm:0.0011219509178772569 max memory_allocated 29268.81298828125 
[2025-03-02 14:24:17 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.20148375630378723 norm:0.0011322182836011052 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.20079565048217773 norm:0.001138422405347228 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.2003287971019745 norm:0.0011325206141918898 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.19990533590316772 norm:0.0011495548533275723 max memory_allocated 29268.81298828125 
[2025-03-02 14:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.19957251846790314 norm:0.0011394137982279062 max memory_allocated 29268.81298828125 
[2025-03-02 14:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.19925132393836975 norm:0.0011201021261513233 max memory_allocated 29268.81298828125 
[2025-03-02 14:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.1990291029214859 norm:0.0010832857806235552 max memory_allocated 29268.81298828125 
[2025-03-02 14:30:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.19888371229171753 norm:0.0011123779695481062 max memory_allocated 29268.81298828125 
[2025-03-02 14:30:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.19874191284179688 norm:0.0010582125978544354 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.19860056042671204 norm:0.0010659208055585623 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.1984972506761551 norm:0.001078436616808176 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.19834890961647034 norm:0.0010505685349926353 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.33381810784339905 norm:0.009888796135783195 max memory_allocated 29269.00048828125 
[2025-03-02 14:35:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.30475425720214844 norm:0.0055634635500609875 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.2838766574859619 norm:0.0040317438542842865 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.27471089363098145 norm:0.00324610760435462 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.269681841135025 norm:0.002853918122127652 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.26439186930656433 norm:0.002443355740979314 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.2619625926017761 norm:0.002447623759508133 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.2611411511898041 norm:0.003063394920900464 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.25786906480789185 norm:0.002243107883259654 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.2567940354347229 norm:0.002271006116643548 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.25598394870758057 norm:0.0021747183054685593 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.25508037209510803 norm:0.00216849846765399 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.2546805441379547 norm:0.0022688014432787895 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.2545467019081116 norm:0.0023407081607729197 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.2544008791446686 norm:0.0023438967764377594 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.25412648916244507 norm:0.0023684490006417036 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.2540353536605835 norm:0.0024054048117250204 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.25339826941490173 norm:0.0022422969341278076 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.25331419706344604 norm:0.0024024841841310263 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.2530449330806732 norm:0.0024460235144943 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:51:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.3243943154811859 norm:0.008907802402973175 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.30063310265541077 norm:0.003859147895127535 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:00 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.2840310037136078 norm:0.0021062425803393126 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.27715831995010376 norm:0.0014102597488090396 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.273505300283432 norm:0.00110367382876575 max memory_allocated 29269.18798828125 
[2025-03-02 14:55:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.27118945121765137 norm:0.0009474573307670653 max memory_allocated 29269.18798828125 
[2025-03-02 14:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.2695435881614685 norm:0.0008882362744770944 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.2683807611465454 norm:0.0008501819102093577 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.26756343245506287 norm:0.000836562248878181 max memory_allocated 29269.18798828125 
[2025-03-02 14:58:47 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.266944020986557 norm:0.0008276210282929242 max memory_allocated 29269.18798828125 
[2025-03-02 14:59:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.26646071672439575 norm:0.0008181512239389122 max memory_allocated 29269.18798828125 
[2025-03-02 15:00:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.2661014795303345 norm:0.0008242594776675105 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.26590824127197266 norm:0.0008357991464436054 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.2656840682029724 norm:0.0008298945613205433 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.26549232006073 norm:0.0008380388026125729 max memory_allocated 29269.18798828125 
[2025-03-02 15:03:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.2653501331806183 norm:0.0008364340756088495 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.26521211862564087 norm:0.0008417683420702815 max memory_allocated 29269.18798828125 
[2025-03-02 15:05:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.26510682702064514 norm:0.0008503573480993509 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.26497647166252136 norm:0.000846522394567728 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.2649228870868683 norm:0.0008519301773048937 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:08:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.32324689626693726 norm:0.012747167609632015 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.29366713762283325 norm:0.007621102966368198 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.2631460428237915 norm:0.0025003431364893913 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.25373202562332153 norm:0.0013138229260221124 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.25000572204589844 norm:0.0010381944011896849 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.24782603979110718 norm:0.000879789178725332 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.24635374546051025 norm:0.0007972766761668026 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.24549278616905212 norm:0.0007580386591143906 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.24504299461841583 norm:0.0007166387513279915 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.24480190873146057 norm:0.0007032277644611895 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.24461767077445984 norm:0.0006838753470219672 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.24449501931667328 norm:0.0006754631758667529 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.24432304501533508 norm:0.0006601534551009536 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.24419155716896057 norm:0.000648059300146997 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.24414405226707458 norm:0.0006347257294692099 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.24420462548732758 norm:0.000635410426184535 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.24422761797904968 norm:0.0006275015184655786 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.2440398633480072 norm:0.0005879171658307314 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.24400374293327332 norm:0.0005950005725026131 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.24399597942829132 norm:0.0006265583215281367 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.3381873369216919 norm:0.01544493343681097 max memory_allocated 29269.56298828125 
[2025-03-02 15:25:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.2976057827472687 norm:0.0073107583448290825 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.26473987102508545 norm:0.0025179716758430004 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.25518956780433655 norm:0.0012653747107833624 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.25162896513938904 norm:0.0009475534316152334 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.249474436044693 norm:0.0008244728087447584 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.24815461039543152 norm:0.0007476264727301896 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.24729430675506592 norm:0.000705939601175487 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.24678023159503937 norm:0.0006903366302140057 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.2464759349822998 norm:0.0006780650001019239 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.24630703032016754 norm:0.0006657784688286483 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.2461724877357483 norm:0.000656663381960243 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.24613015353679657 norm:0.0006625918904319406 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.2460552453994751 norm:0.0006649271817877889 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.2459029108285904 norm:0.0006490845116786659 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.24579893052577972 norm:0.000628591631539166 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.2457275092601776 norm:0.000617748184595257 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.24571830034255981 norm:0.0006153475842438638 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.24549680948257446 norm:0.0005987504264339805 max memory_allocated 29269.56298828125 
[2025-03-02 15:40:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.24551093578338623 norm:0.0005804726970382035 max memory_allocated 29269.56298828125 
[2025-03-02 15:41:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.3242635726928711 norm:0.013776159845292568 max memory_allocated 29269.75048828125 
[2025-03-02 15:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.2956896424293518 norm:0.007201061118394136 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.2677426040172577 norm:0.0028879065066576004 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.2585339844226837 norm:0.001512529095634818 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.2553824484348297 norm:0.0011887027649208903 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.2534153163433075 norm:0.0010085345711559057 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.2521675229072571 norm:0.0008831839077174664 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.25147202610969543 norm:0.0008431410533376038 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.2508566677570343 norm:0.0007736734114587307 max memory_allocated 29269.75048828125 
[2025-03-02 15:49:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.2504843771457672 norm:0.0007658482063561678 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.24999041855335236 norm:0.0006881963927298784 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.2499704360961914 norm:0.0006795177469030023 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.24990899860858917 norm:0.0006665906403213739 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.2497846484184265 norm:0.0006350309704430401 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.24982018768787384 norm:0.0006402223370969296 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.24984078109264374 norm:0.0006361989071592689 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.249852254986763 norm:0.0006242796662263572 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.24987132847309113 norm:0.000612099829595536 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.2498863935470581 norm:0.0006036083213984966 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.2498159557580948 norm:0.0005726123927161098 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.32795530557632446 norm:0.008756594732403755 max memory_allocated 29269.93798828125 
[2025-03-02 15:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.30363184213638306 norm:0.005559741985052824 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.2756170928478241 norm:0.0024294834583997726 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:18 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.2651088535785675 norm:0.001097685657441616 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.26159724593162537 norm:0.0008328896947205067 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.25963062047958374 norm:0.0007216271478682756 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.25859302282333374 norm:0.0006454386166296899 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.25798290967941284 norm:0.0006172190187498927 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.25759267807006836 norm:0.0005979565903544426 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.2574737071990967 norm:0.0005947904428467155 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.25733596086502075 norm:0.0005919511895626783 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.2572433054447174 norm:0.0005786286783404648 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.25717538595199585 norm:0.0005826317938044667 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.25717929005622864 norm:0.0005957616958767176 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.25729045271873474 norm:0.0006018071435391903 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.2572871446609497 norm:0.0006022118031978607 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.2572448253631592 norm:0.0005742038483731449 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.2570232152938843 norm:0.0005399133078753948 max memory_allocated 29269.93798828125 
[2025-03-02 16:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.25702694058418274 norm:0.0005338868941180408 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.2570793032646179 norm:0.0005332108703441918 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:15:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.3299838602542877 norm:0.008549435995519161 max memory_allocated 29270.12548828125 
[2025-03-02 16:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.302065372467041 norm:0.00440034456551075 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.2789909243583679 norm:0.0019205947173759341 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.2706069052219391 norm:0.0010478065814822912 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.26724952459335327 norm:0.0008275287691503763 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.26522713899612427 norm:0.0007343565230257809 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.26402759552001953 norm:0.0006838685367256403 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.26332518458366394 norm:0.000658066535834223 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.262788861989975 norm:0.0006259953370317817 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.262384295463562 norm:0.0005902203847654164 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.26221713423728943 norm:0.0005689217941835523 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.26220420002937317 norm:0.0005557817639783025 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.26202189922332764 norm:0.0005351312574930489 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.2617669403553009 norm:0.0005187541828490794 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.2616826295852661 norm:0.0005040027899667621 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.26165395975112915 norm:0.0004993732436560094 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.2616301476955414 norm:0.000495045620482415 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.2616250216960907 norm:0.0005032324697822332 max memory_allocated 29270.12548828125 
[2025-03-02 16:30:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.2616674602031708 norm:0.0005041618132963777 max memory_allocated 29270.12548828125 
[2025-03-02 16:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.261658638715744 norm:0.0005085350712761283 max memory_allocated 29270.12548828125 
[2025-03-02 16:31:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:32:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.3212122321128845 norm:0.007119441404938698 max memory_allocated 29270.31298828125 
[2025-03-02 16:33:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.30004578828811646 norm:0.004037788603454828 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.281965970993042 norm:0.0021468219347298145 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.2738877832889557 norm:0.0012984703062102199 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.2698931396007538 norm:0.0009004312450997531 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.2677758038043976 norm:0.0007617420051246881 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.2666904926300049 norm:0.0007174293277785182 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.265933632850647 norm:0.0006540254107676446 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.26543620228767395 norm:0.0006169620319269598 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.26520663499832153 norm:0.000600786239374429 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.26475611329078674 norm:0.0005542041035369039 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.2647334933280945 norm:0.0005553161026909947 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.2646458148956299 norm:0.0005446675349958241 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.2645072042942047 norm:0.0005235783755779266 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.26444581151008606 norm:0.000526501564309001 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.26451095938682556 norm:0.0005386876291595399 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.2647056579589844 norm:0.000563213718123734 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.2647196054458618 norm:0.0005566134350374341 max memory_allocated 29270.31298828125 
[2025-03-02 16:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.2644316852092743 norm:0.0005160198779776692 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.26418328285217285 norm:0.0005044803256168962 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.3074478507041931 norm:0.003746874164789915 max memory_allocated 29270.50048828125 
[2025-03-02 16:50:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.2910086512565613 norm:0.0018175430595874786 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.2793826460838318 norm:0.0010612665209919214 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.27491798996925354 norm:0.0007189991883933544 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.27241432666778564 norm:0.0005698380991816521 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:36 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.2709530293941498 norm:0.000492040126118809 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.2701300382614136 norm:0.0004437437164597213 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.26959019899368286 norm:0.0004115603805985302 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.2692566215991974 norm:0.0003930246166419238 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.26907220482826233 norm:0.0003795620577875525 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.26892903447151184 norm:0.0003715716302394867 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.2687992751598358 norm:0.0003668751160148531 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.26873043179512024 norm:0.0003637811460066587 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.2686140537261963 norm:0.00036057524266652763 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.2685416042804718 norm:0.00035638545523397624 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.2685316801071167 norm:0.00035250530345365405 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.26851439476013184 norm:0.00034811702789738774 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.26850253343582153 norm:0.0003501670144032687 max memory_allocated 29270.50048828125 
[2025-03-02 17:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.26846978068351746 norm:0.00035210486385039985 max memory_allocated 29270.50048828125 
[2025-03-02 17:05:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.2685014009475708 norm:0.0003513247356750071 max memory_allocated 29270.50048828125 
[2025-03-02 17:05:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:06:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.35125917196273804 norm:0.019656168296933174 max memory_allocated 29270.68798828125 
[2025-03-02 17:07:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.331704705953598 norm:0.012228582985699177 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.3040536940097809 norm:0.005147337913513184 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.29408004879951477 norm:0.0027174788992851973 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.2902509868144989 norm:0.0019113420275971293 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.2880815863609314 norm:0.0015421450370922685 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:19 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.28662848472595215 norm:0.001331810373812914 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.2857173681259155 norm:0.0012031671358272433 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.2851237952709198 norm:0.001126970979385078 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.2847781181335449 norm:0.0010837165173143148 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.2845402956008911 norm:0.0010575195774435997 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.28444617986679077 norm:0.0010637291707098484 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.28463369607925415 norm:0.00108706159517169 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.28461015224456787 norm:0.0010576534550637007 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.2842481732368469 norm:0.0009520429885014892 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.2840995490550995 norm:0.0008961972780525684 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.28403037786483765 norm:0.0008574686944484711 max memory_allocated 29270.68798828125 
[2025-03-02 17:20:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.2839062809944153 norm:0.0008379895007237792 max memory_allocated 29270.68798828125 
[2025-03-02 17:21:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.2837809920310974 norm:0.000788937381003052 max memory_allocated 29270.68798828125 
[2025-03-02 17:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.2835995554924011 norm:0.000769072852563113 max memory_allocated 29270.68798828125 
[2025-03-02 17:22:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:23:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.323894739151001 norm:0.0037586865946650505 max memory_allocated 29270.87548828125 
[2025-03-02 17:24:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.31236740946769714 norm:0.0019297313410788774 max memory_allocated 29270.87548828125 
[2025-03-02 17:24:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.3035259246826172 norm:0.0011932130437344313 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.29980969429016113 norm:0.0008468313026241958 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.29773372411727905 norm:0.0006723609985783696 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.2963366210460663 norm:0.0005791453877463937 max memory_allocated 29270.87548828125 
[2025-03-02 17:28:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.2956215739250183 norm:0.0005135781830176711 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.29516780376434326 norm:0.00046650716103613377 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.29495328664779663 norm:0.000438876508269459 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.2948600947856903 norm:0.00042753067100420594 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.2947008013725281 norm:0.00040938545134849846 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.2945789098739624 norm:0.0003977014566771686 max memory_allocated 29270.87548828125 
[2025-03-02 17:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.29450711607933044 norm:0.0003923700423911214 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.29447007179260254 norm:0.00038494716864079237 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.29434454441070557 norm:0.00037619564682245255 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.29430311918258667 norm:0.0003731166943907738 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.2943075895309448 norm:0.00037255999632179737 max memory_allocated 29270.87548828125 
[2025-03-02 17:37:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.294285386800766 norm:0.0003719906962942332 max memory_allocated 29270.87548828125 
[2025-03-02 17:38:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.29419249296188354 norm:0.00036207304219715297 max memory_allocated 29270.87548828125 
[2025-03-02 17:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.2941271662712097 norm:0.00036255287704989314 max memory_allocated 29270.87548828125 
[2025-03-02 17:39:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:40:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.3669055998325348 norm:0.009426388889551163 max memory_allocated 29271.06298828125 
[2025-03-02 17:40:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.3464587330818176 norm:0.0051406389102339745 max memory_allocated 29271.06298828125 
[2025-03-02 17:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.3286963999271393 norm:0.0028150894213467836 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.3211537003517151 norm:0.0016640375833958387 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.31827545166015625 norm:0.0012904972536489367 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.3165375292301178 norm:0.0010528289712965488 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.31522896885871887 norm:0.0008813497261144221 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.3145803213119507 norm:0.000795588013716042 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.3141406774520874 norm:0.0007335309637710452 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.31394708156585693 norm:0.0007011370616964996 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.3139802813529968 norm:0.0006884936592541635 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:13 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.31381240487098694 norm:0.0006653466261923313 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.31360486149787903 norm:0.0006298283115029335 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.3135228455066681 norm:0.0006196674075908959 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.3135625123977661 norm:0.0006292426260188222 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.31352734565734863 norm:0.0006098359590396285 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.3135743737220764 norm:0.0006190614076331258 max memory_allocated 29271.06298828125 
[2025-03-02 17:54:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.3132229149341583 norm:0.0005617783172056079 max memory_allocated 29271.06298828125 
[2025-03-02 17:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.313140332698822 norm:0.0005516072851605713 max memory_allocated 29271.06298828125 
[2025-03-02 17:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.3132033944129944 norm:0.0005469562602229416 max memory_allocated 29271.06298828125 
[2025-03-02 17:56:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.37078261375427246 norm:0.004435411654412746 max memory_allocated 29271.25048828125 
[2025-03-02 17:57:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.3572000563144684 norm:0.0021177884191274643 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.3464055061340332 norm:0.0011781080393120646 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.3424927592277527 norm:0.0008446733700111508 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.340521901845932 norm:0.0007219183607958257 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.3394020199775696 norm:0.0006404723972082138 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.33877527713775635 norm:0.000587682006880641 max memory_allocated 29271.25048828125 
[2025-03-02 18:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.33847910165786743 norm:0.0005515188095159829 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.3381892442703247 norm:0.0005167141207493842 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.3380376398563385 norm:0.000495527230668813 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.337956041097641 norm:0.0004881007189396769 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.33781230449676514 norm:0.0004753002431243658 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.33769482374191284 norm:0.0004604704736266285 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.3375767469406128 norm:0.0004547936259768903 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.3375834822654724 norm:0.00044997368240728974 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:25 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.3374929428100586 norm:0.0004396494769025594 max memory_allocated 29271.25048828125 
[2025-03-02 18:10:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.3373919129371643 norm:0.0004364912456367165 max memory_allocated 29271.25048828125 
[2025-03-02 18:11:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.3373112380504608 norm:0.00042819540249183774 max memory_allocated 29271.25048828125 
[2025-03-02 18:11:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.33727169036865234 norm:0.00042537617264315486 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.33730265498161316 norm:0.0004262757138349116 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.39717429876327515 norm:0.0029555363580584526 max memory_allocated 29271.43798828125 
[2025-03-02 18:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.38547709584236145 norm:0.0015163153875619173 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.376004159450531 norm:0.000979613745585084 max memory_allocated 29271.43798828125 
[2025-03-02 18:16:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.3719869554042816 norm:0.0007175114005804062 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.3697475790977478 norm:0.0005938727408647537 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.3686406910419464 norm:0.0005286700907163322 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.36816516518592834 norm:0.0004974568728357553 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.36784523725509644 norm:0.0004716666298918426 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:29 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.3676189184188843 norm:0.000464617129182443 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.3675607144832611 norm:0.0004593177291098982 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.36747559905052185 norm:0.0004460551426745951 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.3672619163990021 norm:0.0004244391166139394 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.36714258790016174 norm:0.0004219437250867486 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.36695265769958496 norm:0.0004078530182596296 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.3668958842754364 norm:0.0004093969473615289 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.3669063448905945 norm:0.00041216047247871757 max memory_allocated 29271.43798828125 
[2025-03-02 18:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.3668968081474304 norm:0.00040687713772058487 max memory_allocated 29271.43798828125 
[2025-03-02 18:27:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.36685067415237427 norm:0.00040195780456997454 max memory_allocated 29271.43798828125 
[2025-03-02 18:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.3667560815811157 norm:0.00039610633393749595 max memory_allocated 29271.43798828125 
[2025-03-02 18:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.3667491376399994 norm:0.00039597763679921627 max memory_allocated 29271.43798828125 
[2025-03-02 18:29:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:30:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.42926526069641113 norm:0.002924750791862607 max memory_allocated 29271.62548828125 
[2025-03-02 18:31:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.41603368520736694 norm:0.0015994904097169638 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.4053591787815094 norm:0.0010069214040413499 max memory_allocated 29271.62548828125 
[2025-03-02 18:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.40144607424736023 norm:0.0007974033942446113 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.3993113040924072 norm:0.0006847550394013524 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.39823389053344727 norm:0.0006223209202289581 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.39769765734672546 norm:0.0005809911526739597 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.3973630368709564 norm:0.0005413938197307289 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.39707404375076294 norm:0.0005124924355186522 max memory_allocated 29271.62548828125 
[2025-03-02 18:38:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.3969748318195343 norm:0.0004946541739627719 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.39690932631492615 norm:0.000491879996843636 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.3968571126461029 norm:0.00048568769125267863 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.39675697684288025 norm:0.00047984725097194314 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.39669597148895264 norm:0.0004788478254340589 max memory_allocated 29271.62548828125 
[2025-03-02 18:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.39669740200042725 norm:0.00047029738198034465 max memory_allocated 29271.62548828125 
[2025-03-02 18:43:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.39666032791137695 norm:0.00046048068907111883 max memory_allocated 29271.62548828125 
[2025-03-02 18:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.3965202569961548 norm:0.00045137861161492765 max memory_allocated 29271.62548828125 
[2025-03-02 18:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.3964077830314636 norm:0.00044031161814928055 max memory_allocated 29271.62548828125 
[2025-03-02 18:45:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.39627501368522644 norm:0.0004309485375415534 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.3962297737598419 norm:0.0004294029495213181 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:47:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.4740216135978699 norm:0.0033021019771695137 max memory_allocated 29271.81298828125 
[2025-03-02 18:48:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.4599995017051697 norm:0.0017575228121131659 max memory_allocated 29271.81298828125 
[2025-03-02 18:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.4488344192504883 norm:0.0011560437269508839 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.44486406445503235 norm:0.0008743844809941947 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.4427299499511719 norm:0.0007510954746976495 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.44163477420806885 norm:0.0006646380643360317 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.4410196840763092 norm:0.0005962227587588131 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.4406794607639313 norm:0.0005669303936883807 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.4404235780239105 norm:0.000546974188182503 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.44026979804039 norm:0.0005348605336621404 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.4402584433555603 norm:0.000538971449714154 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.440208375453949 norm:0.0005263120983727276 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.4401678144931793 norm:0.0005259382305666804 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.44009092450141907 norm:0.0005131136858835816 max memory_allocated 29271.81298828125 
[2025-03-02 18:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.4400118291378021 norm:0.0005054212524555624 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.4399961829185486 norm:0.0005004701670259237 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.4398723840713501 norm:0.0004908817354589701 max memory_allocated 29271.81298828125 
[2025-03-02 19:01:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.4397881329059601 norm:0.0004896456375718117 max memory_allocated 29271.81298828125 
[2025-03-02 19:02:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.4397839307785034 norm:0.0004918320337310433 max memory_allocated 29271.81298828125 
[2025-03-02 19:03:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.439775288105011 norm:0.0004831385740544647 max memory_allocated 29271.81298828125 
[2025-03-02 19:03:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.5286585092544556 norm:0.0029372533317655325 max memory_allocated 29272.00048828125 
[2025-03-02 19:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.5149973630905151 norm:0.0016496926546096802 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.502879798412323 norm:0.0010934042511507869 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.49874967336654663 norm:0.0008537918329238892 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.4965730607509613 norm:0.0007503494271077216 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.49555933475494385 norm:0.0006797836977057159 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.4950883686542511 norm:0.0006477761780843139 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.49470412731170654 norm:0.0006279082736000419 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.49446535110473633 norm:0.0006177262403070927 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.4942375421524048 norm:0.0005963344010524452 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.49398261308670044 norm:0.0005763137014582753 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.493890643119812 norm:0.0005705665098503232 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.49367445707321167 norm:0.000556638406123966 max memory_allocated 29272.00048828125 
[2025-03-02 19:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.4936085641384125 norm:0.0005563921295106411 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.4936278164386749 norm:0.0005497706006281078 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.4936484098434448 norm:0.0005520379054360092 max memory_allocated 29272.00048828125 
[2025-03-02 19:17:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.49362611770629883 norm:0.0005490870680660009 max memory_allocated 29272.00048828125 
[2025-03-02 19:18:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.4935600757598877 norm:0.0005429564625956118 max memory_allocated 29272.00048828125 
[2025-03-02 19:19:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.49350935220718384 norm:0.0005395084153860807 max memory_allocated 29272.00048828125 
[2025-03-02 19:20:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.49351388216018677 norm:0.0005378625937737525 max memory_allocated 29272.00048828125 
[2025-03-02 19:20:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.5887699723243713 norm:0.003131917677819729 max memory_allocated 29272.18798828125 
[2025-03-02 19:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.5748611688613892 norm:0.0016474844887852669 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.5633482933044434 norm:0.0010648255702108145 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.5593640804290771 norm:0.0008278337772935629 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.5573697090148926 norm:0.0007395792054012418 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.55657958984375 norm:0.0006881576264277101 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.5561487078666687 norm:0.0006650962750427425 max memory_allocated 29272.18798828125 
[2025-03-02 19:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.5558397173881531 norm:0.0006294609629549086 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.555556058883667 norm:0.0006112456321716309 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.5553836226463318 norm:0.0006009360076859593 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.5551626682281494 norm:0.0005810450529679656 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.5549109578132629 norm:0.0005696593434549868 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.5548082590103149 norm:0.0005648646620102227 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.5547417998313904 norm:0.0005582310841418803 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.5546314716339111 norm:0.00054612458916381 max memory_allocated 29272.18798828125 
[2025-03-02 19:33:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.5545566082000732 norm:0.0005495769437402487 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.554567813873291 norm:0.0005560402059927583 max memory_allocated 29272.18798828125 
[2025-03-02 19:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.5545738935470581 norm:0.0005536347161978483 max memory_allocated 29272.18798828125 
[2025-03-02 19:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.5545458793640137 norm:0.0005534451338462532 max memory_allocated 29272.18798828125 
[2025-03-02 19:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.5545470714569092 norm:0.0005471953190863132 max memory_allocated 29272.18798828125 
[2025-03-02 19:37:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.6524696350097656 norm:0.003692053724080324 max memory_allocated 29272.37548828125 
[2025-03-02 19:39:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.6378524899482727 norm:0.0018991936231032014 max memory_allocated 29272.37548828125 
[2025-03-02 19:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.6254358887672424 norm:0.0012047309428453445 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.6211835741996765 norm:0.0009003261802718043 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.6189314126968384 norm:0.0007481693173758686 max memory_allocated 29272.37548828125 
[2025-03-02 19:42:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.6180503964424133 norm:0.0006728759035468102 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.6176274418830872 norm:0.0006290220189839602 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.6173192262649536 norm:0.0005997726693749428 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.617054283618927 norm:0.0005716830492019653 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.6168186068534851 norm:0.0005564582534134388 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.6166241765022278 norm:0.0005364571698009968 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.6164044141769409 norm:0.0005265704239718616 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.6162884831428528 norm:0.0005221205065026879 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.6161977648735046 norm:0.0005243064952082932 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.616113543510437 norm:0.0005217836005613208 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.6160882115364075 norm:0.0005213827826082706 max memory_allocated 29272.37548828125 
[2025-03-02 19:51:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.6160319447517395 norm:0.0005114663508720696 max memory_allocated 29272.37548828125 
[2025-03-02 19:52:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.6159289479255676 norm:0.0005095396772958338 max memory_allocated 29272.37548828125 
[2025-03-02 19:53:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.6159546375274658 norm:0.0005073758075013757 max memory_allocated 29272.37548828125 
[2025-03-02 19:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.615921676158905 norm:0.0005079961265437305 max memory_allocated 29272.37548828125 
[2025-03-02 19:54:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.7297148108482361 norm:0.003190298331901431 max memory_allocated 29272.56298828125 
[2025-03-02 19:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.7144284248352051 norm:0.001922456780448556 max memory_allocated 29272.56298828125 
[2025-03-02 19:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.7009935975074768 norm:0.0013537665363401175 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.696262538433075 norm:0.0010569049045443535 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.6938284635543823 norm:0.0008781364886090159 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.692966639995575 norm:0.0008034288766793907 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.6925228238105774 norm:0.0007624393329024315 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.6921351552009583 norm:0.0007324457401409745 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.6917163133621216 norm:0.0006888980860821903 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.6914039850234985 norm:0.0006701803067699075 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.6910701394081116 norm:0.0006353530334308743 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.6907913088798523 norm:0.0006221204530447721 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.6905408501625061 norm:0.000601869192905724 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.6904719471931458 norm:0.0005987836630083621 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.6904318332672119 norm:0.0005979673005640507 max memory_allocated 29272.56298828125 
[2025-03-02 20:07:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.6902875900268555 norm:0.000591411953791976 max memory_allocated 29272.56298828125 
[2025-03-02 20:08:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.6900574564933777 norm:0.0005810178117826581 max memory_allocated 29272.56298828125 
[2025-03-02 20:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.6899318099021912 norm:0.0005824461113661528 max memory_allocated 29272.56298828125 
[2025-03-02 20:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.6898236274719238 norm:0.0005766082904301584 max memory_allocated 29272.56298828125 
[2025-03-02 20:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.6898159980773926 norm:0.0005799700156785548 max memory_allocated 29272.56298828125 
[2025-03-02 20:11:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:12:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.7971223592758179 norm:0.003219417529180646 max memory_allocated 29272.75048828125 
[2025-03-02 20:12:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.7823415398597717 norm:0.0015599887119606137 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.7691479921340942 norm:0.001069261459633708 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.764680802822113 norm:0.0008605298353359103 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.7625154256820679 norm:0.0007412720005959272 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.7615302801132202 norm:0.0006478526629507542 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.7612255811691284 norm:0.0006128564709797502 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.760940670967102 norm:0.0005931966006755829 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.7606809139251709 norm:0.0005822966923005879 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.7605204582214355 norm:0.0005725480150431395 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.7604183554649353 norm:0.0005616096896119416 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.7602895498275757 norm:0.0005413598846644163 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.7601413130760193 norm:0.000524181523360312 max memory_allocated 29272.75048828125 
[2025-03-02 20:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.7600057721138 norm:0.0005156745319254696 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.7599389553070068 norm:0.0005121242138557136 max memory_allocated 29272.75048828125 
[2025-03-02 20:24:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.7598003149032593 norm:0.0004951542359776795 max memory_allocated 29272.75048828125 
[2025-03-02 20:25:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.7596243619918823 norm:0.0004881881468463689 max memory_allocated 29272.75048828125 
[2025-03-02 20:26:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.7595110535621643 norm:0.0004835074651055038 max memory_allocated 29272.75048828125 
[2025-03-02 20:26:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.7594385147094727 norm:0.0004773222317453474 max memory_allocated 29272.75048828125 
[2025-03-02 20:27:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.7594018578529358 norm:0.00047873659059405327 max memory_allocated 29272.75048828125 
[2025-03-02 20:28:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.8847774267196655 norm:0.0023966277949512005 max memory_allocated 29272.93798828125 
[2025-03-02 20:29:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.8684808015823364 norm:0.0013000783510506153 max memory_allocated 29272.93798828125 
[2025-03-02 20:30:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.8531866073608398 norm:0.0009125915239565074 max memory_allocated 29272.93798828125 
[2025-03-02 20:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.8481568694114685 norm:0.0007247960893437266 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.8457493782043457 norm:0.000642093364149332 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.8448097705841064 norm:0.0006131567060947418 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.8443377614021301 norm:0.0005923545104451478 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.8439664840698242 norm:0.0005629149964079261 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.8437073230743408 norm:0.0005441802786663175 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.8435080051422119 norm:0.000537751941010356 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.8433346748352051 norm:0.0005287330714054406 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.8431084156036377 norm:0.0005254771094769239 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.8430197834968567 norm:0.0005251954426057637 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.8429206609725952 norm:0.0005221504252403975 max memory_allocated 29272.93798828125 
[2025-03-02 20:40:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.8427518606185913 norm:0.0005189362564124167 max memory_allocated 29272.93798828125 
[2025-03-02 20:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.8426619172096252 norm:0.0005203802138566971 max memory_allocated 29272.93798828125 
[2025-03-02 20:42:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.8425881862640381 norm:0.0005138744600117207 max memory_allocated 29272.93798828125 
[2025-03-02 20:43:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.8425071239471436 norm:0.0005144776660017669 max memory_allocated 29272.93798828125 
[2025-03-02 20:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.8424870371818542 norm:0.0005132406949996948 max memory_allocated 29272.93798828125 
[2025-03-02 20:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.842470109462738 norm:0.0005111265927553177 max memory_allocated 29272.93798828125 
[2025-03-02 20:44:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.9756466150283813 norm:0.0055324058048427105 max memory_allocated 29273.12548828125 
[2025-03-02 20:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.9576230049133301 norm:0.002708667190745473 max memory_allocated 29273.12548828125 
[2025-03-02 20:47:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.941953182220459 norm:0.0019187267171218991 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.9366104006767273 norm:0.001558875199407339 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.9336916208267212 norm:0.001226633321493864 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.9325211644172668 norm:0.0011895907809957862 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.9318104982376099 norm:0.0012291946914047003 max memory_allocated 29273.12548828125 
[2025-03-02 20:51:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.931486964225769 norm:0.0010878443717956543 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.9311627149581909 norm:0.0010196430375799537 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.9309647083282471 norm:0.0009509766823612154 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.9306981563568115 norm:0.0009720014058984816 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.9304506182670593 norm:0.0009075156413018703 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.9303609132766724 norm:0.0008323229267261922 max memory_allocated 29273.12548828125 
[2025-03-02 20:56:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.9300440549850464 norm:0.000866129354108125 max memory_allocated 29273.12548828125 
[2025-03-02 20:57:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.929926872253418 norm:0.0008283416391350329 max memory_allocated 29273.12548828125 
[2025-03-02 20:58:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.9298368692398071 norm:0.000858639890793711 max memory_allocated 29273.12548828125 
[2025-03-02 20:59:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.9297897815704346 norm:0.0008482123957946897 max memory_allocated 29273.12548828125 
[2025-03-02 20:59:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.929612934589386 norm:0.0008309443364851177 max memory_allocated 29273.12548828125 
[2025-03-02 21:00:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.9295870661735535 norm:0.0008064018911682069 max memory_allocated 29273.12548828125 
[2025-03-02 21:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.929507851600647 norm:0.0008266808581538498 max memory_allocated 29273.12548828125 
[2025-03-02 21:01:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 21:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:1.0515104532241821 norm:0.004042563959956169 max memory_allocated 29273.31298828125 
[2025-03-02 21:03:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:1.0344469547271729 norm:0.002123229904100299 max memory_allocated 29273.31298828125 
[2025-03-02 21:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:1.0183202028274536 norm:0.0013666250742971897 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:1.0130561590194702 norm:0.0010131754679605365 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:1.0108224153518677 norm:0.0008540404960513115 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:1.0099680423736572 norm:0.0007245990564115345 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:1.00941002368927 norm:0.0006483938195742667 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:1.0090224742889404 norm:0.0006019384600222111 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:1.0087918043136597 norm:0.0005590408109128475 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:1.0086557865142822 norm:0.0005423101247288287 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:1.0084432363510132 norm:0.0005352969747036695 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:1.008270263671875 norm:0.0005316847236827016 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:1.0081318616867065 norm:0.0005146946059539914 max memory_allocated 29273.31298828125 
[2025-03-02 21:13:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:1.0080523490905762 norm:0.000501314178109169 max memory_allocated 29273.31298828125 
[2025-03-02 21:14:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:1.008042573928833 norm:0.0005024300189688802 max memory_allocated 29273.31298828125 
[2025-03-02 21:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:1.007880449295044 norm:0.0004961689119227231 max memory_allocated 29273.31298828125 
[2025-03-02 21:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:1.007725477218628 norm:0.0004899933701381087 max memory_allocated 29273.31298828125 
[2025-03-02 21:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:1.007673978805542 norm:0.0004959242069162428 max memory_allocated 29273.31298828125 
[2025-03-02 21:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:1.007580280303955 norm:0.0004926968249492347 max memory_allocated 29273.31298828125 
[2025-03-02 21:18:24 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:1.0074371099472046 norm:0.0004891988937743008 max memory_allocated 29273.31298828125 
[2025-03-02 21:18:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:19:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.1485661268234253 norm:0.0038615597877651453 max memory_allocated 29273.50048828125 
[2025-03-02 21:20:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:1.12993586063385 norm:0.001991888042539358 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:1.112384557723999 norm:0.001245376537553966 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:1.106285572052002 norm:0.0008949904004111886 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:1.1035088300704956 norm:0.0007742908201180398 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:1.102333426475525 norm:0.0007101335213519633 max memory_allocated 29273.50048828125 
[2025-03-02 21:24:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:1.101847529411316 norm:0.0007632990018464625 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:1.1010771989822388 norm:0.000673484755679965 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:1.100701928138733 norm:0.0006698008510284126 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:1.100386619567871 norm:0.0006647114641964436 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:1.1001203060150146 norm:0.0006440955912694335 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:1.0998491048812866 norm:0.0006345172878354788 max memory_allocated 29273.50048828125 
[2025-03-02 21:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:1.0996737480163574 norm:0.0006266795098781586 max memory_allocated 29273.50048828125 
[2025-03-02 21:30:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:1.099509835243225 norm:0.0006192002911120653 max memory_allocated 29273.50048828125 
[2025-03-02 21:31:08 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:1.0993762016296387 norm:0.0006111507536843419 max memory_allocated 29273.50048828125 
[2025-03-02 21:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:1.0992475748062134 norm:0.000618864840362221 max memory_allocated 29273.50048828125 
[2025-03-02 21:32:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:1.0990064144134521 norm:0.0006095691351220012 max memory_allocated 29273.50048828125 
[2025-03-02 21:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:1.0989376306533813 norm:0.0006168647087179124 max memory_allocated 29273.50048828125 
[2025-03-02 21:34:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:1.0988701581954956 norm:0.0006271530874073505 max memory_allocated 29273.50048828125 
[2025-03-02 21:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:1.0987845659255981 norm:0.0006254400359466672 max memory_allocated 29273.50048828125 
[2025-03-02 21:35:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:36:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:1.243971586227417 norm:0.004363675136119127 max memory_allocated 29273.68798828125 
[2025-03-02 21:37:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:1.2241748571395874 norm:0.002111581852659583 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:1.2061400413513184 norm:0.0013105799444019794 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:1.1997809410095215 norm:0.0009853049414232373 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:1.1971924304962158 norm:0.0008143367595039308 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:1.1961623430252075 norm:0.0007374122506007552 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:1.195494532585144 norm:0.000669147411826998 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:1.1949868202209473 norm:0.0006269597797654569 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:1.1946284770965576 norm:0.0006143557257018983 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:1.1943473815917969 norm:0.0005954839289188385 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:1.1940670013427734 norm:0.0005870444001629949 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:1.1938360929489136 norm:0.0005794367170892656 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:1.1936042308807373 norm:0.0005715814186260104 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:1.1934751272201538 norm:0.0005703908391296864 max memory_allocated 29273.68798828125 
[2025-03-02 21:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:1.1933705806732178 norm:0.0005657721776515245 max memory_allocated 29273.68798828125 
[2025-03-02 21:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:1.193227767944336 norm:0.0005697609158232808 max memory_allocated 29273.68798828125 
[2025-03-02 21:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:1.1930558681488037 norm:0.000573557335883379 max memory_allocated 29273.68798828125 
[2025-03-02 21:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:1.1929445266723633 norm:0.0005600161384791136 max memory_allocated 29273.68798828125 
[2025-03-02 21:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:1.192853331565857 norm:0.000557889579795301 max memory_allocated 29273.68798828125 
[2025-03-02 21:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:1.192772388458252 norm:0.0005611772648990154 max memory_allocated 29273.68798828125 
[2025-03-02 21:52:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:53:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:1.3369828462600708 norm:0.005989777389913797 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:07 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:1.3175740242004395 norm:0.003443182911723852 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:56 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:1.2989479303359985 norm:0.0023220875300467014 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:46 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:1.2927273511886597 norm:0.0017448232974857092 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:36 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:1.2904157638549805 norm:0.0013872579438611865 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:1.289572834968567 norm:0.0012028440833091736 max memory_allocated 29273.87548828125 
[2025-03-02 21:58:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:1.2887861728668213 norm:0.0010359997395426035 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:05 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:1.2884440422058105 norm:0.0009558725287206471 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:54 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:1.288148283958435 norm:0.0009056681883521378 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:1.2879014015197754 norm:0.0008796614711172879 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:1.2878010272979736 norm:0.0008499680552631617 max memory_allocated 29273.87548828125 
[2025-03-02 22:02:24 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:1.2877224683761597 norm:0.0008403938845731318 max memory_allocated 29273.87548828125 
[2025-03-02 22:03:13 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:1.2874006032943726 norm:0.0007908747647888958 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:03 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:1.28721022605896 norm:0.0007745875045657158 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:1.2870893478393555 norm:0.0007411277038045228 max memory_allocated 29273.87548828125 
[2025-03-02 22:05:42 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:1.286983609199524 norm:0.0007232594070956111 max memory_allocated 29273.87548828125 
[2025-03-02 22:06:32 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:1.2868599891662598 norm:0.0007055614842101932 max memory_allocated 29273.87548828125 
[2025-03-02 22:07:22 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:1.2865456342697144 norm:0.0006812595529481769 max memory_allocated 29273.87548828125 
[2025-03-02 22:08:12 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:1.2863357067108154 norm:0.0006813196814619005 max memory_allocated 29273.87548828125 
[2025-03-02 22:09:01 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:1.2861700057983398 norm:0.00066399882780388 max memory_allocated 29273.87548828125 
[2025-03-02 22:09:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:10:11 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:1.4510776996612549 norm:0.004408584907650948 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:01 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:1.4296313524246216 norm:0.0024655505549162626 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:1.4098095893859863 norm:0.0016361050074920058 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:1.4026272296905518 norm:0.0010371188400313258 max memory_allocated 29274.06298828125 
[2025-03-02 22:13:30 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:1.3997210264205933 norm:0.0008203951874747872 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:1.398477554321289 norm:0.0007552460301667452 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:09 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:1.397836685180664 norm:0.0007231667987070978 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:1.3973441123962402 norm:0.0007021218771114945 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:48 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:1.3970394134521484 norm:0.0007047585677355528 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:1.3967818021774292 norm:0.000686159823089838 max memory_allocated 29274.06298828125 
[2025-03-02 22:18:28 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:1.3964656591415405 norm:0.0006837837281636894 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:1.396241545677185 norm:0.0006844614399597049 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:1.39609694480896 norm:0.0007113078609108925 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:1.395714521408081 norm:0.0007061496144160628 max memory_allocated 29274.06298828125 
[2025-03-02 22:21:47 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:1.3955379724502563 norm:0.0007064345409162343 max memory_allocated 29274.06298828125 
[2025-03-02 22:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:1.3954901695251465 norm:0.0007015004521235824 max memory_allocated 29274.06298828125 
[2025-03-02 22:23:26 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:1.3953254222869873 norm:0.0007005507359281182 max memory_allocated 29274.06298828125 
[2025-03-02 22:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:1.3951994180679321 norm:0.0006934215198270977 max memory_allocated 29274.06298828125 
[2025-03-02 22:25:06 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:1.3950746059417725 norm:0.0006716839852742851 max memory_allocated 29274.06298828125 
[2025-03-02 22:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:1.3949722051620483 norm:0.000677551724947989 max memory_allocated 29274.06298828125 
[2025-03-02 22:26:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:27:03 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:1.5935187339782715 norm:0.004430966917425394 max memory_allocated 29274.25048828125 
[2025-03-02 22:27:53 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:1.5684773921966553 norm:0.00249162083491683 max memory_allocated 29274.25048828125 
[2025-03-02 22:28:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:1.544698715209961 norm:0.001647208584472537 max memory_allocated 29274.25048828125 
[2025-03-02 22:29:32 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:1.5364269018173218 norm:0.0012698553036898375 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:22 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:1.533745527267456 norm:0.0011444659903645515 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:12 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:1.5325541496276855 norm:0.0010390040697529912 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:01 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:1.5317950248718262 norm:0.0009980308823287487 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:51 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:1.5313198566436768 norm:0.0009597406606189907 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:41 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:1.5307868719100952 norm:0.0009343174169771373 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:1.5304170846939087 norm:0.00092413614038378 max memory_allocated 29274.25048828125 
[2025-03-02 22:35:20 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:1.5301835536956787 norm:0.0009205453097820282 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:1.5300099849700928 norm:0.0009250118164345622 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:1.529828667640686 norm:0.0009168977849185467 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:1.5296170711517334 norm:0.0009105174103751779 max memory_allocated 29274.25048828125 
[2025-03-02 22:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:1.5293138027191162 norm:0.0009105707868002355 max memory_allocated 29274.25048828125 
[2025-03-02 22:39:29 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:1.528978943824768 norm:0.0009007404441945255 max memory_allocated 29274.25048828125 
[2025-03-02 22:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:1.528792381286621 norm:0.0008957531535997987 max memory_allocated 29274.25048828125 
[2025-03-02 22:41:08 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:1.528664231300354 norm:0.000888511654920876 max memory_allocated 29274.25048828125 
[2025-03-02 22:41:58 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:1.5284647941589355 norm:0.0008810411673039198 max memory_allocated 29274.25048828125 
[2025-03-02 22:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:1.5282436609268188 norm:0.0008742879726924002 max memory_allocated 29274.25048828125 
[2025-03-02 22:43:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:43:56 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:1.7332897186279297 norm:0.007231736555695534 max memory_allocated 29274.43798828125 
[2025-03-02 22:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:1.7049312591552734 norm:0.003929893020540476 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:1.6788283586502075 norm:0.002483312739059329 max memory_allocated 29274.43798828125 
[2025-03-02 22:46:25 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:1.6698288917541504 norm:0.0017945412546396255 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:1.6665433645248413 norm:0.0014806799590587616 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:04 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:1.665187120437622 norm:0.0013404893688857555 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:1.6641608476638794 norm:0.001243524719029665 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:1.6636128425598145 norm:0.0011666333302855492 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:1.66300368309021 norm:0.0011535140220075846 max memory_allocated 29274.43798828125 
[2025-03-02 22:51:23 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:1.6625398397445679 norm:0.0011257645674049854 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:1.6621330976486206 norm:0.0011305848602205515 max memory_allocated 29274.43798828125 
[2025-03-02 22:53:02 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:1.6616709232330322 norm:0.0011335844174027443 max memory_allocated 29274.43798828125 
[2025-03-02 22:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:1.6612274646759033 norm:0.0011353601003065705 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:42 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:1.6608728170394897 norm:0.0011016103671863675 max memory_allocated 29274.43798828125 
[2025-03-02 22:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:1.6605422496795654 norm:0.0010957666672766209 max memory_allocated 29274.43798828125 
[2025-03-02 22:56:21 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:1.660365104675293 norm:0.0010906290262937546 max memory_allocated 29274.43798828125 
[2025-03-02 22:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:1.6602108478546143 norm:0.001086602220311761 max memory_allocated 29274.43798828125 
[2025-03-02 22:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:1.6600618362426758 norm:0.0010813155677169561 max memory_allocated 29274.43798828125 
[2025-03-02 22:58:50 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:1.659800410270691 norm:0.001080327550880611 max memory_allocated 29274.43798828125 
[2025-03-02 22:59:40 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:1.6595786809921265 norm:0.0010637488448992372 max memory_allocated 29274.43798828125 
[2025-03-02 22:59:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 22:59:58 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:00:48 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:1.8815112113952637 norm:0.02411571890115738 max memory_allocated 29274.77001953125 
[2025-03-02 23:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:1.8488240242004395 norm:0.020717747509479523 max memory_allocated 29274.77001953125 
[2025-03-02 23:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:1.8186633586883545 norm:0.01650015078485012 max memory_allocated 29274.77001953125 
[2025-03-02 23:03:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:1.808436393737793 norm:0.014674799516797066 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:1.8040097951889038 norm:0.013253184035420418 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:1.8018107414245605 norm:0.012010474689304829 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:1.800484299659729 norm:0.011312587186694145 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:1.799079179763794 norm:0.010850104503333569 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:27 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:1.7981905937194824 norm:0.010069671086966991 max memory_allocated 29274.77001953125 
[2025-03-02 23:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:1.797380805015564 norm:0.00944097526371479 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:1.7966657876968384 norm:0.009059008210897446 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:1.7960214614868164 norm:0.008768797852098942 max memory_allocated 29274.77001953125 
[2025-03-02 23:10:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:1.795562505722046 norm:0.00850827619433403 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:1.795218586921692 norm:0.008266565389931202 max memory_allocated 29274.77001953125 
[2025-03-02 23:12:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:1.7949471473693848 norm:0.008111552335321903 max memory_allocated 29274.77001953125 
[2025-03-02 23:13:16 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:1.7945843935012817 norm:0.008070970885455608 max memory_allocated 29274.77001953125 
[2025-03-02 23:14:06 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:1.7943508625030518 norm:0.007944328710436821 max memory_allocated 29274.77001953125 
[2025-03-02 23:14:56 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:1.7941468954086304 norm:0.007848626933991909 max memory_allocated 29274.77001953125 
[2025-03-02 23:15:46 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:1.793941855430603 norm:0.007734721526503563 max memory_allocated 29274.77001953125 
[2025-03-02 23:16:36 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:1.7937636375427246 norm:0.00764613039791584 max memory_allocated 29274.77001953125 
[2025-03-02 23:16:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:16:54 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:2.1002695560455322 norm:0.03643650561571121 max memory_allocated 29274.95751953125 
[2025-03-02 23:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:2.054403066635132 norm:0.02766988053917885 max memory_allocated 29274.95751953125 
[2025-03-02 23:19:24 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:2.012422561645508 norm:0.020696455612778664 max memory_allocated 29274.95751953125 
[2025-03-02 23:20:14 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:1.9982856512069702 norm:0.017872903496026993 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:04 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:1.9927479028701782 norm:0.015818705782294273 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:53 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:1.9899283647537231 norm:0.01413269154727459 max memory_allocated 29274.95751953125 
[2025-03-02 23:22:43 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:1.9881120920181274 norm:0.012782113626599312 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:1.9865041971206665 norm:0.011725792661309242 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:23 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:1.9853829145431519 norm:0.011369416490197182 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:1.984744906425476 norm:0.01112456526607275 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:1.9839690923690796 norm:0.010842852294445038 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:1.9832472801208496 norm:0.010548307560384274 max memory_allocated 29274.95751953125 
[2025-03-02 23:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:1.9824696779251099 norm:0.010325976647436619 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:1.9820173978805542 norm:0.010157140903174877 max memory_allocated 29274.95751953125 
[2025-03-02 23:29:23 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:1.981422781944275 norm:0.010108791291713715 max memory_allocated 29274.95751953125 
[2025-03-02 23:30:13 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:1.9808965921401978 norm:0.00996148120611906 max memory_allocated 29274.95751953125 
[2025-03-02 23:31:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:1.980346918106079 norm:0.009904774837195873 max memory_allocated 29274.95751953125 
[2025-03-02 23:31:52 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:1.9800782203674316 norm:0.009877326898276806 max memory_allocated 29274.95751953125 
[2025-03-02 23:32:42 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:1.9797132015228271 norm:0.009945578873157501 max memory_allocated 29274.95751953125 
[2025-03-02 23:33:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:1.9796088933944702 norm:0.0099274180829525 max memory_allocated 29274.95751953125 
[2025-03-02 23:33:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:33:51 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:2.686537981033325 norm:0.11122563481330872 max memory_allocated 29275.14501953125 
[2025-03-02 23:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:2.5796091556549072 norm:0.0824844017624855 max memory_allocated 29275.14501953125 
[2025-03-02 23:36:20 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:2.5085206031799316 norm:0.06434717029333115 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:10 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:2.47735595703125 norm:0.05533355101943016 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:2.4573493003845215 norm:0.046259570866823196 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:2.4463634490966797 norm:0.0422363243997097 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:2.437106132507324 norm:0.03834189474582672 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:2.427264451980591 norm:0.03231246769428253 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:19 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:2.420959711074829 norm:0.028599761426448822 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:09 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:2.415253162384033 norm:0.025446083396673203 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:2.4113917350769043 norm:0.024463428184390068 max memory_allocated 29275.14501953125 
[2025-03-02 23:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:2.4071078300476074 norm:0.02208816632628441 max memory_allocated 29275.14501953125 
[2025-03-02 23:44:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:2.403632879257202 norm:0.02129255048930645 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:2.4008963108062744 norm:0.02138286828994751 max memory_allocated 29275.14501953125 
[2025-03-02 23:46:18 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:2.398646831512451 norm:0.020991142839193344 max memory_allocated 29275.14501953125 
[2025-03-02 23:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:2.396402359008789 norm:0.0208120159804821 max memory_allocated 29275.14501953125 
[2025-03-02 23:47:58 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:2.395496129989624 norm:0.02145720273256302 max memory_allocated 29275.14501953125 
[2025-03-02 23:48:48 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:2.3945693969726562 norm:0.021606193855404854 max memory_allocated 29275.14501953125 
[2025-03-02 23:49:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:2.3934881687164307 norm:0.021206773817539215 max memory_allocated 29275.14501953125 
[2025-03-02 23:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:2.3923230171203613 norm:0.020717404782772064 max memory_allocated 29275.14501953125 
[2025-03-02 23:50:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:50:46 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:51:36 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:4.355471611022949 norm:0.1702699214220047 max memory_allocated 29275.33251953125 
[2025-03-02 23:52:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:4.129201889038086 norm:0.10935906320810318 max memory_allocated 29275.33251953125 
[2025-03-02 23:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:3.9701285362243652 norm:0.06907854229211807 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:3.9237658977508545 norm:0.06796728819608688 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:3.8916687965393066 norm:0.07886312156915665 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:45 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:3.8658084869384766 norm:0.06678000092506409 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:35 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:3.840873956680298 norm:0.05919807404279709 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:25 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:3.8252296447753906 norm:0.05783857777714729 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:15 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:3.813446521759033 norm:0.05913028493523598 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:05 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:3.806088924407959 norm:0.059267908334732056 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:3.7998313903808594 norm:0.0592065267264843 max memory_allocated 29275.33251953125 
[2025-03-03 00:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:3.7930290699005127 norm:0.0582255944609642 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:3.7857325077056885 norm:0.057706356048583984 max memory_allocated 29275.33251953125 
[2025-03-03 00:02:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:3.781071186065674 norm:0.05682573840022087 max memory_allocated 29275.33251953125 
[2025-03-03 00:03:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:3.7787325382232666 norm:0.05710062384605408 max memory_allocated 29275.33251953125 
[2025-03-03 00:04:04 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:3.7743794918060303 norm:0.054699938744306564 max memory_allocated 29275.33251953125 
[2025-03-03 00:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:3.771923542022705 norm:0.05394989624619484 max memory_allocated 29275.33251953125 
[2025-03-03 00:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:3.7701148986816406 norm:0.05439671128988266 max memory_allocated 29275.33251953125 
[2025-03-03 00:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:3.769474506378174 norm:0.05755339935421944 max memory_allocated 29275.33251953125 
[2025-03-03 00:07:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:3.7658348083496094 norm:0.05586446449160576 max memory_allocated 29275.33251953125 
[2025-03-03 00:07:38 root] (main_calib_config2.py 372): INFO 40507.970259428024
[2025-03-03 00:07:48 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:09:45 root] (main_calib_config2.py 159): INFO wikitext2 : 5.898108005523682
[2025-03-03 00:09:45 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:12:46 root] (main_calib_config2.py 159): INFO c4 : 7.9620466232299805
