[2025-03-01 14:27:49 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.6', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.6.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-01 14:28:23 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-01 14:28:23 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-01 14:28:24 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.6.pkl
[2025-03-01 14:28:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-01 14:29:00 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.013493414036929607 norm:0.015894653275609016 max memory_allocated 29271.02001953125 
[2025-03-01 14:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.007415170315653086 norm:0.00820193998515606 max memory_allocated 29271.02001953125 
[2025-03-01 14:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.005364108830690384 norm:0.005776688456535339 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.00473885890096426 norm:0.004585320129990578 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0044848681427538395 norm:0.003631726372987032 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0042472523637115955 norm:0.002954300958663225 max memory_allocated 29271.02001953125 
[2025-03-01 14:34:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.003972087055444717 norm:0.0025134675670415163 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.003922022879123688 norm:0.002321929670870304 max memory_allocated 29271.02001953125 
[2025-03-01 14:36:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0038031472358852625 norm:0.002042784821242094 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.003881757613271475 norm:0.0019358278950676322 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.00379298347979784 norm:0.0017508930759504437 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.003739149309694767 norm:0.0016158698126673698 max memory_allocated 29271.02001953125 
[2025-03-01 14:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0037609615828841925 norm:0.001493742223829031 max memory_allocated 29271.02001953125 
[2025-03-01 14:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0037086536176502705 norm:0.0012646197574213147 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0036872548516839743 norm:0.0013045804807916284 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.003705491777509451 norm:0.0012284230906516314 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.003738796105608344 norm:0.001180588616989553 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0036982474848628044 norm:0.0011609509820118546 max memory_allocated 29271.02001953125 
[2025-03-01 14:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0036749010905623436 norm:0.0010690228082239628 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0036376803182065487 norm:0.0010888699907809496 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-01 14:45:50 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.026005703955888748 norm:0.012714839540421963 max memory_allocated 29271.02001953125 
[2025-03-01 14:47:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.016537878662347794 norm:0.00786131713539362 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.01269964873790741 norm:0.0051937224343419075 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.011554826982319355 norm:0.00398320984095335 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.011100167408585548 norm:0.003427934367209673 max memory_allocated 29271.02001953125 
[2025-03-01 14:50:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.010857699438929558 norm:0.003035186557099223 max memory_allocated 29271.02001953125 
[2025-03-01 14:51:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.01063686702400446 norm:0.002688445383682847 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.01051043625921011 norm:0.002400532830506563 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.010405303910374641 norm:0.002147454069927335 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.010304728522896767 norm:0.0018884006422013044 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.010218012146651745 norm:0.0016532638110220432 max memory_allocated 29271.02001953125 
[2025-03-01 14:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.010173267684876919 norm:0.0015027571935206652 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.01009462308138609 norm:0.0014531731139868498 max memory_allocated 29271.02001953125 
[2025-03-01 14:57:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.010059138759970665 norm:0.0014240012969821692 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.010034562088549137 norm:0.0013871719129383564 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.010011859238147736 norm:0.0014095825608819723 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.010063939727842808 norm:0.0013219431275501847 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.010022128000855446 norm:0.0012634266167879105 max memory_allocated 29271.02001953125 
[2025-03-01 15:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.0099993497133255 norm:0.0011825492838397622 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.009991289116442204 norm:0.0012177091557532549 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-01 15:02:44 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 15:03:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.02742217667400837 norm:0.009082233533263206 max memory_allocated 29271.39501953125 
[2025-03-01 15:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.020874207839369774 norm:0.007212105672806501 max memory_allocated 29271.39501953125 
[2025-03-01 15:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.017822984606027603 norm:0.005474600475281477 max memory_allocated 29271.39501953125 
[2025-03-01 15:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.01694364845752716 norm:0.004414612427353859 max memory_allocated 29271.39501953125 
[2025-03-01 15:06:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.016469107940793037 norm:0.003648989601060748 max memory_allocated 29271.39501953125 
[2025-03-01 15:07:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.016098057851195335 norm:0.0030234032310545444 max memory_allocated 29271.39501953125 
[2025-03-01 15:08:33 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.015787333250045776 norm:0.0025808087084442377 max memory_allocated 29271.39501953125 
[2025-03-01 15:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.015541793778538704 norm:0.002327466383576393 max memory_allocated 29271.39501953125 
[2025-03-01 15:10:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.01532698143273592 norm:0.002023231703788042 max memory_allocated 29271.39501953125 
[2025-03-01 15:11:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.015221543610095978 norm:0.0018633558647707105 max memory_allocated 29271.39501953125 
[2025-03-01 15:11:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.015154578723013401 norm:0.001772669143974781 max memory_allocated 29271.39501953125 
[2025-03-01 15:12:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.015137049369513988 norm:0.0017896927893161774 max memory_allocated 29271.39501953125 
[2025-03-01 15:13:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.01515455637127161 norm:0.001761080464348197 max memory_allocated 29271.39501953125 
[2025-03-01 15:14:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.015161286108195782 norm:0.0016527586849406362 max memory_allocated 29271.39501953125 
[2025-03-01 15:15:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.015120159834623337 norm:0.0015514455735683441 max memory_allocated 29271.39501953125 
[2025-03-01 15:16:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.015075418166816235 norm:0.0015417212853208184 max memory_allocated 29271.39501953125 
[2025-03-01 15:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.015080978162586689 norm:0.0015259055653586984 max memory_allocated 29271.39501953125 
[2025-03-01 15:17:41 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.015061130747199059 norm:0.001462915213778615 max memory_allocated 29271.39501953125 
[2025-03-01 15:18:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.015019925311207771 norm:0.0013580776285380125 max memory_allocated 29271.39501953125 
[2025-03-01 15:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.015003260225057602 norm:0.0013176960637792945 max memory_allocated 29271.39501953125 
[2025-03-01 15:19:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-01 15:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.13736827671527863 norm:0.016452999785542488 max memory_allocated 29271.39501953125 
[2025-03-01 15:21:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.10261166095733643 norm:0.009509952738881111 max memory_allocated 29271.39501953125 
[2025-03-01 15:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.0723748579621315 norm:0.007958428002893925 max memory_allocated 29271.39501953125 
[2025-03-01 15:22:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.06738758832216263 norm:0.007060007192194462 max memory_allocated 29271.39501953125 
[2025-03-01 15:23:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.06108018755912781 norm:0.006594889331609011 max memory_allocated 29271.39501953125 
[2025-03-01 15:24:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.05621945112943649 norm:0.00571651104837656 max memory_allocated 29271.39501953125 
[2025-03-01 15:25:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.05515182763338089 norm:0.006347512826323509 max memory_allocated 29271.39501953125 
[2025-03-01 15:26:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.05582611262798309 norm:0.005902784876525402 max memory_allocated 29271.39501953125 
[2025-03-01 15:27:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.05245847627520561 norm:0.0055475360713899136 max memory_allocated 29271.39501953125 
[2025-03-01 15:27:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.05159531161189079 norm:0.00541192851960659 max memory_allocated 29271.39501953125 
[2025-03-01 15:28:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.049886830151081085 norm:0.005277290940284729 max memory_allocated 29271.39501953125 
[2025-03-01 15:29:33 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.04923669248819351 norm:0.00520959310233593 max memory_allocated 29271.39501953125 
[2025-03-01 15:30:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.048437874764204025 norm:0.0048324959352612495 max memory_allocated 29271.39501953125 
[2025-03-01 15:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.05243644863367081 norm:0.005762494634836912 max memory_allocated 29271.39501953125 
[2025-03-01 15:32:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.058778904378414154 norm:0.007175634615123272 max memory_allocated 29271.39501953125 
[2025-03-01 15:32:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.059128642082214355 norm:0.007660577539354563 max memory_allocated 29271.39501953125 
[2025-03-01 15:33:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.05416983738541603 norm:0.007419315632432699 max memory_allocated 29271.39501953125 
[2025-03-01 15:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.04723372310400009 norm:0.006196152418851852 max memory_allocated 29271.39501953125 
[2025-03-01 15:35:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.044010888785123825 norm:0.004928816109895706 max memory_allocated 29271.39501953125 
[2025-03-01 15:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.04620186239480972 norm:0.00533484760671854 max memory_allocated 29271.39501953125 
[2025-03-01 15:36:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-01 15:37:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.046319205313920975 norm:0.0008393179741688073 max memory_allocated 29271.39501953125 
[2025-03-01 15:38:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.03852012753486633 norm:0.0003503661719150841 max memory_allocated 29271.39501953125 
[2025-03-01 15:38:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.03452718257904053 norm:0.00021354571799747646 max memory_allocated 29271.39501953125 
[2025-03-01 15:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.03322511166334152 norm:0.00016639195382595062 max memory_allocated 29271.39501953125 
[2025-03-01 15:40:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.03255773335695267 norm:0.00015372521011158824 max memory_allocated 29271.39501953125 
[2025-03-01 15:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.032090671360492706 norm:0.00014869724691379815 max memory_allocated 29271.39501953125 
[2025-03-01 15:42:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.0317520871758461 norm:0.00014093444042373449 max memory_allocated 29271.39501953125 
[2025-03-01 15:43:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.03155243396759033 norm:0.00014000097871758044 max memory_allocated 29271.39501953125 
[2025-03-01 15:43:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.03143513947725296 norm:0.00014206151536200196 max memory_allocated 29271.39501953125 
[2025-03-01 15:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.03138502687215805 norm:0.0001433049765182659 max memory_allocated 29271.39501953125 
[2025-03-01 15:45:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.031343355774879456 norm:0.000138164556119591 max memory_allocated 29271.39501953125 
[2025-03-01 15:46:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.031341489404439926 norm:0.00013612887414637953 max memory_allocated 29271.39501953125 
[2025-03-01 15:47:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.031294502317905426 norm:0.0001273071247851476 max memory_allocated 29271.39501953125 
[2025-03-01 15:48:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.031273964792490005 norm:0.00013360095908865333 max memory_allocated 29271.39501953125 
[2025-03-01 15:48:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.03124798834323883 norm:0.00013520917855203152 max memory_allocated 29271.39501953125 
[2025-03-01 15:49:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.03121328353881836 norm:0.00012909231008961797 max memory_allocated 29271.39501953125 
[2025-03-01 15:50:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.031216584146022797 norm:0.00013778921857010573 max memory_allocated 29271.39501953125 
[2025-03-01 15:51:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.0312163345515728 norm:0.00014113480574451387 max memory_allocated 29271.39501953125 
[2025-03-01 15:52:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.031199002638459206 norm:0.00014142664440441877 max memory_allocated 29271.39501953125 
[2025-03-01 15:53:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.03119819238781929 norm:0.00013335817493498325 max memory_allocated 29271.39501953125 
[2025-03-01 15:53:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-01 15:54:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.05141320824623108 norm:0.0011479804525151849 max memory_allocated 29271.81298828125 
[2025-03-01 15:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.04181821644306183 norm:0.00047897445620037615 max memory_allocated 29271.81298828125 
[2025-03-01 15:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.03715742379426956 norm:0.00026665328186936677 max memory_allocated 29271.81298828125 
[2025-03-01 15:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.03569531440734863 norm:0.00020005865371786058 max memory_allocated 29271.81298828125 
[2025-03-01 15:57:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.0348355658352375 norm:0.00016903987852856517 max memory_allocated 29271.81298828125 
[2025-03-01 15:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.03426538035273552 norm:0.00014877499779686332 max memory_allocated 29271.81298828125 
[2025-03-01 15:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.03392750769853592 norm:0.00013856652367394418 max memory_allocated 29271.81298828125 
[2025-03-01 15:59:57 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.03375193849205971 norm:0.0001359607558697462 max memory_allocated 29271.81298828125 
[2025-03-01 16:00:47 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.03361377865076065 norm:0.00012419572158250958 max memory_allocated 29271.81298828125 
[2025-03-01 16:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.03353987634181976 norm:0.0001167126974905841 max memory_allocated 29271.81298828125 
[2025-03-01 16:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.033472005277872086 norm:0.0001166664733318612 max memory_allocated 29271.81298828125 
[2025-03-01 16:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.03342411294579506 norm:0.00011310660920571536 max memory_allocated 29271.81298828125 
[2025-03-01 16:04:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.03340035304427147 norm:0.00011702575284289196 max memory_allocated 29271.81298828125 
[2025-03-01 16:04:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.03337334096431732 norm:0.00011703257769113407 max memory_allocated 29271.81298828125 
[2025-03-01 16:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.033363014459609985 norm:0.00011729528341675177 max memory_allocated 29271.81298828125 
[2025-03-01 16:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.0333259142935276 norm:0.00012216765026096255 max memory_allocated 29271.81298828125 
[2025-03-01 16:07:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.03329716622829437 norm:0.00011622629244811833 max memory_allocated 29271.81298828125 
[2025-03-01 16:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.03328360617160797 norm:0.00012000303831882775 max memory_allocated 29271.81298828125 
[2025-03-01 16:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.03327472507953644 norm:0.00012319008237682283 max memory_allocated 29271.81298828125 
[2025-03-01 16:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.03326431289315224 norm:0.00012993042764719576 max memory_allocated 29271.81298828125 
[2025-03-01 16:10:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-01 16:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.05654311925172806 norm:0.0014882509130984545 max memory_allocated 29271.81298828125 
[2025-03-01 16:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.045957788825035095 norm:0.0006305216229520738 max memory_allocated 29271.81298828125 
[2025-03-01 16:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.040394194424152374 norm:0.0003555787552613765 max memory_allocated 29271.81298828125 
[2025-03-01 16:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.03863805532455444 norm:0.00024802848929539323 max memory_allocated 29271.81298828125 
[2025-03-01 16:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.03761812299489975 norm:0.00020517880329862237 max memory_allocated 29271.81298828125 
[2025-03-01 16:15:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.037001512944698334 norm:0.00017600714636500925 max memory_allocated 29271.81298828125 
[2025-03-01 16:15:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.03663245588541031 norm:0.00016605787095613778 max memory_allocated 29271.81298828125 
[2025-03-01 16:16:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.03642449900507927 norm:0.00015479326248168945 max memory_allocated 29271.81298828125 
[2025-03-01 16:17:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.03630568087100983 norm:0.00014930266479495913 max memory_allocated 29271.81298828125 
[2025-03-01 16:18:27 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.036227814853191376 norm:0.0001477128971600905 max memory_allocated 29271.81298828125 
[2025-03-01 16:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.03617902845144272 norm:0.00015021814033389091 max memory_allocated 29271.81298828125 
[2025-03-01 16:20:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.0361136831343174 norm:0.00014715411816723645 max memory_allocated 29271.81298828125 
[2025-03-01 16:20:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.03604273125529289 norm:0.0001379723398713395 max memory_allocated 29271.81298828125 
[2025-03-01 16:21:45 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.03601803258061409 norm:0.0001437571772839874 max memory_allocated 29271.81298828125 
[2025-03-01 16:22:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.035980112850666046 norm:0.00013996534107718617 max memory_allocated 29271.81298828125 
[2025-03-01 16:23:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.03594019636511803 norm:0.0001348734658677131 max memory_allocated 29271.81298828125 
[2025-03-01 16:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.03595074266195297 norm:0.00015503681788686663 max memory_allocated 29271.81298828125 
[2025-03-01 16:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.035948894917964935 norm:0.00014120907871983945 max memory_allocated 29271.81298828125 
[2025-03-01 16:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.03590141981840134 norm:0.0001393928105244413 max memory_allocated 29271.81298828125 
[2025-03-01 16:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.03588990122079849 norm:0.00013768770440947264 max memory_allocated 29271.81298828125 
[2025-03-01 16:26:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-01 16:27:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.06800800561904907 norm:0.001552641624584794 max memory_allocated 29271.81298828125 
[2025-03-01 16:28:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.05348857864737511 norm:0.0006877919076941907 max memory_allocated 29271.81298828125 
[2025-03-01 16:29:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.04630372300744057 norm:0.00039851333713158965 max memory_allocated 29271.81298828125 
[2025-03-01 16:30:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.04423651471734047 norm:0.00030425627483054996 max memory_allocated 29271.81298828125 
[2025-03-01 16:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.043160099536180496 norm:0.0002588546194601804 max memory_allocated 29271.81298828125 
[2025-03-01 16:31:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.042490117251873016 norm:0.00023724272614344954 max memory_allocated 29271.81298828125 
[2025-03-01 16:32:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.04206318408250809 norm:0.00022265661391429603 max memory_allocated 29271.81298828125 
[2025-03-01 16:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.041773486882448196 norm:0.00020653169485740364 max memory_allocated 29271.81298828125 
[2025-03-01 16:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.0415864996612072 norm:0.00021118235599715263 max memory_allocated 29271.81298828125 
[2025-03-01 16:35:17 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.04147816076874733 norm:0.00020699705055449158 max memory_allocated 29271.81298828125 
[2025-03-01 16:36:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.04134258255362511 norm:0.00020958713139407337 max memory_allocated 29271.81298828125 
[2025-03-01 16:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.041297778487205505 norm:0.00021712957823183388 max memory_allocated 29271.81298828125 
[2025-03-01 16:37:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.04124404489994049 norm:0.00021528129582293332 max memory_allocated 29271.81298828125 
[2025-03-01 16:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.04116697236895561 norm:0.00020804999803658575 max memory_allocated 29271.81298828125 
[2025-03-01 16:39:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.04111885651946068 norm:0.0002123764279531315 max memory_allocated 29271.81298828125 
[2025-03-01 16:40:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.04109562560915947 norm:0.00020899959781672806 max memory_allocated 29271.81298828125 
[2025-03-01 16:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.041067373007535934 norm:0.0002013237972278148 max memory_allocated 29271.81298828125 
[2025-03-01 16:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.04101065918803215 norm:0.00020145489543210715 max memory_allocated 29271.81298828125 
[2025-03-01 16:42:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.04099658504128456 norm:0.00019176425121258944 max memory_allocated 29271.81298828125 
[2025-03-01 16:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.04098803177475929 norm:0.00018483826715964824 max memory_allocated 29271.81298828125 
[2025-03-01 16:43:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-01 16:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.06699922680854797 norm:0.0014866270357742906 max memory_allocated 29272.37548828125 
[2025-03-01 16:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.05534885823726654 norm:0.0007119171204976737 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.04896489530801773 norm:0.0004127886495552957 max memory_allocated 29272.37548828125 
[2025-03-01 16:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.04689981788396835 norm:0.0002936029341071844 max memory_allocated 29272.37548828125 
[2025-03-01 16:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.04573791101574898 norm:0.0002361181250307709 max memory_allocated 29272.37548828125 
[2025-03-01 16:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.04507101699709892 norm:0.0002050202601822093 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.04467945173382759 norm:0.00018594237917568535 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.04444725811481476 norm:0.00018162898777518421 max memory_allocated 29272.37548828125 
[2025-03-01 16:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.04428475350141525 norm:0.00016900543414521962 max memory_allocated 29272.37548828125 
[2025-03-01 16:52:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.044165946543216705 norm:0.00016706102178432047 max memory_allocated 29272.37548828125 
[2025-03-01 16:52:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.04407305270433426 norm:0.00016224640421569347 max memory_allocated 29272.37548828125 
[2025-03-01 16:53:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.043985515832901 norm:0.000158226364874281 max memory_allocated 29272.37548828125 
[2025-03-01 16:54:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.043931759893894196 norm:0.0001576258073328063 max memory_allocated 29272.37548828125 
[2025-03-01 16:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.043887414038181305 norm:0.00015463183808606118 max memory_allocated 29272.37548828125 
[2025-03-01 16:56:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.043828777968883514 norm:0.00015110036474652588 max memory_allocated 29272.37548828125 
[2025-03-01 16:57:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.043803051114082336 norm:0.00014918616216164082 max memory_allocated 29272.37548828125 
[2025-03-01 16:57:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.04377782344818115 norm:0.00015033542877063155 max memory_allocated 29272.37548828125 
[2025-03-01 16:58:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.04373214393854141 norm:0.00014536264643538743 max memory_allocated 29272.37548828125 
[2025-03-01 16:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.04371899738907814 norm:0.00014700643077958375 max memory_allocated 29272.37548828125 
[2025-03-01 17:00:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.04370564967393875 norm:0.00015413382789120078 max memory_allocated 29272.37548828125 
[2025-03-01 17:00:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-01 17:01:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.08887571096420288 norm:0.002897983882576227 max memory_allocated 29272.56298828125 
[2025-03-01 17:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.06715178489685059 norm:0.0012708338908851147 max memory_allocated 29272.56298828125 
[2025-03-01 17:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.05653230473399162 norm:0.0006611382705159485 max memory_allocated 29272.56298828125 
[2025-03-01 17:04:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.053326621651649475 norm:0.0004546371637843549 max memory_allocated 29272.56298828125 
[2025-03-01 17:04:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.05162877216935158 norm:0.00035982587723992765 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.05065024644136429 norm:0.000306235917378217 max memory_allocated 29272.56298828125 
[2025-03-01 17:06:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.05015689879655838 norm:0.0002857787476386875 max memory_allocated 29272.56298828125 
[2025-03-01 17:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.04980231821537018 norm:0.00026772136334329844 max memory_allocated 29272.56298828125 
[2025-03-01 17:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.04955550283193588 norm:0.00025624915724620223 max memory_allocated 29272.56298828125 
[2025-03-01 17:08:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.0493483692407608 norm:0.00024302068050019443 max memory_allocated 29272.56298828125 
[2025-03-01 17:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.04917185753583908 norm:0.00023393938317894936 max memory_allocated 29272.56298828125 
[2025-03-01 17:10:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.049045857042074203 norm:0.00022852187976241112 max memory_allocated 29272.56298828125 
[2025-03-01 17:11:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.0489230640232563 norm:0.00023167862673290074 max memory_allocated 29272.56298828125 
[2025-03-01 17:12:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.048777785152196884 norm:0.00022584910038858652 max memory_allocated 29272.56298828125 
[2025-03-01 17:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.048684194684028625 norm:0.0002186217752750963 max memory_allocated 29272.56298828125 
[2025-03-01 17:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.0486045777797699 norm:0.00021249885321594775 max memory_allocated 29272.56298828125 
[2025-03-01 17:14:47 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.04853332042694092 norm:0.0002202158939326182 max memory_allocated 29272.56298828125 
[2025-03-01 17:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.0484958216547966 norm:0.00021762092364951968 max memory_allocated 29272.56298828125 
[2025-03-01 17:16:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.0484190471470356 norm:0.00021697045303881168 max memory_allocated 29272.56298828125 
[2025-03-01 17:17:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.04838483780622482 norm:0.00020809999841731042 max memory_allocated 29272.56298828125 
[2025-03-01 17:17:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-01 17:18:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.07632022351026535 norm:0.0015571224503219128 max memory_allocated 29272.75048828125 
[2025-03-01 17:19:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.06385594606399536 norm:0.0007812753901816905 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.05712133273482323 norm:0.00045771524310112 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.054791808128356934 norm:0.00032426652614958584 max memory_allocated 29272.75048828125 
[2025-03-01 17:21:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.05358898639678955 norm:0.0002615554549265653 max memory_allocated 29272.75048828125 
[2025-03-01 17:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.05287907272577286 norm:0.00022708330652676523 max memory_allocated 29272.75048828125 
[2025-03-01 17:23:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.05246854946017265 norm:0.00020580673299264163 max memory_allocated 29272.75048828125 
[2025-03-01 17:24:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.05221184343099594 norm:0.00019064750813413411 max memory_allocated 29272.75048828125 
[2025-03-01 17:25:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.0520351305603981 norm:0.0001823047932703048 max memory_allocated 29272.75048828125 
[2025-03-01 17:25:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.051916904747486115 norm:0.00018120826280210167 max memory_allocated 29272.75048828125 
[2025-03-01 17:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.05183929204940796 norm:0.00017196207772940397 max memory_allocated 29272.75048828125 
[2025-03-01 17:27:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.05174211412668228 norm:0.00016622478142380714 max memory_allocated 29272.75048828125 
[2025-03-01 17:28:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.05166637897491455 norm:0.00016181213140953332 max memory_allocated 29272.75048828125 
[2025-03-01 17:29:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.051604099571704865 norm:0.00015818062820471823 max memory_allocated 29272.75048828125 
[2025-03-01 17:29:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.05155816301703453 norm:0.000160900890477933 max memory_allocated 29272.75048828125 
[2025-03-01 17:30:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.05151752009987831 norm:0.00015607337991241366 max memory_allocated 29272.75048828125 
[2025-03-01 17:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.05149441584944725 norm:0.00015433476073667407 max memory_allocated 29272.75048828125 
[2025-03-01 17:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.05147440731525421 norm:0.00014769803965464234 max memory_allocated 29272.75048828125 
[2025-03-01 17:33:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.051452960819005966 norm:0.00014870754966977984 max memory_allocated 29272.75048828125 
[2025-03-01 17:34:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.05143751576542854 norm:0.0001476515899412334 max memory_allocated 29272.75048828125 
[2025-03-01 17:34:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-01 17:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.07721272110939026 norm:0.0011456557549536228 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.0659051239490509 norm:0.0005451810429804027 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.05971818417310715 norm:0.00031928601674735546 max memory_allocated 29272.93798828125 
[2025-03-01 17:37:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.05765887722373009 norm:0.00023707673244643956 max memory_allocated 29272.93798828125 
[2025-03-01 17:38:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.05661841109395027 norm:0.00019878760213032365 max memory_allocated 29272.93798828125 
[2025-03-01 17:39:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.05600636079907417 norm:0.00018228375120088458 max memory_allocated 29272.93798828125 
[2025-03-01 17:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.05565319582819939 norm:0.00017243617912754416 max memory_allocated 29272.93798828125 
[2025-03-01 17:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.055475980043411255 norm:0.00016473786672577262 max memory_allocated 29272.93798828125 
[2025-03-01 17:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.05532491207122803 norm:0.00015587678353767842 max memory_allocated 29272.93798828125 
[2025-03-01 17:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.05521676689386368 norm:0.00015249797434080392 max memory_allocated 29272.93798828125 
[2025-03-01 17:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.0551527701318264 norm:0.00015086497296579182 max memory_allocated 29272.93798828125 
[2025-03-01 17:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.05508032813668251 norm:0.00014343290240503848 max memory_allocated 29272.93798828125 
[2025-03-01 17:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.05503353849053383 norm:0.00014010295853950083 max memory_allocated 29272.93798828125 
[2025-03-01 17:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.054967839270830154 norm:0.00013804875197820365 max memory_allocated 29272.93798828125 
[2025-03-01 17:46:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.05492361634969711 norm:0.00014157718396745622 max memory_allocated 29272.93798828125 
[2025-03-01 17:47:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.05488121882081032 norm:0.00013284689339343458 max memory_allocated 29272.93798828125 
[2025-03-01 17:48:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.054838865995407104 norm:0.0001309104700339958 max memory_allocated 29272.93798828125 
[2025-03-01 17:49:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.054799072444438934 norm:0.0001316582493018359 max memory_allocated 29272.93798828125 
[2025-03-01 17:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.054779455065727234 norm:0.00012797597446478903 max memory_allocated 29272.93798828125 
[2025-03-01 17:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.05477670580148697 norm:0.0001298811985179782 max memory_allocated 29272.93798828125 
[2025-03-01 17:51:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-01 17:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.08059665560722351 norm:0.0010830189567059278 max memory_allocated 29273.12548828125 
[2025-03-01 17:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.06837065517902374 norm:0.0005366133991628885 max memory_allocated 29273.12548828125 
[2025-03-01 17:53:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.06183081120252609 norm:0.00030573923140764236 max memory_allocated 29273.12548828125 
[2025-03-01 17:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.05980858579277992 norm:0.00023864282411523163 max memory_allocated 29273.12548828125 
[2025-03-01 17:55:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.058808740228414536 norm:0.0002051239280262962 max memory_allocated 29273.12548828125 
[2025-03-01 17:56:15 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.0581708699464798 norm:0.00018178496975451708 max memory_allocated 29273.12548828125 
[2025-03-01 17:57:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.057809438556432724 norm:0.0001710036158328876 max memory_allocated 29273.12548828125 
[2025-03-01 17:57:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.05753866583108902 norm:0.0001620207040105015 max memory_allocated 29273.12548828125 
[2025-03-01 17:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.05738021060824394 norm:0.00015470395737793297 max memory_allocated 29273.12548828125 
[2025-03-01 17:59:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.05725584924221039 norm:0.00014852453023195267 max memory_allocated 29273.12548828125 
[2025-03-01 18:00:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.05715072154998779 norm:0.0001460274652345106 max memory_allocated 29273.12548828125 
[2025-03-01 18:01:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.05708582326769829 norm:0.0001513046445325017 max memory_allocated 29273.12548828125 
[2025-03-01 18:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.05699555203318596 norm:0.00014583408483304083 max memory_allocated 29273.12548828125 
[2025-03-01 18:02:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.05693575367331505 norm:0.00014255131827667356 max memory_allocated 29273.12548828125 
[2025-03-01 18:03:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.05691022425889969 norm:0.0001317233545705676 max memory_allocated 29273.12548828125 
[2025-03-01 18:04:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.056863728910684586 norm:0.00012828923354391009 max memory_allocated 29273.12548828125 
[2025-03-01 18:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.05685284361243248 norm:0.00012243793753441423 max memory_allocated 29273.12548828125 
[2025-03-01 18:06:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.056822143495082855 norm:0.00012185149535071105 max memory_allocated 29273.12548828125 
[2025-03-01 18:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.056796565651893616 norm:0.00012312523904256523 max memory_allocated 29273.12548828125 
[2025-03-01 18:07:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.05676434189081192 norm:0.00012258646893315017 max memory_allocated 29273.12548828125 
[2025-03-01 18:08:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-01 18:08:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.08130894601345062 norm:0.001223269966430962 max memory_allocated 29273.31298828125 
[2025-03-01 18:09:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.07040075957775116 norm:0.0006128405220806599 max memory_allocated 29273.31298828125 
[2025-03-01 18:10:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.06443548947572708 norm:0.0003799087426159531 max memory_allocated 29273.31298828125 
[2025-03-01 18:11:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.06227800250053406 norm:0.0002807559503708035 max memory_allocated 29273.31298828125 
[2025-03-01 18:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.061083972454071045 norm:0.00023339515610132366 max memory_allocated 29273.31298828125 
[2025-03-01 18:13:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.06042150780558586 norm:0.00020513657364062965 max memory_allocated 29273.31298828125 
[2025-03-01 18:13:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.059989288449287415 norm:0.00019191404862795025 max memory_allocated 29273.31298828125 
[2025-03-01 18:14:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.05972494184970856 norm:0.0001848178362706676 max memory_allocated 29273.31298828125 
[2025-03-01 18:15:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.0595654733479023 norm:0.00017616909462958574 max memory_allocated 29273.31298828125 
[2025-03-01 18:16:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.0594044029712677 norm:0.00016503823280800134 max memory_allocated 29273.31298828125 
[2025-03-01 18:17:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.05929211154580116 norm:0.00016033115389291197 max memory_allocated 29273.31298828125 
[2025-03-01 18:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.05919118970632553 norm:0.00014999249833635986 max memory_allocated 29273.31298828125 
[2025-03-01 18:18:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.05911262333393097 norm:0.00014978334365878254 max memory_allocated 29273.31298828125 
[2025-03-01 18:19:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.05906081944704056 norm:0.00014424601977225393 max memory_allocated 29273.31298828125 
[2025-03-01 18:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.05900576710700989 norm:0.00013964599929749966 max memory_allocated 29273.31298828125 
[2025-03-01 18:21:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.05895833298563957 norm:0.00014089408796280622 max memory_allocated 29273.31298828125 
[2025-03-01 18:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.05892704427242279 norm:0.00013314097304828465 max memory_allocated 29273.31298828125 
[2025-03-01 18:23:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.05888249725103378 norm:0.00013356679119169712 max memory_allocated 29273.31298828125 
[2025-03-01 18:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.05882891267538071 norm:0.0001283988676732406 max memory_allocated 29273.31298828125 
[2025-03-01 18:24:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.0587865486741066 norm:0.00012076504935976118 max memory_allocated 29273.31298828125 
[2025-03-01 18:24:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-01 18:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.08153380453586578 norm:0.0010444542858749628 max memory_allocated 29273.50048828125 
[2025-03-01 18:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.07183785736560822 norm:0.0005303203361108899 max memory_allocated 29273.50048828125 
[2025-03-01 18:27:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.06605276465415955 norm:0.00032834074227139354 max memory_allocated 29273.50048828125 
[2025-03-01 18:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.06413164734840393 norm:0.0002470790932420641 max memory_allocated 29273.50048828125 
[2025-03-01 18:29:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.06314194947481155 norm:0.00020904344273731112 max memory_allocated 29273.50048828125 
[2025-03-01 18:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.06249970570206642 norm:0.00018522363097872585 max memory_allocated 29273.50048828125 
[2025-03-01 18:30:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.06210733577609062 norm:0.00016944308299571276 max memory_allocated 29273.50048828125 
[2025-03-01 18:31:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.061810772866010666 norm:0.00015575920406263322 max memory_allocated 29273.50048828125 
[2025-03-01 18:32:29 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.06162358075380325 norm:0.0001500974758528173 max memory_allocated 29273.50048828125 
[2025-03-01 18:33:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.0615355521440506 norm:0.00014238110452424735 max memory_allocated 29273.50048828125 
[2025-03-01 18:34:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.061434682458639145 norm:0.00013890748959966004 max memory_allocated 29273.50048828125 
[2025-03-01 18:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.06131841242313385 norm:0.00013323590974323452 max memory_allocated 29273.50048828125 
[2025-03-01 18:35:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.06123809516429901 norm:0.00012682218221016228 max memory_allocated 29273.50048828125 
[2025-03-01 18:36:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.06118478626012802 norm:0.0001239932025782764 max memory_allocated 29273.50048828125 
[2025-03-01 18:37:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.061125144362449646 norm:0.00011965652811340988 max memory_allocated 29273.50048828125 
[2025-03-01 18:38:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.06110337749123573 norm:0.00011871219612658024 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.06107373535633087 norm:0.00011911596811842173 max memory_allocated 29273.50048828125 
[2025-03-01 18:39:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.06104053556919098 norm:0.00012060272274538875 max memory_allocated 29273.50048828125 
[2025-03-01 18:40:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.061021581292152405 norm:0.0001202634593937546 max memory_allocated 29273.50048828125 
[2025-03-01 18:41:36 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.06101103872060776 norm:0.00011881856335094199 max memory_allocated 29273.50048828125 
[2025-03-01 18:41:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-01 18:42:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.07968688756227493 norm:0.0007078758208081126 max memory_allocated 29273.68798828125 
[2025-03-01 18:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.07148389518260956 norm:0.0003772007185034454 max memory_allocated 29273.68798828125 
[2025-03-01 18:44:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.06600666046142578 norm:0.00024447074974887073 max memory_allocated 29273.68798828125 
[2025-03-01 18:45:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.06423512101173401 norm:0.00019255743245594203 max memory_allocated 29273.68798828125 
[2025-03-01 18:46:03 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.06337744742631912 norm:0.0001672994258115068 max memory_allocated 29273.68798828125 
[2025-03-01 18:46:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.06279213726520538 norm:0.00015222045476548374 max memory_allocated 29273.68798828125 
[2025-03-01 18:47:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.062398962676525116 norm:0.00014145126624498516 max memory_allocated 29273.68798828125 
[2025-03-01 18:48:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.062175292521715164 norm:0.00013446994125843048 max memory_allocated 29273.68798828125 
[2025-03-01 18:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.061997830867767334 norm:0.0001265467726625502 max memory_allocated 29273.68798828125 
[2025-03-01 18:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.06187252700328827 norm:0.00012241874355822802 max memory_allocated 29273.68798828125 
[2025-03-01 18:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.06177269667387009 norm:0.00011701335461111739 max memory_allocated 29273.68798828125 
[2025-03-01 18:51:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.061698269098997116 norm:0.00011221114982618019 max memory_allocated 29273.68798828125 
[2025-03-01 18:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.06163118779659271 norm:0.00010866294906008989 max memory_allocated 29273.68798828125 
[2025-03-01 18:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.06159641593694687 norm:0.00010836526053026319 max memory_allocated 29273.68798828125 
[2025-03-01 18:54:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.061561550945043564 norm:0.00010375070996815339 max memory_allocated 29273.68798828125 
[2025-03-01 18:55:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.061530813574790955 norm:0.00010318804561393335 max memory_allocated 29273.68798828125 
[2025-03-01 18:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.061482254415750504 norm:0.0001019098490360193 max memory_allocated 29273.68798828125 
[2025-03-01 18:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.06145462393760681 norm:9.996381413657218e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:57:39 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.06142779439687729 norm:9.802109707379714e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:58:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.061401981860399246 norm:0.00010069718700833619 max memory_allocated 29273.68798828125 
[2025-03-01 18:58:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-01 18:59:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.08563986420631409 norm:0.0011830750154331326 max memory_allocated 29273.87548828125 
[2025-03-01 19:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.07497799396514893 norm:0.0005741224158555269 max memory_allocated 29273.87548828125 
[2025-03-01 19:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.06864482909440994 norm:0.00036710864515043795 max memory_allocated 29273.87548828125 
[2025-03-01 19:02:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.06647699326276779 norm:0.00026382648502476513 max memory_allocated 29273.87548828125 
[2025-03-01 19:02:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.06539176404476166 norm:0.00022179383086040616 max memory_allocated 29273.87548828125 
[2025-03-01 19:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.06470493227243423 norm:0.0001990507444133982 max memory_allocated 29273.87548828125 
[2025-03-01 19:04:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.06425141543149948 norm:0.00018516677664592862 max memory_allocated 29273.87548828125 
[2025-03-01 19:05:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.06392092257738113 norm:0.00017134110385086387 max memory_allocated 29273.87548828125 
[2025-03-01 19:06:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.0637165755033493 norm:0.00016663192945998162 max memory_allocated 29273.87548828125 
[2025-03-01 19:07:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.06355476379394531 norm:0.00015747958968859166 max memory_allocated 29273.87548828125 
[2025-03-01 19:07:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.06344342976808548 norm:0.000156333640916273 max memory_allocated 29273.87548828125 
[2025-03-01 19:08:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.06333725154399872 norm:0.0001493557938374579 max memory_allocated 29273.87548828125 
[2025-03-01 19:09:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.06323347985744476 norm:0.00014353847655002028 max memory_allocated 29273.87548828125 
[2025-03-01 19:10:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.06315035372972488 norm:0.0001371716643916443 max memory_allocated 29273.87548828125 
[2025-03-01 19:11:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.06311963498592377 norm:0.0001371313410345465 max memory_allocated 29273.87548828125 
[2025-03-01 19:12:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.06303347647190094 norm:0.00013091278378851712 max memory_allocated 29273.87548828125 
[2025-03-01 19:12:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.06295305490493774 norm:0.00013164315896574408 max memory_allocated 29273.87548828125 
[2025-03-01 19:13:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.06290611624717712 norm:0.0001311191008426249 max memory_allocated 29273.87548828125 
[2025-03-01 19:14:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.06286008656024933 norm:0.00012753506598528475 max memory_allocated 29273.87548828125 
[2025-03-01 19:15:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.06284687668085098 norm:0.0001263270532945171 max memory_allocated 29273.87548828125 
[2025-03-01 19:15:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-01 19:16:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.08198586851358414 norm:0.0011123609729111195 max memory_allocated 29274.06298828125 
[2025-03-01 19:17:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.0737132653594017 norm:0.0005960713606327772 max memory_allocated 29274.06298828125 
[2025-03-01 19:18:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.06831368058919907 norm:0.0003791257622651756 max memory_allocated 29274.06298828125 
[2025-03-01 19:18:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.06656034290790558 norm:0.0002717750903684646 max memory_allocated 29274.06298828125 
[2025-03-01 19:19:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.0655226856470108 norm:0.00022795879340264946 max memory_allocated 29274.06298828125 
[2025-03-01 19:20:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.06484284996986389 norm:0.00020008812134619802 max memory_allocated 29274.06298828125 
[2025-03-01 19:21:28 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.06443268060684204 norm:0.0001818314631236717 max memory_allocated 29274.06298828125 
[2025-03-01 19:22:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.0641811415553093 norm:0.0001695698156254366 max memory_allocated 29274.06298828125 
[2025-03-01 19:23:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.0640062615275383 norm:0.00015532676479779184 max memory_allocated 29274.06298828125 
[2025-03-01 19:23:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.06387791037559509 norm:0.00014883565017953515 max memory_allocated 29274.06298828125 
[2025-03-01 19:24:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.06377210468053818 norm:0.00014249852392822504 max memory_allocated 29274.06298828125 
[2025-03-01 19:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.06369730085134506 norm:0.00014502777776215225 max memory_allocated 29274.06298828125 
[2025-03-01 19:26:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.0636342242360115 norm:0.00013904429215472192 max memory_allocated 29274.06298828125 
[2025-03-01 19:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.06357467919588089 norm:0.00013603316619992256 max memory_allocated 29274.06298828125 
[2025-03-01 19:28:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.06352691352367401 norm:0.00013302596926223487 max memory_allocated 29274.06298828125 
[2025-03-01 19:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.06350149214267731 norm:0.00013124692486599088 max memory_allocated 29274.06298828125 
[2025-03-01 19:29:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.06347717344760895 norm:0.00012820653500966728 max memory_allocated 29274.06298828125 
[2025-03-01 19:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.06346745789051056 norm:0.00013138189387973398 max memory_allocated 29274.06298828125 
[2025-03-01 19:31:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.063435398042202 norm:0.00012932826939504594 max memory_allocated 29274.06298828125 
[2025-03-01 19:32:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.06341730803251266 norm:0.00012628054537344724 max memory_allocated 29274.06298828125 
[2025-03-01 19:32:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-01 19:33:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.08083724975585938 norm:0.0007972324383445084 max memory_allocated 29274.25048828125 
[2025-03-01 19:34:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.07362855970859528 norm:0.0003791016060858965 max memory_allocated 29274.25048828125 
[2025-03-01 19:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.0691087618470192 norm:0.00024715266772545874 max memory_allocated 29274.25048828125 
[2025-03-01 19:35:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.06765063852071762 norm:0.00019360122678335756 max memory_allocated 29274.25048828125 
[2025-03-01 19:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.06672520190477371 norm:0.00016115920152515173 max memory_allocated 29274.25048828125 
[2025-03-01 19:37:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.06609836965799332 norm:0.00014137616381049156 max memory_allocated 29274.25048828125 
[2025-03-01 19:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.06568951159715652 norm:0.0001271346991416067 max memory_allocated 29274.25048828125 
[2025-03-01 19:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.06546828895807266 norm:0.00012096588761778548 max memory_allocated 29274.25048828125 
[2025-03-01 19:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.06532289832830429 norm:0.00011426360288169235 max memory_allocated 29274.25048828125 
[2025-03-01 19:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.06520158052444458 norm:0.00010746104089776054 max memory_allocated 29274.25048828125 
[2025-03-01 19:41:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.06511387974023819 norm:0.00010321309673599899 max memory_allocated 29274.25048828125 
[2025-03-01 19:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.06503981351852417 norm:0.0001008531398838386 max memory_allocated 29274.25048828125 
[2025-03-01 19:43:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.0649908035993576 norm:9.815148951020092e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.06492216885089874 norm:9.595889423508197e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.06487847119569778 norm:9.265496919397265e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:45:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.06483440846204758 norm:8.94164913916029e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.06482046842575073 norm:8.80873340065591e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.06479042023420334 norm:9.082318138098344e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:48:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.06475286185741425 norm:8.9145680249203e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.0647275447845459 norm:8.881899702828377e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:49:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-01 19:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.08298645913600922 norm:0.0006391236674971879 max memory_allocated 29274.43798828125 
[2025-03-01 19:51:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.07658159732818604 norm:0.000328702008118853 max memory_allocated 29274.43798828125 
[2025-03-01 19:51:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.07199157774448395 norm:0.00021535406995099038 max memory_allocated 29274.43798828125 
[2025-03-01 19:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.07060056179761887 norm:0.00016597090871073306 max memory_allocated 29274.43798828125 
[2025-03-01 19:53:35 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.06974447518587112 norm:0.00014430185547098517 max memory_allocated 29274.43798828125 
[2025-03-01 19:54:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.0691535472869873 norm:0.00013023585779592395 max memory_allocated 29274.43798828125 
[2025-03-01 19:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.06880085915327072 norm:0.00012241804506629705 max memory_allocated 29274.43798828125 
[2025-03-01 19:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.06856581568717957 norm:0.00011343399091856554 max memory_allocated 29274.43798828125 
[2025-03-01 19:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.06842052191495895 norm:0.00010489937994861975 max memory_allocated 29274.43798828125 
[2025-03-01 19:57:43 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.06830804795026779 norm:0.00010264967568218708 max memory_allocated 29274.43798828125 
[2025-03-01 19:58:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.06823043525218964 norm:9.764579590409994e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.06817594915628433 norm:9.607002721168101e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:00:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.06811933219432831 norm:9.262246021535248e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.0680633932352066 norm:8.863615948939696e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.06801290065050125 norm:8.929119212552905e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.06796496361494064 norm:8.629737567389384e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:03:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.06792626529932022 norm:8.37875486467965e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.06790000200271606 norm:8.211444219341502e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:05:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.06788602471351624 norm:8.245279605034739e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.06786549091339111 norm:8.240820170613006e-05 max memory_allocated 29274.43798828125 
[2025-03-01 20:06:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-01 20:07:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.08641917258501053 norm:0.0006698471261188388 max memory_allocated 29274.62548828125 
[2025-03-01 20:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.08020584285259247 norm:0.0003266204730607569 max memory_allocated 29274.62548828125 
[2025-03-01 20:08:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.07555094361305237 norm:0.00021186111553106457 max memory_allocated 29274.62548828125 
[2025-03-01 20:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.07414428144693375 norm:0.00016043907089624554 max memory_allocated 29274.62548828125 
[2025-03-01 20:10:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.07331311702728271 norm:0.00013490833225660026 max memory_allocated 29274.62548828125 
[2025-03-01 20:11:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.07267565280199051 norm:0.00012045219773426652 max memory_allocated 29274.62548828125 
[2025-03-01 20:12:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.07228786498308182 norm:0.00011096345406258479 max memory_allocated 29274.62548828125 
[2025-03-01 20:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.07208948582410812 norm:0.0001051044455380179 max memory_allocated 29274.62548828125 
[2025-03-01 20:13:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.07195772230625153 norm:9.915856935549527e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:14:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.07183900475502014 norm:9.386887541040778e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:15:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.07176700234413147 norm:9.103927004616708e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:16:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.07171837240457535 norm:8.937012898968533e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:17:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.0716424286365509 norm:8.567756594857201e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:17:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.07160875201225281 norm:8.572412480134517e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:18:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.07157392799854279 norm:8.490926120430231e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:19:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.07154586166143417 norm:8.639619045425206e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:20:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.07149337232112885 norm:8.257903391495347e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:21:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.07147184014320374 norm:8.147953485604376e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.0714443102478981 norm:8.193040412152186e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:22:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.07144241780042648 norm:8.124054147629067e-05 max memory_allocated 29274.62548828125 
[2025-03-01 20:23:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-01 20:24:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.09413863718509674 norm:0.0008371761650778353 max memory_allocated 29274.81298828125 
[2025-03-01 20:24:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.08688894659280777 norm:0.0004201193223707378 max memory_allocated 29274.81298828125 
[2025-03-01 20:25:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.08162467181682587 norm:0.00027183082420378923 max memory_allocated 29274.81298828125 
[2025-03-01 20:26:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.08012358099222183 norm:0.00020601722644641995 max memory_allocated 29274.81298828125 
[2025-03-01 20:27:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.07916395366191864 norm:0.00017396867042407393 max memory_allocated 29274.81298828125 
[2025-03-01 20:28:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.0784543976187706 norm:0.00015419081319123507 max memory_allocated 29274.81298828125 
[2025-03-01 20:29:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.07801498472690582 norm:0.0001449467963539064 max memory_allocated 29274.81298828125 
[2025-03-01 20:29:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.07778000086545944 norm:0.00013539165956899524 max memory_allocated 29274.81298828125 
[2025-03-01 20:30:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.07760996371507645 norm:0.00012757924559991807 max memory_allocated 29274.81298828125 
[2025-03-01 20:31:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.07747673988342285 norm:0.00012293725740164518 max memory_allocated 29274.81298828125 
[2025-03-01 20:32:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.07737112790346146 norm:0.00011836338671855628 max memory_allocated 29274.81298828125 
[2025-03-01 20:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.07728338241577148 norm:0.00011524875299073756 max memory_allocated 29274.81298828125 
[2025-03-01 20:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.07719819247722626 norm:0.00011190830991836265 max memory_allocated 29274.81298828125 
[2025-03-01 20:34:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.07713810354471207 norm:0.00010837324953172356 max memory_allocated 29274.81298828125 
[2025-03-01 20:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.07708321511745453 norm:0.00010667849710443988 max memory_allocated 29274.81298828125 
[2025-03-01 20:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.07703887671232224 norm:0.00010382782784290612 max memory_allocated 29274.81298828125 
[2025-03-01 20:37:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.07700714468955994 norm:0.00010225905862171203 max memory_allocated 29274.81298828125 
[2025-03-01 20:38:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.07696129381656647 norm:0.00010086739348480478 max memory_allocated 29274.81298828125 
[2025-03-01 20:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.07693213224411011 norm:0.00010137061326531693 max memory_allocated 29274.81298828125 
[2025-03-01 20:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.0769021287560463 norm:9.836000390350819e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:40:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-01 20:40:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.09736695140600204 norm:0.0005790044087916613 max memory_allocated 29275.00048828125 
[2025-03-01 20:41:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.09153086692094803 norm:0.0002869937161449343 max memory_allocated 29275.00048828125 
[2025-03-01 20:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.08675777167081833 norm:0.00017986494640354067 max memory_allocated 29275.00048828125 
[2025-03-01 20:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.08555729687213898 norm:0.00014684905181638896 max memory_allocated 29275.00048828125 
[2025-03-01 20:44:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.08474048972129822 norm:0.0001253490918315947 max memory_allocated 29275.00048828125 
[2025-03-01 20:45:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.0840924084186554 norm:0.00011494872160255909 max memory_allocated 29275.00048828125 
[2025-03-01 20:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.0836954265832901 norm:0.00010796602146001533 max memory_allocated 29275.00048828125 
[2025-03-01 20:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.08349071443080902 norm:0.00010428517998661846 max memory_allocated 29275.00048828125 
[2025-03-01 20:47:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.08334818482398987 norm:0.0001004872246994637 max memory_allocated 29275.00048828125 
[2025-03-01 20:48:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.0832483321428299 norm:9.596422023605555e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:49:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.08317957818508148 norm:9.405094897374511e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:50:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.08310620486736298 norm:9.245576075045392e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.083040252327919 norm:8.8224966020789e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:51:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.08298765867948532 norm:8.720964251551777e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:52:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.0829538032412529 norm:8.578527922509238e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:53:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.08291316032409668 norm:9.318374941358343e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:54:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.08287276327610016 norm:8.85057816049084e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.08284042775630951 norm:8.804332901490852e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.08281853049993515 norm:8.772256114752963e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:56:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.08279263973236084 norm:8.818642527330667e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:56:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-01 20:57:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.10508602857589722 norm:0.0006315202335827053 max memory_allocated 29275.18798828125 
[2025-03-01 20:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.09929709881544113 norm:0.0003422895388212055 max memory_allocated 29275.18798828125 
[2025-03-01 20:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.09427511692047119 norm:0.00019544264068827033 max memory_allocated 29275.18798828125 
[2025-03-01 21:00:18 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.09306210279464722 norm:0.0001526979322079569 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.09222342818975449 norm:0.0001333062391495332 max memory_allocated 29275.18798828125 
[2025-03-01 21:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.09151720255613327 norm:0.00011951604392379522 max memory_allocated 29275.18798828125 
[2025-03-01 21:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.09112408012151718 norm:0.00011102692224085331 max memory_allocated 29275.18798828125 
[2025-03-01 21:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.09091357886791229 norm:0.0001049391576088965 max memory_allocated 29275.18798828125 
[2025-03-01 21:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.0907813310623169 norm:0.00010158099757973105 max memory_allocated 29275.18798828125 
[2025-03-01 21:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.0906696766614914 norm:9.634959860704839e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:06:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.09056742489337921 norm:0.00026140312547795475 max memory_allocated 29275.18798828125 
[2025-03-01 21:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.09049167484045029 norm:9.029901411850005e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.09042517840862274 norm:8.74312172527425e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.09036916494369507 norm:8.654114208184183e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:09:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.09032329171895981 norm:8.378223719773814e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.09027770906686783 norm:8.326710667461157e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:11:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.0902319848537445 norm:8.23790323920548e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:11:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.090202197432518 norm:8.140251156874001e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:12:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.09017050266265869 norm:8.191453525796533e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.09014427661895752 norm:8.389178401557729e-05 max memory_allocated 29275.18798828125 
[2025-03-01 21:13:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-01 21:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.113324835896492 norm:0.0005350693827494979 max memory_allocated 29275.37548828125 
[2025-03-01 21:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.1076129674911499 norm:0.00028540819766931236 max memory_allocated 29275.37548828125 
[2025-03-01 21:16:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.10249294340610504 norm:0.0001865975500550121 max memory_allocated 29275.37548828125 
[2025-03-01 21:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.10126129537820816 norm:0.00014936027582734823 max memory_allocated 29275.37548828125 
[2025-03-01 21:18:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.10035296529531479 norm:0.0001298165152547881 max memory_allocated 29275.37548828125 
[2025-03-01 21:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.09964803606271744 norm:0.00011725829972419888 max memory_allocated 29275.37548828125 
[2025-03-01 21:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.0992857813835144 norm:0.0001142566034104675 max memory_allocated 29275.37548828125 
[2025-03-01 21:20:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.09911118447780609 norm:0.00010916760220425203 max memory_allocated 29275.37548828125 
[2025-03-01 21:21:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.09899239987134933 norm:0.00010455124720465392 max memory_allocated 29275.37548828125 
[2025-03-01 21:22:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.09890607744455338 norm:0.00010394234413979575 max memory_allocated 29275.37548828125 
[2025-03-01 21:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.09882210195064545 norm:9.98099276330322e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:23:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.09875591099262238 norm:9.469182987231761e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:24:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.09869290143251419 norm:9.364391735289246e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:25:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.09863041341304779 norm:9.350074105896056e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:26:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.09859460592269897 norm:0.00010006741649704054 max memory_allocated 29275.37548828125 
[2025-03-01 21:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.09854879230260849 norm:0.00010163639672100544 max memory_allocated 29275.37548828125 
[2025-03-01 21:27:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.09851939976215363 norm:9.957452857634053e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:28:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.09849132597446442 norm:9.764950664248317e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.09845471382141113 norm:9.833362128119916e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.09843171387910843 norm:9.857404802460223e-05 max memory_allocated 29275.37548828125 
[2025-03-01 21:30:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-01 21:31:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.12320388853549957 norm:0.0005275849835015833 max memory_allocated 29275.56298828125 
[2025-03-01 21:32:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.1172838807106018 norm:0.00028467189986258745 max memory_allocated 29275.56298828125 
[2025-03-01 21:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.11182035505771637 norm:0.00018699339125305414 max memory_allocated 29275.56298828125 
[2025-03-01 21:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.1105416864156723 norm:0.00014626479241997004 max memory_allocated 29275.56298828125 
[2025-03-01 21:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.10960747301578522 norm:0.0001232301292475313 max memory_allocated 29275.56298828125 
[2025-03-01 21:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.10889381915330887 norm:0.00011197041749255732 max memory_allocated 29275.56298828125 
[2025-03-01 21:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.10853496938943863 norm:0.00011445322161307558 max memory_allocated 29275.56298828125 
[2025-03-01 21:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.10834559053182602 norm:9.566231165081263e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:38:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.10821118950843811 norm:9.180835331790149e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.10810672491788864 norm:9.002736624097452e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:39:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.10802078992128372 norm:8.664499910082668e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.10794626921415329 norm:8.576079562772065e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.10788117349147797 norm:8.300546323880553e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.10782204568386078 norm:8.041993714869022e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:43:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.10777151584625244 norm:7.950313010951504e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:44:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.10771103203296661 norm:7.821311010047793e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:44:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.1076769009232521 norm:7.633188215550035e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.10763926059007645 norm:7.5053634645883e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:46:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.10761166363954544 norm:7.56328518036753e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:47:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.10757366567850113 norm:7.498831837438047e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:47:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-01 21:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.13555507361888885 norm:0.0005742672947235405 max memory_allocated 29275.75048828125 
[2025-03-01 21:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.12922856211662292 norm:0.00032870855648070574 max memory_allocated 29275.75048828125 
[2025-03-01 21:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.12337218970060349 norm:0.0002133490634150803 max memory_allocated 29275.75048828125 
[2025-03-01 21:50:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.12186749279499054 norm:0.00016654252249281853 max memory_allocated 29275.75048828125 
[2025-03-01 21:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.12075769901275635 norm:0.00013952681911177933 max memory_allocated 29275.75048828125 
[2025-03-01 21:52:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.11998703330755234 norm:0.00012968634837307036 max memory_allocated 29275.75048828125 
[2025-03-01 21:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.11962737888097763 norm:0.00011867082503158599 max memory_allocated 29275.75048828125 
[2025-03-01 21:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.11944293975830078 norm:0.00011273742711637169 max memory_allocated 29275.75048828125 
[2025-03-01 21:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.11930645257234573 norm:0.00010892513091675937 max memory_allocated 29275.75048828125 
[2025-03-01 21:55:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.11920478940010071 norm:0.00010688294423744082 max memory_allocated 29275.75048828125 
[2025-03-01 21:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.11911161988973618 norm:0.00010613285121507943 max memory_allocated 29275.75048828125 
[2025-03-01 21:57:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.1190337985754013 norm:0.00010527912672841921 max memory_allocated 29275.75048828125 
[2025-03-01 21:58:25 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.1189732700586319 norm:0.00010632524208631366 max memory_allocated 29275.75048828125 
[2025-03-01 21:59:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.11890321969985962 norm:0.00010154874325962737 max memory_allocated 29275.75048828125 
[2025-03-01 22:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.11885327100753784 norm:0.00010148570436285809 max memory_allocated 29275.75048828125 
[2025-03-01 22:00:54 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.11880841106176376 norm:0.0001001440396066755 max memory_allocated 29275.75048828125 
[2025-03-01 22:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.11876881122589111 norm:0.00010052818106487393 max memory_allocated 29275.75048828125 
[2025-03-01 22:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.1187315359711647 norm:0.00010086990369018167 max memory_allocated 29275.75048828125 
[2025-03-01 22:03:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.11870338022708893 norm:0.00010186073632212356 max memory_allocated 29275.75048828125 
[2025-03-01 22:04:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.11866046488285065 norm:9.797119855647907e-05 max memory_allocated 29275.75048828125 
[2025-03-01 22:04:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-01 22:05:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.14572501182556152 norm:0.0003669221478048712 max memory_allocated 29275.93798828125 
[2025-03-01 22:06:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.13969619572162628 norm:0.000221467184019275 max memory_allocated 29275.93798828125 
[2025-03-01 22:07:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.13385602831840515 norm:0.0001532640162622556 max memory_allocated 29275.93798828125 
[2025-03-01 22:07:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.13248354196548462 norm:0.0001279703719774261 max memory_allocated 29275.93798828125 
[2025-03-01 22:08:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.13145485520362854 norm:0.00011506658483995125 max memory_allocated 29275.93798828125 
[2025-03-01 22:09:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.13073411583900452 norm:0.00010457731696078554 max memory_allocated 29275.93798828125 
[2025-03-01 22:10:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.1304396092891693 norm:9.979459719033912e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.13025134801864624 norm:9.439344285055995e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:12:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.13011057674884796 norm:8.945430454332381e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:12:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.1300010085105896 norm:8.845517731970176e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:13:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.12989889085292816 norm:8.958662510849535e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.12982144951820374 norm:8.632206299807876e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:15:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.12974074482917786 norm:8.75376135809347e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:16:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.12966971099376678 norm:0.00011432266182964668 max memory_allocated 29275.93798828125 
[2025-03-01 22:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.1296057254076004 norm:8.249874372268096e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:17:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.12955091893672943 norm:8.139899000525475e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.12950047850608826 norm:8.489619358442724e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:19:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.1294560730457306 norm:8.341334614669904e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:20:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.1294167935848236 norm:8.17369218566455e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.12937507033348083 norm:8.009203156689182e-05 max memory_allocated 29275.93798828125 
[2025-03-01 22:21:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-01 22:22:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.16046291589736938 norm:0.0006739043747074902 max memory_allocated 29276.12548828125 
[2025-03-01 22:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.15379375219345093 norm:0.00040407333290204406 max memory_allocated 29276.12548828125 
[2025-03-01 22:23:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.1475425660610199 norm:0.00025914626894518733 max memory_allocated 29276.12548828125 
[2025-03-01 22:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.14591658115386963 norm:0.00019768933998420835 max memory_allocated 29276.12548828125 
[2025-03-01 22:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.1446867287158966 norm:0.00017096752708312124 max memory_allocated 29276.12548828125 
[2025-03-01 22:26:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.14390479028224945 norm:0.0001477688056183979 max memory_allocated 29276.12548828125 
[2025-03-01 22:27:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.14360502362251282 norm:0.00013983796816319227 max memory_allocated 29276.12548828125 
[2025-03-01 22:28:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.1434262990951538 norm:0.000130970380268991 max memory_allocated 29276.12548828125 
[2025-03-01 22:28:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.1432959884405136 norm:0.00012653229350689799 max memory_allocated 29276.12548828125 
[2025-03-01 22:29:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.14317470788955688 norm:0.00012165102816652507 max memory_allocated 29276.12548828125 
[2025-03-01 22:30:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.14307865500450134 norm:0.00012111237447243184 max memory_allocated 29276.12548828125 
[2025-03-01 22:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.14298579096794128 norm:0.00011678942973958328 max memory_allocated 29276.12548828125 
[2025-03-01 22:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.14292559027671814 norm:0.00011930800974369049 max memory_allocated 29276.12548828125 
[2025-03-01 22:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.1428551971912384 norm:0.00011316203745082021 max memory_allocated 29276.12548828125 
[2025-03-01 22:33:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.14279164373874664 norm:0.00011131217615911737 max memory_allocated 29276.12548828125 
[2025-03-01 22:34:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.14275236427783966 norm:0.0001131762401200831 max memory_allocated 29276.12548828125 
[2025-03-01 22:35:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.14270202815532684 norm:0.00011555141827557236 max memory_allocated 29276.12548828125 
[2025-03-01 22:36:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.1426468938589096 norm:0.00010655207734089345 max memory_allocated 29276.12548828125 
[2025-03-01 22:37:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.142616406083107 norm:0.00011478542000986636 max memory_allocated 29276.12548828125 
[2025-03-01 22:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.1425739973783493 norm:0.00010988327267114073 max memory_allocated 29276.12548828125 
[2025-03-01 22:38:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-01 22:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.1740931123495102 norm:0.000508055672980845 max memory_allocated 29276.31298828125 
[2025-03-01 22:39:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.1673874706029892 norm:0.0002962629951070994 max memory_allocated 29276.31298828125 
[2025-03-01 22:40:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.1610092967748642 norm:0.00019649227033369243 max memory_allocated 29276.31298828125 
[2025-03-01 22:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.1594449281692505 norm:0.00015519985754508525 max memory_allocated 29276.31298828125 
[2025-03-01 22:42:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.15824714303016663 norm:0.00013069761916995049 max memory_allocated 29276.31298828125 
[2025-03-01 22:43:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.15757235884666443 norm:0.00011558798723854125 max memory_allocated 29276.31298828125 
[2025-03-01 22:44:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.15728506445884705 norm:0.00010636345541570336 max memory_allocated 29276.31298828125 
[2025-03-01 22:44:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.1571042388677597 norm:0.00010090266005136073 max memory_allocated 29276.31298828125 
[2025-03-01 22:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.15695618093013763 norm:9.354608482681215e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:46:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.15683841705322266 norm:9.064813639270142e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.1567423790693283 norm:8.761371282162145e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:48:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.15665966272354126 norm:8.627720671938732e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:49:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.15658651292324066 norm:8.58249914017506e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.15651610493659973 norm:8.305008668685332e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.15645822882652283 norm:8.561953291064128e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:51:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.1563994437456131 norm:8.448831795249134e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:52:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.15635617077350616 norm:8.295704174088314e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.156304270029068 norm:8.38872219901532e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.15627124905586243 norm:8.277567394543439e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.1562330722808838 norm:8.192482346203178e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:55:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-01 22:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.19267763197422028 norm:0.000621714920271188 max memory_allocated 29276.50048828125 
[2025-03-01 22:56:52 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.1844971477985382 norm:0.0003335137153044343 max memory_allocated 29276.50048828125 
[2025-03-01 22:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.17688341438770294 norm:0.00020286637300159782 max memory_allocated 29276.50048828125 
[2025-03-01 22:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.17499138414859772 norm:0.0001593370398040861 max memory_allocated 29276.50048828125 
[2025-03-01 22:59:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.17371703684329987 norm:0.00013667275197803974 max memory_allocated 29276.50048828125 
[2025-03-01 23:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.17308686673641205 norm:0.00017540880071464926 max memory_allocated 29276.50048828125 
[2025-03-01 23:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.17280757427215576 norm:0.00011385147809050977 max memory_allocated 29276.50048828125 
[2025-03-01 23:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.1726250946521759 norm:0.00010771922825369984 max memory_allocated 29276.50048828125 
[2025-03-01 23:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.17245496809482574 norm:0.0001025449309963733 max memory_allocated 29276.50048828125 
[2025-03-01 23:03:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.17232683300971985 norm:9.923153993440792e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.17220190167427063 norm:9.632146975491196e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.17211323976516724 norm:9.667328413343057e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.17202383279800415 norm:9.181742643704638e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.17193961143493652 norm:9.070165106095374e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:07:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.17187553644180298 norm:9.0240610006731e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:08:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.17180784046649933 norm:8.832800813252106e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:09:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.17175273597240448 norm:8.773676381679252e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:10:08 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.17170369625091553 norm:8.864791016094387e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:10:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.17165479063987732 norm:8.93758624442853e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:11:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.17161360383033752 norm:8.801611693343148e-05 max memory_allocated 29276.50048828125 
[2025-03-01 23:12:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-01 23:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.20887987315654755 norm:0.000599631282966584 max memory_allocated 29276.68798828125 
[2025-03-01 23:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.20097118616104126 norm:0.0003337479429319501 max memory_allocated 29276.68798828125 
[2025-03-01 23:14:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.19329698383808136 norm:0.00019800216250587255 max memory_allocated 29276.68798828125 
[2025-03-01 23:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.19132551550865173 norm:0.00015481346054002643 max memory_allocated 29276.68798828125 
[2025-03-01 23:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.19005295634269714 norm:0.00013187696458771825 max memory_allocated 29276.68798828125 
[2025-03-01 23:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.189509317278862 norm:0.0001189477916341275 max memory_allocated 29276.68798828125 
[2025-03-01 23:17:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.18927177786827087 norm:0.000111021327029448 max memory_allocated 29276.68798828125 
[2025-03-01 23:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.18911199271678925 norm:0.00010589599696686491 max memory_allocated 29276.68798828125 
[2025-03-01 23:19:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.18899324536323547 norm:0.00010450643458170816 max memory_allocated 29276.68798828125 
[2025-03-01 23:20:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.1888716220855713 norm:0.00010044695227406919 max memory_allocated 29276.68798828125 
[2025-03-01 23:21:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.18875697255134583 norm:0.000101947553048376 max memory_allocated 29276.68798828125 
[2025-03-01 23:22:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.1886589676141739 norm:9.884640167001635e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:22:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.18855680525302887 norm:9.885108011076227e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:23:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.1884729564189911 norm:0.0001000944830593653 max memory_allocated 29276.68798828125 
[2025-03-01 23:24:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.1883998066186905 norm:9.781536209629849e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.18833884596824646 norm:9.94362126220949e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:26:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.1882827877998352 norm:9.628569387132302e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:27:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.1882341504096985 norm:9.746103751240298e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:27:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.1881905496120453 norm:9.606337698642164e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:28:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.18814170360565186 norm:9.659387433202937e-05 max memory_allocated 29276.68798828125 
[2025-03-01 23:28:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-01 23:29:49 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.2297998070716858 norm:0.0007277530385181308 max memory_allocated 29276.87548828125 
[2025-03-01 23:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.220846489071846 norm:0.000384773884434253 max memory_allocated 29276.87548828125 
[2025-03-01 23:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.21254152059555054 norm:0.00023175198293756694 max memory_allocated 29276.87548828125 
[2025-03-01 23:32:18 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.2102690041065216 norm:0.0001785552012734115 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.20890004932880402 norm:0.00015095260459929705 max memory_allocated 29276.87548828125 
[2025-03-01 23:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.2083326131105423 norm:0.00013604570995084941 max memory_allocated 29276.87548828125 
[2025-03-01 23:34:47 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.20804022252559662 norm:0.00012822046119254082 max memory_allocated 29276.87548828125 
[2025-03-01 23:35:37 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.20781837403774261 norm:0.00012216964387334883 max memory_allocated 29276.87548828125 
[2025-03-01 23:36:26 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.20766238868236542 norm:0.0001170970281236805 max memory_allocated 29276.87548828125 
[2025-03-01 23:37:16 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.20751094818115234 norm:0.00011023426486644894 max memory_allocated 29276.87548828125 
[2025-03-01 23:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.20739352703094482 norm:0.00010699628182919696 max memory_allocated 29276.87548828125 
[2025-03-01 23:38:55 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.20729155838489532 norm:0.00010339100117562339 max memory_allocated 29276.87548828125 
[2025-03-01 23:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.20719954371452332 norm:0.00010141610255232081 max memory_allocated 29276.87548828125 
[2025-03-01 23:40:35 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.2071022391319275 norm:9.936158312484622e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:41:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.20701324939727783 norm:9.813124052016065e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:42:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.20694801211357117 norm:9.71091867540963e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.20689502358436584 norm:9.732838225318119e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:43:54 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.20683017373085022 norm:9.565172513248399e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:44:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.206780344247818 norm:9.791713091544807e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:45:33 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.20673464238643646 norm:9.887693886412308e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:45:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-01 23:46:41 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.25057315826416016 norm:0.0005996568943373859 max memory_allocated 29277.06298828125 
[2025-03-01 23:47:31 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.24105951189994812 norm:0.00034712240449152887 max memory_allocated 29277.06298828125 
[2025-03-01 23:48:21 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.23217104375362396 norm:0.00021081193699501455 max memory_allocated 29277.06298828125 
[2025-03-01 23:49:11 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.22986678779125214 norm:0.00015876196266617626 max memory_allocated 29277.06298828125 
[2025-03-01 23:50:00 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.22853019833564758 norm:0.00014064015704207122 max memory_allocated 29277.06298828125 
[2025-03-01 23:50:50 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.2280379831790924 norm:0.00013413662964012474 max memory_allocated 29277.06298828125 
[2025-03-01 23:51:40 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.22768965363502502 norm:0.00012986274668946862 max memory_allocated 29277.06298828125 
[2025-03-01 23:52:29 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.22749388217926025 norm:0.00012259581126272678 max memory_allocated 29277.06298828125 
[2025-03-01 23:53:19 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.22733451426029205 norm:0.00012013753439532593 max memory_allocated 29277.06298828125 
[2025-03-01 23:54:09 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.2271878868341446 norm:0.00011872393952216953 max memory_allocated 29277.06298828125 
[2025-03-01 23:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.22707603871822357 norm:0.00011651423847069964 max memory_allocated 29277.06298828125 
[2025-03-01 23:55:48 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.22694547474384308 norm:0.00011535886733327061 max memory_allocated 29277.06298828125 
[2025-03-01 23:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.22685173153877258 norm:0.00011452780745457858 max memory_allocated 29277.06298828125 
[2025-03-01 23:57:28 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.22677496075630188 norm:0.00011266588990110904 max memory_allocated 29277.06298828125 
[2025-03-01 23:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.22669973969459534 norm:0.00011194334365427494 max memory_allocated 29277.06298828125 
[2025-03-01 23:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.2266227751970291 norm:0.00010994946933351457 max memory_allocated 29277.06298828125 
[2025-03-01 23:59:57 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.22655150294303894 norm:0.00011039833771064878 max memory_allocated 29277.06298828125 
[2025-03-02 00:00:47 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.22650721669197083 norm:0.00011118432303192094 max memory_allocated 29277.06298828125 
[2025-03-02 00:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.22647400200366974 norm:0.0001106638228520751 max memory_allocated 29277.06298828125 
[2025-03-02 00:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.22642025351524353 norm:0.0001090614459826611 max memory_allocated 29277.06298828125 
[2025-03-02 00:02:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 00:03:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.2770995795726776 norm:0.0006862487061880529 max memory_allocated 29277.25048828125 
[2025-03-02 00:04:24 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.2664787173271179 norm:0.00036450865445658565 max memory_allocated 29277.25048828125 
[2025-03-02 00:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.2573069632053375 norm:0.00023609933850821108 max memory_allocated 29277.25048828125 
[2025-03-02 00:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.254668653011322 norm:0.00019015172438230366 max memory_allocated 29277.25048828125 
[2025-03-02 00:06:53 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.25320005416870117 norm:0.0001677306863712147 max memory_allocated 29277.25048828125 
[2025-03-02 00:07:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.2526276111602783 norm:0.00015343428822234273 max memory_allocated 29277.25048828125 
[2025-03-02 00:08:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.2522773742675781 norm:0.00014740342157892883 max memory_allocated 29277.25048828125 
[2025-03-02 00:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.2519984245300293 norm:0.00014072435442358255 max memory_allocated 29277.25048828125 
[2025-03-02 00:10:12 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.25174662470817566 norm:0.00013239652616903186 max memory_allocated 29277.25048828125 
[2025-03-02 00:11:02 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.25154945254325867 norm:0.0001273994130315259 max memory_allocated 29277.25048828125 
[2025-03-02 00:11:52 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.2513771653175354 norm:0.00012281516683287919 max memory_allocated 29277.25048828125 
[2025-03-02 00:12:41 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.2512354254722595 norm:0.00012472024536691606 max memory_allocated 29277.25048828125 
[2025-03-02 00:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.25111228227615356 norm:0.0001205250810016878 max memory_allocated 29277.25048828125 
[2025-03-02 00:14:21 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.25098320841789246 norm:0.0001148250958067365 max memory_allocated 29277.25048828125 
[2025-03-02 00:15:11 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.25085964798927307 norm:0.00011298072058707476 max memory_allocated 29277.25048828125 
[2025-03-02 00:16:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.2507743835449219 norm:0.00011380326759535819 max memory_allocated 29277.25048828125 
[2025-03-02 00:16:50 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.2506971061229706 norm:0.00011456193897174671 max memory_allocated 29277.25048828125 
[2025-03-02 00:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.25061655044555664 norm:0.00011300980258965865 max memory_allocated 29277.25048828125 
[2025-03-02 00:18:30 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.25054484605789185 norm:0.00011288457608316094 max memory_allocated 29277.25048828125 
[2025-03-02 00:19:19 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.2504739761352539 norm:0.00010619276872603223 max memory_allocated 29277.25048828125 
[2025-03-02 00:19:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 00:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.3047867715358734 norm:0.0011146937031298876 max memory_allocated 29277.43798828125 
[2025-03-02 00:21:17 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.29341328144073486 norm:0.0005923793651163578 max memory_allocated 29277.43798828125 
[2025-03-02 00:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.28350040316581726 norm:0.00036509858909994364 max memory_allocated 29277.43798828125 
[2025-03-02 00:22:57 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.2805453836917877 norm:0.0002606578345876187 max memory_allocated 29277.43798828125 
[2025-03-02 00:23:47 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.27912336587905884 norm:0.00020519293320830911 max memory_allocated 29277.43798828125 
[2025-03-02 00:24:36 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.27857357263565063 norm:0.00017440205556340516 max memory_allocated 29277.43798828125 
[2025-03-02 00:25:26 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.2782348096370697 norm:0.00015478447312489152 max memory_allocated 29277.43798828125 
[2025-03-02 00:26:16 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.27797430753707886 norm:0.00014101367560215294 max memory_allocated 29277.43798828125 
[2025-03-02 00:27:05 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.27777308225631714 norm:0.0001348994264844805 max memory_allocated 29277.43798828125 
[2025-03-02 00:27:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.27757999300956726 norm:0.00012848625192418694 max memory_allocated 29277.43798828125 
[2025-03-02 00:28:45 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.2774241864681244 norm:0.0001243484002770856 max memory_allocated 29277.43798828125 
[2025-03-02 00:29:34 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.2772678732872009 norm:0.00012010998761979863 max memory_allocated 29277.43798828125 
[2025-03-02 00:30:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.277138888835907 norm:0.00011768225522246212 max memory_allocated 29277.43798828125 
[2025-03-02 00:31:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.27703922986984253 norm:0.00011624107719399035 max memory_allocated 29277.43798828125 
[2025-03-02 00:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.27692803740501404 norm:0.00011429499863879755 max memory_allocated 29277.43798828125 
[2025-03-02 00:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.2768274247646332 norm:0.00011344670929247513 max memory_allocated 29277.43798828125 
[2025-03-02 00:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.27674075961112976 norm:0.00011252258263994008 max memory_allocated 29277.43798828125 
[2025-03-02 00:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.2766595482826233 norm:0.00011134942178614438 max memory_allocated 29277.43798828125 
[2025-03-02 00:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.27658140659332275 norm:0.00011083701247116551 max memory_allocated 29277.43798828125 
[2025-03-02 00:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.2765147387981415 norm:0.00011113441723864526 max memory_allocated 29277.43798828125 
[2025-03-02 00:36:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 00:36:31 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.3424528241157532 norm:0.009094319306313992 max memory_allocated 29277.77001953125 
[2025-03-02 00:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.3281489908695221 norm:0.007066028192639351 max memory_allocated 29277.77001953125 
[2025-03-02 00:39:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.3164820373058319 norm:0.005221470724791288 max memory_allocated 29277.77001953125 
[2025-03-02 00:39:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.31288084387779236 norm:0.004373377189040184 max memory_allocated 29277.77001953125 
[2025-03-02 00:40:40 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.31115058064460754 norm:0.003592831315472722 max memory_allocated 29277.77001953125 
[2025-03-02 00:41:30 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.3104320764541626 norm:0.0029846588149666786 max memory_allocated 29277.77001953125 
[2025-03-02 00:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.30994659662246704 norm:0.002664037048816681 max memory_allocated 29277.77001953125 
[2025-03-02 00:43:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.309636652469635 norm:0.002610917901620269 max memory_allocated 29277.77001953125 
[2025-03-02 00:43:59 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.30936264991760254 norm:0.0024772321339696646 max memory_allocated 29277.77001953125 
[2025-03-02 00:44:49 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.30910512804985046 norm:0.0023821815848350525 max memory_allocated 29277.77001953125 
[2025-03-02 00:45:39 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.30885791778564453 norm:0.0022566940169781446 max memory_allocated 29277.77001953125 
[2025-03-02 00:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.30869317054748535 norm:0.0021410142071545124 max memory_allocated 29277.77001953125 
[2025-03-02 00:47:19 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.30848604440689087 norm:0.0021266373805701733 max memory_allocated 29277.77001953125 
[2025-03-02 00:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.30833086371421814 norm:0.0020219674333930016 max memory_allocated 29277.77001953125 
[2025-03-02 00:48:58 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.3081602156162262 norm:0.0020199501886963844 max memory_allocated 29277.77001953125 
[2025-03-02 00:49:48 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.30805128812789917 norm:0.0019645816646516323 max memory_allocated 29277.77001953125 
[2025-03-02 00:50:38 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.30789926648139954 norm:0.0019229694735258818 max memory_allocated 29277.77001953125 
[2025-03-02 00:51:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.3077988028526306 norm:0.001877074595540762 max memory_allocated 29277.77001953125 
[2025-03-02 00:52:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.3076898157596588 norm:0.0018016622634604573 max memory_allocated 29277.77001953125 
[2025-03-02 00:53:08 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.3075791001319885 norm:0.0018033154774457216 max memory_allocated 29277.77001953125 
[2025-03-02 00:53:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 00:53:26 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.3822406232357025 norm:0.009567324072122574 max memory_allocated 29277.95751953125 
[2025-03-02 00:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.3662164807319641 norm:0.007319572381675243 max memory_allocated 29277.95751953125 
[2025-03-02 00:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.352414071559906 norm:0.005286604166030884 max memory_allocated 29277.95751953125 
[2025-03-02 00:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.3481437563896179 norm:0.004456514958292246 max memory_allocated 29277.95751953125 
[2025-03-02 00:57:35 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.3463937044143677 norm:0.00371084944345057 max memory_allocated 29277.95751953125 
[2025-03-02 00:58:25 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.34560608863830566 norm:0.0031144595704972744 max memory_allocated 29277.95751953125 
[2025-03-02 00:59:15 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.3450513482093811 norm:0.002739925403147936 max memory_allocated 29277.95751953125 
[2025-03-02 01:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.3446790874004364 norm:0.0025718773249536753 max memory_allocated 29277.95751953125 
[2025-03-02 01:00:54 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.3445119857788086 norm:0.0026292481925338507 max memory_allocated 29277.95751953125 
[2025-03-02 01:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.3441922664642334 norm:0.0023961132392287254 max memory_allocated 29277.95751953125 
[2025-03-02 01:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.3439030051231384 norm:0.0022149025462567806 max memory_allocated 29277.95751953125 
[2025-03-02 01:03:24 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.34374839067459106 norm:0.0022277154494076967 max memory_allocated 29277.95751953125 
[2025-03-02 01:04:14 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.3436430096626282 norm:0.0023287045769393444 max memory_allocated 29277.95751953125 
[2025-03-02 01:05:04 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.34348341822624207 norm:0.0021628199610859156 max memory_allocated 29277.95751953125 
[2025-03-02 01:05:54 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.3433821499347687 norm:0.002245755633339286 max memory_allocated 29277.95751953125 
[2025-03-02 01:06:43 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.3433295786380768 norm:0.002230239799246192 max memory_allocated 29277.95751953125 
[2025-03-02 01:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.3431992530822754 norm:0.0022356626577675343 max memory_allocated 29277.95751953125 
[2025-03-02 01:08:23 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.34301358461380005 norm:0.0020812712609767914 max memory_allocated 29277.95751953125 
[2025-03-02 01:09:13 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.34298670291900635 norm:0.0020997151732444763 max memory_allocated 29277.95751953125 
[2025-03-02 01:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.3429781198501587 norm:0.0021539279259741306 max memory_allocated 29277.95751953125 
[2025-03-02 01:10:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 01:10:21 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:11:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.45119422674179077 norm:0.013242676854133606 max memory_allocated 29278.14501953125 
[2025-03-02 01:12:01 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.4321724474430084 norm:0.005279414355754852 max memory_allocated 29278.14501953125 
[2025-03-02 01:12:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.413100928068161 norm:0.004485161509364843 max memory_allocated 29278.14501953125 
[2025-03-02 01:13:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.40741297602653503 norm:0.004544675350189209 max memory_allocated 29278.14501953125 
[2025-03-02 01:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.40523433685302734 norm:0.004452692344784737 max memory_allocated 29278.14501953125 
[2025-03-02 01:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.4043826460838318 norm:0.004379257559776306 max memory_allocated 29278.14501953125 
[2025-03-02 01:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.4036729335784912 norm:0.004345787223428488 max memory_allocated 29278.14501953125 
[2025-03-02 01:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.40295347571372986 norm:0.004132869653403759 max memory_allocated 29278.14501953125 
[2025-03-02 01:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.40266138315200806 norm:0.004191132728010416 max memory_allocated 29278.14501953125 
[2025-03-02 01:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.4023417532444 norm:0.004387468099594116 max memory_allocated 29278.14501953125 
[2025-03-02 01:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.40214240550994873 norm:0.004376912489533424 max memory_allocated 29278.14501953125 
[2025-03-02 01:20:19 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.40192848443984985 norm:0.004420984070748091 max memory_allocated 29278.14501953125 
[2025-03-02 01:21:09 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.40159866213798523 norm:0.004497080110013485 max memory_allocated 29278.14501953125 
[2025-03-02 01:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.4012702703475952 norm:0.004759022034704685 max memory_allocated 29278.14501953125 
[2025-03-02 01:22:49 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.40123164653778076 norm:0.005220221355557442 max memory_allocated 29278.14501953125 
[2025-03-02 01:23:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.40088072419166565 norm:0.005318352486938238 max memory_allocated 29278.14501953125 
[2025-03-02 01:24:29 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.40067535638809204 norm:0.005301797762513161 max memory_allocated 29278.14501953125 
[2025-03-02 01:25:19 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.4005066156387329 norm:0.005350916180759668 max memory_allocated 29278.14501953125 
[2025-03-02 01:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.4005380868911743 norm:0.005500278435647488 max memory_allocated 29278.14501953125 
[2025-03-02 01:26:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.40024805068969727 norm:0.005418216809630394 max memory_allocated 29278.14501953125 
[2025-03-02 01:27:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 01:27:17 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 01:28:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.6150485277175903 norm:0.03883157670497894 max memory_allocated 29278.33251953125 
[2025-03-02 01:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.5730297565460205 norm:0.021337298676371574 max memory_allocated 29278.33251953125 
[2025-03-02 01:29:47 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.5523566007614136 norm:0.014682359993457794 max memory_allocated 29278.33251953125 
[2025-03-02 01:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.5404001474380493 norm:0.01252274215221405 max memory_allocated 29278.33251953125 
[2025-03-02 01:31:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.5332697629928589 norm:0.011374911293387413 max memory_allocated 29278.33251953125 
[2025-03-02 01:32:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.5291692614555359 norm:0.010667732916772366 max memory_allocated 29278.33251953125 
[2025-03-02 01:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.5265107154846191 norm:0.0102736447006464 max memory_allocated 29278.33251953125 
[2025-03-02 01:33:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.5247550010681152 norm:0.009678572416305542 max memory_allocated 29278.33251953125 
[2025-03-02 01:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.5230383276939392 norm:0.009386793710291386 max memory_allocated 29278.33251953125 
[2025-03-02 01:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.5216785073280334 norm:0.00955876149237156 max memory_allocated 29278.33251953125 
[2025-03-02 01:36:25 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.5211307406425476 norm:0.009230267256498337 max memory_allocated 29278.33251953125 
[2025-03-02 01:37:15 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.5200257301330566 norm:0.009407120756804943 max memory_allocated 29278.33251953125 
[2025-03-02 01:38:05 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.5196510553359985 norm:0.009047740139067173 max memory_allocated 29278.33251953125 
[2025-03-02 01:38:55 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.5196101069450378 norm:0.010043052025139332 max memory_allocated 29278.33251953125 
[2025-03-02 01:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.519619345664978 norm:0.009773223660886288 max memory_allocated 29278.33251953125 
[2025-03-02 01:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.5190212726593018 norm:0.009443726390600204 max memory_allocated 29278.33251953125 
[2025-03-02 01:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.5190137028694153 norm:0.009633821435272694 max memory_allocated 29278.33251953125 
[2025-03-02 01:42:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.5185108780860901 norm:0.009118331596255302 max memory_allocated 29278.33251953125 
[2025-03-02 01:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.5181698799133301 norm:0.008859585039317608 max memory_allocated 29278.33251953125 
[2025-03-02 01:43:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.5172470808029175 norm:0.008585205301642418 max memory_allocated 29278.33251953125 
[2025-03-02 01:44:08 root] (main_calib_config2.py 380): INFO 40545.70202469826
[2025-03-02 01:44:23 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-02 01:46:20 root] (main_calib_config2.py 159): INFO wikitext2 : 5.086357116699219
[2025-03-02 01:46:20 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-02 01:49:22 root] (main_calib_config2.py 159): INFO c4 : 6.763779640197754
