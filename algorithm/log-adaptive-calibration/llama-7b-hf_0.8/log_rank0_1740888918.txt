[2025-03-02 04:15:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.8', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.8.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 04:16:52 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 04:16:52 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.8.pkl
[2025-03-02 04:16:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 04:16:57 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:17:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.003714621299877763 norm:0.004499450325965881 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0023765601217746735 norm:0.003566259751096368 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.002048582537099719 norm:0.0029273475520312786 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0018676151521503925 norm:0.002399195684120059 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0017051511676982045 norm:0.0019264296861365438 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0016407464863732457 norm:0.0016486435197293758 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0015949902590364218 norm:0.0014125477755442262 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0015458478592336178 norm:0.0011978513794019818 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0015071083325892687 norm:0.001053130836226046 max memory_allocated 22559.10693359375 
[2025-03-02 04:22:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.001487157540395856 norm:0.0009166565141640604 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0014711701078340411 norm:0.0008340857457369566 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0014549334300681949 norm:0.0007410826510749757 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0014356186147779226 norm:0.0006717179785482585 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0014292444102466106 norm:0.0006273600156418979 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001431346987374127 norm:0.0006152974092401564 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.001427703071385622 norm:0.0005849546869285405 max memory_allocated 22559.10693359375 
[2025-03-02 04:26:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0014132729265838861 norm:0.0005380155052989721 max memory_allocated 22559.10693359375 
[2025-03-02 04:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0014020409435033798 norm:0.0005237672012299299 max memory_allocated 22559.10693359375 
[2025-03-02 04:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0014083876740187407 norm:0.0005081385024823248 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.001395556377246976 norm:0.0004976550699211657 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 04:28:12 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.013256669044494629 norm:0.014544591307640076 max memory_allocated 22559.27880859375 
[2025-03-02 04:29:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.007241734303534031 norm:0.008839314803481102 max memory_allocated 22559.27880859375 
[2025-03-02 04:29:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.005935422144830227 norm:0.0053352839313447475 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.005495008081197739 norm:0.004278754349797964 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.005250635091215372 norm:0.0038987542502582073 max memory_allocated 22559.27880859375 
[2025-03-02 04:31:32 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.00507868267595768 norm:0.0034929378889501095 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.004971737507730722 norm:0.003232267452403903 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.0048822807148098946 norm:0.0029362747445702553 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.004805878736078739 norm:0.0027129463851451874 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:45 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.00469968281686306 norm:0.002448747865855694 max memory_allocated 22559.27880859375 
[2025-03-02 04:34:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.004708575084805489 norm:0.0022844746708869934 max memory_allocated 22559.27880859375 
[2025-03-02 04:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.004704316146671772 norm:0.002027912298217416 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:24 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.0047081755474209785 norm:0.0018327359575778246 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.004642227664589882 norm:0.0016016141744330525 max memory_allocated 22559.27880859375 
[2025-03-02 04:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.004594235215336084 norm:0.0014218639116734266 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.004605771973729134 norm:0.0012529751984402537 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.0045585003681480885 norm:0.0010773263638839126 max memory_allocated 22559.27880859375 
[2025-03-02 04:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.004528906662017107 norm:0.0010088295675814152 max memory_allocated 22559.27880859375 
[2025-03-02 04:38:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004533970262855291 norm:0.001060619717463851 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.004504223819822073 norm:0.000922423554584384 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 04:39:29 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:40:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.11722730100154877 norm:0.033700935542583466 max memory_allocated 22559.45068359375 
[2025-03-02 04:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.04188333824276924 norm:0.02172114886343479 max memory_allocated 22559.45068359375 
[2025-03-02 04:41:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.020986473187804222 norm:0.014437148347496986 max memory_allocated 22559.45068359375 
[2025-03-02 04:41:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.014303608797490597 norm:0.006319674663245678 max memory_allocated 22559.45068359375 
[2025-03-02 04:42:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.0131516233086586 norm:0.005413162522017956 max memory_allocated 22559.45068359375 
[2025-03-02 04:42:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.012465841136872768 norm:0.005099872127175331 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.011568669229745865 norm:0.004768725484609604 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.010857997462153435 norm:0.003988286945968866 max memory_allocated 22559.45068359375 
[2025-03-02 04:44:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.010405948385596275 norm:0.0038009434938430786 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.01020237896591425 norm:0.0036373245529830456 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.010052674449980259 norm:0.0034094953443855047 max memory_allocated 22559.45068359375 
[2025-03-02 04:46:08 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.009555904194712639 norm:0.003147516865283251 max memory_allocated 22559.45068359375 
[2025-03-02 04:46:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.009218061342835426 norm:0.0026096852961927652 max memory_allocated 22559.45068359375 
[2025-03-02 04:47:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.009159679524600506 norm:0.002568081021308899 max memory_allocated 22559.45068359375 
[2025-03-02 04:47:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.009141253307461739 norm:0.002591719850897789 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.009213685058057308 norm:0.002622503088787198 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.009026261046528816 norm:0.0021256161853671074 max memory_allocated 22559.45068359375 
[2025-03-02 04:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.009538264013826847 norm:0.0031050778925418854 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.008879823610186577 norm:0.0019117583287879825 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.009079249575734138 norm:0.002140490338206291 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.016271937638521194 norm:0.00211545848287642 max memory_allocated 22559.50732421875 
[2025-03-02 04:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.013177633285522461 norm:0.0008856040076352656 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.012008542194962502 norm:0.00044696545228362083 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.011283984407782555 norm:0.0002526410389691591 max memory_allocated 22559.50732421875 
[2025-03-02 04:53:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.010783401317894459 norm:0.0001728940405882895 max memory_allocated 22559.50732421875 
[2025-03-02 04:54:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.010476124472916126 norm:0.00012452657392714173 max memory_allocated 22559.50732421875 
[2025-03-02 04:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.010371727868914604 norm:0.00010356215352658182 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.010352512821555138 norm:0.00010148113506147638 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.010340903885662556 norm:9.852115181274712e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.010327587835490704 norm:0.00010000664769904688 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.010332275182008743 norm:9.763980779098347e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.010329639539122581 norm:9.576355660101399e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.010333026759326458 norm:9.91271881503053e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:58:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.010324826464056969 norm:9.109361417358741e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.010329684242606163 norm:9.134833089774475e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:59:37 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.010326295159757137 norm:8.90558585524559e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.010323538444936275 norm:8.776529284659773e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.010323187336325645 norm:8.568554039811715e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.010330047458410263 norm:9.16442513698712e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.0103278374299407 norm:9.147929813480005e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 05:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.020722324028611183 norm:0.0020222123712301254 max memory_allocated 22559.67919921875 
[2025-03-02 05:03:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.01717304065823555 norm:0.0008808987913653255 max memory_allocated 22559.67919921875 
[2025-03-02 05:03:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.015580238774418831 norm:0.00045960929128341377 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.014624097384512424 norm:0.00024760575615800917 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.014064615592360497 norm:0.0001883740769699216 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.013807236216962337 norm:0.00017125977319665253 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.013745145872235298 norm:0.000149213126860559 max memory_allocated 22559.67919921875 
[2025-03-02 05:06:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.01372675970196724 norm:0.00012430846982169896 max memory_allocated 22559.67919921875 
[2025-03-02 05:06:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.013715658336877823 norm:0.00011725154763553292 max memory_allocated 22559.67919921875 
[2025-03-02 05:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.01371141616255045 norm:0.0001335216365987435 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.013706039637327194 norm:0.00011278515012236312 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.013706745579838753 norm:0.00013501667126547545 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.013685954734683037 norm:0.00011351605644449592 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.013691850006580353 norm:0.00014046199794393033 max memory_allocated 22559.67919921875 
[2025-03-02 05:10:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.013684537261724472 norm:0.00010655046935426071 max memory_allocated 22559.67919921875 
[2025-03-02 05:10:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.013681642711162567 norm:0.00011608928616624326 max memory_allocated 22559.67919921875 
[2025-03-02 05:11:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.013685048557817936 norm:0.000140383854159154 max memory_allocated 22559.67919921875 
[2025-03-02 05:11:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.013677367940545082 norm:0.00010508210107218474 max memory_allocated 22559.67919921875 
[2025-03-02 05:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.01367585826665163 norm:0.00010441421181894839 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.013681713491678238 norm:0.00012696548947133124 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 05:13:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.023658255115151405 norm:0.001960378373041749 max memory_allocated 22559.85107421875 
[2025-03-02 05:14:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.01993183046579361 norm:0.0009014069219119847 max memory_allocated 22559.85107421875 
[2025-03-02 05:14:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.018185993656516075 norm:0.00046439003199338913 max memory_allocated 22559.85107421875 
[2025-03-02 05:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.017068548128008842 norm:0.0002495985827408731 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.016447756439447403 norm:0.0001504754036432132 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.016209464520215988 norm:0.0001088352728402242 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.016140474006533623 norm:9.891344234347343e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.016116607934236526 norm:9.324876009486616e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:18:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.01609504222869873 norm:9.394824883202091e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.016072995960712433 norm:9.451585356146097e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.016058873385190964 norm:9.398229303769767e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.01605343073606491 norm:9.676405170466751e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:20:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.016046226024627686 norm:9.347036393592134e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.016042444854974747 norm:9.184757072944194e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.016035567969083786 norm:9.561878687236458e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:22:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.016028884798288345 norm:9.50737448874861e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:22:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.01602082885801792 norm:9.165713709080592e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:23:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.016018588095903397 norm:9.327382576884702e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:23:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.01601390354335308 norm:9.633784793550149e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.016007546335458755 norm:9.297052747569978e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 05:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.02485829032957554 norm:0.001234337454661727 max memory_allocated 22560.02294921875 
[2025-03-02 05:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.02193048782646656 norm:0.00044451566645875573 max memory_allocated 22560.02294921875 
[2025-03-02 05:26:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.020561276003718376 norm:0.0002749565173871815 max memory_allocated 22560.02294921875 
[2025-03-02 05:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.01963619329035282 norm:0.00017509664758108556 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.019104499369859695 norm:0.00013432859850581735 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.018862327560782433 norm:0.00011448954319348559 max memory_allocated 22560.02294921875 
[2025-03-02 05:28:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.01879836618900299 norm:0.0001036678659147583 max memory_allocated 22560.02294921875 
[2025-03-02 05:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.01877341791987419 norm:9.443596354685724e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.018752574920654297 norm:8.861938840709627e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:30:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.018730714917182922 norm:8.754184091230854e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.018724074587225914 norm:9.371713531436399e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:31:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.018714243546128273 norm:8.628413343103603e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:31:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.018712278455495834 norm:8.67662820382975e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:32:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.018722983077168465 norm:9.630963177187368e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:32:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.01870764046907425 norm:8.478757081320509e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.01870797574520111 norm:8.737212920095772e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.01869949884712696 norm:8.432907634414732e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.018701335415244102 norm:8.431627793470398e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:35:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.01870010979473591 norm:8.671802061144263e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:35:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.0187008548527956 norm:8.934760990086943e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:35:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 05:36:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.030110344290733337 norm:0.0012091945391148329 max memory_allocated 22560.19482421875 
[2025-03-02 05:36:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.0259209293872118 norm:0.000605754554271698 max memory_allocated 22560.19482421875 
[2025-03-02 05:37:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.024049675092101097 norm:0.0003542712947819382 max memory_allocated 22560.19482421875 
[2025-03-02 05:37:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.02298254519701004 norm:0.0002547681797295809 max memory_allocated 22560.19482421875 
[2025-03-02 05:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.02229277417063713 norm:0.00021005627058912069 max memory_allocated 22560.19482421875 
[2025-03-02 05:39:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.02190817892551422 norm:0.00017722124175634235 max memory_allocated 22560.19482421875 
[2025-03-02 05:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.02181749790906906 norm:0.00017963578284252435 max memory_allocated 22560.19482421875 
[2025-03-02 05:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.021722428500652313 norm:0.00016184593550860882 max memory_allocated 22560.19482421875 
[2025-03-02 05:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.021650323644280434 norm:0.00014831742737442255 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.021587787196040154 norm:0.00015125173376873136 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.021546179428696632 norm:0.00015602468920405954 max memory_allocated 22560.19482421875 
[2025-03-02 05:42:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.021529030054807663 norm:0.00015181474736891687 max memory_allocated 22560.19482421875 
[2025-03-02 05:42:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.02153700590133667 norm:0.00015748522127978504 max memory_allocated 22560.19482421875 
[2025-03-02 05:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.021528320387005806 norm:0.0001392982085235417 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.021485906094312668 norm:0.00013710373605135828 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.02147463522851467 norm:0.00014833520981483161 max memory_allocated 22560.19482421875 
[2025-03-02 05:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.021458420902490616 norm:0.000144061486935243 max memory_allocated 22560.19482421875 
[2025-03-02 05:45:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.021465357393026352 norm:0.00014007040590513498 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.021469147875905037 norm:0.00014468113658949733 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.021435026079416275 norm:0.00014059338718652725 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:47:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.03150893747806549 norm:0.0008827620185911655 max memory_allocated 22560.36669921875 
[2025-03-02 05:48:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.027537114918231964 norm:0.0004070810100529343 max memory_allocated 22560.36669921875 
[2025-03-02 05:48:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.025878824293613434 norm:0.00026349371182732284 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:14 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.02483639493584633 norm:0.00019066836102865636 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.024192947894334793 norm:0.00017208332428708673 max memory_allocated 22560.36669921875 
[2025-03-02 05:50:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.023911723867058754 norm:0.0001845686201704666 max memory_allocated 22560.36669921875 
[2025-03-02 05:50:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.023692715913057327 norm:0.00014923325215931982 max memory_allocated 22560.36669921875 
[2025-03-02 05:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.023584997281432152 norm:0.00014560739509761333 max memory_allocated 22560.36669921875 
[2025-03-02 05:51:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.02354799024760723 norm:0.00014398143684957176 max memory_allocated 22560.36669921875 
[2025-03-02 05:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.023497924208641052 norm:0.00014849264698568732 max memory_allocated 22560.36669921875 
[2025-03-02 05:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.023424876853823662 norm:0.00014422864478547126 max memory_allocated 22560.36669921875 
[2025-03-02 05:53:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.023416535928845406 norm:0.00014365465904120356 max memory_allocated 22560.36669921875 
[2025-03-02 05:54:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.023389145731925964 norm:0.0001416439627064392 max memory_allocated 22560.36669921875 
[2025-03-02 05:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.02336161769926548 norm:0.00013656006194651127 max memory_allocated 22560.36669921875 
[2025-03-02 05:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.023356182500720024 norm:0.0001339679874945432 max memory_allocated 22560.36669921875 
[2025-03-02 05:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.023346830159425735 norm:0.00014015148917678744 max memory_allocated 22560.36669921875 
[2025-03-02 05:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.023350704461336136 norm:0.0001329628430539742 max memory_allocated 22560.36669921875 
[2025-03-02 05:56:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.02336263842880726 norm:0.00014055667270440608 max memory_allocated 22560.36669921875 
[2025-03-02 05:57:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.023335488513112068 norm:0.00014258846931625158 max memory_allocated 22560.36669921875 
[2025-03-02 05:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.02333575114607811 norm:0.00013463178765960038 max memory_allocated 22560.36669921875 
[2025-03-02 05:58:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 05:58:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.03640644624829292 norm:0.0011468371376395226 max memory_allocated 22560.53857421875 
[2025-03-02 05:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.0314287506043911 norm:0.0005522891879081726 max memory_allocated 22560.53857421875 
[2025-03-02 05:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.029108526185154915 norm:0.00033940374851226807 max memory_allocated 22560.53857421875 
[2025-03-02 06:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.027919558808207512 norm:0.000241134301177226 max memory_allocated 22560.53857421875 
[2025-03-02 06:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.027141980826854706 norm:0.00019434207933954895 max memory_allocated 22560.53857421875 
[2025-03-02 06:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.026760078966617584 norm:0.00018164199718739837 max memory_allocated 22560.53857421875 
[2025-03-02 06:02:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.026563970372080803 norm:0.0001667808392085135 max memory_allocated 22560.53857421875 
[2025-03-02 06:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.026476437225937843 norm:0.0001642078423174098 max memory_allocated 22560.53857421875 
[2025-03-02 06:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.026375968009233475 norm:0.0001506183616584167 max memory_allocated 22560.53857421875 
[2025-03-02 06:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.026309316977858543 norm:0.0001421495690010488 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.026289401575922966 norm:0.0001422071800334379 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.026261940598487854 norm:0.00013507483527064323 max memory_allocated 22560.53857421875 
[2025-03-02 06:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.02621685341000557 norm:0.00013675697846338153 max memory_allocated 22560.53857421875 
[2025-03-02 06:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.026199033483862877 norm:0.00013355778355617076 max memory_allocated 22560.53857421875 
[2025-03-02 06:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.02616666629910469 norm:0.00013014176511205733 max memory_allocated 22560.53857421875 
[2025-03-02 06:07:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.02618991583585739 norm:0.00013292997027747333 max memory_allocated 22560.53857421875 
[2025-03-02 06:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.026146190240979195 norm:0.00012813249486498535 max memory_allocated 22560.53857421875 
[2025-03-02 06:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.02612946555018425 norm:0.00012976273137610406 max memory_allocated 22560.53857421875 
[2025-03-02 06:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.02611728385090828 norm:0.00012964868801645935 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.026128025725483894 norm:0.00013426992518361658 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 06:10:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.03462199121713638 norm:0.0007895954186096787 max memory_allocated 22560.71044921875 
[2025-03-02 06:10:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.03186658024787903 norm:0.00038374800351448357 max memory_allocated 22560.71044921875 
[2025-03-02 06:11:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.030421346426010132 norm:0.0002380130608798936 max memory_allocated 22560.71044921875 
[2025-03-02 06:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.02944868989288807 norm:0.00018283832469023764 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.028737200424075127 norm:0.00015003922453615814 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.028387906029820442 norm:0.00013436318840831518 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.028256405144929886 norm:0.00011909316526725888 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.028200626373291016 norm:0.00011629169603111222 max memory_allocated 22560.71044921875 
[2025-03-02 06:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.028143880888819695 norm:0.0001073836610885337 max memory_allocated 22560.71044921875 
[2025-03-02 06:15:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.028085041791200638 norm:0.00010748485510703176 max memory_allocated 22560.71044921875 
[2025-03-02 06:15:36 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.0280462559312582 norm:0.00010392322292318568 max memory_allocated 22560.71044921875 
[2025-03-02 06:16:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.028040610253810883 norm:0.00010375396232120693 max memory_allocated 22560.71044921875 
[2025-03-02 06:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.028027888387441635 norm:0.00010572319297352806 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.02802322991192341 norm:0.00010395680146757513 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.027988608926534653 norm:0.0001019447372527793 max memory_allocated 22560.71044921875 
[2025-03-02 06:18:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.027953939512372017 norm:0.00010398331505712122 max memory_allocated 22560.71044921875 
[2025-03-02 06:18:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.027954241260886192 norm:0.00010449324327055365 max memory_allocated 22560.71044921875 
[2025-03-02 06:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.027959229424595833 norm:0.00010292707884218544 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.027953214943408966 norm:9.880972356768325e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.027923105284571648 norm:9.901626617647707e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 06:21:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.03569982573390007 norm:0.0008585951291024685 max memory_allocated 22560.88232421875 
[2025-03-02 06:21:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.032843321561813354 norm:0.0004041885840706527 max memory_allocated 22560.88232421875 
[2025-03-02 06:22:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.03144945949316025 norm:0.0002521992428228259 max memory_allocated 22560.88232421875 
[2025-03-02 06:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.03044053353369236 norm:0.0001593121123732999 max memory_allocated 22560.88232421875 
[2025-03-02 06:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.029810579493641853 norm:0.0001297983544645831 max memory_allocated 22560.88232421875 
[2025-03-02 06:24:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.029501497745513916 norm:0.00011962939606746659 max memory_allocated 22560.88232421875 
[2025-03-02 06:24:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.029360271990299225 norm:0.00011006253043888137 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.029313137754797935 norm:0.00011231069220229983 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.029249507933855057 norm:9.966917423298582e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:26:18 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.029198430478572845 norm:0.00010165431740460917 max memory_allocated 22560.88232421875 
[2025-03-02 06:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.029153432697057724 norm:9.893560491036624e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:27:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.029154149815440178 norm:9.943159966496751e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.029135102406144142 norm:9.728637814987451e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.02911446802318096 norm:9.652742301113904e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.02911176159977913 norm:9.742367547005415e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.02910679765045643 norm:9.738422522787005e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.02908061258494854 norm:9.796459198696539e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.0290745347738266 norm:9.856667747953907e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.029099561274051666 norm:9.670078725321218e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.02910229004919529 norm:9.798834071261808e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 06:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.0368691012263298 norm:0.0005711463745683432 max memory_allocated 22561.05419921875 
[2025-03-02 06:33:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.034521572291851044 norm:0.0003147175593767315 max memory_allocated 22561.05419921875 
[2025-03-02 06:33:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.03311885893344879 norm:0.0002175049448851496 max memory_allocated 22561.05419921875 
[2025-03-02 06:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.03204512968659401 norm:0.00017285760259255767 max memory_allocated 22561.05419921875 
[2025-03-02 06:34:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.031397998332977295 norm:0.0001490512804593891 max memory_allocated 22561.05419921875 
[2025-03-02 06:35:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.03102489560842514 norm:0.00013205042341724038 max memory_allocated 22561.05419921875 
[2025-03-02 06:35:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.030805105343461037 norm:0.00012334952771198004 max memory_allocated 22561.05419921875 
[2025-03-02 06:36:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.030705736950039864 norm:0.00011640867160167545 max memory_allocated 22561.05419921875 
[2025-03-02 06:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.03066372498869896 norm:0.00010916887549683452 max memory_allocated 22561.05419921875 
[2025-03-02 06:37:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.030606355518102646 norm:9.996208245866e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.03056824952363968 norm:9.616330498829484e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.0305426437407732 norm:9.361010597785935e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.03053334169089794 norm:8.965718006948009e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.030528247356414795 norm:8.890610479284078e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:40:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.030493713915348053 norm:8.758350304560736e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:40:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.030466031283140182 norm:8.443111437372863e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:41:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.030458740890026093 norm:8.458830416202545e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:41:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.030445728451013565 norm:8.625398913864046e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.030462173745036125 norm:8.784795500105247e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.030472733080387115 norm:8.71569209266454e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:43:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 06:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.03776044026017189 norm:0.0005501356208696961 max memory_allocated 22561.22607421875 
[2025-03-02 06:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.035628411918878555 norm:0.0002861837565433234 max memory_allocated 22561.22607421875 
[2025-03-02 06:44:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.03435136750340462 norm:0.0001925108372233808 max memory_allocated 22561.22607421875 
[2025-03-02 06:45:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.03345854580402374 norm:0.0001551919267512858 max memory_allocated 22561.22607421875 
[2025-03-02 06:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.03282719478011131 norm:0.00013435087748803198 max memory_allocated 22561.22607421875 
[2025-03-02 06:46:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.032460689544677734 norm:0.00011751843703677878 max memory_allocated 22561.22607421875 
[2025-03-02 06:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.03228917717933655 norm:0.0001065919132088311 max memory_allocated 22561.22607421875 
[2025-03-02 06:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.03223133087158203 norm:0.0001007510072668083 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.03219243139028549 norm:9.031069203047082e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.03215721622109413 norm:9.212450095219538e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.032113559544086456 norm:8.889336459105834e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.0320817306637764 norm:8.458747470285743e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.0320766307413578 norm:8.592081576352939e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:51:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.03206389397382736 norm:8.579889981774613e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:51:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.0320538766682148 norm:8.689676906215027e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.03202362358570099 norm:8.364363020518795e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:52:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.03202200308442116 norm:8.335588790941983e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:53:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.03201132267713547 norm:8.814701141091064e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:53:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.03199829161167145 norm:8.36157996673137e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.03199870511889458 norm:8.464319398626685e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:55:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.04235338047146797 norm:0.0010294596431776881 max memory_allocated 22561.39794921875 
[2025-03-02 06:55:36 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.03891061991453171 norm:0.0004911110154353082 max memory_allocated 22561.39794921875 
[2025-03-02 06:56:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.03715543821454048 norm:0.00030277218320406973 max memory_allocated 22561.39794921875 
[2025-03-02 06:56:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.03608093038201332 norm:0.00021610160183627158 max memory_allocated 22561.39794921875 
[2025-03-02 06:57:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.03537841886281967 norm:0.00017444835975766182 max memory_allocated 22561.39794921875 
[2025-03-02 06:57:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.035044826567173004 norm:0.00014742718485649675 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.034864071756601334 norm:0.00013189563469495624 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.03475402295589447 norm:0.00012283150863368064 max memory_allocated 22561.39794921875 
[2025-03-02 06:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.03465648368000984 norm:0.00012110370153095573 max memory_allocated 22561.39794921875 
[2025-03-02 07:00:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.034582577645778656 norm:0.00011138906120322645 max memory_allocated 22561.39794921875 
[2025-03-02 07:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.03455442190170288 norm:0.00010266216122545302 max memory_allocated 22561.39794921875 
[2025-03-02 07:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.03453812375664711 norm:9.774712816579267e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:01:40 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.034515220671892166 norm:9.664851677371189e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.03451336547732353 norm:9.528912050882354e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.03450150042772293 norm:9.302902617491782e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.03449703007936478 norm:9.46722793742083e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:03:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.03447212651371956 norm:9.58502059802413e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.034470200538635254 norm:9.109359234571457e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:04:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.034443050622940063 norm:9.125298674916849e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.034446027129888535 norm:9.343778947368264e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 07:06:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.042707834392786026 norm:0.0007125919801183045 max memory_allocated 22561.56982421875 
[2025-03-02 07:06:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.04059768095612526 norm:0.0003588045947253704 max memory_allocated 22561.56982421875 
[2025-03-02 07:07:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.03920165076851845 norm:0.0002213866973761469 max memory_allocated 22561.56982421875 
[2025-03-02 07:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.038126371800899506 norm:0.0001606136211194098 max memory_allocated 22561.56982421875 
[2025-03-02 07:08:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.03747056797146797 norm:0.00014263034972827882 max memory_allocated 22561.56982421875 
[2025-03-02 07:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.037149496376514435 norm:0.0001193274583783932 max memory_allocated 22561.56982421875 
[2025-03-02 07:09:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.037002433091402054 norm:0.00010704219312174246 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.036914948374032974 norm:9.819745173444971e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.036872655153274536 norm:9.314403723692521e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.03681210055947304 norm:8.831944433040917e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.03680917248129845 norm:0.00010937111073872074 max memory_allocated 22561.56982421875 
[2025-03-02 07:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.03676417097449303 norm:8.786865510046482e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.036766767501831055 norm:8.504495781380683e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.036743953824043274 norm:8.64726462168619e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:14:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.036745745688676834 norm:8.850899757817388e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.03673045337200165 norm:8.358908235095441e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.03670822083950043 norm:8.484436693834141e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.03669937700033188 norm:8.61656735651195e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.036693863570690155 norm:8.374609024031088e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.03667936846613884 norm:8.292014535982162e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 07:17:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.048270635306835175 norm:0.0009875084506347775 max memory_allocated 22561.74169921875 
[2025-03-02 07:18:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.04474779590964317 norm:0.00037346530007198453 max memory_allocated 22561.74169921875 
[2025-03-02 07:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.04303041100502014 norm:0.00023398241319227964 max memory_allocated 22561.74169921875 
[2025-03-02 07:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.04187818244099617 norm:0.0001845588703872636 max memory_allocated 22561.74169921875 
[2025-03-02 07:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.04116112366318703 norm:0.0001629714824957773 max memory_allocated 22561.74169921875 
[2025-03-02 07:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.040840230882167816 norm:0.0001374406274408102 max memory_allocated 22561.74169921875 
[2025-03-02 07:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.040711525827646255 norm:0.00013534064055420458 max memory_allocated 22561.74169921875 
[2025-03-02 07:21:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.04062506556510925 norm:0.00011635327973635867 max memory_allocated 22561.74169921875 
[2025-03-02 07:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.040511585772037506 norm:0.00010927458788501099 max memory_allocated 22561.74169921875 
[2025-03-02 07:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.04044271633028984 norm:0.0001106487907236442 max memory_allocated 22561.74169921875 
[2025-03-02 07:23:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.04042698070406914 norm:0.00010181117977481335 max memory_allocated 22561.74169921875 
[2025-03-02 07:23:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.04038698598742485 norm:0.00010575987107586116 max memory_allocated 22561.74169921875 
[2025-03-02 07:24:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.04033853858709335 norm:9.988668898586184e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:24:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.040320251137018204 norm:9.536833385936916e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:25:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.040300171822309494 norm:9.1786656412296e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:25:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.04031321406364441 norm:9.690502338344231e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.04031338915228844 norm:9.743150440044701e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:26:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.04028965160250664 norm:9.467657218920067e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:27:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.04027283936738968 norm:9.550462709739804e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:28:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.04025499150156975 norm:9.373103239340708e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:28:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 07:28:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.05316348373889923 norm:0.0011461088433861732 max memory_allocated 22561.91357421875 
[2025-03-02 07:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.04986337944865227 norm:0.0004797734145540744 max memory_allocated 22561.91357421875 
[2025-03-02 07:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.04796243831515312 norm:0.00029437971534207463 max memory_allocated 22561.91357421875 
[2025-03-02 07:30:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.04664238169789314 norm:0.000210473794140853 max memory_allocated 22561.91357421875 
[2025-03-02 07:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.04586309567093849 norm:0.00016290687199216336 max memory_allocated 22561.91357421875 
[2025-03-02 07:31:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.045604538172483444 norm:0.0001402623311150819 max memory_allocated 22561.91357421875 
[2025-03-02 07:32:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.04546128585934639 norm:0.0001346216449746862 max memory_allocated 22561.91357421875 
[2025-03-02 07:32:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.04538934677839279 norm:0.00011883332626894116 max memory_allocated 22561.91357421875 
[2025-03-02 07:33:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.0453362800180912 norm:0.00011192593956366181 max memory_allocated 22561.91357421875 
[2025-03-02 07:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.04526771232485771 norm:0.0001079927824321203 max memory_allocated 22561.91357421875 
[2025-03-02 07:34:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.04520673677325249 norm:0.0001005439626169391 max memory_allocated 22561.91357421875 
[2025-03-02 07:34:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.04521668702363968 norm:9.954687993740663e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.045187078416347504 norm:9.741894609760493e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:35:58 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.04515787586569786 norm:9.848362969933078e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.0451357364654541 norm:9.452791709918529e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.045125268399715424 norm:9.526280337013304e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.045107632875442505 norm:9.318092634202912e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:38:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.04509566351771355 norm:9.594285802450031e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:38:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.04508281871676445 norm:9.450659126741812e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.045071110129356384 norm:9.437774860998616e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 07:40:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.058011770248413086 norm:0.0005849538720212877 max memory_allocated 22562.08544921875 
[2025-03-02 07:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.05551975220441818 norm:0.0002766899997368455 max memory_allocated 22562.08544921875 
[2025-03-02 07:41:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.054079726338386536 norm:0.0002020643005380407 max memory_allocated 22562.08544921875 
[2025-03-02 07:41:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.05279446765780449 norm:0.0001627891615498811 max memory_allocated 22562.08544921875 
[2025-03-02 07:42:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.05210135504603386 norm:0.00013419774768408388 max memory_allocated 22562.08544921875 
[2025-03-02 07:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.051876794546842575 norm:0.0001235625531990081 max memory_allocated 22562.08544921875 
[2025-03-02 07:43:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.05176501348614693 norm:0.00011270830145804211 max memory_allocated 22562.08544921875 
[2025-03-02 07:43:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.051709044724702835 norm:0.00010394536366220564 max memory_allocated 22562.08544921875 
[2025-03-02 07:44:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.0516473725438118 norm:9.737093205330893e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:45:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.05159957706928253 norm:9.363143180962652e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:45:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.05157335847616196 norm:9.063804463949054e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:46:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.05155397579073906 norm:8.927581802709028e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:46:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.05151562765240669 norm:8.302243804791942e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.051491692662239075 norm:8.323827933054417e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.05146901309490204 norm:8.289620018331334e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:48:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.051474329084157944 norm:8.254844578914344e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:48:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.05147995427250862 norm:8.361750224139541e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:49:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.05147106572985649 norm:8.352921577170491e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.05146440118551254 norm:8.400886144954711e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:50:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.05144903063774109 norm:8.56084079714492e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:50:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.06710894405841827 norm:0.0008868714212439954 max memory_allocated 22562.25732421875 
[2025-03-02 07:51:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.06427913904190063 norm:0.000361290032742545 max memory_allocated 22562.25732421875 
[2025-03-02 07:52:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.06253664195537567 norm:0.00023674794647376984 max memory_allocated 22562.25732421875 
[2025-03-02 07:52:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.061099179089069366 norm:0.0001854966685641557 max memory_allocated 22562.25732421875 
[2025-03-02 07:53:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.06039433181285858 norm:0.00015680486103519797 max memory_allocated 22562.25732421875 
[2025-03-02 07:54:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.060179419815540314 norm:0.0001384780916851014 max memory_allocated 22562.25732421875 
[2025-03-02 07:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.0600627064704895 norm:0.00013222484267316759 max memory_allocated 22562.25732421875 
[2025-03-02 07:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.05997169762849808 norm:0.00012119027087464929 max memory_allocated 22562.25732421875 
[2025-03-02 07:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.05993235111236572 norm:0.00011579490819713101 max memory_allocated 22562.25732421875 
[2025-03-02 07:56:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.05985322594642639 norm:0.00010924269736278802 max memory_allocated 22562.25732421875 
[2025-03-02 07:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.05984830856323242 norm:0.00011508588795550168 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.059829309582710266 norm:0.00010486938845133409 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.05981123074889183 norm:0.00010845061478903517 max memory_allocated 22562.25732421875 
[2025-03-02 07:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.05976610630750656 norm:0.00010472382564330474 max memory_allocated 22562.25732421875 
[2025-03-02 07:59:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.059734635055065155 norm:0.00010434392606839538 max memory_allocated 22562.25732421875 
[2025-03-02 07:59:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.059725552797317505 norm:0.00010262958676321432 max memory_allocated 22562.25732421875 
[2025-03-02 08:00:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.05971616134047508 norm:0.00010222725541098043 max memory_allocated 22562.25732421875 
[2025-03-02 08:00:41 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.059703726321458817 norm:0.00010245024895993993 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.05972140654921532 norm:0.0001061882940120995 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.05972610414028168 norm:0.00010550423030508682 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 08:02:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.08140290528535843 norm:0.0021548569202423096 max memory_allocated 22562.42919921875 
[2025-03-02 08:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.07675629109144211 norm:0.0006528814556077123 max memory_allocated 22562.42919921875 
[2025-03-02 08:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.07433144003152847 norm:0.00038871244760230184 max memory_allocated 22562.42919921875 
[2025-03-02 08:04:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.07253807038068771 norm:0.00030417306697927415 max memory_allocated 22562.42919921875 
[2025-03-02 08:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.07184989750385284 norm:0.0002614559489302337 max memory_allocated 22562.42919921875 
[2025-03-02 08:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.07155893743038177 norm:0.00020520735415630043 max memory_allocated 22562.42919921875 
[2025-03-02 08:05:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.07143096625804901 norm:0.00019786534539889544 max memory_allocated 22562.42919921875 
[2025-03-02 08:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.07133321464061737 norm:0.000179799142642878 max memory_allocated 22562.42919921875 
[2025-03-02 08:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.07118885964155197 norm:0.0001605628931429237 max memory_allocated 22562.42919921875 
[2025-03-02 08:07:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.07110574841499329 norm:0.00015623364015482366 max memory_allocated 22562.42919921875 
[2025-03-02 08:08:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.07105182856321335 norm:0.0001466256071580574 max memory_allocated 22562.42919921875 
[2025-03-02 08:08:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.07102229446172714 norm:0.0001417039311490953 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.07097828388214111 norm:0.0001449502306059003 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.07092279195785522 norm:0.00013866981316823512 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.07090099155902863 norm:0.00013473090075422078 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.07086080312728882 norm:0.00014175946125760674 max memory_allocated 22562.42919921875 
[2025-03-02 08:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.07087826728820801 norm:0.00015101877215784043 max memory_allocated 22562.42919921875 
[2025-03-02 08:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.07088158279657364 norm:0.0001442478533135727 max memory_allocated 22562.42919921875 
[2025-03-02 08:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.07082966715097427 norm:0.00014353888400364667 max memory_allocated 22562.42919921875 
[2025-03-02 08:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.07083384692668915 norm:0.0001391149708069861 max memory_allocated 22562.42919921875 
[2025-03-02 08:13:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 08:13:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.09296325594186783 norm:0.0021686754189431667 max memory_allocated 22562.60107421875 
[2025-03-02 08:14:20 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.08986642956733704 norm:0.0007886035600677133 max memory_allocated 22562.60107421875 
[2025-03-02 08:14:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.08766935020685196 norm:0.0004446206148713827 max memory_allocated 22562.60107421875 
[2025-03-02 08:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.08579099178314209 norm:0.0003576800227165222 max memory_allocated 22562.60107421875 
[2025-03-02 08:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.08515701442956924 norm:0.00031437751022167504 max memory_allocated 22562.60107421875 
[2025-03-02 08:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.08490875363349915 norm:0.00026697636349126697 max memory_allocated 22562.60107421875 
[2025-03-02 08:17:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.08479788899421692 norm:0.0002542275469750166 max memory_allocated 22562.60107421875 
[2025-03-02 08:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.0846601352095604 norm:0.00022253007045947015 max memory_allocated 22562.60107421875 
[2025-03-02 08:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.08457570523023605 norm:0.0002080662379739806 max memory_allocated 22562.60107421875 
[2025-03-02 08:18:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.0845084860920906 norm:0.00019210022583138198 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.08446730673313141 norm:0.00017524708528071642 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.08441813290119171 norm:0.00016215210780501366 max memory_allocated 22562.60107421875 
[2025-03-02 08:20:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.08437009900808334 norm:0.00015578391321469098 max memory_allocated 22562.60107421875 
[2025-03-02 08:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.0843595564365387 norm:0.00014662221656180918 max memory_allocated 22562.60107421875 
[2025-03-02 08:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.08432377129793167 norm:0.00013652084453497082 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.08429339528083801 norm:0.00013467228563968092 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.08428069204092026 norm:0.00013589623267762363 max memory_allocated 22562.60107421875 
[2025-03-02 08:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.08426204323768616 norm:0.00014067826850805432 max memory_allocated 22562.60107421875 
[2025-03-02 08:23:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.0842483788728714 norm:0.00013854546705260873 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.0842435285449028 norm:0.0001355278945993632 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 08:25:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.10756124556064606 norm:0.001392080564983189 max memory_allocated 22562.77294921875 
[2025-03-02 08:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.10457277297973633 norm:0.0006434497190639377 max memory_allocated 22562.77294921875 
[2025-03-02 08:26:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.10215092450380325 norm:0.00041285919724032283 max memory_allocated 22562.77294921875 
[2025-03-02 08:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.1002047210931778 norm:0.0002897102676797658 max memory_allocated 22562.77294921875 
[2025-03-02 08:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.09968353807926178 norm:0.00023488272563554347 max memory_allocated 22562.77294921875 
[2025-03-02 08:27:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.09950520098209381 norm:0.00019010169489774853 max memory_allocated 22562.77294921875 
[2025-03-02 08:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.09937244653701782 norm:0.00016365089686587453 max memory_allocated 22562.77294921875 
[2025-03-02 08:28:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.09929697215557098 norm:0.00015190242265816778 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.09924745559692383 norm:0.000146634440170601 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.09920709580183029 norm:0.0001347000797977671 max memory_allocated 22562.77294921875 
[2025-03-02 08:30:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.09919175505638123 norm:0.00013554577890317887 max memory_allocated 22562.77294921875 
[2025-03-02 08:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.09916678816080093 norm:0.00013047675020061433 max memory_allocated 22562.77294921875 
[2025-03-02 08:31:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.0991494357585907 norm:0.00012609532859642059 max memory_allocated 22562.77294921875 
[2025-03-02 08:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.09911859780550003 norm:0.00012485063052736223 max memory_allocated 22562.77294921875 
[2025-03-02 08:32:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.09910861402750015 norm:0.0001255976821994409 max memory_allocated 22562.77294921875 
[2025-03-02 08:33:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.09909217804670334 norm:0.00012527349463198334 max memory_allocated 22562.77294921875 
[2025-03-02 08:33:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.09907885640859604 norm:0.00012590140977408737 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.0990758016705513 norm:0.00012713969044853002 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.0990586057305336 norm:0.00012651608267333359 max memory_allocated 22562.77294921875 
[2025-03-02 08:35:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.09905660152435303 norm:0.0001300690055359155 max memory_allocated 22562.77294921875 
[2025-03-02 08:35:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 08:36:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.1259448528289795 norm:0.0017189787467941642 max memory_allocated 22562.94482421875 
[2025-03-02 08:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.12281929701566696 norm:0.000927619868889451 max memory_allocated 22562.94482421875 
[2025-03-02 08:37:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.1203441470861435 norm:0.0006082788459025323 max memory_allocated 22562.94482421875 
[2025-03-02 08:37:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.11822862923145294 norm:0.0004170822794549167 max memory_allocated 22562.94482421875 
[2025-03-02 08:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.11768641322851181 norm:0.00032196668325923383 max memory_allocated 22562.94482421875 
[2025-03-02 08:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.11743897199630737 norm:0.0002768179401755333 max memory_allocated 22562.94482421875 
[2025-03-02 08:39:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.11719118803739548 norm:0.00023013622558210045 max memory_allocated 22562.94482421875 
[2025-03-02 08:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.11706791818141937 norm:0.00020337592286523432 max memory_allocated 22562.94482421875 
[2025-03-02 08:40:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.11697104573249817 norm:0.00018526503117755055 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.11689545214176178 norm:0.00018068775534629822 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.11680769920349121 norm:0.000169325532624498 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.11680199205875397 norm:0.00016792652604635805 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.11678741872310638 norm:0.00016441229672636837 max memory_allocated 22562.94482421875 
[2025-03-02 08:43:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.11672886461019516 norm:0.0001602016855031252 max memory_allocated 22562.94482421875 
[2025-03-02 08:44:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.11672011017799377 norm:0.00015778245870023966 max memory_allocated 22562.94482421875 
[2025-03-02 08:44:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.11670329421758652 norm:0.000160954863531515 max memory_allocated 22562.94482421875 
[2025-03-02 08:45:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.11669505387544632 norm:0.00016705832968000323 max memory_allocated 22562.94482421875 
[2025-03-02 08:45:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.11665517836809158 norm:0.00015799827815499157 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.1166684478521347 norm:0.00015930355584714562 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.11669781804084778 norm:0.00016158631478901953 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:47:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.1438644975423813 norm:0.0008814046159386635 max memory_allocated 22563.11669921875 
[2025-03-02 08:48:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.14124943315982819 norm:0.0005057948874309659 max memory_allocated 22563.11669921875 
[2025-03-02 08:48:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.1385529786348343 norm:0.00036378580261953175 max memory_allocated 22563.11669921875 
[2025-03-02 08:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.13648968935012817 norm:0.00028602618840523064 max memory_allocated 22563.11669921875 
[2025-03-02 08:49:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.13603100180625916 norm:0.00024294831382576376 max memory_allocated 22563.11669921875 
[2025-03-02 08:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.13576632738113403 norm:0.0002194523112848401 max memory_allocated 22563.11669921875 
[2025-03-02 08:50:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.135619655251503 norm:0.00019531404541339725 max memory_allocated 22563.11669921875 
[2025-03-02 08:51:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.1355239599943161 norm:0.0001832715206546709 max memory_allocated 22563.11669921875 
[2025-03-02 08:51:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.13546724617481232 norm:0.00017427222337573767 max memory_allocated 22563.11669921875 
[2025-03-02 08:52:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.13536572456359863 norm:0.0001652306818868965 max memory_allocated 22563.11669921875 
[2025-03-02 08:53:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.13531672954559326 norm:0.00016387186769861728 max memory_allocated 22563.11669921875 
[2025-03-02 08:53:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.13529179990291595 norm:0.00016166701971087605 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.13521096110343933 norm:0.00015612668357789516 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.13517828285694122 norm:0.00015399845142383128 max memory_allocated 22563.11669921875 
[2025-03-02 08:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.13514289259910583 norm:0.00015541679749730974 max memory_allocated 22563.11669921875 
[2025-03-02 08:55:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.13513360917568207 norm:0.00015330270980484784 max memory_allocated 22563.11669921875 
[2025-03-02 08:56:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.13512694835662842 norm:0.00015293346950784326 max memory_allocated 22563.11669921875 
[2025-03-02 08:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.1351260244846344 norm:0.0001511339796707034 max memory_allocated 22563.11669921875 
[2025-03-02 08:57:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.13515059649944305 norm:0.00014931007171981037 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.13513746857643127 norm:0.00015056613483466208 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 08:58:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.16698773205280304 norm:0.001523137092590332 max memory_allocated 22563.28857421875 
[2025-03-02 08:59:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.1637861132621765 norm:0.0007921569631434977 max memory_allocated 22563.28857421875 
[2025-03-02 08:59:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.16036906838417053 norm:0.0005161918234080076 max memory_allocated 22563.28857421875 
[2025-03-02 09:00:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.15809376537799835 norm:0.00035539266536943614 max memory_allocated 22563.28857421875 
[2025-03-02 09:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.15769647061824799 norm:0.0002791427250485867 max memory_allocated 22563.28857421875 
[2025-03-02 09:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.1575624942779541 norm:0.00023273570695891976 max memory_allocated 22563.28857421875 
[2025-03-02 09:02:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.15745872259140015 norm:0.00020452243916224688 max memory_allocated 22563.28857421875 
[2025-03-02 09:02:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.1573982983827591 norm:0.00017995321832131594 max memory_allocated 22563.28857421875 
[2025-03-02 09:03:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.1573271006345749 norm:0.00017092347843572497 max memory_allocated 22563.28857421875 
[2025-03-02 09:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.15726321935653687 norm:0.00015986525977496058 max memory_allocated 22563.28857421875 
[2025-03-02 09:04:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.15721972286701202 norm:0.00015229007112793624 max memory_allocated 22563.28857421875 
[2025-03-02 09:04:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.15719640254974365 norm:0.00014857682981528342 max memory_allocated 22563.28857421875 
[2025-03-02 09:05:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.15716537833213806 norm:0.0001433210272807628 max memory_allocated 22563.28857421875 
[2025-03-02 09:05:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.15714837610721588 norm:0.00013982367818243802 max memory_allocated 22563.28857421875 
[2025-03-02 09:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.1571127474308014 norm:0.00013641560508403927 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.15710094571113586 norm:0.00013564052642323077 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.15708105266094208 norm:0.00013625010615214705 max memory_allocated 22563.28857421875 
[2025-03-02 09:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.1570681482553482 norm:0.0001364331692457199 max memory_allocated 22563.28857421875 
[2025-03-02 09:08:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.1570635885000229 norm:0.0001332884276052937 max memory_allocated 22563.28857421875 
[2025-03-02 09:09:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.15704935789108276 norm:0.00013411094550974667 max memory_allocated 22563.28857421875 
[2025-03-02 09:09:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 09:10:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.1962314397096634 norm:0.0053135245107114315 max memory_allocated 22563.46044921875 
[2025-03-02 09:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.19045552611351013 norm:0.0027283858507871628 max memory_allocated 22563.46044921875 
[2025-03-02 09:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.18581411242485046 norm:0.0016570950392633677 max memory_allocated 22563.46044921875 
[2025-03-02 09:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.18316978216171265 norm:0.0011034676572307944 max memory_allocated 22563.46044921875 
[2025-03-02 09:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.1824408620595932 norm:0.0007919168565422297 max memory_allocated 22563.46044921875 
[2025-03-02 09:12:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.1820903867483139 norm:0.0006039285799488425 max memory_allocated 22563.46044921875 
[2025-03-02 09:13:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.18187467753887177 norm:0.0004784514894708991 max memory_allocated 22563.46044921875 
[2025-03-02 09:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.18171316385269165 norm:0.00039890658808872104 max memory_allocated 22563.46044921875 
[2025-03-02 09:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.18156342208385468 norm:0.00034042540937662125 max memory_allocated 22563.46044921875 
[2025-03-02 09:14:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.18146899342536926 norm:0.0002987685729749501 max memory_allocated 22563.46044921875 
[2025-03-02 09:15:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.1813848614692688 norm:0.00027082592714577913 max memory_allocated 22563.46044921875 
[2025-03-02 09:16:05 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.18129101395606995 norm:0.0002527634787838906 max memory_allocated 22563.46044921875 
[2025-03-02 09:16:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.18124862015247345 norm:0.00023416135809384286 max memory_allocated 22563.46044921875 
[2025-03-02 09:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.18122105300426483 norm:0.0002237267472082749 max memory_allocated 22563.46044921875 
[2025-03-02 09:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.1811707615852356 norm:0.00021721652592532337 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.1811569184064865 norm:0.00021045519679319113 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.18112343549728394 norm:0.00020638688874896616 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.18110395967960358 norm:0.0002075052761938423 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.18112081289291382 norm:0.0002034158242167905 max memory_allocated 22563.46044921875 
[2025-03-02 09:20:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.18107536435127258 norm:0.00020036453497596085 max memory_allocated 22563.46044921875 
[2025-03-02 09:20:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 09:21:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.2176024317741394 norm:0.00272392644546926 max memory_allocated 22563.63232421875 
[2025-03-02 09:21:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.2126387059688568 norm:0.0014023138210177422 max memory_allocated 22563.63232421875 
[2025-03-02 09:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.20881496369838715 norm:0.0008997915429063141 max memory_allocated 22563.63232421875 
[2025-03-02 09:22:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.20682081580162048 norm:0.0006418308475986123 max memory_allocated 22563.63232421875 
[2025-03-02 09:23:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.20628803968429565 norm:0.0005234507261775434 max memory_allocated 22563.63232421875 
[2025-03-02 09:24:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.2060222178697586 norm:0.00040539592737331986 max memory_allocated 22563.63232421875 
[2025-03-02 09:24:35 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.20584657788276672 norm:0.00034737130044959486 max memory_allocated 22563.63232421875 
[2025-03-02 09:25:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.2057291567325592 norm:0.00030476879328489304 max memory_allocated 22563.63232421875 
[2025-03-02 09:25:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.20561127364635468 norm:0.00027620504260994494 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.20565100014209747 norm:0.0002811704180203378 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.20550861954689026 norm:0.0002476041845511645 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.2054547369480133 norm:0.00025348231429234147 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.20537032186985016 norm:0.00022624112898483872 max memory_allocated 22563.63232421875 
[2025-03-02 09:28:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.2053384929895401 norm:0.00022044275829102844 max memory_allocated 22563.63232421875 
[2025-03-02 09:29:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.20531940460205078 norm:0.00022526820248458534 max memory_allocated 22563.63232421875 
[2025-03-02 09:29:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.20527373254299164 norm:0.00021685715182684362 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.20524370670318604 norm:0.0002093798975693062 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.20523124933242798 norm:0.00020932313054800034 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.20518335700035095 norm:0.00021092806127853692 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:46 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.20519697666168213 norm:0.00021430637571029365 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 09:31:58 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:32:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.25314319133758545 norm:0.005979105830192566 max memory_allocated 22563.91943359375 
[2025-03-02 09:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.24838043749332428 norm:0.005392145831137896 max memory_allocated 22563.91943359375 
[2025-03-02 09:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.24333730340003967 norm:0.004480530507862568 max memory_allocated 22563.91943359375 
[2025-03-02 09:34:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.24085023999214172 norm:0.0039591798558831215 max memory_allocated 22563.91943359375 
[2025-03-02 09:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.240289568901062 norm:0.0033658251632004976 max memory_allocated 22563.91943359375 
[2025-03-02 09:35:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.23987264931201935 norm:0.003010944928973913 max memory_allocated 22563.91943359375 
[2025-03-02 09:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.2396499216556549 norm:0.0027798989322036505 max memory_allocated 22563.91943359375 
[2025-03-02 09:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.23947612941265106 norm:0.0025874117854982615 max memory_allocated 22563.91943359375 
[2025-03-02 09:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.23937667906284332 norm:0.002616405952721834 max memory_allocated 22563.91943359375 
[2025-03-02 09:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.2394641935825348 norm:0.00235940795391798 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.23928065598011017 norm:0.0024753303732722998 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.23920732736587524 norm:0.0021325936540961266 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.23909439146518707 norm:0.002303059445694089 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.2390524446964264 norm:0.002120361663401127 max memory_allocated 22563.91943359375 
[2025-03-02 09:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.23899035155773163 norm:0.002155642956495285 max memory_allocated 22563.91943359375 
[2025-03-02 09:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.2389354258775711 norm:0.0020344629883766174 max memory_allocated 22563.91943359375 
[2025-03-02 09:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.23889385163784027 norm:0.002048427937552333 max memory_allocated 22563.91943359375 
[2025-03-02 09:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.23886573314666748 norm:0.0019563930109143257 max memory_allocated 22563.91943359375 
[2025-03-02 09:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.23883958160877228 norm:0.0020006985869258642 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.2388181835412979 norm:0.0019131280714645982 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 09:43:15 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:43:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.2964518964290619 norm:0.007053741719573736 max memory_allocated 22564.09130859375 
[2025-03-02 09:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.2903789281845093 norm:0.005449302494525909 max memory_allocated 22564.09130859375 
[2025-03-02 09:44:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.2846544682979584 norm:0.004667703993618488 max memory_allocated 22564.09130859375 
[2025-03-02 09:45:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.2821563482284546 norm:0.003910875413566828 max memory_allocated 22564.09130859375 
[2025-03-02 09:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.28155073523521423 norm:0.0033846742007881403 max memory_allocated 22564.09130859375 
[2025-03-02 09:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.28106269240379333 norm:0.002906725276261568 max memory_allocated 22564.09130859375 
[2025-03-02 09:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.28086555004119873 norm:0.002707803389057517 max memory_allocated 22564.09130859375 
[2025-03-02 09:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.28063076734542847 norm:0.0026231163647025824 max memory_allocated 22564.09130859375 
[2025-03-02 09:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.2806617319583893 norm:0.002417627489194274 max memory_allocated 22564.09130859375 
[2025-03-02 09:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.2804794907569885 norm:0.0025962889194488525 max memory_allocated 22564.09130859375 
[2025-03-02 09:49:21 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.28053900599479675 norm:0.0022982442751526833 max memory_allocated 22564.09130859375 
[2025-03-02 09:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.2803478538990021 norm:0.0024511993397027254 max memory_allocated 22564.09130859375 
[2025-03-02 09:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.28029370307922363 norm:0.002295211423188448 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.28014877438545227 norm:0.0022297187242656946 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.28008902072906494 norm:0.002168976003304124 max memory_allocated 22564.09130859375 
[2025-03-02 09:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.2800654172897339 norm:0.0021319305524230003 max memory_allocated 22564.09130859375 
[2025-03-02 09:52:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.27999988198280334 norm:0.0020931793842464685 max memory_allocated 22564.09130859375 
[2025-03-02 09:53:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.2800584137439728 norm:0.0021757797803729773 max memory_allocated 22564.09130859375 
[2025-03-02 09:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.2801362872123718 norm:0.001970754936337471 max memory_allocated 22564.09130859375 
[2025-03-02 09:54:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.28009212017059326 norm:0.0021464352030307055 max memory_allocated 22564.09130859375 
[2025-03-02 09:54:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:54:32 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.390164852142334 norm:0.01920248381793499 max memory_allocated 22564.26318359375 
[2025-03-02 09:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.3710586428642273 norm:0.017102548852562904 max memory_allocated 22564.26318359375 
[2025-03-02 09:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.3616892099380493 norm:0.017639338970184326 max memory_allocated 22564.26318359375 
[2025-03-02 09:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.3572885990142822 norm:0.017577506601810455 max memory_allocated 22564.26318359375 
[2025-03-02 09:57:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.35549795627593994 norm:0.017486251890659332 max memory_allocated 22564.26318359375 
[2025-03-02 09:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.3543732166290283 norm:0.01685713231563568 max memory_allocated 22564.26318359375 
[2025-03-02 09:58:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.3533070683479309 norm:0.016510633751749992 max memory_allocated 22564.26318359375 
[2025-03-02 09:58:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.3528505265712738 norm:0.01678195409476757 max memory_allocated 22564.26318359375 
[2025-03-02 09:59:31 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.3522338569164276 norm:0.016650976613163948 max memory_allocated 22564.26318359375 
[2025-03-02 10:00:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.35205650329589844 norm:0.015973182395100594 max memory_allocated 22564.26318359375 
[2025-03-02 10:00:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.35147368907928467 norm:0.015324428677558899 max memory_allocated 22564.26318359375 
[2025-03-02 10:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.3508126735687256 norm:0.013826022855937481 max memory_allocated 22564.26318359375 
[2025-03-02 10:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.35047268867492676 norm:0.013264451175928116 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.3502591550350189 norm:0.01274719275534153 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:50 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.35004135966300964 norm:0.012554977089166641 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:23 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.34999457001686096 norm:0.011921525001525879 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.35001376271247864 norm:0.011626699939370155 max memory_allocated 22564.26318359375 
[2025-03-02 10:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.34989669919013977 norm:0.011443679220974445 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.3497236669063568 norm:0.01119239628314972 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.3496377170085907 norm:0.01083242055028677 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 10:05:48 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 10:06:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.6878445148468018 norm:0.04270824417471886 max memory_allocated 22564.43505859375 
[2025-03-02 10:06:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.6435229182243347 norm:0.029105093330144882 max memory_allocated 22564.43505859375 
[2025-03-02 10:07:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.6172833442687988 norm:0.022044960409402847 max memory_allocated 22564.43505859375 
[2025-03-02 10:08:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.602651059627533 norm:0.01804252900183201 max memory_allocated 22564.43505859375 
[2025-03-02 10:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.594118595123291 norm:0.015342661179602146 max memory_allocated 22564.43505859375 
[2025-03-02 10:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.5877255201339722 norm:0.013893011957406998 max memory_allocated 22564.43505859375 
[2025-03-02 10:09:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.5834217071533203 norm:0.013331796042621136 max memory_allocated 22564.43505859375 
[2025-03-02 10:10:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.5804557204246521 norm:0.012675907462835312 max memory_allocated 22564.43505859375 
[2025-03-02 10:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.578550398349762 norm:0.012864789925515652 max memory_allocated 22564.43505859375 
[2025-03-02 10:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.5773642659187317 norm:0.012926961295306683 max memory_allocated 22564.43505859375 
[2025-03-02 10:11:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.5763732194900513 norm:0.012232196517288685 max memory_allocated 22564.43505859375 
[2025-03-02 10:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.5749560594558716 norm:0.012534761801362038 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.5745557546615601 norm:0.012362872250378132 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.5741990208625793 norm:0.012365898117423058 max memory_allocated 22564.43505859375 
[2025-03-02 10:14:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.5736066699028015 norm:0.011995966546237469 max memory_allocated 22564.43505859375 
[2025-03-02 10:14:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.5730355381965637 norm:0.01219627819955349 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.5725744962692261 norm:0.011875348165631294 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.5723276138305664 norm:0.012073121033608913 max memory_allocated 22564.43505859375 
[2025-03-02 10:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.5717737078666687 norm:0.011717595160007477 max memory_allocated 22564.43505859375 
[2025-03-02 10:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.5716796517372131 norm:0.01182903628796339 max memory_allocated 22564.43505859375 
[2025-03-02 10:17:03 root] (main_calib_config2.py 372): INFO 21611.171899795532
[2025-03-02 10:17:09 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 10:18:19 root] (main_calib_config2.py 159): INFO wikitext2 : 5.812169551849365
[2025-03-02 10:18:19 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 10:20:07 root] (main_calib_config2.py 159): INFO c4 : 7.280241966247559
[2025-03-02 12:00:35 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.812169551849365, 'c4': 7.280241966247559, 'results': {'piqa': {'acc': 0.7736670293797606, 'acc_stderr': 0.009763294246879425, 'acc_norm': 0.7731229597388466, 'acc_norm_stderr': 0.00977158425921518}, 'hellaswag': {'acc': 0.5557657837084247, 'acc_stderr': 0.00495864962381534, 'acc_norm': 0.7170882294363673, 'acc_norm_stderr': 0.0044949340254623405}, 'winogrande': {'acc': 0.6511444356748224, 'acc_stderr': 0.013395059320137329}, 'arc_easy': {'acc': 0.6595117845117845, 'acc_stderr': 0.009723676813825865, 'acc_norm': 0.5218855218855218, 'acc_norm_stderr': 0.010249950427234162}, 'boolq': {'acc': 0.7198776758409786, 'acc_stderr': 0.007854087822506241}, 'arc_challenge': {'acc': 0.38822525597269625, 'acc_stderr': 0.014241614207414037, 'acc_norm': 0.3993174061433447, 'acc_norm_stderr': 0.014312094557946709}}, 'versions': {'piqa': 0, 'hellaswag': 0, 'winogrande': 0, 'arc_easy': 0, 'boolq': 1, 'arc_challenge': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
