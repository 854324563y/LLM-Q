[2025-03-01 14:29:16 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-13b-hf_0.95', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.95.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-01 14:29:21 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-01 14:29:21 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-01 14:29:21 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-01 14:29:21 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.95.pkl
[2025-03-01 14:29:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-01 14:29:44 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.006509814877063036 norm:0.01168204564601183 max memory_allocated 29271.02001953125 
[2025-03-01 14:31:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.003579376731067896 norm:0.006682621780782938 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0029958924278616905 norm:0.005195687524974346 max memory_allocated 29271.02001953125 
[2025-03-01 14:32:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.00269558047875762 norm:0.004146229475736618 max memory_allocated 29271.02001953125 
[2025-03-01 14:33:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.002493839943781495 norm:0.0034108080435544252 max memory_allocated 29271.02001953125 
[2025-03-01 14:34:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.002383796265348792 norm:0.002825790084898472 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0022070189006626606 norm:0.0022159649524837732 max memory_allocated 29271.02001953125 
[2025-03-01 14:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.002154208952561021 norm:0.001996826846152544 max memory_allocated 29271.02001953125 
[2025-03-01 14:36:35 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.002218365203589201 norm:0.0018851794302463531 max memory_allocated 29271.02001953125 
[2025-03-01 14:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.002118071774020791 norm:0.001612937543541193 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0020931661128997803 norm:0.001412676996551454 max memory_allocated 29271.02001953125 
[2025-03-01 14:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.002091404516249895 norm:0.0014193210517987609 max memory_allocated 29271.02001953125 
[2025-03-01 14:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0019615450873970985 norm:0.0011253771372139454 max memory_allocated 29271.02001953125 
[2025-03-01 14:40:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.001980625791475177 norm:0.0010509464191272855 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001983711263164878 norm:0.0010247613536193967 max memory_allocated 29271.02001953125 
[2025-03-01 14:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.001959980931133032 norm:0.0009997168090194464 max memory_allocated 29271.02001953125 
[2025-03-01 14:42:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.00192761211656034 norm:0.000930356327444315 max memory_allocated 29271.02001953125 
[2025-03-01 14:43:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.00194416637532413 norm:0.0009498932049609721 max memory_allocated 29271.02001953125 
[2025-03-01 14:44:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0020899823866784573 norm:0.0010334181133657694 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0020113401114940643 norm:0.0009914740221574903 max memory_allocated 29271.02001953125 
[2025-03-01 14:45:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-01 14:45:23 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 14:46:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.007322071120142937 norm:0.005172959063202143 max memory_allocated 29271.02001953125 
[2025-03-01 14:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.005087078548967838 norm:0.0037953041028231382 max memory_allocated 29271.02001953125 
[2025-03-01 14:47:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.004467072896659374 norm:0.0028369452338665724 max memory_allocated 29271.02001953125 
[2025-03-01 14:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.004193206317722797 norm:0.00243734591640532 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.004029398784041405 norm:0.0021608537063002586 max memory_allocated 29271.02001953125 
[2025-03-01 14:49:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.00393690587952733 norm:0.00199307082220912 max memory_allocated 29271.02001953125 
[2025-03-01 14:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.0038720525335520506 norm:0.00178622140083462 max memory_allocated 29271.02001953125 
[2025-03-01 14:51:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.003818295430392027 norm:0.0015881359577178955 max memory_allocated 29271.02001953125 
[2025-03-01 14:52:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.003753500757738948 norm:0.0013458628673106432 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.003706617746502161 norm:0.001183142652735114 max memory_allocated 29271.02001953125 
[2025-03-01 14:53:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.0036787253338843584 norm:0.0010965998517349362 max memory_allocated 29271.02001953125 
[2025-03-01 14:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.003649946302175522 norm:0.0010107510024681687 max memory_allocated 29271.02001953125 
[2025-03-01 14:55:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.003618058282881975 norm:0.0009436841355636716 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.0035973861813545227 norm:0.0008624990005046129 max memory_allocated 29271.02001953125 
[2025-03-01 14:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.00357427797280252 norm:0.0008430158486589789 max memory_allocated 29271.02001953125 
[2025-03-01 14:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.0035795692820101976 norm:0.0008543612784706056 max memory_allocated 29271.02001953125 
[2025-03-01 14:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.00361144682392478 norm:0.0010525309480726719 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.0035290259402245283 norm:0.0007628087769262493 max memory_allocated 29271.02001953125 
[2025-03-01 14:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.0034852034877985716 norm:0.0006548315286636353 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.003480759682133794 norm:0.0006420508725568652 max memory_allocated 29271.02001953125 
[2025-03-01 15:00:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-01 15:01:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 15:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.008717754855751991 norm:0.0034689619205892086 max memory_allocated 29271.02001953125 
[2025-03-01 15:02:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.006808836944401264 norm:0.0032374709844589233 max memory_allocated 29271.02001953125 
[2025-03-01 15:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.006207883358001709 norm:0.002421353477984667 max memory_allocated 29271.02001953125 
[2025-03-01 15:04:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.005925554316490889 norm:0.00205252505838871 max memory_allocated 29271.02001953125 
[2025-03-01 15:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.005773305427283049 norm:0.0018539665034040809 max memory_allocated 29271.02001953125 
[2025-03-01 15:05:38 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.0056404005736112595 norm:0.0016295819077640772 max memory_allocated 29271.02001953125 
[2025-03-01 15:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.005494983866810799 norm:0.0013885319931432605 max memory_allocated 29271.02001953125 
[2025-03-01 15:07:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.005380401853471994 norm:0.0012316586216911674 max memory_allocated 29271.02001953125 
[2025-03-01 15:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.005273682065308094 norm:0.0010492451256141067 max memory_allocated 29271.02001953125 
[2025-03-01 15:08:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.005188283044844866 norm:0.0009342600824311376 max memory_allocated 29271.02001953125 
[2025-03-01 15:09:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.005121405236423016 norm:0.0008290352998301387 max memory_allocated 29271.02001953125 
[2025-03-01 15:10:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.005160985514521599 norm:0.0008374496246688068 max memory_allocated 29271.02001953125 
[2025-03-01 15:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.005109670106321573 norm:0.0007835070136934519 max memory_allocated 29271.02001953125 
[2025-03-01 15:11:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.005048163700848818 norm:0.0006286093848757446 max memory_allocated 29271.02001953125 
[2025-03-01 15:12:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.0050612459890544415 norm:0.0006020060973241925 max memory_allocated 29271.02001953125 
[2025-03-01 15:13:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.005121039226651192 norm:0.0007422554772347212 max memory_allocated 29271.02001953125 
[2025-03-01 15:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.005357885733246803 norm:0.001103284303098917 max memory_allocated 29271.02001953125 
[2025-03-01 15:14:50 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.005064445082098246 norm:0.0005857752403244376 max memory_allocated 29271.02001953125 
[2025-03-01 15:15:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.005014063324779272 norm:0.0004959421930834651 max memory_allocated 29271.02001953125 
[2025-03-01 15:16:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.004987976048141718 norm:0.00040235609048977494 max memory_allocated 29271.02001953125 
[2025-03-01 15:16:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-01 15:17:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.11677060276269913 norm:0.01807154342532158 max memory_allocated 29271.43798828125 
[2025-03-01 15:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.08992915600538254 norm:0.01292990893125534 max memory_allocated 29271.43798828125 
[2025-03-01 15:18:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.0628526583313942 norm:0.012899469584226608 max memory_allocated 29271.43798828125 
[2025-03-01 15:19:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.04410408064723015 norm:0.007287220563739538 max memory_allocated 29271.43798828125 
[2025-03-01 15:20:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.0373072512447834 norm:0.005037915427237749 max memory_allocated 29271.43798828125 
[2025-03-01 15:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.03109428845345974 norm:0.003514571115374565 max memory_allocated 29271.43798828125 
[2025-03-01 15:22:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.030937829986214638 norm:0.0038363945204764605 max memory_allocated 29271.43798828125 
[2025-03-01 15:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.030952492728829384 norm:0.004166581202298403 max memory_allocated 29271.43798828125 
[2025-03-01 15:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.028773963451385498 norm:0.00332066067494452 max memory_allocated 29271.43798828125 
[2025-03-01 15:24:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.028252702206373215 norm:0.0033638791646808386 max memory_allocated 29271.43798828125 
[2025-03-01 15:25:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.02718282677233219 norm:0.002642516978085041 max memory_allocated 29271.43798828125 
[2025-03-01 15:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.02593958005309105 norm:0.002586415968835354 max memory_allocated 29271.43798828125 
[2025-03-01 15:26:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.025816630572080612 norm:0.0024716926272958517 max memory_allocated 29271.43798828125 
[2025-03-01 15:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.02694092132151127 norm:0.002892737742513418 max memory_allocated 29271.43798828125 
[2025-03-01 15:28:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.02435935288667679 norm:0.0024173669517040253 max memory_allocated 29271.43798828125 
[2025-03-01 15:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.025704458355903625 norm:0.003100108355283737 max memory_allocated 29271.43798828125 
[2025-03-01 15:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.025346878916025162 norm:0.0022936337627470493 max memory_allocated 29271.43798828125 
[2025-03-01 15:30:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.024898607283830643 norm:0.0023810751736164093 max memory_allocated 29271.43798828125 
[2025-03-01 15:31:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.02368534915149212 norm:0.00238132756203413 max memory_allocated 29271.43798828125 
[2025-03-01 15:31:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.024760426953434944 norm:0.0025404056068509817 max memory_allocated 29271.43798828125 
[2025-03-01 15:32:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-01 15:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.020856015384197235 norm:0.0005816866178065538 max memory_allocated 29271.43798828125 
[2025-03-01 15:33:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.01843889430165291 norm:0.00023879102081991732 max memory_allocated 29271.43798828125 
[2025-03-01 15:34:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.017727594822645187 norm:0.0001349575031781569 max memory_allocated 29271.43798828125 
[2025-03-01 15:35:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.017387421801686287 norm:0.00010271858627675101 max memory_allocated 29271.43798828125 
[2025-03-01 15:36:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.017150405794382095 norm:9.049726213561371e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:36:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.016939518973231316 norm:8.064048597589135e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.01678297109901905 norm:7.76311062509194e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:38:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.016668379306793213 norm:7.399519381579012e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.016611091792583466 norm:7.462255598511547e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:39:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.016580965369939804 norm:7.705775351496413e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.01654909923672676 norm:7.315907714655623e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.01654866896569729 norm:7.807445217622444e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:42:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.016536232084035873 norm:8.196416456485167e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:42:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.01652054861187935 norm:7.621471741003916e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:43:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.01651126518845558 norm:8.128277841024101e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:44:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.01650049537420273 norm:7.896324677858502e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:45:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.016495682299137115 norm:7.952774467412382e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.016481567174196243 norm:8.1986901932396e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:46:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.01648836024105549 norm:8.404685650020838e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:47:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.01648274064064026 norm:8.101634011836722e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:47:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-01 15:48:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.02172435261309147 norm:0.0007124874973669648 max memory_allocated 29271.43798828125 
[2025-03-01 15:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.01937519758939743 norm:0.00029856947367079556 max memory_allocated 29271.43798828125 
[2025-03-01 15:50:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.018627339974045753 norm:0.0001857923052739352 max memory_allocated 29271.43798828125 
[2025-03-01 15:51:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.018257634714245796 norm:0.00013573854812420905 max memory_allocated 29271.43798828125 
[2025-03-01 15:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.017969269305467606 norm:0.00011580232967389748 max memory_allocated 29271.43798828125 
[2025-03-01 15:52:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.01773223839700222 norm:9.903051977744326e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:53:17 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.017566543072462082 norm:9.539158781990409e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:54:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.017464350908994675 norm:9.548108209855855e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:54:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.01742401160299778 norm:9.56410585786216e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:55:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.017375821247696877 norm:8.598092244938016e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.01735564135015011 norm:8.701648039277643e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:57:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.01733323186635971 norm:8.475460344925523e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:57:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.017327498644590378 norm:9.373411739943549e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.017317242920398712 norm:8.912419434636831e-05 max memory_allocated 29271.43798828125 
[2025-03-01 15:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.017301097512245178 norm:8.835792687023059e-05 max memory_allocated 29271.43798828125 
[2025-03-01 16:00:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.017288483679294586 norm:8.645690104458481e-05 max memory_allocated 29271.43798828125 
[2025-03-01 16:00:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.017286745831370354 norm:9.026918996823952e-05 max memory_allocated 29271.43798828125 
[2025-03-01 16:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.017287753522396088 norm:8.915402577258646e-05 max memory_allocated 29271.43798828125 
[2025-03-01 16:02:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.017283178865909576 norm:9.608433174435049e-05 max memory_allocated 29271.43798828125 
[2025-03-01 16:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.01728035695850849 norm:0.00010291471699019894 max memory_allocated 29271.43798828125 
[2025-03-01 16:03:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-01 16:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.02444816194474697 norm:0.0011066601146012545 max memory_allocated 29272.00048828125 
[2025-03-01 16:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.0209965780377388 norm:0.000462629395769909 max memory_allocated 29272.00048828125 
[2025-03-01 16:05:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.0198654942214489 norm:0.0002545938768889755 max memory_allocated 29272.00048828125 
[2025-03-01 16:06:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.019325613975524902 norm:0.0001724454778013751 max memory_allocated 29272.00048828125 
[2025-03-01 16:07:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.018971141427755356 norm:0.00013506413961295038 max memory_allocated 29272.00048828125 
[2025-03-01 16:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.01868923008441925 norm:0.00011756250751204789 max memory_allocated 29272.00048828125 
[2025-03-01 16:08:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.018500789999961853 norm:0.00010550278966547921 max memory_allocated 29272.00048828125 
[2025-03-01 16:09:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.018402883782982826 norm:0.00010261794523103163 max memory_allocated 29272.00048828125 
[2025-03-01 16:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.018330032005906105 norm:9.469537326367572e-05 max memory_allocated 29272.00048828125 
[2025-03-01 16:11:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.01829332299530506 norm:0.00010314860264770687 max memory_allocated 29272.00048828125 
[2025-03-01 16:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.01826752908527851 norm:9.409605263499543e-05 max memory_allocated 29272.00048828125 
[2025-03-01 16:12:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.018258314579725266 norm:9.448147466173396e-05 max memory_allocated 29272.00048828125 
[2025-03-01 16:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.018236737698316574 norm:9.797517122933641e-05 max memory_allocated 29272.00048828125 
[2025-03-01 16:14:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.018228864297270775 norm:0.00010523144737817347 max memory_allocated 29272.00048828125 
[2025-03-01 16:15:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.01821887493133545 norm:9.870671055978164e-05 max memory_allocated 29272.00048828125 
[2025-03-01 16:15:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.01821432262659073 norm:0.00010532565647736192 max memory_allocated 29272.00048828125 
[2025-03-01 16:16:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.018205471336841583 norm:0.00010340633889427409 max memory_allocated 29272.00048828125 
[2025-03-01 16:17:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.018203839659690857 norm:0.00011348610132699832 max memory_allocated 29272.00048828125 
[2025-03-01 16:18:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.018199672922492027 norm:0.00010849507089005783 max memory_allocated 29272.00048828125 
[2025-03-01 16:18:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.018207749351859093 norm:0.00010616701183607802 max memory_allocated 29272.00048828125 
[2025-03-01 16:19:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-01 16:19:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.02648276276886463 norm:0.0009755039936862886 max memory_allocated 29272.18798828125 
[2025-03-01 16:20:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.022998640313744545 norm:0.0004504774115048349 max memory_allocated 29272.18798828125 
[2025-03-01 16:21:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.02190469764173031 norm:0.000282973051071167 max memory_allocated 29272.18798828125 
[2025-03-01 16:22:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.021320398896932602 norm:0.00021593880956061184 max memory_allocated 29272.18798828125 
[2025-03-01 16:22:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.020924236625432968 norm:0.000178203743416816 max memory_allocated 29272.18798828125 
[2025-03-01 16:23:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.020626287907361984 norm:0.00016388898075092584 max memory_allocated 29272.18798828125 
[2025-03-01 16:24:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.02040313370525837 norm:0.00014510499022435397 max memory_allocated 29272.18798828125 
[2025-03-01 16:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.02027757279574871 norm:0.00013567354471888393 max memory_allocated 29272.18798828125 
[2025-03-01 16:25:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.02021847665309906 norm:0.00013904467050451785 max memory_allocated 29272.18798828125 
[2025-03-01 16:26:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.02016608975827694 norm:0.00013368811050895602 max memory_allocated 29272.18798828125 
[2025-03-01 16:27:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.020125512033700943 norm:0.00013920170022174716 max memory_allocated 29272.18798828125 
[2025-03-01 16:28:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.020096248015761375 norm:0.00013830690295435488 max memory_allocated 29272.18798828125 
[2025-03-01 16:29:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.020091133192181587 norm:0.00013315868272911757 max memory_allocated 29272.18798828125 
[2025-03-01 16:29:47 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.02007412351667881 norm:0.00013498857151716948 max memory_allocated 29272.18798828125 
[2025-03-01 16:30:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.020049050450325012 norm:0.00012512413377407938 max memory_allocated 29272.18798828125 
[2025-03-01 16:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.02003231644630432 norm:0.0001255795214092359 max memory_allocated 29272.18798828125 
[2025-03-01 16:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.020018544048070908 norm:0.00012868049088865519 max memory_allocated 29272.18798828125 
[2025-03-01 16:32:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.02000471204519272 norm:0.00012672407319769263 max memory_allocated 29272.18798828125 
[2025-03-01 16:33:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.02001211978495121 norm:0.00013398942246567458 max memory_allocated 29272.18798828125 
[2025-03-01 16:34:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.02000180073082447 norm:0.0001308389037149027 max memory_allocated 29272.18798828125 
[2025-03-01 16:34:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-01 16:35:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.03014100342988968 norm:0.0011560353450477123 max memory_allocated 29272.37548828125 
[2025-03-01 16:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.02531892992556095 norm:0.0005400972440838814 max memory_allocated 29272.37548828125 
[2025-03-01 16:36:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.02352333255112171 norm:0.0003101785259786993 max memory_allocated 29272.37548828125 
[2025-03-01 16:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.022746602073311806 norm:0.0002092711511068046 max memory_allocated 29272.37548828125 
[2025-03-01 16:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.022266598418354988 norm:0.00016090292774606496 max memory_allocated 29272.37548828125 
[2025-03-01 16:39:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.021955139935016632 norm:0.00013594148913398385 max memory_allocated 29272.37548828125 
[2025-03-01 16:39:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.021746106445789337 norm:0.00012741117097903043 max memory_allocated 29272.37548828125 
[2025-03-01 16:40:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.021633630618453026 norm:0.0001165695211966522 max memory_allocated 29272.37548828125 
[2025-03-01 16:41:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.02155900001525879 norm:0.00011408761201892048 max memory_allocated 29272.37548828125 
[2025-03-01 16:42:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.021505193784832954 norm:0.00010865960211958736 max memory_allocated 29272.37548828125 
[2025-03-01 16:43:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.02147233672440052 norm:0.000106621919258032 max memory_allocated 29272.37548828125 
[2025-03-01 16:43:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.021429579704999924 norm:0.00010172970360144973 max memory_allocated 29272.37548828125 
[2025-03-01 16:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.021421410143375397 norm:0.0001005400117719546 max memory_allocated 29272.37548828125 
[2025-03-01 16:45:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.02139686606824398 norm:9.737406799104065e-05 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.02137318067252636 norm:9.580767073202878e-05 max memory_allocated 29272.37548828125 
[2025-03-01 16:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.021359797567129135 norm:9.724592382553965e-05 max memory_allocated 29272.37548828125 
[2025-03-01 16:47:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.021359501406550407 norm:0.00010180014214711264 max memory_allocated 29272.37548828125 
[2025-03-01 16:48:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.0213469248265028 norm:9.683835378382355e-05 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.021325817331671715 norm:9.811478230403736e-05 max memory_allocated 29272.37548828125 
[2025-03-01 16:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.02130994386970997 norm:9.940263407770544e-05 max memory_allocated 29272.37548828125 
[2025-03-01 16:50:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-01 16:50:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.032491814345121384 norm:0.0011154123349115252 max memory_allocated 29272.56298828125 
[2025-03-01 16:51:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.027929965406656265 norm:0.0005481973639689386 max memory_allocated 29272.56298828125 
[2025-03-01 16:52:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.02615048550069332 norm:0.00033838165109045804 max memory_allocated 29272.56298828125 
[2025-03-01 16:53:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.02519279532134533 norm:0.0002424760168651119 max memory_allocated 29272.56298828125 
[2025-03-01 16:53:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.024609893560409546 norm:0.00018595987057778984 max memory_allocated 29272.56298828125 
[2025-03-01 16:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.024215172976255417 norm:0.00015708926366642118 max memory_allocated 29272.56298828125 
[2025-03-01 16:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.02401416376233101 norm:0.0001439713960280642 max memory_allocated 29272.56298828125 
[2025-03-01 16:56:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.023874932900071144 norm:0.00013951497385278344 max memory_allocated 29272.56298828125 
[2025-03-01 16:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.02380264364182949 norm:0.00013084124657325447 max memory_allocated 29272.56298828125 
[2025-03-01 16:57:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.02375260926783085 norm:0.00013236686936579645 max memory_allocated 29272.56298828125 
[2025-03-01 16:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.023698190227150917 norm:0.00012593477731570601 max memory_allocated 29272.56298828125 
[2025-03-01 16:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.023661335930228233 norm:0.00012391289055813104 max memory_allocated 29272.56298828125 
[2025-03-01 17:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.02363002859055996 norm:0.00012388150207698345 max memory_allocated 29272.56298828125 
[2025-03-01 17:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.023609798401594162 norm:0.00012091681128367782 max memory_allocated 29272.56298828125 
[2025-03-01 17:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.0236014686524868 norm:0.00012100923777325079 max memory_allocated 29272.56298828125 
[2025-03-01 17:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.023604627698659897 norm:0.0001225191808771342 max memory_allocated 29272.56298828125 
[2025-03-01 17:03:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.02359124831855297 norm:0.00011804186215158552 max memory_allocated 29272.56298828125 
[2025-03-01 17:03:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.02358580380678177 norm:0.00013321859296411276 max memory_allocated 29272.56298828125 
[2025-03-01 17:04:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.023599334061145782 norm:0.00012675923062488437 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.023571649566292763 norm:0.00011917969095520675 max memory_allocated 29272.56298828125 
[2025-03-01 17:05:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-01 17:06:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.03504066914319992 norm:0.00128086656332016 max memory_allocated 29272.75048828125 
[2025-03-01 17:07:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.029992302879691124 norm:0.0006394467782229185 max memory_allocated 29272.75048828125 
[2025-03-01 17:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.027977988123893738 norm:0.0003745784633792937 max memory_allocated 29272.75048828125 
[2025-03-01 17:08:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.027031781151890755 norm:0.00025786482729017735 max memory_allocated 29272.75048828125 
[2025-03-01 17:09:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.026463495567440987 norm:0.00019662242266349494 max memory_allocated 29272.75048828125 
[2025-03-01 17:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.026109201833605766 norm:0.00016563473036512733 max memory_allocated 29272.75048828125 
[2025-03-01 17:11:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.02589796483516693 norm:0.00015027832705527544 max memory_allocated 29272.75048828125 
[2025-03-01 17:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.025749672204256058 norm:0.00013409236271400005 max memory_allocated 29272.75048828125 
[2025-03-01 17:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.02565360628068447 norm:0.00012517053983174264 max memory_allocated 29272.75048828125 
[2025-03-01 17:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.025582216680049896 norm:0.00012121624604333192 max memory_allocated 29272.75048828125 
[2025-03-01 17:14:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.025525787845253944 norm:0.00011717785673681647 max memory_allocated 29272.75048828125 
[2025-03-01 17:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.02548983134329319 norm:0.00011131943756481633 max memory_allocated 29272.75048828125 
[2025-03-01 17:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.025445494800806046 norm:0.00010783512698253617 max memory_allocated 29272.75048828125 
[2025-03-01 17:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.02542301081120968 norm:0.00010782921162899584 max memory_allocated 29272.75048828125 
[2025-03-01 17:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.025396928191184998 norm:0.00010907286196015775 max memory_allocated 29272.75048828125 
[2025-03-01 17:17:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.0253984984010458 norm:0.00010326615301892161 max memory_allocated 29272.75048828125 
[2025-03-01 17:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.025382181629538536 norm:0.0001016675159917213 max memory_allocated 29272.75048828125 
[2025-03-01 17:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.025389820337295532 norm:0.00010312359518138692 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.025357503443956375 norm:0.00010006200318457559 max memory_allocated 29272.75048828125 
[2025-03-01 17:20:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.02534349448978901 norm:9.752601908985525e-05 max memory_allocated 29272.75048828125 
[2025-03-01 17:21:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-01 17:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.03536798804998398 norm:0.0008459120872430503 max memory_allocated 29272.93798828125 
[2025-03-01 17:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.030897248536348343 norm:0.00039303829544223845 max memory_allocated 29272.93798828125 
[2025-03-01 17:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.029203811660408974 norm:0.00023188465274870396 max memory_allocated 29272.93798828125 
[2025-03-01 17:24:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.028464721515774727 norm:0.000166502853971906 max memory_allocated 29272.93798828125 
[2025-03-01 17:25:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.02800728753209114 norm:0.00013306520122569054 max memory_allocated 29272.93798828125 
[2025-03-01 17:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.027722403407096863 norm:0.00011701836046995595 max memory_allocated 29272.93798828125 
[2025-03-01 17:26:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.027561111375689507 norm:0.00010926040704362094 max memory_allocated 29272.93798828125 
[2025-03-01 17:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.02745714969933033 norm:0.00010580415255390108 max memory_allocated 29272.93798828125 
[2025-03-01 17:28:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.027390217408537865 norm:0.00010168056178372353 max memory_allocated 29272.93798828125 
[2025-03-01 17:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.02735637128353119 norm:9.983097697841004e-05 max memory_allocated 29272.93798828125 
[2025-03-01 17:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.027313247323036194 norm:9.632709407014772e-05 max memory_allocated 29272.93798828125 
[2025-03-01 17:30:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.027278760448098183 norm:9.579469042364508e-05 max memory_allocated 29272.93798828125 
[2025-03-01 17:31:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.027248509228229523 norm:9.256979683414102e-05 max memory_allocated 29272.93798828125 
[2025-03-01 17:31:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.027223028242588043 norm:8.953924407251179e-05 max memory_allocated 29272.93798828125 
[2025-03-01 17:32:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.02720535919070244 norm:9.061046876013279e-05 max memory_allocated 29272.93798828125 
[2025-03-01 17:33:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.02719019539654255 norm:8.966866880655289e-05 max memory_allocated 29272.93798828125 
[2025-03-01 17:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.027179766446352005 norm:8.912370685720816e-05 max memory_allocated 29272.93798828125 
[2025-03-01 17:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.027167558670043945 norm:8.669457747600973e-05 max memory_allocated 29272.93798828125 
[2025-03-01 17:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.02715829387307167 norm:8.639433508506045e-05 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.02714758738875389 norm:8.694861753610894e-05 max memory_allocated 29272.93798828125 
[2025-03-01 17:36:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-01 17:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.036749083548784256 norm:0.0007965224795043468 max memory_allocated 29273.12548828125 
[2025-03-01 17:38:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.032007209956645966 norm:0.000375541829271242 max memory_allocated 29273.12548828125 
[2025-03-01 17:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.030399195849895477 norm:0.00023717843578197062 max memory_allocated 29273.12548828125 
[2025-03-01 17:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.029625479131937027 norm:0.0001752069656504318 max memory_allocated 29273.12548828125 
[2025-03-01 17:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.029157938435673714 norm:0.0001409278338542208 max memory_allocated 29273.12548828125 
[2025-03-01 17:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.02885344810783863 norm:0.0001242171711055562 max memory_allocated 29273.12548828125 
[2025-03-01 17:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.028673890978097916 norm:0.0001139938976848498 max memory_allocated 29273.12548828125 
[2025-03-01 17:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.02855401486158371 norm:0.00010800492600537837 max memory_allocated 29273.12548828125 
[2025-03-01 17:43:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.028464026749134064 norm:0.00010268851474393159 max memory_allocated 29273.12548828125 
[2025-03-01 17:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.02839827537536621 norm:9.797295206226408e-05 max memory_allocated 29273.12548828125 
[2025-03-01 17:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.02836218848824501 norm:9.450447396375239e-05 max memory_allocated 29273.12548828125 
[2025-03-01 17:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.02832842990756035 norm:9.274364856537431e-05 max memory_allocated 29273.12548828125 
[2025-03-01 17:46:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.02830028533935547 norm:9.040892473421991e-05 max memory_allocated 29273.12548828125 
[2025-03-01 17:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.028274476528167725 norm:8.915083890315145e-05 max memory_allocated 29273.12548828125 
[2025-03-01 17:48:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.0282440185546875 norm:8.730402623768896e-05 max memory_allocated 29273.12548828125 
[2025-03-01 17:48:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.02822849154472351 norm:8.450054883724079e-05 max memory_allocated 29273.12548828125 
[2025-03-01 17:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.028220802545547485 norm:8.202246681321412e-05 max memory_allocated 29273.12548828125 
[2025-03-01 17:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.028206033632159233 norm:8.127683395287022e-05 max memory_allocated 29273.12548828125 
[2025-03-01 17:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.028181975707411766 norm:7.839260797481984e-05 max memory_allocated 29273.12548828125 
[2025-03-01 17:52:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.02817620523273945 norm:8.233349944930524e-05 max memory_allocated 29273.12548828125 
[2025-03-01 17:52:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-01 17:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.03758284077048302 norm:0.0008369909483008087 max memory_allocated 29273.31298828125 
[2025-03-01 17:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.03352578729391098 norm:0.0004359296290203929 max memory_allocated 29273.31298828125 
[2025-03-01 17:54:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.03180886059999466 norm:0.00027570148813538253 max memory_allocated 29273.31298828125 
[2025-03-01 17:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.03099181316792965 norm:0.00020806468091905117 max memory_allocated 29273.31298828125 
[2025-03-01 17:56:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.03051295503973961 norm:0.0001686186296865344 max memory_allocated 29273.31298828125 
[2025-03-01 17:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.030183423310518265 norm:0.00015087406791280955 max memory_allocated 29273.31298828125 
[2025-03-01 17:57:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.02997148036956787 norm:0.00013339571887627244 max memory_allocated 29273.31298828125 
[2025-03-01 17:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.02983420342206955 norm:0.0001223625586135313 max memory_allocated 29273.31298828125 
[2025-03-01 17:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.02975425124168396 norm:0.00012070894445059821 max memory_allocated 29273.31298828125 
[2025-03-01 18:00:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.029674971476197243 norm:0.00011281722981948406 max memory_allocated 29273.31298828125 
[2025-03-01 18:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.029613973572850227 norm:0.00010548430873313919 max memory_allocated 29273.31298828125 
[2025-03-01 18:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.029573019593954086 norm:0.00010286002361681312 max memory_allocated 29273.31298828125 
[2025-03-01 18:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.029537731781601906 norm:9.833086369326338e-05 max memory_allocated 29273.31298828125 
[2025-03-01 18:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.0294979065656662 norm:9.357954695587978e-05 max memory_allocated 29273.31298828125 
[2025-03-01 18:03:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.02946999855339527 norm:9.096178109757602e-05 max memory_allocated 29273.31298828125 
[2025-03-01 18:04:40 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.029445599764585495 norm:8.963532309280708e-05 max memory_allocated 29273.31298828125 
[2025-03-01 18:05:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.02940382808446884 norm:8.32351652206853e-05 max memory_allocated 29273.31298828125 
[2025-03-01 18:06:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.029384534806013107 norm:8.059215906541795e-05 max memory_allocated 29273.31298828125 
[2025-03-01 18:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.02937047742307186 norm:7.938429189380258e-05 max memory_allocated 29273.31298828125 
[2025-03-01 18:07:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.02935176156461239 norm:7.93518775026314e-05 max memory_allocated 29273.31298828125 
[2025-03-01 18:07:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-01 18:08:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.038456931710243225 norm:0.0008475723443552852 max memory_allocated 29273.50048828125 
[2025-03-01 18:09:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.03432396054267883 norm:0.0004374756827019155 max memory_allocated 29273.50048828125 
[2025-03-01 18:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.032677941024303436 norm:0.00027006107848137617 max memory_allocated 29273.50048828125 
[2025-03-01 18:11:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.03193216770887375 norm:0.00019519409397616982 max memory_allocated 29273.50048828125 
[2025-03-01 18:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.03148188441991806 norm:0.00015965082275215536 max memory_allocated 29273.50048828125 
[2025-03-01 18:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.031149718910455704 norm:0.00013826650683768094 max memory_allocated 29273.50048828125 
[2025-03-01 18:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.030940940603613853 norm:0.00012677516497205943 max memory_allocated 29273.50048828125 
[2025-03-01 18:14:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.030807487666606903 norm:0.0001218194593093358 max memory_allocated 29273.50048828125 
[2025-03-01 18:14:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.030701395124197006 norm:0.00011227439244976267 max memory_allocated 29273.50048828125 
[2025-03-01 18:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.030643384903669357 norm:0.00010890838166233152 max memory_allocated 29273.50048828125 
[2025-03-01 18:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.030592886731028557 norm:0.00010389274393673986 max memory_allocated 29273.50048828125 
[2025-03-01 18:17:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.030538108199834824 norm:9.741880057845265e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:17:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.030486570671200752 norm:9.387994941789657e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:18:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.030457347631454468 norm:9.152817801805213e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.03043329529464245 norm:8.756632450968027e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:20:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.03040885180234909 norm:8.49700954859145e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:20:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.03037583827972412 norm:8.280665497295558e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:21:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.03036154992878437 norm:8.111839997582138e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.030352279543876648 norm:8.20190689410083e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:23:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.030337870121002197 norm:8.378307393286377e-05 max memory_allocated 29273.50048828125 
[2025-03-01 18:23:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-01 18:24:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.03637552633881569 norm:0.0005918891401961446 max memory_allocated 29273.68798828125 
[2025-03-01 18:25:03 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.033404625952243805 norm:0.0003017677227035165 max memory_allocated 29273.68798828125 
[2025-03-01 18:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.032177455723285675 norm:0.00019073740986641496 max memory_allocated 29273.68798828125 
[2025-03-01 18:26:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.03160226717591286 norm:0.00014653350808657706 max memory_allocated 29273.68798828125 
[2025-03-01 18:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.031217603012919426 norm:0.0001240079727722332 max memory_allocated 29273.68798828125 
[2025-03-01 18:28:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.030939891934394836 norm:0.00011126841855002567 max memory_allocated 29273.68798828125 
[2025-03-01 18:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.030751116573810577 norm:0.00010096669575432315 max memory_allocated 29273.68798828125 
[2025-03-01 18:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.030621830374002457 norm:9.313326881965622e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:30:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.030545148998498917 norm:8.789915591478348e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:31:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.030487485229969025 norm:8.491081825923175e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:31:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.030445583164691925 norm:8.168719796231017e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:32:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.0304112546145916 norm:7.921674841782078e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:33:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.030381355434656143 norm:7.495352474506944e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.030347924679517746 norm:7.047328108455986e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.03032638132572174 norm:6.835749081801623e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.0303142499178648 norm:6.747939914930612e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.030309636145830154 norm:6.718460645060986e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:37:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.030303779989480972 norm:6.393871444743127e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:38:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.03029414638876915 norm:6.332436169032007e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:38:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.03027632087469101 norm:6.139022298157215e-05 max memory_allocated 29273.68798828125 
[2025-03-01 18:38:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-01 18:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.04037509113550186 norm:0.0010013461578637362 max memory_allocated 29273.87548828125 
[2025-03-01 18:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.03556680679321289 norm:0.0004779496812261641 max memory_allocated 29273.87548828125 
[2025-03-01 18:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.03357335925102234 norm:0.000289165269350633 max memory_allocated 29273.87548828125 
[2025-03-01 18:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.03271901234984398 norm:0.00020149146439507604 max memory_allocated 29273.87548828125 
[2025-03-01 18:42:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.03226838633418083 norm:0.00016757301636971533 max memory_allocated 29273.87548828125 
[2025-03-01 18:43:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.03193100541830063 norm:0.00014716072473675013 max memory_allocated 29273.87548828125 
[2025-03-01 18:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.03169112280011177 norm:0.0001322323951171711 max memory_allocated 29273.87548828125 
[2025-03-01 18:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.03152449429035187 norm:0.00011977383837802336 max memory_allocated 29273.87548828125 
[2025-03-01 18:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.03141265735030174 norm:0.00011462887050583959 max memory_allocated 29273.87548828125 
[2025-03-01 18:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.03134099021553993 norm:0.00011015399650204927 max memory_allocated 29273.87548828125 
[2025-03-01 18:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.031268246471881866 norm:0.00010591201134957373 max memory_allocated 29273.87548828125 
[2025-03-01 18:48:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.031203916296362877 norm:0.0001000125048449263 max memory_allocated 29273.87548828125 
[2025-03-01 18:48:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.031159188598394394 norm:9.782561392057687e-05 max memory_allocated 29273.87548828125 
[2025-03-01 18:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.031121855601668358 norm:9.38819648581557e-05 max memory_allocated 29273.87548828125 
[2025-03-01 18:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.03108515590429306 norm:9.228700946550816e-05 max memory_allocated 29273.87548828125 
[2025-03-01 18:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.031058814376592636 norm:8.941820124164224e-05 max memory_allocated 29273.87548828125 
[2025-03-01 18:52:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.03101964481174946 norm:8.849385631037876e-05 max memory_allocated 29273.87548828125 
[2025-03-01 18:52:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.03098895400762558 norm:8.835709013510495e-05 max memory_allocated 29273.87548828125 
[2025-03-01 18:53:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.030965887010097504 norm:8.655266719870269e-05 max memory_allocated 29273.87548828125 
[2025-03-01 18:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.03094465285539627 norm:8.199355215765536e-05 max memory_allocated 29273.87548828125 
[2025-03-01 18:54:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-01 18:55:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.03735530748963356 norm:0.000993969151750207 max memory_allocated 29274.06298828125 
[2025-03-01 18:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.03431519865989685 norm:0.00048157136188820004 max memory_allocated 29274.06298828125 
[2025-03-01 18:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.03315144404768944 norm:0.0002997205301653594 max memory_allocated 29274.06298828125 
[2025-03-01 18:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.032599058002233505 norm:0.0002139423886546865 max memory_allocated 29274.06298828125 
[2025-03-01 18:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.03222908452153206 norm:0.00017070946341846138 max memory_allocated 29274.06298828125 
[2025-03-01 18:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.03193037956953049 norm:0.00014432851457968354 max memory_allocated 29274.06298828125 
[2025-03-01 18:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.03171687573194504 norm:0.00012694142060354352 max memory_allocated 29274.06298828125 
[2025-03-01 19:00:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.03157349303364754 norm:0.00011266416549915448 max memory_allocated 29274.06298828125 
[2025-03-01 19:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.03147824853658676 norm:0.00010250193008687347 max memory_allocated 29274.06298828125 
[2025-03-01 19:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.031418971717357635 norm:9.546212095301598e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.03136482834815979 norm:8.94707627594471e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.031329989433288574 norm:8.552549843443558e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:04:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.03129856288433075 norm:8.22387810330838e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:05:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.03126462176442146 norm:7.87731769378297e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.031242050230503082 norm:7.568062574137002e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.031226234510540962 norm:7.303627353394404e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.03121061995625496 norm:7.005703082541004e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.03120124340057373 norm:6.674676114926115e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.031188396736979485 norm:6.449945067288354e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.03116566315293312 norm:6.372629286488518e-05 max memory_allocated 29274.06298828125 
[2025-03-01 19:10:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-01 19:10:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.03699447959661484 norm:0.0006405009189620614 max memory_allocated 29274.25048828125 
[2025-03-01 19:11:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.03429010510444641 norm:0.0002935142256319523 max memory_allocated 29274.25048828125 
[2025-03-01 19:12:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.033395033329725266 norm:0.0001867048704298213 max memory_allocated 29274.25048828125 
[2025-03-01 19:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.03295256569981575 norm:0.00013897466124035418 max memory_allocated 29274.25048828125 
[2025-03-01 19:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.03262566402554512 norm:0.00011434033513069153 max memory_allocated 29274.25048828125 
[2025-03-01 19:14:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.03235887736082077 norm:9.856391989160329e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.032167062163352966 norm:8.814579632598907e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.03205396234989166 norm:8.128596527967602e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.03198079764842987 norm:7.552701572421938e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.03193432092666626 norm:7.169300079112872e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:18:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.031898196786642075 norm:6.78872675052844e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:19:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.03186711668968201 norm:6.644833774771541e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:20:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.03183731064200401 norm:6.32854353170842e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:20:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.03180931881070137 norm:6.120862963143736e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:21:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.03178906813263893 norm:5.964664160273969e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:22:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.031773537397384644 norm:5.7834567996906117e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:23:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.03175719827413559 norm:5.6665689044166356e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:23:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.03174905478954315 norm:5.562379374168813e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:24:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.03173808753490448 norm:5.537597098737024e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:25:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.03172536939382553 norm:5.432284888229333e-05 max memory_allocated 29274.25048828125 
[2025-03-01 19:25:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-01 19:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.0379575714468956 norm:0.0005431807949207723 max memory_allocated 29274.43798828125 
[2025-03-01 19:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.035822950303554535 norm:0.000267894210992381 max memory_allocated 29274.43798828125 
[2025-03-01 19:27:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.034964267164468765 norm:0.00016948468692135066 max memory_allocated 29274.43798828125 
[2025-03-01 19:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.03450704365968704 norm:0.00012395111843943596 max memory_allocated 29274.43798828125 
[2025-03-01 19:29:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.03419307991862297 norm:0.0001044051386998035 max memory_allocated 29274.43798828125 
[2025-03-01 19:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.03393251448869705 norm:9.367140592075884e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:30:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.03375592827796936 norm:8.571534999646246e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:31:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.033634573221206665 norm:7.915943569969386e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.03355633467435837 norm:7.257957622641698e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.033503543585538864 norm:6.872370431665331e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.03347121924161911 norm:6.619097257498652e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.03344627469778061 norm:6.409425259334967e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:35:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.03341449052095413 norm:6.151790148578584e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.03339222073554993 norm:6.0503218264784664e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.0333716906607151 norm:5.943072392255999e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:37:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.033361129462718964 norm:5.7636338169686496e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:38:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.033344026654958725 norm:5.502265048562549e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:39:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.03333495184779167 norm:5.503580905497074e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:40:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.03332822769880295 norm:5.29499702679459e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:40:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.033321406692266464 norm:5.2360941481310874e-05 max memory_allocated 29274.43798828125 
[2025-03-01 19:41:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-01 19:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.03939441218972206 norm:0.0004722846788354218 max memory_allocated 29274.62548828125 
[2025-03-01 19:42:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.037412531673908234 norm:0.00023424855316989124 max memory_allocated 29274.62548828125 
[2025-03-01 19:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.036627259105443954 norm:0.00014718955208081752 max memory_allocated 29274.62548828125 
[2025-03-01 19:44:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.03619914501905441 norm:0.00011115743109257892 max memory_allocated 29274.62548828125 
[2025-03-01 19:44:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.035875074565410614 norm:9.175174636766315e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:45:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.03560992702841759 norm:8.253076521214098e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.03543589264154434 norm:7.465484668500721e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.035335902124643326 norm:6.949118687771261e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:47:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.03526470437645912 norm:6.558849418070167e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:48:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.03523091971874237 norm:6.41185324639082e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:49:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.03520989418029785 norm:6.240973743842915e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:50:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.035184346139431 norm:5.967103425064124e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.03515034168958664 norm:5.67702081752941e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.03512662276625633 norm:5.342862641555257e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.03511693701148033 norm:5.3283991292119026e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:53:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.03510892763733864 norm:5.1284314395161346e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:54:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.03510122373700142 norm:5.1108825573464856e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.035086072981357574 norm:4.965060725226067e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:55:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.03508035093545914 norm:4.992300091544166e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:56:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.03507815673947334 norm:4.8404541303170845e-05 max memory_allocated 29274.62548828125 
[2025-03-01 19:56:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-01 19:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.04353382810950279 norm:0.0006888274219818413 max memory_allocated 29274.81298828125 
[2025-03-01 19:58:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.04076414927840233 norm:0.00034540926571935415 max memory_allocated 29274.81298828125 
[2025-03-01 19:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.03965406119823456 norm:0.0002125810133293271 max memory_allocated 29274.81298828125 
[2025-03-01 19:59:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.03910275176167488 norm:0.00015568756498396397 max memory_allocated 29274.81298828125 
[2025-03-01 20:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.03874657675623894 norm:0.00013139820657670498 max memory_allocated 29274.81298828125 
[2025-03-01 20:01:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.03844185173511505 norm:0.0001142282853834331 max memory_allocated 29274.81298828125 
[2025-03-01 20:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.038233399391174316 norm:0.00010405359353171661 max memory_allocated 29274.81298828125 
[2025-03-01 20:02:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.03809370845556259 norm:9.642071381676942e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:03:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.038010016083717346 norm:9.0272820671089e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:04:16 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.037955716252326965 norm:8.761601930018514e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:05:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.0379059761762619 norm:8.312489808304235e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.03785356506705284 norm:7.808789086993784e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.037815872579813004 norm:7.483042281819507e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:07:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.037803445011377335 norm:7.410120451822877e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:08:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.03777025267481804 norm:7.043735240586102e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.0377456471323967 norm:6.759027746738866e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:09:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.03772745281457901 norm:6.472403765656054e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:10:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.037715017795562744 norm:6.275781925069168e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.03770222142338753 norm:6.036009290255606e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.03768245875835419 norm:5.757371400250122e-05 max memory_allocated 29274.81298828125 
[2025-03-01 20:12:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-01 20:12:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.044102054089307785 norm:0.0004481007345020771 max memory_allocated 29275.00048828125 
[2025-03-01 20:13:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.042721934616565704 norm:0.00020871618471574038 max memory_allocated 29275.00048828125 
[2025-03-01 20:14:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.042133986949920654 norm:0.00013388344086706638 max memory_allocated 29275.00048828125 
[2025-03-01 20:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.041784852743148804 norm:0.00010221335105597973 max memory_allocated 29275.00048828125 
[2025-03-01 20:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.04148561507463455 norm:8.586337935412303e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.041210610419511795 norm:7.542415551142767e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.0410393550992012 norm:7.071667641866952e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.040951065719127655 norm:6.743874837411568e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:19:02 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.040906086564064026 norm:6.387421308318153e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:19:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.040875114500522614 norm:6.211338768480346e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.04084334895014763 norm:6.025849506841041e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:21:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.040821779519319534 norm:5.8111480029765517e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:22:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.04080650582909584 norm:5.6122247769962996e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:22:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.04079173132777214 norm:5.5780728871468455e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:23:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.040777575224637985 norm:5.370534199755639e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:24:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.04076533764600754 norm:5.387490091379732e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:25:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.0407564677298069 norm:5.28137206856627e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.040756162256002426 norm:5.387450073612854e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.040750790387392044 norm:5.462238550535403e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:27:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.04074830189347267 norm:5.3965319239068776e-05 max memory_allocated 29275.00048828125 
[2025-03-01 20:27:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-01 20:28:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.046912189573049545 norm:0.0003943667106796056 max memory_allocated 29275.18798828125 
[2025-03-01 20:29:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.046065039932727814 norm:0.00019577516650315374 max memory_allocated 29275.18798828125 
[2025-03-01 20:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.0456446148455143 norm:0.00011961552081629634 max memory_allocated 29275.18798828125 
[2025-03-01 20:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.045340195298194885 norm:8.758108742767945e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:31:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.04503772780299187 norm:7.119184010662138e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:32:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.044779278337955475 norm:6.191646389197558e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.04463169723749161 norm:5.527321991394274e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:33:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.04455820098519325 norm:5.134674211149104e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.04451710730791092 norm:5.080492337583564e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:35:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.04449876397848129 norm:4.855081715504639e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.04448004439473152 norm:4.7271401854231954e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.04446642845869064 norm:4.637229721993208e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.04445497319102287 norm:4.48449318355415e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.044443171471357346 norm:4.42168275185395e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.04443005844950676 norm:4.389967580209486e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.04442236199975014 norm:4.4304124457994476e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:40:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.04441378265619278 norm:4.443492798600346e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.04440491646528244 norm:4.362402614788152e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.04439832270145416 norm:4.298172643757425e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.0443926639854908 norm:4.3598280171863735e-05 max memory_allocated 29275.18798828125 
[2025-03-01 20:43:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-01 20:43:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.051607418805360794 norm:0.00038557726657018065 max memory_allocated 29275.37548828125 
[2025-03-01 20:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.05042728781700134 norm:0.0001849918335210532 max memory_allocated 29275.37548828125 
[2025-03-01 20:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.04993158578872681 norm:0.00012370746117085218 max memory_allocated 29275.37548828125 
[2025-03-01 20:46:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.04960709437727928 norm:0.00010069686686620116 max memory_allocated 29275.37548828125 
[2025-03-01 20:47:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.04928484186530113 norm:8.793940651230514e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:47:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.049005184322595596 norm:7.622895645909011e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:48:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.04885642230510712 norm:7.193202327471226e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.04878130555152893 norm:6.993258284637704e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.048742394894361496 norm:6.44722895231098e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.048699118196964264 norm:6.227475387277082e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.04866752773523331 norm:5.734205842600204e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.048645783215761185 norm:5.386675911722705e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:53:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.04863148555159569 norm:5.3373136324808e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:53:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.04861663654446602 norm:5.197407153900713e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:54:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.04859458655118942 norm:5.172611781745218e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:55:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.04858378693461418 norm:5.0552924221847206e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.04857992008328438 norm:5.18220585945528e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:56:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.04857032746076584 norm:5.139916902408004e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:57:44 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.04856071621179581 norm:5.007947038393468e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:58:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.048559777438640594 norm:5.223839252721518e-05 max memory_allocated 29275.37548828125 
[2025-03-01 20:58:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-01 20:59:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.05622806400060654 norm:0.0003760151448659599 max memory_allocated 29275.56298828125 
[2025-03-01 21:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.055171847343444824 norm:0.000184658492798917 max memory_allocated 29275.56298828125 
[2025-03-01 21:01:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.05471809580922127 norm:0.00012253494060132653 max memory_allocated 29275.56298828125 
[2025-03-01 21:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.0543617308139801 norm:9.632200817577541e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:02:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.053996119648218155 norm:8.121530117932707e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.05370161309838295 norm:7.24850979167968e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:04:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.05356917530298233 norm:6.695326010230929e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:04:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.05349918454885483 norm:6.157558527775109e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:05:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.05345715954899788 norm:5.880798926227726e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.053431421518325806 norm:5.542994404095225e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.05340452492237091 norm:5.28236705577001e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:07:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.053377483040094376 norm:5.021542892791331e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:08:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.053363725543022156 norm:4.883381916442886e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:09:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.05335060879588127 norm:4.787589205079712e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:10:12 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.05333917587995529 norm:4.766620622831397e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.053329721093177795 norm:4.698632983490825e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.053327638655900955 norm:4.5534176024375483e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:12:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.0533202588558197 norm:4.445362719707191e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:13:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.05330934375524521 norm:4.462982542463578e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.05330740660429001 norm:4.4637279643211514e-05 max memory_allocated 29275.56298828125 
[2025-03-01 21:14:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-01 21:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.062014319002628326 norm:0.00041437323670834303 max memory_allocated 29275.75048828125 
[2025-03-01 21:15:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.060907404869794846 norm:0.00023856018378864974 max memory_allocated 29275.75048828125 
[2025-03-01 21:16:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.06035265326499939 norm:0.0001645707234274596 max memory_allocated 29275.75048828125 
[2025-03-01 21:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.0599161796271801 norm:0.0001268501946469769 max memory_allocated 29275.75048828125 
[2025-03-01 21:18:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.059492237865924835 norm:0.00010618036321830004 max memory_allocated 29275.75048828125 
[2025-03-01 21:18:53 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.05919104069471359 norm:9.883274469757453e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:19:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.05905584618449211 norm:8.609603537479416e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:20:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.05898693576455116 norm:8.068590250331908e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:21:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.05894351005554199 norm:7.670412742299959e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.05890270322561264 norm:7.441438356181607e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:22:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.058872926980257034 norm:7.274956442415714e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:23:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.05884682387113571 norm:6.893892714288086e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:24:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.05882246419787407 norm:6.469628715422004e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:24:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.05881120637059212 norm:6.263937393669039e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.05879797413945198 norm:6.149406544864178e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:26:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.058790236711502075 norm:6.179894262459129e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.058780502527952194 norm:6.422316073440015e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:28:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.05876854434609413 norm:6.300234235823154e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.05876459553837776 norm:6.286118150455877e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:29:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.058748405426740646 norm:6.171371205709875e-05 max memory_allocated 29275.75048828125 
[2025-03-01 21:29:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-01 21:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.06713111698627472 norm:0.00028900106553919613 max memory_allocated 29275.93798828125 
[2025-03-01 21:31:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.06629642099142075 norm:0.00017043607658706605 max memory_allocated 29275.93798828125 
[2025-03-01 21:32:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.06586602330207825 norm:0.00012304428673814982 max memory_allocated 29275.93798828125 
[2025-03-01 21:32:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.0654575377702713 norm:9.812276402954012e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:33:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.06501922011375427 norm:8.237134898081422e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:34:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.06474265456199646 norm:7.200737309176475e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:35:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.06464651226997375 norm:6.653809396084398e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:35:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.06460404396057129 norm:6.288943404797465e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.06456401944160461 norm:5.9594298363663256e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:37:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.06453597545623779 norm:5.8015986724058166e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.06452573090791702 norm:5.742251960327849e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:38:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.06450192630290985 norm:5.3982694225851446e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.06448104232549667 norm:5.311940549290739e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:40:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.06446967273950577 norm:5.367219273466617e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.06444945186376572 norm:5.1244500355096534e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:42:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.06444086879491806 norm:4.895414531347342e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:42:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.06443317234516144 norm:4.935743345413357e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.06442445516586304 norm:4.8386940761702135e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:44:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.06441748142242432 norm:4.7607867600163445e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:45:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.06441136449575424 norm:4.7203051508404315e-05 max memory_allocated 29275.93798828125 
[2025-03-01 21:45:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-01 21:46:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.07526320964097977 norm:0.0005426669376902282 max memory_allocated 29276.12548828125 
[2025-03-01 21:46:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.07380294054746628 norm:0.00031847439822740853 max memory_allocated 29276.12548828125 
[2025-03-01 21:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.07302866131067276 norm:0.0002161898446502164 max memory_allocated 29276.12548828125 
[2025-03-01 21:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.0724906325340271 norm:0.00016760089783929288 max memory_allocated 29276.12548828125 
[2025-03-01 21:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.07196488976478577 norm:0.0001392428675899282 max memory_allocated 29276.12548828125 
[2025-03-01 21:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.07166208326816559 norm:0.00012109072122257203 max memory_allocated 29276.12548828125 
[2025-03-01 21:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.07153870165348053 norm:0.00010803829354699701 max memory_allocated 29276.12548828125 
[2025-03-01 21:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.07149546593427658 norm:0.00010358521103626117 max memory_allocated 29276.12548828125 
[2025-03-01 21:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.07143370062112808 norm:9.63283673627302e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.07138291001319885 norm:9.072318789549172e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:53:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.07134479284286499 norm:8.712663111509755e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:54:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.07131613045930862 norm:8.444440027233213e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:55:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.07129106670618057 norm:8.795973553787917e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:56:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.07126324623823166 norm:8.193774556275457e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.07123714685440063 norm:8.093284122878686e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.07122842222452164 norm:8.059470565058291e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:58:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.07120753824710846 norm:7.661005656700581e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.07119844853878021 norm:7.304531754925847e-05 max memory_allocated 29276.12548828125 
[2025-03-01 21:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.07119108736515045 norm:7.254960655700415e-05 max memory_allocated 29276.12548828125 
[2025-03-01 22:00:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.07117865979671478 norm:7.438103784807026e-05 max memory_allocated 29276.12548828125 
[2025-03-01 22:00:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-01 22:01:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.08105416595935822 norm:0.00040841451846063137 max memory_allocated 29276.31298828125 
[2025-03-01 22:02:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.08015516400337219 norm:0.00022942233772482723 max memory_allocated 29276.31298828125 
[2025-03-01 22:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.07968361675739288 norm:0.00016019944450818002 max memory_allocated 29276.31298828125 
[2025-03-01 22:03:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.07922594249248505 norm:0.00012315581261646003 max memory_allocated 29276.31298828125 
[2025-03-01 22:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.07873305678367615 norm:0.00010044319787994027 max memory_allocated 29276.31298828125 
[2025-03-01 22:05:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.07849924266338348 norm:8.626325870864093e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:06:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.07842640578746796 norm:7.56566078052856e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.07838457077741623 norm:7.115709740901366e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.0783594474196434 norm:6.643999950028956e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:08:32 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.07833126187324524 norm:6.236608896870166e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.07830768823623657 norm:5.946366582065821e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.07829190790653229 norm:5.777474143542349e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:10:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.07828677445650101 norm:5.778168633696623e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:11:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.078273244202137 norm:5.5661606893409044e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.07826004177331924 norm:5.380059883464128e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:13:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.07825492322444916 norm:5.3137773647904396e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.07824697345495224 norm:5.3695806855103e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.07823747396469116 norm:5.4508698667632416e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.07822620868682861 norm:5.564509774558246e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.07822161912918091 norm:5.5265169066842645e-05 max memory_allocated 29276.31298828125 
[2025-03-01 22:16:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-01 22:17:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.08922834694385529 norm:0.00039986034971661866 max memory_allocated 29276.50048828125 
[2025-03-01 22:17:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.08822401612997055 norm:0.00021098821889609098 max memory_allocated 29276.50048828125 
[2025-03-01 22:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.08763522654771805 norm:0.00013981995289213955 max memory_allocated 29276.50048828125 
[2025-03-01 22:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.08706972002983093 norm:0.0001049863058142364 max memory_allocated 29276.50048828125 
[2025-03-01 22:20:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.0865432471036911 norm:8.573669765610248e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.08633438497781754 norm:7.313832611544058e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:21:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.08626911044120789 norm:6.723025580868125e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.08622702211141586 norm:6.223951641004533e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:23:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.08619022369384766 norm:5.8996767620556056e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:24:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.08616387099027634 norm:5.7146273320540786e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:24:50 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.08614203333854675 norm:5.601448719971813e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:25:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.08612971007823944 norm:5.536243406822905e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:26:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.08611486107110977 norm:5.4246436775429174e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.08610328286886215 norm:5.4249663662631065e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:27:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.0860920250415802 norm:5.3922714869258925e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.08608393371105194 norm:5.420740490080789e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:29:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.08607635647058487 norm:5.5384105507982895e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.08606767654418945 norm:5.4216099670156837e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:30:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.08606180548667908 norm:5.3408359235618263e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:31:42 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.08605559170246124 norm:5.3907591791357845e-05 max memory_allocated 29276.50048828125 
[2025-03-01 22:31:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-01 22:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.09750515967607498 norm:0.0004000320623163134 max memory_allocated 29276.68798828125 
[2025-03-01 22:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.09669756889343262 norm:0.00020755644072778523 max memory_allocated 29276.68798828125 
[2025-03-01 22:34:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.09620094299316406 norm:0.0001345851633232087 max memory_allocated 29276.68798828125 
[2025-03-01 22:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.09561993181705475 norm:0.00010402403131593019 max memory_allocated 29276.68798828125 
[2025-03-01 22:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.09509653598070145 norm:8.60208019730635e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.09493133425712585 norm:7.704574090894312e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:37:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.09487514942884445 norm:7.289909262908623e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.09483159333467484 norm:6.983084313105792e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:38:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.09480376541614532 norm:6.715915515087545e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.09478050470352173 norm:6.559718167409301e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.09476174414157867 norm:6.526533979922533e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:41:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.09474334865808487 norm:6.484363984782249e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.09472586214542389 norm:6.478418072219938e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:42:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.0947120413184166 norm:6.323534762486815e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.0947071760892868 norm:6.450864020735025e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.09469921886920929 norm:6.383939762599766e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:44:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.09469154477119446 norm:6.36326294625178e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.09467846155166626 norm:6.200491770869121e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.09467270970344543 norm:6.212491280166432e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.09465987980365753 norm:6.228529673535377e-05 max memory_allocated 29276.68798828125 
[2025-03-01 22:47:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-01 22:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.10759805887937546 norm:0.0004914800520054996 max memory_allocated 29276.87548828125 
[2025-03-01 22:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.10652360320091248 norm:0.0002483927528373897 max memory_allocated 29276.87548828125 
[2025-03-01 22:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.1058432012796402 norm:0.00015836487000342458 max memory_allocated 29276.87548828125 
[2025-03-01 22:50:39 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.10513772815465927 norm:0.00011493293277453631 max memory_allocated 29276.87548828125 
[2025-03-01 22:51:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.10460378974676132 norm:9.176139428745955e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:52:10 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.10445860028266907 norm:7.980062218848616e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.10439760982990265 norm:7.219661347335204e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:53:42 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.1043589860200882 norm:6.86037601553835e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:54:28 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.10432463139295578 norm:6.57773416605778e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:55:13 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.1043047234416008 norm:6.491508975159377e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.1042889952659607 norm:6.372159987222403e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.10427622497081757 norm:6.342000415315852e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:57:31 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.10425663739442825 norm:6.272368773352355e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:58:16 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.10425286740064621 norm:6.251621380215511e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:59:02 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.10424809157848358 norm:6.223167292773724e-05 max memory_allocated 29276.87548828125 
[2025-03-01 22:59:48 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.10423985868692398 norm:6.212800508365035e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.1042395830154419 norm:6.177525210659951e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.10423335433006287 norm:6.080429011490196e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.1042243018746376 norm:6.098181620473042e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:02:51 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.10422383248806 norm:6.133213173598051e-05 max memory_allocated 29276.87548828125 
[2025-03-01 23:03:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-01 23:03:53 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.11754945665597916 norm:0.0004043634107802063 max memory_allocated 29277.06298828125 
[2025-03-01 23:04:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.116488516330719 norm:0.00021512637613341212 max memory_allocated 29277.06298828125 
[2025-03-01 23:05:24 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.11579890549182892 norm:0.00014447383000515401 max memory_allocated 29277.06298828125 
[2025-03-01 23:06:10 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.11504059284925461 norm:0.00011017419456038624 max memory_allocated 29277.06298828125 
[2025-03-01 23:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.11453065276145935 norm:8.920721302274615e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:07:42 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.11440401524305344 norm:7.885821833042428e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:08:27 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.1143452599644661 norm:7.25289064575918e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:09:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.11430546641349792 norm:7.022636418696493e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:09:59 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.11428700387477875 norm:6.600921915378422e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:10:45 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.11426745355129242 norm:6.435344403143972e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:11:31 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.1142471432685852 norm:6.337337981676683e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.11423620581626892 norm:6.218448106665164e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.11422015726566315 norm:6.160618795547634e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:13:48 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.1142047643661499 norm:6.260177178774029e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.11419593542814255 norm:6.0968988691456616e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.1141875684261322 norm:6.190332351252437e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:16:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.11419001966714859 norm:6.249469879548997e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.11417994648218155 norm:6.191281136125326e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:17:37 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.11417149007320404 norm:6.216768815647811e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.11416291445493698 norm:6.207295518834144e-05 max memory_allocated 29277.06298828125 
[2025-03-01 23:18:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-01 23:19:24 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.1304894983768463 norm:0.00043737899977713823 max memory_allocated 29277.25048828125 
[2025-03-01 23:20:10 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.12924009561538696 norm:0.00022088494733907282 max memory_allocated 29277.25048828125 
[2025-03-01 23:20:56 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.12837035953998566 norm:0.0001428973046131432 max memory_allocated 29277.25048828125 
[2025-03-01 23:21:42 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.12747277319431305 norm:0.00010654344805516303 max memory_allocated 29277.25048828125 
[2025-03-01 23:22:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.12698723375797272 norm:8.80642473930493e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:23:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.12686407566070557 norm:7.791304960846901e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.1267983764410019 norm:7.324289617827162e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.12675052881240845 norm:6.911688979016617e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:25:31 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.1267254650592804 norm:6.797171954531223e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:26:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.12669982016086578 norm:6.791248597437516e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.12667514383792877 norm:6.665963883278891e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.12665481865406036 norm:6.461900193244219e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.1266433447599411 norm:6.453783134929836e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.12663127481937408 norm:6.369935726979747e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:30:06 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.12661539018154144 norm:6.351026968332008e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:30:52 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.12660962343215942 norm:6.436956027755514e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:31:37 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.12660068273544312 norm:6.416246469598264e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.12659752368927002 norm:6.466207560151815e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:33:09 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.12658946216106415 norm:6.426172330975533e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:33:55 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.12658673524856567 norm:6.453498644987121e-05 max memory_allocated 29277.25048828125 
[2025-03-01 23:34:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-01 23:34:57 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.14487871527671814 norm:0.0009278723155148327 max memory_allocated 29277.43798828125 
[2025-03-01 23:35:42 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.14319202303886414 norm:0.0004776940040756017 max memory_allocated 29277.43798828125 
[2025-03-01 23:36:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.14201515913009644 norm:0.00029156124219298363 max memory_allocated 29277.43798828125 
[2025-03-01 23:37:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.14095647633075714 norm:0.0001990075979847461 max memory_allocated 29277.43798828125 
[2025-03-01 23:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.14049358665943146 norm:0.0001494282769272104 max memory_allocated 29277.43798828125 
[2025-03-01 23:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.1403704434633255 norm:0.00012199802586110309 max memory_allocated 29277.43798828125 
[2025-03-01 23:39:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.14030233025550842 norm:0.00010555936023592949 max memory_allocated 29277.43798828125 
[2025-03-01 23:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.14024391770362854 norm:9.422934090252966e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.1402048021554947 norm:8.725958468858153e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.14017215371131897 norm:8.248099038610235e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.14014749228954315 norm:7.947612175485119e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:43:20 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.14012451469898224 norm:7.727841148152947e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:44:06 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.14011113345623016 norm:7.611038745380938e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.14009925723075867 norm:7.501939398935065e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:45:38 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.14008276164531708 norm:7.405578071484342e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:46:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.1400732696056366 norm:7.41507246857509e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:47:09 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.14006538689136505 norm:7.300800643861294e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.14005768299102783 norm:7.238915713969618e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:48:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.14005440473556519 norm:7.332011591643095e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:49:27 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.14004917442798615 norm:7.332622044486925e-05 max memory_allocated 29277.43798828125 
[2025-03-01 23:49:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-01 23:49:43 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-01 23:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.16178713738918304 norm:0.0038217995315790176 max memory_allocated 29277.77001953125 
[2025-03-01 23:51:14 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.1597796082496643 norm:0.0034146022517234087 max memory_allocated 29277.77001953125 
[2025-03-01 23:52:01 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.15825724601745605 norm:0.002783606294542551 max memory_allocated 29277.77001953125 
[2025-03-01 23:52:47 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.15696291625499725 norm:0.0022384317126125097 max memory_allocated 29277.77001953125 
[2025-03-01 23:53:33 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.15642453730106354 norm:0.001825704239308834 max memory_allocated 29277.77001953125 
[2025-03-01 23:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.1562274843454361 norm:0.001561792683787644 max memory_allocated 29277.77001953125 
[2025-03-01 23:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.156147763133049 norm:0.0014826756669208407 max memory_allocated 29277.77001953125 
[2025-03-01 23:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.15605172514915466 norm:0.0013698951806873083 max memory_allocated 29277.77001953125 
[2025-03-01 23:56:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.15594802796840668 norm:0.0012427211040630937 max memory_allocated 29277.77001953125 
[2025-03-01 23:57:23 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.15591205656528473 norm:0.0012065856717526913 max memory_allocated 29277.77001953125 
[2025-03-01 23:58:09 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.15588025748729706 norm:0.0011569596827030182 max memory_allocated 29277.77001953125 
[2025-03-01 23:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.1558845043182373 norm:0.0011569125344976783 max memory_allocated 29277.77001953125 
[2025-03-01 23:59:41 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.15590262413024902 norm:0.0012162873754277825 max memory_allocated 29277.77001953125 
[2025-03-02 00:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.1558741331100464 norm:0.0011417418718338013 max memory_allocated 29277.77001953125 
[2025-03-02 00:01:13 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.15589623153209686 norm:0.0012151265982538462 max memory_allocated 29277.77001953125 
[2025-03-02 00:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.15592682361602783 norm:0.0009858645498752594 max memory_allocated 29277.77001953125 
[2025-03-02 00:02:45 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.15577653050422668 norm:0.0010363536421209574 max memory_allocated 29277.77001953125 
[2025-03-02 00:03:31 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.1558082550764084 norm:0.0010123670799657702 max memory_allocated 29277.77001953125 
[2025-03-02 00:04:17 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.155792236328125 norm:0.0010526493424549699 max memory_allocated 29277.77001953125 
[2025-03-02 00:05:02 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.1558307707309723 norm:0.0010549990693107247 max memory_allocated 29277.77001953125 
[2025-03-02 00:05:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 00:05:21 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:06:07 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.18318939208984375 norm:0.0035611819475889206 max memory_allocated 29277.95751953125 
[2025-03-02 00:06:53 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.1796899139881134 norm:0.002745934296399355 max memory_allocated 29277.95751953125 
[2025-03-02 00:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.17726793885231018 norm:0.0022189151495695114 max memory_allocated 29277.95751953125 
[2025-03-02 00:08:25 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.1755957305431366 norm:0.0018284133402630687 max memory_allocated 29277.95751953125 
[2025-03-02 00:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.17498870193958282 norm:0.0015696478076279163 max memory_allocated 29277.95751953125 
[2025-03-02 00:09:57 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.17473486065864563 norm:0.001348473015241325 max memory_allocated 29277.95751953125 
[2025-03-02 00:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.174575537443161 norm:0.0012243380770087242 max memory_allocated 29277.95751953125 
[2025-03-02 00:11:28 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.17444032430648804 norm:0.0011176447151228786 max memory_allocated 29277.95751953125 
[2025-03-02 00:12:14 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.17437000572681427 norm:0.0010925305541604757 max memory_allocated 29277.95751953125 
[2025-03-02 00:13:00 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.1742939054965973 norm:0.001010192558169365 max memory_allocated 29277.95751953125 
[2025-03-02 00:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.17424650490283966 norm:0.0009749346063472331 max memory_allocated 29277.95751953125 
[2025-03-02 00:14:32 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.1742294430732727 norm:0.001003350829705596 max memory_allocated 29277.95751953125 
[2025-03-02 00:15:18 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.1742786020040512 norm:0.0010507093975320458 max memory_allocated 29277.95751953125 
[2025-03-02 00:16:04 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.17426370084285736 norm:0.0010235441150143743 max memory_allocated 29277.95751953125 
[2025-03-02 00:16:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.17419663071632385 norm:0.0010155865456908941 max memory_allocated 29277.95751953125 
[2025-03-02 00:17:36 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.1741681694984436 norm:0.0009534673881717026 max memory_allocated 29277.95751953125 
[2025-03-02 00:18:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.17414358258247375 norm:0.000987323117442429 max memory_allocated 29277.95751953125 
[2025-03-02 00:19:08 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.1741543561220169 norm:0.0009134332649409771 max memory_allocated 29277.95751953125 
[2025-03-02 00:19:54 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.1741255670785904 norm:0.0009717934881336987 max memory_allocated 29277.95751953125 
[2025-03-02 00:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.17416974902153015 norm:0.0008959395927377045 max memory_allocated 29277.95751953125 
[2025-03-02 00:20:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 00:20:56 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:21:42 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.22716370224952698 norm:0.005138378590345383 max memory_allocated 29278.14501953125 
[2025-03-02 00:22:28 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.21587349474430084 norm:0.003695305436849594 max memory_allocated 29278.14501953125 
[2025-03-02 00:23:14 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.20925022661685944 norm:0.0038621947169303894 max memory_allocated 29278.14501953125 
[2025-03-02 00:24:00 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.2066265344619751 norm:0.0038375556468963623 max memory_allocated 29278.14501953125 
[2025-03-02 00:24:46 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.20586472749710083 norm:0.0037032091058790684 max memory_allocated 29278.14501953125 
[2025-03-02 00:25:32 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.20521506667137146 norm:0.0035576841328293085 max memory_allocated 29278.14501953125 
[2025-03-02 00:26:18 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.20467989146709442 norm:0.003290723543614149 max memory_allocated 29278.14501953125 
[2025-03-02 00:27:04 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.20436060428619385 norm:0.0032407576218247414 max memory_allocated 29278.14501953125 
[2025-03-02 00:27:50 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.2041114866733551 norm:0.003298697294667363 max memory_allocated 29278.14501953125 
[2025-03-02 00:28:36 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.20383912324905396 norm:0.003189063398167491 max memory_allocated 29278.14501953125 
[2025-03-02 00:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.2035989761352539 norm:0.0030832018237560987 max memory_allocated 29278.14501953125 
[2025-03-02 00:30:08 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.20334118604660034 norm:0.002895388985052705 max memory_allocated 29278.14501953125 
[2025-03-02 00:30:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.20307311415672302 norm:0.0027245101518929005 max memory_allocated 29278.14501953125 
[2025-03-02 00:31:40 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.20287223160266876 norm:0.0026864497922360897 max memory_allocated 29278.14501953125 
[2025-03-02 00:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.20265644788742065 norm:0.0025661690160632133 max memory_allocated 29278.14501953125 
[2025-03-02 00:33:12 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.2025008350610733 norm:0.002447409089654684 max memory_allocated 29278.14501953125 
[2025-03-02 00:33:58 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.20237132906913757 norm:0.0023933215998113155 max memory_allocated 29278.14501953125 
[2025-03-02 00:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.20236432552337646 norm:0.0024594073183834553 max memory_allocated 29278.14501953125 
[2025-03-02 00:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.20231740176677704 norm:0.0024243907537311316 max memory_allocated 29278.14501953125 
[2025-03-02 00:36:16 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.20227748155593872 norm:0.0024878703989088535 max memory_allocated 29278.14501953125 
[2025-03-02 00:36:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 00:36:32 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 00:37:18 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.29495522379875183 norm:0.01407934445887804 max memory_allocated 29278.33251953125 
[2025-03-02 00:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.2812469005584717 norm:0.009122496470808983 max memory_allocated 29278.33251953125 
[2025-03-02 00:38:50 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.2740150988101959 norm:0.006778200622648001 max memory_allocated 29278.33251953125 
[2025-03-02 00:39:36 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.26983746886253357 norm:0.006501386407762766 max memory_allocated 29278.33251953125 
[2025-03-02 00:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.2675548195838928 norm:0.005737383849918842 max memory_allocated 29278.33251953125 
[2025-03-02 00:41:08 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.26611465215682983 norm:0.005211900919675827 max memory_allocated 29278.33251953125 
[2025-03-02 00:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.26510849595069885 norm:0.005441216751933098 max memory_allocated 29278.33251953125 
[2025-03-02 00:42:40 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.26425400376319885 norm:0.0048875948414206505 max memory_allocated 29278.33251953125 
[2025-03-02 00:43:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.263746052980423 norm:0.00486793601885438 max memory_allocated 29278.33251953125 
[2025-03-02 00:44:12 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.2634592652320862 norm:0.004930887836962938 max memory_allocated 29278.33251953125 
[2025-03-02 00:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.26299041509628296 norm:0.00464551942422986 max memory_allocated 29278.33251953125 
[2025-03-02 00:45:44 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.26268285512924194 norm:0.004448206163942814 max memory_allocated 29278.33251953125 
[2025-03-02 00:46:30 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.26268869638442993 norm:0.004784706514328718 max memory_allocated 29278.33251953125 
[2025-03-02 00:47:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.26251447200775146 norm:0.004696795716881752 max memory_allocated 29278.33251953125 
[2025-03-02 00:48:02 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.2623180150985718 norm:0.004524913616478443 max memory_allocated 29278.33251953125 
[2025-03-02 00:48:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.2623276710510254 norm:0.0046338583342731 max memory_allocated 29278.33251953125 
[2025-03-02 00:49:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.2624282240867615 norm:0.004834816325455904 max memory_allocated 29278.33251953125 
[2025-03-02 00:50:20 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.2624928653240204 norm:0.005017600022256374 max memory_allocated 29278.33251953125 
[2025-03-02 00:51:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.2630985975265503 norm:0.005451447796076536 max memory_allocated 29278.33251953125 
[2025-03-02 00:51:52 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.2622411549091339 norm:0.004433040972799063 max memory_allocated 29278.33251953125 
[2025-03-02 00:52:04 root] (main_calib_config2.py 380): INFO 37363.45715093613
[2025-03-02 00:52:35 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-02 00:54:18 root] (main_calib_config2.py 159): INFO wikitext2 : 4.984560966491699
[2025-03-02 00:54:18 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-02 00:57:00 root] (main_calib_config2.py 159): INFO c4 : 6.6180267333984375
[2025-03-02 02:54:19 root] (main_calib_config2.py 170): INFO {'wikitext2': 4.984560966491699, 'c4': 6.6180267333984375, 'results': {'arc_easy': {'acc': 0.7247474747474747, 'acc_stderr': 0.009164888895174745, 'acc_norm': 0.571969696969697, 'acc_norm_stderr': 0.010152943316426263}, 'piqa': {'acc': 0.7861806311207835, 'acc_stderr': 0.0095659942069156, 'acc_norm': 0.7889009793253536, 'acc_norm_stderr': 0.009521377378734144}, 'hellaswag': {'acc': 0.5911173073093009, 'acc_stderr': 0.004906227902850757, 'acc_norm': 0.7597092212706632, 'acc_norm_stderr': 0.004263868161042477}, 'arc_challenge': {'acc': 0.4325938566552901, 'acc_stderr': 0.01447800569418253, 'acc_norm': 0.431740614334471, 'acc_norm_stderr': 0.014474591427196204}, 'winogrande': {'acc': 0.6906077348066298, 'acc_stderr': 0.012991329330822993}, 'boolq': {'acc': 0.6669724770642201, 'acc_stderr': 0.008243023912688888}}, 'versions': {'arc_easy': 0, 'piqa': 0, 'hellaswag': 0, 'arc_challenge': 0, 'winogrande': 0, 'boolq': 1}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
