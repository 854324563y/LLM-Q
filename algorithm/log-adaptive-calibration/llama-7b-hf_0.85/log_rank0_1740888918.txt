[2025-03-02 04:15:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.85', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.85.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 04:16:52 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 04:16:52 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 04:16:52 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.85.pkl
[2025-03-02 04:16:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 04:16:57 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.0031088695395737886 norm:0.002690092660486698 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.001874260837212205 norm:0.0016375239938497543 max memory_allocated 22559.10693359375 
[2025-03-02 04:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0015919094439595938 norm:0.0015175105072557926 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.001504550687968731 norm:0.00143649079836905 max memory_allocated 22559.10693359375 
[2025-03-02 04:19:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0014467278961092234 norm:0.001424369285814464 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0013813989935442805 norm:0.0013088081032037735 max memory_allocated 22559.10693359375 
[2025-03-02 04:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0013567015994340181 norm:0.001262114499695599 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.001327704987488687 norm:0.0011379625648260117 max memory_allocated 22559.10693359375 
[2025-03-02 04:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0012987395748496056 norm:0.0010189791209995747 max memory_allocated 22559.10693359375 
[2025-03-02 04:22:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0012853782391175628 norm:0.0009136587614193559 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0012593193678185344 norm:0.0008232032996602356 max memory_allocated 22559.10693359375 
[2025-03-02 04:23:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.001243233447894454 norm:0.0007718184497207403 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0012068561045452952 norm:0.0006804789300076663 max memory_allocated 22559.10693359375 
[2025-03-02 04:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0011957616079598665 norm:0.00061737623764202 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001187480054795742 norm:0.0005752405850216746 max memory_allocated 22559.10693359375 
[2025-03-02 04:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0011829185532405972 norm:0.0005445734714157879 max memory_allocated 22559.10693359375 
[2025-03-02 04:26:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.001176358899101615 norm:0.0005034827045165002 max memory_allocated 22559.10693359375 
[2025-03-02 04:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.001170051284134388 norm:0.00046955945435911417 max memory_allocated 22559.10693359375 
[2025-03-02 04:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0011628781212493777 norm:0.00041757262079045177 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0011596090625971556 norm:0.00041608454193919897 max memory_allocated 22559.10693359375 
[2025-03-02 04:28:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 04:28:21 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.013075601309537888 norm:0.014453801326453686 max memory_allocated 22559.27880859375 
[2025-03-02 04:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.007108302786946297 norm:0.00884055346250534 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.005804415792226791 norm:0.005277273245155811 max memory_allocated 22559.27880859375 
[2025-03-02 04:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.0053633530624210835 norm:0.00433680135756731 max memory_allocated 22559.27880859375 
[2025-03-02 04:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.0051406011916697025 norm:0.003926185425370932 max memory_allocated 22559.27880859375 
[2025-03-02 04:31:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.004958771169185638 norm:0.0034864521585404873 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.0048597571440041065 norm:0.0032191681675612926 max memory_allocated 22559.27880859375 
[2025-03-02 04:32:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.0047790491953492165 norm:0.0029951566830277443 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:24 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.004692653194069862 norm:0.0027297413907945156 max memory_allocated 22559.27880859375 
[2025-03-02 04:33:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.004605742637068033 norm:0.002501262119039893 max memory_allocated 22559.27880859375 
[2025-03-02 04:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.004589395597577095 norm:0.0022766778711229563 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.004580260254442692 norm:0.0020250079687684774 max memory_allocated 22559.27880859375 
[2025-03-02 04:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.004528909921646118 norm:0.0018106992356479168 max memory_allocated 22559.27880859375 
[2025-03-02 04:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.00451483903452754 norm:0.0015939396107569337 max memory_allocated 22559.27880859375 
[2025-03-02 04:36:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.00448150560259819 norm:0.0014223578618839383 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.0044608754105865955 norm:0.0012107716174796224 max memory_allocated 22559.27880859375 
[2025-03-02 04:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.004457434173673391 norm:0.0010406080400571227 max memory_allocated 22559.27880859375 
[2025-03-02 04:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.004450657404959202 norm:0.0009623878868296742 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004456298425793648 norm:0.0010024880757555366 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.004449703264981508 norm:0.0010652132332324982 max memory_allocated 22559.27880859375 
[2025-03-02 04:39:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 04:39:47 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 04:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.1177862361073494 norm:0.03372785821557045 max memory_allocated 22559.45068359375 
[2025-03-02 04:40:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.040605731308460236 norm:0.02149123139679432 max memory_allocated 22559.45068359375 
[2025-03-02 04:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.02067403495311737 norm:0.014378917403519154 max memory_allocated 22559.45068359375 
[2025-03-02 04:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.015202530659735203 norm:0.008316850289702415 max memory_allocated 22559.45068359375 
[2025-03-02 04:42:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.013066454790532589 norm:0.006352511700242758 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.011794664897024632 norm:0.0048360805958509445 max memory_allocated 22559.45068359375 
[2025-03-02 04:43:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.010764671489596367 norm:0.004325768910348415 max memory_allocated 22559.45068359375 
[2025-03-02 04:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.0103733716532588 norm:0.003987214062362909 max memory_allocated 22559.45068359375 
[2025-03-02 04:44:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.009977200999855995 norm:0.0036580541636794806 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.009761562570929527 norm:0.00362356542609632 max memory_allocated 22559.45068359375 
[2025-03-02 04:45:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.009485021233558655 norm:0.0033528434578329325 max memory_allocated 22559.45068359375 
[2025-03-02 04:46:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.009391299448907375 norm:0.003437791718170047 max memory_allocated 22559.45068359375 
[2025-03-02 04:47:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.009154957719147205 norm:0.002887497656047344 max memory_allocated 22559.45068359375 
[2025-03-02 04:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.009055803529918194 norm:0.0030517056584358215 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.008945468813180923 norm:0.002832890022546053 max memory_allocated 22559.45068359375 
[2025-03-02 04:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.008802318945527077 norm:0.002638784935697913 max memory_allocated 22559.45068359375 
[2025-03-02 04:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.008669544011354446 norm:0.002306021749973297 max memory_allocated 22559.45068359375 
[2025-03-02 04:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.008452659472823143 norm:0.0022015064023435116 max memory_allocated 22559.45068359375 
[2025-03-02 04:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.008387645706534386 norm:0.0018235889729112387 max memory_allocated 22559.45068359375 
[2025-03-02 04:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.008432251401245594 norm:0.0018494764808565378 max memory_allocated 22559.45068359375 
[2025-03-02 04:51:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.014383167028427124 norm:0.0021070358343422413 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.01172847580164671 norm:0.0008805558318272233 max memory_allocated 22559.50732421875 
[2025-03-02 04:52:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.010770972818136215 norm:0.00045193079859018326 max memory_allocated 22559.50732421875 
[2025-03-02 04:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.010218655690550804 norm:0.0002520364650990814 max memory_allocated 22559.50732421875 
[2025-03-02 04:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.009778129868209362 norm:0.00016928408876992762 max memory_allocated 22559.50732421875 
[2025-03-02 04:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.009476890787482262 norm:0.00012185236846562475 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.0093710757791996 norm:0.00010399068560218439 max memory_allocated 22559.50732421875 
[2025-03-02 04:55:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.009353438392281532 norm:9.895368566503748e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.009337655268609524 norm:9.864185994956642e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.009332825429737568 norm:9.389444312546402e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.0093311732634902 norm:9.23520783544518e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.009318603202700615 norm:8.910457836464047e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:58:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.009314054623246193 norm:9.651839354773983e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.009309574030339718 norm:9.246347326552495e-05 max memory_allocated 22559.50732421875 
[2025-03-02 04:59:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.009303168393671513 norm:8.798462658887729e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.009306463412940502 norm:9.422544826520607e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.009310071356594563 norm:9.530460374662653e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.009313644841313362 norm:8.916088700061664e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.00931601319462061 norm:8.509214239893481e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.009318282827734947 norm:8.421607344644144e-05 max memory_allocated 22559.50732421875 
[2025-03-02 05:02:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 05:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.017970304936170578 norm:0.0019674422219395638 max memory_allocated 22559.67919921875 
[2025-03-02 05:03:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.015038970857858658 norm:0.0008796515758149326 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.013824118301272392 norm:0.00043546452070586383 max memory_allocated 22559.67919921875 
[2025-03-02 05:04:52 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.013105777092278004 norm:0.0002498740213923156 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.012586865574121475 norm:0.00017330308037344366 max memory_allocated 22559.67919921875 
[2025-03-02 05:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.012346483767032623 norm:0.000142191638587974 max memory_allocated 22559.67919921875 
[2025-03-02 05:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.012279313057661057 norm:0.0001694110978860408 max memory_allocated 22559.67919921875 
[2025-03-02 05:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.012245925143361092 norm:0.00011714029096765444 max memory_allocated 22559.67919921875 
[2025-03-02 05:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.012232005596160889 norm:0.00011513541539898142 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.012218228541314602 norm:0.00010655295773176476 max memory_allocated 22559.67919921875 
[2025-03-02 05:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.012211848050355911 norm:0.00011668546358123422 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.012208922766149044 norm:0.0001322720927419141 max memory_allocated 22559.67919921875 
[2025-03-02 05:09:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.01220150850713253 norm:0.00010081458458444104 max memory_allocated 22559.67919921875 
[2025-03-02 05:10:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.012197844684123993 norm:0.0001043608135660179 max memory_allocated 22559.67919921875 
[2025-03-02 05:11:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.012199407443404198 norm:0.00010969018330797553 max memory_allocated 22559.67919921875 
[2025-03-02 05:11:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.012196267955005169 norm:0.00014203955652192235 max memory_allocated 22559.67919921875 
[2025-03-02 05:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.012197192758321762 norm:0.00013702650903724134 max memory_allocated 22559.67919921875 
[2025-03-02 05:12:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.012191097252070904 norm:9.916969429468736e-05 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.01218568254262209 norm:0.0001127853465732187 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.01218483503907919 norm:0.00012308923760429025 max memory_allocated 22559.67919921875 
[2025-03-02 05:13:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 05:14:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.020817382261157036 norm:0.0019468901446089149 max memory_allocated 22559.85107421875 
[2025-03-02 05:15:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.017631549388170242 norm:0.0009041877929121256 max memory_allocated 22559.85107421875 
[2025-03-02 05:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.016193371266126633 norm:0.0004646233865059912 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:17 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.015286000445485115 norm:0.0002454194182064384 max memory_allocated 22559.85107421875 
[2025-03-02 05:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.01471081655472517 norm:0.00014115797239355743 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.014487712644040585 norm:0.00010305439354851842 max memory_allocated 22559.85107421875 
[2025-03-02 05:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.014436518773436546 norm:9.047686035046354e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:18:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.01442616619169712 norm:9.264577238354832e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.014385487884283066 norm:9.047070489032194e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.014357398264110088 norm:9.575484727974981e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:20:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.014328350313007832 norm:9.296120697399601e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:20:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.014308182522654533 norm:9.102775948122144e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:21:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.01429589744657278 norm:9.141233749687672e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:21:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.014289761893451214 norm:9.149489778792486e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:22:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.014286474324762821 norm:8.664618508191779e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:23:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.014293703250586987 norm:9.087663056561723e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:23:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.014284122735261917 norm:8.8779917859938e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.01427479088306427 norm:8.794879249762744e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.014268679544329643 norm:9.17612633202225e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.0142652727663517 norm:8.891164907254279e-05 max memory_allocated 22559.85107421875 
[2025-03-02 05:25:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 05:26:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.02131006307899952 norm:0.0012117770966142416 max memory_allocated 22560.02294921875 
[2025-03-02 05:26:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.019045226275920868 norm:0.00045113038504496217 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.018073521554470062 norm:0.0002602227032184601 max memory_allocated 22560.02294921875 
[2025-03-02 05:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.017384888604283333 norm:0.0001791117392713204 max memory_allocated 22560.02294921875 
[2025-03-02 05:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.01687747985124588 norm:0.000134894551592879 max memory_allocated 22560.02294921875 
[2025-03-02 05:28:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.016652360558509827 norm:0.00011276119766989723 max memory_allocated 22560.02294921875 
[2025-03-02 05:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.016574034467339516 norm:9.746715659275651e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.016550667583942413 norm:8.36027757031843e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:30:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.0165223628282547 norm:8.381044608540833e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.016496744006872177 norm:8.146397885866463e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:31:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.01648247055709362 norm:7.972493040142581e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:32:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.016474643722176552 norm:7.909601845312864e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.01646779663860798 norm:8.054851059569046e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.016477525234222412 norm:8.764083759160712e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:33:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.016467664390802383 norm:7.969601574586704e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:34:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.01646488346159458 norm:7.767076749587432e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.016470592468976974 norm:7.601700053783134e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.016463488340377808 norm:7.862259371904656e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.01646110601723194 norm:7.945664401631802e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:36:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.016454804688692093 norm:7.75911976234056e-05 max memory_allocated 22560.02294921875 
[2025-03-02 05:36:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 05:37:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.025894977152347565 norm:0.0014944098656997085 max memory_allocated 22560.19482421875 
[2025-03-02 05:37:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.022463295608758926 norm:0.0006613826844841242 max memory_allocated 22560.19482421875 
[2025-03-02 05:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.02113163098692894 norm:0.0003845744067803025 max memory_allocated 22560.19482421875 
[2025-03-02 05:39:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.02027847431600094 norm:0.0002284235815750435 max memory_allocated 22560.19482421875 
[2025-03-02 05:39:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.019703973084688187 norm:0.00017504699644632638 max memory_allocated 22560.19482421875 
[2025-03-02 05:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.019438695162534714 norm:0.00014007753634359688 max memory_allocated 22560.19482421875 
[2025-03-02 05:40:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.01930798590183258 norm:0.0001278552954318002 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.019245438277721405 norm:0.00012211834837216884 max memory_allocated 22560.19482421875 
[2025-03-02 05:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.01919703371822834 norm:0.00011316510062897578 max memory_allocated 22560.19482421875 
[2025-03-02 05:42:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.01917073130607605 norm:0.00011366528633516282 max memory_allocated 22560.19482421875 
[2025-03-02 05:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.019159924238920212 norm:0.00011202425230294466 max memory_allocated 22560.19482421875 
[2025-03-02 05:43:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.01913394220173359 norm:0.00010849255340872332 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.01911851018667221 norm:0.00010245622252114117 max memory_allocated 22560.19482421875 
[2025-03-02 05:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.019120970740914345 norm:0.00010416723671369255 max memory_allocated 22560.19482421875 
[2025-03-02 05:45:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.01911008358001709 norm:0.00010115337499883026 max memory_allocated 22560.19482421875 
[2025-03-02 05:45:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.01909601129591465 norm:9.961203613784164e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.019095957279205322 norm:0.00010941440268652514 max memory_allocated 22560.19482421875 
[2025-03-02 05:46:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.019086746498942375 norm:0.0001045037861331366 max memory_allocated 22560.19482421875 
[2025-03-02 05:47:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.01907626911997795 norm:9.617868636269122e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:48:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.019070826470851898 norm:9.910593507811427e-05 max memory_allocated 22560.19482421875 
[2025-03-02 05:48:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.025947609916329384 norm:0.0011066963197663426 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.02354806661605835 norm:0.0004418526077643037 max memory_allocated 22560.36669921875 
[2025-03-02 05:49:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.022483889013528824 norm:0.00023946385772433132 max memory_allocated 22560.36669921875 
[2025-03-02 05:50:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.02173808217048645 norm:0.00016379148291889578 max memory_allocated 22560.36669921875 
[2025-03-02 05:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.02125982940196991 norm:0.00012588466051965952 max memory_allocated 22560.36669921875 
[2025-03-02 05:51:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.02101896144449711 norm:0.00010577886860119179 max memory_allocated 22560.36669921875 
[2025-03-02 05:52:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.02091592364013195 norm:9.822783613344654e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:52:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.020868079736828804 norm:9.387181489728391e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:53:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.020835693925619125 norm:8.247939695138484e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:53:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.020807504653930664 norm:8.31679135444574e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.02078228071331978 norm:8.324827649630606e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:55:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.020765608176589012 norm:8.205454651033506e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.020756792277097702 norm:8.067061571637169e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:56:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.020750360563397408 norm:8.091585914371535e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:56:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.020738910883665085 norm:7.897910109022632e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:57:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.020727258175611496 norm:7.725418254267424e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:57:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.020717067644000053 norm:7.871435809647664e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.02070632204413414 norm:7.644618017366156e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:58:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.020709970965981483 norm:7.642138371011242e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:59:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.02070930041372776 norm:7.478400220861658e-05 max memory_allocated 22560.36669921875 
[2025-03-02 05:59:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 06:00:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.031355466693639755 norm:0.0015410128980875015 max memory_allocated 22560.53857421875 
[2025-03-02 06:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.02712518535554409 norm:0.0005900325486436486 max memory_allocated 22560.53857421875 
[2025-03-02 06:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.025495950132608414 norm:0.0003214648459106684 max memory_allocated 22560.53857421875 
[2025-03-02 06:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.024582529440522194 norm:0.00022420332243200392 max memory_allocated 22560.53857421875 
[2025-03-02 06:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.024004679173231125 norm:0.00017365800158586353 max memory_allocated 22560.53857421875 
[2025-03-02 06:03:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.02372625097632408 norm:0.00014901021495461464 max memory_allocated 22560.53857421875 
[2025-03-02 06:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.023598792031407356 norm:0.00013788742944598198 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.023514356464147568 norm:0.00012337666703388095 max memory_allocated 22560.53857421875 
[2025-03-02 06:04:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.02343880943953991 norm:0.00011531838390510529 max memory_allocated 22560.53857421875 
[2025-03-02 06:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.023387132212519646 norm:0.00010540631046751514 max memory_allocated 22560.53857421875 
[2025-03-02 06:05:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.0233576949685812 norm:9.968756057787687e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.023327207192778587 norm:9.677213529357687e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:06:59 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.023310665041208267 norm:9.371936903335154e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:07:32 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.023292312398552895 norm:9.301392856286839e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:08:06 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.023272495716810226 norm:8.893892663763836e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:08:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.023258617147803307 norm:8.727631939109415e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.023254457861185074 norm:8.818667265586555e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:09:47 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.02324349246919155 norm:8.41141227283515e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:10:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.023239053785800934 norm:8.564633753849193e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.023241065442562103 norm:8.276768494397402e-05 max memory_allocated 22560.53857421875 
[2025-03-02 06:11:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 06:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.03045220859348774 norm:0.0009404320735484362 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.02801572158932686 norm:0.00040547328535467386 max memory_allocated 22560.71044921875 
[2025-03-02 06:12:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.026854895055294037 norm:0.0002484100987203419 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.02600870653986931 norm:0.0001772755931597203 max memory_allocated 22560.71044921875 
[2025-03-02 06:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.025490598753094673 norm:0.00013655165093950927 max memory_allocated 22560.71044921875 
[2025-03-02 06:14:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.025230003520846367 norm:0.0001174011267721653 max memory_allocated 22560.71044921875 
[2025-03-02 06:15:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.025084352120757103 norm:0.00010042732174042612 max memory_allocated 22560.71044921875 
[2025-03-02 06:15:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.02502349019050598 norm:9.336165385320783e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:16:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.024975469335913658 norm:8.782181248534471e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:16:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.024944091215729713 norm:8.152635564329103e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.02491786703467369 norm:7.559651567135006e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.02490205317735672 norm:7.382639159914106e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.024884242564439774 norm:7.299181743292138e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:18:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.02487780526280403 norm:7.130933954613283e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:19:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.024894235655665398 norm:7.230545452330261e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.024884164333343506 norm:6.876408588141203e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:20:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.024878203868865967 norm:6.880460568936542e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:21:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.02487732283771038 norm:6.731483153998852e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:21:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.02487642504274845 norm:6.638908962486312e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:22:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.024880757555365562 norm:6.694304465781897e-05 max memory_allocated 22560.71044921875 
[2025-03-02 06:22:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 06:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.03203307092189789 norm:0.0011336193419992924 max memory_allocated 22560.88232421875 
[2025-03-02 06:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.029365167021751404 norm:0.00045911260531283915 max memory_allocated 22560.88232421875 
[2025-03-02 06:24:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.028101976960897446 norm:0.00027423276333138347 max memory_allocated 22560.88232421875 
[2025-03-02 06:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.027227871119976044 norm:0.0001747306960169226 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.026706626638770103 norm:0.00013460198533721268 max memory_allocated 22560.88232421875 
[2025-03-02 06:25:53 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.02644636109471321 norm:0.00011388465645723045 max memory_allocated 22560.88232421875 
[2025-03-02 06:26:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.02633044868707657 norm:9.779912215890363e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:27:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.026258345693349838 norm:8.881810936145484e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:27:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.02621978335082531 norm:8.460455137537792e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:28:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.026187311857938766 norm:8.132876973832026e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:28:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.026163404807448387 norm:7.544410618720576e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.02614910528063774 norm:7.43707932997495e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:29:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.026138223707675934 norm:7.440440822392702e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.026133958250284195 norm:7.371366518782452e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.026126759126782417 norm:7.353760884143412e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:31:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.026122059673070908 norm:7.170101162046194e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:32:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.026115231215953827 norm:7.231187919387594e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:32:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.026110606268048286 norm:7.180679676821455e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.02611440047621727 norm:7.645932782907039e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.026118971407413483 norm:7.220401312224567e-05 max memory_allocated 22560.88232421875 
[2025-03-02 06:33:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 06:34:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.032499589025974274 norm:0.0007986829150468111 max memory_allocated 22561.05419921875 
[2025-03-02 06:35:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.03050599992275238 norm:0.0003682464302983135 max memory_allocated 22561.05419921875 
[2025-03-02 06:35:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.02934442274272442 norm:0.000225395560846664 max memory_allocated 22561.05419921875 
[2025-03-02 06:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.02852894365787506 norm:0.00017449705046601593 max memory_allocated 22561.05419921875 
[2025-03-02 06:36:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.0279744453728199 norm:0.00014609203208237886 max memory_allocated 22561.05419921875 
[2025-03-02 06:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.02765992097556591 norm:0.00012368644820526242 max memory_allocated 22561.05419921875 
[2025-03-02 06:37:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.02750178799033165 norm:0.00011013213952537626 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.02741958200931549 norm:9.775614307727665e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.027353927493095398 norm:8.88209615368396e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.027322594076395035 norm:8.016879291972145e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:40:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.02729337476193905 norm:7.611879118485376e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:40:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.027268633246421814 norm:7.231959170894697e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:41:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.027261875569820404 norm:6.86029379721731e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.027247531339526176 norm:6.550151010742411e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:42:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.02723027393221855 norm:6.474206747952849e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.027224062010645866 norm:6.290946475928649e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.02722182497382164 norm:6.230138387763873e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:44:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.02721983939409256 norm:6.061534077161923e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.027219079434871674 norm:6.156325980555266e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.027223210781812668 norm:6.100182145019062e-05 max memory_allocated 22561.05419921875 
[2025-03-02 06:45:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 06:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.03328661248087883 norm:0.0006616297177970409 max memory_allocated 22561.22607421875 
[2025-03-02 06:46:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.0315416157245636 norm:0.0003110228863079101 max memory_allocated 22561.22607421875 
[2025-03-02 06:47:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.03057689219713211 norm:0.00020109277102164924 max memory_allocated 22561.22607421875 
[2025-03-02 06:47:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.029799818992614746 norm:0.00015090001397766173 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.029246505349874496 norm:0.00012141659681219608 max memory_allocated 22561.22607421875 
[2025-03-02 06:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.028959808871150017 norm:0.00010359105363022536 max memory_allocated 22561.22607421875 
[2025-03-02 06:49:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.028833288699388504 norm:8.823102689348161e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:49:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.02879490703344345 norm:8.273292041849345e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:50:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.028748739510774612 norm:7.619707321282476e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:50:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.028717046603560448 norm:7.238597027026117e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:51:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.028689850121736526 norm:6.886506889713928e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:52:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.02867971733212471 norm:6.698457582388073e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:52:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.028670528903603554 norm:6.467409548349679e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:53:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.02865491434931755 norm:6.354122160701081e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.02866179123520851 norm:6.437682168325409e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.028654126450419426 norm:6.335591024253517e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.02864493429660797 norm:6.17428231635131e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:55:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.028634650632739067 norm:6.073223994462751e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.028628133237361908 norm:6.083142579882406e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:56:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.028629088774323463 norm:6.101162580307573e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:56:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:57:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.03735067695379257 norm:0.001193889183923602 max memory_allocated 22561.39794921875 
[2025-03-02 06:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.03449803218245506 norm:0.0005175202386453748 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.03319544345140457 norm:0.00031263611163012683 max memory_allocated 22561.39794921875 
[2025-03-02 06:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.03224356099963188 norm:0.00021171188564039767 max memory_allocated 22561.39794921875 
[2025-03-02 06:59:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.0316149964928627 norm:0.0001616840745555237 max memory_allocated 22561.39794921875 
[2025-03-02 07:00:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.031310342252254486 norm:0.00013246131129562855 max memory_allocated 22561.39794921875 
[2025-03-02 07:00:40 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.031178578734397888 norm:0.00011808170529548079 max memory_allocated 22561.39794921875 
[2025-03-02 07:01:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.031093863770365715 norm:0.00010769595246529207 max memory_allocated 22561.39794921875 
[2025-03-02 07:01:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.031029608100652695 norm:9.787872841116041e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.030993515625596046 norm:9.556618897477165e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:02:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.030960429459810257 norm:8.635469566797838e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.030918847769498825 norm:8.302815695060417e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.030900727957487106 norm:7.635099609615281e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:04:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.030884163454174995 norm:7.237610407173634e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.030874773859977722 norm:7.11514730937779e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:05:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.030873285606503487 norm:7.164245471358299e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:06:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.030871108174324036 norm:7.119568908819929e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.03087419830262661 norm:6.985123764025047e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:07:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.03086828626692295 norm:6.888073403388262e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.03086222894489765 norm:6.90991073497571e-05 max memory_allocated 22561.39794921875 
[2025-03-02 07:08:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 07:08:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.03838301822543144 norm:0.0008490273030474782 max memory_allocated 22561.56982421875 
[2025-03-02 07:09:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.036320775747299194 norm:0.0003742737171705812 max memory_allocated 22561.56982421875 
[2025-03-02 07:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.03515927493572235 norm:0.00022582634119316936 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.03428063541650772 norm:0.00017225542978849262 max memory_allocated 22561.56982421875 
[2025-03-02 07:10:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.033635035157203674 norm:0.0001320517621934414 max memory_allocated 22561.56982421875 
[2025-03-02 07:11:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.03334789723157883 norm:0.00010932071745628491 max memory_allocated 22561.56982421875 
[2025-03-02 07:12:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.03324785828590393 norm:0.00010053210280602798 max memory_allocated 22561.56982421875 
[2025-03-02 07:12:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.03318478539586067 norm:9.606399544281885e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:13:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.033128805458545685 norm:8.389900176553056e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.03309740126132965 norm:7.47505109757185e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:14:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.03307065740227699 norm:7.367045327555388e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:14:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.033054377883672714 norm:7.120466034393758e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.033036742359399796 norm:6.866412149975076e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.03300859034061432 norm:6.445878534577787e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:16:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.03299567103385925 norm:6.31825314485468e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:17:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.03300372138619423 norm:6.325888534775004e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.03299536183476448 norm:6.126703374320641e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:18:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.03298143669962883 norm:5.959094414720312e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:18:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.032975610345602036 norm:5.912489723414183e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:19:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.032977838069200516 norm:5.8907768107019365e-05 max memory_allocated 22561.56982421875 
[2025-03-02 07:19:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 07:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.043000657111406326 norm:0.0014759423211216927 max memory_allocated 22561.74169921875 
[2025-03-02 07:20:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.03991450369358063 norm:0.0004677788238041103 max memory_allocated 22561.74169921875 
[2025-03-02 07:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.03857113793492317 norm:0.00027415144722908735 max memory_allocated 22561.74169921875 
[2025-03-02 07:21:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.037580568343400955 norm:0.00020302804477978498 max memory_allocated 22561.74169921875 
[2025-03-02 07:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.036917105317115784 norm:0.00017042960098478943 max memory_allocated 22561.74169921875 
[2025-03-02 07:22:55 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.03665892407298088 norm:0.00014842001837678254 max memory_allocated 22561.74169921875 
[2025-03-02 07:23:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.03654535859823227 norm:0.0001261600700672716 max memory_allocated 22561.74169921875 
[2025-03-02 07:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.03647339716553688 norm:0.0001188023597933352 max memory_allocated 22561.74169921875 
[2025-03-02 07:24:36 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.036398109048604965 norm:0.00010637426748871803 max memory_allocated 22561.74169921875 
[2025-03-02 07:25:09 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.03634866327047348 norm:9.827306348597631e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:25:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.036316417157649994 norm:9.977664012694731e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:26:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.03628642484545708 norm:9.136373410001397e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:26:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.03624989092350006 norm:8.26939576654695e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:27:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.03623354434967041 norm:8.087363676168025e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.03621441125869751 norm:7.709108467679471e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.03619467467069626 norm:7.301952427951619e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.03619655966758728 norm:7.349997758865356e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.03618529811501503 norm:7.094458123901859e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.03618251159787178 norm:6.98386284057051e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.03618500381708145 norm:6.998939352342859e-05 max memory_allocated 22561.74169921875 
[2025-03-02 07:30:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 07:31:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.0478874146938324 norm:0.001541938167065382 max memory_allocated 22561.91357421875 
[2025-03-02 07:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.044797930866479874 norm:0.0005748604889959097 max memory_allocated 22561.91357421875 
[2025-03-02 07:32:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.04319765791296959 norm:0.0003223267267458141 max memory_allocated 22561.91357421875 
[2025-03-02 07:33:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.04200560972094536 norm:0.00022685009753331542 max memory_allocated 22561.91357421875 
[2025-03-02 07:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.04133976250886917 norm:0.00018592140986584127 max memory_allocated 22561.91357421875 
[2025-03-02 07:34:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.04108922928571701 norm:0.00015143993368837982 max memory_allocated 22561.91357421875 
[2025-03-02 07:34:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.040971193462610245 norm:0.00012821733253076673 max memory_allocated 22561.91357421875 
[2025-03-02 07:35:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.040929295122623444 norm:0.00012469786452129483 max memory_allocated 22561.91357421875 
[2025-03-02 07:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.04086685925722122 norm:0.00011253467528149486 max memory_allocated 22561.91357421875 
[2025-03-02 07:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.040815647691488266 norm:0.00010424216452520341 max memory_allocated 22561.91357421875 
[2025-03-02 07:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.04078848659992218 norm:9.500159649178386e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.04075250402092934 norm:8.764656377024949e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.040723592042922974 norm:8.830976003082469e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.040709737688302994 norm:8.618582069175318e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.040701352059841156 norm:8.324066584464163e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.040688373148441315 norm:8.148296910803765e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.04067740589380264 norm:8.135660027619451e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:41:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.04067632555961609 norm:7.996693602763116e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:41:36 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.04067129269242287 norm:7.899796037236229e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:42:09 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.04067263752222061 norm:7.890383858466521e-05 max memory_allocated 22561.91357421875 
[2025-03-02 07:42:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 07:42:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.05201075226068497 norm:0.000866248388774693 max memory_allocated 22562.08544921875 
[2025-03-02 07:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.05003020912408829 norm:0.000341447681421414 max memory_allocated 22562.08544921875 
[2025-03-02 07:44:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.0488082617521286 norm:0.00022322092263493687 max memory_allocated 22562.08544921875 
[2025-03-02 07:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.04760092496871948 norm:0.00016022402269300073 max memory_allocated 22562.08544921875 
[2025-03-02 07:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.04698823392391205 norm:0.000134149071527645 max memory_allocated 22562.08544921875 
[2025-03-02 07:45:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.046816881746053696 norm:0.00011552023352123797 max memory_allocated 22562.08544921875 
[2025-03-02 07:46:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.04673847183585167 norm:0.00010913920414168388 max memory_allocated 22562.08544921875 
[2025-03-02 07:46:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.046669382601976395 norm:9.994927677325904e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.046619754284620285 norm:9.279256482841447e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.0465678945183754 norm:8.55309481266886e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.04652892053127289 norm:7.97206157585606e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.046512503176927567 norm:7.597078365506604e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:49:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.04649144038558006 norm:7.220613770186901e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.046484507620334625 norm:7.020785415079445e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.046472638845443726 norm:7.048383122310042e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.04645676538348198 norm:6.819177360739559e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.04644408077001572 norm:6.901675078552216e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.04646015167236328 norm:6.83759935782291e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:53:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.04646192118525505 norm:6.748958548996598e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.046451859176158905 norm:6.787871825508773e-05 max memory_allocated 22562.08544921875 
[2025-03-02 07:53:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:54:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.060370415449142456 norm:0.001362085109576583 max memory_allocated 22562.25732421875 
[2025-03-02 07:54:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.057839326560497284 norm:0.0004436842573340982 max memory_allocated 22562.25732421875 
[2025-03-02 07:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.05642218515276909 norm:0.0002716085291467607 max memory_allocated 22562.25732421875 
[2025-03-02 07:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.05514119192957878 norm:0.00019900139886885881 max memory_allocated 22562.25732421875 
[2025-03-02 07:56:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.05453558266162872 norm:0.00016903514915611595 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.05438173934817314 norm:0.00014313591236714274 max memory_allocated 22562.25732421875 
[2025-03-02 07:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.05428916588425636 norm:0.00013323868915904313 max memory_allocated 22562.25732421875 
[2025-03-02 07:58:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.054214395582675934 norm:0.00012135082215536386 max memory_allocated 22562.25732421875 
[2025-03-02 07:58:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.05417632311582565 norm:0.00011135392560390756 max memory_allocated 22562.25732421875 
[2025-03-02 07:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.054140519350767136 norm:9.749410673975945e-05 max memory_allocated 22562.25732421875 
[2025-03-02 07:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.05409923940896988 norm:9.028918429976329e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.05406954884529114 norm:8.659761806484312e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.054045215249061584 norm:8.489866013405845e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.0540233850479126 norm:8.311065175803378e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.054005540907382965 norm:8.181999146472663e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:02:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.05399134010076523 norm:7.951178849907592e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:03:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.053982533514499664 norm:7.606039434904233e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:03:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.053974300622940063 norm:7.46775112929754e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:04:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.05397618189454079 norm:7.552101305918768e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:04:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.05396895483136177 norm:7.435398583766073e-05 max memory_allocated 22562.25732421875 
[2025-03-02 08:05:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 08:05:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.0735335648059845 norm:0.00307666789740324 max memory_allocated 22562.42919921875 
[2025-03-02 08:06:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.06917159259319305 norm:0.0009019930148497224 max memory_allocated 22562.42919921875 
[2025-03-02 08:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.06712973117828369 norm:0.0004500245559029281 max memory_allocated 22562.42919921875 
[2025-03-02 08:07:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.06552784889936447 norm:0.00031895903521217406 max memory_allocated 22562.42919921875 
[2025-03-02 08:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.06490980833768845 norm:0.0002522311406210065 max memory_allocated 22562.42919921875 
[2025-03-02 08:08:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.06472338736057281 norm:0.0002412753674434498 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.06458359956741333 norm:0.0002166584599763155 max memory_allocated 22562.42919921875 
[2025-03-02 08:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.06447408348321915 norm:0.0001915487227961421 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.06436397135257721 norm:0.00016530218999832869 max memory_allocated 22562.42919921875 
[2025-03-02 08:10:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.06429757922887802 norm:0.00015617311873938888 max memory_allocated 22562.42919921875 
[2025-03-02 08:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.06425529718399048 norm:0.00014811233268119395 max memory_allocated 22562.42919921875 
[2025-03-02 08:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.06420321017503738 norm:0.00013817602302879095 max memory_allocated 22562.42919921875 
[2025-03-02 08:12:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.06416527926921844 norm:0.00012708958820439875 max memory_allocated 22562.42919921875 
[2025-03-02 08:13:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.06414926797151566 norm:0.00011545610323082656 max memory_allocated 22562.42919921875 
[2025-03-02 08:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.06412628293037415 norm:0.00011185278708580881 max memory_allocated 22562.42919921875 
[2025-03-02 08:14:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.06410317122936249 norm:0.00010993100295308977 max memory_allocated 22562.42919921875 
[2025-03-02 08:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.06409227848052979 norm:0.0001089266297640279 max memory_allocated 22562.42919921875 
[2025-03-02 08:15:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.06407193839550018 norm:0.00010423272760817781 max memory_allocated 22562.42919921875 
[2025-03-02 08:15:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.06405235826969147 norm:9.814478835323825e-05 max memory_allocated 22562.42919921875 
[2025-03-02 08:16:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.06406798958778381 norm:0.0001035818931995891 max memory_allocated 22562.42919921875 
[2025-03-02 08:16:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 08:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.08328463137149811 norm:0.001683815149590373 max memory_allocated 22562.60107421875 
[2025-03-02 08:17:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.08068989962339401 norm:0.0004772386164404452 max memory_allocated 22562.60107421875 
[2025-03-02 08:18:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.07901743799448013 norm:0.00029277114663273096 max memory_allocated 22562.60107421875 
[2025-03-02 08:18:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.07739557325839996 norm:0.00023826038523111492 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.07681997120380402 norm:0.00020607146143447608 max memory_allocated 22562.60107421875 
[2025-03-02 08:19:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.07663934677839279 norm:0.0001902924559544772 max memory_allocated 22562.60107421875 
[2025-03-02 08:20:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.07650922983884811 norm:0.00017431470041628927 max memory_allocated 22562.60107421875 
[2025-03-02 08:21:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.07639651000499725 norm:0.0001654472725931555 max memory_allocated 22562.60107421875 
[2025-03-02 08:21:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.07631651312112808 norm:0.00014614763495046645 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.07625412940979004 norm:0.0001351218088530004 max memory_allocated 22562.60107421875 
[2025-03-02 08:22:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.07620538771152496 norm:0.00012989988317713141 max memory_allocated 22562.60107421875 
[2025-03-02 08:23:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.0761629194021225 norm:0.00011984985030721873 max memory_allocated 22562.60107421875 
[2025-03-02 08:23:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.07612635940313339 norm:0.00011619956785580143 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.07611088454723358 norm:0.00011168103810632601 max memory_allocated 22562.60107421875 
[2025-03-02 08:24:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.07608379423618317 norm:0.00010551418381510302 max memory_allocated 22562.60107421875 
[2025-03-02 08:25:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.07607094198465347 norm:0.00010381681204307824 max memory_allocated 22562.60107421875 
[2025-03-02 08:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.07605442404747009 norm:0.00010177237709285691 max memory_allocated 22562.60107421875 
[2025-03-02 08:26:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.0760389193892479 norm:9.760130342328921e-05 max memory_allocated 22562.60107421875 
[2025-03-02 08:27:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.07602475583553314 norm:9.861748549155891e-05 max memory_allocated 22562.60107421875 
[2025-03-02 08:27:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.07601509243249893 norm:9.520258026896045e-05 max memory_allocated 22562.60107421875 
[2025-03-02 08:27:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 08:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.09590920805931091 norm:0.0012032691156491637 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.0928068533539772 norm:0.0005860681994818151 max memory_allocated 22562.77294921875 
[2025-03-02 08:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.09083089232444763 norm:0.00038517077337019145 max memory_allocated 22562.77294921875 
[2025-03-02 08:30:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.08947346359491348 norm:0.0002882889239117503 max memory_allocated 22562.77294921875 
[2025-03-02 08:30:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.08913273364305496 norm:0.00022735883248969913 max memory_allocated 22562.77294921875 
[2025-03-02 08:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.08890729397535324 norm:0.00019508542027324438 max memory_allocated 22562.77294921875 
[2025-03-02 08:31:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.08879072219133377 norm:0.00017034681513905525 max memory_allocated 22562.77294921875 
[2025-03-02 08:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.08863327652215958 norm:0.00015245360555127263 max memory_allocated 22562.77294921875 
[2025-03-02 08:33:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.08859268575906754 norm:0.00014966298476792872 max memory_allocated 22562.77294921875 
[2025-03-02 08:33:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.0885482132434845 norm:0.00014815364556852728 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.0885375440120697 norm:0.0001527635904494673 max memory_allocated 22562.77294921875 
[2025-03-02 08:34:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.08851082623004913 norm:0.00013819166633766145 max memory_allocated 22562.77294921875 
[2025-03-02 08:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.08848563581705093 norm:0.00014065272989682853 max memory_allocated 22562.77294921875 
[2025-03-02 08:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.08844459056854248 norm:0.00013624512939713895 max memory_allocated 22562.77294921875 
[2025-03-02 08:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.08843918144702911 norm:0.00013835520076099783 max memory_allocated 22562.77294921875 
[2025-03-02 08:36:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.08845003694295883 norm:0.0001343823823845014 max memory_allocated 22562.77294921875 
[2025-03-02 08:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.08844315260648727 norm:0.00014204611943569034 max memory_allocated 22562.77294921875 
[2025-03-02 08:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.08844446390867233 norm:0.00014074789942242205 max memory_allocated 22562.77294921875 
[2025-03-02 08:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.08845499157905579 norm:0.00013957719784229994 max memory_allocated 22562.77294921875 
[2025-03-02 08:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.08845346421003342 norm:0.0001463416265323758 max memory_allocated 22562.77294921875 
[2025-03-02 08:39:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 08:39:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.11366613209247589 norm:0.0018199103651568294 max memory_allocated 22562.94482421875 
[2025-03-02 08:40:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.11079271137714386 norm:0.0009341285331174731 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.10843418538570404 norm:0.0006056082784198225 max memory_allocated 22562.94482421875 
[2025-03-02 08:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.10642355680465698 norm:0.00042226514779031277 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.10589201748371124 norm:0.00032879001810215414 max memory_allocated 22562.94482421875 
[2025-03-02 08:42:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.10569771379232407 norm:0.0002747342805378139 max memory_allocated 22562.94482421875 
[2025-03-02 08:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.10557034611701965 norm:0.00024397383094765246 max memory_allocated 22562.94482421875 
[2025-03-02 08:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.10544409602880478 norm:0.00020228333596605808 max memory_allocated 22562.94482421875 
[2025-03-02 08:44:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.10536222904920578 norm:0.0001833316491683945 max memory_allocated 22562.94482421875 
[2025-03-02 08:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.10530327260494232 norm:0.00016846311336848885 max memory_allocated 22562.94482421875 
[2025-03-02 08:45:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.1052427589893341 norm:0.0001519560464657843 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.10520961135625839 norm:0.00014947772433515638 max memory_allocated 22562.94482421875 
[2025-03-02 08:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.1051739752292633 norm:0.0001443234650650993 max memory_allocated 22562.94482421875 
[2025-03-02 08:47:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.10515324026346207 norm:0.0001451425050618127 max memory_allocated 22562.94482421875 
[2025-03-02 08:47:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.1051253005862236 norm:0.00014552548236679286 max memory_allocated 22562.94482421875 
[2025-03-02 08:48:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.10510016977787018 norm:0.00014441375969909132 max memory_allocated 22562.94482421875 
[2025-03-02 08:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.10508013516664505 norm:0.00014332834689412266 max memory_allocated 22562.94482421875 
[2025-03-02 08:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.10506550222635269 norm:0.00014422732056118548 max memory_allocated 22562.94482421875 
[2025-03-02 08:50:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.10506095737218857 norm:0.0001426479429937899 max memory_allocated 22562.94482421875 
[2025-03-02 08:50:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.10504009574651718 norm:0.00014090398326516151 max memory_allocated 22562.94482421875 
[2025-03-02 08:50:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:51:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.12842361629009247 norm:0.0009207180701196194 max memory_allocated 22563.11669921875 
[2025-03-02 08:51:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.12549470365047455 norm:0.000475252018077299 max memory_allocated 22563.11669921875 
[2025-03-02 08:52:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.12319235503673553 norm:0.00034307915484532714 max memory_allocated 22563.11669921875 
[2025-03-02 08:53:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.12171543389558792 norm:0.0002713462745305151 max memory_allocated 22563.11669921875 
[2025-03-02 08:53:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.12138248980045319 norm:0.00022843285114504397 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.12114822119474411 norm:0.0001983980182558298 max memory_allocated 22563.11669921875 
[2025-03-02 08:54:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.12099069356918335 norm:0.00018090505909640342 max memory_allocated 22563.11669921875 
[2025-03-02 08:55:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.12091655284166336 norm:0.0001667994656600058 max memory_allocated 22563.11669921875 
[2025-03-02 08:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.12085305899381638 norm:0.0001594939240021631 max memory_allocated 22563.11669921875 
[2025-03-02 08:56:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.12075556814670563 norm:0.00015105976490303874 max memory_allocated 22563.11669921875 
[2025-03-02 08:56:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.12069526314735413 norm:0.00014526181621477008 max memory_allocated 22563.11669921875 
[2025-03-02 08:57:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.12063479423522949 norm:0.0001421995839336887 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.12061327695846558 norm:0.00014113762881606817 max memory_allocated 22563.11669921875 
[2025-03-02 08:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.12055882811546326 norm:0.00013785960618406534 max memory_allocated 22563.11669921875 
[2025-03-02 08:59:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.120524562895298 norm:0.0001351381652057171 max memory_allocated 22563.11669921875 
[2025-03-02 08:59:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.12051840871572495 norm:0.00013446231605485082 max memory_allocated 22563.11669921875 
[2025-03-02 09:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.12049207836389542 norm:0.00013333340757526457 max memory_allocated 22563.11669921875 
[2025-03-02 09:00:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.12047784775495529 norm:0.0001355634449282661 max memory_allocated 22563.11669921875 
[2025-03-02 09:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.12048022449016571 norm:0.00013465256779454648 max memory_allocated 22563.11669921875 
[2025-03-02 09:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.12045640498399734 norm:0.0001309365325141698 max memory_allocated 22563.11669921875 
[2025-03-02 09:02:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 09:02:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.14825446903705597 norm:0.0012821017298847437 max memory_allocated 22563.28857421875 
[2025-03-02 09:03:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.14491868019104004 norm:0.000709490617737174 max memory_allocated 22563.28857421875 
[2025-03-02 09:03:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.14226922392845154 norm:0.0004908728296868503 max memory_allocated 22563.28857421875 
[2025-03-02 09:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.14073297381401062 norm:0.00036704266676679254 max memory_allocated 22563.28857421875 
[2025-03-02 09:05:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.14039842784404755 norm:0.0003012308734469116 max memory_allocated 22563.28857421875 
[2025-03-02 09:05:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.14014258980751038 norm:0.00024463882436975837 max memory_allocated 22563.28857421875 
[2025-03-02 09:06:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.14003202319145203 norm:0.000212729413760826 max memory_allocated 22563.28857421875 
[2025-03-02 09:06:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.1399010270833969 norm:0.00020099937682971358 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.1398049145936966 norm:0.00017366508836857975 max memory_allocated 22563.28857421875 
[2025-03-02 09:07:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.1397448480129242 norm:0.00016952023725025356 max memory_allocated 22563.28857421875 
[2025-03-02 09:08:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.1397002637386322 norm:0.00016252842033281922 max memory_allocated 22563.28857421875 
[2025-03-02 09:08:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.13966615498065948 norm:0.00016125959518831223 max memory_allocated 22563.28857421875 
[2025-03-02 09:09:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.13964486122131348 norm:0.0001569585729157552 max memory_allocated 22563.28857421875 
[2025-03-02 09:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.13962464034557343 norm:0.00015307313879020512 max memory_allocated 22563.28857421875 
[2025-03-02 09:10:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.13959595561027527 norm:0.00015041028382256627 max memory_allocated 22563.28857421875 
[2025-03-02 09:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.13958001136779785 norm:0.0001465195819037035 max memory_allocated 22563.28857421875 
[2025-03-02 09:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.13957348465919495 norm:0.0001471495343139395 max memory_allocated 22563.28857421875 
[2025-03-02 09:12:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.13954320549964905 norm:0.00014614942483603954 max memory_allocated 22563.28857421875 
[2025-03-02 09:12:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.13957719504833221 norm:0.00014487048611044884 max memory_allocated 22563.28857421875 
[2025-03-02 09:13:24 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.13959017395973206 norm:0.0001514986652182415 max memory_allocated 22563.28857421875 
[2025-03-02 09:13:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 09:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.1741849184036255 norm:0.005109118297696114 max memory_allocated 22563.46044921875 
[2025-03-02 09:14:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.1684332638978958 norm:0.0025795630645006895 max memory_allocated 22563.46044921875 
[2025-03-02 09:15:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.16467677056789398 norm:0.0015608491376042366 max memory_allocated 22563.46044921875 
[2025-03-02 09:15:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.16260644793510437 norm:0.0010472865542396903 max memory_allocated 22563.46044921875 
[2025-03-02 09:16:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.16200383007526398 norm:0.0007544765248894691 max memory_allocated 22563.46044921875 
[2025-03-02 09:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.16167810559272766 norm:0.0005722569185309112 max memory_allocated 22563.46044921875 
[2025-03-02 09:17:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.16141977906227112 norm:0.00045358837815001607 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:05 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.16125671565532684 norm:0.0003750348696485162 max memory_allocated 22563.46044921875 
[2025-03-02 09:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.161180317401886 norm:0.0003228665154892951 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.16105636954307556 norm:0.0002860640233848244 max memory_allocated 22563.46044921875 
[2025-03-02 09:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.16098670661449432 norm:0.0002649764937814325 max memory_allocated 22563.46044921875 
[2025-03-02 09:20:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.16090287268161774 norm:0.00024181479238905013 max memory_allocated 22563.46044921875 
[2025-03-02 09:20:53 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.1608632653951645 norm:0.0002294290898134932 max memory_allocated 22563.46044921875 
[2025-03-02 09:21:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.1608084887266159 norm:0.0002200313174398616 max memory_allocated 22563.46044921875 
[2025-03-02 09:22:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.16076591610908508 norm:0.00021369612659327686 max memory_allocated 22563.46044921875 
[2025-03-02 09:22:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.16072669625282288 norm:0.0002090059861075133 max memory_allocated 22563.46044921875 
[2025-03-02 09:23:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.16073031723499298 norm:0.0002084980660583824 max memory_allocated 22563.46044921875 
[2025-03-02 09:23:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.16076236963272095 norm:0.00020623058662749827 max memory_allocated 22563.46044921875 
[2025-03-02 09:24:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.16070447862148285 norm:0.00019981876539532095 max memory_allocated 22563.46044921875 
[2025-03-02 09:24:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.1606796532869339 norm:0.00019909605907741934 max memory_allocated 22563.46044921875 
[2025-03-02 09:24:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 09:25:35 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.1942903697490692 norm:0.002995049813762307 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.18984392285346985 norm:0.001523875631392002 max memory_allocated 22563.63232421875 
[2025-03-02 09:26:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.18645264208316803 norm:0.0009724675328470767 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.18464571237564087 norm:0.000687422405462712 max memory_allocated 22563.63232421875 
[2025-03-02 09:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.18416106700897217 norm:0.0005372797604650259 max memory_allocated 22563.63232421875 
[2025-03-02 09:28:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.1839527040719986 norm:0.0004508105048444122 max memory_allocated 22563.63232421875 
[2025-03-02 09:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.1837729811668396 norm:0.00037527186213992536 max memory_allocated 22563.63232421875 
[2025-03-02 09:29:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.18360668420791626 norm:0.000319543614750728 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.18346992135047913 norm:0.00028345765895210207 max memory_allocated 22563.63232421875 
[2025-03-02 09:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.1833634227514267 norm:0.0002615576086100191 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.18328061699867249 norm:0.00024171703262254596 max memory_allocated 22563.63232421875 
[2025-03-02 09:31:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.18321776390075684 norm:0.00022632755280938 max memory_allocated 22563.63232421875 
[2025-03-02 09:32:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.18315473198890686 norm:0.00021253799786791205 max memory_allocated 22563.63232421875 
[2025-03-02 09:32:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.18310555815696716 norm:0.00020659822621382773 max memory_allocated 22563.63232421875 
[2025-03-02 09:33:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.18309861421585083 norm:0.00019133868045173585 max memory_allocated 22563.63232421875 
[2025-03-02 09:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.18308289349079132 norm:0.00018411141354590654 max memory_allocated 22563.63232421875 
[2025-03-02 09:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.18306249380111694 norm:0.00018478280981071293 max memory_allocated 22563.63232421875 
[2025-03-02 09:35:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.18302519619464874 norm:0.00018292840104550123 max memory_allocated 22563.63232421875 
[2025-03-02 09:35:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.18301135301589966 norm:0.00019196687208022922 max memory_allocated 22563.63232421875 
[2025-03-02 09:36:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.1829991340637207 norm:0.00018954675761051476 max memory_allocated 22563.63232421875 
[2025-03-02 09:36:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 09:36:26 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:37:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.2253287136554718 norm:0.007492039818316698 max memory_allocated 22563.91943359375 
[2025-03-02 09:37:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.22035843133926392 norm:0.006095375400036573 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.21610665321350098 norm:0.004799420014023781 max memory_allocated 22563.91943359375 
[2025-03-02 09:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.21424292027950287 norm:0.004169838968664408 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.2136422097682953 norm:0.003536175936460495 max memory_allocated 22563.91943359375 
[2025-03-02 09:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.21324598789215088 norm:0.00306645967066288 max memory_allocated 22563.91943359375 
[2025-03-02 09:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.2130366712808609 norm:0.0028044558130204678 max memory_allocated 22563.91943359375 
[2025-03-02 09:40:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.21291522681713104 norm:0.002635024255141616 max memory_allocated 22563.91943359375 
[2025-03-02 09:41:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.21283100545406342 norm:0.0026858963537961245 max memory_allocated 22563.91943359375 
[2025-03-02 09:42:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.21287263929843903 norm:0.002251584315672517 max memory_allocated 22563.91943359375 
[2025-03-02 09:42:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.21267250180244446 norm:0.0024582126643508673 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.21259723603725433 norm:0.0020803106017410755 max memory_allocated 22563.91943359375 
[2025-03-02 09:43:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.21244703233242035 norm:0.0022346472833305597 max memory_allocated 22563.91943359375 
[2025-03-02 09:44:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.21239030361175537 norm:0.0020308210514485836 max memory_allocated 22563.91943359375 
[2025-03-02 09:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.21236515045166016 norm:0.002032936317846179 max memory_allocated 22563.91943359375 
[2025-03-02 09:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.21229824423789978 norm:0.0019963851664215326 max memory_allocated 22563.91943359375 
[2025-03-02 09:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.2122689038515091 norm:0.001888374099507928 max memory_allocated 22563.91943359375 
[2025-03-02 09:46:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.21220971643924713 norm:0.0019053053110837936 max memory_allocated 22563.91943359375 
[2025-03-02 09:47:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.21222254633903503 norm:0.0018741864478215575 max memory_allocated 22563.91943359375 
[2025-03-02 09:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.2122146487236023 norm:0.0018825015285983682 max memory_allocated 22563.91943359375 
[2025-03-02 09:47:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 09:47:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:48:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.26303642988204956 norm:0.008174537681043148 max memory_allocated 22564.09130859375 
[2025-03-02 09:49:01 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.2567967176437378 norm:0.005928418133407831 max memory_allocated 22564.09130859375 
[2025-03-02 09:49:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.2521772086620331 norm:0.004700301680713892 max memory_allocated 22564.09130859375 
[2025-03-02 09:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.2501817047595978 norm:0.003966639284044504 max memory_allocated 22564.09130859375 
[2025-03-02 09:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.24960054457187653 norm:0.0034508956596255302 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.24909989535808563 norm:0.0029362046625465155 max memory_allocated 22564.09130859375 
[2025-03-02 09:51:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.2487635463476181 norm:0.0025407997891306877 max memory_allocated 22564.09130859375 
[2025-03-02 09:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.24857330322265625 norm:0.0024453597143292427 max memory_allocated 22564.09130859375 
[2025-03-02 09:52:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.24852293729782104 norm:0.0022169644944369793 max memory_allocated 22564.09130859375 
[2025-03-02 09:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.24840764701366425 norm:0.002426296938210726 max memory_allocated 22564.09130859375 
[2025-03-02 09:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.2484344094991684 norm:0.0017582295695319772 max memory_allocated 22564.09130859375 
[2025-03-02 09:54:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.2481384575366974 norm:0.0019863019697368145 max memory_allocated 22564.09130859375 
[2025-03-02 09:55:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.2480422407388687 norm:0.0019459874602034688 max memory_allocated 22564.09130859375 
[2025-03-02 09:55:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.24804933369159698 norm:0.002038360107690096 max memory_allocated 22564.09130859375 
[2025-03-02 09:56:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.24803593754768372 norm:0.0020144861191511154 max memory_allocated 22564.09130859375 
[2025-03-02 09:56:53 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.2480151653289795 norm:0.001991857308894396 max memory_allocated 22564.09130859375 
[2025-03-02 09:57:27 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.24797885119915009 norm:0.0019271621713414788 max memory_allocated 22564.09130859375 
[2025-03-02 09:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.24790239334106445 norm:0.001871852669864893 max memory_allocated 22564.09130859375 
[2025-03-02 09:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.24789002537727356 norm:0.0017886364366859198 max memory_allocated 22564.09130859375 
[2025-03-02 09:59:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.24788153171539307 norm:0.0019036860903725028 max memory_allocated 22564.09130859375 
[2025-03-02 09:59:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:59:20 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.3488084077835083 norm:0.01705743931233883 max memory_allocated 22564.26318359375 
[2025-03-02 10:00:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.3316429853439331 norm:0.016123563051223755 max memory_allocated 22564.26318359375 
[2025-03-02 10:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.3236337900161743 norm:0.01713767647743225 max memory_allocated 22564.26318359375 
[2025-03-02 10:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.3198067843914032 norm:0.0172125194221735 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.31816837191581726 norm:0.016971098259091377 max memory_allocated 22564.26318359375 
[2025-03-02 10:02:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.3170831799507141 norm:0.016540290787816048 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.3160836696624756 norm:0.01609092578291893 max memory_allocated 22564.26318359375 
[2025-03-02 10:03:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.3154531419277191 norm:0.016244806349277496 max memory_allocated 22564.26318359375 
[2025-03-02 10:04:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.3154025077819824 norm:0.016133058816194534 max memory_allocated 22564.26318359375 
[2025-03-02 10:04:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.31450140476226807 norm:0.015254169702529907 max memory_allocated 22564.26318359375 
[2025-03-02 10:05:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.313838392496109 norm:0.013812295161187649 max memory_allocated 22564.26318359375 
[2025-03-02 10:06:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.3134852647781372 norm:0.013247591443359852 max memory_allocated 22564.26318359375 
[2025-03-02 10:06:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.31330764293670654 norm:0.013103356584906578 max memory_allocated 22564.26318359375 
[2025-03-02 10:07:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.31312820315361023 norm:0.012584607116878033 max memory_allocated 22564.26318359375 
[2025-03-02 10:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.3129056692123413 norm:0.011953918263316154 max memory_allocated 22564.26318359375 
[2025-03-02 10:08:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.31274595856666565 norm:0.011827643029391766 max memory_allocated 22564.26318359375 
[2025-03-02 10:08:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.3126738369464874 norm:0.011407021433115005 max memory_allocated 22564.26318359375 
[2025-03-02 10:09:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.31257012486457825 norm:0.011252665892243385 max memory_allocated 22564.26318359375 
[2025-03-02 10:10:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.3125247657299042 norm:0.011220322921872139 max memory_allocated 22564.26318359375 
[2025-03-02 10:10:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.3124041259288788 norm:0.010676334612071514 max memory_allocated 22564.26318359375 
[2025-03-02 10:10:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 10:10:48 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 10:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.6186062693595886 norm:0.04171173647046089 max memory_allocated 22564.43505859375 
[2025-03-02 10:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.5768561363220215 norm:0.028072090819478035 max memory_allocated 22564.43505859375 
[2025-03-02 10:12:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.5519055724143982 norm:0.02099434658885002 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.5379798412322998 norm:0.016526827588677406 max memory_allocated 22564.43505859375 
[2025-03-02 10:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.5301962494850159 norm:0.014978419058024883 max memory_allocated 22564.43505859375 
[2025-03-02 10:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.5252688527107239 norm:0.01412953995168209 max memory_allocated 22564.43505859375 
[2025-03-02 10:14:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.5216822028160095 norm:0.012985949404537678 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.5190020799636841 norm:0.012340760789811611 max memory_allocated 22564.43505859375 
[2025-03-02 10:15:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.5169053673744202 norm:0.012078536674380302 max memory_allocated 22564.43505859375 
[2025-03-02 10:16:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.5154836177825928 norm:0.01219774316996336 max memory_allocated 22564.43505859375 
[2025-03-02 10:16:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.5142285823822021 norm:0.012679173611104488 max memory_allocated 22564.43505859375 
[2025-03-02 10:17:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.5134899616241455 norm:0.011902415193617344 max memory_allocated 22564.43505859375 
[2025-03-02 10:18:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.5128706097602844 norm:0.012400642037391663 max memory_allocated 22564.43505859375 
[2025-03-02 10:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.5123525857925415 norm:0.011491162702441216 max memory_allocated 22564.43505859375 
[2025-03-02 10:19:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.5119870901107788 norm:0.011460156179964542 max memory_allocated 22564.43505859375 
[2025-03-02 10:19:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.5114620327949524 norm:0.011366857215762138 max memory_allocated 22564.43505859375 
[2025-03-02 10:20:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.5112101435661316 norm:0.01134900376200676 max memory_allocated 22564.43505859375 
[2025-03-02 10:20:55 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.5105711221694946 norm:0.010802628472447395 max memory_allocated 22564.43505859375 
[2025-03-02 10:21:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.5102253556251526 norm:0.010674208402633667 max memory_allocated 22564.43505859375 
[2025-03-02 10:22:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.5098665356636047 norm:0.010492672212421894 max memory_allocated 22564.43505859375 
[2025-03-02 10:22:12 root] (main_calib_config2.py 372): INFO 21920.043172597885
[2025-03-02 10:22:17 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 10:23:28 root] (main_calib_config2.py 159): INFO wikitext2 : 5.7938032150268555
[2025-03-02 10:23:28 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 10:25:18 root] (main_calib_config2.py 159): INFO c4 : 7.255876064300537
[2025-03-02 12:05:05 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.7938032150268555, 'c4': 7.255876064300537, 'results': {'hellaswag': {'acc': 0.5553674566819359, 'acc_stderr': 0.004959094146471522, 'acc_norm': 0.7201752638916551, 'acc_norm_stderr': 0.004479955169853627}, 'piqa': {'acc': 0.779651795429815, 'acc_stderr': 0.009670535456853126, 'acc_norm': 0.7709466811751904, 'acc_norm_stderr': 0.009804509865175505}, 'arc_challenge': {'acc': 0.371160409556314, 'acc_stderr': 0.014117971901142813, 'acc_norm': 0.39590443686006827, 'acc_norm_stderr': 0.014291228393536592}, 'boolq': {'acc': 0.7226299694189603, 'acc_stderr': 0.007830334077028924}, 'arc_easy': {'acc': 0.6574074074074074, 'acc_stderr': 0.009738105469984193, 'acc_norm': 0.5117845117845118, 'acc_norm_stderr': 0.01025693347591102}, 'winogrande': {'acc': 0.6692975532754538, 'acc_stderr': 0.013222435887002705}}, 'versions': {'hellaswag': 0, 'piqa': 0, 'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0, 'winogrande': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
