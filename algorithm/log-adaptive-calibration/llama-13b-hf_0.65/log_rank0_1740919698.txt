[2025-03-02 12:48:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.65', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.65.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.65.pkl
[2025-03-02 12:52:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.012706432491540909 norm:0.008276726119220257 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0073852441273629665 norm:0.004119965247809887 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.005107165779918432 norm:0.0026743595954030752 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.004486559424549341 norm:0.0021215646993368864 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.004285126458853483 norm:0.0018192732241004705 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.004103098530322313 norm:0.0015963446348905563 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0039921109564602375 norm:0.0014115608064457774 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0038887360133230686 norm:0.0012377549428492785 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.003857993520796299 norm:0.001173199387267232 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.003797752782702446 norm:0.001027728314511478 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0037778669502586126 norm:0.0009701538947410882 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0037855831906199455 norm:0.0009183965157717466 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.003760118503123522 norm:0.0008345625828951597 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0037146881222724915 norm:0.0007623894489370286 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0037006561178714037 norm:0.0007300017750822008 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0036916155368089676 norm:0.0007143103866837919 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0036853288765996695 norm:0.0007115653133951128 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0036522301379591227 norm:0.0006376246456056833 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0036630844697356224 norm:0.0006457687704823911 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0036424011923372746 norm:0.0005911012412980199 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:20 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.01915867067873478 norm:0.015224272385239601 max memory_allocated 29268.02001953125 
[2025-03-02 13:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.011060109362006187 norm:0.00858116615563631 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.008924886584281921 norm:0.00577573524788022 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.008054484613239765 norm:0.004769931081682444 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.007628034334629774 norm:0.004156192298978567 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.007389393635094166 norm:0.00371764344163239 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.007186149246990681 norm:0.0034438048023730516 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.007050023414194584 norm:0.0031295090448111296 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.006921190768480301 norm:0.0028936502058058977 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.006791973952203989 norm:0.002637718804180622 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.006701809354126453 norm:0.0024151732213795185 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.006604114547371864 norm:0.0022520001512020826 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.006520743481814861 norm:0.0020628608763217926 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.006451833061873913 norm:0.0018631714629009366 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.0063904281705617905 norm:0.0017010915325954556 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.006338234059512615 norm:0.0015230074059218168 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.006303370464593172 norm:0.0013969882857054472 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.006293850019574165 norm:0.0013950674328953028 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.006355689372867346 norm:0.0014392964076250792 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.0063381437212228775 norm:0.0013848610688000917 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:06 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:26:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.03200169652700424 norm:0.010183616541326046 max memory_allocated 29268.02001953125 
[2025-03-02 13:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.02402539923787117 norm:0.007146148011088371 max memory_allocated 29268.02001953125 
[2025-03-02 13:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.020280901342630386 norm:0.005651416257023811 max memory_allocated 29268.02001953125 
[2025-03-02 13:29:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.01804809272289276 norm:0.004037263337522745 max memory_allocated 29268.02001953125 
[2025-03-02 13:30:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.016639716923236847 norm:0.0031048778910189867 max memory_allocated 29268.02001953125 
[2025-03-02 13:31:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.015692180022597313 norm:0.0025399932637810707 max memory_allocated 29268.02001953125 
[2025-03-02 13:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.014941316097974777 norm:0.0020279104355722666 max memory_allocated 29268.02001953125 
[2025-03-02 13:32:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.014394674450159073 norm:0.0018500208389014006 max memory_allocated 29268.02001953125 
[2025-03-02 13:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.014125969260931015 norm:0.0018309794832020998 max memory_allocated 29268.02001953125 
[2025-03-02 13:34:19 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.01385335810482502 norm:0.0016448341775685549 max memory_allocated 29268.02001953125 
[2025-03-02 13:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.013727590441703796 norm:0.0015523434849455953 max memory_allocated 29268.02001953125 
[2025-03-02 13:35:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.013697650283575058 norm:0.0015573594719171524 max memory_allocated 29268.02001953125 
[2025-03-02 13:36:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.013679844327270985 norm:0.001482145395129919 max memory_allocated 29268.02001953125 
[2025-03-02 13:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.013492836616933346 norm:0.0014175822725519538 max memory_allocated 29268.02001953125 
[2025-03-02 13:38:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.013579973950982094 norm:0.0014335053274407983 max memory_allocated 29268.02001953125 
[2025-03-02 13:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.013292265124619007 norm:0.001311232685111463 max memory_allocated 29268.02001953125 
[2025-03-02 13:40:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.013126173987984657 norm:0.0011453331680968404 max memory_allocated 29268.02001953125 
[2025-03-02 13:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.013212041929364204 norm:0.0012928376672789454 max memory_allocated 29268.02001953125 
[2025-03-02 13:41:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.013031785376369953 norm:0.0012195646995678544 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:33 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.01300258468836546 norm:0.0011404819088056684 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:43:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.028637124225497246 norm:0.0017120980191975832 max memory_allocated 29268.43798828125 
[2025-03-02 13:44:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.02152407541871071 norm:0.000701235665474087 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.01805129088461399 norm:0.00034499511821195483 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.017172949388623238 norm:0.0002540765854064375 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.01664617843925953 norm:0.00014497508527711034 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.016219794750213623 norm:0.0001343767944490537 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.015962202101945877 norm:0.00016234544455073774 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.015791723504662514 norm:0.00014485674910247326 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.01565641351044178 norm:0.00013596599455922842 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.015636064112186432 norm:0.0001418960018781945 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.015603875741362572 norm:0.00013951357686892152 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.015544073656201363 norm:0.00011602316953940317 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.015513647347688675 norm:0.0001131255630753003 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.015488546341657639 norm:0.00011679054296109825 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.015468800440430641 norm:0.0001130100863520056 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.015447946265339851 norm:0.00010934039892163128 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.015454559586942196 norm:0.00012860797869507223 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.015444834716618061 norm:0.00013475619198288769 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.015429212711751461 norm:0.00014161186118144542 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.015424942597746849 norm:0.00016470591071993113 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:00:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.036470845341682434 norm:0.008063212037086487 max memory_allocated 29268.62548828125 
[2025-03-02 14:01:13 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.02645617537200451 norm:0.00198762072250247 max memory_allocated 29268.62548828125 
[2025-03-02 14:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.02306050807237625 norm:0.0009837162215262651 max memory_allocated 29268.62548828125 
[2025-03-02 14:02:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.021550117060542107 norm:0.0007245909073390067 max memory_allocated 29268.62548828125 
[2025-03-02 14:03:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.02062138170003891 norm:0.0005555454408749938 max memory_allocated 29268.62548828125 
[2025-03-02 14:04:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.020050376653671265 norm:0.0004660889972001314 max memory_allocated 29268.62548828125 
[2025-03-02 14:05:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.019720105454325676 norm:0.0004288000054657459 max memory_allocated 29268.62548828125 
[2025-03-02 14:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.019579466432332993 norm:0.00034396868431940675 max memory_allocated 29268.62548828125 
[2025-03-02 14:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.019474640488624573 norm:0.0003203956293873489 max memory_allocated 29268.62548828125 
[2025-03-02 14:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.019440030679106712 norm:0.0003168343100696802 max memory_allocated 29268.62548828125 
[2025-03-02 14:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.019383670762181282 norm:0.0002655769058037549 max memory_allocated 29268.62548828125 
[2025-03-02 14:09:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.019344110041856766 norm:0.00023700752353761345 max memory_allocated 29268.62548828125 
[2025-03-02 14:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.019328761845827103 norm:0.00024298214702866971 max memory_allocated 29268.62548828125 
[2025-03-02 14:11:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.019316285848617554 norm:0.00020013152970932424 max memory_allocated 29268.62548828125 
[2025-03-02 14:11:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.01931958831846714 norm:0.000216033891774714 max memory_allocated 29268.62548828125 
[2025-03-02 14:12:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.019255081191658974 norm:0.0001838150928961113 max memory_allocated 29268.62548828125 
[2025-03-02 14:13:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.019248133525252342 norm:0.00015548389637842774 max memory_allocated 29268.62548828125 
[2025-03-02 14:14:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.01924026943743229 norm:0.00015669538697693497 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.019235024228692055 norm:0.0001580362004460767 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.01922537386417389 norm:0.00015350597095675766 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:17:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.044093046337366104 norm:0.007664790377020836 max memory_allocated 29268.81298828125 
[2025-03-02 14:17:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.030983412638306618 norm:0.0019102032529190183 max memory_allocated 29268.81298828125 
[2025-03-02 14:18:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.026897044852375984 norm:0.0009445828618481755 max memory_allocated 29268.81298828125 
[2025-03-02 14:19:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.025039052590727806 norm:0.0006022588349878788 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.023908820003271103 norm:0.0004685893072746694 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.023251814767718315 norm:0.0003925780765712261 max memory_allocated 29268.81298828125 
[2025-03-02 14:22:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.022884061560034752 norm:0.0003392759244889021 max memory_allocated 29268.81298828125 
[2025-03-02 14:22:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.022692352533340454 norm:0.0003143286448903382 max memory_allocated 29268.81298828125 
[2025-03-02 14:23:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.0225742869079113 norm:0.0002700848563108593 max memory_allocated 29268.81298828125 
[2025-03-02 14:24:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.022487524896860123 norm:0.00025507764075882733 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.02242783084511757 norm:0.00023966880689840764 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.0223800390958786 norm:0.00020938675152137876 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.02232489548623562 norm:0.00020453933393582702 max memory_allocated 29268.81298828125 
[2025-03-02 14:27:47 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.02231510542333126 norm:0.0002183762117056176 max memory_allocated 29268.81298828125 
[2025-03-02 14:28:36 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.022287528961896896 norm:0.0002117091789841652 max memory_allocated 29268.81298828125 
[2025-03-02 14:29:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.022272633388638496 norm:0.0001777472934918478 max memory_allocated 29268.81298828125 
[2025-03-02 14:30:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.02225407399237156 norm:0.00018700797227211297 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.022261720150709152 norm:0.00020561883866321295 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.022235434502363205 norm:0.00017000702791847289 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.022200528532266617 norm:0.0001573587505845353 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:33:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.0464201420545578 norm:0.0025324192829430103 max memory_allocated 29269.00048828125 
[2025-03-02 14:34:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.03729010000824928 norm:0.0013388348743319511 max memory_allocated 29269.00048828125 
[2025-03-02 14:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.033123042434453964 norm:0.0008904528804123402 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.03046640008687973 norm:0.0007056151516735554 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.02900778129696846 norm:0.0006150599219836295 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.028229698538780212 norm:0.0005324229714460671 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.027797531336545944 norm:0.0004952466697432101 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.02755069173872471 norm:0.0004163847188465297 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:24 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.027394602075219154 norm:0.0004055476456414908 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.027299394831061363 norm:0.00039072605432011187 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.02723078243434429 norm:0.0003810905327554792 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:52 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.027304863557219505 norm:0.00044296137639321387 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.02722148969769478 norm:0.00039604646735824645 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.027192752808332443 norm:0.00041377259185537696 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.027139104902744293 norm:0.00035869263228960335 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.027108147740364075 norm:0.00037802261067554355 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.027106545865535736 norm:0.00036103659658692777 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.02707647904753685 norm:0.0003499142767395824 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.02710122801363468 norm:0.0003787793393712491 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.0271061472594738 norm:0.0003971919941250235 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.04943901300430298 norm:0.001475950120948255 max memory_allocated 29269.18798828125 
[2025-03-02 14:51:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.039541177451610565 norm:0.0006785385776311159 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.03427420184016228 norm:0.000358426827006042 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.03284914046525955 norm:0.00023663540196139365 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.03200897201895714 norm:0.00019268583855591714 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.03150811418890953 norm:0.00017380468489136547 max memory_allocated 29269.18798828125 
[2025-03-02 14:55:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.031213849782943726 norm:0.00015977100702002645 max memory_allocated 29269.18798828125 
[2025-03-02 14:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.031040428206324577 norm:0.00015085196355357766 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.030925961211323738 norm:0.00014452570758294314 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.030855819582939148 norm:0.00014390223077498376 max memory_allocated 29269.18798828125 
[2025-03-02 14:58:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.03079511970281601 norm:0.00015339633682742715 max memory_allocated 29269.18798828125 
[2025-03-02 14:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.03075416199862957 norm:0.00014726723020430654 max memory_allocated 29269.18798828125 
[2025-03-02 15:00:25 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.030694974586367607 norm:0.00014060323883313686 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.030656710267066956 norm:0.0001389829849358648 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.030603375285863876 norm:0.00013895457959733903 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.030597811564803123 norm:0.00014634671970270574 max memory_allocated 29269.18798828125 
[2025-03-02 15:03:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.030567530542612076 norm:0.00014192269009072334 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.030549004673957825 norm:0.00014292527339421213 max memory_allocated 29269.18798828125 
[2025-03-02 15:05:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.030563436448574066 norm:0.00015743784024380147 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.030583737418055534 norm:0.00015087325300555676 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:07:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.05257922038435936 norm:0.0016104512615129352 max memory_allocated 29269.37548828125 
[2025-03-02 15:08:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.04286599159240723 norm:0.0006730710156261921 max memory_allocated 29269.37548828125 
[2025-03-02 15:08:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.0380295030772686 norm:0.00036019415711052716 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.03656700626015663 norm:0.00025496326270513237 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.035706691443920135 norm:0.00020781622151844203 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.03521287068724632 norm:0.0001849091931944713 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.03486475348472595 norm:0.00016848466475494206 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.03467397391796112 norm:0.00016522406076546758 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:51 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.03454539179801941 norm:0.00015554406854789704 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.03446152061223984 norm:0.00014669931260868907 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.03442007303237915 norm:0.00015211910067591816 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.034410540014505386 norm:0.00014598984853364527 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.03435005992650986 norm:0.00014468580775428563 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.03434891253709793 norm:0.00014890445163473487 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.03433319926261902 norm:0.0001415116130374372 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.034310925751924515 norm:0.00014050985919311643 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.03426959738135338 norm:0.00013930593559052795 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.03421896696090698 norm:0.0001328959478996694 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.034210506826639175 norm:0.00013253034558147192 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.03420316055417061 norm:0.00013046602543909103 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:24:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.05445820838212967 norm:0.0013129382859915495 max memory_allocated 29269.56298828125 
[2025-03-02 15:24:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.04567119479179382 norm:0.0005747562390752137 max memory_allocated 29269.56298828125 
[2025-03-02 15:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.040803052484989166 norm:0.000300434825476259 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.039431385695934296 norm:0.00020786485401913524 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.038646794855594635 norm:0.00016871040861587971 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.038166292011737823 norm:0.00015025585889816284 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.03787115216255188 norm:0.00014611506776418537 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.0376959890127182 norm:0.0001381241891067475 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.037591785192489624 norm:0.0001310611260123551 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.03752408176660538 norm:0.00012951868120580912 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.03745691850781441 norm:0.00012865918688476086 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.03746052086353302 norm:0.0001299054129049182 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.0374065600335598 norm:0.00013120997755322605 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.03740281984210014 norm:0.00013286984176374972 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.03738754242658615 norm:0.00014160844148136675 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.03736519068479538 norm:0.00013777369167655706 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.0373585969209671 norm:0.00013553837197832763 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.037342362105846405 norm:0.00013545305409934372 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:47 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.037328366190195084 norm:0.00014105495938565582 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.03731328248977661 norm:0.0001447068789275363 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.05621635168790817 norm:0.001132067060098052 max memory_allocated 29269.75048828125 
[2025-03-02 15:41:33 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.04824936017394066 norm:0.00045293732546269894 max memory_allocated 29269.75048828125 
[2025-03-02 15:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.04378945380449295 norm:0.0002516241802368313 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.042515795677900314 norm:0.00019066644017584622 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.04177843779325485 norm:0.00016365763440262526 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.04128717631101608 norm:0.00014363863738253713 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.041004832834005356 norm:0.00013407778169494122 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.04085478186607361 norm:0.0001341267634415999 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.04076976701617241 norm:0.00012498232536017895 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.04068095609545708 norm:0.000122499477583915 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.04060438647866249 norm:0.00011590062786126509 max memory_allocated 29269.75048828125 
[2025-03-02 15:49:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.04056771472096443 norm:0.00011886849097209051 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.04053182527422905 norm:0.00011850187729578465 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.040497276932001114 norm:0.00011558084952412173 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.04047603905200958 norm:0.00011575439566513523 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.04047083109617233 norm:0.00011518524115672335 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.04045061022043228 norm:0.00011320268822601065 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.04048938304185867 norm:0.00011538257967913523 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:30 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.04049462080001831 norm:0.00011685934441629797 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.04050470516085625 norm:0.00012022350711049512 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:57:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.0606473907828331 norm:0.0011696659494191408 max memory_allocated 29269.93798828125 
[2025-03-02 15:58:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.05263615399599075 norm:0.0005171392112970352 max memory_allocated 29269.93798828125 
[2025-03-02 15:59:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.04758583381772041 norm:0.00027438736287876964 max memory_allocated 29269.93798828125 
[2025-03-02 15:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.046200018376111984 norm:0.00018534206901676953 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.04543820768594742 norm:0.00015203726070467383 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.04489675536751747 norm:0.00013499105989467353 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.04462755471467972 norm:0.00012693127791862935 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.04444200173020363 norm:0.00011949429608648643 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.044362958520650864 norm:0.000119981006719172 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.04427460581064224 norm:0.00011512840865179896 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.04422048479318619 norm:0.00011569388152565807 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.044154588133096695 norm:0.0001104917173506692 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:18 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.04413279891014099 norm:0.00011367270053597167 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.04411407932639122 norm:0.00011404257384128869 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.04408805072307587 norm:0.00011326166713843122 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.044073499739170074 norm:0.00010894158185692504 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.04405222460627556 norm:0.00010884959192480892 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.044057317078113556 norm:0.00010836056026164442 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:14 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.044076379388570786 norm:0.00011443280527601019 max memory_allocated 29269.93798828125 
[2025-03-02 16:13:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.04407089203596115 norm:0.0001140112362918444 max memory_allocated 29269.93798828125 
[2025-03-02 16:13:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.06229238584637642 norm:0.0009665543911978602 max memory_allocated 29270.12548828125 
[2025-03-02 16:14:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.055001016706228256 norm:0.00043688909499906003 max memory_allocated 29270.12548828125 
[2025-03-02 16:15:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.05026121810078621 norm:0.00025976874167099595 max memory_allocated 29270.12548828125 
[2025-03-02 16:16:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.04896048083901405 norm:0.00019080562924500555 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.04812462627887726 norm:0.000156103415065445 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.047644201666116714 norm:0.00014288978127297014 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.04736637696623802 norm:0.00013287135516293347 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.04720117151737213 norm:0.0001256395480595529 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.04709378629922867 norm:0.0001222639693878591 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.04698178172111511 norm:0.0001194794022012502 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.046929240226745605 norm:0.00011676635767798871 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.04689323902130127 norm:0.00011575091048143804 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.046853192150592804 norm:0.00011419538350310177 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.04683128744363785 norm:0.00011526144953677431 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.04680974781513214 norm:0.00011282222112640738 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.04677460342645645 norm:0.00011213365360163152 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.04674806073307991 norm:0.00011113712389487773 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.046740151941776276 norm:0.00011163039016537368 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.046733539551496506 norm:0.0001113343532779254 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.046710558235645294 norm:0.00011198250285815448 max memory_allocated 29270.12548828125 
[2025-03-02 16:30:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:30:54 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.0649990662932396 norm:0.0007144606206566095 max memory_allocated 29270.31298828125 
[2025-03-02 16:31:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.05807110667228699 norm:0.00036332232411950827 max memory_allocated 29270.31298828125 
[2025-03-02 16:32:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.05323696881532669 norm:0.00023548206081613898 max memory_allocated 29270.31298828125 
[2025-03-02 16:33:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.05190988630056381 norm:0.00017814605962485075 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.05108710005879402 norm:0.0001520001096650958 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.05055553838610649 norm:0.0001363516494166106 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.05022763833403587 norm:0.00012414134107530117 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.0500607043504715 norm:0.0001218826582771726 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.04994828253984451 norm:0.0001180297986138612 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.04985002800822258 norm:0.00011621357407420874 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.04978615418076515 norm:0.00011232570977881551 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.04974357411265373 norm:0.00010949924035230651 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.04970941320061684 norm:0.00010925379319814965 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.049670130014419556 norm:0.00010861438204301521 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.04966263100504875 norm:0.00011065979924751446 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:13 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.049649450927972794 norm:0.00010931646102108061 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.04960024356842041 norm:0.00010823306365637109 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.049568526446819305 norm:0.00010597341315587983 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.049548011273145676 norm:0.00010567142453510314 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.04953957349061966 norm:0.00010626103903632611 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.07048697769641876 norm:0.0011284144129604101 max memory_allocated 29270.50048828125 
[2025-03-02 16:48:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.06245147064328194 norm:0.0005606742342934012 max memory_allocated 29270.50048828125 
[2025-03-02 16:49:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.05686093121767044 norm:0.00032784751965664327 max memory_allocated 29270.50048828125 
[2025-03-02 16:50:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.05540399253368378 norm:0.00023369546397589147 max memory_allocated 29270.50048828125 
[2025-03-02 16:50:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.0545080304145813 norm:0.00018237708718515933 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.05393447354435921 norm:0.00015729460574220866 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.05362646281719208 norm:0.0001436802849639207 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.05344105139374733 norm:0.00013348630454856902 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.05329546332359314 norm:0.00012648435949813575 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.053197916597127914 norm:0.0001233004149980843 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.05314711481332779 norm:0.00011924878344871104 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.053088828921318054 norm:0.0001143102053902112 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:29 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.05303642526268959 norm:0.00011780395288951695 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.05300299823284149 norm:0.00011833527241833508 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.0529610775411129 norm:0.00011481773253763095 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.052914563566446304 norm:0.0001137438157456927 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.05289030075073242 norm:0.00011396836634958163 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.0528760626912117 norm:0.00011270755203440785 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.05285973474383354 norm:0.0001125409544329159 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.052839264273643494 norm:0.00011206256749574095 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.06665565073490143 norm:0.0010107009438797832 max memory_allocated 29270.68798828125 
[2025-03-02 17:05:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.062152255326509476 norm:0.0003833965165540576 max memory_allocated 29270.68798828125 
[2025-03-02 17:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.05997453257441521 norm:0.0002567677875049412 max memory_allocated 29270.68798828125 
[2025-03-02 17:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.05827418714761734 norm:0.0001993005134863779 max memory_allocated 29270.68798828125 
[2025-03-02 17:07:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.05724518746137619 norm:0.0001645651791477576 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.056673042476177216 norm:0.00014690957323182374 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.05639254301786423 norm:0.00013339921133592725 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.05626017227768898 norm:0.0001232639915542677 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.05617343634366989 norm:0.00011679941235342994 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.05613217130303383 norm:0.00010878670582314953 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.05611143261194229 norm:0.00010591642785584554 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.05606495961546898 norm:0.00010010384721681476 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.05604298412799835 norm:9.661056537879631e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.0560169517993927 norm:9.646685066400096e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.05600809305906296 norm:9.579782636137679e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.055975060909986496 norm:9.283575491281226e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.05597912520170212 norm:9.343729470856488e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.05599326640367508 norm:9.278585639549419e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.05599784851074219 norm:9.12970572244376e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.05598887801170349 norm:9.058729483513162e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:20:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:21:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.06869211792945862 norm:0.0010998230427503586 max memory_allocated 29270.87548828125 
[2025-03-02 17:21:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.06549026072025299 norm:0.0005344297387637198 max memory_allocated 29270.87548828125 
[2025-03-02 17:22:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.063605397939682 norm:0.0003318719973322004 max memory_allocated 29270.87548828125 
[2025-03-02 17:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.062052298337221146 norm:0.0002322712098248303 max memory_allocated 29270.87548828125 
[2025-03-02 17:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.0610683374106884 norm:0.0001770361850503832 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.060555703938007355 norm:0.0001416012819390744 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.060354579240083694 norm:0.00012181991769466549 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.06028533726930618 norm:0.00011053922935388982 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.06024019792675972 norm:0.00010396324069006369 max memory_allocated 29270.87548828125 
[2025-03-02 17:28:28 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.0601988285779953 norm:9.868883353192359e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.060161836445331573 norm:9.424400195712224e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.06016243249177933 norm:9.256615157937631e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.06016668677330017 norm:9.147419041255489e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.060153938829898834 norm:9.071851673070341e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.060151394456624985 norm:9.18806908885017e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:33:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.060136597603559494 norm:9.093045810004696e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.06012408435344696 norm:9.099814633373171e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.060118816792964935 norm:9.099703311221674e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.060113027691841125 norm:9.11505994736217e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.06011204421520233 norm:9.024585597217083e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:37:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.07517495006322861 norm:0.0014473809860646725 max memory_allocated 29271.06298828125 
[2025-03-02 17:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.07125240564346313 norm:0.0006565105868503451 max memory_allocated 29271.06298828125 
[2025-03-02 17:39:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.06888218224048615 norm:0.0003941208415199071 max memory_allocated 29271.06298828125 
[2025-03-02 17:40:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.06711413711309433 norm:0.0002727388055063784 max memory_allocated 29271.06298828125 
[2025-03-02 17:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.06606830656528473 norm:0.00020294157729949802 max memory_allocated 29271.06298828125 
[2025-03-02 17:41:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.06554128229618073 norm:0.00016349469660781324 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.06533250212669373 norm:0.0001389385579386726 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.06522980332374573 norm:0.00012319296365603805 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.0651816800236702 norm:0.00011308398097753525 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.0651395320892334 norm:0.00010491220746189356 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.06510736793279648 norm:9.99189360300079e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.06508640944957733 norm:9.651212894823402e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.06508183479309082 norm:9.380376286571845e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.06507419049739838 norm:9.312939801020548e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.06505914032459259 norm:9.300914098275825e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.06506702303886414 norm:9.28975860006176e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.0650620311498642 norm:9.26933134905994e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.06505565345287323 norm:9.258408681489527e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.06504953652620316 norm:9.257218334823847e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.06505001336336136 norm:9.260201477445662e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.08236677944660187 norm:0.0013416333822533488 max memory_allocated 29271.25048828125 
[2025-03-02 17:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.07827986776828766 norm:0.0005649360246025026 max memory_allocated 29271.25048828125 
[2025-03-02 17:56:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.07586465030908585 norm:0.00033344700932502747 max memory_allocated 29271.25048828125 
[2025-03-02 17:57:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.07405078411102295 norm:0.00023473627516068518 max memory_allocated 29271.25048828125 
[2025-03-02 17:57:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.07297978550195694 norm:0.00018206833919975907 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.07247943431138992 norm:0.00015106586215551943 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.07229248434305191 norm:0.00013387428771238774 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.072188600897789 norm:0.00012523829354904592 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.0721249207854271 norm:0.00011753853323170915 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.07205729931592941 norm:0.00011272310803178698 max memory_allocated 29271.25048828125 
[2025-03-02 18:02:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.0720231756567955 norm:0.00010834501154022291 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.07199917733669281 norm:0.00010533687600400299 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.0719624012708664 norm:0.00010516124166315421 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.07195981591939926 norm:0.00010426197695778683 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.07193104177713394 norm:0.00010258897964376956 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.07193297147750854 norm:0.00010158326040254906 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.07193269580602646 norm:0.00010070871212519705 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.0719345286488533 norm:0.00010353653487982228 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.07192233949899673 norm:0.00010389598901383579 max memory_allocated 29271.25048828125 
[2025-03-02 18:10:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.07189632952213287 norm:0.00010208892490481958 max memory_allocated 29271.25048828125 
[2025-03-02 18:10:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.08897539228200912 norm:0.0009111335966736078 max memory_allocated 29271.43798828125 
[2025-03-02 18:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.08592892438173294 norm:0.0004158650990575552 max memory_allocated 29271.43798828125 
[2025-03-02 18:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.08358548581600189 norm:0.0002637435682117939 max memory_allocated 29271.43798828125 
[2025-03-02 18:13:43 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.08171934634447098 norm:0.0001911989093059674 max memory_allocated 29271.43798828125 
[2025-03-02 18:14:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.08065944910049438 norm:0.00015375996008515358 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.08025568723678589 norm:0.00013348099309951067 max memory_allocated 29271.43798828125 
[2025-03-02 18:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.080096535384655 norm:0.00011927568266401067 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.08000261336565018 norm:0.00011272264237049967 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.07993709295988083 norm:0.00011058929521823302 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.07992137968540192 norm:0.00010872945131268352 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.0798993706703186 norm:0.00010543619282543659 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.0798749178647995 norm:0.0001027960897772573 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.07986585050821304 norm:0.00010313414531992748 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.0798642560839653 norm:0.00010079255298478529 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.07983142882585526 norm:0.00010215877409791574 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.07982444763183594 norm:0.00010020086483564228 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.07980035990476608 norm:0.0001005432422971353 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.07980292290449142 norm:9.945900819730014e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.07981695234775543 norm:0.00010051155550172552 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.07982233911752701 norm:0.00010242834105156362 max memory_allocated 29271.43798828125 
[2025-03-02 18:27:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.0985708236694336 norm:0.0008974664378911257 max memory_allocated 29271.62548828125 
[2025-03-02 18:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.09458327293395996 norm:0.00040201115189120173 max memory_allocated 29271.62548828125 
[2025-03-02 18:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.09189248085021973 norm:0.00026345596415922046 max memory_allocated 29271.62548828125 
[2025-03-02 18:30:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.08982221782207489 norm:0.0001965019473573193 max memory_allocated 29271.62548828125 
[2025-03-02 18:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.08873487263917923 norm:0.0001633318024687469 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.08833766728639603 norm:0.0001411909470334649 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.08817187696695328 norm:0.00012829685874748975 max memory_allocated 29271.62548828125 
[2025-03-02 18:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.08810737729072571 norm:0.00012068558862665668 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.08801998198032379 norm:0.00011551880743354559 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.08795590698719025 norm:0.00011285057553322986 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.08791623264551163 norm:0.00010621831461321563 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.08788403868675232 norm:0.00010496393224457279 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.08785241842269897 norm:0.00010166353604290634 max memory_allocated 29271.62548828125 
[2025-03-02 18:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.08783283829689026 norm:9.977635636460036e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.087823286652565 norm:0.00010113457392435521 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.08782699704170227 norm:9.888578642858192e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.08780759572982788 norm:0.00010018629109254107 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.08778895437717438 norm:9.844575833994895e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.08776687830686569 norm:9.710549784358591e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:43:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.08777254074811935 norm:9.67574305832386e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:43:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.11067869514226913 norm:0.0012169332476332784 max memory_allocated 29271.81298828125 
[2025-03-02 18:45:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.10635969042778015 norm:0.0005821656668558717 max memory_allocated 29271.81298828125 
[2025-03-02 18:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.10349161177873611 norm:0.00038214088999666274 max memory_allocated 29271.81298828125 
[2025-03-02 18:47:10 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.10129838436841965 norm:0.0002756887406576425 max memory_allocated 29271.81298828125 
[2025-03-02 18:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.10011035948991776 norm:0.00021760104573331773 max memory_allocated 29271.81298828125 
[2025-03-02 18:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.09970643371343613 norm:0.00018227880354970694 max memory_allocated 29271.81298828125 
[2025-03-02 18:49:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.09951819479465485 norm:0.0001614612847333774 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.09943059831857681 norm:0.00014882443065289408 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.09935791790485382 norm:0.0001385659270454198 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.0992828905582428 norm:0.00013209371536504477 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.09923885017633438 norm:0.00012773441267199814 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.09920112788677216 norm:0.00012149771646363661 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.09918242692947388 norm:0.0001200881160912104 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.09916823357343674 norm:0.00011722715134965256 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.09917023777961731 norm:0.00011729731340892613 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.09914848953485489 norm:0.00011668572551570833 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.09915181994438171 norm:0.00011818962229881436 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.0991392433643341 norm:0.00011662561882985756 max memory_allocated 29271.81298828125 
[2025-03-02 18:59:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.0991324856877327 norm:0.00011498931417008862 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.09912147372961044 norm:0.00011573686060728505 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.12245409935712814 norm:0.0009548668749630451 max memory_allocated 29272.00048828125 
[2025-03-02 19:02:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.11917005479335785 norm:0.0005007619620300829 max memory_allocated 29272.00048828125 
[2025-03-02 19:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.11649070680141449 norm:0.00032407170510850847 max memory_allocated 29272.00048828125 
[2025-03-02 19:03:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.11424501985311508 norm:0.00023491433239541948 max memory_allocated 29272.00048828125 
[2025-03-02 19:04:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.11312799900770187 norm:0.00018515833653509617 max memory_allocated 29272.00048828125 
[2025-03-02 19:05:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.11280622333288193 norm:0.0001625486765988171 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.11265905946493149 norm:0.00014968906180001795 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.11256546527147293 norm:0.00014113642100710422 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.11249794065952301 norm:0.0001337202120339498 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.11247090995311737 norm:0.0001314899418503046 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.11246128380298615 norm:0.00013020097685512155 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.11242512613534927 norm:0.00013030233094468713 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.1123957559466362 norm:0.00012810129555873573 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.112367644906044 norm:0.0001300052390433848 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.11233355104923248 norm:0.00012680060171987861 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.11232151836156845 norm:0.0001269947679247707 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.11232117563486099 norm:0.00012597820023074746 max memory_allocated 29272.00048828125 
[2025-03-02 19:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.11232081055641174 norm:0.0001261883444385603 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.11232256889343262 norm:0.00012977744336239994 max memory_allocated 29272.00048828125 
[2025-03-02 19:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.1123298853635788 norm:0.0001273306697839871 max memory_allocated 29272.00048828125 
[2025-03-02 19:17:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:18:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.13847926259040833 norm:0.001123693655245006 max memory_allocated 29272.18798828125 
[2025-03-02 19:18:59 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.13504385948181152 norm:0.0005739250918850303 max memory_allocated 29272.18798828125 
[2025-03-02 19:19:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.13229946792125702 norm:0.0003702628891915083 max memory_allocated 29272.18798828125 
[2025-03-02 19:20:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.129826620221138 norm:0.00027456687530502677 max memory_allocated 29272.18798828125 
[2025-03-02 19:21:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.12867556512355804 norm:0.00022414712293539196 max memory_allocated 29272.18798828125 
[2025-03-02 19:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.12838077545166016 norm:0.00019249615434091538 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.1282547414302826 norm:0.00017571514763403684 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.12816102802753448 norm:0.00016360922018066049 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.12808610498905182 norm:0.00015772537153679878 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.12803590297698975 norm:0.00015496417472604662 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.1279863566160202 norm:0.00015105726197361946 max memory_allocated 29272.18798828125 
[2025-03-02 19:27:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.1279883235692978 norm:0.00014728467795066535 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.1279362589120865 norm:0.00014735606964677572 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.12793736159801483 norm:0.00014526743325404823 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.1279076635837555 norm:0.00014507098239846528 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.1278895139694214 norm:0.00014484708663076162 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:18 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.12790536880493164 norm:0.00014015780470799655 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.12787775695323944 norm:0.00014427573478315026 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.12788458168506622 norm:0.00014363798254635185 max memory_allocated 29272.18798828125 
[2025-03-02 19:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.1278965175151825 norm:0.0001437962637282908 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.15427327156066895 norm:0.0013732397928833961 max memory_allocated 29272.37548828125 
[2025-03-02 19:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.15122485160827637 norm:0.0007103342213667929 max memory_allocated 29272.37548828125 
[2025-03-02 19:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.14850085973739624 norm:0.0004545990959741175 max memory_allocated 29272.37548828125 
[2025-03-02 19:37:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.14589980244636536 norm:0.0003201448416803032 max memory_allocated 29272.37548828125 
[2025-03-02 19:38:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.14484407007694244 norm:0.0002457617374602705 max memory_allocated 29272.37548828125 
[2025-03-02 19:39:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.1445530503988266 norm:0.00020425717229954898 max memory_allocated 29272.37548828125 
[2025-03-02 19:39:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.14441514015197754 norm:0.00017411554290447384 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.14433906972408295 norm:0.00016317976405844092 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.14429044723510742 norm:0.00015314092161133885 max memory_allocated 29272.37548828125 
[2025-03-02 19:42:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.14424510300159454 norm:0.0001451045973226428 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.14419499039649963 norm:0.00014159647980704904 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.14416782557964325 norm:0.00013815176498610526 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.14414779841899872 norm:0.00014017277862876654 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.14414198696613312 norm:0.00013786049385089427 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.14413291215896606 norm:0.0001389406534144655 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.14411547780036926 norm:0.00013771059457212687 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.1441182792186737 norm:0.00013953805319033563 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.14409688115119934 norm:0.00013773758837487549 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.14407792687416077 norm:0.00013804443005938083 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.14407439529895782 norm:0.00013855466386303306 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.17372828722000122 norm:0.0009458372369408607 max memory_allocated 29272.56298828125 
[2025-03-02 19:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.17045333981513977 norm:0.0005064121214672923 max memory_allocated 29272.56298828125 
[2025-03-02 19:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.16737161576747894 norm:0.00034093239810317755 max memory_allocated 29272.56298828125 
[2025-03-02 19:54:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.1646522730588913 norm:0.00025672081392258406 max memory_allocated 29272.56298828125 
[2025-03-02 19:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.16365960240364075 norm:0.0002046048321062699 max memory_allocated 29272.56298828125 
[2025-03-02 19:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.16339105367660522 norm:0.00018304762488696724 max memory_allocated 29272.56298828125 
[2025-03-02 19:56:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.16321024298667908 norm:0.00016691583732608706 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.16311104595661163 norm:0.00016166199930012226 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:12 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.16300956904888153 norm:0.00015434285160154104 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.16294434666633606 norm:0.00014682981418445706 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.1629149615764618 norm:0.0001458730548620224 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.162872776389122 norm:0.00014073896454647183 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.16285279393196106 norm:0.00013748336641583592 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.16285234689712524 norm:0.00013901488273404539 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.1628764122724533 norm:0.00014120539708528668 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.16285167634487152 norm:0.00013768297503702343 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.16284355521202087 norm:0.0001404861977789551 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.16283251345157623 norm:0.00013821342145092785 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.16283433139324188 norm:0.00013853156997356564 max memory_allocated 29272.56298828125 
[2025-03-02 20:07:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.16282528638839722 norm:0.00013985738041810691 max memory_allocated 29272.56298828125 
[2025-03-02 20:07:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:08:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.19173146784305573 norm:0.0011058419477194548 max memory_allocated 29272.75048828125 
[2025-03-02 20:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.18889641761779785 norm:0.00048578763380646706 max memory_allocated 29272.75048828125 
[2025-03-02 20:10:00 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.18611764907836914 norm:0.00030493392841890454 max memory_allocated 29272.75048828125 
[2025-03-02 20:10:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.18337304890155792 norm:0.00022597250062972307 max memory_allocated 29272.75048828125 
[2025-03-02 20:11:38 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.1824289709329605 norm:0.00018329118029214442 max memory_allocated 29272.75048828125 
[2025-03-02 20:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.18217331171035767 norm:0.00016430055256932974 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.18208050727844238 norm:0.00015011698997113854 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.18200357258319855 norm:0.00014408925198949873 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.18195420503616333 norm:0.0001373613195028156 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.18190324306488037 norm:0.00013388325169216841 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.1818804144859314 norm:0.00013327194028533995 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.18184685707092285 norm:0.00013179521192796528 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.18184126913547516 norm:0.00013290536298882216 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.18183961510658264 norm:0.00013427548401523381 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.1818452924489975 norm:0.00013276496611069888 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.18182413280010223 norm:0.0001331699313595891 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.18181270360946655 norm:0.00013407593360170722 max memory_allocated 29272.75048828125 
[2025-03-02 20:22:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.1818055957555771 norm:0.00013245065929368138 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.18179476261138916 norm:0.00013258482795208693 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.1817907691001892 norm:0.00013150915037840605 max memory_allocated 29272.75048828125 
[2025-03-02 20:24:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:25:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.21476465463638306 norm:0.0008790846914052963 max memory_allocated 29272.93798828125 
[2025-03-02 20:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.21179988980293274 norm:0.0004546063137240708 max memory_allocated 29272.93798828125 
[2025-03-02 20:26:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.20878484845161438 norm:0.0003121636400464922 max memory_allocated 29272.93798828125 
[2025-03-02 20:27:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.20581984519958496 norm:0.00024063260934781283 max memory_allocated 29272.93798828125 
[2025-03-02 20:28:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.20485709607601166 norm:0.000202208713744767 max memory_allocated 29272.93798828125 
[2025-03-02 20:29:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.20457786321640015 norm:0.00018216148600913584 max memory_allocated 29272.93798828125 
[2025-03-02 20:30:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.20439621806144714 norm:0.00017187072080560029 max memory_allocated 29272.93798828125 
[2025-03-02 20:30:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.20429620146751404 norm:0.00016254698857665062 max memory_allocated 29272.93798828125 
[2025-03-02 20:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.20422276854515076 norm:0.00015543025801889598 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.20416885614395142 norm:0.00015212073049042374 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.20411349833011627 norm:0.0001500927028246224 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.2040562629699707 norm:0.00014668784569948912 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.20405152440071106 norm:0.00014942584675736725 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.20403262972831726 norm:0.00014778212062083185 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.20403890311717987 norm:0.00015148200327530503 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.20403939485549927 norm:0.00014923563867341727 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.20403708517551422 norm:0.00014962704153731465 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.2040427029132843 norm:0.0001509931025793776 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.20404717326164246 norm:0.00015364591672550887 max memory_allocated 29272.93798828125 
[2025-03-02 20:40:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.2040524184703827 norm:0.00015135554713197052 max memory_allocated 29272.93798828125 
[2025-03-02 20:40:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.23970922827720642 norm:0.0012954684207215905 max memory_allocated 29273.12548828125 
[2025-03-02 20:42:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.235289067029953 norm:0.0005824738764204085 max memory_allocated 29273.12548828125 
[2025-03-02 20:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.23198126256465912 norm:0.0004578310181386769 max memory_allocated 29273.12548828125 
[2025-03-02 20:44:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.22878913581371307 norm:0.0003445023321546614 max memory_allocated 29273.12548828125 
[2025-03-02 20:45:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.22783270478248596 norm:0.00031300541013479233 max memory_allocated 29273.12548828125 
[2025-03-02 20:45:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.22753773629665375 norm:0.00029448283021338284 max memory_allocated 29273.12548828125 
[2025-03-02 20:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.22730916738510132 norm:0.0002646912762429565 max memory_allocated 29273.12548828125 
[2025-03-02 20:47:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.22724829614162445 norm:0.0002627285139169544 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.22715717554092407 norm:0.00026498062652535737 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.22714580595493317 norm:0.00028182737878523767 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.22710876166820526 norm:0.0003543173079378903 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.2270439714193344 norm:0.0003582107601687312 max memory_allocated 29273.12548828125 
[2025-03-02 20:51:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.2270054668188095 norm:0.000289456540485844 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:31 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.2269761562347412 norm:0.00027289948775433004 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.22694748640060425 norm:0.00023782308562658727 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.22692781686782837 norm:0.00022619585797656327 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.22691726684570312 norm:0.00024234919692389667 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.2268964946269989 norm:0.0002259106549900025 max memory_allocated 29273.12548828125 
[2025-03-02 20:56:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.22689318656921387 norm:0.00022729457123205066 max memory_allocated 29273.12548828125 
[2025-03-02 20:57:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.2269250452518463 norm:0.00027019844856113195 max memory_allocated 29273.12548828125 
[2025-03-02 20:57:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 20:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.26101428270339966 norm:0.0016335282707586884 max memory_allocated 29273.31298828125 
[2025-03-02 20:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.2578844428062439 norm:0.0008471031906083226 max memory_allocated 29273.31298828125 
[2025-03-02 21:00:13 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.25447213649749756 norm:0.0005228071822784841 max memory_allocated 29273.31298828125 
[2025-03-02 21:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.2513284683227539 norm:0.00035802728962153196 max memory_allocated 29273.31298828125 
[2025-03-02 21:01:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.250478595495224 norm:0.000272858829703182 max memory_allocated 29273.31298828125 
[2025-03-02 21:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.2502419352531433 norm:0.00022814988915342838 max memory_allocated 29273.31298828125 
[2025-03-02 21:03:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.2501242160797119 norm:0.00019951898138970137 max memory_allocated 29273.31298828125 
[2025-03-02 21:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.2500544488430023 norm:0.00018024150631390512 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.2500181496143341 norm:0.00016848728409968317 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.2499823272228241 norm:0.00015896421973593533 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.2499614953994751 norm:0.00015654736489523202 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.24992090463638306 norm:0.0001532120950287208 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.24990656971931458 norm:0.00015183976211119443 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.24989154934883118 norm:0.00015097585855983198 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.24986858665943146 norm:0.0001497145276516676 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.24988996982574463 norm:0.0001497310004197061 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.24987377226352692 norm:0.00015108025399968028 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:32 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.24988022446632385 norm:0.00015165277000050992 max memory_allocated 29273.31298828125 
[2025-03-02 21:13:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.24987997114658356 norm:0.0001478583726566285 max memory_allocated 29273.31298828125 
[2025-03-02 21:14:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.24986694753170013 norm:0.00014871529128868133 max memory_allocated 29273.31298828125 
[2025-03-02 21:14:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:15:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.2890942394733429 norm:0.0015603239880874753 max memory_allocated 29273.50048828125 
[2025-03-02 21:16:08 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.28541824221611023 norm:0.0007939153583720326 max memory_allocated 29273.50048828125 
[2025-03-02 21:16:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.28150689601898193 norm:0.0004944190150126815 max memory_allocated 29273.50048828125 
[2025-03-02 21:17:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.27818241715431213 norm:0.0003492202376946807 max memory_allocated 29273.50048828125 
[2025-03-02 21:18:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.27735042572021484 norm:0.0002784737735055387 max memory_allocated 29273.50048828125 
[2025-03-02 21:19:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.27708765864372253 norm:0.00023650187358725816 max memory_allocated 29273.50048828125 
[2025-03-02 21:20:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.27691876888275146 norm:0.00021429365733638406 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.2768114507198334 norm:0.00021028010814916342 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.276705265045166 norm:0.00020597837283276021 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:42 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.27661749720573425 norm:0.00018224478117190301 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.276561439037323 norm:0.00017803006630856544 max memory_allocated 29273.50048828125 
[2025-03-02 21:24:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.27654045820236206 norm:0.0001781789178494364 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.276498943567276 norm:0.00017443679098505527 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.2765074074268341 norm:0.00017542880959808826 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.2764936089515686 norm:0.0001730955409584567 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.2764630913734436 norm:0.00017143614240922034 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.2764696776866913 norm:0.00017408968415111303 max memory_allocated 29273.50048828125 
[2025-03-02 21:29:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.27646464109420776 norm:0.00017848832067102194 max memory_allocated 29273.50048828125 
[2025-03-02 21:30:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.27646100521087646 norm:0.0001768275978974998 max memory_allocated 29273.50048828125 
[2025-03-02 21:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.2764548063278198 norm:0.00017936364747583866 max memory_allocated 29273.50048828125 
[2025-03-02 21:31:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:32:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.31733179092407227 norm:0.0018397500971332192 max memory_allocated 29273.68798828125 
[2025-03-02 21:32:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.31333574652671814 norm:0.0008868859149515629 max memory_allocated 29273.68798828125 
[2025-03-02 21:33:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.3089888095855713 norm:0.0005364945391193032 max memory_allocated 29273.68798828125 
[2025-03-02 21:34:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.3055345118045807 norm:0.0003649746358860284 max memory_allocated 29273.68798828125 
[2025-03-02 21:35:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.304734468460083 norm:0.00028425504569895566 max memory_allocated 29273.68798828125 
[2025-03-02 21:36:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.3044958710670471 norm:0.0002393269242020324 max memory_allocated 29273.68798828125 
[2025-03-02 21:36:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.30439329147338867 norm:0.00021802719857078046 max memory_allocated 29273.68798828125 
[2025-03-02 21:37:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.304309606552124 norm:0.00020137097453698516 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.3042216897010803 norm:0.00018655667372513562 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.30416232347488403 norm:0.00018108812218997627 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.3041398823261261 norm:0.00017984918667934835 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.3041398525238037 norm:0.00017656442651059479 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.3041207790374756 norm:0.0001791589893400669 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.3040916621685028 norm:0.00017312058480456471 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.3041304051876068 norm:0.00017578421102371067 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.3041200339794159 norm:0.00017892142932396382 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.3040873408317566 norm:0.00018022158474195749 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.30404531955718994 norm:0.00017958595708478242 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.30405157804489136 norm:0.00017745603690855205 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.3040506839752197 norm:0.00018139113672077656 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.34446796774864197 norm:0.0022455728612840176 max memory_allocated 29273.87548828125 
[2025-03-02 21:49:36 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.3409620523452759 norm:0.0011325064115226269 max memory_allocated 29273.87548828125 
[2025-03-02 21:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.3368200957775116 norm:0.0006891638622619212 max memory_allocated 29273.87548828125 
[2025-03-02 21:51:14 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.33351635932922363 norm:0.0004654609365388751 max memory_allocated 29273.87548828125 
[2025-03-02 21:52:03 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.33279797434806824 norm:0.000353456474840641 max memory_allocated 29273.87548828125 
[2025-03-02 21:52:53 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.3325382471084595 norm:0.0002888931194320321 max memory_allocated 29273.87548828125 
[2025-03-02 21:53:42 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.33237195014953613 norm:0.00025398016441613436 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:31 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.3322778344154358 norm:0.000225588126340881 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.33221566677093506 norm:0.00020637571287807077 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:10 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.3321363031864166 norm:0.00019724408048205078 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.33210399746894836 norm:0.00019097272888757288 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:48 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.3320712149143219 norm:0.00018579534662421793 max memory_allocated 29273.87548828125 
[2025-03-02 21:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.33207443356513977 norm:0.00018238576012663543 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:27 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.3320685625076294 norm:0.00018240070494357497 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:16 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.33207157254219055 norm:0.00018194649601355195 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:06 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.3320624530315399 norm:0.0001788290246622637 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:55 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.3320682644844055 norm:0.00017743848729878664 max memory_allocated 29273.87548828125 
[2025-03-02 22:02:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.3320520520210266 norm:0.00017594773089513183 max memory_allocated 29273.87548828125 
[2025-03-02 22:03:34 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.33203333616256714 norm:0.00017610355280339718 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.33202698826789856 norm:0.0001752725220285356 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:05:30 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.38046973943710327 norm:0.0012838136171922088 max memory_allocated 29274.06298828125 
[2025-03-02 22:06:20 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.37601128220558167 norm:0.0006945462664589286 max memory_allocated 29274.06298828125 
[2025-03-02 22:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.37099945545196533 norm:0.0004654850345104933 max memory_allocated 29274.06298828125 
[2025-03-02 22:07:58 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.36748576164245605 norm:0.00033852719934657216 max memory_allocated 29274.06298828125 
[2025-03-02 22:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.36669713258743286 norm:0.0002890654723159969 max memory_allocated 29274.06298828125 
[2025-03-02 22:09:37 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.3664105534553528 norm:0.0002606554189696908 max memory_allocated 29274.06298828125 
[2025-03-02 22:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.3662067949771881 norm:0.0002358047349844128 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.3660825192928314 norm:0.00022401072783395648 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.3660028576850891 norm:0.00021994279813952744 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.3659471273422241 norm:0.00022015975264366716 max memory_allocated 29274.06298828125 
[2025-03-02 22:13:43 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.36589741706848145 norm:0.000218511326238513 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.36586081981658936 norm:0.0002237666049040854 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:22 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.3658483028411865 norm:0.0002267298987135291 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.3657892942428589 norm:0.0002214288106188178 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.36575984954833984 norm:0.0002202345640398562 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.3657345473766327 norm:0.00021600283798761666 max memory_allocated 29274.06298828125 
[2025-03-02 22:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.36576324701309204 norm:0.00022352230735123158 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.3657650947570801 norm:0.0002185818593716249 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.3657979369163513 norm:0.00021732362802140415 max memory_allocated 29274.06298828125 
[2025-03-02 22:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.36585700511932373 norm:0.00021948089124634862 max memory_allocated 29274.06298828125 
[2025-03-02 22:21:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:22:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.4221407473087311 norm:0.0016950767021626234 max memory_allocated 29274.25048828125 
[2025-03-02 22:23:04 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.4167921543121338 norm:0.0008581981528550386 max memory_allocated 29274.25048828125 
[2025-03-02 22:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.41091668605804443 norm:0.0005522356368601322 max memory_allocated 29274.25048828125 
[2025-03-02 22:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.4072877764701843 norm:0.0004021704662591219 max memory_allocated 29274.25048828125 
[2025-03-02 22:25:32 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.4064945578575134 norm:0.000328965688822791 max memory_allocated 29274.25048828125 
[2025-03-02 22:26:21 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.406158983707428 norm:0.0002959572011604905 max memory_allocated 29274.25048828125 
[2025-03-02 22:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.4059813618659973 norm:0.00027081096777692437 max memory_allocated 29274.25048828125 
[2025-03-02 22:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.40585440397262573 norm:0.0002503786818124354 max memory_allocated 29274.25048828125 
[2025-03-02 22:28:49 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.40576139092445374 norm:0.00024238126934506 max memory_allocated 29274.25048828125 
[2025-03-02 22:29:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.40567415952682495 norm:0.0002339593629585579 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.40560922026634216 norm:0.0002282783534610644 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.4055469334125519 norm:0.00022634273045696318 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:06 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.4055069088935852 norm:0.00023120913829188794 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:55 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.4054938554763794 norm:0.00022539656492881477 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:45 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.40551552176475525 norm:0.00022513388830702752 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.4055376648902893 norm:0.0002281956549268216 max memory_allocated 29274.25048828125 
[2025-03-02 22:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.4055321216583252 norm:0.00022393463586922735 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.4055290222167969 norm:0.0002295986341778189 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.4055245816707611 norm:0.00022709085897076875 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:51 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.405534952878952 norm:0.00022648979211226106 max memory_allocated 29274.25048828125 
[2025-03-02 22:38:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.465949684381485 norm:0.003130972618237138 max memory_allocated 29274.43798828125 
[2025-03-02 22:39:48 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.4594974219799042 norm:0.0016706790775060654 max memory_allocated 29274.43798828125 
[2025-03-02 22:40:37 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.452735960483551 norm:0.0010407258523628116 max memory_allocated 29274.43798828125 
[2025-03-02 22:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.4491550624370575 norm:0.0007181443506851792 max memory_allocated 29274.43798828125 
[2025-03-02 22:42:16 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.4482097625732422 norm:0.0005481152329593897 max memory_allocated 29274.43798828125 
[2025-03-02 22:43:05 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.4476545751094818 norm:0.0004576772917062044 max memory_allocated 29274.43798828125 
[2025-03-02 22:43:54 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.4473402798175812 norm:0.00040011771488934755 max memory_allocated 29274.43798828125 
[2025-03-02 22:44:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.4471478760242462 norm:0.0003606777754612267 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:33 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.44696396589279175 norm:0.00033344750409014523 max memory_allocated 29274.43798828125 
[2025-03-02 22:46:22 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.44683900475502014 norm:0.000321711617289111 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.44670483469963074 norm:0.000305508088786155 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:01 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.4466024935245514 norm:0.00030628283275291324 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.4465213716030121 norm:0.0002984778257086873 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.44646745920181274 norm:0.00029750782414339483 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.4465288519859314 norm:0.00028692674823105335 max memory_allocated 29274.43798828125 
[2025-03-02 22:51:18 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.44662904739379883 norm:0.00028294441290199757 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:07 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.44659876823425293 norm:0.0002860527310986072 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.4465932250022888 norm:0.00027707841945812106 max memory_allocated 29274.43798828125 
[2025-03-02 22:53:46 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.4465794563293457 norm:0.0002775170432869345 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.446616530418396 norm:0.00027695990866050124 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 22:54:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 22:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.5130224227905273 norm:0.008676130324602127 max memory_allocated 29274.77001953125 
[2025-03-02 22:56:32 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.5066302418708801 norm:0.0071946484968066216 max memory_allocated 29274.77001953125 
[2025-03-02 22:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.4994775056838989 norm:0.0056801591999828815 max memory_allocated 29274.77001953125 
[2025-03-02 22:58:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.49581876397132874 norm:0.004578958265483379 max memory_allocated 29274.77001953125 
[2025-03-02 22:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.494762122631073 norm:0.003767439629882574 max memory_allocated 29274.77001953125 
[2025-03-02 22:59:49 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.49407118558883667 norm:0.003235549433156848 max memory_allocated 29274.77001953125 
[2025-03-02 23:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.49367406964302063 norm:0.0029211014043539762 max memory_allocated 29274.77001953125 
[2025-03-02 23:01:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.4935179650783539 norm:0.0027827643789350986 max memory_allocated 29274.77001953125 
[2025-03-02 23:02:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.49337050318717957 norm:0.002707980340346694 max memory_allocated 29274.77001953125 
[2025-03-02 23:03:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.49332961440086365 norm:0.002828999189659953 max memory_allocated 29274.77001953125 
[2025-03-02 23:03:57 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.4931913912296295 norm:0.002810436300933361 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.49296432733535767 norm:0.002659267047420144 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:36 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.4927842319011688 norm:0.002609128598123789 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.49263858795166016 norm:0.002480500377714634 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:15 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.4924224317073822 norm:0.0024445494636893272 max memory_allocated 29274.77001953125 
[2025-03-02 23:08:04 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.49242275953292847 norm:0.002320163417607546 max memory_allocated 29274.77001953125 
[2025-03-02 23:08:53 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.49239739775657654 norm:0.002356480108574033 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.4923681318759918 norm:0.0022152503952383995 max memory_allocated 29274.77001953125 
[2025-03-02 23:10:32 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.4923252761363983 norm:0.002309297677129507 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.492373526096344 norm:0.0022082009818404913 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:11:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:12:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.5858927965164185 norm:0.01279706321656704 max memory_allocated 29274.95751953125 
[2025-03-02 23:13:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.5752750635147095 norm:0.008763834834098816 max memory_allocated 29274.95751953125 
[2025-03-02 23:14:08 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.5634676814079285 norm:0.00785750150680542 max memory_allocated 29274.95751953125 
[2025-03-02 23:14:58 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.5582501888275146 norm:0.007363088428974152 max memory_allocated 29274.95751953125 
[2025-03-02 23:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.5567589402198792 norm:0.007197082508355379 max memory_allocated 29274.95751953125 
[2025-03-02 23:16:36 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.5561437010765076 norm:0.006606548558920622 max memory_allocated 29274.95751953125 
[2025-03-02 23:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.5557074546813965 norm:0.006872929632663727 max memory_allocated 29274.95751953125 
[2025-03-02 23:18:15 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.5552931427955627 norm:0.006542862392961979 max memory_allocated 29274.95751953125 
[2025-03-02 23:19:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.5549068450927734 norm:0.00616712961345911 max memory_allocated 29274.95751953125 
[2025-03-02 23:19:54 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.5546149611473083 norm:0.005931264255195856 max memory_allocated 29274.95751953125 
[2025-03-02 23:20:44 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.5543596744537354 norm:0.005576814524829388 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.5543286800384521 norm:0.00555843161419034 max memory_allocated 29274.95751953125 
[2025-03-02 23:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.5541561245918274 norm:0.005397062283009291 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.5540475845336914 norm:0.0052145300433039665 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:01 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.553955078125 norm:0.005045158788561821 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:51 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.5538805723190308 norm:0.005094738677144051 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:40 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.553725004196167 norm:0.00477022398263216 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:30 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.5537877678871155 norm:0.004607458133250475 max memory_allocated 29274.95751953125 
[2025-03-02 23:27:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.5537891387939453 norm:0.00460397033020854 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.5537798404693604 norm:0.004598455503582954 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:28:27 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:29:16 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.8193753957748413 norm:0.04043591022491455 max memory_allocated 29275.14501953125 
[2025-03-02 23:30:06 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.7744829058647156 norm:0.02959843911230564 max memory_allocated 29275.14501953125 
[2025-03-02 23:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.7414820194244385 norm:0.022433049976825714 max memory_allocated 29275.14501953125 
[2025-03-02 23:31:44 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.7239571213722229 norm:0.019295889884233475 max memory_allocated 29275.14501953125 
[2025-03-02 23:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.7159459590911865 norm:0.017061002552509308 max memory_allocated 29275.14501953125 
[2025-03-02 23:33:23 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.7113704085350037 norm:0.015269564464688301 max memory_allocated 29275.14501953125 
[2025-03-02 23:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.7082669138908386 norm:0.014208381064236164 max memory_allocated 29275.14501953125 
[2025-03-02 23:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.7062868475914001 norm:0.013364146463572979 max memory_allocated 29275.14501953125 
[2025-03-02 23:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.7040822505950928 norm:0.012985930778086185 max memory_allocated 29275.14501953125 
[2025-03-02 23:36:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.7025033831596375 norm:0.012318026274442673 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.7013802528381348 norm:0.011597047559916973 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.7003411054611206 norm:0.011681962758302689 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.6995073556900024 norm:0.011340933851897717 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:58 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.6991038918495178 norm:0.010657122358679771 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:48 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.6986843347549438 norm:0.010480587370693684 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:37 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.6975857019424438 norm:0.00999059434980154 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:26 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.6974582672119141 norm:0.00971493311226368 max memory_allocated 29275.14501953125 
[2025-03-02 23:43:16 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.6972404718399048 norm:0.009419865906238556 max memory_allocated 29275.14501953125 
[2025-03-02 23:44:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.6971601247787476 norm:0.009757410734891891 max memory_allocated 29275.14501953125 
[2025-03-02 23:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.6973492503166199 norm:0.009588733315467834 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:45:13 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:1.2868311405181885 norm:0.0588119700551033 max memory_allocated 29275.33251953125 
[2025-03-02 23:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:1.2218390703201294 norm:0.04032465070486069 max memory_allocated 29275.33251953125 
[2025-03-02 23:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:1.1861628293991089 norm:0.0327564962208271 max memory_allocated 29275.33251953125 
[2025-03-02 23:48:30 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:1.1657687425613403 norm:0.03024032711982727 max memory_allocated 29275.33251953125 
[2025-03-02 23:49:19 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:1.1519155502319336 norm:0.031316112726926804 max memory_allocated 29275.33251953125 
[2025-03-02 23:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:1.1467987298965454 norm:0.03356771916151047 max memory_allocated 29275.33251953125 
[2025-03-02 23:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:1.1416350603103638 norm:0.031623415648937225 max memory_allocated 29275.33251953125 
[2025-03-02 23:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:1.1364068984985352 norm:0.030266255140304565 max memory_allocated 29275.33251953125 
[2025-03-02 23:52:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:1.1334444284439087 norm:0.028737660497426987 max memory_allocated 29275.33251953125 
[2025-03-02 23:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:1.1312451362609863 norm:0.027743466198444366 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:1.127535343170166 norm:0.02546500228345394 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:1.125326156616211 norm:0.026480797678232193 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:1.1248128414154053 norm:0.027267180383205414 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:1.123026967048645 norm:0.02630946785211563 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:1.1230717897415161 norm:0.027829639613628387 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:1.1216884851455688 norm:0.0254371277987957 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:1.1195658445358276 norm:0.027303921058773994 max memory_allocated 29275.33251953125 
[2025-03-03 00:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:1.1207475662231445 norm:0.027301639318466187 max memory_allocated 29275.33251953125 
[2025-03-03 00:00:52 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:1.12017023563385 norm:0.028754495084285736 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:1.120640516281128 norm:0.02755059115588665 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:55 root] (main_calib_config2.py 372): INFO 40165.232471227646
[2025-03-03 00:02:05 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:04:01 root] (main_calib_config2.py 159): INFO wikitext2 : 5.244112014770508
[2025-03-03 00:04:01 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:07:00 root] (main_calib_config2.py 159): INFO c4 : 6.809186935424805
