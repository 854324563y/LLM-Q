[2025-03-02 03:28:16 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.4', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.4.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 03:30:43 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-02 03:30:43 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.4.pkl
[2025-03-02 03:30:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 03:30:51 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.02673458121716976 norm:0.02244323119521141 max memory_allocated 22559.10693359375 
[2025-03-02 03:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.014227859675884247 norm:0.009200572036206722 max memory_allocated 22559.10693359375 
[2025-03-02 03:32:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.009924205020070076 norm:0.005894805304706097 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.008294792845845222 norm:0.00488684605807066 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.007741672918200493 norm:0.004158018622547388 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0074160839430987835 norm:0.0035039042122662067 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.007169905584305525 norm:0.0030166683718562126 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.006965122185647488 norm:0.0026226991321891546 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.006854823790490627 norm:0.0024140479508787394 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.006793462671339512 norm:0.0021495630498975515 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:59 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0067194923758506775 norm:0.0019436803413555026 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0066490755416452885 norm:0.001761586987413466 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.00663452222943306 norm:0.0016175310593098402 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.00658761989325285 norm:0.0014561276184394956 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.006571522913873196 norm:0.0013693805085495114 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.006493350490927696 norm:0.0012471935478970408 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.006523739546537399 norm:0.0012083991896361113 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.006524090655148029 norm:0.0011674279812723398 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.006495742592960596 norm:0.0011416035704314709 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:01 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.006524828262627125 norm:0.00122766790445894 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 03:42:13 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:42:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.07351255416870117 norm:0.023947829380631447 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.05787995830178261 norm:0.015764977782964706 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.05080460384488106 norm:0.010370457544922829 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.04799460619688034 norm:0.008560162037611008 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.046640727669000626 norm:0.007448314223438501 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:34 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.0457119382917881 norm:0.006329728290438652 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.045041169971227646 norm:0.005321711301803589 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.04455241560935974 norm:0.004496322013437748 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:15 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.04414606839418411 norm:0.0038891187869012356 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.04376533254981041 norm:0.0034035330172628164 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.04363571107387543 norm:0.0032001228537410498 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.04347147420048714 norm:0.003148839343339205 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.043414197862148285 norm:0.0029875938780605793 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.04340510442852974 norm:0.003084323601797223 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.04322035610675812 norm:0.0029079532250761986 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.04324857145547867 norm:0.0028841590974479914 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.04310554638504982 norm:0.002743325661867857 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.04309459775686264 norm:0.002699453616514802 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.04302166402339935 norm:0.0026220816653221846 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.04305431619286537 norm:0.002731754444539547 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 03:53:35 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:54:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.15321171283721924 norm:0.029020745307207108 max memory_allocated 22559.45068359375 
[2025-03-02 03:54:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.1278151273727417 norm:0.022933604195713997 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.11659213900566101 norm:0.01566978730261326 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.11164644360542297 norm:0.014281269162893295 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.10892096161842346 norm:0.013722811825573444 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.10730776935815811 norm:0.013519329950213432 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:30 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.10565026104450226 norm:0.012739398516714573 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.10455791652202606 norm:0.011931822635233402 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.1047239750623703 norm:0.011490325443446636 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.10471893101930618 norm:0.01065962016582489 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.10428223758935928 norm:0.010600018315017223 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.10330282151699066 norm:0.010154700838029385 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.10328558087348938 norm:0.00996408425271511 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.10261322557926178 norm:0.009742522612214088 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.10287681221961975 norm:0.009793265722692013 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.10246817022562027 norm:0.010088915005326271 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.10215353220701218 norm:0.009599810466170311 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.10192140936851501 norm:0.009563155472278595 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.10205918550491333 norm:0.00936204381287098 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.10202041268348694 norm:0.009382324293255806 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.1139831393957138 norm:0.01244262419641018 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.09203950315713882 norm:0.004349826835095882 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.08155487477779388 norm:0.0023499426897615194 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.07776223868131638 norm:0.0014907113509252667 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.07576897740364075 norm:0.0009395214729011059 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.07478293031454086 norm:0.0006663149106316268 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.07433529198169708 norm:0.0005885748541913927 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.0740649551153183 norm:0.0005071653868071735 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:59 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.07385595142841339 norm:0.0004478619957808405 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.07372082769870758 norm:0.0004074960888829082 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.07360386848449707 norm:0.0003872434899676591 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.07350780814886093 norm:0.0003744704299606383 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.0734739750623703 norm:0.0003669781144708395 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.07343289256095886 norm:0.0003610718995332718 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.07337359338998795 norm:0.0003537823213264346 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.0733252540230751 norm:0.0003523611812852323 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.07328670471906662 norm:0.00034844406764023006 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.07327276468276978 norm:0.000349618581822142 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.07327195256948471 norm:0.0003473303804639727 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.07326982915401459 norm:0.00034471164690330625 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 04:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.15947997570037842 norm:0.026379050686955452 max memory_allocated 22559.67919921875 
[2025-03-02 04:17:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.12176035344600677 norm:0.008588645607233047 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.09856917709112167 norm:0.003938260488212109 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.08900363743305206 norm:0.0015960659366101027 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.08604142814874649 norm:0.0012181743513792753 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.08455288410186768 norm:0.0010232271160930395 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.08383702486753464 norm:0.0009212089935317636 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.08361344039440155 norm:0.0009748699376359582 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.08323872834444046 norm:0.0008654585108160973 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.08291088789701462 norm:0.0007743084570392966 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.082620769739151 norm:0.0007454450824297965 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.08250263333320618 norm:0.0006865073810331523 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.08250720798969269 norm:0.0007047786493785679 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.08265076577663422 norm:0.0006947608781047165 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.08259926736354828 norm:0.000644453102722764 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.08247087150812149 norm:0.000562645960599184 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.08275848627090454 norm:0.0006282074609771371 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.08274586498737335 norm:0.0005822047241963446 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:56 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.08297549188137054 norm:0.0005892049521207809 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.08270689100027084 norm:0.0005817878409288824 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 04:28:16 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.13658592104911804 norm:0.01256223302334547 max memory_allocated 22559.85107421875 
[2025-03-02 04:28:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.11134015023708344 norm:0.004533377476036549 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.09737345576286316 norm:0.0020716567523777485 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.0924709290266037 norm:0.0013254752848297358 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.08988582342863083 norm:0.0009262686362490058 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.08849430084228516 norm:0.0007639682735316455 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:37 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.08789485692977905 norm:0.0006569400429725647 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.08755509555339813 norm:0.0005994114326313138 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.08738118410110474 norm:0.0005566158215515316 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:17 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.08723695576190948 norm:0.0005379533977247775 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.08714760839939117 norm:0.0005300372722558677 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.08724400401115417 norm:0.0005071937921456993 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.08718664944171906 norm:0.0005028582527302206 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.08728770911693573 norm:0.00048250029794871807 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.08724115043878555 norm:0.0004677091201301664 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.08726215362548828 norm:0.0004694294184446335 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.08747678995132446 norm:0.0004489002749323845 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.08749367296695709 norm:0.00043576714233495295 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.08757443726062775 norm:0.00043951565749011934 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.08770865201950073 norm:0.00044386793160811067 max memory_allocated 22559.85107421875 
[2025-03-02 04:39:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 04:39:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.1414109319448471 norm:0.016042161732912064 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.11750731617212296 norm:0.004650222137570381 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.10404296219348907 norm:0.0014024145202711225 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.09944404661655426 norm:0.000951470690779388 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.09725610166788101 norm:0.0007212581695057452 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:27 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.09608124196529388 norm:0.0006243468378670514 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.09552443027496338 norm:0.0005614512483589351 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.09514504671096802 norm:0.0005378919886425138 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.0950143039226532 norm:0.0005040158284828067 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.09493115544319153 norm:0.00047923732199706137 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.0948745533823967 norm:0.0004911322030238807 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.09475363045930862 norm:0.0004850226396229118 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.09478984773159027 norm:0.0004726565966848284 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.09468679130077362 norm:0.00045459470129571855 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.09467947483062744 norm:0.0004281530564185232 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.09473595768213272 norm:0.00042559506255201995 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.09474910795688629 norm:0.0004343735345173627 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.09472651034593582 norm:0.0004188252496533096 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.09468904882669449 norm:0.0004093314055353403 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.09470603615045547 norm:0.00041572769987396896 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 04:51:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.15021373331546783 norm:0.009103288874030113 max memory_allocated 22560.19482421875 
[2025-03-02 04:51:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.12730757892131805 norm:0.0030729908030480146 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.11216548085212708 norm:0.0013574836775660515 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.10766233503818512 norm:0.0009395373053848743 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:17 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.10540857166051865 norm:0.0007157521322369576 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.10424602031707764 norm:0.0006408815388567746 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.10357339680194855 norm:0.0005470023024827242 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.10321452468633652 norm:0.0004813777923118323 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.10295955836772919 norm:0.00047127861762419343 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.10281485319137573 norm:0.00043583172373473644 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.10266707837581635 norm:0.0004201473784632981 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.10264844447374344 norm:0.00040854336111806333 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.10265856236219406 norm:0.00041180229163728654 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.1025955080986023 norm:0.00040733630885370076 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.10262331366539001 norm:0.0003960639296565205 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.10270153731107712 norm:0.000390050612622872 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.10277286171913147 norm:0.00039594434201717377 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.10282483696937561 norm:0.00038035871693864465 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.10286340862512589 norm:0.00038758551818318665 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.10291306674480438 norm:0.0003859551507048309 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:02:25 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.1550779789686203 norm:0.0061060581356287 max memory_allocated 22560.36669921875 
[2025-03-02 05:02:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.13175402581691742 norm:0.0021858986001461744 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:32 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.11762578040361404 norm:0.000852076627779752 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.11321333050727844 norm:0.0005933194770477712 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.11102251708507538 norm:0.00046033941907808185 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.1098465770483017 norm:0.00041082387906499207 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.10917661339044571 norm:0.00038555479841306806 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.10884558409452438 norm:0.00036921328864991665 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.10863588750362396 norm:0.0003543535422068089 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.10854902863502502 norm:0.00036210351390764117 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.10837137699127197 norm:0.000356621399987489 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.10827429592609406 norm:0.0003462242893874645 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.10824409127235413 norm:0.0003417506522964686 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.10819791257381439 norm:0.0003394567465875298 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.10818590968847275 norm:0.00033927834010683 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.1081840917468071 norm:0.00033270701533183455 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.10818970948457718 norm:0.00034439374576322734 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.10821259021759033 norm:0.000343390362104401 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.10822015255689621 norm:0.0003410484059713781 max memory_allocated 22560.36669921875 
[2025-03-02 05:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.10826995968818665 norm:0.00034080087789334357 max memory_allocated 22560.36669921875 
[2025-03-02 05:13:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 05:13:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.16338998079299927 norm:0.006956840865314007 max memory_allocated 22560.53857421875 
[2025-03-02 05:14:22 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.13984738290309906 norm:0.002561460714787245 max memory_allocated 22560.53857421875 
[2025-03-02 05:14:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.12457863241434097 norm:0.0010427847737446427 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.11976988613605499 norm:0.0006827815668657422 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.11779682338237762 norm:0.000515260617248714 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.11649644374847412 norm:0.0004303022287786007 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.11580623686313629 norm:0.0003837559197563678 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.11541422456502914 norm:0.00036786432610824704 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.11519743502140045 norm:0.0003557975869625807 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.11505597084760666 norm:0.0003398148692212999 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.11492922157049179 norm:0.00032296573044732213 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.11485464125871658 norm:0.00030834542121738195 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.11479935050010681 norm:0.00030420703114941716 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.11480113863945007 norm:0.00030760178924538195 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.11477412283420563 norm:0.0003030048683285713 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.1147938221693039 norm:0.0003009056963492185 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.11472515761852264 norm:0.0002977445547003299 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.11468632519245148 norm:0.0002918595855589956 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.11474098265171051 norm:0.0002916229423135519 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.11472325772047043 norm:0.0002879539388231933 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 05:25:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.15516316890716553 norm:0.00437835743650794 max memory_allocated 22560.71044921875 
[2025-03-02 05:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.1391124576330185 norm:0.0017358682816848159 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.1281335949897766 norm:0.0007627321756444871 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.12406358122825623 norm:0.0004966423148289323 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.12235866487026215 norm:0.0003971323021687567 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.12147510796785355 norm:0.00035223388113081455 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.12106794118881226 norm:0.0003263089165557176 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.12090208381414413 norm:0.0003136246232315898 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.12074944376945496 norm:0.0002956282696686685 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.12064025551080704 norm:0.00028911919798702 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.12060445547103882 norm:0.0002854697813745588 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.12057303637266159 norm:0.0002770288847386837 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.12053779512643814 norm:0.00027329527074471116 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.12049884349107742 norm:0.00026759455795399845 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.12043583393096924 norm:0.00026737124426290393 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.12042076885700226 norm:0.0002663306368049234 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.12041348218917847 norm:0.0002650286187417805 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.12040354311466217 norm:0.00026513866032473743 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.12040523439645767 norm:0.00026311364490538836 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.12040144950151443 norm:0.00026297132717445493 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 05:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.15833038091659546 norm:0.0038085379637777805 max memory_allocated 22560.88232421875 
[2025-03-02 05:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.1409510225057602 norm:0.0014723294880241156 max memory_allocated 22560.88232421875 
[2025-03-02 05:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.13054126501083374 norm:0.0007338901632465422 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.12682639062404633 norm:0.000475972454296425 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.12510688602924347 norm:0.00036621291656047106 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.12415067106485367 norm:0.0003126134106423706 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.12368131428956985 norm:0.00028816633857786655 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.12345989793539047 norm:0.00027724815299734473 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.12325561046600342 norm:0.0002712995046749711 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.12314729392528534 norm:0.0002665654756128788 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.12305700778961182 norm:0.0002625579945743084 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.1229938268661499 norm:0.00025895709404721856 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.12297743558883667 norm:0.00026015096227638423 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.12293191999197006 norm:0.0002610269875731319 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.12292022258043289 norm:0.00026211157091893256 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.1229054257273674 norm:0.0002603133034426719 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.12286615371704102 norm:0.0002588596544228494 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.12286309152841568 norm:0.0002597576822154224 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.12283866107463837 norm:0.0002586983027867973 max memory_allocated 22560.88232421875 
[2025-03-02 05:47:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.12283354252576828 norm:0.0002615675039123744 max memory_allocated 22560.88232421875 
[2025-03-02 05:47:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 05:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.15704241394996643 norm:0.0034079276956617832 max memory_allocated 22561.05419921875 
[2025-03-02 05:48:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.14271029829978943 norm:0.0014601859729737043 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.1332959532737732 norm:0.0008619402069598436 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.12959672510623932 norm:0.0005917775561101735 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.1277935802936554 norm:0.000479124573757872 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.12686815857887268 norm:0.0004069748683832586 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.12637890875339508 norm:0.00036593055119737983 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.12610042095184326 norm:0.0003320480464026332 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.12593510746955872 norm:0.0003159194311592728 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.1258283257484436 norm:0.0003002634912263602 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.12576042115688324 norm:0.000288911018287763 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.12567777931690216 norm:0.00028208771254867315 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.12561334669589996 norm:0.00027622628840617836 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.1255447268486023 norm:0.0002733286237344146 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.1255011409521103 norm:0.0002651861577760428 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.12548302114009857 norm:0.00026428181445226073 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.12544165551662445 norm:0.00025878896121867 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.1254306435585022 norm:0.0002560903667472303 max memory_allocated 22561.05419921875 
[2025-03-02 05:58:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.12540128827095032 norm:0.0002547825570218265 max memory_allocated 22561.05419921875 
[2025-03-02 05:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.12537969648838043 norm:0.00025470840046182275 max memory_allocated 22561.05419921875 
[2025-03-02 05:58:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 05:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.16140688955783844 norm:0.0045149619691073895 max memory_allocated 22561.22607421875 
[2025-03-02 05:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.14612914621829987 norm:0.0016908319666981697 max memory_allocated 22561.22607421875 
[2025-03-02 06:00:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.1358761340379715 norm:0.0006645434768870473 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.13229382038116455 norm:0.00042498548282310367 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.13046576082706451 norm:0.0003434605314396322 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.1295163482427597 norm:0.0003179264022037387 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.12891195714473724 norm:0.00029002365772612393 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.12861880660057068 norm:0.00028067862149327993 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.12839533388614655 norm:0.0002674971183296293 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.12830008566379547 norm:0.0002572933444753289 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.1282433569431305 norm:0.00024776035570539534 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.12823796272277832 norm:0.00024663342628628016 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.12819017469882965 norm:0.00024003112048376352 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.1282099336385727 norm:0.0002402311802143231 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.128211110830307 norm:0.0002385775587754324 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.1281595379114151 norm:0.00023473118199035525 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.1281401515007019 norm:0.00023466034326702356 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:50 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.1281183362007141 norm:0.0002324503439012915 max memory_allocated 22561.22607421875 
[2025-03-02 06:09:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.12812650203704834 norm:0.00023296932340599597 max memory_allocated 22561.22607421875 
[2025-03-02 06:09:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.12812690436840057 norm:0.00023329602845478803 max memory_allocated 22561.22607421875 
[2025-03-02 06:10:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:10:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.1640244722366333 norm:0.002916861092671752 max memory_allocated 22561.39794921875 
[2025-03-02 06:11:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.15065999329090118 norm:0.0013232049532234669 max memory_allocated 22561.39794921875 
[2025-03-02 06:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.14225442707538605 norm:0.0007568438304588199 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.13888409733772278 norm:0.0005081996787339449 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.13732679188251495 norm:0.00039442547131329775 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.13650104403495789 norm:0.00033066043397411704 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.13607697188854218 norm:0.00029744129278697073 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.1358785778284073 norm:0.0002779862261377275 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.135748952627182 norm:0.0002673294802661985 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.1356327086687088 norm:0.00025860127061605453 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.13555121421813965 norm:0.00025623859255574644 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.13547195494174957 norm:0.00025425018975511193 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.13541552424430847 norm:0.0002536815882194787 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.13538075983524323 norm:0.00025179286603815854 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.1353607177734375 norm:0.00025212226319126785 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.13534867763519287 norm:0.00025137915508821607 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.13533633947372437 norm:0.0002575741964392364 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.1353326439857483 norm:0.00025784570607356727 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.13532982766628265 norm:0.0002571806835476309 max memory_allocated 22561.39794921875 
[2025-03-02 06:21:21 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.13531945645809174 norm:0.0002552926307544112 max memory_allocated 22561.39794921875 
[2025-03-02 06:21:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 06:22:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.16640228033065796 norm:0.0019199055386707187 max memory_allocated 22561.56982421875 
[2025-03-02 06:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.15548257529735565 norm:0.0008857680950313807 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.14797726273536682 norm:0.0005212188698351383 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.14507871866226196 norm:0.00037885468918830156 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:20 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.14367976784706116 norm:0.00031928528915159404 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.1429777592420578 norm:0.00028816406847909093 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.14267060160636902 norm:0.000281801272649318 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.14242835342884064 norm:0.0002692671259865165 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.142283096909523 norm:0.000261537148617208 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.14215081930160522 norm:0.00025492077111266553 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.1420826017856598 norm:0.00025206065038219094 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.14201000332832336 norm:0.00025833118706941605 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.14196299016475677 norm:0.00025441241450607777 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.14191383123397827 norm:0.0002503465802874416 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.14190544188022614 norm:0.00025168037973344326 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.14188939332962036 norm:0.00024752633180469275 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.14185558259487152 norm:0.0002521453716326505 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:37 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.14182522892951965 norm:0.0002472371852491051 max memory_allocated 22561.56982421875 
[2025-03-02 06:32:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.14180615544319153 norm:0.0002449457533657551 max memory_allocated 22561.56982421875 
[2025-03-02 06:32:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.14180417358875275 norm:0.0002465196303091943 max memory_allocated 22561.56982421875 
[2025-03-02 06:32:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 06:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.18034006655216217 norm:0.002370331436395645 max memory_allocated 22561.74169921875 
[2025-03-02 06:34:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.16698004305362701 norm:0.000918466888833791 max memory_allocated 22561.74169921875 
[2025-03-02 06:34:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.1582031100988388 norm:0.0005224322667345405 max memory_allocated 22561.74169921875 
[2025-03-02 06:35:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.1549767553806305 norm:0.00037806652835570276 max memory_allocated 22561.74169921875 
[2025-03-02 06:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.1533898413181305 norm:0.00030978411086834967 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.15260076522827148 norm:0.00028074998408555984 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.15219013392925262 norm:0.00026382808573544025 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.15194855630397797 norm:0.00025616592029109597 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.15177080035209656 norm:0.00025262479903176427 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.15165627002716064 norm:0.00025017469306476414 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.15154807269573212 norm:0.0002501111011952162 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.1514848917722702 norm:0.0002489099570084363 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.15142345428466797 norm:0.00024932241649366915 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.15137803554534912 norm:0.00024585076607763767 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.15130668878555298 norm:0.00024368670710828155 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.15128354728221893 norm:0.00024652600404806435 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:26 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.1512775868177414 norm:0.000246967189013958 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.15125496685504913 norm:0.0002463476557750255 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.1512090265750885 norm:0.0002447822771500796 max memory_allocated 22561.74169921875 
[2025-03-02 06:44:07 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.15118156373500824 norm:0.00024510343791916966 max memory_allocated 22561.74169921875 
[2025-03-02 06:44:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 06:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.195863738656044 norm:0.00291653024032712 max memory_allocated 22561.91357421875 
[2025-03-02 06:45:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.18204498291015625 norm:0.0012219777563586831 max memory_allocated 22561.91357421875 
[2025-03-02 06:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.17274916172027588 norm:0.0007082782685756683 max memory_allocated 22561.91357421875 
[2025-03-02 06:46:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.16946832835674286 norm:0.0004919009516015649 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.1679420918226242 norm:0.0003909735241904855 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.16724997758865356 norm:0.0003344977740198374 max memory_allocated 22561.91357421875 
[2025-03-02 06:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.1668829619884491 norm:0.0003068470396101475 max memory_allocated 22561.91357421875 
[2025-03-02 06:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.1666378676891327 norm:0.0002916135417763144 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.16646592319011688 norm:0.00028294528601691127 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.1663159430027008 norm:0.0002712053246796131 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.1661939024925232 norm:0.00026401254581287503 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.16607776284217834 norm:0.0002596575068309903 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.16599002480506897 norm:0.0002559862332418561 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.16593259572982788 norm:0.00025282593560405076 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.1658761352300644 norm:0.0002507742610760033 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.165801540017128 norm:0.00025111768627539277 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.1657632291316986 norm:0.000249694858212024 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.1657208353281021 norm:0.0002491382183507085 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.16569755971431732 norm:0.000248671363806352 max memory_allocated 22561.91357421875 
[2025-03-02 06:55:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.16566821932792664 norm:0.00024853122886270285 max memory_allocated 22561.91357421875 
[2025-03-02 06:55:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 06:56:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.21521803736686707 norm:0.0033253731671720743 max memory_allocated 22562.08544921875 
[2025-03-02 06:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.20191365480422974 norm:0.0015508567448705435 max memory_allocated 22562.08544921875 
[2025-03-02 06:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.19267329573631287 norm:0.0008062705164775252 max memory_allocated 22562.08544921875 
[2025-03-02 06:57:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.18960252404212952 norm:0.0005670867394655943 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.18812119960784912 norm:0.00045634759590029716 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.1875070184469223 norm:0.00039202472544275224 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.1871572732925415 norm:0.0003550236870069057 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.18690375983715057 norm:0.00032786981319077313 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.18673552572727203 norm:0.0003127901582047343 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.18660590052604675 norm:0.00030235902522690594 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.18647441267967224 norm:0.00029229396022856236 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.18633025884628296 norm:0.00028362550074234605 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.18625280261039734 norm:0.000278500490821898 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.18617525696754456 norm:0.000274239806458354 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.18611876666545868 norm:0.00027220207266509533 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.1861000657081604 norm:0.0002688980312086642 max memory_allocated 22562.08544921875 
[2025-03-02 07:05:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.18604274094104767 norm:0.00026794071891345084 max memory_allocated 22562.08544921875 
[2025-03-02 07:05:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.18600431084632874 norm:0.0002669066016096622 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.18597997725009918 norm:0.0002650426176842302 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.18594053387641907 norm:0.00026349929976277053 max memory_allocated 22562.08544921875 
[2025-03-02 07:07:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:07:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.23679780960083008 norm:0.0032792952843010426 max memory_allocated 22562.25732421875 
[2025-03-02 07:08:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.22422078251838684 norm:0.0013418918242678046 max memory_allocated 22562.25732421875 
[2025-03-02 07:08:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.2147175520658493 norm:0.0006863173912279308 max memory_allocated 22562.25732421875 
[2025-03-02 07:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.211556077003479 norm:0.0004860255867242813 max memory_allocated 22562.25732421875 
[2025-03-02 07:09:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.21022139489650726 norm:0.00044931378215551376 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.20968185365200043 norm:0.0003967402153648436 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.20941224694252014 norm:0.0003884407051373273 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.20926785469055176 norm:0.00035917016793973744 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.20912814140319824 norm:0.00033918279223144054 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.20892181992530823 norm:0.000314687640639022 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.20876085758209229 norm:0.00030150520615279675 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.20865920186042786 norm:0.0002966653264593333 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.2085423618555069 norm:0.00027782758115790784 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.20844244956970215 norm:0.00027650571428239346 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.20855265855789185 norm:0.00027760531520470977 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.2085283249616623 norm:0.0002731026615947485 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:35 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.20847147703170776 norm:0.0002678264572750777 max memory_allocated 22562.25732421875 
[2025-03-02 07:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.20859725773334503 norm:0.0002709924301598221 max memory_allocated 22562.25732421875 
[2025-03-02 07:17:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.20863483846187592 norm:0.0002646197681315243 max memory_allocated 22562.25732421875 
[2025-03-02 07:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.20868054032325745 norm:0.0002620912855491042 max memory_allocated 22562.25732421875 
[2025-03-02 07:18:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 07:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.28229227662086487 norm:0.008169462904334068 max memory_allocated 22562.42919921875 
[2025-03-02 07:19:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.26431190967559814 norm:0.0030678086914122105 max memory_allocated 22562.42919921875 
[2025-03-02 07:20:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.25067850947380066 norm:0.0011629265500232577 max memory_allocated 22562.42919921875 
[2025-03-02 07:20:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.24661514163017273 norm:0.0008247718214988708 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.24492447078227997 norm:0.0007657266687601805 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.24424035847187042 norm:0.0006863593589514494 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.24370285868644714 norm:0.0005871358443982899 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.24336087703704834 norm:0.0005437098443508148 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.2431250959634781 norm:0.0004949854919686913 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.2428501397371292 norm:0.00044637182145379484 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.24271532893180847 norm:0.0004307491471990943 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.2425970435142517 norm:0.0004196451627649367 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.24254506826400757 norm:0.0003939921734854579 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.24230585992336273 norm:0.00037347438046708703 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.24217362701892853 norm:0.0003608569095376879 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:24 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.24214133620262146 norm:0.0003435451362747699 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.242062047123909 norm:0.0003407997719477862 max memory_allocated 22562.42919921875 
[2025-03-02 07:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.24199704825878143 norm:0.0003378695109859109 max memory_allocated 22562.42919921875 
[2025-03-02 07:29:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.2419218122959137 norm:0.00033427405287511647 max memory_allocated 22562.42919921875 
[2025-03-02 07:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.2419368326663971 norm:0.0003362403658684343 max memory_allocated 22562.42919921875 
[2025-03-02 07:29:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 07:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.3135693073272705 norm:0.001989879412576556 max memory_allocated 22562.60107421875 
[2025-03-02 07:30:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.3006901741027832 norm:0.0009635752066969872 max memory_allocated 22562.60107421875 
[2025-03-02 07:31:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.28958937525749207 norm:0.0007149081793613732 max memory_allocated 22562.60107421875 
[2025-03-02 07:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.28611159324645996 norm:0.0005925885634496808 max memory_allocated 22562.60107421875 
[2025-03-02 07:32:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.2848036587238312 norm:0.0005274048307910562 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.28420937061309814 norm:0.0004912892472930253 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.28388580679893494 norm:0.00048785842955112457 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.2834540903568268 norm:0.0005240713362582028 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:53 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.2834125757217407 norm:0.0004750913940370083 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.2831338942050934 norm:0.0005240541067905724 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.2829495966434479 norm:0.0004827688098885119 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.283056378364563 norm:0.00048759611672721803 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.2830468416213989 norm:0.0005617766873911023 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.28295835852622986 norm:0.0005882233963347971 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.28323423862457275 norm:0.000511550810188055 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.28270798921585083 norm:0.0006290605524554849 max memory_allocated 22562.60107421875 
[2025-03-02 07:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.28296613693237305 norm:0.0005479929386638105 max memory_allocated 22562.60107421875 
[2025-03-02 07:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.28259554505348206 norm:0.0006095657590776682 max memory_allocated 22562.60107421875 
[2025-03-02 07:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.28261440992355347 norm:0.0005267648957669735 max memory_allocated 22562.60107421875 
[2025-03-02 07:41:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.2826448082923889 norm:0.0005966327153146267 max memory_allocated 22562.60107421875 
[2025-03-02 07:41:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 07:41:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.3620372414588928 norm:0.0029229093343019485 max memory_allocated 22562.77294921875 
[2025-03-02 07:42:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.346910685300827 norm:0.0014603513991460204 max memory_allocated 22562.77294921875 
[2025-03-02 07:42:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.33479684591293335 norm:0.0009061858872883022 max memory_allocated 22562.77294921875 
[2025-03-02 07:43:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.330910325050354 norm:0.0006513146217912436 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:02 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.32936084270477295 norm:0.0005168089410290122 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.32871079444885254 norm:0.00044429436093196273 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.3282872438430786 norm:0.00040095369331538677 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.3279123604297638 norm:0.00037622713716700673 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.3276020884513855 norm:0.0003587007522583008 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.3274054527282715 norm:0.00034715697984211147 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.3272213637828827 norm:0.00033846747828647494 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.32705047726631165 norm:0.00033442594576627016 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.32690906524658203 norm:0.0003305405261926353 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.32677292823791504 norm:0.0003252688911743462 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.3266546428203583 norm:0.0003213415329810232 max memory_allocated 22562.77294921875 
[2025-03-02 07:50:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.3265342712402344 norm:0.0003187803376931697 max memory_allocated 22562.77294921875 
[2025-03-02 07:50:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.3264186382293701 norm:0.0003173726727254689 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.32636186480522156 norm:0.0003199784259777516 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.32630619406700134 norm:0.000317397469189018 max memory_allocated 22562.77294921875 
[2025-03-02 07:52:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.32623201608657837 norm:0.00031488246168009937 max memory_allocated 22562.77294921875 
[2025-03-02 07:52:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 07:53:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.4163232147693634 norm:0.004182844888418913 max memory_allocated 22562.94482421875 
[2025-03-02 07:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.4013538956642151 norm:0.0021363976411521435 max memory_allocated 22562.94482421875 
[2025-03-02 07:54:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.3881383538246155 norm:0.0013145997654646635 max memory_allocated 22562.94482421875 
[2025-03-02 07:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.3836700916290283 norm:0.000917629455216229 max memory_allocated 22562.94482421875 
[2025-03-02 07:55:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.3819149136543274 norm:0.0007218417013064027 max memory_allocated 22562.94482421875 
[2025-03-02 07:55:58 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.38116639852523804 norm:0.000610029324889183 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:32 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.3805972635746002 norm:0.0005313643487170339 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.38039523363113403 norm:0.0004845963849220425 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.3800683319568634 norm:0.0004662990686483681 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.37974774837493896 norm:0.00043511722469702363 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.3795452117919922 norm:0.0004337411082815379 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.3793758153915405 norm:0.00041308923391625285 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.3794700503349304 norm:0.0004068188136443496 max memory_allocated 22562.94482421875 
[2025-03-02 08:00:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.37923088669776917 norm:0.00040250818710774183 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.3790988326072693 norm:0.0003913242544513196 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.3790017068386078 norm:0.00038684208993799984 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.3790265917778015 norm:0.00039414307684637606 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.3790602684020996 norm:0.0003974938881583512 max memory_allocated 22562.94482421875 
[2025-03-02 08:03:14 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.37905240058898926 norm:0.00041309426887892187 max memory_allocated 22562.94482421875 
[2025-03-02 08:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.3790546953678131 norm:0.0004066901747137308 max memory_allocated 22562.94482421875 
[2025-03-02 08:03:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:04:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.4694579243659973 norm:0.003932533320039511 max memory_allocated 22563.11669921875 
[2025-03-02 08:05:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.45421892404556274 norm:0.0020146826282143593 max memory_allocated 22563.11669921875 
[2025-03-02 08:05:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.4389601945877075 norm:0.00098121608607471 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.43436962366104126 norm:0.0007117455825209618 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.43289798498153687 norm:0.0006186715909279883 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.4322435259819031 norm:0.0005567227490246296 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.4318349063396454 norm:0.0005047855083830655 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.4315738379955292 norm:0.00046800810378044844 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.43129581212997437 norm:0.0004345649795141071 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.43109557032585144 norm:0.00041211018105968833 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.43089544773101807 norm:0.0003892226086463779 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.4307827353477478 norm:0.0003810262423940003 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.4307015836238861 norm:0.0003741936234291643 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.4306235909461975 norm:0.0003607101971283555 max memory_allocated 22563.11669921875 
[2025-03-02 08:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.43056154251098633 norm:0.00035302952164784074 max memory_allocated 22563.11669921875 
[2025-03-02 08:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.43049055337905884 norm:0.0003475440025795251 max memory_allocated 22563.11669921875 
[2025-03-02 08:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.43042469024658203 norm:0.00033934725797735155 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.4304172694683075 norm:0.00033806340070441365 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.43035319447517395 norm:0.00034012607648037374 max memory_allocated 22563.11669921875 
[2025-03-02 08:15:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.4303017854690552 norm:0.0003364298609085381 max memory_allocated 22563.11669921875 
[2025-03-02 08:15:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 08:15:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.5336725115776062 norm:0.004559175111353397 max memory_allocated 22563.28857421875 
[2025-03-02 08:16:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.517278254032135 norm:0.002349644200876355 max memory_allocated 22563.28857421875 
[2025-03-02 08:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.5006459951400757 norm:0.0012059719301760197 max memory_allocated 22563.28857421875 
[2025-03-02 08:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.4956062138080597 norm:0.0009025802719406784 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.4940205514431 norm:0.0007277335389517248 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.4934441149234772 norm:0.0006325242575258017 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.49298280477523804 norm:0.0005446119466796517 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.4926574230194092 norm:0.00047947748680599034 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.49233075976371765 norm:0.00044105274719186127 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.4921518564224243 norm:0.00041870365384966135 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.49196913838386536 norm:0.0004116543277632445 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.49196717143058777 norm:0.00040552017162553966 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.4918173849582672 norm:0.00039401924004778266 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.4916655421257019 norm:0.0003874624671880156 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.49159732460975647 norm:0.0003848667547572404 max memory_allocated 22563.28857421875 
[2025-03-02 08:24:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.49132436513900757 norm:0.00037566793616861105 max memory_allocated 22563.28857421875 
[2025-03-02 08:24:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.49137595295906067 norm:0.0003742501139640808 max memory_allocated 22563.28857421875 
[2025-03-02 08:25:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.49119094014167786 norm:0.00037178208003751934 max memory_allocated 22563.28857421875 
[2025-03-02 08:26:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.4911153018474579 norm:0.00037258974043652415 max memory_allocated 22563.28857421875 
[2025-03-02 08:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.4910133481025696 norm:0.0003746237780433148 max memory_allocated 22563.28857421875 
[2025-03-02 08:26:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 08:27:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.6140012741088867 norm:0.012536469846963882 max memory_allocated 22563.46044921875 
[2025-03-02 08:27:54 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.5899184942245483 norm:0.006167751736938953 max memory_allocated 22563.46044921875 
[2025-03-02 08:28:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.5697726011276245 norm:0.0035044895485043526 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.5630514025688171 norm:0.002305718371644616 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.5610350966453552 norm:0.0017059635138139129 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.5600686073303223 norm:0.0013316263211891055 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.5593892335891724 norm:0.0010634170612320304 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.5587891936302185 norm:0.000900656683370471 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.5585105419158936 norm:0.0007743679452687502 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.5583069920539856 norm:0.0006898162537254393 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.5580779314041138 norm:0.0006282824324443936 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.5579275488853455 norm:0.0005804385291412473 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.557663083076477 norm:0.0005454424535855651 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.5574782490730286 norm:0.0005259702447801828 max memory_allocated 22563.46044921875 
[2025-03-02 08:35:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.5573405623435974 norm:0.000507319055031985 max memory_allocated 22563.46044921875 
[2025-03-02 08:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.5572161674499512 norm:0.0004860533226747066 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.5570883750915527 norm:0.00047045378596521914 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.5570656657218933 norm:0.0004643674474209547 max memory_allocated 22563.46044921875 
[2025-03-02 08:37:25 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.5569037795066833 norm:0.0004668706969823688 max memory_allocated 22563.46044921875 
[2025-03-02 08:37:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.5568729639053345 norm:0.0004541271482594311 max memory_allocated 22563.46044921875 
[2025-03-02 08:38:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 08:38:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.6753329038619995 norm:0.006842541508376598 max memory_allocated 22563.63232421875 
[2025-03-02 08:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.6544872522354126 norm:0.0033780818339437246 max memory_allocated 22563.63232421875 
[2025-03-02 08:39:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.6368164420127869 norm:0.0020176642574369907 max memory_allocated 22563.63232421875 
[2025-03-02 08:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.631148099899292 norm:0.0014189098728820682 max memory_allocated 22563.63232421875 
[2025-03-02 08:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.6296871304512024 norm:0.0011205438058823347 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.6290224194526672 norm:0.0009453058592043817 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.6285330057144165 norm:0.0008367763366550207 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.6282694935798645 norm:0.0007688581827096641 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.6280739307403564 norm:0.0007035231101326644 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.627566397190094 norm:0.0006509518716484308 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.6273671388626099 norm:0.0006725407438352704 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.6277429461479187 norm:0.0006068529328331351 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.6275988221168518 norm:0.0006332502234727144 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.6268455982208252 norm:0.0006495966808870435 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.626764178276062 norm:0.0006083892658352852 max memory_allocated 22563.63232421875 
[2025-03-02 08:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.626577615737915 norm:0.000607056193985045 max memory_allocated 22563.63232421875 
[2025-03-02 08:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.6273337602615356 norm:0.0005504954606294632 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.626777172088623 norm:0.0005935841472819448 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.6264650821685791 norm:0.0005963392904959619 max memory_allocated 22563.63232421875 
[2025-03-02 08:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.6264787316322327 norm:0.0005321278003975749 max memory_allocated 22563.63232421875 
[2025-03-02 08:49:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 08:49:34 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 08:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.7706311941146851 norm:0.0214128065854311 max memory_allocated 22563.91943359375 
[2025-03-02 08:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.7470505237579346 norm:0.017829949036240578 max memory_allocated 22563.91943359375 
[2025-03-02 08:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.7275174260139465 norm:0.012234880588948727 max memory_allocated 22563.91943359375 
[2025-03-02 08:51:49 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.7209344506263733 norm:0.010777909308671951 max memory_allocated 22563.91943359375 
[2025-03-02 08:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.7188401222229004 norm:0.009615456685423851 max memory_allocated 22563.91943359375 
[2025-03-02 08:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.7175804972648621 norm:0.00854487158358097 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.7168432474136353 norm:0.007679554633796215 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.7161277532577515 norm:0.006901424843817949 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.715680718421936 norm:0.006575440522283316 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.715387225151062 norm:0.006326788105070591 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.7151334881782532 norm:0.006174542009830475 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.7149941325187683 norm:0.006238687317818403 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.7147706747055054 norm:0.0059532709419727325 max memory_allocated 22563.91943359375 
[2025-03-02 08:57:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.7146285176277161 norm:0.00604625977575779 max memory_allocated 22563.91943359375 
[2025-03-02 08:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.7142682671546936 norm:0.005750549491494894 max memory_allocated 22563.91943359375 
[2025-03-02 08:58:33 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.7139933109283447 norm:0.005539650097489357 max memory_allocated 22563.91943359375 
[2025-03-02 08:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.7138155102729797 norm:0.005359426140785217 max memory_allocated 22563.91943359375 
[2025-03-02 08:59:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.7138319611549377 norm:0.005402175709605217 max memory_allocated 22563.91943359375 
[2025-03-02 09:00:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.7137837409973145 norm:0.005472111981362104 max memory_allocated 22563.91943359375 
[2025-03-02 09:00:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.713701605796814 norm:0.0053945439867675304 max memory_allocated 22563.91943359375 
[2025-03-02 09:00:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 09:01:00 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.8878120183944702 norm:0.029669180512428284 max memory_allocated 22564.09130859375 
[2025-03-02 09:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.8598511815071106 norm:0.021731046959757805 max memory_allocated 22564.09130859375 
[2025-03-02 09:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.8357358574867249 norm:0.014939457178115845 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.8280052542686462 norm:0.012215698137879372 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.8255717158317566 norm:0.010418077930808067 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.8242611885070801 norm:0.008950438350439072 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.823164165019989 norm:0.008155053481459618 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.8224040269851685 norm:0.007241713814437389 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.8216780424118042 norm:0.006686490960419178 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.821294903755188 norm:0.0062555051408708096 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.8214574456214905 norm:0.006097698584198952 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.8212233185768127 norm:0.006216580513864756 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.8210926055908203 norm:0.005831742659211159 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.8207463026046753 norm:0.005686200223863125 max memory_allocated 22564.09130859375 
[2025-03-02 09:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.8205723762512207 norm:0.005324804224073887 max memory_allocated 22564.09130859375 
[2025-03-02 09:09:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.8205451369285583 norm:0.005469846539199352 max memory_allocated 22564.09130859375 
[2025-03-02 09:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.8203960061073303 norm:0.005274083930999041 max memory_allocated 22564.09130859375 
[2025-03-02 09:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.8202255368232727 norm:0.005147465970367193 max memory_allocated 22564.09130859375 
[2025-03-02 09:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.8201261162757874 norm:0.004997635260224342 max memory_allocated 22564.09130859375 
[2025-03-02 09:12:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.8200588226318359 norm:0.004829251207411289 max memory_allocated 22564.09130859375 
[2025-03-02 09:12:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:12:27 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:13:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.1930322647094727 norm:0.034594208002090454 max memory_allocated 22564.26318359375 
[2025-03-02 09:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:1.1114698648452759 norm:0.027601946145296097 max memory_allocated 22564.26318359375 
[2025-03-02 09:14:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:1.064343810081482 norm:0.02836689166724682 max memory_allocated 22564.26318359375 
[2025-03-02 09:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:1.0517023801803589 norm:0.028683174401521683 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:1.0467469692230225 norm:0.029960885643959045 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:1.0433568954467773 norm:0.030583782121539116 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:1.0414328575134277 norm:0.030796904116868973 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:1.0394339561462402 norm:0.030346443876624107 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:1.038224458694458 norm:0.02999209240078926 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:03 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:1.0374864339828491 norm:0.03023415058851242 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:1.0366591215133667 norm:0.02992972545325756 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:1.0360349416732788 norm:0.029595406726002693 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:1.0362569093704224 norm:0.028873661532998085 max memory_allocated 22564.26318359375 
[2025-03-02 09:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:1.035569667816162 norm:0.02908420003950596 max memory_allocated 22564.26318359375 
[2025-03-02 09:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:1.0355859994888306 norm:0.028553670272231102 max memory_allocated 22564.26318359375 
[2025-03-02 09:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:1.034635066986084 norm:0.02785409241914749 max memory_allocated 22564.26318359375 
[2025-03-02 09:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:1.0344822406768799 norm:0.027808232232928276 max memory_allocated 22564.26318359375 
[2025-03-02 09:22:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:1.0349012613296509 norm:0.028277894482016563 max memory_allocated 22564.26318359375 
[2025-03-02 09:23:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:1.0360970497131348 norm:0.030435234308242798 max memory_allocated 22564.26318359375 
[2025-03-02 09:23:40 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:1.0352598428726196 norm:0.02805761992931366 max memory_allocated 22564.26318359375 
[2025-03-02 09:23:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 09:23:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:2.2272086143493652 norm:0.13792061805725098 max memory_allocated 22564.43505859375 
[2025-03-02 09:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:2.061483383178711 norm:0.09344218671321869 max memory_allocated 22564.43505859375 
[2025-03-02 09:25:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:1.9373447895050049 norm:0.06847773492336273 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:1.8906058073043823 norm:0.06368844211101532 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:1.8646173477172852 norm:0.058925285935401917 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:1.845726490020752 norm:0.05564796179533005 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:1.832294225692749 norm:0.05488203838467598 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:1.820860505104065 norm:0.053492940962314606 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:1.8119192123413086 norm:0.05322693660855293 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:1.8031628131866455 norm:0.05119439959526062 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:1.79667067527771 norm:0.04885395988821983 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:1.791806697845459 norm:0.049516819417476654 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:1.787459135055542 norm:0.05220775678753853 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:1.7842960357666016 norm:0.0484750010073185 max memory_allocated 22564.43505859375 
[2025-03-02 09:32:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:1.7821975946426392 norm:0.04981417953968048 max memory_allocated 22564.43505859375 
[2025-03-02 09:32:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:1.781665563583374 norm:0.0512361004948616 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:1.777756929397583 norm:0.045058783143758774 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:1.7773936986923218 norm:0.04853548854589462 max memory_allocated 22564.43505859375 
[2025-03-02 09:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:1.7746567726135254 norm:0.04775051772594452 max memory_allocated 22564.43505859375 
[2025-03-02 09:35:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:1.7730686664581299 norm:0.04842096567153931 max memory_allocated 22564.43505859375 
[2025-03-02 09:35:16 root] (main_calib_config2.py 380): INFO 21873.02145266533
[2025-03-02 09:35:21 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 09:36:32 root] (main_calib_config2.py 159): INFO wikitext2 : 6.236941337585449
[2025-03-02 09:36:32 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 09:38:21 root] (main_calib_config2.py 159): INFO c4 : 7.919139862060547
