[2025-03-02 03:28:16 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-7b-hf_0.65', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.65.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 03:30:43 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-03-02 03:30:43 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 03:30:44 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.65.pkl
[2025-03-02 03:30:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 03:30:52 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:31:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.009160309098660946 norm:0.00650403555482626 max memory_allocated 22559.10693359375 
[2025-03-02 03:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.005347258411347866 norm:0.0038557809311896563 max memory_allocated 22559.10693359375 
[2025-03-02 03:32:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.003748443443328142 norm:0.002657388336956501 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0033264101948589087 norm:0.0021868390031158924 max memory_allocated 22559.10693359375 
[2025-03-02 03:33:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0031476302538067102 norm:0.0018160361796617508 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0030520749278366566 norm:0.001534273847937584 max memory_allocated 22559.10693359375 
[2025-03-02 03:34:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.002971747424453497 norm:0.0013159668305888772 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.002932047238573432 norm:0.001177780912257731 max memory_allocated 22559.10693359375 
[2025-03-02 03:35:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0029705518390983343 norm:0.0010325605981051922 max memory_allocated 22559.10693359375 
[2025-03-02 03:36:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0028883672785013914 norm:0.0008912557386793196 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0028480691835284233 norm:0.0007758396677672863 max memory_allocated 22559.10693359375 
[2025-03-02 03:37:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.002820102032274008 norm:0.0006850822828710079 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.002799765206873417 norm:0.0006449646316468716 max memory_allocated 22559.10693359375 
[2025-03-02 03:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.002795333042740822 norm:0.0006102359620854259 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.002783004892989993 norm:0.0005764123052358627 max memory_allocated 22559.10693359375 
[2025-03-02 03:39:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.002773476531729102 norm:0.000533732061740011 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0027616089209914207 norm:0.0005421626847237349 max memory_allocated 22559.10693359375 
[2025-03-02 03:40:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0027416825760155916 norm:0.0005174423567950726 max memory_allocated 22559.10693359375 
[2025-03-02 03:41:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.002743090968579054 norm:0.0004981622332707047 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0027438290417194366 norm:0.00048510325723327696 max memory_allocated 22559.10693359375 
[2025-03-02 03:42:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 03:42:15 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:42:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.02201937884092331 norm:0.016888856887817383 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.012322723865509033 norm:0.009295087307691574 max memory_allocated 22559.27880859375 
[2025-03-02 03:43:56 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.008846958167850971 norm:0.005396252032369375 max memory_allocated 22559.27880859375 
[2025-03-02 03:44:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.008127364329993725 norm:0.004606486763805151 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.007798581384122372 norm:0.004016253165900707 max memory_allocated 22559.27880859375 
[2025-03-02 03:45:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.007577897049486637 norm:0.0036247549578547478 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.007411370053887367 norm:0.003348875790834427 max memory_allocated 22559.27880859375 
[2025-03-02 03:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.007286655716598034 norm:0.003046195488423109 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.00717453146353364 norm:0.0028159325011074543 max memory_allocated 22559.27880859375 
[2025-03-02 03:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.007142437156289816 norm:0.0026198369450867176 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.0070686847902834415 norm:0.0023584167938679457 max memory_allocated 22559.27880859375 
[2025-03-02 03:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.0070415460504591465 norm:0.0021294993348419666 max memory_allocated 22559.27880859375 
[2025-03-02 03:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.007006671745330095 norm:0.0019539978820830584 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.007013340946286917 norm:0.0017618879210203886 max memory_allocated 22559.27880859375 
[2025-03-02 03:50:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.006989913061261177 norm:0.001565042999573052 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.006912137381732464 norm:0.001405350281856954 max memory_allocated 22559.27880859375 
[2025-03-02 03:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.006896238308399916 norm:0.0012587257660925388 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.006864262744784355 norm:0.0011277575977146626 max memory_allocated 22559.27880859375 
[2025-03-02 03:52:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.00694139814004302 norm:0.0011830049334093928 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.007051413878798485 norm:0.0012776048388332129 max memory_allocated 22559.27880859375 
[2025-03-02 03:53:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 03:53:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 03:54:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.07922695577144623 norm:0.022608131170272827 max memory_allocated 22559.45068359375 
[2025-03-02 03:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.0401461124420166 norm:0.017365777865052223 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.02457556128501892 norm:0.013099606148898602 max memory_allocated 22559.45068359375 
[2025-03-02 03:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.01858949288725853 norm:0.006465279031544924 max memory_allocated 22559.45068359375 
[2025-03-02 03:56:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.016892120242118835 norm:0.005488816648721695 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.015877382829785347 norm:0.004803849384188652 max memory_allocated 22559.45068359375 
[2025-03-02 03:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.01507532224059105 norm:0.00445354450494051 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.014684735797345638 norm:0.00408910121768713 max memory_allocated 22559.45068359375 
[2025-03-02 03:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.014406493864953518 norm:0.0035725024063140154 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.014159522950649261 norm:0.0033169325906783342 max memory_allocated 22559.45068359375 
[2025-03-02 03:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.014023711904883385 norm:0.0030413924250751734 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.014144846238195896 norm:0.0028856713324785233 max memory_allocated 22559.45068359375 
[2025-03-02 04:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.013816848397254944 norm:0.002684215549379587 max memory_allocated 22559.45068359375 
[2025-03-02 04:01:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.01372356154024601 norm:0.002502996474504471 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.013504640199244022 norm:0.002164229052141309 max memory_allocated 22559.45068359375 
[2025-03-02 04:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.01339680515229702 norm:0.0020724101923406124 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.013460229150950909 norm:0.0021439469419419765 max memory_allocated 22559.45068359375 
[2025-03-02 04:03:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.013585928827524185 norm:0.0022528739646077156 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.013487964868545532 norm:0.0022206150460988283 max memory_allocated 22559.45068359375 
[2025-03-02 04:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.013379989191889763 norm:0.0020109754987061024 max memory_allocated 22559.45068359375 
[2025-03-02 04:05:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 04:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.026270492002367973 norm:0.0022703539580106735 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.020056836307048798 norm:0.0009420023416168988 max memory_allocated 22559.50732421875 
[2025-03-02 04:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.01702350378036499 norm:0.00048003142001107335 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.016047630459070206 norm:0.0002668699889909476 max memory_allocated 22559.50732421875 
[2025-03-02 04:07:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.015456841327250004 norm:0.00019404526392463595 max memory_allocated 22559.50732421875 
[2025-03-02 04:08:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.015109539963304996 norm:0.0001433482248103246 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.014990776777267456 norm:0.00012042534945067018 max memory_allocated 22559.50732421875 
[2025-03-02 04:09:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.014952261932194233 norm:0.000112967609311454 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:08 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.01493329368531704 norm:0.00011271642870269716 max memory_allocated 22559.50732421875 
[2025-03-02 04:10:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.014917444437742233 norm:0.00011100430128863081 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.014911685138940811 norm:0.0001138114312198013 max memory_allocated 22559.50732421875 
[2025-03-02 04:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.0148937301710248 norm:0.00010219648538623005 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.014886411838233471 norm:0.00010560361988609657 max memory_allocated 22559.50732421875 
[2025-03-02 04:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.014882061630487442 norm:0.00011166850890731439 max memory_allocated 22559.50732421875 
[2025-03-02 04:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.014872747473418713 norm:0.00010344466136302799 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.014866827055811882 norm:0.00010369136725785211 max memory_allocated 22559.50732421875 
[2025-03-02 04:14:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.014873364940285683 norm:0.00011044998973375186 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.014877759851515293 norm:0.00010608352022245526 max memory_allocated 22559.50732421875 
[2025-03-02 04:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.014872856438159943 norm:0.00010372269025538117 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.014865671284496784 norm:0.00010256488167215139 max memory_allocated 22559.50732421875 
[2025-03-02 04:16:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 04:17:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.0334993340075016 norm:0.00227341684512794 max memory_allocated 22559.67919921875 
[2025-03-02 04:17:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.025817930698394775 norm:0.0009970751125365496 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.021698376163840294 norm:0.000502687762491405 max memory_allocated 22559.67919921875 
[2025-03-02 04:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.020293788984417915 norm:0.0002940904814749956 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.019626175984740257 norm:0.00021472301159519702 max memory_allocated 22559.67919921875 
[2025-03-02 04:19:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.019314927980303764 norm:0.0001917407789733261 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.01922209933400154 norm:0.0001817745651351288 max memory_allocated 22559.67919921875 
[2025-03-02 04:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.019159574061632156 norm:0.00017169062630273402 max memory_allocated 22559.67919921875 
[2025-03-02 04:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.019130131229758263 norm:0.00017140930867753923 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.019085578620433807 norm:0.00017155485693365335 max memory_allocated 22559.67919921875 
[2025-03-02 04:22:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.0190575048327446 norm:0.00016774062532931566 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.019040480256080627 norm:0.0001677494146861136 max memory_allocated 22559.67919921875 
[2025-03-02 04:23:44 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.01902734488248825 norm:0.00016333772509824485 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.019012976437807083 norm:0.00016320460417773575 max memory_allocated 22559.67919921875 
[2025-03-02 04:24:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.019008297473192215 norm:0.0001685989846009761 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.018990999087691307 norm:0.00016384784248657525 max memory_allocated 22559.67919921875 
[2025-03-02 04:25:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.018980680033564568 norm:0.00016385404160246253 max memory_allocated 22559.67919921875 
[2025-03-02 04:26:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.018978366628289223 norm:0.00016261037671938539 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.018967773765325546 norm:0.00016304942255374044 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.018970157951116562 norm:0.00016072308062575758 max memory_allocated 22559.67919921875 
[2025-03-02 04:27:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 04:28:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.037559133023023605 norm:0.002152219181880355 max memory_allocated 22559.85107421875 
[2025-03-02 04:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.029556050896644592 norm:0.0009761523688212037 max memory_allocated 22559.85107421875 
[2025-03-02 04:29:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.025113491341471672 norm:0.0004966563428752124 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.023599818348884583 norm:0.00027941304142586887 max memory_allocated 22559.85107421875 
[2025-03-02 04:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.02285107783973217 norm:0.00017064885469153523 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.022541027516126633 norm:0.00012655832688324153 max memory_allocated 22559.85107421875 
[2025-03-02 04:31:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.022429658100008965 norm:0.00011712741979863495 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.022351078689098358 norm:0.00011159266432514414 max memory_allocated 22559.85107421875 
[2025-03-02 04:32:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.02229105308651924 norm:0.0001080650690710172 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.022241834551095963 norm:0.0001084450414055027 max memory_allocated 22559.85107421875 
[2025-03-02 04:33:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.022209705784916878 norm:0.00010928288247669116 max memory_allocated 22559.85107421875 
[2025-03-02 04:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.022180140018463135 norm:0.0001082696471712552 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:06 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.022169889882206917 norm:0.00010555453627603129 max memory_allocated 22559.85107421875 
[2025-03-02 04:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.022137904539704323 norm:0.000104136997833848 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.0221189484000206 norm:0.0001042229778249748 max memory_allocated 22559.85107421875 
[2025-03-02 04:36:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.022102251648902893 norm:0.00010195500362897292 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.022090230137109756 norm:0.00010100877989316359 max memory_allocated 22559.85107421875 
[2025-03-02 04:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.022076912224292755 norm:0.00010047446994576603 max memory_allocated 22559.85107421875 
[2025-03-02 04:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.02207585610449314 norm:9.967941150534898e-05 max memory_allocated 22559.85107421875 
[2025-03-02 04:39:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.022071469575166702 norm:9.894749382510781e-05 max memory_allocated 22559.85107421875 
[2025-03-02 04:39:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 04:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.038993965834379196 norm:0.0013281453866511583 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.03200320154428482 norm:0.0004931053263135254 max memory_allocated 22560.02294921875 
[2025-03-02 04:40:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.027987683191895485 norm:0.00027875712839886546 max memory_allocated 22560.02294921875 
[2025-03-02 04:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.02675062231719494 norm:0.00018696540792007 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.026123343035578728 norm:0.00014611432561650872 max memory_allocated 22560.02294921875 
[2025-03-02 04:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.025812117382884026 norm:0.00012272912135813385 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.025691034272313118 norm:0.00010446632950333878 max memory_allocated 22560.02294921875 
[2025-03-02 04:43:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.025628959760069847 norm:9.794783545657992e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.02559436485171318 norm:9.530593524686992e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.025559011846780777 norm:9.630390559323132e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.025525305420160294 norm:9.343143756268546e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:45:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.02550983615219593 norm:9.579093602951616e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:46:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.025496553629636765 norm:9.279254300054163e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.02547752484679222 norm:8.751708082854748e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.02546420320868492 norm:8.827551209833473e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.02546513080596924 norm:9.754759230418131e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:48:45 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.02545693889260292 norm:9.495105769019574e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.02545040473341942 norm:9.054487600224093e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:49:52 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.025438860058784485 norm:8.766630344325677e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.025437258183956146 norm:8.838043868308887e-05 max memory_allocated 22560.02294921875 
[2025-03-02 04:50:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 04:51:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.044919662177562714 norm:0.0013049425324425101 max memory_allocated 22560.19482421875 
[2025-03-02 04:51:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.03673077002167702 norm:0.0006484902696684003 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.03210459649562836 norm:0.00037195466575212777 max memory_allocated 22560.19482421875 
[2025-03-02 04:52:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.0307453740388155 norm:0.0002561919973231852 max memory_allocated 22560.19482421875 
[2025-03-02 04:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.029957862570881844 norm:0.0002386212145211175 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:00 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.029490817338228226 norm:0.00019149709260091186 max memory_allocated 22560.19482421875 
[2025-03-02 04:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.029327768832445145 norm:0.00017812430451158434 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.029247384518384933 norm:0.00018150988034904003 max memory_allocated 22560.19482421875 
[2025-03-02 04:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.02917354553937912 norm:0.00017557668616063893 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.029024194926023483 norm:0.00015786921721883118 max memory_allocated 22560.19482421875 
[2025-03-02 04:56:47 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.028976548463106155 norm:0.0001606970326974988 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.028956441208720207 norm:0.00015946041094139218 max memory_allocated 22560.19482421875 
[2025-03-02 04:57:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.028927775099873543 norm:0.00016558740753680468 max memory_allocated 22560.19482421875 
[2025-03-02 04:58:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.02893032133579254 norm:0.00015372614143416286 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.028881508857011795 norm:0.0001446510141249746 max memory_allocated 22560.19482421875 
[2025-03-02 04:59:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.028863076120615005 norm:0.00014059734530746937 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.028867969289422035 norm:0.00015588474343530834 max memory_allocated 22560.19482421875 
[2025-03-02 05:00:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.028817197307944298 norm:0.0001511056034360081 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.028800083324313164 norm:0.00015160217299126089 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.028792275115847588 norm:0.00015261679072864354 max memory_allocated 22560.19482421875 
[2025-03-02 05:01:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 05:02:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.04662782698869705 norm:0.0009528023074381053 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.038678884506225586 norm:0.00043807135079987347 max memory_allocated 22560.36669921875 
[2025-03-02 05:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.034346938133239746 norm:0.0002774218446575105 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:16 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.033019114285707474 norm:0.000196353648789227 max memory_allocated 22560.36669921875 
[2025-03-02 05:04:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.032291848212480545 norm:0.00017941242549568415 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.03188316524028778 norm:0.00018848276522476226 max memory_allocated 22560.36669921875 
[2025-03-02 05:05:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.03163821995258331 norm:0.0001666643947828561 max memory_allocated 22560.36669921875 
[2025-03-02 05:06:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.031452614814043045 norm:0.00015200316556729376 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.03142692148685455 norm:0.0001505940017523244 max memory_allocated 22560.36669921875 
[2025-03-02 05:07:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.031331293284893036 norm:0.00014886923599988222 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.031264036893844604 norm:0.00015156131121329963 max memory_allocated 22560.36669921875 
[2025-03-02 05:08:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.031247861683368683 norm:0.0001476068573538214 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.03118109703063965 norm:0.00015109805099200457 max memory_allocated 22560.36669921875 
[2025-03-02 05:09:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.031159551814198494 norm:0.00014645705232396722 max memory_allocated 22560.36669921875 
[2025-03-02 05:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.031146854162216187 norm:0.00013925270468462259 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.03117491863667965 norm:0.00015912465460132807 max memory_allocated 22560.36669921875 
[2025-03-02 05:11:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.031139925122261047 norm:0.00014216113777365535 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.03115205280482769 norm:0.00015003353473730385 max memory_allocated 22560.36669921875 
[2025-03-02 05:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.031168360263109207 norm:0.00014638628636021167 max memory_allocated 22560.36669921875 
[2025-03-02 05:13:14 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.031154226511716843 norm:0.00015638081822544336 max memory_allocated 22560.36669921875 
[2025-03-02 05:13:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 05:14:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.052799805998802185 norm:0.0012280476512387395 max memory_allocated 22560.53857421875 
[2025-03-02 05:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.04355741664767265 norm:0.0005965678719803691 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.038263950496912 norm:0.00035566938458941877 max memory_allocated 22560.53857421875 
[2025-03-02 05:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.03676129877567291 norm:0.0002550952194724232 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.03585943952202797 norm:0.00020242863683961332 max memory_allocated 22560.53857421875 
[2025-03-02 05:16:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.03540211543440819 norm:0.000184203265234828 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.035168327391147614 norm:0.0001793407427612692 max memory_allocated 22560.53857421875 
[2025-03-02 05:17:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.03500320762395859 norm:0.00015908520435914397 max memory_allocated 22560.53857421875 
[2025-03-02 05:18:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.03491535037755966 norm:0.00015569105744361877 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.03484460338950157 norm:0.00015265727415680885 max memory_allocated 22560.53857421875 
[2025-03-02 05:19:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.03474780544638634 norm:0.00013981887605041265 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.03471203148365021 norm:0.00013698151451535523 max memory_allocated 22560.53857421875 
[2025-03-02 05:20:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.034667354077100754 norm:0.00014618574641644955 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.03461778163909912 norm:0.000136564951390028 max memory_allocated 22560.53857421875 
[2025-03-02 05:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.03456984832882881 norm:0.00014065345749258995 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:24 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.03453514724969864 norm:0.000135514754219912 max memory_allocated 22560.53857421875 
[2025-03-02 05:22:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.03454151749610901 norm:0.000137334645842202 max memory_allocated 22560.53857421875 
[2025-03-02 05:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.0345379039645195 norm:0.0001316082925768569 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:05 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.03450312465429306 norm:0.00013089858111925423 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.0344836451113224 norm:0.00013069795386400074 max memory_allocated 22560.53857421875 
[2025-03-02 05:24:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 05:25:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.0501859076321125 norm:0.0008548659970983863 max memory_allocated 22560.71044921875 
[2025-03-02 05:25:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.0437500923871994 norm:0.0004137284413445741 max memory_allocated 22560.71044921875 
[2025-03-02 05:26:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.03978731483221054 norm:0.00024987710639834404 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.0385172963142395 norm:0.00018614355940371752 max memory_allocated 22560.71044921875 
[2025-03-02 05:27:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.037764813750982285 norm:0.00016149543807841837 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.03735208511352539 norm:0.0001356404391117394 max memory_allocated 22560.71044921875 
[2025-03-02 05:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.03714706003665924 norm:0.00012520777818281204 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:19 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.03704652935266495 norm:0.00011733653809642419 max memory_allocated 22560.71044921875 
[2025-03-02 05:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.03696661442518234 norm:0.00011020063539035618 max memory_allocated 22560.71044921875 
[2025-03-02 05:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.036886364221572876 norm:0.00011023852857761085 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.03684167563915253 norm:0.00010901418863795698 max memory_allocated 22560.71044921875 
[2025-03-02 05:31:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.03679526597261429 norm:0.00010912316793110222 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:07 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.03677147626876831 norm:0.00010234470391878858 max memory_allocated 22560.71044921875 
[2025-03-02 05:32:41 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.036776743829250336 norm:0.00010922116052825004 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.036745693534612656 norm:0.00010439315519761294 max memory_allocated 22560.71044921875 
[2025-03-02 05:33:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.03672097623348236 norm:0.00010879394540097564 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.036706000566482544 norm:0.000109294087451417 max memory_allocated 22560.71044921875 
[2025-03-02 05:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.03670012950897217 norm:0.0001108159776777029 max memory_allocated 22560.71044921875 
[2025-03-02 05:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.03669815510511398 norm:0.00010962154919980094 max memory_allocated 22560.71044921875 
[2025-03-02 05:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.03669145330786705 norm:0.00010280667629558593 max memory_allocated 22560.71044921875 
[2025-03-02 05:36:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 05:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.05243397131562233 norm:0.0009384087170474231 max memory_allocated 22560.88232421875 
[2025-03-02 05:37:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.04563724622130394 norm:0.00043655914487317204 max memory_allocated 22560.88232421875 
[2025-03-02 05:37:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.04141535982489586 norm:0.000265828100964427 max memory_allocated 22560.88232421875 
[2025-03-02 05:38:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.04012736305594444 norm:0.00017431161541026086 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.03942791372537613 norm:0.00014185340842232108 max memory_allocated 22560.88232421875 
[2025-03-02 05:39:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.0390196293592453 norm:0.00012470627552829683 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.03882939741015434 norm:0.00011733984138118103 max memory_allocated 22560.88232421875 
[2025-03-02 05:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.038717590272426605 norm:0.00011391223961254582 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:18 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.038629621267318726 norm:0.00010904778901021928 max memory_allocated 22560.88232421875 
[2025-03-02 05:41:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.03853686898946762 norm:0.00010728936467785388 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.0384812131524086 norm:0.00010254239168716595 max memory_allocated 22560.88232421875 
[2025-03-02 05:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.03846345469355583 norm:0.00010257342364639044 max memory_allocated 22560.88232421875 
[2025-03-02 05:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.038437485694885254 norm:0.0001040275747072883 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.03840989992022514 norm:0.00010138154902961105 max memory_allocated 22560.88232421875 
[2025-03-02 05:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.03839420527219772 norm:0.00010296089749317616 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.03838960826396942 norm:0.00010067239054478705 max memory_allocated 22560.88232421875 
[2025-03-02 05:45:46 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.03838841989636421 norm:0.00010284345626132563 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.03837596997618675 norm:9.95124428300187e-05 max memory_allocated 22560.88232421875 
[2025-03-02 05:46:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.0383722223341465 norm:9.879611752694473e-05 max memory_allocated 22560.88232421875 
[2025-03-02 05:47:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.03835950046777725 norm:0.00010074961028294638 max memory_allocated 22560.88232421875 
[2025-03-02 05:47:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 05:48:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.054604023694992065 norm:0.0006826648022979498 max memory_allocated 22561.05419921875 
[2025-03-02 05:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.04813721030950546 norm:0.0003600170894060284 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.043808985501527786 norm:0.00023733792477287352 max memory_allocated 22561.05419921875 
[2025-03-02 05:49:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.04241224750876427 norm:0.00018365304276812822 max memory_allocated 22561.05419921875 
[2025-03-02 05:50:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.04168263077735901 norm:0.00016393685655202717 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.04121749475598335 norm:0.00014449482841882855 max memory_allocated 22561.05419921875 
[2025-03-02 05:51:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.04091355949640274 norm:0.0001310973020736128 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.04075025022029877 norm:0.00012733608309645206 max memory_allocated 22561.05419921875 
[2025-03-02 05:52:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.04064583033323288 norm:0.00011887844448210672 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.04058154299855232 norm:0.00010925497190328315 max memory_allocated 22561.05419921875 
[2025-03-02 05:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.040508247911930084 norm:0.00010071405995404348 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.04045673832297325 norm:9.938082075677812e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:54:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.04040791839361191 norm:9.713358303997666e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:55:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.040381692349910736 norm:9.433420200366527e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.040346283465623856 norm:9.318892989540473e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:56:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.040333181619644165 norm:9.342200064565986e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.04029978811740875 norm:9.408138430444524e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:57:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.0402950681746006 norm:9.16839053388685e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.040309809148311615 norm:9.293751645600423e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.04030509293079376 norm:9.175368177238852e-05 max memory_allocated 22561.05419921875 
[2025-03-02 05:59:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 05:59:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.05609336122870445 norm:0.0006080268649384379 max memory_allocated 22561.22607421875 
[2025-03-02 06:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.04991751164197922 norm:0.0003127403906546533 max memory_allocated 22561.22607421875 
[2025-03-02 06:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.045631829649209976 norm:0.00020268028310965747 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.04440268501639366 norm:0.00016263581346720457 max memory_allocated 22561.22607421875 
[2025-03-02 06:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.043648600578308105 norm:0.0001397844753228128 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.04322284832596779 norm:0.00012387354217935354 max memory_allocated 22561.22607421875 
[2025-03-02 06:02:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.04297343268990517 norm:0.000116091723612044 max memory_allocated 22561.22607421875 
[2025-03-02 06:03:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.04285312443971634 norm:0.00010491580178495497 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.04276831075549126 norm:9.837793186306953e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:04:40 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.04269683361053467 norm:9.838865662459284e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.0426284596323967 norm:9.65335129876621e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.042575664818286896 norm:9.24546257010661e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:21 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.042558878660202026 norm:9.057611168827862e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:06:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.04253166541457176 norm:9.285052510676906e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:07:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.04251566901803017 norm:9.115551802096888e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.042479678988456726 norm:8.804995013633743e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.042451515793800354 norm:9.026257612276822e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:09:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.04243861138820648 norm:9.06544883036986e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.04242035374045372 norm:8.681832696311176e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.04239233583211899 norm:8.672987314639613e-05 max memory_allocated 22561.22607421875 
[2025-03-02 06:10:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 06:11:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.062258608639240265 norm:0.0011786380782723427 max memory_allocated 22561.39794921875 
[2025-03-02 06:11:36 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.05447398126125336 norm:0.0005554308881983161 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:09 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.04952928423881531 norm:0.0003262089448980987 max memory_allocated 22561.39794921875 
[2025-03-02 06:12:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.04809148982167244 norm:0.00023971448536030948 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.0472240149974823 norm:0.00018961314344778657 max memory_allocated 22561.39794921875 
[2025-03-02 06:13:50 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.046783968806266785 norm:0.00016149510338436812 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.046528566628694534 norm:0.00014190904039423913 max memory_allocated 22561.39794921875 
[2025-03-02 06:14:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.04637271538376808 norm:0.0001319700531894341 max memory_allocated 22561.39794921875 
[2025-03-02 06:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.04621868208050728 norm:0.0001234483061125502 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.046085942536592484 norm:0.00011995679960818961 max memory_allocated 22561.39794921875 
[2025-03-02 06:16:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.0460120253264904 norm:0.00011323233775328845 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.04596982151269913 norm:0.00010505158570595086 max memory_allocated 22561.39794921875 
[2025-03-02 06:17:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.045930687338113785 norm:0.00010430911788716912 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.04589888080954552 norm:0.00010238656250294298 max memory_allocated 22561.39794921875 
[2025-03-02 06:18:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.04585929960012436 norm:0.0001051030121743679 max memory_allocated 22561.39794921875 
[2025-03-02 06:19:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.04581502825021744 norm:0.00010055276652565226 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.04580772668123245 norm:9.740294626681134e-05 max memory_allocated 22561.39794921875 
[2025-03-02 06:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.04579170048236847 norm:0.00010131164162885398 max memory_allocated 22561.39794921875 
[2025-03-02 06:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.045751556754112244 norm:9.499015868641436e-05 max memory_allocated 22561.39794921875 
[2025-03-02 06:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.045727819204330444 norm:9.824066364672035e-05 max memory_allocated 22561.39794921875 
[2025-03-02 06:21:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 06:22:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.0641859918832779 norm:0.0008054758072830737 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.05755411088466644 norm:0.0003984363575000316 max memory_allocated 22561.56982421875 
[2025-03-02 06:23:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.05276763066649437 norm:0.0002442113764118403 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.05131763219833374 norm:0.00017384836974088103 max memory_allocated 22561.56982421875 
[2025-03-02 06:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.05050760880112648 norm:0.0001490958093199879 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.050045520067214966 norm:0.0001369039819110185 max memory_allocated 22561.56982421875 
[2025-03-02 06:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.04981208220124245 norm:0.00011964107397943735 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.049649059772491455 norm:0.00010713744268286973 max memory_allocated 22561.56982421875 
[2025-03-02 06:26:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.04956530034542084 norm:9.79433607426472e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:27:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.049526479095220566 norm:0.00011230688687646762 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:03 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.049419086426496506 norm:9.846778266364709e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:28:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.04935632273554802 norm:9.647115075495094e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:10 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.04930589348077774 norm:9.226732072420418e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:29:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.04929940402507782 norm:9.35265634325333e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.04927578195929527 norm:9.010380017571151e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:30:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.04925243929028511 norm:9.005483298096806e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.0492335669696331 norm:9.95762602542527e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:31:58 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.04920555651187897 norm:9.366533777210861e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:32:32 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.04918105527758598 norm:0.00010211667540716007 max memory_allocated 22561.56982421875 
[2025-03-02 06:33:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.04914802312850952 norm:9.10328672034666e-05 max memory_allocated 22561.56982421875 
[2025-03-02 06:33:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 06:33:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.07230954617261887 norm:0.0010839984752237797 max memory_allocated 22561.74169921875 
[2025-03-02 06:34:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.06377234309911728 norm:0.0004341499588917941 max memory_allocated 22561.74169921875 
[2025-03-02 06:34:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.058178260922431946 norm:0.00025413354160264134 max memory_allocated 22561.74169921875 
[2025-03-02 06:35:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.05665738508105278 norm:0.00019914735457859933 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.05579787492752075 norm:0.0001741604064591229 max memory_allocated 22561.74169921875 
[2025-03-02 06:36:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.0553489550948143 norm:0.00015009900380391628 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.055128052830696106 norm:0.00014457992801908404 max memory_allocated 22561.74169921875 
[2025-03-02 06:37:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.05493995174765587 norm:0.00013386089995037764 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.05476757884025574 norm:0.00011937660747207701 max memory_allocated 22561.74169921875 
[2025-03-02 06:38:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.05465276166796684 norm:0.00012112081458326429 max memory_allocated 22561.74169921875 
[2025-03-02 06:39:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.05463068559765816 norm:0.00011807110422523692 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.05456113815307617 norm:0.00011010329035343602 max memory_allocated 22561.74169921875 
[2025-03-02 06:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.05445779860019684 norm:0.00010880414629355073 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.05440601706504822 norm:0.00010768612992251292 max memory_allocated 22561.74169921875 
[2025-03-02 06:41:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.054376810789108276 norm:0.00010273291991325095 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.05434911698102951 norm:0.00010162147373193875 max memory_allocated 22561.74169921875 
[2025-03-02 06:42:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.05433810129761696 norm:0.0001067797202267684 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.05433257296681404 norm:0.00010815968562383205 max memory_allocated 22561.74169921875 
[2025-03-02 06:43:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.05429373309016228 norm:0.00010459912300575525 max memory_allocated 22561.74169921875 
[2025-03-02 06:44:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.05426385998725891 norm:0.00010421540355309844 max memory_allocated 22561.74169921875 
[2025-03-02 06:44:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 06:45:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.07241304218769073 norm:0.002093055984005332 max memory_allocated 22561.91357421875 
[2025-03-02 06:45:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.06678871065378189 norm:0.0007643551216460764 max memory_allocated 22561.91357421875 
[2025-03-02 06:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.06340844184160233 norm:0.00039533947710879147 max memory_allocated 22561.91357421875 
[2025-03-02 06:46:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.06141833961009979 norm:0.0002814701001625508 max memory_allocated 22561.91357421875 
[2025-03-02 06:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.06047161668539047 norm:0.0002162006130674854 max memory_allocated 22561.91357421875 
[2025-03-02 06:48:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.0601317472755909 norm:0.00019164841796737164 max memory_allocated 22561.91357421875 
[2025-03-02 06:48:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.059973448514938354 norm:0.00017986763850785792 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.05989181622862816 norm:0.00015372548659797758 max memory_allocated 22561.91357421875 
[2025-03-02 06:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.0598384290933609 norm:0.0001355565618723631 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.05976147577166557 norm:0.0001304427714785561 max memory_allocated 22561.91357421875 
[2025-03-02 06:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.05971348658204079 norm:0.00012121712643420324 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.05971458554267883 norm:0.00011488343443488702 max memory_allocated 22561.91357421875 
[2025-03-02 06:51:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.0597081258893013 norm:0.00011682341573759913 max memory_allocated 22561.91357421875 
[2025-03-02 06:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.05968406796455383 norm:0.00010879482579184696 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.05966277793049812 norm:0.00010732575174188241 max memory_allocated 22561.91357421875 
[2025-03-02 06:53:40 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.05966916307806969 norm:0.0001080308502423577 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.059646107256412506 norm:0.00010720839782152325 max memory_allocated 22561.91357421875 
[2025-03-02 06:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.0596376396715641 norm:0.00010841645416803658 max memory_allocated 22561.91357421875 
[2025-03-02 06:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.059662360697984695 norm:0.00011058914242312312 max memory_allocated 22561.91357421875 
[2025-03-02 06:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.059628941118717194 norm:0.00010881996422540396 max memory_allocated 22561.91357421875 
[2025-03-02 06:56:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 06:56:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.07811270654201508 norm:0.0014537489041686058 max memory_allocated 22562.08544921875 
[2025-03-02 06:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.0735883042216301 norm:0.0005162243032827973 max memory_allocated 22562.08544921875 
[2025-03-02 06:57:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.07078921794891357 norm:0.00028704319265671074 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.06890718638896942 norm:0.00021664837549906224 max memory_allocated 22562.08544921875 
[2025-03-02 06:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.0680316686630249 norm:0.00017207699420396239 max memory_allocated 22562.08544921875 
[2025-03-02 06:59:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.06778967380523682 norm:0.00016053572471719235 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.06766490638256073 norm:0.000143440454849042 max memory_allocated 22562.08544921875 
[2025-03-02 07:00:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.06756642460823059 norm:0.00013369675434660167 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.0675240159034729 norm:0.00011804792302427813 max memory_allocated 22562.08544921875 
[2025-03-02 07:01:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.0675073117017746 norm:0.00011193069076398388 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.06750807166099548 norm:0.0001108989745262079 max memory_allocated 22562.08544921875 
[2025-03-02 07:02:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.0674864873290062 norm:0.00010323031165171415 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.06745775043964386 norm:0.00010211290646111593 max memory_allocated 22562.08544921875 
[2025-03-02 07:03:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.06743481755256653 norm:0.00010115362238138914 max memory_allocated 22562.08544921875 
[2025-03-02 07:04:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.06741640716791153 norm:0.00010212113556917757 max memory_allocated 22562.08544921875 
[2025-03-02 07:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.0673990398645401 norm:0.00010052105062641203 max memory_allocated 22562.08544921875 
[2025-03-02 07:05:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.0673782154917717 norm:0.00010134347394341603 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.06738732010126114 norm:0.0001005047743092291 max memory_allocated 22562.08544921875 
[2025-03-02 07:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.06743259727954865 norm:0.00010294694220647216 max memory_allocated 22562.08544921875 
[2025-03-02 07:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.06741958111524582 norm:0.00010337533603888005 max memory_allocated 22562.08544921875 
[2025-03-02 07:07:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 07:08:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.08841290324926376 norm:0.001579355914145708 max memory_allocated 22562.25732421875 
[2025-03-02 07:08:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.08405931293964386 norm:0.0006097711157053709 max memory_allocated 22562.25732421875 
[2025-03-02 07:09:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.08097662031650543 norm:0.0003188021364621818 max memory_allocated 22562.25732421875 
[2025-03-02 07:09:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.07895846664905548 norm:0.00024383686832152307 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.07814311236143112 norm:0.00020735889847856015 max memory_allocated 22562.25732421875 
[2025-03-02 07:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.07790016382932663 norm:0.00017347795073874295 max memory_allocated 22562.25732421875 
[2025-03-02 07:11:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.07779491692781448 norm:0.00017824112728703767 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.07769662886857986 norm:0.0001544958504382521 max memory_allocated 22562.25732421875 
[2025-03-02 07:12:35 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.07766135036945343 norm:0.00015050322690512985 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.07760205119848251 norm:0.0001339065347565338 max memory_allocated 22562.25732421875 
[2025-03-02 07:13:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.07759635150432587 norm:0.00012858165428042412 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.07759346812963486 norm:0.00013398154987953603 max memory_allocated 22562.25732421875 
[2025-03-02 07:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.07754583656787872 norm:0.00012329017044976354 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.07753929495811462 norm:0.00012923212489113212 max memory_allocated 22562.25732421875 
[2025-03-02 07:15:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.07754672318696976 norm:0.00012419938866514713 max memory_allocated 22562.25732421875 
[2025-03-02 07:16:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.0775298997759819 norm:0.00012314552441239357 max memory_allocated 22562.25732421875 
[2025-03-02 07:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.0774955227971077 norm:0.00012081256863893941 max memory_allocated 22562.25732421875 
[2025-03-02 07:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.07749024778604507 norm:0.0001221041748067364 max memory_allocated 22562.25732421875 
[2025-03-02 07:18:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.07749035209417343 norm:0.00012227734259795398 max memory_allocated 22562.25732421875 
[2025-03-02 07:18:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.0774846002459526 norm:0.00012072394019924104 max memory_allocated 22562.25732421875 
[2025-03-02 07:18:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 07:19:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.10869036614894867 norm:0.0045586745254695415 max memory_allocated 22562.42919921875 
[2025-03-02 07:20:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.10065001994371414 norm:0.0013497998006641865 max memory_allocated 22562.42919921875 
[2025-03-02 07:20:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.09602387249469757 norm:0.0005370944272726774 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.09358153492212296 norm:0.00043379870476201177 max memory_allocated 22562.42919921875 
[2025-03-02 07:21:46 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.09267020225524902 norm:0.0003705376584548503 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.09232491254806519 norm:0.00030825723661109805 max memory_allocated 22562.42919921875 
[2025-03-02 07:22:53 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.09212587773799896 norm:0.0002863503759726882 max memory_allocated 22562.42919921875 
[2025-03-02 07:23:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.09196199476718903 norm:0.0002521169080864638 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.09190044552087784 norm:0.00025693868519738317 max memory_allocated 22562.42919921875 
[2025-03-02 07:24:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.09179876744747162 norm:0.0002190145751228556 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.0917334333062172 norm:0.00020040060917381197 max memory_allocated 22562.42919921875 
[2025-03-02 07:25:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.09166114032268524 norm:0.00018869925406761467 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.09161102026700974 norm:0.00017423159442842007 max memory_allocated 22562.42919921875 
[2025-03-02 07:26:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.0916428342461586 norm:0.00016206335567403585 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.09160415828227997 norm:0.00016179266094695777 max memory_allocated 22562.42919921875 
[2025-03-02 07:27:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.09157954901456833 norm:0.00015719537623226643 max memory_allocated 22562.42919921875 
[2025-03-02 07:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.09156884998083115 norm:0.0001578776864334941 max memory_allocated 22562.42919921875 
[2025-03-02 07:29:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.0915907621383667 norm:0.00015617962344549596 max memory_allocated 22562.42919921875 
[2025-03-02 07:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.09160225093364716 norm:0.00017033136100508273 max memory_allocated 22562.42919921875 
[2025-03-02 07:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.09162100404500961 norm:0.00015143753262236714 max memory_allocated 22562.42919921875 
[2025-03-02 07:30:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 07:30:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.11966832727193832 norm:0.0013276665704324841 max memory_allocated 22562.60107421875 
[2025-03-02 07:31:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.11565382033586502 norm:0.0005307826213538647 max memory_allocated 22562.60107421875 
[2025-03-02 07:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.11228284984827042 norm:0.0004038785700686276 max memory_allocated 22562.60107421875 
[2025-03-02 07:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.11011861264705658 norm:0.00036317738704383373 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.10912773758172989 norm:0.0002986782055813819 max memory_allocated 22562.60107421875 
[2025-03-02 07:33:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.10883370041847229 norm:0.00026027101557701826 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.10873657464981079 norm:0.0003274435002822429 max memory_allocated 22562.60107421875 
[2025-03-02 07:34:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.10855820775032043 norm:0.00023109350877348334 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.10843304544687271 norm:0.00020158456754870713 max memory_allocated 22562.60107421875 
[2025-03-02 07:35:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.1083696186542511 norm:0.00023284758208319545 max memory_allocated 22562.60107421875 
[2025-03-02 07:36:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.10833252966403961 norm:0.0002163940080208704 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.10830743610858917 norm:0.0002071435155812651 max memory_allocated 22562.60107421875 
[2025-03-02 07:37:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.1082645058631897 norm:0.00020006735576316714 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.10821739584207535 norm:0.0002336852194275707 max memory_allocated 22562.60107421875 
[2025-03-02 07:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.10818853974342346 norm:0.0002174778637709096 max memory_allocated 22562.60107421875 
[2025-03-02 07:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.10823925584554672 norm:0.00023040725500322878 max memory_allocated 22562.60107421875 
[2025-03-02 07:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.10824476182460785 norm:0.00024412859056610614 max memory_allocated 22562.60107421875 
[2025-03-02 07:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.10816490650177002 norm:0.00019807839998975396 max memory_allocated 22562.60107421875 
[2025-03-02 07:41:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.10813020169734955 norm:0.00021681418002117425 max memory_allocated 22562.60107421875 
[2025-03-02 07:41:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.10818497091531754 norm:0.000215769701753743 max memory_allocated 22562.60107421875 
[2025-03-02 07:41:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 07:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.13764283061027527 norm:0.002018435625359416 max memory_allocated 22562.77294921875 
[2025-03-02 07:42:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.13306844234466553 norm:0.0008669947274029255 max memory_allocated 22562.77294921875 
[2025-03-02 07:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.12945735454559326 norm:0.0004756434354931116 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.12705343961715698 norm:0.0003548967943061143 max memory_allocated 22562.77294921875 
[2025-03-02 07:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.12635594606399536 norm:0.0002878455852624029 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.1260906457901001 norm:0.00022212907788343728 max memory_allocated 22562.77294921875 
[2025-03-02 07:45:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.12594911456108093 norm:0.00020995283557567745 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.12584257125854492 norm:0.0001964495750144124 max memory_allocated 22562.77294921875 
[2025-03-02 07:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.12582318484783173 norm:0.00017791855498217046 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.12579038739204407 norm:0.0001789878006093204 max memory_allocated 22562.77294921875 
[2025-03-02 07:47:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.12579062581062317 norm:0.00018318579532206059 max memory_allocated 22562.77294921875 
[2025-03-02 07:48:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.12576869130134583 norm:0.00017239719454664737 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.12574663758277893 norm:0.00017132514039985836 max memory_allocated 22562.77294921875 
[2025-03-02 07:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.12569592893123627 norm:0.00017118988034781069 max memory_allocated 22562.77294921875 
[2025-03-02 07:50:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.12568657100200653 norm:0.00017490287427790463 max memory_allocated 22562.77294921875 
[2025-03-02 07:50:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.12568873167037964 norm:0.00017217895947396755 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.12564252316951752 norm:0.00017013304750435054 max memory_allocated 22562.77294921875 
[2025-03-02 07:51:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.12566488981246948 norm:0.00016947800759226084 max memory_allocated 22562.77294921875 
[2025-03-02 07:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.12564705312252045 norm:0.00017628638306632638 max memory_allocated 22562.77294921875 
[2025-03-02 07:53:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.12565915286540985 norm:0.00017600042338017374 max memory_allocated 22562.77294921875 
[2025-03-02 07:53:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 07:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.16200989484786987 norm:0.0019382513128221035 max memory_allocated 22562.94482421875 
[2025-03-02 07:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.1569238007068634 norm:0.000995846465229988 max memory_allocated 22562.94482421875 
[2025-03-02 07:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.15292157232761383 norm:0.0006398537079803646 max memory_allocated 22562.94482421875 
[2025-03-02 07:55:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.150095596909523 norm:0.00045437997323460877 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.14936625957489014 norm:0.0003768894821405411 max memory_allocated 22562.94482421875 
[2025-03-02 07:56:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.14893725514411926 norm:0.0002879183739423752 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.1487630009651184 norm:0.0002594343386590481 max memory_allocated 22562.94482421875 
[2025-03-02 07:57:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.14865897595882416 norm:0.00024019970442168415 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.1486303210258484 norm:0.00022625426936428994 max memory_allocated 22562.94482421875 
[2025-03-02 07:58:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.14863437414169312 norm:0.00021131693210918456 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.14852796494960785 norm:0.0002068247995339334 max memory_allocated 22562.94482421875 
[2025-03-02 07:59:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.14845801889896393 norm:0.00020143089932389557 max memory_allocated 22562.94482421875 
[2025-03-02 08:00:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.14848166704177856 norm:0.00020312206470407546 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.1484154760837555 norm:0.0002019183593802154 max memory_allocated 22562.94482421875 
[2025-03-02 08:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.14834171533584595 norm:0.0001976309431483969 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.14830751717090607 norm:0.00019536263425834477 max memory_allocated 22562.94482421875 
[2025-03-02 08:02:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.14828521013259888 norm:0.00019782419258262962 max memory_allocated 22562.94482421875 
[2025-03-02 08:03:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.148294597864151 norm:0.0001995189522858709 max memory_allocated 22562.94482421875 
[2025-03-02 08:03:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.1483016014099121 norm:0.00020305917132645845 max memory_allocated 22562.94482421875 
[2025-03-02 08:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.14827467501163483 norm:0.0001996390346903354 max memory_allocated 22562.94482421875 
[2025-03-02 08:04:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 08:05:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.18321342766284943 norm:0.0019125674152746797 max memory_allocated 22563.11669921875 
[2025-03-02 08:05:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.1791149079799652 norm:0.0009814061922952533 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.17454078793525696 norm:0.000488527410198003 max memory_allocated 22563.11669921875 
[2025-03-02 08:06:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.17170248925685883 norm:0.0003653837484307587 max memory_allocated 22563.11669921875 
[2025-03-02 08:07:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.17103350162506104 norm:0.00030648356187157333 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.1708071529865265 norm:0.0002848764997906983 max memory_allocated 22563.11669921875 
[2025-03-02 08:08:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.1706753671169281 norm:0.00024243541702162474 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.17055220901966095 norm:0.00022930547129362822 max memory_allocated 22563.11669921875 
[2025-03-02 08:09:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.17044669389724731 norm:0.00020966664305888116 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.17038410902023315 norm:0.0001937171764438972 max memory_allocated 22563.11669921875 
[2025-03-02 08:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.1703135371208191 norm:0.00018897939298767596 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.1702735722064972 norm:0.00018516399723012 max memory_allocated 22563.11669921875 
[2025-03-02 08:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.1702640801668167 norm:0.00018185412045568228 max memory_allocated 22563.11669921875 
[2025-03-02 08:12:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.17027069628238678 norm:0.00018449101480655372 max memory_allocated 22563.11669921875 
[2025-03-02 08:13:03 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.17025408148765564 norm:0.00018209473637398332 max memory_allocated 22563.11669921875 
[2025-03-02 08:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.17022304236888885 norm:0.00018070366058964282 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.1701715588569641 norm:0.00017698010196909308 max memory_allocated 22563.11669921875 
[2025-03-02 08:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.17012766003608704 norm:0.00017583051521796733 max memory_allocated 22563.11669921875 
[2025-03-02 08:15:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.17011748254299164 norm:0.0001760751474648714 max memory_allocated 22563.11669921875 
[2025-03-02 08:15:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.1701814830303192 norm:0.00017939350800588727 max memory_allocated 22563.11669921875 
[2025-03-02 08:16:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 08:16:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.21073821187019348 norm:0.0019313204102218151 max memory_allocated 22563.28857421875 
[2025-03-02 08:17:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.2059052288532257 norm:0.000952901435084641 max memory_allocated 22563.28857421875 
[2025-03-02 08:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.20091512799263 norm:0.0005607953644357622 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.19807937741279602 norm:0.0004213006468489766 max memory_allocated 22563.28857421875 
[2025-03-02 08:18:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.19743523001670837 norm:0.00033838386298157275 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.19720079004764557 norm:0.0002880782703869045 max memory_allocated 22563.28857421875 
[2025-03-02 08:19:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.19709861278533936 norm:0.00026791758136823773 max memory_allocated 22563.28857421875 
[2025-03-02 08:20:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.19700013101100922 norm:0.00023058359511196613 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.1969219446182251 norm:0.00020164737361483276 max memory_allocated 22563.28857421875 
[2025-03-02 08:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.1969107836484909 norm:0.00019552340381778777 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.19687223434448242 norm:0.00019231429905630648 max memory_allocated 22563.28857421875 
[2025-03-02 08:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.19684235751628876 norm:0.00018939931760542095 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.19679321348667145 norm:0.00018207775428891182 max memory_allocated 22563.28857421875 
[2025-03-02 08:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.19675078988075256 norm:0.00018095574341714382 max memory_allocated 22563.28857421875 
[2025-03-02 08:24:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.19671779870986938 norm:0.00018413229554425925 max memory_allocated 22563.28857421875 
[2025-03-02 08:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.19671005010604858 norm:0.00018220339552499354 max memory_allocated 22563.28857421875 
[2025-03-02 08:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.19669969379901886 norm:0.00018272676970809698 max memory_allocated 22563.28857421875 
[2025-03-02 08:26:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.19667541980743408 norm:0.0001819807366700843 max memory_allocated 22563.28857421875 
[2025-03-02 08:26:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.19668179750442505 norm:0.00018491076480131596 max memory_allocated 22563.28857421875 
[2025-03-02 08:27:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.19663837552070618 norm:0.00017870147712528706 max memory_allocated 22563.28857421875 
[2025-03-02 08:27:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 08:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.2467649281024933 norm:0.005705773830413818 max memory_allocated 22563.46044921875 
[2025-03-02 08:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.238673135638237 norm:0.002851806115359068 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.23168843984603882 norm:0.0017028049333021045 max memory_allocated 22563.46044921875 
[2025-03-02 08:29:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.2281951755285263 norm:0.0011324083898216486 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.22732871770858765 norm:0.0008271385449916124 max memory_allocated 22563.46044921875 
[2025-03-02 08:30:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.22694838047027588 norm:0.0006391293718479574 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.2266804426908493 norm:0.0005152487428858876 max memory_allocated 22563.46044921875 
[2025-03-02 08:31:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.22655360400676727 norm:0.0004242236609570682 max memory_allocated 22563.46044921875 
[2025-03-02 08:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.2263961136341095 norm:0.00036566026392392814 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.22629305720329285 norm:0.0003305122081656009 max memory_allocated 22563.46044921875 
[2025-03-02 08:33:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.22618240118026733 norm:0.0002995970717165619 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.22612006962299347 norm:0.0002828431024681777 max memory_allocated 22563.46044921875 
[2025-03-02 08:34:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.22610566020011902 norm:0.00026517215883359313 max memory_allocated 22563.46044921875 
[2025-03-02 08:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.2261173129081726 norm:0.00025562840164639056 max memory_allocated 22563.46044921875 
[2025-03-02 08:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.22607757151126862 norm:0.00024461332941427827 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.22608137130737305 norm:0.000245625211391598 max memory_allocated 22563.46044921875 
[2025-03-02 08:36:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.2260490208864212 norm:0.0002452482294756919 max memory_allocated 22563.46044921875 
[2025-03-02 08:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.22603543102741241 norm:0.00023936365323606879 max memory_allocated 22563.46044921875 
[2025-03-02 08:38:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.22602859139442444 norm:0.00023714535927865654 max memory_allocated 22563.46044921875 
[2025-03-02 08:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.22600580751895905 norm:0.00023598475672770292 max memory_allocated 22563.46044921875 
[2025-03-02 08:38:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 08:39:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.2720656394958496 norm:0.0028247255831956863 max memory_allocated 22563.63232421875 
[2025-03-02 08:39:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.26645296812057495 norm:0.0014864562544971704 max memory_allocated 22563.63232421875 
[2025-03-02 08:40:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.261070191860199 norm:0.0009461439913138747 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.25809136033058167 norm:0.0006664563552476466 max memory_allocated 22563.63232421875 
[2025-03-02 08:41:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.2574380040168762 norm:0.0005328171537257731 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.25708943605422974 norm:0.00041996894287876785 max memory_allocated 22563.63232421875 
[2025-03-02 08:42:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.25694555044174194 norm:0.00035786296939477324 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.2568073868751526 norm:0.00031589329591952264 max memory_allocated 22563.63232421875 
[2025-03-02 08:43:51 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.2566773593425751 norm:0.0002868202864192426 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.2566140294075012 norm:0.00027163352933712304 max memory_allocated 22563.63232421875 
[2025-03-02 08:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.2565855085849762 norm:0.00025905604707077146 max memory_allocated 22563.63232421875 
[2025-03-02 08:45:32 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.2564915716648102 norm:0.00025186920538544655 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.2564820647239685 norm:0.000245742907281965 max memory_allocated 22563.63232421875 
[2025-03-02 08:46:39 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.25638988614082336 norm:0.00022797960264142603 max memory_allocated 22563.63232421875 
[2025-03-02 08:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.25640588998794556 norm:0.00022628461010754108 max memory_allocated 22563.63232421875 
[2025-03-02 08:47:46 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.25638434290885925 norm:0.00022977584740146995 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.2563941478729248 norm:0.000225317373406142 max memory_allocated 22563.63232421875 
[2025-03-02 08:48:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.2563565969467163 norm:0.0002197055146098137 max memory_allocated 22563.63232421875 
[2025-03-02 08:49:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.2563360631465912 norm:0.00022928585531190038 max memory_allocated 22563.63232421875 
[2025-03-02 08:50:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.2563401162624359 norm:0.00022421873291023076 max memory_allocated 22563.63232421875 
[2025-03-02 08:50:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 08:50:12 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 08:50:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.31867748498916626 norm:0.01614520326256752 max memory_allocated 22563.91943359375 
[2025-03-02 08:51:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.3100288212299347 norm:0.012153406627476215 max memory_allocated 22563.91943359375 
[2025-03-02 08:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.3029724955558777 norm:0.008526967838406563 max memory_allocated 22563.91943359375 
[2025-03-02 08:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.2992498278617859 norm:0.00726421969011426 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:00 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.29835912585258484 norm:0.0062843747437000275 max memory_allocated 22563.91943359375 
[2025-03-02 08:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.29780811071395874 norm:0.005496498662978411 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.29741597175598145 norm:0.004740598611533642 max memory_allocated 22563.91943359375 
[2025-03-02 08:54:41 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.29708632826805115 norm:0.004116795491427183 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.2969667315483093 norm:0.003927930723875761 max memory_allocated 22563.91943359375 
[2025-03-02 08:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.2969971001148224 norm:0.004004774149507284 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.2970063090324402 norm:0.003953476902097464 max memory_allocated 22563.91943359375 
[2025-03-02 08:56:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.29698723554611206 norm:0.003957152366638184 max memory_allocated 22563.91943359375 
[2025-03-02 08:57:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.2970738410949707 norm:0.003508542198687792 max memory_allocated 22563.91943359375 
[2025-03-02 08:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.296907514333725 norm:0.0038015954196453094 max memory_allocated 22563.91943359375 
[2025-03-02 08:58:37 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.2968495488166809 norm:0.0033416850492358208 max memory_allocated 22563.91943359375 
[2025-03-02 08:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.2967427670955658 norm:0.0034450064413249493 max memory_allocated 22563.91943359375 
[2025-03-02 08:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.2966909110546112 norm:0.0032365238294005394 max memory_allocated 22563.91943359375 
[2025-03-02 09:00:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.2966376841068268 norm:0.003221784019842744 max memory_allocated 22563.91943359375 
[2025-03-02 09:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.29659563302993774 norm:0.0031603651586920023 max memory_allocated 22563.91943359375 
[2025-03-02 09:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.29657313227653503 norm:0.003049317514523864 max memory_allocated 22563.91943359375 
[2025-03-02 09:01:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 09:01:37 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:02:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.37001287937164307 norm:0.018077466636896133 max memory_allocated 22564.09130859375 
[2025-03-02 09:02:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.36058104038238525 norm:0.013038676232099533 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.3524744510650635 norm:0.009088382124900818 max memory_allocated 22564.09130859375 
[2025-03-02 09:03:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.3488234281539917 norm:0.007298785261809826 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.3478436768054962 norm:0.006227864418178797 max memory_allocated 22564.09130859375 
[2025-03-02 09:04:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.34729766845703125 norm:0.005307193845510483 max memory_allocated 22564.09130859375 
[2025-03-02 09:05:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.3468150794506073 norm:0.004523851443082094 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:06 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.34655147790908813 norm:0.004213239066302776 max memory_allocated 22564.09130859375 
[2025-03-02 09:06:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.3465878665447235 norm:0.004319892730563879 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.3465784192085266 norm:0.004408782348036766 max memory_allocated 22564.09130859375 
[2025-03-02 09:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.3464377820491791 norm:0.0039443811401724815 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:21 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.3463980555534363 norm:0.003970517311245203 max memory_allocated 22564.09130859375 
[2025-03-02 09:08:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.3464116156101227 norm:0.0036451672203838825 max memory_allocated 22564.09130859375 
[2025-03-02 09:09:28 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.346332311630249 norm:0.003548489650711417 max memory_allocated 22564.09130859375 
[2025-03-02 09:10:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.3461882174015045 norm:0.003304222598671913 max memory_allocated 22564.09130859375 
[2025-03-02 09:10:35 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.3462507128715515 norm:0.0034599334467202425 max memory_allocated 22564.09130859375 
[2025-03-02 09:11:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.34629541635513306 norm:0.0033893699292093515 max memory_allocated 22564.09130859375 
[2025-03-02 09:11:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.34630584716796875 norm:0.003368364181369543 max memory_allocated 22564.09130859375 
[2025-03-02 09:12:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.34621042013168335 norm:0.0031621912494301796 max memory_allocated 22564.09130859375 
[2025-03-02 09:12:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.34625062346458435 norm:0.00326176336966455 max memory_allocated 22564.09130859375 
[2025-03-02 09:12:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 09:13:02 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.4861128628253937 norm:0.01931334100663662 max memory_allocated 22564.26318359375 
[2025-03-02 09:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.4625398516654968 norm:0.0187558401376009 max memory_allocated 22564.26318359375 
[2025-03-02 09:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.4502427577972412 norm:0.01931232400238514 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.4449484348297119 norm:0.01984134316444397 max memory_allocated 22564.26318359375 
[2025-03-02 09:15:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.4428440034389496 norm:0.020340388640761375 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.4411298930644989 norm:0.019804297015070915 max memory_allocated 22564.26318359375 
[2025-03-02 09:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.4400637447834015 norm:0.019922852516174316 max memory_allocated 22564.26318359375 
[2025-03-02 09:17:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.4390678405761719 norm:0.019900918006896973 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.43824899196624756 norm:0.01830585114657879 max memory_allocated 22564.26318359375 
[2025-03-02 09:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.4377194344997406 norm:0.017415674403309822 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.4372525215148926 norm:0.016697824001312256 max memory_allocated 22564.26318359375 
[2025-03-02 09:19:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.43691062927246094 norm:0.015923667699098587 max memory_allocated 22564.26318359375 
[2025-03-02 09:20:20 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.4366971552371979 norm:0.01523887924849987 max memory_allocated 22564.26318359375 
[2025-03-02 09:20:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.436452180147171 norm:0.0144831333309412 max memory_allocated 22564.26318359375 
[2025-03-02 09:21:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.43630358576774597 norm:0.014561845920979977 max memory_allocated 22564.26318359375 
[2025-03-02 09:22:01 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.43619078397750854 norm:0.014115302823483944 max memory_allocated 22564.26318359375 
[2025-03-02 09:22:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.43616464734077454 norm:0.014286715537309647 max memory_allocated 22564.26318359375 
[2025-03-02 09:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.4360215663909912 norm:0.013764596544206142 max memory_allocated 22564.26318359375 
[2025-03-02 09:23:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.43612223863601685 norm:0.013790826313197613 max memory_allocated 22564.26318359375 
[2025-03-02 09:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.4361242651939392 norm:0.013427464291453362 max memory_allocated 22564.26318359375 
[2025-03-02 09:24:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 09:24:29 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 09:25:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.862119734287262 norm:0.04812490567564964 max memory_allocated 22564.43505859375 
[2025-03-02 09:25:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.8132494688034058 norm:0.034933146089315414 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.7842487096786499 norm:0.02993774227797985 max memory_allocated 22564.43505859375 
[2025-03-02 09:26:44 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.7676421999931335 norm:0.028448622673749924 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:17 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.7600393891334534 norm:0.03086058795452118 max memory_allocated 22564.43505859375 
[2025-03-02 09:27:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.7547386288642883 norm:0.03230413794517517 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.7496863007545471 norm:0.02948855422437191 max memory_allocated 22564.43505859375 
[2025-03-02 09:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.7451983690261841 norm:0.02767697162926197 max memory_allocated 22564.43505859375 
[2025-03-02 09:29:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.7425180077552795 norm:0.02787618339061737 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.741179347038269 norm:0.02698187530040741 max memory_allocated 22564.43505859375 
[2025-03-02 09:30:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.7398409247398376 norm:0.027016427367925644 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.7392310500144958 norm:0.027897562831640244 max memory_allocated 22564.43505859375 
[2025-03-02 09:31:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.7382253408432007 norm:0.02784348838031292 max memory_allocated 22564.43505859375 
[2025-03-02 09:32:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.7366837859153748 norm:0.02526785619556904 max memory_allocated 22564.43505859375 
[2025-03-02 09:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.735940158367157 norm:0.025647811591625214 max memory_allocated 22564.43505859375 
[2025-03-02 09:33:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.7348335981369019 norm:0.02405596897006035 max memory_allocated 22564.43505859375 
[2025-03-02 09:34:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.7341998219490051 norm:0.024629969149827957 max memory_allocated 22564.43505859375 
[2025-03-02 09:34:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.733852207660675 norm:0.024765104055404663 max memory_allocated 22564.43505859375 
[2025-03-02 09:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.7335509657859802 norm:0.027434244751930237 max memory_allocated 22564.43505859375 
[2025-03-02 09:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.7323570251464844 norm:0.023016348481178284 max memory_allocated 22564.43505859375 
[2025-03-02 09:35:53 root] (main_calib_config2.py 380): INFO 21909.71629691124
[2025-03-02 09:35:58 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-02 09:37:09 root] (main_calib_config2.py 159): INFO wikitext2 : 5.842095851898193
[2025-03-02 09:37:09 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-02 09:38:58 root] (main_calib_config2.py 159): INFO c4 : 7.337431907653809
[2025-03-02 11:18:11 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.842095851898193, 'c4': 7.337431907653809, 'results': {'hellaswag': {'acc': 0.5505875323640709, 'acc_stderr': 0.004964177035221421, 'acc_norm': 0.7164907388966342, 'acc_norm_stderr': 0.004497803024345145}, 'arc_easy': {'acc': 0.6725589225589226, 'acc_stderr': 0.009629415859100609, 'acc_norm': 0.5260942760942761, 'acc_norm_stderr': 0.010245801990240054}, 'arc_challenge': {'acc': 0.3856655290102389, 'acc_stderr': 0.01422425097325717, 'acc_norm': 0.3984641638225256, 'acc_norm_stderr': 0.014306946052735569}, 'winogrande': {'acc': 0.6503551696921863, 'acc_stderr': 0.013402073680850508}, 'piqa': {'acc': 0.7747551686615887, 'acc_stderr': 0.009746643471032155, 'acc_norm': 0.7709466811751904, 'acc_norm_stderr': 0.009804509865175505}, 'boolq': {'acc': 0.7296636085626911, 'acc_stderr': 0.007767944951388912}}, 'versions': {'hellaswag': 0, 'arc_easy': 0, 'arc_challenge': 0, 'winogrande': 0, 'piqa': 0, 'boolq': 1}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
