[2025-03-02 12:49:23 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.85', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.85.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.85.pkl
[2025-03-02 12:52:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.005081752315163612 norm:0.004723029211163521 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0030420285183936357 norm:0.0031397121492773294 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0025509463157504797 norm:0.0024353349581360817 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.002300884574651718 norm:0.001999391708523035 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.002149722073227167 norm:0.0017188889905810356 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.002038628561422229 norm:0.0015149898827075958 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:32 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.001950758509337902 norm:0.001355821848846972 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0018764312844723463 norm:0.0012229103595018387 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0018334046471863985 norm:0.0011327755637466908 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0018168651731684804 norm:0.001042380928993225 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0018147083465009928 norm:0.0009327623411081731 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0017842259258031845 norm:0.000889469578396529 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0017969155451282859 norm:0.000876365986187011 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.001787551329471171 norm:0.0008078160462900996 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001770390896126628 norm:0.0008155338000506163 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.001766468514688313 norm:0.0007576371426694095 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0017757234163582325 norm:0.0007655985536985099 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0017586847534403205 norm:0.0007143114926293492 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.001755062723532319 norm:0.0006966231158003211 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0017442593816667795 norm:0.000666047097183764 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:46 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.008384671062231064 norm:0.005128906108438969 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.006226418074220419 norm:0.004411187954246998 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.00557071715593338 norm:0.0034706012811511755 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:07 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.005208645947277546 norm:0.002773199463263154 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.005040072835981846 norm:0.0023651656229048967 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:48 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.004958611447364092 norm:0.0020136795938014984 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.004855121951550245 norm:0.0016677051316946745 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.004735840950161219 norm:0.0014061187393963337 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.004654296208173037 norm:0.0012168471002951264 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.004606937523931265 norm:0.0012021801667287946 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.004619913641363382 norm:0.0012170958798378706 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.004583083558827639 norm:0.0011903258273378015 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.004581227898597717 norm:0.0012141495244577527 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.004450645763427019 norm:0.0009014694369398057 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.004407420288771391 norm:0.0009091305546462536 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.00445847911760211 norm:0.0010475933086127043 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:03 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.004403747618198395 norm:0.0008285981020890176 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.004347291775047779 norm:0.0008164314203895628 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004466155543923378 norm:0.0009541742037981749 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:34 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.004377164412289858 norm:0.0007839686004444957 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:53 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.022260235622525215 norm:0.010014600120484829 max memory_allocated 29268.39501953125 
[2025-03-02 13:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.01687333732843399 norm:0.008177898824214935 max memory_allocated 29268.39501953125 
[2025-03-02 13:29:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.014671774581074715 norm:0.008035263046622276 max memory_allocated 29268.39501953125 
[2025-03-02 13:30:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.012990315444767475 norm:0.00645441934466362 max memory_allocated 29268.39501953125 
[2025-03-02 13:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.012095758691430092 norm:0.005373494233936071 max memory_allocated 29268.39501953125 
[2025-03-02 13:31:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.011376787908375263 norm:0.00433033611625433 max memory_allocated 29268.39501953125 
[2025-03-02 13:32:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.01070424634963274 norm:0.0035029142163693905 max memory_allocated 29268.39501953125 
[2025-03-02 13:33:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.0103683490306139 norm:0.003682642476633191 max memory_allocated 29268.39501953125 
[2025-03-02 13:34:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.010123159736394882 norm:0.00336093595251441 max memory_allocated 29268.39501953125 
[2025-03-02 13:35:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.009956998750567436 norm:0.0031552191358059645 max memory_allocated 29268.39501953125 
[2025-03-02 13:36:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.009859852492809296 norm:0.0029464990366250277 max memory_allocated 29268.39501953125 
[2025-03-02 13:36:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.009771355427801609 norm:0.002857855288311839 max memory_allocated 29268.39501953125 
[2025-03-02 13:37:48 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.009722602553665638 norm:0.0027405759319663048 max memory_allocated 29268.39501953125 
[2025-03-02 13:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.009599444456398487 norm:0.0027641435153782368 max memory_allocated 29268.39501953125 
[2025-03-02 13:39:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.00963651668280363 norm:0.002932529430836439 max memory_allocated 29268.39501953125 
[2025-03-02 13:40:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.009539242833852768 norm:0.0022977045737206936 max memory_allocated 29268.39501953125 
[2025-03-02 13:41:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.009536406956613064 norm:0.002282131230458617 max memory_allocated 29268.39501953125 
[2025-03-02 13:42:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.009465828537940979 norm:0.002190064173191786 max memory_allocated 29268.39501953125 
[2025-03-02 13:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.009435757994651794 norm:0.002232055179774761 max memory_allocated 29268.39501953125 
[2025-03-02 13:43:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.009429019875824451 norm:0.002118632895871997 max memory_allocated 29268.39501953125 
[2025-03-02 13:43:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:44:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.015467168763279915 norm:0.0016076336614787579 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.012962115928530693 norm:0.0006586879026144743 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.012109619565308094 norm:0.0003954421554226428 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.011679536662995815 norm:0.00027145547210238874 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.011292370967566967 norm:0.00017411420412827283 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:02 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.01096247136592865 norm:0.00014702192856930196 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.010734708979725838 norm:0.00015203905059024692 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.010626080445945263 norm:0.00014844167162664235 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:33 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.010577404871582985 norm:0.00012664386304095387 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.010555518791079521 norm:0.00012779829557985067 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.010539982467889786 norm:0.00011509838805068284 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.010526205413043499 norm:0.00012678344501182437 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.010523390956223011 norm:0.00012489901564549655 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.010510340332984924 norm:0.00013351776578929275 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:35 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.010506144724786282 norm:0.0001394365099258721 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.01050708070397377 norm:0.00012824998702853918 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.010503239929676056 norm:0.00013239961117506027 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.01049304660409689 norm:0.00013540207874029875 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.010494109243154526 norm:0.0001319617877015844 max memory_allocated 29268.43798828125 
[2025-03-02 14:00:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.010493895970284939 norm:0.0001265481987502426 max memory_allocated 29268.43798828125 
[2025-03-02 14:01:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:01:55 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.021455898880958557 norm:0.0033051047939807177 max memory_allocated 29268.43798828125 
[2025-03-02 14:02:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.017282648012042046 norm:0.0010416554287075996 max memory_allocated 29268.43798828125 
[2025-03-02 14:03:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.016045179218053818 norm:0.0005710810655727983 max memory_allocated 29268.43798828125 
[2025-03-02 14:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.01534714549779892 norm:0.00041907705599442124 max memory_allocated 29268.43798828125 
[2025-03-02 14:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.014785170555114746 norm:0.0003383340663276613 max memory_allocated 29268.43798828125 
[2025-03-02 14:06:06 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.01438983716070652 norm:0.00028048414969816804 max memory_allocated 29268.43798828125 
[2025-03-02 14:06:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.014172125607728958 norm:0.0002360344078624621 max memory_allocated 29268.43798828125 
[2025-03-02 14:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.014078609645366669 norm:0.0002076217351714149 max memory_allocated 29268.43798828125 
[2025-03-02 14:08:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.014032178558409214 norm:0.0002018388477154076 max memory_allocated 29268.43798828125 
[2025-03-02 14:09:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.013995032757520676 norm:0.00016574765322729945 max memory_allocated 29268.43798828125 
[2025-03-02 14:10:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.013971689157187939 norm:0.00017142060096375644 max memory_allocated 29268.43798828125 
[2025-03-02 14:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.013950947672128677 norm:0.0001540010707685724 max memory_allocated 29268.43798828125 
[2025-03-02 14:11:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.013946392573416233 norm:0.0001437555911252275 max memory_allocated 29268.43798828125 
[2025-03-02 14:12:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.01392386108636856 norm:0.00013637312804348767 max memory_allocated 29268.43798828125 
[2025-03-02 14:13:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.013903682120144367 norm:0.00013185717398300767 max memory_allocated 29268.43798828125 
[2025-03-02 14:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.013900192454457283 norm:0.00013525249960366637 max memory_allocated 29268.43798828125 
[2025-03-02 14:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.013889612630009651 norm:0.00012610304111149162 max memory_allocated 29268.43798828125 
[2025-03-02 14:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.013879877515137196 norm:0.00012034408428007737 max memory_allocated 29268.43798828125 
[2025-03-02 14:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.013876705430448055 norm:0.00012590907863341272 max memory_allocated 29268.43798828125 
[2025-03-02 14:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.01386165339499712 norm:0.00011728305253200233 max memory_allocated 29268.43798828125 
[2025-03-02 14:18:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:19:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.029908034950494766 norm:0.0030994853004813194 max memory_allocated 29268.43798828125 
[2025-03-02 14:19:50 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.021318823099136353 norm:0.0010092913871631026 max memory_allocated 29268.43798828125 
[2025-03-02 14:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.01890728995203972 norm:0.0005585452308878303 max memory_allocated 29268.43798828125 
[2025-03-02 14:21:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.017785942181944847 norm:0.0003776165540330112 max memory_allocated 29268.43798828125 
[2025-03-02 14:22:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.017180874943733215 norm:0.00029567672754637897 max memory_allocated 29268.43798828125 
[2025-03-02 14:23:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.016802137717604637 norm:0.00024728706921450794 max memory_allocated 29268.43798828125 
[2025-03-02 14:24:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.016594678163528442 norm:0.0002150368527509272 max memory_allocated 29268.43798828125 
[2025-03-02 14:24:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.01647494174540043 norm:0.0002016684738919139 max memory_allocated 29268.43798828125 
[2025-03-02 14:25:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.016399022191762924 norm:0.00017499009845778346 max memory_allocated 29268.43798828125 
[2025-03-02 14:26:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.016345739364624023 norm:0.0001637769746594131 max memory_allocated 29268.43798828125 
[2025-03-02 14:27:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.016292063519358635 norm:0.00017179743736051023 max memory_allocated 29268.43798828125 
[2025-03-02 14:28:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.01629738137125969 norm:0.00017894523625727743 max memory_allocated 29268.43798828125 
[2025-03-02 14:29:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.016268523409962654 norm:0.0001598196104168892 max memory_allocated 29268.43798828125 
[2025-03-02 14:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.016213808208703995 norm:0.0001381407055305317 max memory_allocated 29268.43798828125 
[2025-03-02 14:30:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.016192669048905373 norm:0.00014901321264915168 max memory_allocated 29268.43798828125 
[2025-03-02 14:31:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.016203634440898895 norm:0.00014781084610149264 max memory_allocated 29268.43798828125 
[2025-03-02 14:32:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.016210779547691345 norm:0.00014976042439229786 max memory_allocated 29268.43798828125 
[2025-03-02 14:33:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.016202649101614952 norm:0.00015084570623002946 max memory_allocated 29268.43798828125 
[2025-03-02 14:34:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.01619016006588936 norm:0.0001494251046096906 max memory_allocated 29268.43798828125 
[2025-03-02 14:34:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.016193121671676636 norm:0.00014850734442006797 max memory_allocated 29268.43798828125 
[2025-03-02 14:35:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:36:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.0342298299074173 norm:0.0020716662984341383 max memory_allocated 29268.43798828125 
[2025-03-02 14:36:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.027262074872851372 norm:0.001290667918510735 max memory_allocated 29268.43798828125 
[2025-03-02 14:37:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.024157853797078133 norm:0.0008963355794548988 max memory_allocated 29268.43798828125 
[2025-03-02 14:38:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.022427914664149284 norm:0.0006835336098447442 max memory_allocated 29268.43798828125 
[2025-03-02 14:39:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.021743889898061752 norm:0.0005906642181798816 max memory_allocated 29268.43798828125 
[2025-03-02 14:40:15 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.021182740107178688 norm:0.0005333853187039495 max memory_allocated 29268.43798828125 
[2025-03-02 14:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.020827535539865494 norm:0.00048631930258125067 max memory_allocated 29268.43798828125 
[2025-03-02 14:41:56 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.02044602483510971 norm:0.00044986046850681305 max memory_allocated 29268.43798828125 
[2025-03-02 14:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.02022125944495201 norm:0.0003911464009433985 max memory_allocated 29268.43798828125 
[2025-03-02 14:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.02013060823082924 norm:0.00039874931098893285 max memory_allocated 29268.43798828125 
[2025-03-02 14:44:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.020082639530301094 norm:0.0003878214629366994 max memory_allocated 29268.43798828125 
[2025-03-02 14:45:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.020035039633512497 norm:0.0005106634926050901 max memory_allocated 29268.43798828125 
[2025-03-02 14:46:07 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.020007425919175148 norm:0.00037558222538791597 max memory_allocated 29268.43798828125 
[2025-03-02 14:46:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.019976157695055008 norm:0.0003499515005387366 max memory_allocated 29268.43798828125 
[2025-03-02 14:47:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.019905587658286095 norm:0.000310593779431656 max memory_allocated 29268.43798828125 
[2025-03-02 14:48:38 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.019918767735362053 norm:0.00035128509625792503 max memory_allocated 29268.43798828125 
[2025-03-02 14:49:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.019901148974895477 norm:0.00033720748615451157 max memory_allocated 29268.43798828125 
[2025-03-02 14:50:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.01993565633893013 norm:0.00032805942464619875 max memory_allocated 29268.43798828125 
[2025-03-02 14:51:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.019907858222723007 norm:0.00031795440008863807 max memory_allocated 29268.43798828125 
[2025-03-02 14:51:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.019948001950979233 norm:0.000356910633854568 max memory_allocated 29268.43798828125 
[2025-03-02 14:52:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:53:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.02933409996330738 norm:0.0013711045030504465 max memory_allocated 29268.43798828125 
[2025-03-02 14:53:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.025542346760630608 norm:0.0006054423865862191 max memory_allocated 29268.43798828125 
[2025-03-02 14:54:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.024140754714608192 norm:0.00030207663075998425 max memory_allocated 29268.43798828125 
[2025-03-02 14:55:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.02333894558250904 norm:0.0001786044449545443 max memory_allocated 29268.43798828125 
[2025-03-02 14:56:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.022787999361753464 norm:0.00013864177162759006 max memory_allocated 29268.43798828125 
[2025-03-02 14:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.022435635328292847 norm:0.00012692071322817355 max memory_allocated 29268.43798828125 
[2025-03-02 14:58:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.022275380790233612 norm:0.00011776213068515062 max memory_allocated 29268.43798828125 
[2025-03-02 14:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.022192854434251785 norm:0.00011542989523150027 max memory_allocated 29268.43798828125 
[2025-03-02 14:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.022144755348563194 norm:0.00010924282833002508 max memory_allocated 29268.43798828125 
[2025-03-02 15:00:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.022117486223578453 norm:0.00011062140401918441 max memory_allocated 29268.43798828125 
[2025-03-02 15:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.022102508693933487 norm:0.00011041497782571241 max memory_allocated 29268.43798828125 
[2025-03-02 15:02:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.022081948816776276 norm:0.00011081554839620367 max memory_allocated 29268.43798828125 
[2025-03-02 15:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.02208288386464119 norm:0.00011528075265232474 max memory_allocated 29268.43798828125 
[2025-03-02 15:04:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.022063978016376495 norm:0.00010952351294690743 max memory_allocated 29268.43798828125 
[2025-03-02 15:04:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.022053107619285583 norm:0.00010722650040406734 max memory_allocated 29268.43798828125 
[2025-03-02 15:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.022057602182030678 norm:0.00011526346497703344 max memory_allocated 29268.43798828125 
[2025-03-02 15:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.022051924839615822 norm:0.00010805787314893678 max memory_allocated 29268.43798828125 
[2025-03-02 15:07:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.022042805328965187 norm:0.0001088814387912862 max memory_allocated 29268.43798828125 
[2025-03-02 15:08:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.022030828520655632 norm:0.00010676770762074739 max memory_allocated 29268.43798828125 
[2025-03-02 15:09:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.02203603833913803 norm:0.00011000558151863515 max memory_allocated 29268.43798828125 
[2025-03-02 15:09:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:10:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.03225273638963699 norm:0.0014885269338265061 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:03 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.028297794982790947 norm:0.000604890868999064 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.02690955251455307 norm:0.0003043165779672563 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.02609686367213726 norm:0.00019320109277032316 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.025481734424829483 norm:0.00015519902808591723 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.025139685720205307 norm:0.00013531239528674632 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.024959798902273178 norm:0.00012577012239489704 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.02486083284020424 norm:0.00011655344133032486 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.02481621690094471 norm:0.0001103910180972889 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.02479749172925949 norm:0.00011176135012647137 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.024773454293608665 norm:0.00010709976777434349 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.02476145140826702 norm:0.00010522308730287477 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.02474881336092949 norm:0.00010424916399642825 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.024731770157814026 norm:0.00010658442624844611 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.024715587496757507 norm:0.00010502958321012557 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.024709470570087433 norm:0.00010485020175110549 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.02471085824072361 norm:0.00010527666745474562 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.02472158893942833 norm:0.00010239947732770815 max memory_allocated 29269.37548828125 
[2025-03-02 15:25:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.024704139679670334 norm:0.00010151430615223944 max memory_allocated 29269.37548828125 
[2025-03-02 15:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.024692345410585403 norm:0.00010240125993732363 max memory_allocated 29269.37548828125 
[2025-03-02 15:26:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:27:18 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.0337584987282753 norm:0.0012111023534089327 max memory_allocated 29269.37548828125 
[2025-03-02 15:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.03028130903840065 norm:0.0005060583935119212 max memory_allocated 29269.37548828125 
[2025-03-02 15:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.028960689902305603 norm:0.0002533729712013155 max memory_allocated 29269.37548828125 
[2025-03-02 15:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.028197044506669044 norm:0.00016056993626989424 max memory_allocated 29269.37548828125 
[2025-03-02 15:30:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.027624856680631638 norm:0.00012495525879785419 max memory_allocated 29269.37548828125 
[2025-03-02 15:31:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.027291279286146164 norm:0.00011206873023184016 max memory_allocated 29269.37548828125 
[2025-03-02 15:32:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.027114298194646835 norm:0.00010407849913462996 max memory_allocated 29269.37548828125 
[2025-03-02 15:33:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.027054063975811005 norm:9.890860383166e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.027024541050195694 norm:9.772554039955139e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:34:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.026995114982128143 norm:0.00010084948735311627 max memory_allocated 29269.37548828125 
[2025-03-02 15:35:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.026975270360708237 norm:9.753995254868641e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.02695096656680107 norm:9.680494986241683e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:37:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.026945576071739197 norm:9.7765150712803e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:38:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.026936717331409454 norm:9.668456914369017e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:39:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.026921069249510765 norm:9.44949861150235e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:39:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.026914596557617188 norm:9.606784442439675e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.026914920657873154 norm:9.668411803431809e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.02690969593822956 norm:0.00010036156891146675 max memory_allocated 29269.37548828125 
[2025-03-02 15:42:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.02690930664539337 norm:0.0001023722579702735 max memory_allocated 29269.37548828125 
[2025-03-02 15:43:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.026908207684755325 norm:0.00010182567348238081 max memory_allocated 29269.37548828125 
[2025-03-02 15:43:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:44:22 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.03596076741814613 norm:0.001113927224650979 max memory_allocated 29269.37548828125 
[2025-03-02 15:45:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.03245013207197189 norm:0.0004164180136285722 max memory_allocated 29269.37548828125 
[2025-03-02 15:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.031306397169828415 norm:0.00022108526900410652 max memory_allocated 29269.37548828125 
[2025-03-02 15:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.030560914427042007 norm:0.00015606213128194213 max memory_allocated 29269.37548828125 
[2025-03-02 15:47:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.030010804533958435 norm:0.0001292482193093747 max memory_allocated 29269.37548828125 
[2025-03-02 15:48:33 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.02966049686074257 norm:0.00011333871952956542 max memory_allocated 29269.37548828125 
[2025-03-02 15:49:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.029463499784469604 norm:0.00010413262498332188 max memory_allocated 29269.37548828125 
[2025-03-02 15:50:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.029373375698924065 norm:9.851589857134968e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:51:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.02930176816880703 norm:9.318080265074968e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:51:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.029281193390488625 norm:8.929500472731888e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:52:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.029276425018906593 norm:8.945618174038827e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:53:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.02926502376794815 norm:8.820193761494011e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:54:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.0292474627494812 norm:8.71919619385153e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:55:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.02923862263560295 norm:8.460313983960077e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:56:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.029232285916805267 norm:8.358075137948617e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:56:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.029224343597888947 norm:8.427810098510236e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:57:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.02922820672392845 norm:8.515234367223457e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:58:36 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.029224762693047523 norm:8.326522947754711e-05 max memory_allocated 29269.37548828125 
[2025-03-02 15:59:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.029213713482022285 norm:8.251726103480905e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.02921587973833084 norm:8.357001934200525e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:00:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 16:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.03942854329943657 norm:0.0011112149804830551 max memory_allocated 29269.37548828125 
[2025-03-02 16:02:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.03570949658751488 norm:0.0004760214069392532 max memory_allocated 29269.37548828125 
[2025-03-02 16:03:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.03417057916522026 norm:0.00024398465757258236 max memory_allocated 29269.37548828125 
[2025-03-02 16:03:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.033346377313137054 norm:0.0001596323272679001 max memory_allocated 29269.37548828125 
[2025-03-02 16:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.03274404630064964 norm:0.00012788092135451734 max memory_allocated 29269.37548828125 
[2025-03-02 16:05:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.032369162887334824 norm:0.00011164155148435384 max memory_allocated 29269.37548828125 
[2025-03-02 16:06:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.03217196837067604 norm:0.00010293391824234277 max memory_allocated 29269.37548828125 
[2025-03-02 16:07:18 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.032079555094242096 norm:9.719467925606295e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:08:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.032022181898355484 norm:9.404542652191594e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:08:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.03199007734656334 norm:9.152392158284783e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:09:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.03195616230368614 norm:9.15361670195125e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:10:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.03193182498216629 norm:8.84600740391761e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.0319233275949955 norm:8.86533671291545e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:12:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.0319051556289196 norm:8.603951573604718e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:13:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.03190000355243683 norm:8.486279693897814e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:14:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.03189418464899063 norm:8.444229752058163e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:14:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.031884558498859406 norm:8.32734294817783e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.0318867526948452 norm:8.268675446743146e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:16:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.031889937818050385 norm:8.390888251597062e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.03188823536038399 norm:8.253243140643463e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:17:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:18:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.039425574243068695 norm:0.0008960256818681955 max memory_allocated 29269.37548828125 
[2025-03-02 16:19:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.03693043440580368 norm:0.0003894382680300623 max memory_allocated 29269.37548828125 
[2025-03-02 16:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.035811398178339005 norm:0.00022549460118170828 max memory_allocated 29269.37548828125 
[2025-03-02 16:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.035042375326156616 norm:0.000158000344526954 max memory_allocated 29269.37548828125 
[2025-03-02 16:21:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.034455351531505585 norm:0.00012902833987027407 max memory_allocated 29269.37548828125 
[2025-03-02 16:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.03409983217716217 norm:0.00011207412899238989 max memory_allocated 29269.37548828125 
[2025-03-02 16:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.03390646353363991 norm:9.999836765928194e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.03382987529039383 norm:9.661247167969123e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:25:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.033776331692934036 norm:9.423831943422556e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:26:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.0337379053235054 norm:8.790669380687177e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.033723264932632446 norm:8.632999379187822e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.03371194377541542 norm:8.244499622378498e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:28:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.03370223194360733 norm:8.304210496135056e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:29:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.03369031101465225 norm:8.165095641743392e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:30:14 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.0336771160364151 norm:8.166549378074706e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:31:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.03366550803184509 norm:8.163480379153043e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:31:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.03365836665034294 norm:8.08654076536186e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:32:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.033658139407634735 norm:8.164588507497683e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:33:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.033657871186733246 norm:8.14802770037204e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:34:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.033659033477306366 norm:8.195876580430195e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:34:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.04097891226410866 norm:0.0006565235089510679 max memory_allocated 29269.37548828125 
[2025-03-02 16:36:25 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.03883614018559456 norm:0.0003239590732846409 max memory_allocated 29269.37548828125 
[2025-03-02 16:37:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.03776494041085243 norm:0.0002022533881245181 max memory_allocated 29269.37548828125 
[2025-03-02 16:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.03696916252374649 norm:0.00014642186579294503 max memory_allocated 29269.37548828125 
[2025-03-02 16:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.03634677827358246 norm:0.0001178741076728329 max memory_allocated 29269.37548828125 
[2025-03-02 16:39:46 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.03596389666199684 norm:0.00010314770770492032 max memory_allocated 29269.37548828125 
[2025-03-02 16:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.03576233610510826 norm:9.626495011616498e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.03566795960068703 norm:9.273782779928297e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:42:17 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.035615816712379456 norm:8.94856930244714e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:43:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.03557177633047104 norm:8.41025248519145e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:43:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.03554873540997505 norm:8.172987872967497e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:44:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.03553048148751259 norm:8.164547762135044e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:45:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.035515282303094864 norm:8.284737123176455e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:46:28 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.035494156181812286 norm:7.924585224827752e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:47:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.035484857857227325 norm:7.849007670301944e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:48:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.035481296479701996 norm:7.806313078617677e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.03548024594783783 norm:7.713823288213462e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:49:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.03547258302569389 norm:7.7787772170268e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:50:40 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.03546460345387459 norm:7.617014489369467e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:51:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.0354645773768425 norm:7.855883450247347e-05 max memory_allocated 29269.37548828125 
[2025-03-02 16:51:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:52:39 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.044217441231012344 norm:0.0010325642069801688 max memory_allocated 29269.37548828125 
[2025-03-02 16:53:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.041398562490940094 norm:0.0004957623896189034 max memory_allocated 29269.37548828125 
[2025-03-02 16:54:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.040086325258016586 norm:0.00029167719185352325 max memory_allocated 29269.37548828125 
[2025-03-02 16:55:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.03919176757335663 norm:0.00020136388775426894 max memory_allocated 29269.37548828125 
[2025-03-02 16:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.03850957006216049 norm:0.00015021904255263507 max memory_allocated 29269.37548828125 
[2025-03-02 16:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.03809795528650284 norm:0.00012478024291340262 max memory_allocated 29269.37548828125 
[2025-03-02 16:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.037900783121585846 norm:0.00011261671170359477 max memory_allocated 29269.37548828125 
[2025-03-02 16:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.037802841514348984 norm:0.00010081653454108164 max memory_allocated 29269.37548828125 
[2025-03-02 16:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.03775594010949135 norm:9.540351311443374e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:00:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.03771207854151726 norm:8.969615737441927e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.03768843412399292 norm:8.523608994437382e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.03766573220491409 norm:8.408645953750238e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:02:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.03763560205698013 norm:8.083265129243955e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:03:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.037623852491378784 norm:7.949455175548792e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.037611521780490875 norm:7.880226621637121e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.03761007636785507 norm:7.768506475258619e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:06:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.03760342299938202 norm:7.816727156750858e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:06:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.03760159760713577 norm:7.94174920883961e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:07:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.03759631887078285 norm:8.010975579963997e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.03758898749947548 norm:8.020507812034339e-05 max memory_allocated 29269.37548828125 
[2025-03-02 17:08:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:09:44 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.0465736985206604 norm:0.0009003133163787425 max memory_allocated 29269.68798828125 
[2025-03-02 17:10:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.044063881039619446 norm:0.00034829979995265603 max memory_allocated 29269.68798828125 
[2025-03-02 17:11:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.04301737621426582 norm:0.00021435640519484878 max memory_allocated 29269.68798828125 
[2025-03-02 17:12:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.04217349737882614 norm:0.00016413077537436038 max memory_allocated 29269.68798828125 
[2025-03-02 17:13:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.041452664881944656 norm:0.00013524506357498467 max memory_allocated 29269.68798828125 
[2025-03-02 17:13:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.041004788130521774 norm:0.00011936663941014558 max memory_allocated 29269.68798828125 
[2025-03-02 17:14:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.04079398512840271 norm:0.00011075226939283311 max memory_allocated 29269.68798828125 
[2025-03-02 17:15:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.04070473089814186 norm:9.831529314396903e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:16:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.04064365476369858 norm:9.095465793507174e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:17:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.04060528054833412 norm:9.065664926311001e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:18:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.04056478291749954 norm:8.42619119794108e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:18:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.040525883436203 norm:7.957019261084497e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:19:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.040500104427337646 norm:7.672186620766297e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:20:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.04047756642103195 norm:7.514574826927856e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:21:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.0404646173119545 norm:7.66263110563159e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:22:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.04045151174068451 norm:7.388493395410478e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.040437065064907074 norm:7.156429637689143e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:23:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.04043443500995636 norm:6.939309241715819e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:24:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.040435291826725006 norm:7.043711957521737e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:25:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.04042130336165428 norm:7.1140137151815e-05 max memory_allocated 29269.68798828125 
[2025-03-02 17:25:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:26:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.04892230033874512 norm:0.0010835210559889674 max memory_allocated 29269.87548828125 
[2025-03-02 17:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.0470927432179451 norm:0.0005196320707909763 max memory_allocated 29269.87548828125 
[2025-03-02 17:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.046102430671453476 norm:0.0003159198386128992 max memory_allocated 29269.87548828125 
[2025-03-02 17:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.04526454582810402 norm:0.00021402313723228872 max memory_allocated 29269.87548828125 
[2025-03-02 17:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.04454217106103897 norm:0.00015679329226259142 max memory_allocated 29269.87548828125 
[2025-03-02 17:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.04411765933036804 norm:0.00012429669732227921 max memory_allocated 29269.87548828125 
[2025-03-02 17:31:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.043969035148620605 norm:0.00010506897524464875 max memory_allocated 29269.87548828125 
[2025-03-02 17:32:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.04391716793179512 norm:9.32209804886952e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:33:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.04388732463121414 norm:8.387215348193422e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:34:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.0438595786690712 norm:7.927577826194465e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:35:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.043828144669532776 norm:7.653200009372085e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:36:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.04380747303366661 norm:7.392332190647721e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:36:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.04379922151565552 norm:7.244094740599394e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:37:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.04378988593816757 norm:7.082406955305487e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.04378297179937363 norm:6.991495320107788e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:39:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.04377717524766922 norm:6.967489025555551e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.04378166422247887 norm:7.022028148639947e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:41:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.04377048462629318 norm:6.933694385224953e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.04376804456114769 norm:7.058529445203021e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:42:44 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.0437614880502224 norm:6.888083589728922e-05 max memory_allocated 29269.87548828125 
[2025-03-02 17:42:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:43:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.05389244854450226 norm:0.0014297254383563995 max memory_allocated 29270.06298828125 
[2025-03-02 17:44:44 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.051364462822675705 norm:0.0006471819942817092 max memory_allocated 29270.06298828125 
[2025-03-02 17:45:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.05011092498898506 norm:0.000383822392905131 max memory_allocated 29270.06298828125 
[2025-03-02 17:46:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.04906938970088959 norm:0.0002565608883742243 max memory_allocated 29270.06298828125 
[2025-03-02 17:47:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.048240017145872116 norm:0.00018781202379614115 max memory_allocated 29270.06298828125 
[2025-03-02 17:48:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.04782461002469063 norm:0.0001462399523006752 max memory_allocated 29270.06298828125 
[2025-03-02 17:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.04766981303691864 norm:0.00012237593182362616 max memory_allocated 29270.06298828125 
[2025-03-02 17:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.04758940264582634 norm:0.00010824277705978602 max memory_allocated 29270.06298828125 
[2025-03-02 17:50:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.04753667116165161 norm:9.669690189184621e-05 max memory_allocated 29270.06298828125 
[2025-03-02 17:51:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.047501616179943085 norm:8.8813467300497e-05 max memory_allocated 29270.06298828125 
[2025-03-02 17:52:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.04747183620929718 norm:8.388064452446997e-05 max memory_allocated 29270.06298828125 
[2025-03-02 17:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.04745008423924446 norm:8.023264672374353e-05 max memory_allocated 29270.06298828125 
[2025-03-02 17:53:56 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.04742076247930527 norm:7.830807589925826e-05 max memory_allocated 29270.06298828125 
[2025-03-02 17:54:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.047415606677532196 norm:7.66888988437131e-05 max memory_allocated 29270.06298828125 
[2025-03-02 17:55:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.04741400107741356 norm:7.595134957227856e-05 max memory_allocated 29270.06298828125 
[2025-03-02 17:56:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.047415800392627716 norm:7.654719956917688e-05 max memory_allocated 29270.06298828125 
[2025-03-02 17:57:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.0474092960357666 norm:7.565584382973611e-05 max memory_allocated 29270.06298828125 
[2025-03-02 17:58:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.0473974347114563 norm:7.397867739200592e-05 max memory_allocated 29270.06298828125 
[2025-03-02 17:58:58 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.04738451912999153 norm:7.293743692571297e-05 max memory_allocated 29270.06298828125 
[2025-03-02 17:59:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.0473792627453804 norm:7.383531192317605e-05 max memory_allocated 29270.06298828125 
[2025-03-02 18:00:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 18:00:57 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.05942732095718384 norm:0.00131698336917907 max memory_allocated 29270.25048828125 
[2025-03-02 18:01:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.05681609362363815 norm:0.0005520847626030445 max memory_allocated 29270.25048828125 
[2025-03-02 18:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.05547969415783882 norm:0.0003136887098662555 max memory_allocated 29270.25048828125 
[2025-03-02 18:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.05440050736069679 norm:0.00021055097749922425 max memory_allocated 29270.25048828125 
[2025-03-02 18:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.05355369672179222 norm:0.00015798895037733018 max memory_allocated 29270.25048828125 
[2025-03-02 18:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.05317014828324318 norm:0.00013033108552917838 max memory_allocated 29270.25048828125 
[2025-03-02 18:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.05304659157991409 norm:0.00011269925744272768 max memory_allocated 29270.25048828125 
[2025-03-02 18:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.05298299714922905 norm:0.00010322692833142355 max memory_allocated 29270.25048828125 
[2025-03-02 18:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.05292958766222 norm:9.584365761838853e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.05288896709680557 norm:9.259858052246273e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.05285439267754555 norm:8.939895633375272e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.05282500386238098 norm:8.502131822751835e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.052798353135585785 norm:8.295723091578111e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:11:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.052786797285079956 norm:8.220349263865501e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:12:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.05276285484433174 norm:8.20141431177035e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:13:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.05274927243590355 norm:8.057293598540127e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:14:21 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.052730705589056015 norm:7.928653212729841e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:15:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.05272157862782478 norm:7.889939297456294e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.05271371826529503 norm:7.927163824206218e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:16:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.05271300673484802 norm:7.871429988881573e-05 max memory_allocated 29270.25048828125 
[2025-03-02 18:17:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:18:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.06443031132221222 norm:0.0009020654833875597 max memory_allocated 29270.43798828125 
[2025-03-02 18:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.06257670372724533 norm:0.00039786193519830704 max memory_allocated 29270.43798828125 
[2025-03-02 18:19:42 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.06137562915682793 norm:0.0002431810717098415 max memory_allocated 29270.43798828125 
[2025-03-02 18:20:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.060215435922145844 norm:0.0001691279176156968 max memory_allocated 29270.43798828125 
[2025-03-02 18:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.05936192721128464 norm:0.0001299152208957821 max memory_allocated 29270.43798828125 
[2025-03-02 18:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.05907416716217995 norm:0.00010886776726692915 max memory_allocated 29270.43798828125 
[2025-03-02 18:23:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.05897326394915581 norm:9.641782526159659e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.05892931669950485 norm:9.239737846655771e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:24:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.05889049544930458 norm:8.681560575496405e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.05884552001953125 norm:8.271589467767626e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:26:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.05880984663963318 norm:8.028486627154052e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:27:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.058781880885362625 norm:7.861787162255496e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:28:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.058779533952474594 norm:7.881291094236076e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.05876879021525383 norm:7.68112950026989e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:29:46 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.05876026675105095 norm:7.775828999001533e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.05876165255904198 norm:7.877167081460357e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:31:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.05875040218234062 norm:7.680415001232177e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:32:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.058745674788951874 norm:7.631309563294053e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.058740418404340744 norm:7.526008994318545e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.05873475223779678 norm:7.688322511967272e-05 max memory_allocated 29270.43798828125 
[2025-03-02 18:34:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:35:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.07215724885463715 norm:0.0009250197908841074 max memory_allocated 29270.62548828125 
[2025-03-02 18:35:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.06950875371694565 norm:0.0003995929437223822 max memory_allocated 29270.62548828125 
[2025-03-02 18:36:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.06808022409677505 norm:0.0002513582003302872 max memory_allocated 29270.62548828125 
[2025-03-02 18:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.06676226109266281 norm:0.00018675556930247694 max memory_allocated 29270.62548828125 
[2025-03-02 18:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.06586378812789917 norm:0.00014975498197600245 max memory_allocated 29270.62548828125 
[2025-03-02 18:39:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.06556888669729233 norm:0.00012780069664586335 max memory_allocated 29270.62548828125 
[2025-03-02 18:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.06546558439731598 norm:0.00011498695675982162 max memory_allocated 29270.62548828125 
[2025-03-02 18:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.06537847220897675 norm:0.0001052455190801993 max memory_allocated 29270.62548828125 
[2025-03-02 18:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.06531945616006851 norm:9.82029814622365e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.06527160108089447 norm:9.30907335714437e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.06523577123880386 norm:8.910149335861206e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:44:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.06520552933216095 norm:8.527227328158915e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:45:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.06517766416072845 norm:8.292451093439013e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.06514895707368851 norm:8.147457265295088e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.06513078510761261 norm:8.055493526626378e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.06510704010725021 norm:7.737398118479177e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:48:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.06509730964899063 norm:7.582225953228772e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.06507737934589386 norm:7.475614256691188e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.0650712102651596 norm:7.432031270582229e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.06507208943367004 norm:7.416930748149753e-05 max memory_allocated 29270.62548828125 
[2025-03-02 18:51:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:52:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.08237478137016296 norm:0.0012641502544283867 max memory_allocated 29270.81298828125 
[2025-03-02 18:53:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.07906588912010193 norm:0.0005908478051424026 max memory_allocated 29270.81298828125 
[2025-03-02 18:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.07730273902416229 norm:0.00036958427517674863 max memory_allocated 29270.81298828125 
[2025-03-02 18:54:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.07576480507850647 norm:0.0002613672986626625 max memory_allocated 29270.81298828125 
[2025-03-02 18:55:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.0748177319765091 norm:0.00020417358609847724 max memory_allocated 29270.81298828125 
[2025-03-02 18:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.07452815771102905 norm:0.00016741811123210937 max memory_allocated 29270.81298828125 
[2025-03-02 18:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.07439432293176651 norm:0.00014803570229560137 max memory_allocated 29270.81298828125 
[2025-03-02 18:58:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.07430589944124222 norm:0.0001328857324551791 max memory_allocated 29270.81298828125 
[2025-03-02 18:58:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.07422743737697601 norm:0.0001216212403960526 max memory_allocated 29270.81298828125 
[2025-03-02 18:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.0741710364818573 norm:0.00011519069812493399 max memory_allocated 29270.81298828125 
[2025-03-02 19:00:35 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.07412314414978027 norm:0.0001103276590583846 max memory_allocated 29270.81298828125 
[2025-03-02 19:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.07408376783132553 norm:0.00010321235458832234 max memory_allocated 29270.81298828125 
[2025-03-02 19:02:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.07405324280261993 norm:9.816115925787017e-05 max memory_allocated 29270.81298828125 
[2025-03-02 19:03:05 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.07402797043323517 norm:9.431825310457498e-05 max memory_allocated 29270.81298828125 
[2025-03-02 19:03:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.07401379942893982 norm:9.300104284193367e-05 max memory_allocated 29270.81298828125 
[2025-03-02 19:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.0740010216832161 norm:9.356613736599684e-05 max memory_allocated 29270.81298828125 
[2025-03-02 19:05:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.07397686690092087 norm:9.211650467477739e-05 max memory_allocated 29270.81298828125 
[2025-03-02 19:06:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.07396096736192703 norm:9.155173029284924e-05 max memory_allocated 29270.81298828125 
[2025-03-02 19:07:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.07395230978727341 norm:9.098405280383304e-05 max memory_allocated 29270.81298828125 
[2025-03-02 19:08:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.07394182682037354 norm:8.959059050539508e-05 max memory_allocated 29270.81298828125 
[2025-03-02 19:08:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:09:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.09114571660757065 norm:0.0009631147840991616 max memory_allocated 29271.00048828125 
[2025-03-02 19:10:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.08892305195331573 norm:0.0004947322304360569 max memory_allocated 29271.00048828125 
[2025-03-02 19:10:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.08729705959558487 norm:0.0003130667610093951 max memory_allocated 29271.00048828125 
[2025-03-02 19:11:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.08570640534162521 norm:0.00021790947357658297 max memory_allocated 29271.00048828125 
[2025-03-02 19:12:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.08482326567173004 norm:0.00016741851868573576 max memory_allocated 29271.00048828125 
[2025-03-02 19:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.08458955585956573 norm:0.00014119110710453242 max memory_allocated 29271.00048828125 
[2025-03-02 19:14:18 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.084490567445755 norm:0.000124730373499915 max memory_allocated 29271.00048828125 
[2025-03-02 19:15:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.0844281017780304 norm:0.00011538033868419006 max memory_allocated 29271.00048828125 
[2025-03-02 19:15:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.08437338471412659 norm:0.00010735489922808483 max memory_allocated 29271.00048828125 
[2025-03-02 19:16:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.08433790504932404 norm:0.00010343792382627726 max memory_allocated 29271.00048828125 
[2025-03-02 19:17:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.08429908752441406 norm:9.771643817657605e-05 max memory_allocated 29271.00048828125 
[2025-03-02 19:18:29 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.0842699408531189 norm:9.650056017562747e-05 max memory_allocated 29271.00048828125 
[2025-03-02 19:19:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.0842491164803505 norm:9.36235228436999e-05 max memory_allocated 29271.00048828125 
[2025-03-02 19:20:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.08423022925853729 norm:9.333564958069474e-05 max memory_allocated 29271.00048828125 
[2025-03-02 19:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.08422401547431946 norm:9.358457464259118e-05 max memory_allocated 29271.00048828125 
[2025-03-02 19:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.08421791344881058 norm:9.325135761173442e-05 max memory_allocated 29271.00048828125 
[2025-03-02 19:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.08421153575181961 norm:9.142041380982846e-05 max memory_allocated 29271.00048828125 
[2025-03-02 19:23:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.0841943696141243 norm:9.073709225049242e-05 max memory_allocated 29271.00048828125 
[2025-03-02 19:24:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.08417550474405289 norm:9.012777445605025e-05 max memory_allocated 29271.00048828125 
[2025-03-02 19:25:11 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.08416792005300522 norm:9.21619648579508e-05 max memory_allocated 29271.00048828125 
[2025-03-02 19:25:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.10362124443054199 norm:0.0012025674805045128 max memory_allocated 29271.18798828125 
[2025-03-02 19:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.10051833093166351 norm:0.0005961396964266896 max memory_allocated 29271.18798828125 
[2025-03-02 19:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.09857668727636337 norm:0.00036676324089057744 max memory_allocated 29271.18798828125 
[2025-03-02 19:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.0970173254609108 norm:0.0002626173954922706 max memory_allocated 29271.18798828125 
[2025-03-02 19:29:41 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.0963054820895195 norm:0.0002061447303276509 max memory_allocated 29271.18798828125 
[2025-03-02 19:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.09606748819351196 norm:0.0001741721498547122 max memory_allocated 29271.18798828125 
[2025-03-02 19:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.09594161808490753 norm:0.0001539964141556993 max memory_allocated 29271.18798828125 
[2025-03-02 19:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.09585069864988327 norm:0.00014228159852791578 max memory_allocated 29271.18798828125 
[2025-03-02 19:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.09578872472047806 norm:0.0001309803337790072 max memory_allocated 29271.18798828125 
[2025-03-02 19:33:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.09572217613458633 norm:0.0001243266451638192 max memory_allocated 29271.18798828125 
[2025-03-02 19:34:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.09566768258810043 norm:0.00011771494610002264 max memory_allocated 29271.18798828125 
[2025-03-02 19:35:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.095637246966362 norm:0.0001135253842221573 max memory_allocated 29271.18798828125 
[2025-03-02 19:36:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.09561772644519806 norm:0.00010749469947768375 max memory_allocated 29271.18798828125 
[2025-03-02 19:37:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.09560084342956543 norm:0.00010645049042068422 max memory_allocated 29271.18798828125 
[2025-03-02 19:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.09559629112482071 norm:0.00010444518557051197 max memory_allocated 29271.18798828125 
[2025-03-02 19:38:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.09557740390300751 norm:0.00010294585081283003 max memory_allocated 29271.18798828125 
[2025-03-02 19:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.09555844962596893 norm:0.00010226989252259955 max memory_allocated 29271.18798828125 
[2025-03-02 19:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.09555485844612122 norm:0.00010237758397124708 max memory_allocated 29271.18798828125 
[2025-03-02 19:41:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.09554952383041382 norm:0.00010286943870596588 max memory_allocated 29271.18798828125 
[2025-03-02 19:42:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.09555564075708389 norm:0.00010263248259434476 max memory_allocated 29271.18798828125 
[2025-03-02 19:42:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.1141665130853653 norm:0.0013069711858406663 max memory_allocated 29271.37548828125 
[2025-03-02 19:44:14 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.11187851428985596 norm:0.0006702237296849489 max memory_allocated 29271.37548828125 
[2025-03-02 19:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.11022640019655228 norm:0.00042917823884636164 max memory_allocated 29271.37548828125 
[2025-03-02 19:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.10875123739242554 norm:0.00030695312307216227 max memory_allocated 29271.37548828125 
[2025-03-02 19:46:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.10808601975440979 norm:0.00023375959426630288 max memory_allocated 29271.37548828125 
[2025-03-02 19:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.10782485455274582 norm:0.0001926109689520672 max memory_allocated 29271.37548828125 
[2025-03-02 19:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.10770465433597565 norm:0.00016916720778681338 max memory_allocated 29271.37548828125 
[2025-03-02 19:49:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.10764452815055847 norm:0.00015303028339985758 max memory_allocated 29271.37548828125 
[2025-03-02 19:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.1076047420501709 norm:0.00014159480633679777 max memory_allocated 29271.37548828125 
[2025-03-02 19:50:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.10755813866853714 norm:0.00013104727258905768 max memory_allocated 29271.37548828125 
[2025-03-02 19:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.10752125829458237 norm:0.00012770593457389623 max memory_allocated 29271.37548828125 
[2025-03-02 19:52:37 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.10748261213302612 norm:0.0001239167177118361 max memory_allocated 29271.37548828125 
[2025-03-02 19:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.10744462162256241 norm:0.00012333173071965575 max memory_allocated 29271.37548828125 
[2025-03-02 19:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.10742390900850296 norm:0.00012118487211409956 max memory_allocated 29271.37548828125 
[2025-03-02 19:55:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.107399582862854 norm:0.00011848056601593271 max memory_allocated 29271.37548828125 
[2025-03-02 19:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.10740138590335846 norm:0.0001175771321868524 max memory_allocated 29271.37548828125 
[2025-03-02 19:56:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.10740647464990616 norm:0.00011994694796158001 max memory_allocated 29271.37548828125 
[2025-03-02 19:57:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.10742457211017609 norm:0.00012102848995709792 max memory_allocated 29271.37548828125 
[2025-03-02 19:58:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.10741976648569107 norm:0.00012166134547442198 max memory_allocated 29271.37548828125 
[2025-03-02 19:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.10740967839956284 norm:0.00012106107897125185 max memory_allocated 29271.37548828125 
[2025-03-02 19:59:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 20:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.127577543258667 norm:0.000891915347892791 max memory_allocated 29271.56298828125 
[2025-03-02 20:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.12542104721069336 norm:0.00046944129280745983 max memory_allocated 29271.56298828125 
[2025-03-02 20:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.123745858669281 norm:0.0003173968871124089 max memory_allocated 29271.56298828125 
[2025-03-02 20:03:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.12229819595813751 norm:0.00023846104159019887 max memory_allocated 29271.56298828125 
[2025-03-02 20:03:50 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.12167051434516907 norm:0.00019503163639456034 max memory_allocated 29271.56298828125 
[2025-03-02 20:04:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.12142569571733475 norm:0.00016653355851303786 max memory_allocated 29271.56298828125 
[2025-03-02 20:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.1212739422917366 norm:0.000151923464727588 max memory_allocated 29271.56298828125 
[2025-03-02 20:06:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.12120865285396576 norm:0.00014624823234044015 max memory_allocated 29271.56298828125 
[2025-03-02 20:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.12117674201726913 norm:0.00013536175538320094 max memory_allocated 29271.56298828125 
[2025-03-02 20:08:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.12111610174179077 norm:0.00012751971371471882 max memory_allocated 29271.56298828125 
[2025-03-02 20:08:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.1210588812828064 norm:0.0001242897124029696 max memory_allocated 29271.56298828125 
[2025-03-02 20:09:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.12104503810405731 norm:0.0001221788115799427 max memory_allocated 29271.56298828125 
[2025-03-02 20:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.1210189238190651 norm:0.00012211916327942163 max memory_allocated 29271.56298828125 
[2025-03-02 20:11:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.12098416686058044 norm:0.00012056042032781988 max memory_allocated 29271.56298828125 
[2025-03-02 20:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.1209786906838417 norm:0.00011836950579890981 max memory_allocated 29271.56298828125 
[2025-03-02 20:13:03 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.12097783386707306 norm:0.0001187809684779495 max memory_allocated 29271.56298828125 
[2025-03-02 20:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.12097706645727158 norm:0.00012211163993924856 max memory_allocated 29271.56298828125 
[2025-03-02 20:14:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.1209760457277298 norm:0.00011960350093431771 max memory_allocated 29271.56298828125 
[2025-03-02 20:15:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.12097717821598053 norm:0.00012216791219543666 max memory_allocated 29271.56298828125 
[2025-03-02 20:16:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.12097622454166412 norm:0.00012378772953525186 max memory_allocated 29271.56298828125 
[2025-03-02 20:16:40 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.14154762029647827 norm:0.00105091102886945 max memory_allocated 29271.75048828125 
[2025-03-02 20:18:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.1394348293542862 norm:0.0004527072887867689 max memory_allocated 29271.75048828125 
[2025-03-02 20:19:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.13773271441459656 norm:0.00028536541503854096 max memory_allocated 29271.75048828125 
[2025-03-02 20:20:05 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.1362321674823761 norm:0.0002125600294675678 max memory_allocated 29271.75048828125 
[2025-03-02 20:20:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.13566026091575623 norm:0.0001712334924377501 max memory_allocated 29271.75048828125 
[2025-03-02 20:21:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.13546094298362732 norm:0.0001502460363553837 max memory_allocated 29271.75048828125 
[2025-03-02 20:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.13535897433757782 norm:0.00013617120566777885 max memory_allocated 29271.75048828125 
[2025-03-02 20:23:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.13528315722942352 norm:0.00012845871970057487 max memory_allocated 29271.75048828125 
[2025-03-02 20:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.13522112369537354 norm:0.00012294607586227357 max memory_allocated 29271.75048828125 
[2025-03-02 20:25:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.13517168164253235 norm:0.00011876580538228154 max memory_allocated 29271.75048828125 
[2025-03-02 20:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.13514983654022217 norm:0.00011660160089377314 max memory_allocated 29271.75048828125 
[2025-03-02 20:26:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.13513556122779846 norm:0.00011424429249018431 max memory_allocated 29271.75048828125 
[2025-03-02 20:27:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.13513390719890594 norm:0.00011627770436462015 max memory_allocated 29271.75048828125 
[2025-03-02 20:28:27 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.13514013588428497 norm:0.00011391230509616435 max memory_allocated 29271.75048828125 
[2025-03-02 20:29:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.1351088583469391 norm:0.00011263441410847008 max memory_allocated 29271.75048828125 
[2025-03-02 20:30:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.13509587943553925 norm:0.00011296327284071594 max memory_allocated 29271.75048828125 
[2025-03-02 20:30:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.13509364426136017 norm:0.00011332141002640128 max memory_allocated 29271.75048828125 
[2025-03-02 20:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.13510555028915405 norm:0.00011445189011283219 max memory_allocated 29271.75048828125 
[2025-03-02 20:32:39 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.13510584831237793 norm:0.00011569356138352305 max memory_allocated 29271.75048828125 
[2025-03-02 20:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.13510292768478394 norm:0.00011534728400874883 max memory_allocated 29271.75048828125 
[2025-03-02 20:33:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.15852046012878418 norm:0.0008467313018627465 max memory_allocated 29271.93798828125 
[2025-03-02 20:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.1562439352273941 norm:0.0004337916325312108 max memory_allocated 29271.93798828125 
[2025-03-02 20:36:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.1544017344713211 norm:0.00029405823443084955 max memory_allocated 29271.93798828125 
[2025-03-02 20:37:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.1527288556098938 norm:0.0002264559589093551 max memory_allocated 29271.93798828125 
[2025-03-02 20:37:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.15213927626609802 norm:0.00019062198407482356 max memory_allocated 29271.93798828125 
[2025-03-02 20:38:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.15191848576068878 norm:0.00017113352078013122 max memory_allocated 29271.93798828125 
[2025-03-02 20:39:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.1517806053161621 norm:0.00016174078336916864 max memory_allocated 29271.93798828125 
[2025-03-02 20:40:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.15169744193553925 norm:0.00015117453585844487 max memory_allocated 29271.93798828125 
[2025-03-02 20:41:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.15161192417144775 norm:0.0001415791775798425 max memory_allocated 29271.93798828125 
[2025-03-02 20:42:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.15155664086341858 norm:0.00013562192907556891 max memory_allocated 29271.93798828125 
[2025-03-02 20:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.15147733688354492 norm:0.00013283370935823768 max memory_allocated 29271.93798828125 
[2025-03-02 20:43:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.15143901109695435 norm:0.00013188731099944562 max memory_allocated 29271.93798828125 
[2025-03-02 20:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.15141601860523224 norm:0.00013396257418207824 max memory_allocated 29271.93798828125 
[2025-03-02 20:45:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.15140876173973083 norm:0.00013206005678512156 max memory_allocated 29271.93798828125 
[2025-03-02 20:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.1514235883951187 norm:0.0001325798366451636 max memory_allocated 29271.93798828125 
[2025-03-02 20:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.1514364778995514 norm:0.00013208342716097832 max memory_allocated 29271.93798828125 
[2025-03-02 20:48:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.15143318474292755 norm:0.00013084035890642554 max memory_allocated 29271.93798828125 
[2025-03-02 20:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.15142737329006195 norm:0.00013227413001004606 max memory_allocated 29271.93798828125 
[2025-03-02 20:49:44 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.15142834186553955 norm:0.00013419118477031589 max memory_allocated 29271.93798828125 
[2025-03-02 20:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.15143153071403503 norm:0.00013498464250005782 max memory_allocated 29271.93798828125 
[2025-03-02 20:50:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:51:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.17635536193847656 norm:0.0011326964013278484 max memory_allocated 29272.12548828125 
[2025-03-02 20:52:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.17387551069259644 norm:0.0005635187844745815 max memory_allocated 29272.12548828125 
[2025-03-02 20:53:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.17175431549549103 norm:0.00040010534576140344 max memory_allocated 29272.12548828125 
[2025-03-02 20:54:14 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.16994096338748932 norm:0.0003480041050352156 max memory_allocated 29272.12548828125 
[2025-03-02 20:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.16941986978054047 norm:0.0002832323662005365 max memory_allocated 29272.12548828125 
[2025-03-02 20:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.16922108829021454 norm:0.0002488232566975057 max memory_allocated 29272.12548828125 
[2025-03-02 20:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.1690768003463745 norm:0.0002327502879779786 max memory_allocated 29272.12548828125 
[2025-03-02 20:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.16900154948234558 norm:0.00021918158745393157 max memory_allocated 29272.12548828125 
[2025-03-02 20:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.16894978284835815 norm:0.00021835241932421923 max memory_allocated 29272.12548828125 
[2025-03-02 20:59:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.16891904175281525 norm:0.000210761179914698 max memory_allocated 29272.12548828125 
[2025-03-02 21:00:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.16887755692005157 norm:0.000206561220693402 max memory_allocated 29272.12548828125 
[2025-03-02 21:00:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.16885064542293549 norm:0.00017821314395405352 max memory_allocated 29272.12548828125 
[2025-03-02 21:01:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.1688361018896103 norm:0.00019604212138801813 max memory_allocated 29272.12548828125 
[2025-03-02 21:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.16881601512432098 norm:0.0001895985915325582 max memory_allocated 29272.12548828125 
[2025-03-02 21:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.1687900722026825 norm:0.00018910167273133993 max memory_allocated 29272.12548828125 
[2025-03-02 21:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.16878743469715118 norm:0.00018076378910336643 max memory_allocated 29272.12548828125 
[2025-03-02 21:05:08 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.16880249977111816 norm:0.00018098238797392696 max memory_allocated 29272.12548828125 
[2025-03-02 21:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.1687929630279541 norm:0.00018219277262687683 max memory_allocated 29272.12548828125 
[2025-03-02 21:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.16881541907787323 norm:0.00018115955754183233 max memory_allocated 29272.12548828125 
[2025-03-02 21:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.16881322860717773 norm:0.00018028804333880544 max memory_allocated 29272.12548828125 
[2025-03-02 21:07:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 21:08:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.19377271831035614 norm:0.001584359211847186 max memory_allocated 29272.31298828125 
[2025-03-02 21:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.1911911815404892 norm:0.0008103483123704791 max memory_allocated 29272.31298828125 
[2025-03-02 21:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.18896545469760895 norm:0.000500052934512496 max memory_allocated 29272.31298828125 
[2025-03-02 21:11:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.18709035217761993 norm:0.0003403259615879506 max memory_allocated 29272.31298828125 
[2025-03-02 21:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.186562642455101 norm:0.00025740728597156703 max memory_allocated 29272.31298828125 
[2025-03-02 21:13:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.18638065457344055 norm:0.00021155693684704602 max memory_allocated 29272.31298828125 
[2025-03-02 21:13:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.18628045916557312 norm:0.00018130146781913936 max memory_allocated 29272.31298828125 
[2025-03-02 21:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.18620586395263672 norm:0.00016207194130402058 max memory_allocated 29272.31298828125 
[2025-03-02 21:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.18617025017738342 norm:0.00014948853640817106 max memory_allocated 29272.31298828125 
[2025-03-02 21:16:21 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.18614839017391205 norm:0.00014179450226947665 max memory_allocated 29272.31298828125 
[2025-03-02 21:17:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.18611770868301392 norm:0.00013621104881167412 max memory_allocated 29272.31298828125 
[2025-03-02 21:18:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.18609926104545593 norm:0.0001320825394941494 max memory_allocated 29272.31298828125 
[2025-03-02 21:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.18608209490776062 norm:0.00012851883366238326 max memory_allocated 29272.31298828125 
[2025-03-02 21:19:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.1860658973455429 norm:0.00012645803508348763 max memory_allocated 29272.31298828125 
[2025-03-02 21:20:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.18604882061481476 norm:0.0001258553093066439 max memory_allocated 29272.31298828125 
[2025-03-02 21:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.18603596091270447 norm:0.00012564157077576965 max memory_allocated 29272.31298828125 
[2025-03-02 21:22:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.18602846562862396 norm:0.00012599973706528544 max memory_allocated 29272.31298828125 
[2025-03-02 21:23:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.1860262155532837 norm:0.00012516345304902643 max memory_allocated 29272.31298828125 
[2025-03-02 21:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.18601468205451965 norm:0.00012399566185195 max memory_allocated 29272.31298828125 
[2025-03-02 21:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.18600903451442719 norm:0.0001237717951880768 max memory_allocated 29272.31298828125 
[2025-03-02 21:24:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.21367160975933075 norm:0.0014965859008952975 max memory_allocated 29272.50048828125 
[2025-03-02 21:26:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.2111295461654663 norm:0.0007448775577358902 max memory_allocated 29272.50048828125 
[2025-03-02 21:27:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.208749920129776 norm:0.0004635835066437721 max memory_allocated 29272.50048828125 
[2025-03-02 21:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.20691832900047302 norm:0.0003283090190961957 max memory_allocated 29272.50048828125 
[2025-03-02 21:29:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.2064162939786911 norm:0.00025826896307989955 max memory_allocated 29272.50048828125 
[2025-03-02 21:30:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.20618760585784912 norm:0.00021999531600158662 max memory_allocated 29272.50048828125 
[2025-03-02 21:30:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.20605529844760895 norm:0.00019433238776400685 max memory_allocated 29272.50048828125 
[2025-03-02 21:31:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.2059364914894104 norm:0.00018243520753458142 max memory_allocated 29272.50048828125 
[2025-03-02 21:32:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.20586879551410675 norm:0.00018833999638445675 max memory_allocated 29272.50048828125 
[2025-03-02 21:33:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.20582355558872223 norm:0.00018168445967603475 max memory_allocated 29272.50048828125 
[2025-03-02 21:34:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.20577389001846313 norm:0.00016697881801519543 max memory_allocated 29272.50048828125 
[2025-03-02 21:35:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.2057529240846634 norm:0.000172170257428661 max memory_allocated 29272.50048828125 
[2025-03-02 21:35:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.20572897791862488 norm:0.00015810604963917285 max memory_allocated 29272.50048828125 
[2025-03-02 21:36:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.2056969404220581 norm:0.00016097817569971085 max memory_allocated 29272.50048828125 
[2025-03-02 21:37:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.2056683897972107 norm:0.00016119098290801048 max memory_allocated 29272.50048828125 
[2025-03-02 21:38:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.2056587189435959 norm:0.00016273646906483918 max memory_allocated 29272.50048828125 
[2025-03-02 21:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.20562784373760223 norm:0.00016164193220902234 max memory_allocated 29272.50048828125 
[2025-03-02 21:40:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.20562368631362915 norm:0.0001612907653907314 max memory_allocated 29272.50048828125 
[2025-03-02 21:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.2056184709072113 norm:0.00015985970094334334 max memory_allocated 29272.50048828125 
[2025-03-02 21:41:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.2056238353252411 norm:0.00015853405056986958 max memory_allocated 29272.50048828125 
[2025-03-02 21:42:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.23587650060653687 norm:0.00179256871342659 max memory_allocated 29272.68798828125 
[2025-03-02 21:43:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.23259630799293518 norm:0.0008592274971306324 max memory_allocated 29272.68798828125 
[2025-03-02 21:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.22982463240623474 norm:0.0005190330557525158 max memory_allocated 29272.68798828125 
[2025-03-02 21:45:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.22778795659542084 norm:0.0003538991149980575 max memory_allocated 29272.68798828125 
[2025-03-02 21:46:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.22729916870594025 norm:0.0002718487521633506 max memory_allocated 29272.68798828125 
[2025-03-02 21:47:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.227092444896698 norm:0.00022888381499797106 max memory_allocated 29272.68798828125 
[2025-03-02 21:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.2269614338874817 norm:0.00019886773952748626 max memory_allocated 29272.68798828125 
[2025-03-02 21:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.22688715159893036 norm:0.0001835991133702919 max memory_allocated 29272.68798828125 
[2025-03-02 21:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.2268444299697876 norm:0.0001749027578625828 max memory_allocated 29272.68798828125 
[2025-03-02 21:50:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.22679951786994934 norm:0.0001643263385631144 max memory_allocated 29272.68798828125 
[2025-03-02 21:51:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.226780965924263 norm:0.00015905703185126185 max memory_allocated 29272.68798828125 
[2025-03-02 21:52:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.226758673787117 norm:0.00015351930051110685 max memory_allocated 29272.68798828125 
[2025-03-02 21:53:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.22674109041690826 norm:0.00014777420437894762 max memory_allocated 29272.68798828125 
[2025-03-02 21:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.2267305701971054 norm:0.00014938536332920194 max memory_allocated 29272.68798828125 
[2025-03-02 21:54:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.22670389711856842 norm:0.00015175962471403182 max memory_allocated 29272.68798828125 
[2025-03-02 21:55:32 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.22670044004917145 norm:0.0001479284546803683 max memory_allocated 29272.68798828125 
[2025-03-02 21:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.22670069336891174 norm:0.00014749847468920052 max memory_allocated 29272.68798828125 
[2025-03-02 21:57:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.2266891896724701 norm:0.00014572679356206208 max memory_allocated 29272.68798828125 
[2025-03-02 21:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.22668331861495972 norm:0.00014635012485086918 max memory_allocated 29272.68798828125 
[2025-03-02 21:58:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.22668930888175964 norm:0.00014940029359422624 max memory_allocated 29272.68798828125 
[2025-03-02 21:59:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 22:00:04 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.2564917802810669 norm:0.0021804491989314556 max memory_allocated 29272.87548828125 
[2025-03-02 22:00:54 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.2536380887031555 norm:0.0010827623773366213 max memory_allocated 29272.87548828125 
[2025-03-02 22:01:44 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.2510615289211273 norm:0.0006563067436218262 max memory_allocated 29272.87548828125 
[2025-03-02 22:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.24917522072792053 norm:0.00044325058115646243 max memory_allocated 29272.87548828125 
[2025-03-02 22:03:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.24865314364433289 norm:0.0003319613169878721 max memory_allocated 29272.87548828125 
[2025-03-02 22:04:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.2484237253665924 norm:0.00026826607063412666 max memory_allocated 29272.87548828125 
[2025-03-02 22:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.24828246235847473 norm:0.00022832535614725202 max memory_allocated 29272.87548828125 
[2025-03-02 22:05:55 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.24818742275238037 norm:0.0002033429773291573 max memory_allocated 29272.87548828125 
[2025-03-02 22:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.24811486899852753 norm:0.00018579036986920983 max memory_allocated 29272.87548828125 
[2025-03-02 22:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.24805708229541779 norm:0.00017515677609480917 max memory_allocated 29272.87548828125 
[2025-03-02 22:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.2480270266532898 norm:0.00016754328680690378 max memory_allocated 29272.87548828125 
[2025-03-02 22:09:16 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.24800840020179749 norm:0.00016154612239915878 max memory_allocated 29272.87548828125 
[2025-03-02 22:10:07 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.24798500537872314 norm:0.0001572647743159905 max memory_allocated 29272.87548828125 
[2025-03-02 22:10:57 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.2479722946882248 norm:0.00015433946100529283 max memory_allocated 29272.87548828125 
[2025-03-02 22:11:47 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.24795469641685486 norm:0.0001516114134574309 max memory_allocated 29272.87548828125 
[2025-03-02 22:12:38 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.24794542789459229 norm:0.00015114370035007596 max memory_allocated 29272.87548828125 
[2025-03-02 22:13:28 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.2479282021522522 norm:0.00015050840738695115 max memory_allocated 29272.87548828125 
[2025-03-02 22:14:18 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.24791808426380157 norm:0.00014985728194005787 max memory_allocated 29272.87548828125 
[2025-03-02 22:15:09 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.24790875613689423 norm:0.00014848662249278277 max memory_allocated 29272.87548828125 
[2025-03-02 22:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.24790026247501373 norm:0.00014814030146226287 max memory_allocated 29272.87548828125 
[2025-03-02 22:16:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:17:08 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.2823239266872406 norm:0.0012259581126272678 max memory_allocated 29273.06298828125 
[2025-03-02 22:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.279155969619751 norm:0.0006527147488668561 max memory_allocated 29273.06298828125 
[2025-03-02 22:18:48 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.27614453434944153 norm:0.0004343915788922459 max memory_allocated 29273.06298828125 
[2025-03-02 22:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.2742893099784851 norm:0.0003192745498381555 max memory_allocated 29273.06298828125 
[2025-03-02 22:20:29 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.27375108003616333 norm:0.00026233922108076513 max memory_allocated 29273.06298828125 
[2025-03-02 22:21:19 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.27350419759750366 norm:0.00023436459014192224 max memory_allocated 29273.06298828125 
[2025-03-02 22:22:10 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.2733366787433624 norm:0.00021279194334056228 max memory_allocated 29273.06298828125 
[2025-03-02 22:22:59 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.27319833636283875 norm:0.00019882972992490977 max memory_allocated 29273.06298828125 
[2025-03-02 22:23:50 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.27310800552368164 norm:0.00019123891252093017 max memory_allocated 29273.06298828125 
[2025-03-02 22:24:40 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.2730439305305481 norm:0.00018532987451180816 max memory_allocated 29273.06298828125 
[2025-03-02 22:25:30 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.2729886770248413 norm:0.00018413994985166937 max memory_allocated 29273.06298828125 
[2025-03-02 22:26:20 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.2729640305042267 norm:0.00018657273903954774 max memory_allocated 29273.06298828125 
[2025-03-02 22:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.2729254364967346 norm:0.00018592625565361232 max memory_allocated 29273.06298828125 
[2025-03-02 22:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.27290165424346924 norm:0.00018165404617320746 max memory_allocated 29273.06298828125 
[2025-03-02 22:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.2728670835494995 norm:0.00018148300296161324 max memory_allocated 29273.06298828125 
[2025-03-02 22:29:41 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.27284619212150574 norm:0.0001804224302759394 max memory_allocated 29273.06298828125 
[2025-03-02 22:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.2728404700756073 norm:0.0001818264281610027 max memory_allocated 29273.06298828125 
[2025-03-02 22:31:22 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.2728341519832611 norm:0.0001843864592956379 max memory_allocated 29273.06298828125 
[2025-03-02 22:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.27285411953926086 norm:0.00018899032147601247 max memory_allocated 29273.06298828125 
[2025-03-02 22:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.27284324169158936 norm:0.0001897619222290814 max memory_allocated 29273.06298828125 
[2025-03-02 22:33:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.3132811486721039 norm:0.0016159623628482223 max memory_allocated 29273.25048828125 
[2025-03-02 22:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.309329628944397 norm:0.0007975319167599082 max memory_allocated 29273.25048828125 
[2025-03-02 22:35:52 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.30568429827690125 norm:0.0005011051543988287 max memory_allocated 29273.25048828125 
[2025-03-02 22:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.30372777581214905 norm:0.00036079896381124854 max memory_allocated 29273.25048828125 
[2025-03-02 22:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.3032964766025543 norm:0.000289200252154842 max memory_allocated 29273.25048828125 
[2025-03-02 22:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.3030654788017273 norm:0.00024707187549211085 max memory_allocated 29273.25048828125 
[2025-03-02 22:39:13 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.3028891980648041 norm:0.00022339678253047168 max memory_allocated 29273.25048828125 
[2025-03-02 22:40:04 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.30277225375175476 norm:0.00020829058485105634 max memory_allocated 29273.25048828125 
[2025-03-02 22:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.3026794195175171 norm:0.0001979871594812721 max memory_allocated 29273.25048828125 
[2025-03-02 22:41:44 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.30263134837150574 norm:0.0001940732472576201 max memory_allocated 29273.25048828125 
[2025-03-02 22:42:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.3025553524494171 norm:0.00018702402303460985 max memory_allocated 29273.25048828125 
[2025-03-02 22:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.3025200068950653 norm:0.00018642413488123566 max memory_allocated 29273.25048828125 
[2025-03-02 22:44:15 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.3024998605251312 norm:0.00018601276678964496 max memory_allocated 29273.25048828125 
[2025-03-02 22:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.3024611473083496 norm:0.0001856240996858105 max memory_allocated 29273.25048828125 
[2025-03-02 22:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.3024354875087738 norm:0.0001853584690252319 max memory_allocated 29273.25048828125 
[2025-03-02 22:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.3024103343486786 norm:0.00018434422963764518 max memory_allocated 29273.25048828125 
[2025-03-02 22:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.30241310596466064 norm:0.00018995186837855726 max memory_allocated 29273.25048828125 
[2025-03-02 22:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.30242007970809937 norm:0.0001878429320640862 max memory_allocated 29273.25048828125 
[2025-03-02 22:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.3024025559425354 norm:0.00018596433801576495 max memory_allocated 29273.25048828125 
[2025-03-02 22:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.30238378047943115 norm:0.00018731191812548786 max memory_allocated 29273.25048828125 
[2025-03-02 22:50:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:51:16 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.34647148847579956 norm:0.0030005427543073893 max memory_allocated 29273.43798828125 
[2025-03-02 22:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.34142428636550903 norm:0.0015669087879359722 max memory_allocated 29273.43798828125 
[2025-03-02 22:52:57 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.3371402323246002 norm:0.0009670028812251985 max memory_allocated 29273.43798828125 
[2025-03-02 22:53:47 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.33512449264526367 norm:0.0006702530663460493 max memory_allocated 29273.43798828125 
[2025-03-02 22:54:37 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.33441275358200073 norm:0.0004977167118340731 max memory_allocated 29273.43798828125 
[2025-03-02 22:55:27 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.33396556973457336 norm:0.00039947539335116744 max memory_allocated 29273.43798828125 
[2025-03-02 22:56:18 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.3337450623512268 norm:0.00033953931415453553 max memory_allocated 29273.43798828125 
[2025-03-02 22:57:08 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.3335762321949005 norm:0.00030546262860298157 max memory_allocated 29273.43798828125 
[2025-03-02 22:57:58 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.3334495425224304 norm:0.0002767894766293466 max memory_allocated 29273.43798828125 
[2025-03-02 22:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.3333643674850464 norm:0.0002613955002743751 max memory_allocated 29273.43798828125 
[2025-03-02 22:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.333276629447937 norm:0.00025197601644322276 max memory_allocated 29273.43798828125 
[2025-03-02 23:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.333229660987854 norm:0.00024262088118121028 max memory_allocated 29273.43798828125 
[2025-03-02 23:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.3331682085990906 norm:0.00023837787739466876 max memory_allocated 29273.43798828125 
[2025-03-02 23:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.33311018347740173 norm:0.00023662415333092213 max memory_allocated 29273.43798828125 
[2025-03-02 23:03:00 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.33311405777931213 norm:0.0002325817767996341 max memory_allocated 29273.43798828125 
[2025-03-02 23:03:50 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.3331121504306793 norm:0.00023420507204718888 max memory_allocated 29273.43798828125 
[2025-03-02 23:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.3330998122692108 norm:0.00022902966884430498 max memory_allocated 29273.43798828125 
[2025-03-02 23:05:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.33304956555366516 norm:0.00022517616162076592 max memory_allocated 29273.43798828125 
[2025-03-02 23:06:21 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.3330390751361847 norm:0.0002229847596026957 max memory_allocated 29273.43798828125 
[2025-03-02 23:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.33301711082458496 norm:0.00022517333854921162 max memory_allocated 29273.43798828125 
[2025-03-02 23:07:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 23:07:30 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:08:21 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.3816553056240082 norm:0.006862695328891277 max memory_allocated 29273.77001953125 
[2025-03-02 23:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.3765468895435333 norm:0.005569745320826769 max memory_allocated 29273.77001953125 
[2025-03-02 23:10:01 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.3720635175704956 norm:0.004504273179918528 max memory_allocated 29273.77001953125 
[2025-03-02 23:10:52 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.369890958070755 norm:0.003602806944400072 max memory_allocated 29273.77001953125 
[2025-03-02 23:11:42 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.3692447245121002 norm:0.0029745097272098064 max memory_allocated 29273.77001953125 
[2025-03-02 23:12:33 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.3687213659286499 norm:0.002508233767002821 max memory_allocated 29273.77001953125 
[2025-03-02 23:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.36849501729011536 norm:0.002348432783037424 max memory_allocated 29273.77001953125 
[2025-03-02 23:14:14 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.36834201216697693 norm:0.002282046712934971 max memory_allocated 29273.77001953125 
[2025-03-02 23:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.36821749806404114 norm:0.002086077816784382 max memory_allocated 29273.77001953125 
[2025-03-02 23:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.3681190013885498 norm:0.0020892976317554712 max memory_allocated 29273.77001953125 
[2025-03-02 23:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.3680601119995117 norm:0.002002936787903309 max memory_allocated 29273.77001953125 
[2025-03-02 23:17:36 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.3679952621459961 norm:0.0020082471892237663 max memory_allocated 29273.77001953125 
[2025-03-02 23:18:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.36799195408821106 norm:0.001930592698045075 max memory_allocated 29273.77001953125 
[2025-03-02 23:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.3679276704788208 norm:0.0019634964410215616 max memory_allocated 29273.77001953125 
[2025-03-02 23:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.36791959404945374 norm:0.0018703164532780647 max memory_allocated 29273.77001953125 
[2025-03-02 23:20:58 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.36793461441993713 norm:0.001931795384734869 max memory_allocated 29273.77001953125 
[2025-03-02 23:21:48 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.3679751753807068 norm:0.001787259359844029 max memory_allocated 29273.77001953125 
[2025-03-02 23:22:38 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.36789703369140625 norm:0.0018872161163017154 max memory_allocated 29273.77001953125 
[2025-03-02 23:23:29 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.36782002449035645 norm:0.0017312581185251474 max memory_allocated 29273.77001953125 
[2025-03-02 23:24:19 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.3677588403224945 norm:0.0017856645863503218 max memory_allocated 29273.77001953125 
[2025-03-02 23:24:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:24:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.43304815888404846 norm:0.007740036118775606 max memory_allocated 29273.95751953125 
[2025-03-02 23:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.42380601167678833 norm:0.005711243022233248 max memory_allocated 29273.95751953125 
[2025-03-02 23:27:09 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.41760173439979553 norm:0.006211874540895224 max memory_allocated 29273.95751953125 
[2025-03-02 23:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.41508400440216064 norm:0.006262470036745071 max memory_allocated 29273.95751953125 
[2025-03-02 23:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.4142233729362488 norm:0.005807270761579275 max memory_allocated 29273.95751953125 
[2025-03-02 23:29:41 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.41360539197921753 norm:0.00504171522334218 max memory_allocated 29273.95751953125 
[2025-03-02 23:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.41310811042785645 norm:0.00521477684378624 max memory_allocated 29273.95751953125 
[2025-03-02 23:31:21 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.4127471446990967 norm:0.004988647997379303 max memory_allocated 29273.95751953125 
[2025-03-02 23:32:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.4125266969203949 norm:0.004718863405287266 max memory_allocated 29273.95751953125 
[2025-03-02 23:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.41239073872566223 norm:0.004371023271232843 max memory_allocated 29273.95751953125 
[2025-03-02 23:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.4122980237007141 norm:0.004239493049681187 max memory_allocated 29273.95751953125 
[2025-03-02 23:34:43 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.4122546315193176 norm:0.004124430939555168 max memory_allocated 29273.95751953125 
[2025-03-02 23:35:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.4123653769493103 norm:0.004356794990599155 max memory_allocated 29273.95751953125 
[2025-03-02 23:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.4124765694141388 norm:0.004500807728618383 max memory_allocated 29273.95751953125 
[2025-03-02 23:37:14 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.41263747215270996 norm:0.004409522749483585 max memory_allocated 29273.95751953125 
[2025-03-02 23:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.41213303804397583 norm:0.0037447677459567785 max memory_allocated 29273.95751953125 
[2025-03-02 23:38:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.4120628833770752 norm:0.0037460154853761196 max memory_allocated 29273.95751953125 
[2025-03-02 23:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.41202041506767273 norm:0.003624723991379142 max memory_allocated 29273.95751953125 
[2025-03-02 23:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.4119616448879242 norm:0.0036071459762752056 max memory_allocated 29273.95751953125 
[2025-03-02 23:41:26 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.4119146168231964 norm:0.003435660619288683 max memory_allocated 29273.95751953125 
[2025-03-02 23:41:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:41:45 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.5765129327774048 norm:0.03387145698070526 max memory_allocated 29274.14501953125 
[2025-03-02 23:43:26 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.5467835068702698 norm:0.025038236752152443 max memory_allocated 29274.14501953125 
[2025-03-02 23:44:16 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.5290802121162415 norm:0.01941443607211113 max memory_allocated 29274.14501953125 
[2025-03-02 23:45:06 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.5196134448051453 norm:0.015246962197124958 max memory_allocated 29274.14501953125 
[2025-03-02 23:45:57 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.5140770673751831 norm:0.01319393515586853 max memory_allocated 29274.14501953125 
[2025-03-02 23:46:47 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.5110626220703125 norm:0.01146086398512125 max memory_allocated 29274.14501953125 
[2025-03-02 23:47:38 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.5091196298599243 norm:0.010397273115813732 max memory_allocated 29274.14501953125 
[2025-03-02 23:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.5074511766433716 norm:0.009738799184560776 max memory_allocated 29274.14501953125 
[2025-03-02 23:49:19 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.506476879119873 norm:0.009367665275931358 max memory_allocated 29274.14501953125 
[2025-03-02 23:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.5061681270599365 norm:0.009106814861297607 max memory_allocated 29274.14501953125 
[2025-03-02 23:51:00 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.5053789019584656 norm:0.008324884809553623 max memory_allocated 29274.14501953125 
[2025-03-02 23:51:50 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.5050719380378723 norm:0.008221576921641827 max memory_allocated 29274.14501953125 
[2025-03-02 23:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.5044615864753723 norm:0.007554688025265932 max memory_allocated 29274.14501953125 
[2025-03-02 23:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.5040163397789001 norm:0.007321157958358526 max memory_allocated 29274.14501953125 
[2025-03-02 23:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.5039482116699219 norm:0.007662876509130001 max memory_allocated 29274.14501953125 
[2025-03-02 23:55:12 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.503939151763916 norm:0.00732220895588398 max memory_allocated 29274.14501953125 
[2025-03-02 23:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.5038430094718933 norm:0.006963170133531094 max memory_allocated 29274.14501953125 
[2025-03-02 23:56:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.5034791231155396 norm:0.006966551300138235 max memory_allocated 29274.14501953125 
[2025-03-02 23:57:43 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.5035114884376526 norm:0.007152751553803682 max memory_allocated 29274.14501953125 
[2025-03-02 23:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.5034931898117065 norm:0.007200544700026512 max memory_allocated 29274.14501953125 
[2025-03-02 23:58:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:58:52 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:59:43 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.962988555431366 norm:0.05213850736618042 max memory_allocated 29274.33251953125 
[2025-03-03 00:00:33 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.8996062278747559 norm:0.032126542180776596 max memory_allocated 29274.33251953125 
[2025-03-03 00:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.8679107427597046 norm:0.021959301084280014 max memory_allocated 29274.33251953125 
[2025-03-03 00:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.8482908606529236 norm:0.01837919093668461 max memory_allocated 29274.33251953125 
[2025-03-03 00:03:04 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.8359701633453369 norm:0.014921370893716812 max memory_allocated 29274.33251953125 
[2025-03-03 00:03:55 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.8275233507156372 norm:0.012348942458629608 max memory_allocated 29274.33251953125 
[2025-03-03 00:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.8221233487129211 norm:0.012598535045981407 max memory_allocated 29274.33251953125 
[2025-03-03 00:05:36 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.8190011978149414 norm:0.014289426617324352 max memory_allocated 29274.33251953125 
[2025-03-03 00:06:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.8169805407524109 norm:0.015300021506845951 max memory_allocated 29274.33251953125 
[2025-03-03 00:07:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.8165838718414307 norm:0.016514839604496956 max memory_allocated 29274.33251953125 
[2025-03-03 00:08:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.8149809837341309 norm:0.014358749613165855 max memory_allocated 29274.33251953125 
[2025-03-03 00:08:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.8130484819412231 norm:0.011945993639528751 max memory_allocated 29274.33251953125 
[2025-03-03 00:09:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.811812162399292 norm:0.012366648763418198 max memory_allocated 29274.33251953125 
[2025-03-03 00:10:38 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.8103310465812683 norm:0.012632304802536964 max memory_allocated 29274.33251953125 
[2025-03-03 00:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.8099392056465149 norm:0.013370191678404808 max memory_allocated 29274.33251953125 
[2025-03-03 00:12:19 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.8094054460525513 norm:0.012853207997977734 max memory_allocated 29274.33251953125 
[2025-03-03 00:13:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.8086893558502197 norm:0.01243718434125185 max memory_allocated 29274.33251953125 
[2025-03-03 00:14:00 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.809028685092926 norm:0.013001573272049427 max memory_allocated 29274.33251953125 
[2025-03-03 00:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.8081350922584534 norm:0.012219538912177086 max memory_allocated 29274.33251953125 
[2025-03-03 00:15:41 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.8074619770050049 norm:0.012166484259068966 max memory_allocated 29274.33251953125 
[2025-03-03 00:15:56 root] (main_calib_config2.py 372): INFO 41005.60988163948
[2025-03-03 00:16:06 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:18:05 root] (main_calib_config2.py 159): INFO wikitext2 : 5.210086822509766
[2025-03-03 00:18:05 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:21:11 root] (main_calib_config2.py 159): INFO c4 : 6.747143745422363
[2025-03-03 02:23:54 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.210086822509766, 'c4': 6.747143745422363, 'results': {'piqa': {'acc': 0.7834602829162133, 'acc_stderr': 0.009609984714384599, 'acc_norm': 0.779651795429815, 'acc_norm_stderr': 0.00967053545685314}, 'hellaswag': {'acc': 0.5836486755626369, 'acc_stderr': 0.0049194578501042365, 'acc_norm': 0.7564230233021311, 'acc_norm_stderr': 0.004283630516444484}, 'winogrande': {'acc': 0.6961325966850829, 'acc_stderr': 0.012926209475483579}, 'arc_challenge': {'acc': 0.4283276450511945, 'acc_stderr': 0.014460496367599022, 'acc_norm': 0.4300341296928328, 'acc_norm_stderr': 0.014467631559137994}, 'boolq': {'acc': 0.6847094801223241, 'acc_stderr': 0.008126455592662889}, 'arc_easy': {'acc': 0.7377946127946128, 'acc_stderr': 0.009025197991724817, 'acc_norm': 0.5892255892255892, 'acc_norm_stderr': 0.010095101349348648}}, 'versions': {'piqa': 0, 'hellaswag': 0, 'winogrande': 0, 'arc_challenge': 0, 'boolq': 1, 'arc_easy': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
