[2025-02-28 13:17:24 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-7b-hf_0.4', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.4.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:20:27 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:20:27 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.4.pkl
[2025-02-28 13:20:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:20:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:21:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.017905225977301598 norm:0.015470749698579311 max memory_allocated 22562.10693359375 
[2025-02-28 13:21:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.00967568252235651 norm:0.00852949172258377 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:11 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.006926071364432573 norm:0.005576315335929394 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:44 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.005944966338574886 norm:0.004950284492224455 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.005651797167956829 norm:0.006311905570328236 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.005397176370024681 norm:0.0035829346161335707 max memory_allocated 22562.10693359375 
[2025-02-28 13:24:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.005241918843239546 norm:0.002939924830570817 max memory_allocated 22562.10693359375 
[2025-02-28 13:24:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.005149892531335354 norm:0.002497216686606407 max memory_allocated 22562.10693359375 
[2025-02-28 13:25:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.005082802847027779 norm:0.003242658916860819 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.005000559613108635 norm:0.002116528805345297 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.004966560285538435 norm:0.0018315883353352547 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.00492515554651618 norm:0.001814717659726739 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.004986089188605547 norm:0.001988682895898819 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.004934558644890785 norm:0.0027082194574177265 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.004841341637074947 norm:0.0017644792096689343 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.004812187980860472 norm:0.001504753716289997 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.004837367217987776 norm:0.001429593889042735 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0047950055450201035 norm:0.0013457091990858316 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.00471912045031786 norm:0.001239361590705812 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.004764098208397627 norm:0.0011629466898739338 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:31:46 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:32:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.12790776789188385 norm:0.05337498337030411 max memory_allocated 22562.27880859375 
[2025-02-28 13:32:52 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.09867147356271744 norm:0.04320560395717621 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.0841255784034729 norm:0.03325337916612625 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.07990880310535431 norm:0.03248776122927666 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.07734961807727814 norm:0.029983723536133766 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.0761682465672493 norm:0.029231980443000793 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:37 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.07777921855449677 norm:0.02757854387164116 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.07690930366516113 norm:0.02580307610332966 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.07707872241735458 norm:0.025977561250329018 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.07749375700950623 norm:0.02500837855041027 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.07614830136299133 norm:0.023503143340349197 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.07608312368392944 norm:0.022829648107290268 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.07591210305690765 norm:0.02204245515167713 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.07602698355913162 norm:0.021681755781173706 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.0749368965625763 norm:0.020581305027008057 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.07594965398311615 norm:0.02112007699906826 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.07580708712339401 norm:0.021235940977931023 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.07494277507066727 norm:0.02021070569753647 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.07473362982273102 norm:0.019888686016201973 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.07427056133747101 norm:0.0189165361225605 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:56 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 13:42:59 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.11626584082841873 norm:0.020148394629359245 max memory_allocated 22562.45068359375 
[2025-02-28 13:44:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.09963413327932358 norm:0.014029138721525669 max memory_allocated 22562.45068359375 
[2025-02-28 13:44:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.09142470359802246 norm:0.010673735290765762 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.08814594894647598 norm:0.008683258667588234 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:45 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.08621194213628769 norm:0.007146832533180714 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.08490517735481262 norm:0.005457011982798576 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.0840458869934082 norm:0.004563052207231522 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.08360221236944199 norm:0.004060857929289341 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.08324915170669556 norm:0.004009176045656204 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.0830266922712326 norm:0.003863256424665451 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.08284314721822739 norm:0.0037127237301319838 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:37 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.08263750374317169 norm:0.00344462669454515 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.0825846716761589 norm:0.003314427100121975 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.08245299011468887 norm:0.00322068203240633 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.08246420323848724 norm:0.0031280783005058765 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.08240418881177902 norm:0.003141154069453478 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.08237992227077484 norm:0.0031655537895858288 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.082368403673172 norm:0.0032965943682938814 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.08238302916288376 norm:0.0033083786256611347 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.0823519229888916 norm:0.003276350675150752 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 13:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.11195573210716248 norm:0.009993692860007286 max memory_allocated 22562.50732421875 
[2025-02-28 13:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.09325358271598816 norm:0.002844085218384862 max memory_allocated 22562.50732421875 
[2025-02-28 13:55:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.08483201265335083 norm:0.0016529805725440383 max memory_allocated 22562.50732421875 
[2025-02-28 13:56:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.0814405232667923 norm:0.0010174353374168277 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.07973255217075348 norm:0.0007476615719497204 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.07893997430801392 norm:0.0006281213718466461 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.0785880833864212 norm:0.0005672081606462598 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.07840559631586075 norm:0.000515551189891994 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.07830534130334854 norm:0.0006601482164114714 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.07815266400575638 norm:0.0005305536324158311 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.07807737588882446 norm:0.0004822170012630522 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.0780288577079773 norm:0.0004653882933780551 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.07796876132488251 norm:0.0004578286607284099 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.07785997539758682 norm:0.000453128304798156 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.07785242795944214 norm:0.000453798973467201 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:04 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.07778283208608627 norm:0.00045769510325044394 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.07778734713792801 norm:0.0004494989989325404 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.07776171714067459 norm:0.00044593075290322304 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:43 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.0777386948466301 norm:0.0004475994792301208 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.07771613448858261 norm:0.0004672137147281319 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.13295096158981323 norm:0.01460958831012249 max memory_allocated 22562.67919921875 
[2025-02-28 14:06:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.10831384360790253 norm:0.0054130093194544315 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.09161850064992905 norm:0.0029307142831385136 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:41 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.08717136085033417 norm:0.0017323922365903854 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:14 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.08503325283527374 norm:0.0012031046207994223 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.08403871953487396 norm:0.0010655729565769434 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.08348827064037323 norm:0.0008664844208396971 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.08311588317155838 norm:0.0007683380390517414 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.0829017162322998 norm:0.0006909673102200031 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.08278482407331467 norm:0.000713896588422358 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.08267739415168762 norm:0.0007016176823526621 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.08260060846805573 norm:0.0006425348692573607 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.08247873932123184 norm:0.0006618911866098642 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.08241086453199387 norm:0.0006305406568571925 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.08241669833660126 norm:0.0005939900875091553 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.08246465772390366 norm:0.0005725753144361079 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.08249112218618393 norm:0.0005629369989037514 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.08249747008085251 norm:0.0005649345112033188 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.08250561356544495 norm:0.0005416619824245572 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.08246546983718872 norm:0.0005510704941116273 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:17:15 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.13834187388420105 norm:0.012496637180447578 max memory_allocated 22562.85107421875 
[2025-02-28 14:17:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.11730120331048965 norm:0.005468614399433136 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.09816815704107285 norm:0.0019425534410402179 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.09253445267677307 norm:0.0012282839743420482 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.09022067487239838 norm:0.001045693876221776 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.0890008732676506 norm:0.0008163330494426191 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.08838064968585968 norm:0.0006934158154763281 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.08806166797876358 norm:0.0006211274885572493 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.08789008855819702 norm:0.0005925217992626131 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.08766724169254303 norm:0.0005787344416603446 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.08747915923595428 norm:0.0005875699571333826 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.08741611987352371 norm:0.0006078742444515228 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:52 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.08738233149051666 norm:0.0006209681741893291 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:25 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.0874224603176117 norm:0.0005888625746592879 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:58 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.0873623862862587 norm:0.0006058969884179533 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.08733007311820984 norm:0.0006367397727444768 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.08736807852983475 norm:0.0005975152598693967 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.08739900588989258 norm:0.0005443526315502822 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.08743089437484741 norm:0.0005377278430387378 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.08752623945474625 norm:0.0005135554238222539 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 14:28:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.1465180516242981 norm:0.013989493250846863 max memory_allocated 22563.02294921875 
[2025-02-28 14:29:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.12066086381673813 norm:0.004980397876352072 max memory_allocated 22563.02294921875 
[2025-02-28 14:29:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.1070520356297493 norm:0.0027702089864760637 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.10189390927553177 norm:0.0018019367707893252 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.09946241229772568 norm:0.0014385024551302195 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.09826620668172836 norm:0.0010761196026578546 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.09754131734371185 norm:0.0008771460270509124 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.097132608294487 norm:0.0007707579061388969 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.09679004549980164 norm:0.000738862669095397 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.0965973287820816 norm:0.0006752483313903213 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.09648482501506805 norm:0.0006134647992439568 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.09635340422391891 norm:0.0005891962791793048 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.09627056121826172 norm:0.0005685813957825303 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.0962621346116066 norm:0.0005433186888694763 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.0963662788271904 norm:0.0005360338254831731 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:45 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.0965508371591568 norm:0.0005610525840893388 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.09670086950063705 norm:0.000552824349142611 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:52 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.09682875126600266 norm:0.0005202015163376927 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.09693805128335953 norm:0.0005239318707026541 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.09704218804836273 norm:0.0005202907486818731 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 14:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.15360569953918457 norm:0.008383167907595634 max memory_allocated 22563.19482421875 
[2025-02-28 14:40:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.12522894144058228 norm:0.01087061408907175 max memory_allocated 22563.19482421875 
[2025-02-28 14:40:49 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.11221255362033844 norm:0.0014722238993272185 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.10763481259346008 norm:0.0010579255176708102 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.10538382828235626 norm:0.0008357156766578555 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.10422564297914505 norm:0.000715356320142746 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.1035979837179184 norm:0.0006306669092737138 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.10309187322854996 norm:0.0005556439864449203 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.1027943417429924 norm:0.0004832883132621646 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.10265178233385086 norm:0.0004743094614241272 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.10257288068532944 norm:0.00044749287189915776 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.10260215401649475 norm:0.00042410066816955805 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.10254634916782379 norm:0.0004142074612900615 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.1024993360042572 norm:0.00040664547123014927 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.1024608388543129 norm:0.00039379033842124045 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.10255474597215652 norm:0.00041231626528315246 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.10253246128559113 norm:0.000395173323340714 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:05 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.10242535173892975 norm:0.000399281270802021 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.10237637162208557 norm:0.0003985898511018604 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:12 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.10236221551895142 norm:0.0004099024517927319 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 14:50:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.15185992419719696 norm:0.004279395565390587 max memory_allocated 22563.36669921875 
[2025-02-28 14:51:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.13060598075389862 norm:0.0018292616587132215 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:03 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.1190861389040947 norm:0.0010481756180524826 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.11472535878419876 norm:0.0007103514508344233 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.11259616911411285 norm:0.0005639242590405047 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.11156391352415085 norm:0.00048097193939611316 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.11107952147722244 norm:0.00044714592513628304 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.11071860045194626 norm:0.0004146806022617966 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.11047274619340897 norm:0.0003988241369370371 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.11035715788602829 norm:0.0003834288800135255 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.11026205867528915 norm:0.0003776812518481165 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.11016007512807846 norm:0.000380367215257138 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.11012053489685059 norm:0.00037087511736899614 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.11003140360116959 norm:0.0003725750430021435 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.10997988283634186 norm:0.0003780114930123091 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.10998314619064331 norm:0.000367847882444039 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:46 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.10995520651340485 norm:0.00037001181044615805 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.10993868857622147 norm:0.00037186723784543574 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:53 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.10992006957530975 norm:0.0003734893980436027 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.10990587621927261 norm:0.00036892140633426607 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 15:02:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.16238094866275787 norm:0.006839659996330738 max memory_allocated 22563.53857421875 
[2025-02-28 15:02:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.13790583610534668 norm:0.0021113501861691475 max memory_allocated 22563.53857421875 
[2025-02-28 15:03:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.12464095652103424 norm:0.0009073666296899319 max memory_allocated 22563.53857421875 
[2025-02-28 15:03:50 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.12014085054397583 norm:0.0005537064280360937 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.1181490421295166 norm:0.0004239422269165516 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.11708606779575348 norm:0.0003628542472142726 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.11659625172615051 norm:0.0003436408005654812 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.11629102379083633 norm:0.00032883731182664633 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.11607178300619125 norm:0.0003195229801349342 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.1158890500664711 norm:0.00032498917425982654 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.11578324437141418 norm:0.0003163652145303786 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.11570937186479568 norm:0.0003156123566441238 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.11568949371576309 norm:0.0003162918728776276 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.11564283818006516 norm:0.00032199130509980023 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.11560090631246567 norm:0.0003171689168084413 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.11556389182806015 norm:0.0003124997892882675 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.11550433933734894 norm:0.00032091798493638635 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.11546342074871063 norm:0.00032216834370046854 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.11545524001121521 norm:0.00031876174034550786 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.11549883335828781 norm:0.0003166966198477894 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 15:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.1586902141571045 norm:0.002652026480063796 max memory_allocated 22563.71044921875 
[2025-02-28 15:13:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.14068755507469177 norm:0.0013091206783428788 max memory_allocated 22563.71044921875 
[2025-02-28 15:14:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.12907379865646362 norm:0.0007199054816737771 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.12452614307403564 norm:0.0004966854467056692 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.12262266874313354 norm:0.0004009916156064719 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.12168046832084656 norm:0.0003580607590265572 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.12115119397640228 norm:0.0003383196599315852 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.12085942924022675 norm:0.0003291150205768645 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.12069955468177795 norm:0.00032538577215746045 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.12055458128452301 norm:0.0003263215476181358 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.12045453488826752 norm:0.00032171569182537496 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:29 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.12037664651870728 norm:0.0003166383830830455 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.12026806175708771 norm:0.0003106424992438406 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.12021106481552124 norm:0.00031505327206104994 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.12017276138067245 norm:0.0003119130851700902 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.12014594674110413 norm:0.00031435664277523756 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.12008538842201233 norm:0.0003130811091978103 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.12006304413080215 norm:0.0003162948996759951 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.12003756314516068 norm:0.0003148532414343208 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.11997181177139282 norm:0.0003175032907165587 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 15:24:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.16395707428455353 norm:0.008219280280172825 max memory_allocated 22563.88232421875 
[2025-02-28 15:25:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.14271074533462524 norm:0.004001383204013109 max memory_allocated 22563.88232421875 
[2025-02-28 15:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.13055527210235596 norm:0.0020077265799045563 max memory_allocated 22563.88232421875 
[2025-02-28 15:26:18 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.12570816278457642 norm:0.0010904795490205288 max memory_allocated 22563.88232421875 
[2025-02-28 15:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.12344107031822205 norm:0.0004379574384074658 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.12247364223003387 norm:0.0004056767502333969 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.1219952404499054 norm:0.0003776088124141097 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.1217215359210968 norm:0.00035696959821507335 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.12152842432260513 norm:0.0003479409497231245 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.12138670682907104 norm:0.0003344187280163169 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.12133654952049255 norm:0.000332097610225901 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.12125899642705917 norm:0.0003302124096080661 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.1211816817522049 norm:0.0003291538159828633 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:50 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.12112747132778168 norm:0.00032325275242328644 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.12113168090581894 norm:0.0003206777910236269 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:56 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.12111623585224152 norm:0.0003120824694633484 max memory_allocated 22563.88232421875 
[2025-02-28 15:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.12110410630702972 norm:0.00031480705365538597 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.1210654005408287 norm:0.0003105365904048085 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.1210707277059555 norm:0.00031118676997721195 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:08 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.12105745822191238 norm:0.00030665050144307315 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 15:35:54 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.15953025221824646 norm:0.002872937358915806 max memory_allocated 22564.05419921875 
[2025-02-28 15:36:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.1424582600593567 norm:0.0013787366915494204 max memory_allocated 22564.05419921875 
[2025-02-28 15:37:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.13202674686908722 norm:0.0008249506936408579 max memory_allocated 22564.05419921875 
[2025-02-28 15:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.12789107859134674 norm:0.000539311848115176 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.12604621052742004 norm:0.00040477956645190716 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.12503965198993683 norm:0.00034428894286975265 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.12457281351089478 norm:0.0003178977349307388 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.12431538850069046 norm:0.0003017834387719631 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.1241363063454628 norm:0.000301171385217458 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.12403078377246857 norm:0.0002939074474852532 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.12390588223934174 norm:0.00028888971428386867 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.12384150922298431 norm:0.00028884640778414905 max memory_allocated 22564.05419921875 
[2025-02-28 15:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.12377992272377014 norm:0.0002887925656978041 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.12371297180652618 norm:0.00028538439073599875 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:37 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.12370015680789948 norm:0.000280505686532706 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.12365598976612091 norm:0.00027989872614853084 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.12363183498382568 norm:0.0002773621818050742 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.12361711263656616 norm:0.000277288316283375 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.12360416352748871 norm:0.00027794274501502514 max memory_allocated 22564.05419921875 
[2025-02-28 15:46:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.12360208481550217 norm:0.00028054119320586324 max memory_allocated 22564.05419921875 
[2025-02-28 15:46:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 15:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.15017053484916687 norm:0.0030003641732037067 max memory_allocated 22564.22607421875 
[2025-02-28 15:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.13561196625232697 norm:0.0013563965912908316 max memory_allocated 22564.22607421875 
[2025-02-28 15:48:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.12698739767074585 norm:0.0007267376640811563 max memory_allocated 22564.22607421875 
[2025-02-28 15:48:47 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.12357061356306076 norm:0.000487701065139845 max memory_allocated 22564.22607421875 
[2025-02-28 15:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.12197922170162201 norm:0.00038259982829913497 max memory_allocated 22564.22607421875 
[2025-02-28 15:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.1210891455411911 norm:0.00032940058736130595 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.12063366174697876 norm:0.0002990116481669247 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.1203974112868309 norm:0.00028118700720369816 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.12018416076898575 norm:0.00026906546554528177 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.12008313089609146 norm:0.00026281055761501193 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.12000268697738647 norm:0.00025915182777680457 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.11992336064577103 norm:0.0002570271899458021 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.11983054131269455 norm:0.0002552188525442034 max memory_allocated 22564.22607421875 
[2025-02-28 15:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.11978431046009064 norm:0.00025351307704113424 max memory_allocated 22564.22607421875 
[2025-02-28 15:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.1197529062628746 norm:0.00025042661582119763 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.11971604824066162 norm:0.0002526858588680625 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.11969608068466187 norm:0.0002499959955457598 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.11968335509300232 norm:0.00025046171504072845 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.11964691430330276 norm:0.00024876106181181967 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.11962021142244339 norm:0.00025058933533728123 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 15:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.14682094752788544 norm:0.001956809079274535 max memory_allocated 22564.39794921875 
[2025-02-28 15:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.13436558842658997 norm:0.0008926080772653222 max memory_allocated 22564.39794921875 
[2025-02-28 15:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.12655115127563477 norm:0.0005206345813348889 max memory_allocated 22564.39794921875 
[2025-02-28 16:00:01 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.12337712943553925 norm:0.0003620507486630231 max memory_allocated 22564.39794921875 
[2025-02-28 16:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.12194570153951645 norm:0.00029721696046181023 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.12115240842103958 norm:0.0002630041853990406 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:40 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.12077241390943527 norm:0.0002454267523717135 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.12051788717508316 norm:0.00023681888706050813 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.12035953998565674 norm:0.00023097143275663257 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.1202738955616951 norm:0.0002306690439581871 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.12020820379257202 norm:0.00023177199182100594 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.12014225125312805 norm:0.00023277818399947137 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:59 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.1200685203075409 norm:0.0002288924006279558 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.12002834677696228 norm:0.0002273527206853032 max memory_allocated 22564.39794921875 
[2025-02-28 16:06:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.11999882757663727 norm:0.00022580174845643342 max memory_allocated 22564.39794921875 
[2025-02-28 16:06:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.11997698247432709 norm:0.0002296353632118553 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.11995764076709747 norm:0.00023079391394276172 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.11994053423404694 norm:0.0002279464533785358 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.1199052557349205 norm:0.00022963728406466544 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.11988914757966995 norm:0.00022771161457058042 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 16:09:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.1491047590970993 norm:0.0027910592034459114 max memory_allocated 22564.56982421875 
[2025-02-28 16:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.13402821123600006 norm:0.0011849012225866318 max memory_allocated 22564.56982421875 
[2025-02-28 16:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.12489674985408783 norm:0.0006526510696858168 max memory_allocated 22564.56982421875 
[2025-02-28 16:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.12146066129207611 norm:0.00044365815119817853 max memory_allocated 22564.56982421875 
[2025-02-28 16:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.11990120261907578 norm:0.0003482697356957942 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.11906633526086807 norm:0.0002995838294737041 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.11863692849874496 norm:0.0002779706846922636 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.11834444105625153 norm:0.00025690984330140054 max memory_allocated 22564.56982421875 
[2025-02-28 16:14:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.11817309260368347 norm:0.0002487286110408604 max memory_allocated 22564.56982421875 
[2025-02-28 16:14:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.11802889406681061 norm:0.00023325026268139482 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.11795054376125336 norm:0.0002305208327015862 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.11786822974681854 norm:0.0002303594519617036 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.11780981719493866 norm:0.0002292474964633584 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.11777126044034958 norm:0.00022687572345603257 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:19 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.11773286014795303 norm:0.00022711302153766155 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.11771182715892792 norm:0.0002257452579215169 max memory_allocated 22564.56982421875 
[2025-02-28 16:18:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.11769691109657288 norm:0.00022534214076586068 max memory_allocated 22564.56982421875 
[2025-02-28 16:18:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.11766457557678223 norm:0.00022401729074772447 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:32 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.11763998866081238 norm:0.0002222748880740255 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.11760983616113663 norm:0.00022461102344095707 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 16:20:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.14721110463142395 norm:0.0028350164648145437 max memory_allocated 22564.74169921875 
[2025-02-28 16:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.13337868452072144 norm:0.001209751470014453 max memory_allocated 22564.74169921875 
[2025-02-28 16:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.12424878776073456 norm:0.000649448367767036 max memory_allocated 22564.74169921875 
[2025-02-28 16:22:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.12113861739635468 norm:0.00045718243927694857 max memory_allocated 22564.74169921875 
[2025-02-28 16:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.11961984634399414 norm:0.0003659028734546155 max memory_allocated 22564.74169921875 
[2025-02-28 16:23:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.11879052221775055 norm:0.00031644507544115186 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.11831773817539215 norm:0.0002898763632401824 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.11800840497016907 norm:0.0002662318293005228 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.11782899498939514 norm:0.0002575558901298791 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.11771529912948608 norm:0.0002467602025717497 max memory_allocated 22564.74169921875 
[2025-02-28 16:26:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.1176043376326561 norm:0.00024081917945295572 max memory_allocated 22564.74169921875 
[2025-02-28 16:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.11753746122121811 norm:0.00023590931959915906 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.11748798191547394 norm:0.00023207420599646866 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.11744063347578049 norm:0.00022904371144250035 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:33 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.11741998046636581 norm:0.0002304418885614723 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.1173844113945961 norm:0.0002271087432745844 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.11734778434038162 norm:0.00022926757810637355 max memory_allocated 22564.74169921875 
[2025-02-28 16:30:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.11730103194713593 norm:0.00022746140894014388 max memory_allocated 22564.74169921875 
[2025-02-28 16:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.11727020889520645 norm:0.00022864597849547863 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.11723658442497253 norm:0.00022914893634151667 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 16:32:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.1385534405708313 norm:0.002099512843415141 max memory_allocated 22564.91357421875 
[2025-02-28 16:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.12940770387649536 norm:0.0007122698007151484 max memory_allocated 22564.91357421875 
[2025-02-28 16:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.12311913073062897 norm:0.00039702001959085464 max memory_allocated 22564.91357421875 
[2025-02-28 16:33:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.12097890675067902 norm:0.00031294446671381593 max memory_allocated 22564.91357421875 
[2025-02-28 16:34:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.11976459622383118 norm:0.0002729046100284904 max memory_allocated 22564.91357421875 
[2025-02-28 16:34:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.11904213577508926 norm:0.00024192333512473851 max memory_allocated 22564.91357421875 
[2025-02-28 16:35:22 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.11862073093652725 norm:0.0002175041299778968 max memory_allocated 22564.91357421875 
[2025-02-28 16:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.11840809136629105 norm:0.00020785050583072007 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.1182815358042717 norm:0.00020470393064897507 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.11817160248756409 norm:0.00020244003098923713 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.11808519810438156 norm:0.00020024219702463597 max memory_allocated 22564.91357421875 
[2025-02-28 16:38:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.11800733208656311 norm:0.00019764716853387654 max memory_allocated 22564.91357421875 
[2025-02-28 16:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.11796094477176666 norm:0.00019630507449619472 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.11792725324630737 norm:0.0001948259014170617 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.11785643547773361 norm:0.00019321643048897386 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.117820143699646 norm:0.0001949748839251697 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.11777828633785248 norm:0.00019081604841630906 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.117765411734581 norm:0.00019476340094115585 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.11773641407489777 norm:0.00019678921671584249 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.11772287636995316 norm:0.00019846734357997775 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 16:43:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.14521975815296173 norm:0.0018222149228677154 max memory_allocated 22565.08544921875 
[2025-02-28 16:43:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.1359681487083435 norm:0.0008789359708316624 max memory_allocated 22565.08544921875 
[2025-02-28 16:44:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.1293337047100067 norm:0.0005472601042129099 max memory_allocated 22565.08544921875 
[2025-02-28 16:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.126996710896492 norm:0.0003948700614273548 max memory_allocated 22565.08544921875 
[2025-02-28 16:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.12565837800502777 norm:0.0003141254128422588 max memory_allocated 22565.08544921875 
[2025-02-28 16:46:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.12487789988517761 norm:0.0002666448999661952 max memory_allocated 22565.08544921875 
[2025-02-28 16:46:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.12451242655515671 norm:0.00024240880156867206 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.12428554892539978 norm:0.00022226346482057124 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.12416556477546692 norm:0.00021089738584123552 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.12404809147119522 norm:0.00020596945250872523 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.12395953387022018 norm:0.00020221718295942992 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.12391465902328491 norm:0.00019700439588632435 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.12384585291147232 norm:0.00019172985048498958 max memory_allocated 22565.08544921875 
[2025-02-28 16:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.12378407269716263 norm:0.00019194715423509479 max memory_allocated 22565.08544921875 
[2025-02-28 16:51:03 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.12377384305000305 norm:0.00018823586287908256 max memory_allocated 22565.08544921875 
[2025-02-28 16:51:36 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.1237378716468811 norm:0.00018703484965953976 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.1237068623304367 norm:0.0001849901891546324 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.12366822361946106 norm:0.0001838481693994254 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.12365049123764038 norm:0.00018543821352068335 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.1236196756362915 norm:0.00018461045692674816 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 16:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.1533181220293045 norm:0.0021206114906817675 max memory_allocated 22565.25732421875 
[2025-02-28 16:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.1448286771774292 norm:0.000865118985529989 max memory_allocated 22565.25732421875 
[2025-02-28 16:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.13760599493980408 norm:0.00043882703175768256 max memory_allocated 22565.25732421875 
[2025-02-28 16:56:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.13541573286056519 norm:0.0003047097416128963 max memory_allocated 22565.25732421875 
[2025-02-28 16:56:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.13421589136123657 norm:0.00024318746000062674 max memory_allocated 22565.25732421875 
[2025-02-28 16:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.1335589438676834 norm:0.00021269400895107538 max memory_allocated 22565.25732421875 
[2025-02-28 16:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.13321462273597717 norm:0.0001950951700564474 max memory_allocated 22565.25732421875 
[2025-02-28 16:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.13302773237228394 norm:0.0001819882309064269 max memory_allocated 22565.25732421875 
[2025-02-28 16:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.132884681224823 norm:0.0001749891962390393 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.13275566697120667 norm:0.0001701612927718088 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.1326543688774109 norm:0.00016675861843395978 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.13258042931556702 norm:0.0001650271296966821 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.13251255452632904 norm:0.000164628800121136 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.132463276386261 norm:0.0001622664713067934 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.132402241230011 norm:0.00016172329196706414 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.1323651671409607 norm:0.00016221217811107635 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.1323467344045639 norm:0.00016366342606488615 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.1323052942752838 norm:0.00016457798483315855 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:31 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.1322844922542572 norm:0.00016080659406725317 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.13226601481437683 norm:0.00016204293933697045 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 17:05:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.16661031544208527 norm:0.002360119018703699 max memory_allocated 22565.42919921875 
[2025-02-28 17:06:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.15737015008926392 norm:0.0009482319001108408 max memory_allocated 22565.42919921875 
[2025-02-28 17:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.1500595360994339 norm:0.0004470234562177211 max memory_allocated 22565.42919921875 
[2025-02-28 17:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.14771972596645355 norm:0.000339056015945971 max memory_allocated 22565.42919921875 
[2025-02-28 17:08:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.14638949930667877 norm:0.00029201977304182947 max memory_allocated 22565.42919921875 
[2025-02-28 17:08:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.145671546459198 norm:0.0002638745936565101 max memory_allocated 22565.42919921875 
[2025-02-28 17:09:09 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.14525078237056732 norm:0.0002445127465762198 max memory_allocated 22565.42919921875 
[2025-02-28 17:09:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.14501775801181793 norm:0.000231335056014359 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:15 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.14484018087387085 norm:0.0002219243615400046 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.1447092741727829 norm:0.00021346111316233873 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.1445891410112381 norm:0.0002102825092151761 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.14448437094688416 norm:0.00020768909598700702 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.14441753923892975 norm:0.0002072935749311 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.14434875547885895 norm:0.0002042053238255903 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.14430031180381775 norm:0.000205264484975487 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.14425614476203918 norm:0.0002042750274995342 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.14422890543937683 norm:0.00019873752899002284 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.14420247077941895 norm:0.00019929670088458806 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.14415894448757172 norm:0.0001993826444959268 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.14413908123970032 norm:0.00020023803517688066 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 17:17:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.17826014757156372 norm:0.0021139588207006454 max memory_allocated 22565.60107421875 
[2025-02-28 17:17:39 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.1694805920124054 norm:0.0007132389582693577 max memory_allocated 22565.60107421875 
[2025-02-28 17:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.16304826736450195 norm:0.0003403682494536042 max memory_allocated 22565.60107421875 
[2025-02-28 17:18:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.16122132539749146 norm:0.0002652083057910204 max memory_allocated 22565.60107421875 
[2025-02-28 17:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.1600324660539627 norm:0.00022887435625307262 max memory_allocated 22565.60107421875 
[2025-02-28 17:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.1593201756477356 norm:0.00020798793411813676 max memory_allocated 22565.60107421875 
[2025-02-28 17:20:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.15899524092674255 norm:0.00019155828340444714 max memory_allocated 22565.60107421875 
[2025-02-28 17:20:58 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.15879757702350616 norm:0.00018744214321486652 max memory_allocated 22565.60107421875 
[2025-02-28 17:21:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.15865777432918549 norm:0.00018482390441931784 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.15852834284305573 norm:0.00018659242778085172 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.1584503948688507 norm:0.00017911747272592038 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.15839381515979767 norm:0.0001829105312936008 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.15833796560764313 norm:0.00017523582209832966 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.1582724004983902 norm:0.0001752651878632605 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.1582164764404297 norm:0.0001743731991155073 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.15818271040916443 norm:0.0001735252299113199 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.1581362634897232 norm:0.0001739819417707622 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.15808513760566711 norm:0.0001717039558570832 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.15806350111961365 norm:0.00017077717348001897 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.15804451704025269 norm:0.00016974529717117548 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 17:28:21 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.20106075704097748 norm:0.003107198979705572 max memory_allocated 22565.77294921875 
[2025-02-28 17:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.19102349877357483 norm:0.0009918076684698462 max memory_allocated 22565.77294921875 
[2025-02-28 17:29:28 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.18343797326087952 norm:0.0005187770584598184 max memory_allocated 22565.77294921875 
[2025-02-28 17:30:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.18072888255119324 norm:0.00039791493327356875 max memory_allocated 22565.77294921875 
[2025-02-28 17:30:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.17936858534812927 norm:0.00036428129533305764 max memory_allocated 22565.77294921875 
[2025-02-28 17:31:07 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.17872802913188934 norm:0.0003591175191104412 max memory_allocated 22565.77294921875 
[2025-02-28 17:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.17849689722061157 norm:0.0003299587988294661 max memory_allocated 22565.77294921875 
[2025-02-28 17:32:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.17824840545654297 norm:0.0003008961502928287 max memory_allocated 22565.77294921875 
[2025-02-28 17:32:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.17804354429244995 norm:0.0002919005637522787 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.17787787318229675 norm:0.0003152904682792723 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.17778272926807404 norm:0.00028587080305442214 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.1776077300310135 norm:0.0002880640095099807 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.17752736806869507 norm:0.0002730849664658308 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.1775452196598053 norm:0.00029010488651692867 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.1774519681930542 norm:0.0003027785860467702 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.17736585438251495 norm:0.000298917293548584 max memory_allocated 22565.77294921875 
[2025-02-28 17:37:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.17739541828632355 norm:0.000296185229672119 max memory_allocated 22565.77294921875 
[2025-02-28 17:37:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.17735405266284943 norm:0.00028171634767204523 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.17726702988147736 norm:0.00030244674417190254 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.17722728848457336 norm:0.0002911531482823193 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 17:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.22094029188156128 norm:0.002122029894962907 max memory_allocated 22565.94482421875 
[2025-02-28 17:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.21227926015853882 norm:0.0010560196824371815 max memory_allocated 22565.94482421875 
[2025-02-28 17:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.20485880970954895 norm:0.0006431868532672524 max memory_allocated 22565.94482421875 
[2025-02-28 17:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.20261846482753754 norm:0.00045654442510567605 max memory_allocated 22565.94482421875 
[2025-02-28 17:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.20118831098079681 norm:0.0003516865544952452 max memory_allocated 22565.94482421875 
[2025-02-28 17:42:24 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.2005210816860199 norm:0.0002905330911744386 max memory_allocated 22565.94482421875 
[2025-02-28 17:42:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.20016983151435852 norm:0.0002532296348363161 max memory_allocated 22565.94482421875 
[2025-02-28 17:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.199981689453125 norm:0.0002238948072772473 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.19983258843421936 norm:0.00020785880042240024 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.19971348345279694 norm:0.00019897616584785283 max memory_allocated 22565.94482421875 
[2025-02-28 17:45:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.19963601231575012 norm:0.00019168731523677707 max memory_allocated 22565.94482421875 
[2025-02-28 17:45:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.19955238699913025 norm:0.00018383788119535893 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.1994723528623581 norm:0.00017976973322220147 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.19938871264457703 norm:0.00017607712652534246 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.1993194967508316 norm:0.00017349247355014086 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.19925323128700256 norm:0.00017398128693457693 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.1992322951555252 norm:0.0001729663781588897 max memory_allocated 22565.94482421875 
[2025-02-28 17:49:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.1991889476776123 norm:0.0001699747226666659 max memory_allocated 22565.94482421875 
[2025-02-28 17:49:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.19914227724075317 norm:0.00016911278362385929 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.1991083174943924 norm:0.00016920320922508836 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 17:50:54 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.24767343699932098 norm:0.003996331710368395 max memory_allocated 22566.11669921875 
[2025-02-28 17:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.23646092414855957 norm:0.0010242483112961054 max memory_allocated 22566.11669921875 
[2025-02-28 17:52:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.2285504788160324 norm:0.000597188773099333 max memory_allocated 22566.11669921875 
[2025-02-28 17:52:33 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.22589386999607086 norm:0.00042454758659005165 max memory_allocated 22566.11669921875 
[2025-02-28 17:53:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.22440536320209503 norm:0.00037390165380202234 max memory_allocated 22566.11669921875 
[2025-02-28 17:53:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.22373075783252716 norm:0.0003424610767979175 max memory_allocated 22566.11669921875 
[2025-02-28 17:54:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.22343645989894867 norm:0.000314882694510743 max memory_allocated 22566.11669921875 
[2025-02-28 17:54:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.2232384830713272 norm:0.0002834700862877071 max memory_allocated 22566.11669921875 
[2025-02-28 17:55:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.22303353250026703 norm:0.0002649972157087177 max memory_allocated 22566.11669921875 
[2025-02-28 17:55:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.22290565073490143 norm:0.0002525999443605542 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.22279466688632965 norm:0.00026764889480546117 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.22267350554466248 norm:0.000251166638918221 max memory_allocated 22566.11669921875 
[2025-02-28 17:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.22259317338466644 norm:0.0002507395693100989 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.2225559949874878 norm:0.00024819900863803923 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:39 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.22250041365623474 norm:0.0002506303135305643 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.22241660952568054 norm:0.0002518417895771563 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.2223954051733017 norm:0.00027311756275594234 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.2223939150571823 norm:0.0002758673799689859 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.22237330675125122 norm:0.00025446704239584506 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.22234193980693817 norm:0.00024212649441324174 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 18:02:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.27877509593963623 norm:0.0015470001380890608 max memory_allocated 22566.28857421875 
[2025-02-28 18:02:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.268807977437973 norm:0.000866018352098763 max memory_allocated 22566.28857421875 
[2025-02-28 18:03:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.2599954307079315 norm:0.0005199647275730968 max memory_allocated 22566.28857421875 
[2025-02-28 18:03:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.2572040557861328 norm:0.00039682607166469097 max memory_allocated 22566.28857421875 
[2025-02-28 18:04:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.2555686831474304 norm:0.0003358082612976432 max memory_allocated 22566.28857421875 
[2025-02-28 18:04:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.25487151741981506 norm:0.000287830043816939 max memory_allocated 22566.28857421875 
[2025-02-28 18:05:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.2545337378978729 norm:0.00026165531016886234 max memory_allocated 22566.28857421875 
[2025-02-28 18:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.25424349308013916 norm:0.0002629521768540144 max memory_allocated 22566.28857421875 
[2025-02-28 18:06:35 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.25403162837028503 norm:0.00025314107188023627 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.25387322902679443 norm:0.0002463750424794853 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.253723680973053 norm:0.0002429900923743844 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.25362223386764526 norm:0.00023715596762485802 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.25352227687835693 norm:0.000233798535191454 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.2534751296043396 norm:0.00023040446103550494 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.25338447093963623 norm:0.0002302768116351217 max memory_allocated 22566.28857421875 
[2025-02-28 18:10:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.25332507491111755 norm:0.000228056131163612 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.2532690167427063 norm:0.00022778002312406898 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.25324884057044983 norm:0.000229257857427001 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.25320854783058167 norm:0.00022643226839136332 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.25314685702323914 norm:0.0002283469366375357 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 18:13:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.3136151134967804 norm:0.003161896485835314 max memory_allocated 22566.46044921875 
[2025-02-28 18:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.3028162121772766 norm:0.0014851668383926153 max memory_allocated 22566.46044921875 
[2025-02-28 18:14:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.29220113158226013 norm:0.0006461020093411207 max memory_allocated 22566.46044921875 
[2025-02-28 18:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.2887173295021057 norm:0.0004816936270799488 max memory_allocated 22566.46044921875 
[2025-02-28 18:15:39 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.287020742893219 norm:0.00040772196371108294 max memory_allocated 22566.46044921875 
[2025-02-28 18:16:12 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.28632763028144836 norm:0.0003480983432382345 max memory_allocated 22566.46044921875 
[2025-02-28 18:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.2859504222869873 norm:0.0003190461138729006 max memory_allocated 22566.46044921875 
[2025-02-28 18:17:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.2856365442276001 norm:0.0002887102891691029 max memory_allocated 22566.46044921875 
[2025-02-28 18:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.28542953729629517 norm:0.0002754402521532029 max memory_allocated 22566.46044921875 
[2025-02-28 18:18:25 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.28527653217315674 norm:0.00026856723707169294 max memory_allocated 22566.46044921875 
[2025-02-28 18:18:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.28509968519210815 norm:0.0002597775892354548 max memory_allocated 22566.46044921875 
[2025-02-28 18:19:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.2849873900413513 norm:0.00026509197778068483 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.2849160134792328 norm:0.00026144683943130076 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.28488093614578247 norm:0.0002599355357233435 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.28479230403900146 norm:0.00025302328867837787 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.2847309112548828 norm:0.00025191414169967175 max memory_allocated 22566.46044921875 
[2025-02-28 18:22:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.28465530276298523 norm:0.00025140249636024237 max memory_allocated 22566.46044921875 
[2025-02-28 18:22:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.2845810651779175 norm:0.0002472289779689163 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.28457796573638916 norm:0.00025239665410481393 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.2845889627933502 norm:0.0002508062752895057 max memory_allocated 22566.46044921875 
[2025-02-28 18:24:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 18:24:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.3527461886405945 norm:0.00590065773576498 max memory_allocated 22566.63232421875 
[2025-02-28 18:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.3392814099788666 norm:0.0019136613700538874 max memory_allocated 22566.63232421875 
[2025-02-28 18:25:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.3282938599586487 norm:0.0006858576089143753 max memory_allocated 22566.63232421875 
[2025-02-28 18:26:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.32494568824768066 norm:0.0005168436910025775 max memory_allocated 22566.63232421875 
[2025-02-28 18:26:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.3233177363872528 norm:0.0004318358551245183 max memory_allocated 22566.63232421875 
[2025-02-28 18:27:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.32272857427597046 norm:0.0004178804811090231 max memory_allocated 22566.63232421875 
[2025-02-28 18:28:01 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.3223537504673004 norm:0.00038474443135783076 max memory_allocated 22566.63232421875 
[2025-02-28 18:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.3220769166946411 norm:0.0003502486215438694 max memory_allocated 22566.63232421875 
[2025-02-28 18:29:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.32185888290405273 norm:0.00032461946830153465 max memory_allocated 22566.63232421875 
[2025-02-28 18:29:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.3217116594314575 norm:0.00029799126787111163 max memory_allocated 22566.63232421875 
[2025-02-28 18:30:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.3215663433074951 norm:0.0002825058763846755 max memory_allocated 22566.63232421875 
[2025-02-28 18:30:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.3214304447174072 norm:0.00027307000709697604 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.32136449217796326 norm:0.0002618150901980698 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:54 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.32127928733825684 norm:0.00025231525069102645 max memory_allocated 22566.63232421875 
[2025-02-28 18:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.32120224833488464 norm:0.0002483143762219697 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.32116177678108215 norm:0.0002485906006768346 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.32106828689575195 norm:0.0002507088065613061 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.3209991455078125 norm:0.00024500468862242997 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.3209945857524872 norm:0.0002432472974760458 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.3209916353225708 norm:0.00023877943749539554 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 18:35:25 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:35:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.39922237396240234 norm:0.017068661749362946 max memory_allocated 22566.91943359375 
[2025-02-28 18:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.3859173357486725 norm:0.012345614843070507 max memory_allocated 22566.91943359375 
[2025-02-28 18:37:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.3748900592327118 norm:0.008003666996955872 max memory_allocated 22566.91943359375 
[2025-02-28 18:37:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.3708152174949646 norm:0.006450212094932795 max memory_allocated 22566.91943359375 
[2025-02-28 18:38:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.3689098656177521 norm:0.005607370287179947 max memory_allocated 22566.91943359375 
[2025-02-28 18:38:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.36809489130973816 norm:0.004949511028826237 max memory_allocated 22566.91943359375 
[2025-02-28 18:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.3676008880138397 norm:0.004350259900093079 max memory_allocated 22566.91943359375 
[2025-02-28 18:39:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.36722540855407715 norm:0.0038437400944530964 max memory_allocated 22566.91943359375 
[2025-02-28 18:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.36690863966941833 norm:0.0034243862610310316 max memory_allocated 22566.91943359375 
[2025-02-28 18:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.3666648864746094 norm:0.003088829107582569 max memory_allocated 22566.91943359375 
[2025-02-28 18:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.36651626229286194 norm:0.0030531533993780613 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.36644911766052246 norm:0.0031354748643934727 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.3664472997188568 norm:0.003133230609819293 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.36625775694847107 norm:0.003008793340995908 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.36608630418777466 norm:0.002844120841473341 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.3660024404525757 norm:0.0027291474398225546 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.3659238815307617 norm:0.0027793110348284245 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.36588460206985474 norm:0.002730337204411626 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.3658475875854492 norm:0.002655021147802472 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.3658401370048523 norm:0.002590866293758154 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 18:46:44 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:47:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.4644622802734375 norm:0.017322547733783722 max memory_allocated 22567.09130859375 
[2025-02-28 18:47:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.44376707077026367 norm:0.011718190275132656 max memory_allocated 22567.09130859375 
[2025-02-28 18:48:24 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.42901134490966797 norm:0.007788350805640221 max memory_allocated 22567.09130859375 
[2025-02-28 18:48:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.42394575476646423 norm:0.006549092475324869 max memory_allocated 22567.09130859375 
[2025-02-28 18:49:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.42156603932380676 norm:0.005546553060412407 max memory_allocated 22567.09130859375 
[2025-02-28 18:50:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.42043882608413696 norm:0.0047697569243609905 max memory_allocated 22567.09130859375 
[2025-02-28 18:50:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.4197431802749634 norm:0.00421532616019249 max memory_allocated 22567.09130859375 
[2025-02-28 18:51:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.41931191086769104 norm:0.0038953605107963085 max memory_allocated 22567.09130859375 
[2025-02-28 18:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.4190591871738434 norm:0.003779038554057479 max memory_allocated 22567.09130859375 
[2025-02-28 18:52:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.41874825954437256 norm:0.0036295498721301556 max memory_allocated 22567.09130859375 
[2025-02-28 18:52:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.4185689389705658 norm:0.003464764216914773 max memory_allocated 22567.09130859375 
[2025-02-28 18:53:24 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.41834649443626404 norm:0.003283726517111063 max memory_allocated 22567.09130859375 
[2025-02-28 18:53:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.4181760549545288 norm:0.003136980812996626 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.4181523323059082 norm:0.003124083625152707 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:04 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.41804012656211853 norm:0.0029620244167745113 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.41804102063179016 norm:0.00289032026194036 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.4180943965911865 norm:0.0029397322796285152 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.41807690262794495 norm:0.0028821174055337906 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:17 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.4180348515510559 norm:0.0028315356466919184 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.4181356430053711 norm:0.0027984161861240864 max memory_allocated 22567.09130859375 
[2025-02-28 18:58:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 18:58:03 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:58:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.5347974300384521 norm:0.1317736953496933 max memory_allocated 22567.26318359375 
[2025-02-28 18:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:1.2909646034240723 norm:0.11158102005720139 max memory_allocated 22567.26318359375 
[2025-02-28 18:59:42 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.968406081199646 norm:0.0663757473230362 max memory_allocated 22567.26318359375 
[2025-02-28 19:00:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.8564796447753906 norm:0.05005030706524849 max memory_allocated 22567.26318359375 
[2025-02-28 19:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.8233100771903992 norm:0.052162256091833115 max memory_allocated 22567.26318359375 
[2025-02-28 19:01:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.7818731665611267 norm:0.045370232313871384 max memory_allocated 22567.26318359375 
[2025-02-28 19:01:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.7624248266220093 norm:0.043257102370262146 max memory_allocated 22567.26318359375 
[2025-02-28 19:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.7574353218078613 norm:0.04764479026198387 max memory_allocated 22567.26318359375 
[2025-02-28 19:03:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.7361642122268677 norm:0.04132784903049469 max memory_allocated 22567.26318359375 
[2025-02-28 19:03:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.7488774657249451 norm:0.05120634287595749 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.7213358879089355 norm:0.04459894821047783 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.7138422131538391 norm:0.04237663745880127 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.7078346014022827 norm:0.04336145520210266 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:48 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.7171440124511719 norm:0.04768690839409828 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.7221707105636597 norm:0.04899204522371292 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.6908303499221802 norm:0.04217524453997612 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.6924585700035095 norm:0.03866271674633026 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.7024061679840088 norm:0.04473252594470978 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.6811022758483887 norm:0.03527470678091049 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.675920307636261 norm:0.033720482140779495 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 19:09:20 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:09:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:1.4306950569152832 norm:0.10832824558019638 max memory_allocated 22567.43505859375 
[2025-02-28 19:10:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:1.3054230213165283 norm:0.07548625767230988 max memory_allocated 22567.43505859375 
[2025-02-28 19:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:1.2080576419830322 norm:0.047126222401857376 max memory_allocated 22567.43505859375 
[2025-02-28 19:11:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:1.1732690334320068 norm:0.040289659053087234 max memory_allocated 22567.43505859375 
[2025-02-28 19:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:1.1548833847045898 norm:0.03690606355667114 max memory_allocated 22567.43505859375 
[2025-02-28 19:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:1.143617033958435 norm:0.03440248221158981 max memory_allocated 22567.43505859375 
[2025-02-28 19:13:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:1.1362831592559814 norm:0.031725239008665085 max memory_allocated 22567.43505859375 
[2025-02-28 19:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:1.1315077543258667 norm:0.03039613552391529 max memory_allocated 22567.43505859375 
[2025-02-28 19:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:1.126664161682129 norm:0.029626598581671715 max memory_allocated 22567.43505859375 
[2025-02-28 19:14:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:1.1214025020599365 norm:0.02729788050055504 max memory_allocated 22567.43505859375 
[2025-02-28 19:15:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:1.1212114095687866 norm:0.02604144997894764 max memory_allocated 22567.43505859375 
[2025-02-28 19:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:1.1165469884872437 norm:0.026677696034312248 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:1.115034580230713 norm:0.026207899674773216 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:1.1142436265945435 norm:0.02510296180844307 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:1.110282301902771 norm:0.02455671690404415 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:1.1105256080627441 norm:0.023853236809372902 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:1.109375 norm:0.023105241358280182 max memory_allocated 22567.43505859375 
[2025-02-28 19:19:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:1.1090891361236572 norm:0.022977370768785477 max memory_allocated 22567.43505859375 
[2025-02-28 19:19:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:1.1079378128051758 norm:0.02362947165966034 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:1.1071668863296509 norm:0.022096015512943268 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:35 root] (main_calib_config2.py 380): INFO 21608.36001110077
[2025-02-28 19:20:40 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 19:21:50 root] (main_calib_config2.py 159): INFO wikitext2 : 6.256859302520752
[2025-02-28 19:21:50 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 19:23:38 root] (main_calib_config2.py 159): INFO c4 : 8.097228050231934
[2025-02-28 21:09:32 root] (main_calib_config2.py 170): INFO {'wikitext2': 6.256859302520752, 'c4': 8.097228050231934, 'results': {'winogrande': {'acc': 0.6385161799526441, 'acc_stderr': 0.013502479670791292}, 'piqa': {'acc': 0.7616974972796517, 'acc_stderr': 0.009940334245876203, 'acc_norm': 0.764417845484222, 'acc_norm_stderr': 0.009901067586473883}, 'hellaswag': {'acc': 0.5338577972515435, 'acc_stderr': 0.0049783281907755245, 'acc_norm': 0.6953794064927306, 'acc_norm_stderr': 0.004593059367676213}, 'arc_challenge': {'acc': 0.37627986348122866, 'acc_stderr': 0.014157022555407177, 'acc_norm': 0.3848122866894198, 'acc_norm_stderr': 0.014218371065251102}, 'arc_easy': {'acc': 0.6531986531986532, 'acc_stderr': 0.009766326091716005, 'acc_norm': 0.5105218855218855, 'acc_norm_stderr': 0.010257511546488225}, 'boolq': {'acc': 0.6685015290519878, 'acc_stderr': 0.008233500324571517}}, 'versions': {'winogrande': 0, 'piqa': 0, 'hellaswag': 0, 'arc_challenge': 0, 'arc_easy': 0, 'boolq': 1}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
