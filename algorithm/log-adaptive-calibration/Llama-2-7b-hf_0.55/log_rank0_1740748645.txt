[2025-02-28 13:17:25 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-7b-hf_0.55', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.55.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:20:27 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:20:27 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.55.pkl
[2025-02-28 13:20:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:20:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.010514951311051846 norm:0.011486624367535114 max memory_allocated 22562.10693359375 
[2025-02-28 13:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.005845536943525076 norm:0.006420317105948925 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.004241944290697575 norm:0.004211500287055969 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0036528497003018856 norm:0.0032656099647283554 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.003444523783400655 norm:0.0028038041200488806 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:53 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0033639143221080303 norm:0.002472459804266691 max memory_allocated 22562.10693359375 
[2025-02-28 13:24:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.003322121687233448 norm:0.0022498718462884426 max memory_allocated 22562.10693359375 
[2025-02-28 13:25:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.003254753304645419 norm:0.0020437799394130707 max memory_allocated 22562.10693359375 
[2025-02-28 13:25:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.003163302317261696 norm:0.0018779051024466753 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0031612878665328026 norm:0.0016844100318849087 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:41 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.003127247327938676 norm:0.0015472739469259977 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0030551578383892775 norm:0.0014387179398909211 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.003056879620999098 norm:0.001286491984501481 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0030544474720954895 norm:0.0012415801174938679 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0030247000977396965 norm:0.0011945656733587384 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0030210278928279877 norm:0.0010973457247018814 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.002970718778669834 norm:0.0010308923665434122 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0029645801987499 norm:0.0009423591545782983 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:09 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0029815335292369127 norm:0.0010082689113914967 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:43 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0030285825487226248 norm:0.0010322844609618187 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:31:55 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:32:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.03376009315252304 norm:0.013371046632528305 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.025002392008900642 norm:0.02030228264629841 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.02056550420820713 norm:0.01971130259335041 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.016804754734039307 norm:0.01156965084373951 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.016066649928689003 norm:0.00977637805044651 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.016705002635717392 norm:0.010252414271235466 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.015360034070909023 norm:0.008526046760380268 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:25 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.015562218613922596 norm:0.008700290694832802 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:58 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.015071101486682892 norm:0.008056189864873886 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:32 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.015164905227720737 norm:0.007955024018883705 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.015464837662875652 norm:0.007967716082930565 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.014715014956891537 norm:0.006690025329589844 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:13 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.014718749560415745 norm:0.006465169135481119 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:47 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.014885272830724716 norm:0.006451569031924009 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.014867620542645454 norm:0.006742138881236315 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:54 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.015600444748997688 norm:0.006478193216025829 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.01512514054775238 norm:0.00597272627055645 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.014843158423900604 norm:0.00637575751170516 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:36 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.01489725150167942 norm:0.005709770601242781 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.016281770542263985 norm:0.006199454423040152 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 13:43:22 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:43:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.0326925553381443 norm:0.00727956322953105 max memory_allocated 22562.45068359375 
[2025-02-28 13:44:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.025087570771574974 norm:0.005448732525110245 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.02213275246322155 norm:0.003953029401600361 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.021138906478881836 norm:0.0030938717536628246 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.020524034276604652 norm:0.002545739058405161 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.020053725689649582 norm:0.0020567309111356735 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:18 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.019790759310126305 norm:0.001620517810806632 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.01966039650142193 norm:0.0012668168637901545 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.019574129953980446 norm:0.000983847421593964 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:59 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.019532427191734314 norm:0.0009463811293244362 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:33 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.019501525908708572 norm:0.001015503192320466 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.01948513835668564 norm:0.0010837523732334375 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.019474973902106285 norm:0.0011150784557685256 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.019469337537884712 norm:0.0011070201871916652 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.01945931278169155 norm:0.0010951667791232467 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.019470445811748505 norm:0.0010897513711825013 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.01946919597685337 norm:0.0010747635969892144 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.019477572292089462 norm:0.0010592818725854158 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.019476229324936867 norm:0.0010616921354085207 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.019485250115394592 norm:0.0010715348180383444 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 13:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.04097311943769455 norm:0.002748320810496807 max memory_allocated 22562.50732421875 
[2025-02-28 13:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.03150090575218201 norm:0.0009904352482408285 max memory_allocated 22562.50732421875 
[2025-02-28 13:56:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.0273295771330595 norm:0.00048047996824607253 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.025960702449083328 norm:0.00031026703072711825 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.025195645168423653 norm:0.00022731997887603939 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.02485583908855915 norm:0.00020295886497478932 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.024760572239756584 norm:0.00018222873040940613 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:17 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.024684937670826912 norm:0.00015610312402714044 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.024648280814290047 norm:0.00015374031499959528 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.02462523803114891 norm:0.00015031076327431947 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.024624094367027283 norm:0.00015660369535908103 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:32 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.02461167983710766 norm:0.00014801524230279028 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.0245963204652071 norm:0.00015269227151293308 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.024607408791780472 norm:0.00015411802451126277 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.02459869720041752 norm:0.000147574843140319 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:46 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.024587422609329224 norm:0.00014629571523983032 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.024583319202065468 norm:0.00014919413661118597 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.02458498626947403 norm:0.00014841619122307748 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.024573571979999542 norm:0.00014757903409190476 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.02456715703010559 norm:0.0001470799616072327 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.05027223378419876 norm:0.002195710316300392 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.03891799598932266 norm:0.0007892732974141836 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.03301691263914108 norm:0.0004887531977146864 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.030989790335297585 norm:0.00031607263372279704 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.029934553429484367 norm:0.00025441465550102293 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.029463429003953934 norm:0.00023375664022751153 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.029216421768069267 norm:0.00021150625252630562 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.02909792773425579 norm:0.00019479201000649482 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.029077628627419472 norm:0.00019820794113911688 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.029084937646985054 norm:0.00019396247807890177 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.02901024930179119 norm:0.00018094826373271644 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.028970833867788315 norm:0.00017336916062049568 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.028965551406145096 norm:0.00017604112508706748 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.028962688520550728 norm:0.00018206798995379359 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.02891416661441326 norm:0.00018671347061172128 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.0289179515093565 norm:0.00018181826453655958 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:45 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.02890336699783802 norm:0.0001841038465499878 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.02892177551984787 norm:0.00018330838065594435 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:52 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.02896416187286377 norm:0.00018348700541537255 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.028954047709703445 norm:0.0001796199067030102 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.05036303400993347 norm:0.0019499780610203743 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.04124026745557785 norm:0.0005951054627075791 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:19 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.035979412496089935 norm:0.00036819628439843655 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.0340232327580452 norm:0.00025585462572053075 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.033095840364694595 norm:0.0002300938795087859 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.03276241198182106 norm:0.00020458540529944003 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.03254317492246628 norm:0.00016858731396496296 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.03242592513561249 norm:0.00017186824698001146 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.03236330300569534 norm:0.00016850893734954298 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.032314762473106384 norm:0.00016377033898606896 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.032311636954545975 norm:0.00017066218424588442 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:21 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.032287441194057465 norm:0.00017016366473399103 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.0322958379983902 norm:0.0001680041168583557 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.03225066512823105 norm:0.00015624001389369369 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.03223085403442383 norm:0.00016550037253182381 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.032219432294368744 norm:0.0001577602670295164 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.03223571181297302 norm:0.00016254732327070087 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.032232947647571564 norm:0.00016320603026542813 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:16 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.03225081041455269 norm:0.0001703410380287096 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:50 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.0322423093020916 norm:0.00016670033801347017 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 14:29:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.05883829668164253 norm:0.0014318351168185472 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:09 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.047703273594379425 norm:0.0006224794778972864 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:42 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.04135270416736603 norm:0.0004054818709846586 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.03901073336601257 norm:0.0002811604645103216 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.03789623826742172 norm:0.00024866286548785865 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.037405066192150116 norm:0.00021759375522378832 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.03709879145026207 norm:0.00020078379020560533 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.0369638130068779 norm:0.00019522391085047275 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.03683751821517944 norm:0.00019290244381409138 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.03672248125076294 norm:0.00018697549239732325 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.03666536137461662 norm:0.00018593914865050465 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.03660808131098747 norm:0.0001883048826130107 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:18 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.03653460741043091 norm:0.0001906874676933512 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.0365024209022522 norm:0.0001962834649020806 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.036485910415649414 norm:0.0001916628680191934 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.0365481823682785 norm:0.0002142083685612306 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.03650882840156555 norm:0.0001876323949545622 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.03648579493165016 norm:0.00019075874297413975 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.03643951192498207 norm:0.00018800754332914948 max memory_allocated 22563.02294921875 
[2025-02-28 14:40:13 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.03645986318588257 norm:0.00019141100347042084 max memory_allocated 22563.02294921875 
[2025-02-28 14:40:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 14:40:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.06570175290107727 norm:0.002586249029263854 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.05269315093755722 norm:0.0009166201925836504 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.0456559956073761 norm:0.0004835749859921634 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.043057411909103394 norm:0.0003203697851859033 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.04193829372525215 norm:0.00026654970133677125 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.041398078203201294 norm:0.0002327706024516374 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:20 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.04116067290306091 norm:0.00022048458049539477 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.04098424315452576 norm:0.00021093027316965163 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.04086493328213692 norm:0.0002036818623309955 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:00 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.04076192155480385 norm:0.000190379359992221 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.04070504009723663 norm:0.0002027215959969908 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.04064301401376724 norm:0.0001948017015820369 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.040610309690237045 norm:0.0001876120804809034 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.04057427495718002 norm:0.0006478911964222789 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.04055877402424812 norm:0.0001787345390766859 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.040550388395786285 norm:0.00018032338994089514 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.040510181337594986 norm:0.00018880503193940967 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.040488094091415405 norm:0.00018540225573815405 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:02 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.04047417268157005 norm:0.0001852846035035327 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:36 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.0404464490711689 norm:0.00017889108858071268 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 14:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.0664789080619812 norm:0.0011032943148165941 max memory_allocated 22563.36669921875 
[2025-02-28 14:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.05595622956752777 norm:0.0005852588801644742 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.049464061856269836 norm:0.0003635105676949024 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:03 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.047112274914979935 norm:0.0002606264315545559 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:36 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.04601498693227768 norm:0.00021816248772665858 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.045491162687540054 norm:0.00019411879475228488 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:43 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.04529864341020584 norm:0.00020287270308472216 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.0451316200196743 norm:0.00018794534844346344 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.04501751810312271 norm:0.0001828659005695954 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.04492046311497688 norm:0.000183823547558859 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.04485824704170227 norm:0.00017514056526124477 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.0448293536901474 norm:0.00018372145132161677 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:05 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.04479878395795822 norm:0.000196646768017672 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.044850438833236694 norm:0.00019708505715243518 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.04482715576887131 norm:0.00019097092445008457 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.044764261692762375 norm:0.00018176586308982223 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.04476344585418701 norm:0.0001777714933268726 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.04474468529224396 norm:0.00017775921151041985 max memory_allocated 22563.36669921875 
[2025-02-28 15:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.044712431728839874 norm:0.0001731851079966873 max memory_allocated 22563.36669921875 
[2025-02-28 15:03:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.0447043851017952 norm:0.00017623137682676315 max memory_allocated 22563.36669921875 
[2025-02-28 15:03:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 15:03:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.07227735966444016 norm:0.002666965126991272 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.06051996350288391 norm:0.0010062975343316793 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.05319509282708168 norm:0.0004232690844219178 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.05059712380170822 norm:0.0002726555394474417 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.049483876675367355 norm:0.0002155692782253027 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.048990290611982346 norm:0.00020038490765728056 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:07 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.04871373996138573 norm:0.00018183903011959046 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.04857708513736725 norm:0.00016910975682549179 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.048509012907743454 norm:0.00016725280147511512 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.04844529926776886 norm:0.00015713789616711438 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.0483953095972538 norm:0.00016363999748136848 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:55 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.048391591757535934 norm:0.00015991012332960963 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:29 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.04836332052946091 norm:0.0001562406396260485 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.0483226478099823 norm:0.00016126231639645994 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.04827965050935745 norm:0.00015787259326316416 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.04829544574022293 norm:0.00015926428022794425 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.048278361558914185 norm:0.00015485066978726536 max memory_allocated 22563.53857421875 
[2025-02-28 15:13:17 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.048217400908470154 norm:0.00015422901196870953 max memory_allocated 22563.53857421875 
[2025-02-28 15:13:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.04817160218954086 norm:0.00015537752187810838 max memory_allocated 22563.53857421875 
[2025-02-28 15:14:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.04818568378686905 norm:0.00015448890917468816 max memory_allocated 22563.53857421875 
[2025-02-28 15:14:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 15:15:11 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.07304170727729797 norm:0.001217306824401021 max memory_allocated 22563.71044921875 
[2025-02-28 15:15:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.06343516707420349 norm:0.0007009388646110892 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.05615890398621559 norm:0.000341836828738451 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.05357400327920914 norm:0.00020570604829117656 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.05254290997982025 norm:0.00017001733067445457 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.052101943641901016 norm:0.00015707551210653037 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.05187481269240379 norm:0.00015272684686351568 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.05174601823091507 norm:0.0001509657158749178 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.05166567116975784 norm:0.00014986128371674567 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:14 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.05159963294863701 norm:0.0001460001803934574 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.05154092237353325 norm:0.00014621792070101947 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.05142466723918915 norm:0.00014401714724954218 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.05139980465173721 norm:0.00014411135634873062 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.051341887563467026 norm:0.000137978233397007 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:02 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.05131853371858597 norm:0.00013693238724954426 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.05130741745233536 norm:0.00014121636922936887 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.05127464234828949 norm:0.00013998697977513075 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.051247164607048035 norm:0.00014323380310088396 max memory_allocated 22563.71044921875 
[2025-02-28 15:25:17 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.05121443048119545 norm:0.0001434058794984594 max memory_allocated 22563.71044921875 
[2025-02-28 15:25:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.05119581148028374 norm:0.0001464773522457108 max memory_allocated 22563.71044921875 
[2025-02-28 15:26:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 15:26:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.07640749961137772 norm:0.0016657006926834583 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.06554936617612839 norm:0.000778116867877543 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.05847978591918945 norm:0.00037491595139726996 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.05586744472384453 norm:0.0002488160680513829 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.05471675843000412 norm:0.00020369127742014825 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.05420074984431267 norm:0.00019242118287365884 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.05395848676562309 norm:0.00017811876023188233 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.05381566286087036 norm:0.000182133968337439 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.0537358783185482 norm:0.0001688266493147239 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.05364497750997543 norm:0.00017040278180502355 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.053583625704050064 norm:0.0001720713044051081 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.05356007069349289 norm:0.00015636658645235002 max memory_allocated 22563.88232421875 
[2025-02-28 15:33:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.053476620465517044 norm:0.0001545185223221779 max memory_allocated 22563.88232421875 
[2025-02-28 15:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.05342233553528786 norm:0.0001515570911578834 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.053398195654153824 norm:0.00015401974087581038 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.05338965728878975 norm:0.0001533905597170815 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.05336069315671921 norm:0.0001538958167657256 max memory_allocated 22563.88232421875 
[2025-02-28 15:36:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.05335588753223419 norm:0.00015192857244983315 max memory_allocated 22563.88232421875 
[2025-02-28 15:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.0533207431435585 norm:0.00015301296662073582 max memory_allocated 22563.88232421875 
[2025-02-28 15:37:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.053297705948352814 norm:0.0001474111049901694 max memory_allocated 22563.88232421875 
[2025-02-28 15:37:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 15:38:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.07432440668344498 norm:0.0010705256136134267 max memory_allocated 22564.05419921875 
[2025-02-28 15:38:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.06560447067022324 norm:0.0005574962124228477 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:09 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.05954493209719658 norm:0.0003141883935313672 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.0572921559214592 norm:0.00021264904353301972 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:16 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.056316424161195755 norm:0.00017140887212008238 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.05584945157170296 norm:0.0001614038774278015 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.05558282881975174 norm:0.00016567907005082816 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.05543786659836769 norm:0.00016478673205710948 max memory_allocated 22564.05419921875 
[2025-02-28 15:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.05535975098609924 norm:0.00016315950779244304 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.05527499318122864 norm:0.00015998278104234487 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:38 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.05522424727678299 norm:0.00014800808276049793 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.05514823645353317 norm:0.0001426263916073367 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.055099181830883026 norm:0.00014820467913523316 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:19 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.055113285779953 norm:0.0001424527436029166 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.05506958067417145 norm:0.00013431510888040066 max memory_allocated 22564.05419921875 
[2025-02-28 15:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.05502919852733612 norm:0.0001291970838792622 max memory_allocated 22564.05419921875 
[2025-02-28 15:47:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.05500424653291702 norm:0.0001334394619334489 max memory_allocated 22564.05419921875 
[2025-02-28 15:47:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.05496798828244209 norm:0.00013220866094343364 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.054941579699516296 norm:0.00013307362678460777 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.05494989827275276 norm:0.00013750621292274445 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 15:49:27 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.07341375201940536 norm:0.0018403605790808797 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.06476490199565887 norm:0.0006723732803948224 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.05905294418334961 norm:0.0003306897124275565 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:08 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.05695644021034241 norm:0.00022702464775647968 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.05595339089632034 norm:0.0001893284497782588 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.05545838922262192 norm:0.00018162350170314312 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.055161044001579285 norm:0.00017618080892134458 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:23 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.054973408579826355 norm:0.00016360926383640617 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:57 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.05489083379507065 norm:0.00015743263065814972 max memory_allocated 22564.22607421875 
[2025-02-28 15:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.05480320006608963 norm:0.00014337418542709202 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.05473707616329193 norm:0.0001451377320336178 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.0547165647149086 norm:0.00014886612189002335 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.05465115234255791 norm:0.000142629214678891 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.054634902626276016 norm:0.000139527372084558 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:19 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.0546298585832119 norm:0.00014113164797890931 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.05460917204618454 norm:0.00014571493375115097 max memory_allocated 22564.22607421875 
[2025-02-28 15:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.054598644375801086 norm:0.00015040679136291146 max memory_allocated 22564.22607421875 
[2025-02-28 15:59:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.05455666035413742 norm:0.0001384754868922755 max memory_allocated 22564.22607421875 
[2025-02-28 15:59:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.05455269664525986 norm:0.00013550804578699172 max memory_allocated 22564.22607421875 
[2025-02-28 16:00:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.054535284638404846 norm:0.00012897906708531082 max memory_allocated 22564.22607421875 
[2025-02-28 16:00:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 16:00:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.07198129594326019 norm:0.0008430390735156834 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.06465748697519302 norm:0.0004204818978905678 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.05932726711034775 norm:0.0002430443128105253 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.0574713870882988 norm:0.00017507129814475775 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.05666825547814369 norm:0.0001502561935922131 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.05624060332775116 norm:0.00014931817713659257 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.05597582086920738 norm:0.00013960845535621047 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.055831149220466614 norm:0.00012430099013727158 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.05569561943411827 norm:0.00012157529272371903 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.05560467392206192 norm:0.00011708308738889173 max memory_allocated 22564.39794921875 
[2025-02-28 16:06:29 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.055537089705467224 norm:0.00011289034591754898 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.05549808591604233 norm:0.00011549323244253173 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.055481042712926865 norm:0.00011249801173107699 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.055491719394922256 norm:0.00010436226875754073 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.05546592175960541 norm:0.00010139046935364604 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:18 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.05542871728539467 norm:9.980425966205075e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.05540752410888672 norm:0.00010185078281210735 max memory_allocated 22564.39794921875 
[2025-02-28 16:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.055372387170791626 norm:0.00010738533455878496 max memory_allocated 22564.39794921875 
[2025-02-28 16:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.05536046251654625 norm:0.0001055170941981487 max memory_allocated 22564.39794921875 
[2025-02-28 16:11:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.05536767095327377 norm:9.95977025013417e-05 max memory_allocated 22564.39794921875 
[2025-02-28 16:11:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 16:12:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.07563529163599014 norm:0.001635734224691987 max memory_allocated 22564.56982421875 
[2025-02-28 16:12:52 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.06609350442886353 norm:0.0005302734789438546 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.05999580770730972 norm:0.0003185702080372721 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.0579204261302948 norm:0.00022557374904863536 max memory_allocated 22564.56982421875 
[2025-02-28 16:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.05692257732152939 norm:0.00018627772806212306 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.05638210102915764 norm:0.00016722656437195837 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.0560813769698143 norm:0.00015890487702563405 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.05590866878628731 norm:0.0001533530157757923 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.0557747408747673 norm:0.00013966203550808132 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.05567660182714462 norm:0.00013061048230156302 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.05560086667537689 norm:0.0001313066459260881 max memory_allocated 22564.56982421875 
[2025-02-28 16:18:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.055539991706609726 norm:0.00012456730473786592 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.05546888709068298 norm:0.00012382908607833087 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.055404625833034515 norm:0.00012082232569810003 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.055364325642585754 norm:0.00011715538857970387 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.05532733350992203 norm:0.0001140675158239901 max memory_allocated 22564.56982421875 
[2025-02-28 16:21:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.05527142062783241 norm:0.00011081446427851915 max memory_allocated 22564.56982421875 
[2025-02-28 16:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.0552273690700531 norm:0.00011017241922672838 max memory_allocated 22564.56982421875 
[2025-02-28 16:22:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.05521692335605621 norm:0.00010754250979516655 max memory_allocated 22564.56982421875 
[2025-02-28 16:22:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.05519627779722214 norm:0.00010622103582136333 max memory_allocated 22564.56982421875 
[2025-02-28 16:23:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 16:23:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.07572825253009796 norm:0.0018899140413850546 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.06680893898010254 norm:0.0006597937317565084 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.06065067648887634 norm:0.000310029397951439 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.058686427772045135 norm:0.00023723779304418713 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.05771305412054062 norm:0.00020944213611073792 max memory_allocated 22564.74169921875 
[2025-02-28 16:26:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.05715402960777283 norm:0.00019078297191299498 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:05 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.056840743869543076 norm:0.0001721788867143914 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.0566435381770134 norm:0.00016171904280781746 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.05653325468301773 norm:0.00015055415860842913 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.056402843445539474 norm:0.0001428612449672073 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.05631139129400253 norm:0.00013387727085500956 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.05623381584882736 norm:0.000127819599583745 max memory_allocated 22564.74169921875 
[2025-02-28 16:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.05617309361696243 norm:0.00012581805640365928 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.05611475557088852 norm:0.0001227482280228287 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.056051746010780334 norm:0.00012367322051431984 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.05600661039352417 norm:0.00011495008948259056 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.0559564046561718 norm:0.00011141225695610046 max memory_allocated 22564.74169921875 
[2025-02-28 16:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.05591874197125435 norm:0.00011051145702367648 max memory_allocated 22564.74169921875 
[2025-02-28 16:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.05589587613940239 norm:0.00010782873869175091 max memory_allocated 22564.74169921875 
[2025-02-28 16:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.055864449590444565 norm:0.00010941144137177616 max memory_allocated 22564.74169921875 
[2025-02-28 16:34:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 16:35:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.07163377851247787 norm:0.0016708767507225275 max memory_allocated 22564.91357421875 
[2025-02-28 16:35:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.0651010274887085 norm:0.0005213733529672027 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.06052422523498535 norm:0.0002743189688771963 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.058994270861148834 norm:0.00020487121946644038 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.058140721172094345 norm:0.00016820465680211782 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.05767378583550453 norm:0.00014970169286243618 max memory_allocated 22564.91357421875 
[2025-02-28 16:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.05742237716913223 norm:0.0001426223898306489 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.05726787447929382 norm:0.0001350265956716612 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.05713597312569618 norm:0.00012519361916929483 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.05704275518655777 norm:0.0001062418450601399 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.056987058371305466 norm:0.0001069225836545229 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.05693740397691727 norm:0.00010210298205493018 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.05689452961087227 norm:9.81232151389122e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:26 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.05685804784297943 norm:9.542830230202526e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:43:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.056853242218494415 norm:9.287927969126031e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.05682901293039322 norm:8.797486952971667e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:44:07 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.056805569678545 norm:8.924431313062087e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.05679870396852493 norm:9.008349297801033e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:15 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.05676423758268356 norm:9.088285878533497e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.05674917995929718 norm:9.1083042207174e-05 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 16:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.07765040546655655 norm:0.0014279743190854788 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:08 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.07008977234363556 norm:0.000540979381185025 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:42 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.0647764727473259 norm:0.0003148683754261583 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.0630716010928154 norm:0.00022989176795817912 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:49 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.06204717978835106 norm:0.00018694685422815382 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.061501603573560715 norm:0.0001723736058920622 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.06119167432188988 norm:0.0001520212390460074 max memory_allocated 22565.08544921875 
[2025-02-28 16:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.061041031032800674 norm:0.00014382028894033283 max memory_allocated 22565.08544921875 
[2025-02-28 16:51:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.06092765927314758 norm:0.00013664823200087994 max memory_allocated 22565.08544921875 
[2025-02-28 16:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.06082915887236595 norm:0.00013366500206757337 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:11 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.06074381247162819 norm:0.00012064964539604262 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.06066124141216278 norm:0.00011277647718088701 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.06061059981584549 norm:0.00010885758092626929 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.06057199463248253 norm:0.0001072088343789801 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.06053607910871506 norm:0.00010462528007337824 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.06048467755317688 norm:9.889784269034863e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:55:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.06043846905231476 norm:9.923533798428252e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:56:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.060416657477617264 norm:9.567679080646485e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:56:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.06037426367402077 norm:9.764917922439054e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.060369525104761124 norm:9.852802759269252e-05 max memory_allocated 22565.08544921875 
[2025-02-28 16:57:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 16:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.08218810707330704 norm:0.0015599805628880858 max memory_allocated 22565.25732421875 
[2025-02-28 16:58:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.07510317862033844 norm:0.0006146273226477206 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.06922130286693573 norm:0.0002592500823084265 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:41 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.06766824424266815 norm:0.00020173210941720754 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.06669504940509796 norm:0.00016358570428565145 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.06617000699043274 norm:0.000145200319821015 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.0659056305885315 norm:0.00013686141755897552 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.06575728952884674 norm:0.00012539175804704428 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.06564604490995407 norm:0.0001254644594155252 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.06554169952869415 norm:0.00011138671106891707 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.06545348465442657 norm:0.00010224155994364992 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.06538768857717514 norm:9.75711882347241e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.06533505767583847 norm:0.00010023085633292794 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.06528104841709137 norm:0.00010157981159863994 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.0652184784412384 norm:9.605023660697043e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:06:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.06518284231424332 norm:9.266990673495457e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:06:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.06513816118240356 norm:8.576598338549957e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.06509959697723389 norm:8.70714575285092e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:08:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.06508534401655197 norm:8.905135473469272e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:08:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.06505991518497467 norm:8.29846176202409e-05 max memory_allocated 22565.25732421875 
[2025-02-28 17:08:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 17:09:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.0901656448841095 norm:0.0023030349984765053 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.08196207880973816 norm:0.0008333012228831649 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.07609596848487854 norm:0.0003442508459556848 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:07 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.07444500923156738 norm:0.00022981473011896014 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.07338812202215195 norm:0.00020800024503841996 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.0727824866771698 norm:0.000186121033038944 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.07247443497180939 norm:0.00018113484838977456 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:22 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.07228578627109528 norm:0.00017233958351425827 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.07214191555976868 norm:0.00016529734421055764 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.07201516628265381 norm:0.00016349551151506603 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.07193201780319214 norm:0.0001446788664907217 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.0718599259853363 norm:0.00013791400124318898 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.07177446782588959 norm:0.0001278673007618636 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.0716782659292221 norm:0.00012457538105081767 max memory_allocated 22565.42919921875 
[2025-02-28 17:17:17 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.07160216569900513 norm:0.0001281823788303882 max memory_allocated 22565.42919921875 
[2025-02-28 17:17:51 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.07156579941511154 norm:0.0001234536903211847 max memory_allocated 22565.42919921875 
[2025-02-28 17:18:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.07151451706886292 norm:0.00012545993376988918 max memory_allocated 22565.42919921875 
[2025-02-28 17:18:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.07147497683763504 norm:0.00012129169044783339 max memory_allocated 22565.42919921875 
[2025-02-28 17:19:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.07144723832607269 norm:0.00011724157957360148 max memory_allocated 22565.42919921875 
[2025-02-28 17:20:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.07141819596290588 norm:0.00011612031084951013 max memory_allocated 22565.42919921875 
[2025-02-28 17:20:15 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 17:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.09544254839420319 norm:0.0017937931697815657 max memory_allocated 22565.60107421875 
[2025-02-28 17:21:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.08835368603467941 norm:0.0005576316034421325 max memory_allocated 22565.60107421875 
[2025-02-28 17:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.0831618458032608 norm:0.0002661642793100327 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.08176819235086441 norm:0.00020554725779220462 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.08074651658535004 norm:0.00018467518384568393 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.08017175644636154 norm:0.00017399017815478146 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.07990258187055588 norm:0.00016247316671069711 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.07975364476442337 norm:0.0001460619823774323 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.07962527871131897 norm:0.0001301047595916316 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.07952575385570526 norm:0.0001282356824958697 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.07943867892026901 norm:0.0001233848452102393 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.07937449961900711 norm:0.0001221831771545112 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:35 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.07929593324661255 norm:0.0001131081662606448 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.07924391329288483 norm:0.00011004834232153371 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:43 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.07917652279138565 norm:0.00010392797412350774 max memory_allocated 22565.60107421875 
[2025-02-28 17:29:17 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.07912565022706985 norm:0.00010650166950654238 max memory_allocated 22565.60107421875 
[2025-02-28 17:29:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.07907811552286148 norm:9.984336793422699e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:30:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.07906413078308105 norm:0.00010003527131630108 max memory_allocated 22565.60107421875 
[2025-02-28 17:30:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.07904216647148132 norm:9.524165943730623e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:31:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.07900634407997131 norm:9.101053001359105e-05 max memory_allocated 22565.60107421875 
[2025-02-28 17:31:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 17:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.10679343342781067 norm:0.0008938678656704724 max memory_allocated 22565.77294921875 
[2025-02-28 17:32:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.10020146518945694 norm:0.00043489603558555245 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:24 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.09511061012744904 norm:0.00027816204237751663 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.0936029776930809 norm:0.00022446214279625565 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.09253902733325958 norm:0.00018930720398202538 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.09200102090835571 norm:0.000166269950568676 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.09175150096416473 norm:0.00014794130402151495 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.09159495681524277 norm:0.00014492060290649533 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.09146758913993835 norm:0.00020798612968064845 max memory_allocated 22565.77294921875 
[2025-02-28 17:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.0913630872964859 norm:0.00013564166147261858 max memory_allocated 22565.77294921875 
[2025-02-28 17:37:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.0912613645195961 norm:0.00012693692406173795 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.09118454158306122 norm:0.00012354528007563204 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.09109121561050415 norm:0.0001226529129780829 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.09101644903421402 norm:0.00011645617632893845 max memory_allocated 22565.77294921875 
[2025-02-28 17:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.09095795452594757 norm:0.00011725170770660043 max memory_allocated 22565.77294921875 
[2025-02-28 17:40:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.09089957177639008 norm:0.00011544596782187 max memory_allocated 22565.77294921875 
[2025-02-28 17:41:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.09086360782384872 norm:0.00011808804993052036 max memory_allocated 22565.77294921875 
[2025-02-28 17:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.09081771224737167 norm:0.00011498709500301629 max memory_allocated 22565.77294921875 
[2025-02-28 17:42:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.09076747298240662 norm:0.00011584369349293411 max memory_allocated 22565.77294921875 
[2025-02-28 17:42:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.09072990715503693 norm:0.00011690528481267393 max memory_allocated 22565.77294921875 
[2025-02-28 17:43:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 17:43:43 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.1209978461265564 norm:0.0016553053865209222 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.11317617446184158 norm:0.0006586172967217863 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.10662883520126343 norm:0.00035444978857412934 max memory_allocated 22565.94482421875 
[2025-02-28 17:45:24 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.10486365854740143 norm:0.0002766410179901868 max memory_allocated 22565.94482421875 
[2025-02-28 17:45:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.1036846861243248 norm:0.00022768680355511606 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.1031675711274147 norm:0.00019296394020784646 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.10292726755142212 norm:0.00017027162539307028 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.1027694121003151 norm:0.00015509131480939686 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:12 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.10263223201036453 norm:0.00014764109801035374 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.10251262784004211 norm:0.00013512204168364406 max memory_allocated 22565.94482421875 
[2025-02-28 17:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.10240896046161652 norm:0.00011604632891248912 max memory_allocated 22565.94482421875 
[2025-02-28 17:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.10230407118797302 norm:0.00011707978410413489 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.10223626345396042 norm:0.00012395664816722274 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.10217554867267609 norm:0.00011330963025102392 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.10211905837059021 norm:0.0001077264387276955 max memory_allocated 22565.94482421875 
[2025-02-28 17:52:08 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.10208551585674286 norm:0.00010983238462358713 max memory_allocated 22565.94482421875 
[2025-02-28 17:52:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.10202454775571823 norm:0.00010574076441116631 max memory_allocated 22565.94482421875 
[2025-02-28 17:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.10198955982923508 norm:0.0001025133315124549 max memory_allocated 22565.94482421875 
[2025-02-28 17:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.10195275396108627 norm:0.00010679077240638435 max memory_allocated 22565.94482421875 
[2025-02-28 17:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.10190612822771072 norm:0.00010359663428971544 max memory_allocated 22565.94482421875 
[2025-02-28 17:54:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 17:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.13628581166267395 norm:0.0022664079442620277 max memory_allocated 22566.11669921875 
[2025-02-28 17:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.12678244709968567 norm:0.0005384073010645807 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:16 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.12027274072170258 norm:0.0003893274115398526 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.11820971220731735 norm:0.0002636429271660745 max memory_allocated 22566.11669921875 
[2025-02-28 17:57:23 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.11693497002124786 norm:0.00022570861619897187 max memory_allocated 22566.11669921875 
[2025-02-28 17:57:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.11641459167003632 norm:0.00021083117462694645 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.11621491611003876 norm:0.00020530990150291473 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.11602649837732315 norm:0.00018764058768283576 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.11584433168172836 norm:0.00016806421626824886 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:12 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.1157132089138031 norm:0.0001676141982898116 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.11558670550584793 norm:0.00016452885756734759 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.11549607664346695 norm:0.00016798228898551315 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:53 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.11543548852205276 norm:0.0001656567183090374 max memory_allocated 22566.11669921875 
[2025-02-28 18:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.11536534130573273 norm:0.0001604085264261812 max memory_allocated 22566.11669921875 
[2025-02-28 18:03:00 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.11529850959777832 norm:0.00016014229913707823 max memory_allocated 22566.11669921875 
[2025-02-28 18:03:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.11524663865566254 norm:0.00015417335089296103 max memory_allocated 22566.11669921875 
[2025-02-28 18:04:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.11517985165119171 norm:0.00013996324560139328 max memory_allocated 22566.11669921875 
[2025-02-28 18:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.11512354761362076 norm:0.0001324595941696316 max memory_allocated 22566.11669921875 
[2025-02-28 18:05:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.1150684803724289 norm:0.00013498864427674562 max memory_allocated 22566.11669921875 
[2025-02-28 18:05:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.11505038291215897 norm:0.00014101009583100677 max memory_allocated 22566.11669921875 
[2025-02-28 18:05:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 18:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.1544097512960434 norm:0.001209912239573896 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.14532485604286194 norm:0.0006024989415891469 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:42 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.13735583424568176 norm:0.00034972449066117406 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.13506542146205902 norm:0.00027867057360708714 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.133780375123024 norm:0.0002487415913492441 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.13331590592861176 norm:0.00022736321261618286 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:56 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.13296008110046387 norm:0.0002091788046527654 max memory_allocated 22566.28857421875 
[2025-02-28 18:10:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.13277271389961243 norm:0.00018736824858933687 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.13261699676513672 norm:0.00017520417168270797 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.13244406878948212 norm:0.00017551047494634986 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.1323513686656952 norm:0.00015861100109759718 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.13222965598106384 norm:0.00015593276475556195 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.13215935230255127 norm:0.00015205529052764177 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.1320795714855194 norm:0.0001463232038076967 max memory_allocated 22566.28857421875 
[2025-02-28 18:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.13203135132789612 norm:0.00014413794269785285 max memory_allocated 22566.28857421875 
[2025-02-28 18:14:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.13195116817951202 norm:0.00014332326827570796 max memory_allocated 22566.28857421875 
[2025-02-28 18:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.1318921148777008 norm:0.00013925082748755813 max memory_allocated 22566.28857421875 
[2025-02-28 18:16:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.1318289041519165 norm:0.0001419705804437399 max memory_allocated 22566.28857421875 
[2025-02-28 18:16:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.13178417086601257 norm:0.0001331799867330119 max memory_allocated 22566.28857421875 
[2025-02-28 18:17:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.1317444145679474 norm:0.00013297195255290717 max memory_allocated 22566.28857421875 
[2025-02-28 18:17:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 18:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.1721469759941101 norm:0.0017293463461101055 max memory_allocated 22566.46044921875 
[2025-02-28 18:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.1635863184928894 norm:0.0008710320689715445 max memory_allocated 22566.46044921875 
[2025-02-28 18:19:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.15672577917575836 norm:0.0005377086345106363 max memory_allocated 22566.46044921875 
[2025-02-28 18:19:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.1544887274503708 norm:0.00038961751852184534 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.15323707461357117 norm:0.0003038475406356156 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.1527256816625595 norm:0.00025298932450823486 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.1524152010679245 norm:0.00022541095677297562 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.1521528661251068 norm:0.0002041910629486665 max memory_allocated 22566.46044921875 
[2025-02-28 18:22:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.15193578600883484 norm:0.00018771746545098722 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.15178175270557404 norm:0.00018155646102968603 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.1516410857439041 norm:0.00017047100118361413 max memory_allocated 22566.46044921875 
[2025-02-28 18:24:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.15151266753673553 norm:0.00016485170635860413 max memory_allocated 22566.46044921875 
[2025-02-28 18:24:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.15143689513206482 norm:0.00015466002514585853 max memory_allocated 22566.46044921875 
[2025-02-28 18:25:17 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.15132132172584534 norm:0.00015355367213487625 max memory_allocated 22566.46044921875 
[2025-02-28 18:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.15122352540493011 norm:0.00015147842350415885 max memory_allocated 22566.46044921875 
[2025-02-28 18:26:25 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.15117087960243225 norm:0.0001496666664024815 max memory_allocated 22566.46044921875 
[2025-02-28 18:26:58 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.1511041671037674 norm:0.00015289067232515663 max memory_allocated 22566.46044921875 
[2025-02-28 18:27:32 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.15104863047599792 norm:0.00015213452570606023 max memory_allocated 22566.46044921875 
[2025-02-28 18:28:06 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.1509878933429718 norm:0.00014529739564750344 max memory_allocated 22566.46044921875 
[2025-02-28 18:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.15095636248588562 norm:0.00014812551671639085 max memory_allocated 22566.46044921875 
[2025-02-28 18:28:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 18:29:25 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.19646383821964264 norm:0.0022476124577224255 max memory_allocated 22566.63232421875 
[2025-02-28 18:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.1860145777463913 norm:0.0008370382711291313 max memory_allocated 22566.63232421875 
[2025-02-28 18:30:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.17755670845508575 norm:0.00036900967825204134 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:06 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.1748722344636917 norm:0.0002748568949755281 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.1737157702445984 norm:0.0002502287388779223 max memory_allocated 22566.63232421875 
[2025-02-28 18:32:13 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.17330241203308105 norm:0.00022036017617210746 max memory_allocated 22566.63232421875 
[2025-02-28 18:32:47 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.17301170527935028 norm:0.0001968509895959869 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.1727539300918579 norm:0.00019068748224526644 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.17256894707679749 norm:0.00017468568694312125 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:28 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.17242126166820526 norm:0.00017037983343470842 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.17231926321983337 norm:0.00016616928041912615 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.1721799373626709 norm:0.00015580524632241577 max memory_allocated 22566.63232421875 
[2025-02-28 18:36:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.17206107079982758 norm:0.00015040620928630233 max memory_allocated 22566.63232421875 
[2025-02-28 18:36:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.1719541847705841 norm:0.00014523924619425088 max memory_allocated 22566.63232421875 
[2025-02-28 18:37:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.1718732714653015 norm:0.00014349809498526156 max memory_allocated 22566.63232421875 
[2025-02-28 18:37:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.17181147634983063 norm:0.0001465369132347405 max memory_allocated 22566.63232421875 
[2025-02-28 18:38:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.17176084220409393 norm:0.0001439258485333994 max memory_allocated 22566.63232421875 
[2025-02-28 18:38:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.17173027992248535 norm:0.00014097036910243332 max memory_allocated 22566.63232421875 
[2025-02-28 18:39:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.1716957539319992 norm:0.00014161063882056624 max memory_allocated 22566.63232421875 
[2025-02-28 18:40:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.17165392637252808 norm:0.00014200077566783875 max memory_allocated 22566.63232421875 
[2025-02-28 18:40:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 18:40:17 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:40:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.22492671012878418 norm:0.012329066172242165 max memory_allocated 22566.91943359375 
[2025-02-28 18:41:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.21379980444908142 norm:0.008800963871181011 max memory_allocated 22566.91943359375 
[2025-02-28 18:41:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.20464062690734863 norm:0.005994897335767746 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.20153534412384033 norm:0.004869460593909025 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.20024242997169495 norm:0.004117186646908522 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.19971325993537903 norm:0.0034945188090205193 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.19927407801151276 norm:0.0029345727525651455 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.19897699356079102 norm:0.0024799718521535397 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.19882577657699585 norm:0.002453520195558667 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.1986922174692154 norm:0.0024291935842484236 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.19857266545295715 norm:0.0023488299921154976 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:02 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.19845806062221527 norm:0.0022394340485334396 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.19838100671768188 norm:0.0021552005782723427 max memory_allocated 22566.91943359375 
[2025-02-28 18:48:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.1982969045639038 norm:0.002140689641237259 max memory_allocated 22566.91943359375 
[2025-02-28 18:48:43 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.19819201529026031 norm:0.0020082599949091673 max memory_allocated 22566.91943359375 
[2025-02-28 18:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.19808068871498108 norm:0.001916317967697978 max memory_allocated 22566.91943359375 
[2025-02-28 18:49:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.19808442890644073 norm:0.0019263142021372914 max memory_allocated 22566.91943359375 
[2025-02-28 18:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.19806331396102905 norm:0.0019435680005699396 max memory_allocated 22566.91943359375 
[2025-02-28 18:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.19799551367759705 norm:0.0018252430018037558 max memory_allocated 22566.91943359375 
[2025-02-28 18:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.19792665541172028 norm:0.001749293995089829 max memory_allocated 22566.91943359375 
[2025-02-28 18:51:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 18:51:44 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:52:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.27142268419265747 norm:0.01102385576814413 max memory_allocated 22567.09130859375 
[2025-02-28 18:52:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.2535218596458435 norm:0.0078117735683918 max memory_allocated 22567.09130859375 
[2025-02-28 18:53:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.24091525375843048 norm:0.005453674588352442 max memory_allocated 22567.09130859375 
[2025-02-28 18:53:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.2367037832736969 norm:0.004418017342686653 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:33 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.23504531383514404 norm:0.003571636974811554 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.23420265316963196 norm:0.0029120452236384153 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.2335478663444519 norm:0.0023298889864236116 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.23320120573043823 norm:0.0021626418456435204 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.23297002911567688 norm:0.002147048944607377 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.23284399509429932 norm:0.0021604574285447598 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.2327628880739212 norm:0.0022196208592504263 max memory_allocated 22567.09130859375 
[2025-02-28 18:58:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.23261365294456482 norm:0.002276258310303092 max memory_allocated 22567.09130859375 
[2025-02-28 18:59:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.23253807425498962 norm:0.002137519884854555 max memory_allocated 22567.09130859375 
[2025-02-28 18:59:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.23245973885059357 norm:0.0021077150013297796 max memory_allocated 22567.09130859375 
[2025-02-28 19:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.2324739545583725 norm:0.002047434914857149 max memory_allocated 22567.09130859375 
[2025-02-28 19:00:44 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.23242613673210144 norm:0.001989295007660985 max memory_allocated 22567.09130859375 
[2025-02-28 19:01:18 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.23239262402057648 norm:0.0018717212369665504 max memory_allocated 22567.09130859375 
[2025-02-28 19:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.23239310085773468 norm:0.0019120207289233804 max memory_allocated 22567.09130859375 
[2025-02-28 19:02:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.23241490125656128 norm:0.0018666537944227457 max memory_allocated 22567.09130859375 
[2025-02-28 19:02:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.23243525624275208 norm:0.0018389018950983882 max memory_allocated 22567.09130859375 
[2025-02-28 19:03:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 19:03:12 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:03:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.1254743337631226 norm:0.1376892626285553 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.9147703647613525 norm:0.11623814702033997 max memory_allocated 22567.26318359375 
[2025-02-28 19:04:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.6204994916915894 norm:0.06908309459686279 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.5204593539237976 norm:0.04390229657292366 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.47648805379867554 norm:0.0367649681866169 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.45255792140960693 norm:0.03403611108660698 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:08 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.4455527663230896 norm:0.03908543661236763 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:41 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.43297478556632996 norm:0.03788769245147705 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.4240911304950714 norm:0.03721858561038971 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.42101556062698364 norm:0.03815239295363426 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:23 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.4185975193977356 norm:0.03915001451969147 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.41418832540512085 norm:0.03767743706703186 max memory_allocated 22567.26318359375 
[2025-02-28 19:10:30 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.40328824520111084 norm:0.03430464118719101 max memory_allocated 22567.26318359375 
[2025-02-28 19:11:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.3989544212818146 norm:0.031097175553441048 max memory_allocated 22567.26318359375 
[2025-02-28 19:11:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.3983592092990875 norm:0.0313030406832695 max memory_allocated 22567.26318359375 
[2025-02-28 19:12:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.41802269220352173 norm:0.046399034559726715 max memory_allocated 22567.26318359375 
[2025-02-28 19:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.40446531772613525 norm:0.038866572082042694 max memory_allocated 22567.26318359375 
[2025-02-28 19:13:19 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.3905145525932312 norm:0.034866202622652054 max memory_allocated 22567.26318359375 
[2025-02-28 19:13:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.3874044418334961 norm:0.03194901719689369 max memory_allocated 22567.26318359375 
[2025-02-28 19:14:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.3864361643791199 norm:0.030145732685923576 max memory_allocated 22567.26318359375 
[2025-02-28 19:14:36 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 19:14:39 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:15:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.7830747961997986 norm:0.06695953756570816 max memory_allocated 22567.43505859375 
[2025-02-28 19:15:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.71848464012146 norm:0.04565649479627609 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.6794174909591675 norm:0.03286914527416229 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:54 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.6638534069061279 norm:0.026490284129977226 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.6580190658569336 norm:0.020744552835822105 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:01 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.6500188112258911 norm:0.021352844312787056 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.6438891887664795 norm:0.020297860726714134 max memory_allocated 22567.43505859375 
[2025-02-28 19:19:09 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.6387425661087036 norm:0.02009146846830845 max memory_allocated 22567.43505859375 
[2025-02-28 19:19:42 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.6354848146438599 norm:0.01706727221608162 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:16 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.6323103308677673 norm:0.017934858798980713 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.6306768655776978 norm:0.014892065897583961 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:23 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.6298887729644775 norm:0.016751399263739586 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.6294164061546326 norm:0.015139855444431305 max memory_allocated 22567.43505859375 
[2025-02-28 19:22:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.6276229023933411 norm:0.016320200636982918 max memory_allocated 22567.43505859375 
[2025-02-28 19:23:05 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.6281552314758301 norm:0.015169458463788033 max memory_allocated 22567.43505859375 
[2025-02-28 19:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.6272291541099548 norm:0.01549652311950922 max memory_allocated 22567.43505859375 
[2025-02-28 19:24:12 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.6265871524810791 norm:0.01429549790918827 max memory_allocated 22567.43505859375 
[2025-02-28 19:24:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.6247828602790833 norm:0.01440124399960041 max memory_allocated 22567.43505859375 
[2025-02-28 19:25:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.6257548928260803 norm:0.013305289670825005 max memory_allocated 22567.43505859375 
[2025-02-28 19:25:53 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.6235012412071228 norm:0.01329917460680008 max memory_allocated 22567.43505859375 
[2025-02-28 19:26:03 root] (main_calib_config2.py 380): INFO 21936.063441753387
[2025-02-28 19:26:08 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 19:27:19 root] (main_calib_config2.py 159): INFO wikitext2 : 5.814939498901367
[2025-02-28 19:27:19 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 19:29:09 root] (main_calib_config2.py 159): INFO c4 : 7.410371780395508
[2025-02-28 21:14:51 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.814939498901367, 'c4': 7.410371780395508, 'results': {'winogrande': {'acc': 0.6511444356748224, 'acc_stderr': 0.013395059320137327}, 'arc_easy': {'acc': 0.6658249158249159, 'acc_stderr': 0.009679106032919056, 'acc_norm': 0.5130471380471381, 'acc_norm_stderr': 0.010256289925058441}, 'piqa': {'acc': 0.7747551686615887, 'acc_stderr': 0.009746643471032157, 'acc_norm': 0.7709466811751904, 'acc_norm_stderr': 0.009804509865175504}, 'boolq': {'acc': 0.6825688073394496, 'acc_stderr': 0.008141240022609393}, 'hellaswag': {'acc': 0.5481975702051384, 'acc_stderr': 0.004966544724452225, 'acc_norm': 0.7071300537741486, 'acc_norm_stderr': 0.004541492151639238}, 'arc_challenge': {'acc': 0.386518771331058, 'acc_stderr': 0.014230084761910483, 'acc_norm': 0.3916382252559727, 'acc_norm_stderr': 0.014264122124938215}}, 'versions': {'winogrande': 0, 'arc_easy': 0, 'piqa': 0, 'boolq': 1, 'hellaswag': 0, 'arc_challenge': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
