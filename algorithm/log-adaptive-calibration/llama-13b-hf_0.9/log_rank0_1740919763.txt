[2025-03-02 12:49:23 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.9', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.9.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.9.pkl
[2025-03-02 12:52:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.005066227167844772 norm:0.004639932885766029 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0030305050313472748 norm:0.0032074740156531334 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0025165174156427383 norm:0.0025364626199007034 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0022599599324166775 norm:0.002098669297993183 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.002167708473280072 norm:0.0018461624858900905 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.0019344926113262773 norm:0.0013927555410191417 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.0018422262510284781 norm:0.0012643015943467617 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.0017828468699008226 norm:0.001148291863501072 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:02 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0017666607163846493 norm:0.001134535064920783 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0017499130917713046 norm:0.0009800252737477422 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:40 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0017214615363627672 norm:0.0009161882335320115 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0017082515405490994 norm:0.0008486182196065784 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:19 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0017005965346470475 norm:0.0008171842782758176 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0016884345095604658 norm:0.0007819521124474704 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001686860341578722 norm:0.0007557444041594863 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:47 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0016659703105688095 norm:0.0007157031213864684 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0016627118457108736 norm:0.0006881916197016835 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:25 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.0016388724325224757 norm:0.000635067350231111 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.00165635219309479 norm:0.0006529651582241058 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0016411527758464217 norm:0.0006217228947207332 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:22 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.008334844373166561 norm:0.004977402277290821 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.006191534455865622 norm:0.004396009724587202 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.005521621089428663 norm:0.003448889125138521 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.005171711556613445 norm:0.002754016313701868 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:28 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.004999078810214996 norm:0.0023503336124122143 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.0049134171567857265 norm:0.0020034904591739178 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.0048244306817650795 norm:0.0016732125077396631 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.004712472204118967 norm:0.0014343014918267727 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:44 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.004653132986277342 norm:0.0012414848897606134 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.0045742192305624485 norm:0.0011760564520955086 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.004498471971601248 norm:0.001126981107518077 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.004438833333551884 norm:0.0010423383209854364 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.004441964440047741 norm:0.0010974856559187174 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.0045216623693704605 norm:0.001162348547950387 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.004488545004278421 norm:0.001080441172234714 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.004402847494930029 norm:0.0009063755860552192 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:18 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.004314506892114878 norm:0.0007885086233727634 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.00442019896581769 norm:0.000870012678205967 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.004473506473004818 norm:0.0008407822460867465 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.00432504853233695 norm:0.0007980228401720524 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:04 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.023134533315896988 norm:0.010397247970104218 max memory_allocated 29268.02001953125 
[2025-03-02 13:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.015952222049236298 norm:0.007386837620288134 max memory_allocated 29268.02001953125 
[2025-03-02 13:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.013684204779565334 norm:0.006819022819399834 max memory_allocated 29268.02001953125 
[2025-03-02 13:29:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.012463890947401524 norm:0.0062150196172297 max memory_allocated 29268.02001953125 
[2025-03-02 13:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.011542482301592827 norm:0.005565512925386429 max memory_allocated 29268.02001953125 
[2025-03-02 13:30:59 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.011019517667591572 norm:0.005245612934231758 max memory_allocated 29268.02001953125 
[2025-03-02 13:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.010425814427435398 norm:0.0044909510761499405 max memory_allocated 29268.02001953125 
[2025-03-02 13:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.010177908465266228 norm:0.00429790373891592 max memory_allocated 29268.02001953125 
[2025-03-02 13:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.009912854060530663 norm:0.003799508325755596 max memory_allocated 29268.02001953125 
[2025-03-02 13:34:16 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.009710749611258507 norm:0.0038656811229884624 max memory_allocated 29268.02001953125 
[2025-03-02 13:35:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.009513231925666332 norm:0.003475744277238846 max memory_allocated 29268.02001953125 
[2025-03-02 13:35:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.009331266395747662 norm:0.003215538104996085 max memory_allocated 29268.02001953125 
[2025-03-02 13:36:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.009353444911539555 norm:0.0031214954797178507 max memory_allocated 29268.02001953125 
[2025-03-02 13:37:33 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.009226247668266296 norm:0.003012224333360791 max memory_allocated 29268.02001953125 
[2025-03-02 13:38:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.009187523275613785 norm:0.0029350328259170055 max memory_allocated 29268.02001953125 
[2025-03-02 13:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.009122572839260101 norm:0.0028470810502767563 max memory_allocated 29268.02001953125 
[2025-03-02 13:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.009066559374332428 norm:0.0027367165312170982 max memory_allocated 29268.02001953125 
[2025-03-02 13:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.009020291268825531 norm:0.0026725693605840206 max memory_allocated 29268.02001953125 
[2025-03-02 13:41:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.009031681343913078 norm:0.002641444792971015 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:29 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.008997630327939987 norm:0.0026688084471970797 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:43:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.015565421432256699 norm:0.0016084701055660844 max memory_allocated 29268.43798828125 
[2025-03-02 13:44:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.012113001197576523 norm:0.000645178253762424 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.011111335828900337 norm:0.0003174273297190666 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.010702230967581272 norm:0.00023844030511099845 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.010452832095324993 norm:0.00012893721577711403 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.010265731252729893 norm:0.00013563486572820693 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.010139646008610725 norm:0.00014349663979373872 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.010010497644543648 norm:0.0001278950658161193 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.009939610958099365 norm:0.00011943181743845344 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.009967470541596413 norm:0.00016200257232412696 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.00989868026226759 norm:0.00010039485641755164 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.00985898170620203 norm:8.981768041849136e-05 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:25 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.009880809113383293 norm:0.00011922815610887483 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:14 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.009904495440423489 norm:0.00010596640640869737 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.009852617979049683 norm:0.0001108673241105862 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.009845392778515816 norm:0.00011492364865262061 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.009824633598327637 norm:0.00013077358016744256 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.00979425385594368 norm:0.00012608180986717343 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:19 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.009801637381315231 norm:0.00015785903087817132 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.009794699028134346 norm:0.00012808982864953578 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:00:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.021626239642500877 norm:0.0031824815087020397 max memory_allocated 29268.43798828125 
[2025-03-02 14:01:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.016098741441965103 norm:0.0009111503604799509 max memory_allocated 29268.43798828125 
[2025-03-02 14:01:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.014399641193449497 norm:0.0005693570710718632 max memory_allocated 29268.43798828125 
[2025-03-02 14:02:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.013765336945652962 norm:0.0004500458890106529 max memory_allocated 29268.43798828125 
[2025-03-02 14:03:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.013332592323422432 norm:0.00031000078888610005 max memory_allocated 29268.43798828125 
[2025-03-02 14:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.01303352601826191 norm:0.00025461617042310536 max memory_allocated 29268.43798828125 
[2025-03-02 14:05:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.012881782837212086 norm:0.00023099056852515787 max memory_allocated 29268.43798828125 
[2025-03-02 14:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.012790005654096603 norm:0.0002200224407715723 max memory_allocated 29268.43798828125 
[2025-03-02 14:06:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.012743818573653698 norm:0.0001784609630703926 max memory_allocated 29268.43798828125 
[2025-03-02 14:07:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.012712853960692883 norm:0.0001581118704052642 max memory_allocated 29268.43798828125 
[2025-03-02 14:08:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.012685926631093025 norm:0.0001569684100104496 max memory_allocated 29268.43798828125 
[2025-03-02 14:09:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.012685051187872887 norm:0.00017044252308551222 max memory_allocated 29268.43798828125 
[2025-03-02 14:10:05 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.012598061934113503 norm:0.00012812542263418436 max memory_allocated 29268.43798828125 
[2025-03-02 14:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.012571580708026886 norm:0.00014024178381077945 max memory_allocated 29268.43798828125 
[2025-03-02 14:11:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.012547198683023453 norm:0.00010957896301988512 max memory_allocated 29268.43798828125 
[2025-03-02 14:12:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.012546357698738575 norm:0.0001158037775894627 max memory_allocated 29268.43798828125 
[2025-03-02 14:13:21 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.012522002682089806 norm:0.00011050932516809553 max memory_allocated 29268.43798828125 
[2025-03-02 14:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.012509983032941818 norm:0.00011458394874352962 max memory_allocated 29268.43798828125 
[2025-03-02 14:15:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.012543262913823128 norm:0.00014016148634254932 max memory_allocated 29268.43798828125 
[2025-03-02 14:15:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.012582763098180294 norm:0.0001473710872232914 max memory_allocated 29268.43798828125 
[2025-03-02 14:16:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:16:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.027911294251680374 norm:0.0034763896837830544 max memory_allocated 29268.43798828125 
[2025-03-02 14:17:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.019421685487031937 norm:0.0010620830580592155 max memory_allocated 29268.43798828125 
[2025-03-02 14:18:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.017009615898132324 norm:0.0005778651684522629 max memory_allocated 29268.43798828125 
[2025-03-02 14:19:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.016110431402921677 norm:0.00038944772677496076 max memory_allocated 29268.43798828125 
[2025-03-02 14:20:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.01563233695924282 norm:0.0003064790216740221 max memory_allocated 29268.43798828125 
[2025-03-02 14:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.015284733846783638 norm:0.0002557213883846998 max memory_allocated 29268.43798828125 
[2025-03-02 14:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.015070727095007896 norm:0.00022435543360188603 max memory_allocated 29268.43798828125 
[2025-03-02 14:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.014956851489841938 norm:0.00021913388627581298 max memory_allocated 29268.43798828125 
[2025-03-02 14:23:29 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.014901489950716496 norm:0.00016934607992880046 max memory_allocated 29268.43798828125 
[2025-03-02 14:24:18 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.014818143099546432 norm:0.00016485330706927925 max memory_allocated 29268.43798828125 
[2025-03-02 14:25:07 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.014774286188185215 norm:0.00017224758630618453 max memory_allocated 29268.43798828125 
[2025-03-02 14:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.01476491428911686 norm:0.00018718038336373866 max memory_allocated 29268.43798828125 
[2025-03-02 14:26:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.014725602231919765 norm:0.00016144233813975006 max memory_allocated 29268.43798828125 
[2025-03-02 14:27:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.014681259170174599 norm:0.00013637234224006534 max memory_allocated 29268.43798828125 
[2025-03-02 14:28:23 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.014679965563118458 norm:0.00014682122855447233 max memory_allocated 29268.43798828125 
[2025-03-02 14:29:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.014652727171778679 norm:0.0001447357062716037 max memory_allocated 29268.43798828125 
[2025-03-02 14:30:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.014631624333560467 norm:0.00013412719999905676 max memory_allocated 29268.43798828125 
[2025-03-02 14:30:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.014621691778302193 norm:0.00015181369963102043 max memory_allocated 29268.43798828125 
[2025-03-02 14:31:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.014592009596526623 norm:0.00012161371705587953 max memory_allocated 29268.43798828125 
[2025-03-02 14:32:29 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.01455907616764307 norm:0.00011353185982443392 max memory_allocated 29268.43798828125 
[2025-03-02 14:32:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:33:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.030416211113333702 norm:0.00209148321300745 max memory_allocated 29269.00048828125 
[2025-03-02 14:34:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.0239168219268322 norm:0.00127743452321738 max memory_allocated 29269.00048828125 
[2025-03-02 14:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.02119787223637104 norm:0.0008808699203655124 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.01978372037410736 norm:0.0006612182478420436 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:52 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.01914350874722004 norm:0.0005737229948863387 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.018595963716506958 norm:0.0005031233886256814 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.018199190497398376 norm:0.00047188199823722243 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.01794201321899891 norm:0.0005735519807785749 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.017717797309160233 norm:0.00045115529792383313 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.017621442675590515 norm:0.0006316364742815495 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.01752716675400734 norm:0.0004288697091396898 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.01748030260205269 norm:0.0007144305855035782 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.01743614673614502 norm:0.0007107013370841742 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.017429169267416 norm:0.0007141326204873621 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.017389673739671707 norm:0.0007138787186704576 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:52 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.017339790239930153 norm:0.000578000326640904 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.017328282818198204 norm:0.00046659784857183695 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.017341025173664093 norm:0.000381463672965765 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.017296861857175827 norm:0.00030567197245545685 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.01732395775616169 norm:0.0004910264979116619 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.028154319152235985 norm:0.0013659433461725712 max memory_allocated 29269.18798828125 
[2025-03-02 14:51:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.022893542423844337 norm:0.000615609111264348 max memory_allocated 29269.18798828125 
[2025-03-02 14:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.02109590731561184 norm:0.0003270957386121154 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.020290501415729523 norm:0.00021194522560108453 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.019859299063682556 norm:0.0001782201579771936 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.019586853682994843 norm:0.0001583843259140849 max memory_allocated 29269.18798828125 
[2025-03-02 14:55:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.01939813792705536 norm:0.00014863998512737453 max memory_allocated 29269.18798828125 
[2025-03-02 14:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.019278552383184433 norm:0.00013647490413859487 max memory_allocated 29269.18798828125 
[2025-03-02 14:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.019228549674153328 norm:0.00013559212675318122 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.019177986308932304 norm:0.0001385772629873827 max memory_allocated 29269.18798828125 
[2025-03-02 14:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.01914036087691784 norm:0.0001377029693685472 max memory_allocated 29269.18798828125 
[2025-03-02 14:59:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.019098341464996338 norm:0.0001527309068478644 max memory_allocated 29269.18798828125 
[2025-03-02 15:00:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.019059015437960625 norm:0.0001503150415373966 max memory_allocated 29269.18798828125 
[2025-03-02 15:00:53 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.01904018595814705 norm:0.00013963431410957128 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.019022833555936813 norm:0.00013714557280763984 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.019051291048526764 norm:0.0001450180570827797 max memory_allocated 29269.18798828125 
[2025-03-02 15:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.01903184875845909 norm:0.00013148528523743153 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.019022153690457344 norm:0.00013604261039290577 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.019000384956598282 norm:0.00012883628369309008 max memory_allocated 29269.18798828125 
[2025-03-02 15:05:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.01897868700325489 norm:0.00012534639972727746 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:06:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.031180964782834053 norm:0.0015368536114692688 max memory_allocated 29269.37548828125 
[2025-03-02 15:07:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.0253444816917181 norm:0.0006157064926810563 max memory_allocated 29269.37548828125 
[2025-03-02 15:08:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.023567406460642815 norm:0.00033203669590875506 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.022814838215708733 norm:0.00024454217054881155 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.022302161902189255 norm:0.0001982637622859329 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.0219687819480896 norm:0.0001768462243489921 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.021753797307610512 norm:0.00016269594198092818 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.021633900701999664 norm:0.00015983475896064192 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.021523723378777504 norm:0.00014378699415829033 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.021474773064255714 norm:0.00013673875946551561 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.02143595926463604 norm:0.00014635863772127777 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:55 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.021451054140925407 norm:0.00014646652562078089 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.021431103348731995 norm:0.00013779188157059252 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.021449659019708633 norm:0.00014026521239429712 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.02140657603740692 norm:0.00013233913341537118 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.021357541903853416 norm:0.0001309349318034947 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.021344628185033798 norm:0.00013015854347031564 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.021336302161216736 norm:0.000125729784485884 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.021316837519407272 norm:0.00012798261013813317 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.021347010508179665 norm:0.0001261301222257316 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.03170544281601906 norm:0.0012393114157021046 max memory_allocated 29269.56298828125 
[2025-03-02 15:24:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.026828566566109657 norm:0.0005356731708161533 max memory_allocated 29269.56298828125 
[2025-03-02 15:25:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.02509395405650139 norm:0.0002856698411051184 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.024374376982450485 norm:0.0001998239749809727 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.023945942521095276 norm:0.00016552563465666026 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.023659858852624893 norm:0.00015099591109901667 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.02343674749135971 norm:0.00013376897550188005 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.023330481722950935 norm:0.0001283654710277915 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.023262640461325645 norm:0.00012605407391674817 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.02323685586452484 norm:0.00012387838796712458 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:46 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.02320190891623497 norm:0.00012386158050503582 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.023173881694674492 norm:0.00012418036931194365 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.02313828095793724 norm:0.0001215782031067647 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.02311333827674389 norm:0.00011903323320439085 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.02310081012547016 norm:0.000125771330203861 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.02308456227183342 norm:0.00012202448124298826 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.023078439757227898 norm:0.0001191423216369003 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.023072199895977974 norm:0.00011997015099041164 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.023073922842741013 norm:0.00012384465662762523 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.02306962199509144 norm:0.00012422216241247952 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:40:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.030268199741840363 norm:0.0010049963602796197 max memory_allocated 29269.75048828125 
[2025-03-02 15:41:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.027947695925831795 norm:0.0003717032668646425 max memory_allocated 29269.75048828125 
[2025-03-02 15:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.027105648070573807 norm:0.00018484854081179947 max memory_allocated 29269.75048828125 
[2025-03-02 15:42:43 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.026512466371059418 norm:0.00011921430996153504 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.026033880189061165 norm:9.542459883959964e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.025737227872014046 norm:8.503405115334317e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.025606904178857803 norm:7.943516538944095e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.025556333363056183 norm:7.696260581724346e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.02553582936525345 norm:7.533610187238082e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.025535566732287407 norm:7.489336712751538e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.025524927303195 norm:7.427176024066284e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:49:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.025507383048534393 norm:7.296956755453721e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:04 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.025512024760246277 norm:7.314393587876111e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.025504086166620255 norm:7.308667409233749e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.025494160130620003 norm:7.269399065990001e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.025495164096355438 norm:7.220258703455329e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:21 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.025500819087028503 norm:7.156086212489754e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.02548607997596264 norm:7.143468246795237e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.02547990344464779 norm:7.146565621951595e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:48 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.025496309623122215 norm:7.113700121408328e-05 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:56:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.03552541509270668 norm:0.0011021452955901623 max memory_allocated 29269.93798828125 
[2025-03-02 15:57:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.03130418807268143 norm:0.0004821560869459063 max memory_allocated 29269.93798828125 
[2025-03-02 15:58:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.029486993327736855 norm:0.0002555669052526355 max memory_allocated 29269.93798828125 
[2025-03-02 15:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.028751427307724953 norm:0.00017709212261252105 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.028290705755352974 norm:0.0001446227979613468 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.02800210751593113 norm:0.0001268921623704955 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.02780185639858246 norm:0.00011969829211011529 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.027686404064297676 norm:0.00011467470903880894 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.027612771838903427 norm:0.00010986033885274082 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.02755393646657467 norm:0.00010846649820450693 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:06 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.027517851442098618 norm:0.0001042057410813868 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.027508454397320747 norm:0.00010639003448886797 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:44 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.027492454275488853 norm:0.00010533859312999994 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.027469158172607422 norm:0.00010550706792855635 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.02743939310312271 norm:0.00010317327541997656 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.027414947748184204 norm:0.00010034135630121455 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:00 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.027413178235292435 norm:0.00010061690409202129 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.027438022196292877 norm:0.00010289176134392619 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.02743239887058735 norm:0.00010231233318336308 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.027458708733320236 norm:0.00010631325130816549 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:13:34 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.0350707471370697 norm:0.0008842485258355737 max memory_allocated 29270.12548828125 
[2025-03-02 16:14:23 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.032020315527915955 norm:0.0003909390652552247 max memory_allocated 29270.12548828125 
[2025-03-02 16:15:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.03081304207444191 norm:0.00023957119265105575 max memory_allocated 29270.12548828125 
[2025-03-02 16:16:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.030157338827848434 norm:0.00017509961617179215 max memory_allocated 29270.12548828125 
[2025-03-02 16:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.029691636562347412 norm:0.00014622090384364128 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.029414359480142593 norm:0.00012887342018075287 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.029251208528876305 norm:0.00011875997734023258 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.029136214405298233 norm:0.00011222819011891261 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.029049783945083618 norm:0.00010753467358881608 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:56 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.028996895998716354 norm:0.00010404008935438469 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:46 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.028986403718590736 norm:0.00010227655002381653 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:35 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.028974499553442 norm:0.00010331814701203257 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.028954312205314636 norm:0.00010386877693235874 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.028950663283467293 norm:0.00010102341184392571 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.028934355825185776 norm:0.00010068351548397914 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.028921516612172127 norm:0.00010031111742137 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.028919389471411705 norm:0.00010196209041168913 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.028914088383316994 norm:0.00010107441630680114 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.02890491671860218 norm:0.00010085043322760612 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:07 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.028897661715745926 norm:0.00010048616968560964 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:30:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.03634856641292572 norm:0.0006665621767751873 max memory_allocated 29270.31298828125 
[2025-03-02 16:31:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.03357909992337227 norm:0.000337030622176826 max memory_allocated 29270.31298828125 
[2025-03-02 16:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.032361872494220734 norm:0.0002242797054350376 max memory_allocated 29270.31298828125 
[2025-03-02 16:32:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.031676433980464935 norm:0.0001705493195913732 max memory_allocated 29270.31298828125 
[2025-03-02 16:33:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.031199263408780098 norm:0.00014428183203563094 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.03087093122303486 norm:0.000126612838357687 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.03066159598529339 norm:0.00011530206393217668 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:58 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.030554451048374176 norm:0.00011269006790826097 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.030498484149575233 norm:0.00011093092325609177 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.03043871745467186 norm:0.00010614938946673647 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.03040674515068531 norm:0.00010437519813422114 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:15 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.03038904443383217 norm:0.00010415757424198091 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.030351750552654266 norm:0.0001038941991282627 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.03034418821334839 norm:0.0001005791054922156 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:42 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.03034634329378605 norm:0.0001012210050248541 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.030338166281580925 norm:0.00010150055459234864 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.030320461839437485 norm:0.00010164581908611581 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.03029491938650608 norm:9.827599569689482e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.030292287468910217 norm:0.000100305063824635 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.03028932400047779 norm:0.00010090299474541098 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:46:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.03909832611680031 norm:0.0009870280046015978 max memory_allocated 29270.50048828125 
[2025-03-02 16:47:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.035595182329416275 norm:0.00047040751087479293 max memory_allocated 29270.50048828125 
[2025-03-02 16:48:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.03410027176141739 norm:0.0002850066521205008 max memory_allocated 29270.50048828125 
[2025-03-02 16:49:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.03336883336305618 norm:0.00020456819038372487 max memory_allocated 29270.50048828125 
[2025-03-02 16:50:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.03286014124751091 norm:0.00016082580259535462 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.03252365440130234 norm:0.00013958857744000852 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.03232165798544884 norm:0.00012625388626474887 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.03219039738178253 norm:0.00011709932005032897 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.03210742026567459 norm:0.00011111384083051234 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.03206542879343033 norm:0.0001093205573852174 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.03204154223203659 norm:0.00010640696564223617 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.03202889487147331 norm:0.00010489900159882382 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.032001279294490814 norm:0.00010648289753589779 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.031986404210329056 norm:0.00010985043627442792 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.03197887912392616 norm:0.00010911051504081115 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.03196598216891289 norm:0.00010971979645546526 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.03194503113627434 norm:0.00011132056533824652 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:49 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.03193335980176926 norm:0.00011141400318592787 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.03193270415067673 norm:0.00011287904635537416 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:28 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.031925737857818604 norm:0.00011028829612769186 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:03:35 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.04092971980571747 norm:0.000859242572914809 max memory_allocated 29270.68798828125 
[2025-03-02 17:04:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.03771727532148361 norm:0.0003309800522401929 max memory_allocated 29270.68798828125 
[2025-03-02 17:05:13 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.03652771934866905 norm:0.00022955208260100335 max memory_allocated 29270.68798828125 
[2025-03-02 17:06:02 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.03583386540412903 norm:0.00018796503718476743 max memory_allocated 29270.68798828125 
[2025-03-02 17:06:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.035318441689014435 norm:0.00016039740876294672 max memory_allocated 29270.68798828125 
[2025-03-02 17:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.03495467081665993 norm:0.00014182731683831662 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:29 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.03473477065563202 norm:0.00013120254152454436 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.03462398797273636 norm:0.00012329699529800564 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.03456273674964905 norm:0.00011644695041468367 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.03447657451033592 norm:0.00011154764797538519 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.034424446523189545 norm:0.000107837506220676 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.03438965603709221 norm:0.00010424243373563513 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.03435289487242699 norm:0.00010195958020631224 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.03430839627981186 norm:9.765427239472046e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.034301549196243286 norm:9.905932529363781e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:50 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.03428978472948074 norm:9.753427002578974e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:39 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.03429418057203293 norm:0.00010022870992543176 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.03430681675672531 norm:0.00010406273213448003 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.034309931099414825 norm:0.00010349942022003233 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:06 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.03429584950208664 norm:0.0001036939793266356 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:20 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:20:13 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.042184747755527496 norm:0.0010559741640463471 max memory_allocated 29270.87548828125 
[2025-03-02 17:21:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.0398101769387722 norm:0.000504883355461061 max memory_allocated 29270.87548828125 
[2025-03-02 17:21:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.03884703665971756 norm:0.00031377130653709173 max memory_allocated 29270.87548828125 
[2025-03-02 17:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.03820046782493591 norm:0.00022370280930772424 max memory_allocated 29270.87548828125 
[2025-03-02 17:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.03770029544830322 norm:0.00017430637672077864 max memory_allocated 29270.87548828125 
[2025-03-02 17:24:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.03737882897257805 norm:0.00014222762547433376 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.03721604496240616 norm:0.0001258045667782426 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.03714504837989807 norm:0.00011746393283829093 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.03708843141794205 norm:0.00010767367348307744 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.037043459713459015 norm:0.00010423110506962985 max memory_allocated 29270.87548828125 
[2025-03-02 17:28:25 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.03699824959039688 norm:0.00010098372149514034 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.036984965205192566 norm:9.927107748808339e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.03696530684828758 norm:9.708753350423649e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:52 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.03694353252649307 norm:9.553712152410299e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.03693032264709473 norm:9.708521247375757e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:30 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.036932215094566345 norm:9.819243132369593e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:33:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.03692172095179558 norm:9.76105802692473e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.036915309727191925 norm:9.845100430538878e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.03690095618367195 norm:9.693208266980946e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.03689457103610039 norm:9.719608351588249e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:36:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.04610651731491089 norm:0.0013480846537277102 max memory_allocated 29271.06298828125 
[2025-03-02 17:37:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.04327590763568878 norm:0.0005948363686911762 max memory_allocated 29271.06298828125 
[2025-03-02 17:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.04207026958465576 norm:0.0003576753369998187 max memory_allocated 29271.06298828125 
[2025-03-02 17:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.04125121235847473 norm:0.00024584439233876765 max memory_allocated 29271.06298828125 
[2025-03-02 17:40:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.04068469628691673 norm:0.00018470392387825996 max memory_allocated 29271.06298828125 
[2025-03-02 17:40:59 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.0403502993285656 norm:0.00015072552196215838 max memory_allocated 29271.06298828125 
[2025-03-02 17:41:48 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.04017487168312073 norm:0.00013115481124259531 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.04006081074476242 norm:0.00011429849109845236 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.03998073935508728 norm:0.00010316146654076874 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.03993544727563858 norm:9.909005166264251e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.039909422397613525 norm:9.701241651782766e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.03988690674304962 norm:9.317963849753141e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.039865706115961075 norm:9.27321016206406e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:32 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.03984924033284187 norm:9.212903387378901e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.039830684661865234 norm:9.195765596814454e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:11 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.03983137384057045 norm:9.314202179666609e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.03982013463973999 norm:9.135506115853786e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.03980671986937523 norm:9.076943388208747e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:38 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.03978780657052994 norm:9.048760693985969e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.039796970784664154 norm:9.100027818931267e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.050567880272865295 norm:0.001255448441952467 max memory_allocated 29271.25048828125 
[2025-03-02 17:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.04763130471110344 norm:0.0005186655325815082 max memory_allocated 29271.25048828125 
[2025-03-02 17:55:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.04637741297483444 norm:0.0003073947154916823 max memory_allocated 29271.25048828125 
[2025-03-02 17:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.04553408548235893 norm:0.00021769745217170566 max memory_allocated 29271.25048828125 
[2025-03-02 17:56:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.04497140645980835 norm:0.0001725384354358539 max memory_allocated 29271.25048828125 
[2025-03-02 17:57:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.04464885592460632 norm:0.00014990063209552318 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.04446788877248764 norm:0.00013504410162568092 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.044371288269758224 norm:0.00012407249596435577 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:07 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.044288091361522675 norm:0.00011935130169149488 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.04423322528600693 norm:0.0001146474460256286 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.04417851194739342 norm:0.0001096074702218175 max memory_allocated 29271.25048828125 
[2025-03-02 18:02:34 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.044143639504909515 norm:0.00010757611744338647 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:23 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.04411432519555092 norm:0.0001069334102794528 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.044075071811676025 norm:0.00010434415162308142 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.04406999796628952 norm:0.00010556855704635382 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.04407603666186333 norm:0.00010488395491847768 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.044079750776290894 norm:0.00010634129284881055 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.0440664142370224 norm:0.00010509704588912427 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.04406511411070824 norm:0.00010645688598742709 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.04405289143323898 norm:0.00010601407120702788 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:10:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.053988367319107056 norm:0.0008611350203864276 max memory_allocated 29271.43798828125 
[2025-03-02 18:11:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.05193698778748512 norm:0.00038186460733413696 max memory_allocated 29271.43798828125 
[2025-03-02 18:11:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.05086524784564972 norm:0.0002464368590153754 max memory_allocated 29271.43798828125 
[2025-03-02 18:12:41 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.05008484050631523 norm:0.00017803207447286695 max memory_allocated 29271.43798828125 
[2025-03-02 18:13:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.04951980710029602 norm:0.00014536271919496357 max memory_allocated 29271.43798828125 
[2025-03-02 18:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.04924950748682022 norm:0.00012427200272213668 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:08 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.04913722351193428 norm:0.00011378611816326156 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.04906811565160751 norm:0.00010615645442157984 max memory_allocated 29271.43798828125 
[2025-03-02 18:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.04901343584060669 norm:0.00010413050767965615 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.048981234431266785 norm:0.00010130214650416747 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.048951778560876846 norm:0.00010065537207992747 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.04890812560915947 norm:0.00010029374243458733 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.04887223243713379 norm:9.778457024367526e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:52 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.04885384812951088 norm:9.614107693778351e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.048851266503334045 norm:9.665315883466974e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.0488637238740921 norm:0.00010081242362502962 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.04884571582078934 norm:9.849516209214926e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.04885155335068703 norm:9.981434413930401e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.04885737970471382 norm:9.999688336392865e-05 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.04885417968034744 norm:0.00010161756654269993 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.06032899022102356 norm:0.0008218861185014248 max memory_allocated 29271.62548828125 
[2025-03-02 18:27:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.05747329443693161 norm:0.0003646290278993547 max memory_allocated 29271.62548828125 
[2025-03-02 18:28:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.05623595416545868 norm:0.0002486573939677328 max memory_allocated 29271.62548828125 
[2025-03-02 18:29:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.055339083075523376 norm:0.00019000117026735097 max memory_allocated 29271.62548828125 
[2025-03-02 18:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.05471159890294075 norm:0.0001556611096020788 max memory_allocated 29271.62548828125 
[2025-03-02 18:30:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.05445224791765213 norm:0.00013907995889894664 max memory_allocated 29271.62548828125 
[2025-03-02 18:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.05432186275720596 norm:0.00012633248115889728 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.0542093962430954 norm:0.0001184718421427533 max memory_allocated 29271.62548828125 
[2025-03-02 18:33:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.05412426218390465 norm:0.00010977093916153535 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.05405357480049133 norm:0.00010319953435100615 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:05 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.05400446057319641 norm:0.00010184559505432844 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.05397630110383034 norm:0.00010126970300916582 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:43 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.053932931274175644 norm:9.633319859858602e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:32 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.05392269790172577 norm:9.813685028348118e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.05388804152607918 norm:9.468517237110063e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.053877297788858414 norm:9.5513736596331e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.05387568101286888 norm:9.458600106881931e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.05386922508478165 norm:9.512362885288894e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.053860701620578766 norm:9.395063534611836e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:42:27 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.05384849011898041 norm:9.316212526755407e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:42:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.06869986653327942 norm:0.0012958802981302142 max memory_allocated 29271.81298828125 
[2025-03-02 18:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.06542782485485077 norm:0.0006052087992429733 max memory_allocated 29271.81298828125 
[2025-03-02 18:45:12 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.06382841616868973 norm:0.0003706457791849971 max memory_allocated 29271.81298828125 
[2025-03-02 18:46:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.06267053633928299 norm:0.0002662788610905409 max memory_allocated 29271.81298828125 
[2025-03-02 18:46:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.061971694231033325 norm:0.00020831140864174813 max memory_allocated 29271.81298828125 
[2025-03-02 18:47:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.061703626066446304 norm:0.00017026069690473378 max memory_allocated 29271.81298828125 
[2025-03-02 18:48:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.061558984220027924 norm:0.0001482149091316387 max memory_allocated 29271.81298828125 
[2025-03-02 18:49:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.06146740913391113 norm:0.00013332648086361587 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.06139664351940155 norm:0.00012153538409620523 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.061348505318164825 norm:0.00011407485726522282 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.061313774436712265 norm:0.00010691240458982065 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.06128033995628357 norm:0.0001015344969346188 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:24 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.06124654412269592 norm:9.790011972654611e-05 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.06122289225459099 norm:9.497974679106846e-05 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:02 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.06120709329843521 norm:9.342936391476542e-05 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.061198778450489044 norm:9.090943058254197e-05 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.061191216111183167 norm:8.966409222921357e-05 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.061184853315353394 norm:8.789874846115708e-05 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.06117198243737221 norm:8.774510206421837e-05 max memory_allocated 29271.81298828125 
[2025-03-02 18:59:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.061162590980529785 norm:8.568221528548747e-05 max memory_allocated 29271.81298828125 
[2025-03-02 18:59:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:00:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.07543271780014038 norm:0.0009682764648459852 max memory_allocated 29272.00048828125 
[2025-03-02 19:01:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.07327540963888168 norm:0.0004894240410067141 max memory_allocated 29272.00048828125 
[2025-03-02 19:01:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.07190848886966705 norm:0.00030811564647592604 max memory_allocated 29272.00048828125 
[2025-03-02 19:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.07076720893383026 norm:0.00021884965826757252 max memory_allocated 29272.00048828125 
[2025-03-02 19:03:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.07012194395065308 norm:0.00016796354611869901 max memory_allocated 29272.00048828125 
[2025-03-02 19:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.06989391148090363 norm:0.00014074252976570278 max memory_allocated 29272.00048828125 
[2025-03-02 19:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.06977271288633347 norm:0.0001224782463395968 max memory_allocated 29272.00048828125 
[2025-03-02 19:05:58 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.06969840824604034 norm:0.00011288693349342793 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.06964936852455139 norm:0.00010489544365555048 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.06960746645927429 norm:9.789330215426162e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.06956955790519714 norm:9.495070116827264e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.06956034898757935 norm:9.475018305238336e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.06954042613506317 norm:9.176155435852706e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.06953760981559753 norm:8.931213960750028e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.06951697170734406 norm:8.784647798165679e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.06951399892568588 norm:8.863927359925583e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.06950567662715912 norm:8.77210550243035e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:09 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.06950286775827408 norm:8.901632099878043e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:59 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.06949829310178757 norm:8.835863263811916e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.06949643790721893 norm:8.909177267923951e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:16:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.0860627293586731 norm:0.0011800910579040647 max memory_allocated 29272.18798828125 
[2025-03-02 19:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.08347219228744507 norm:0.0005879787495359778 max memory_allocated 29272.18798828125 
[2025-03-02 19:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.08197418600320816 norm:0.0003679764922708273 max memory_allocated 29272.18798828125 
[2025-03-02 19:19:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.0807047188282013 norm:0.00026293957489542663 max memory_allocated 29272.18798828125 
[2025-03-02 19:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.08003561943769455 norm:0.00020401825895532966 max memory_allocated 29272.18798828125 
[2025-03-02 19:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.07980566471815109 norm:0.000171031424542889 max memory_allocated 29272.18798828125 
[2025-03-02 19:21:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.0796695277094841 norm:0.00015046153566800058 max memory_allocated 29272.18798828125 
[2025-03-02 19:22:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.07959029823541641 norm:0.00013621525431517512 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.07951293140649796 norm:0.0001275225804420188 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.07945778965950012 norm:0.00011723607894964516 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.07940821349620819 norm:0.00011124131560791284 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.07938571274280548 norm:0.0001056512410286814 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.0793689638376236 norm:0.0001041115538100712 max memory_allocated 29272.18798828125 
[2025-03-02 19:27:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.07933974266052246 norm:0.0001013727523968555 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:22 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.07932437211275101 norm:9.769712050911039e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:11 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.0793168768286705 norm:9.806009620660916e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:00 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.07931245863437653 norm:9.968133963411674e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:49 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.0793033018708229 norm:9.620517812436447e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.07929548621177673 norm:9.517969738226384e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:28 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.0792967677116394 norm:9.436355321668088e-05 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:33:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.09531649947166443 norm:0.001296858536079526 max memory_allocated 29272.37548828125 
[2025-03-02 19:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.09322533011436462 norm:0.0006623840890824795 max memory_allocated 29272.37548828125 
[2025-03-02 19:35:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.09189163893461227 norm:0.00042783518438227475 max memory_allocated 29272.37548828125 
[2025-03-02 19:36:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.09064365178346634 norm:0.0003005939070135355 max memory_allocated 29272.37548828125 
[2025-03-02 19:36:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.09009377658367157 norm:0.00023022989626042545 max memory_allocated 29272.37548828125 
[2025-03-02 19:37:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.08988897502422333 norm:0.00019501293718349189 max memory_allocated 29272.37548828125 
[2025-03-02 19:38:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.0897514671087265 norm:0.00016788353968877345 max memory_allocated 29272.37548828125 
[2025-03-02 19:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.08967026323080063 norm:0.00015322602121159434 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.08960583060979843 norm:0.00014356171595863998 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.08957907557487488 norm:0.0001338369183940813 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.08953998982906342 norm:0.00012875923130195588 max memory_allocated 29272.37548828125 
[2025-03-02 19:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.08949729055166245 norm:0.00012480319128371775 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.0894622951745987 norm:0.00012111026444472373 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.08943361788988113 norm:0.00012084633635822684 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.08942686021327972 norm:0.00012342995614744723 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.08940482139587402 norm:0.00011910605826415122 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:41 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.08937658369541168 norm:0.00011832345626316965 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.0893755555152893 norm:0.00011982076102867723 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.0893932431936264 norm:0.00011914009519387037 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.08938562870025635 norm:0.0001200968399643898 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.10706698894500732 norm:0.0009448763448745012 max memory_allocated 29272.56298828125 
[2025-03-02 19:51:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.10524269193410873 norm:0.0004948803107254207 max memory_allocated 29272.56298828125 
[2025-03-02 19:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.10381358861923218 norm:0.00032527896109968424 max memory_allocated 29272.56298828125 
[2025-03-02 19:52:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.10249319672584534 norm:0.00023866868286859244 max memory_allocated 29272.56298828125 
[2025-03-02 19:53:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.10193949192762375 norm:0.00019123948004562408 max memory_allocated 29272.56298828125 
[2025-03-02 19:54:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.10173279792070389 norm:0.00016283894365187734 max memory_allocated 29272.56298828125 
[2025-03-02 19:55:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.10162612795829773 norm:0.00014346843818202615 max memory_allocated 29272.56298828125 
[2025-03-02 19:55:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.10154140740633011 norm:0.00012985646026208997 max memory_allocated 29272.56298828125 
[2025-03-02 19:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.10149328410625458 norm:0.00012305707787163556 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.10145603120326996 norm:0.00011646587518043816 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.10141195356845856 norm:0.00011189765064045787 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.10139870643615723 norm:0.00010977278725476936 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:04 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.10137834399938583 norm:0.00010744996689027175 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:54 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.10136077553033829 norm:0.00010534487955737859 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:43 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.10135608911514282 norm:0.0001044456148520112 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:32 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.10134591907262802 norm:0.00010307693446520716 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.10133834183216095 norm:0.00010312178346794099 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.10132841765880585 norm:0.0001031840147334151 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.10131794959306717 norm:0.00010251571802655235 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:48 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.10132033377885818 norm:0.00010329637734685093 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.11959008872509003 norm:0.0011039554374292493 max memory_allocated 29272.75048828125 
[2025-03-02 20:07:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.1176251694560051 norm:0.0004906209069304168 max memory_allocated 29272.75048828125 
[2025-03-02 20:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.1161186471581459 norm:0.00030573512776754797 max memory_allocated 29272.75048828125 
[2025-03-02 20:09:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.11468645930290222 norm:0.0002164049947168678 max memory_allocated 29272.75048828125 
[2025-03-02 20:10:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.11418625712394714 norm:0.00017349114932585508 max memory_allocated 29272.75048828125 
[2025-03-02 20:11:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.11400880664587021 norm:0.00014975226076785475 max memory_allocated 29272.75048828125 
[2025-03-02 20:11:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.11390465497970581 norm:0.00013359914009924978 max memory_allocated 29272.75048828125 
[2025-03-02 20:12:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.11383485049009323 norm:0.00012370938202366233 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.11377876996994019 norm:0.00011628416541498154 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.1137377917766571 norm:0.00011270953109487891 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:08 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.11370508372783661 norm:0.00010921667126240209 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.11369332671165466 norm:0.00010625655704643577 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:46 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.1136777251958847 norm:0.0001054405584000051 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:35 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.11366904526948929 norm:0.00010529740393394604 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:24 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.11365772038698196 norm:0.00010379108425695449 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.11364731192588806 norm:0.00010269613267155364 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.11365209519863129 norm:0.0001027896796585992 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.1136406809091568 norm:0.00010196209768764675 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.11363990604877472 norm:0.00010211711924057454 max memory_allocated 29272.75048828125 
[2025-03-02 20:22:30 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.11364191770553589 norm:0.00010269138147123158 max memory_allocated 29272.75048828125 
[2025-03-02 20:22:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:23:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.13353140652179718 norm:0.0008248445228673518 max memory_allocated 29272.93798828125 
[2025-03-02 20:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.1315830945968628 norm:0.0004225401789881289 max memory_allocated 29272.93798828125 
[2025-03-02 20:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.13002459704875946 norm:0.0002853531623259187 max memory_allocated 29272.93798828125 
[2025-03-02 20:26:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.1286206990480423 norm:0.0002194445551140234 max memory_allocated 29272.93798828125 
[2025-03-02 20:26:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.12817339599132538 norm:0.0001890702551463619 max memory_allocated 29272.93798828125 
[2025-03-02 20:27:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.12798534333705902 norm:0.00017184013267979026 max memory_allocated 29272.93798828125 
[2025-03-02 20:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.12784697115421295 norm:0.00015830178745090961 max memory_allocated 29272.93798828125 
[2025-03-02 20:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.1277286857366562 norm:0.00014821969671174884 max memory_allocated 29272.93798828125 
[2025-03-02 20:30:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.12764960527420044 norm:0.00014145500608719885 max memory_allocated 29272.93798828125 
[2025-03-02 20:30:59 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.12757843732833862 norm:0.00013454256986733526 max memory_allocated 29272.93798828125 
[2025-03-02 20:31:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.12753532826900482 norm:0.00013307962217368186 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.12751075625419617 norm:0.0001350773818558082 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.12747818231582642 norm:0.00013687534374184906 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.12746334075927734 norm:0.00013228371972218156 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.12744230031967163 norm:0.0001330392697127536 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.1274365931749344 norm:0.00013569602742791176 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.1274593621492386 norm:0.00014267575170379132 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.12745696306228638 norm:0.00014294523862190545 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.12743104994297028 norm:0.0001417945750290528 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.12740366160869598 norm:0.00014152923540677875 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:40:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.148413747549057 norm:0.0010932967998087406 max memory_allocated 29273.12548828125 
[2025-03-02 20:41:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.14656603336334229 norm:0.0005510352784767747 max memory_allocated 29273.12548828125 
[2025-03-02 20:41:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.1449333280324936 norm:0.0003823331499006599 max memory_allocated 29273.12548828125 
[2025-03-02 20:42:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.14342094957828522 norm:0.00031439034501090646 max memory_allocated 29273.12548828125 
[2025-03-02 20:43:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.14295420050621033 norm:0.0002727678220253438 max memory_allocated 29273.12548828125 
[2025-03-02 20:44:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.14279469847679138 norm:0.00024046246835496277 max memory_allocated 29273.12548828125 
[2025-03-02 20:45:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.14267247915267944 norm:0.00022938572510611266 max memory_allocated 29273.12548828125 
[2025-03-02 20:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.1425960212945938 norm:0.0002089712070301175 max memory_allocated 29273.12548828125 
[2025-03-02 20:46:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.14254255592823029 norm:0.00020301059703342617 max memory_allocated 29273.12548828125 
[2025-03-02 20:47:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.14250007271766663 norm:0.00018934541731141508 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.1424727588891983 norm:0.00019013494602404535 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:17 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.14245827496051788 norm:0.00019668787717819214 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:06 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.14244520664215088 norm:0.00018128383089788258 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:56 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.1424265056848526 norm:0.000185165336006321 max memory_allocated 29273.12548828125 
[2025-03-02 20:51:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.1423974335193634 norm:0.00017860755906440318 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.1423913836479187 norm:0.00017508062592241913 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:23 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.14239181578159332 norm:0.00018311616440769285 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.1423853635787964 norm:0.0001778664591256529 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.14237745106220245 norm:0.0001727493799990043 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.14237001538276672 norm:0.00016561786469537765 max memory_allocated 29273.12548828125 
[2025-03-02 20:56:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 20:56:57 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.16417959332466125 norm:0.0015686883125454187 max memory_allocated 29273.31298828125 
[2025-03-02 20:57:46 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.16197536885738373 norm:0.0007962383679114282 max memory_allocated 29273.31298828125 
[2025-03-02 20:58:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.16007234156131744 norm:0.0004901902284473181 max memory_allocated 29273.31298828125 
[2025-03-02 20:59:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.15848422050476074 norm:0.000334073236444965 max memory_allocated 29273.31298828125 
[2025-03-02 21:00:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.15806889533996582 norm:0.00025252398336306214 max memory_allocated 29273.31298828125 
[2025-03-02 21:01:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.15788455307483673 norm:0.00020612726802937686 max memory_allocated 29273.31298828125 
[2025-03-02 21:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.1577828973531723 norm:0.00017761897470336407 max memory_allocated 29273.31298828125 
[2025-03-02 21:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.1577092707157135 norm:0.00015761835675220937 max memory_allocated 29273.31298828125 
[2025-03-02 21:03:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.1576765775680542 norm:0.0001474543532822281 max memory_allocated 29273.31298828125 
[2025-03-02 21:04:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.15763956308364868 norm:0.00013856209989171475 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.15760675072669983 norm:0.00013282451254781336 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:58 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.15758389234542847 norm:0.00012803930439986289 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.15757834911346436 norm:0.00012574400170706213 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.15755732357501984 norm:0.00012309852172620595 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:25 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.15754233300685883 norm:0.000123107063700445 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.15753068029880524 norm:0.0001215750235132873 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.15751975774765015 norm:0.00012147475354140624 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.15751783549785614 norm:0.00012153889110777527 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.1575099527835846 norm:0.00012093297846149653 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.1575036644935608 norm:0.00012074736878275871 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:13:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.18147604167461395 norm:0.0014802527148276567 max memory_allocated 29273.50048828125 
[2025-03-02 21:14:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.17912662029266357 norm:0.000734739180188626 max memory_allocated 29273.50048828125 
[2025-03-02 21:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.1770484894514084 norm:0.00045409740414470434 max memory_allocated 29273.50048828125 
[2025-03-02 21:16:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.17554496228694916 norm:0.00032055642805062234 max memory_allocated 29273.50048828125 
[2025-03-02 21:16:54 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.17516785860061646 norm:0.0002537718683015555 max memory_allocated 29273.50048828125 
[2025-03-02 21:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.1750047355890274 norm:0.00021588629169855267 max memory_allocated 29273.50048828125 
[2025-03-02 21:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.1748712956905365 norm:0.00019157654605805874 max memory_allocated 29273.50048828125 
[2025-03-02 21:19:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.17479632794857025 norm:0.00018017340335063636 max memory_allocated 29273.50048828125 
[2025-03-02 21:20:11 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.17472533881664276 norm:0.00017040238890331239 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:00 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.17467328906059265 norm:0.00016030801634769887 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:49 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.17461925745010376 norm:0.00015687578707002103 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.17458496987819672 norm:0.00015830493066459894 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.17456431686878204 norm:0.00016215568757615983 max memory_allocated 29273.50048828125 
[2025-03-02 21:24:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.1745290458202362 norm:0.0001559235533932224 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.17449931800365448 norm:0.00015163158241193742 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.1744832992553711 norm:0.00015402064309455454 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:44 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.17447055876255035 norm:0.00015068583888933063 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.17447200417518616 norm:0.00015073156100697815 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:23 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.17447035014629364 norm:0.0001514814794063568 max memory_allocated 29273.50048828125 
[2025-03-02 21:29:12 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.17445623874664307 norm:0.0001520125224487856 max memory_allocated 29273.50048828125 
[2025-03-02 21:29:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:30:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.2005091905593872 norm:0.0017822207883000374 max memory_allocated 29273.68798828125 
[2025-03-02 21:31:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.19783805310726166 norm:0.0008503365679644048 max memory_allocated 29273.68798828125 
[2025-03-02 21:31:57 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.1954984962940216 norm:0.0005084004951640964 max memory_allocated 29273.68798828125 
[2025-03-02 21:32:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.19381985068321228 norm:0.0003452383098192513 max memory_allocated 29273.68798828125 
[2025-03-02 21:33:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.19340702891349792 norm:0.0002630862290970981 max memory_allocated 29273.68798828125 
[2025-03-02 21:34:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.1932239532470703 norm:0.00021619406470563263 max memory_allocated 29273.68798828125 
[2025-03-02 21:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.19311533868312836 norm:0.00019279065600130707 max memory_allocated 29273.68798828125 
[2025-03-02 21:36:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.1930379420518875 norm:0.00017751927953213453 max memory_allocated 29273.68798828125 
[2025-03-02 21:36:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.19298085570335388 norm:0.00016485706146340817 max memory_allocated 29273.68798828125 
[2025-03-02 21:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.19294384121894836 norm:0.00015656613686587662 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.1929207593202591 norm:0.00015087227802723646 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.19289623200893402 norm:0.00014701140753459185 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.19288168847560883 norm:0.00014359345368575305 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.19286638498306274 norm:0.00014272106636781245 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.1928558498620987 norm:0.00014114445366431028 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.19285044074058533 norm:0.0001407871168339625 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:24 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.19284041225910187 norm:0.00013940094504505396 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:13 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.1928437054157257 norm:0.00013968539133202285 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:02 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.19282302260398865 norm:0.00013791074161417782 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.19282104074954987 norm:0.00013795409176964313 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:46:58 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.2195391058921814 norm:0.0021436193492263556 max memory_allocated 29273.87548828125 
[2025-03-02 21:47:48 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.21696215867996216 norm:0.0010520622599869967 max memory_allocated 29273.87548828125 
[2025-03-02 21:48:37 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.21456511318683624 norm:0.0006328088347800076 max memory_allocated 29273.87548828125 
[2025-03-02 21:49:26 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.21287637948989868 norm:0.0004290858341846615 max memory_allocated 29273.87548828125 
[2025-03-02 21:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.21250243484973907 norm:0.0003216381592210382 max memory_allocated 29273.87548828125 
[2025-03-02 21:51:04 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.21234683692455292 norm:0.00026077424990944564 max memory_allocated 29273.87548828125 
[2025-03-02 21:51:53 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.2122478485107422 norm:0.00022334817913360894 max memory_allocated 29273.87548828125 
[2025-03-02 21:52:42 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.21217402815818787 norm:0.00020092523482162505 max memory_allocated 29273.87548828125 
[2025-03-02 21:53:31 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.2121143788099289 norm:0.00018524534243624657 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:20 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.2120712846517563 norm:0.00017473215120844543 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:09 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.21203579008579254 norm:0.00016549286374356598 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:58 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.2120034247636795 norm:0.00015957946015987545 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:47 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.21197843551635742 norm:0.0001574934576638043 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.21196934580802917 norm:0.0001546982821309939 max memory_allocated 29273.87548828125 
[2025-03-02 21:58:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.21194887161254883 norm:0.00015080298180691898 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:14 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.21193356812000275 norm:0.00015068303036969155 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:03 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.21192216873168945 norm:0.00015035949763841927 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:52 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.21191783249378204 norm:0.00015106557111721486 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:42 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.2119087278842926 norm:0.00014740067126695067 max memory_allocated 29273.87548828125 
[2025-03-02 22:02:31 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.21189366281032562 norm:0.0001502910308772698 max memory_allocated 29273.87548828125 
[2025-03-02 22:02:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:03:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.2430078089237213 norm:0.001253437832929194 max memory_allocated 29274.06298828125 
[2025-03-02 22:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.23991551995277405 norm:0.0006736207869835198 max memory_allocated 29274.06298828125 
[2025-03-02 22:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.2370370328426361 norm:0.00044357357546687126 max memory_allocated 29274.06298828125 
[2025-03-02 22:06:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.23530463874340057 norm:0.0003138676402159035 max memory_allocated 29274.06298828125 
[2025-03-02 22:06:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.23486581444740295 norm:0.00025959929917007685 max memory_allocated 29274.06298828125 
[2025-03-02 22:07:43 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.2346220314502716 norm:0.00023144295846577734 max memory_allocated 29274.06298828125 
[2025-03-02 22:08:32 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.23447735607624054 norm:0.00021300003572832793 max memory_allocated 29274.06298828125 
[2025-03-02 22:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.2343849539756775 norm:0.00019709361367858946 max memory_allocated 29274.06298828125 
[2025-03-02 22:10:11 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.23427270352840424 norm:0.00018516874115448445 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.23421236872673035 norm:0.00018155339057557285 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.23416338860988617 norm:0.00017314759315922856 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:38 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.23411698639392853 norm:0.00016904193034861237 max memory_allocated 29274.06298828125 
[2025-03-02 22:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.234100803732872 norm:0.00016646250151097775 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:16 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.23409248888492584 norm:0.00016298715490847826 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.2340514361858368 norm:0.0001652106293477118 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.23403838276863098 norm:0.00016692187637090683 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:43 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.23406508564949036 norm:0.00016651159967295825 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:33 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.2340727150440216 norm:0.00017686064529698342 max memory_allocated 29274.06298828125 
[2025-03-02 22:18:22 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.234055757522583 norm:0.00017050451424438506 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:11 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.2340468168258667 norm:0.0001671751233516261 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.26835301518440247 norm:0.0016197863733395934 max memory_allocated 29274.25048828125 
[2025-03-02 22:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.2652146816253662 norm:0.0007951287552714348 max memory_allocated 29274.25048828125 
[2025-03-02 22:21:56 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.2622533440589905 norm:0.0004972121096216142 max memory_allocated 29274.25048828125 
[2025-03-02 22:22:45 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.2607145309448242 norm:0.0003558181633707136 max memory_allocated 29274.25048828125 
[2025-03-02 22:23:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.26036038994789124 norm:0.0002841387176886201 max memory_allocated 29274.25048828125 
[2025-03-02 22:24:23 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.26014941930770874 norm:0.00024221721105277538 max memory_allocated 29274.25048828125 
[2025-03-02 22:25:12 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.26000741124153137 norm:0.00022022469784133136 max memory_allocated 29274.25048828125 
[2025-03-02 22:26:01 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.25990530848503113 norm:0.0002069794136332348 max memory_allocated 29274.25048828125 
[2025-03-02 22:26:50 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.2598285377025604 norm:0.00019756596884690225 max memory_allocated 29274.25048828125 
[2025-03-02 22:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.2597598433494568 norm:0.00019031007832381874 max memory_allocated 29274.25048828125 
[2025-03-02 22:28:28 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.25970736145973206 norm:0.00018480073777027428 max memory_allocated 29274.25048828125 
[2025-03-02 22:29:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.25965985655784607 norm:0.0001822647318476811 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:06 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.2596341073513031 norm:0.00018233298033010215 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:56 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.259577214717865 norm:0.00017960452532861382 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:45 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.2595595121383667 norm:0.00018103132606483996 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.25953665375709534 norm:0.00017925632710102946 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:23 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.259533554315567 norm:0.0001785231870599091 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.2595251798629761 norm:0.00017604992899578065 max memory_allocated 29274.25048828125 
[2025-03-02 22:35:01 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.2595040202140808 norm:0.0001760382147040218 max memory_allocated 29274.25048828125 
[2025-03-02 22:35:50 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.25948986411094666 norm:0.00017607490008231252 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:36:57 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.2988866865634918 norm:0.002984840190038085 max memory_allocated 29274.43798828125 
[2025-03-02 22:37:46 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.2942877411842346 norm:0.0015508203068748116 max memory_allocated 29274.43798828125 
[2025-03-02 22:38:36 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.2904284596443176 norm:0.0009503165492787957 max memory_allocated 29274.43798828125 
[2025-03-02 22:39:25 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.2887048125267029 norm:0.0006573398131877184 max memory_allocated 29274.43798828125 
[2025-03-02 22:40:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.2881642282009125 norm:0.00048737754696048796 max memory_allocated 29274.43798828125 
[2025-03-02 22:41:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.2878890037536621 norm:0.00039019426913000643 max memory_allocated 29274.43798828125 
[2025-03-02 22:41:52 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.2876453995704651 norm:0.0003308305749669671 max memory_allocated 29274.43798828125 
[2025-03-02 22:42:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.2874623239040375 norm:0.0003010132350027561 max memory_allocated 29274.43798828125 
[2025-03-02 22:43:30 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.28733891248703003 norm:0.0002742720826063305 max memory_allocated 29274.43798828125 
[2025-03-02 22:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.28721854090690613 norm:0.00025728216860443354 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.28714868426322937 norm:0.0002411041787127033 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:57 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.28711745142936707 norm:0.00023713434347882867 max memory_allocated 29274.43798828125 
[2025-03-02 22:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.2870677411556244 norm:0.0002351303119212389 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:35 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.2870359718799591 norm:0.00022988989076111466 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.28699707984924316 norm:0.00022859845194034278 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:13 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.2869885265827179 norm:0.00022550096036866307 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.2869577407836914 norm:0.00022789435752201825 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.28693121671676636 norm:0.00022265657025855035 max memory_allocated 29274.43798828125 
[2025-03-02 22:51:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.2869392931461334 norm:0.00022705760784447193 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:30 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.28695082664489746 norm:0.0002248208475066349 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 22:52:48 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 22:53:37 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.3307461440563202 norm:0.004559256136417389 max memory_allocated 29274.77001953125 
[2025-03-02 22:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.32605257630348206 norm:0.0031946413218975067 max memory_allocated 29274.77001953125 
[2025-03-02 22:55:16 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.3220229744911194 norm:0.0030974384862929583 max memory_allocated 29274.77001953125 
[2025-03-02 22:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.3201709985733032 norm:0.002720119198784232 max memory_allocated 29274.77001953125 
[2025-03-02 22:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.3197154998779297 norm:0.002300693653523922 max memory_allocated 29274.77001953125 
[2025-03-02 22:57:43 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.31918981671333313 norm:0.0018684153910726309 max memory_allocated 29274.77001953125 
[2025-03-02 22:58:33 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.318840891122818 norm:0.0016645166324451566 max memory_allocated 29274.77001953125 
[2025-03-02 22:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.3186492621898651 norm:0.001639039721339941 max memory_allocated 29274.77001953125 
[2025-03-02 23:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.3186555504798889 norm:0.0018784129060804844 max memory_allocated 29274.77001953125 
[2025-03-02 23:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.3186449408531189 norm:0.0017981247510761023 max memory_allocated 29274.77001953125 
[2025-03-02 23:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.31847333908081055 norm:0.0017163569573312998 max memory_allocated 29274.77001953125 
[2025-03-02 23:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.31825530529022217 norm:0.0013945347163826227 max memory_allocated 29274.77001953125 
[2025-03-02 23:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.31817030906677246 norm:0.0013318440178409219 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.3180830478668213 norm:0.001242874190211296 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:07 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.3180466294288635 norm:0.0012495547998696566 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:56 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.3179907202720642 norm:0.0012153974967077374 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.31797242164611816 norm:0.001231494708918035 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:35 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.31796014308929443 norm:0.00125087087508291 max memory_allocated 29274.77001953125 
[2025-03-02 23:08:24 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.3180011808872223 norm:0.0013239574618637562 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:13 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.3180348575115204 norm:0.0013737771660089493 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:09:31 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:10:21 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.37586402893066406 norm:0.006048213690519333 max memory_allocated 29274.95751953125 
[2025-03-02 23:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.36760932207107544 norm:0.006156650837510824 max memory_allocated 29274.95751953125 
[2025-03-02 23:11:59 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.3619062304496765 norm:0.006297249812632799 max memory_allocated 29274.95751953125 
[2025-03-02 23:12:48 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.3596284091472626 norm:0.006089971400797367 max memory_allocated 29274.95751953125 
[2025-03-02 23:13:38 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.35889744758605957 norm:0.005706567782908678 max memory_allocated 29274.95751953125 
[2025-03-02 23:14:27 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.3582908511161804 norm:0.005196987651288509 max memory_allocated 29274.95751953125 
[2025-03-02 23:15:16 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.3578835725784302 norm:0.004989036358892918 max memory_allocated 29274.95751953125 
[2025-03-02 23:16:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.35748082399368286 norm:0.004577064886689186 max memory_allocated 29274.95751953125 
[2025-03-02 23:16:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.3572525084018707 norm:0.004455301444977522 max memory_allocated 29274.95751953125 
[2025-03-02 23:17:44 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.3570314049720764 norm:0.00399392144754529 max memory_allocated 29274.95751953125 
[2025-03-02 23:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.3569779098033905 norm:0.004061310552060604 max memory_allocated 29274.95751953125 
[2025-03-02 23:19:22 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.35689741373062134 norm:0.003763884073123336 max memory_allocated 29274.95751953125 
[2025-03-02 23:20:12 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.35685157775878906 norm:0.003806193359196186 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.3568089008331299 norm:0.0034580726642161608 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:50 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.35679957270622253 norm:0.0037316407542675734 max memory_allocated 29274.95751953125 
[2025-03-02 23:22:39 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.356723815202713 norm:0.0033751241862773895 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:29 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.3567850589752197 norm:0.003785166423767805 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:18 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.3566829562187195 norm:0.0032716719433665276 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:07 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.35670652985572815 norm:0.0034933716524392366 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.35665827989578247 norm:0.003071766346693039 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:26:14 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:27:04 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.5140440464019775 norm:0.03137870132923126 max memory_allocated 29275.14501953125 
[2025-03-02 23:27:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.4857683777809143 norm:0.02398671582341194 max memory_allocated 29275.14501953125 
[2025-03-02 23:28:42 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.46860599517822266 norm:0.018656039610505104 max memory_allocated 29275.14501953125 
[2025-03-02 23:29:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.4600770175457001 norm:0.016993843019008636 max memory_allocated 29275.14501953125 
[2025-03-02 23:30:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.45510929822921753 norm:0.013088474050164223 max memory_allocated 29275.14501953125 
[2025-03-02 23:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.4519030451774597 norm:0.010979272425174713 max memory_allocated 29275.14501953125 
[2025-03-02 23:31:59 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.4495198726654053 norm:0.00980076938867569 max memory_allocated 29275.14501953125 
[2025-03-02 23:32:48 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.44829249382019043 norm:0.009262091480195522 max memory_allocated 29275.14501953125 
[2025-03-02 23:33:37 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.44709381461143494 norm:0.00865178368985653 max memory_allocated 29275.14501953125 
[2025-03-02 23:34:27 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.4461112320423126 norm:0.008583102375268936 max memory_allocated 29275.14501953125 
[2025-03-02 23:35:16 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.44528698921203613 norm:0.007943550124764442 max memory_allocated 29275.14501953125 
[2025-03-02 23:36:05 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.444736123085022 norm:0.0071906778030097485 max memory_allocated 29275.14501953125 
[2025-03-02 23:36:54 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.4443894624710083 norm:0.007415097672492266 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:43 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.44405847787857056 norm:0.007404351141303778 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:33 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.44368162751197815 norm:0.006805999670177698 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:22 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.44358083605766296 norm:0.006757623981684446 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.4435371160507202 norm:0.006626010872423649 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:00 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.4430862367153168 norm:0.006437650881707668 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.44299063086509705 norm:0.006186439655721188 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.44274649024009705 norm:0.005673229228705168 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:42:57 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:0.857241153717041 norm:0.04678810015320778 max memory_allocated 29275.33251953125 
[2025-03-02 23:44:35 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.7958939671516418 norm:0.026870494708418846 max memory_allocated 29275.33251953125 
[2025-03-02 23:45:25 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.7621851563453674 norm:0.02080611325800419 max memory_allocated 29275.33251953125 
[2025-03-02 23:46:14 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.7431436777114868 norm:0.017522450536489487 max memory_allocated 29275.33251953125 
[2025-03-02 23:47:03 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.7328243255615234 norm:0.016562188044190407 max memory_allocated 29275.33251953125 
[2025-03-02 23:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.7258006930351257 norm:0.015260863117873669 max memory_allocated 29275.33251953125 
[2025-03-02 23:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.720409095287323 norm:0.014483053237199783 max memory_allocated 29275.33251953125 
[2025-03-02 23:49:31 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.7168137431144714 norm:0.01416984386742115 max memory_allocated 29275.33251953125 
[2025-03-02 23:50:20 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.7141996622085571 norm:0.013403701595962048 max memory_allocated 29275.33251953125 
[2025-03-02 23:51:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.7131245732307434 norm:0.013475082814693451 max memory_allocated 29275.33251953125 
[2025-03-02 23:51:59 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.7122363448143005 norm:0.014757342636585236 max memory_allocated 29275.33251953125 
[2025-03-02 23:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.7108661532402039 norm:0.014173349365592003 max memory_allocated 29275.33251953125 
[2025-03-02 23:53:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.7099159359931946 norm:0.013977489434182644 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.7086904644966125 norm:0.013367487117648125 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.7079718708992004 norm:0.01345267053693533 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:05 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.7069991230964661 norm:0.013155996799468994 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.7058123350143433 norm:0.013251722790300846 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:43 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.705312967300415 norm:0.012963948771357536 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:33 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.7043334245681763 norm:0.012772399932146072 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.7037071585655212 norm:0.0127831120043993 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:36 root] (main_calib_config2.py 372): INFO 40026.01004123688
[2025-03-02 23:59:45 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:01:41 root] (main_calib_config2.py 159): INFO wikitext2 : 5.194966793060303
[2025-03-03 00:01:41 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:04:40 root] (main_calib_config2.py 159): INFO c4 : 6.729860305786133
[2025-03-03 02:04:24 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.194966793060303, 'c4': 6.729860305786133, 'results': {'piqa': {'acc': 0.7872687704026116, 'acc_stderr': 0.009548223123047343, 'acc_norm': 0.7883569096844396, 'acc_norm_stderr': 0.009530351270479393}, 'boolq': {'acc': 0.6782874617737003, 'acc_stderr': 0.008170213921675268}, 'hellaswag': {'acc': 0.5836486755626369, 'acc_stderr': 0.004919457850104235, 'acc_norm': 0.7552280422226648, 'acc_norm_stderr': 0.0042907321146620206}, 'arc_challenge': {'acc': 0.42150170648464164, 'acc_stderr': 0.014430197069326023, 'acc_norm': 0.42662116040955633, 'acc_norm_stderr': 0.014453185592920293}, 'arc_easy': {'acc': 0.7276936026936027, 'acc_stderr': 0.009134218447652682, 'acc_norm': 0.5862794612794613, 'acc_norm_stderr': 0.010105878530238137}, 'winogrande': {'acc': 0.6882399368587214, 'acc_stderr': 0.013018571197638551}}, 'versions': {'piqa': 0, 'boolq': 1, 'hellaswag': 0, 'arc_challenge': 0, 'arc_easy': 0, 'winogrande': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
