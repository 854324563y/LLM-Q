[2025-02-28 13:17:24 root] (main_calib_config2.py 284): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/Llama-2-7b-hf_0.45', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.45.pkl', scale_calibration=True, compensation_calibration=True)
[2025-02-28 13:20:27 root] (main_calib_config2.py 351): INFO === start quantization ===
[2025-02-28 13:20:27 root] (main_calib_config2.py 357): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-02-28 13:20:28 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.45.pkl
[2025-02-28 13:20:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-02-28 13:20:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:21:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.015487458556890488 norm:0.014768803492188454 max memory_allocated 22562.10693359375 
[2025-02-28 13:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.008919741958379745 norm:0.008645718917250633 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.006339383777230978 norm:0.005565362051129341 max memory_allocated 22562.10693359375 
[2025-02-28 13:22:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.005455925129354 norm:0.004637577570974827 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:20 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.005194414407014847 norm:0.0039571719244122505 max memory_allocated 22562.10693359375 
[2025-02-28 13:23:54 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.004937513265758753 norm:0.003233271883800626 max memory_allocated 22562.10693359375 
[2025-02-28 13:24:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.004840109962970018 norm:0.0028362972661852837 max memory_allocated 22562.10693359375 
[2025-02-28 13:25:01 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.00475669652223587 norm:0.0026979988906532526 max memory_allocated 22562.10693359375 
[2025-02-28 13:25:35 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.004752895794808865 norm:0.0026571096386760473 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.004744585603475571 norm:0.0027579832822084427 max memory_allocated 22562.10693359375 
[2025-02-28 13:26:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.004582670517265797 norm:0.0017069864552468061 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.004509070888161659 norm:0.0016042235074564815 max memory_allocated 22562.10693359375 
[2025-02-28 13:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0044722966849803925 norm:0.001745323184877634 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:23 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.004430761095136404 norm:0.0021423459984362125 max memory_allocated 22562.10693359375 
[2025-02-28 13:28:57 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.00443930784240365 norm:0.0018446843605488539 max memory_allocated 22562.10693359375 
[2025-02-28 13:29:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.004420048091560602 norm:0.0012892932863906026 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:04 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.004426244646310806 norm:0.0015855692327022552 max memory_allocated 22562.10693359375 
[2025-02-28 13:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.004446528851985931 norm:0.00291295163333416 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:12 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.004460368771106005 norm:0.0016427277587354183 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.004416829906404018 norm:0.0018467784393578768 max memory_allocated 22562.10693359375 
[2025-02-28 13:31:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-02-28 13:31:58 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:32:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.09706191718578339 norm:0.049054864794015884 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:05 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.07707200944423676 norm:0.04312378913164139 max memory_allocated 22562.27880859375 
[2025-02-28 13:33:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.06773648411035538 norm:0.03256076201796532 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.06551676988601685 norm:0.031120900064706802 max memory_allocated 22562.27880859375 
[2025-02-28 13:34:46 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.06537123024463654 norm:0.029206931591033936 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.06438920646905899 norm:0.02555384859442711 max memory_allocated 22562.27880859375 
[2025-02-28 13:35:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.06474003195762634 norm:0.02444564737379551 max memory_allocated 22562.27880859375 
[2025-02-28 13:36:27 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.06464602053165436 norm:0.021508976817131042 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.06457573175430298 norm:0.021827347576618195 max memory_allocated 22562.27880859375 
[2025-02-28 13:37:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.06466139853000641 norm:0.021991275250911713 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.06466112285852432 norm:0.020764827728271484 max memory_allocated 22562.27880859375 
[2025-02-28 13:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.06446539610624313 norm:0.020843761041760445 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.06393314898014069 norm:0.01982843689620495 max memory_allocated 22562.27880859375 
[2025-02-28 13:39:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.0638536885380745 norm:0.019882576540112495 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:23 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.06334394216537476 norm:0.019068831577897072 max memory_allocated 22562.27880859375 
[2025-02-28 13:40:57 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.06346143037080765 norm:0.018824702128767967 max memory_allocated 22562.27880859375 
[2025-02-28 13:41:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.06325343251228333 norm:0.01804790273308754 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.06353665888309479 norm:0.018106896430253983 max memory_allocated 22562.27880859375 
[2025-02-28 13:42:38 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.06297396868467331 norm:0.017375841736793518 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.06400962173938751 norm:0.01809268817305565 max memory_allocated 22562.27880859375 
[2025-02-28 13:43:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-02-28 13:43:24 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 13:43:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.06629009544849396 norm:0.017440786585211754 max memory_allocated 22562.45068359375 
[2025-02-28 13:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.053894706070423126 norm:0.01065874844789505 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.04879208654165268 norm:0.007412363775074482 max memory_allocated 22562.45068359375 
[2025-02-28 13:45:39 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.04682996869087219 norm:0.005697916727513075 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.04578879475593567 norm:0.004577953368425369 max memory_allocated 22562.45068359375 
[2025-02-28 13:46:47 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.045059315860271454 norm:0.00375157967209816 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:20 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.04468812420964241 norm:0.003089575795456767 max memory_allocated 22562.45068359375 
[2025-02-28 13:47:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.04445172846317291 norm:0.002542187226936221 max memory_allocated 22562.45068359375 
[2025-02-28 13:48:28 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.04427586495876312 norm:0.0020365051459521055 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:02 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.044129952788352966 norm:0.0016734156524762511 max memory_allocated 22562.45068359375 
[2025-02-28 13:49:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.04409376531839371 norm:0.0015542390756309032 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.04402477294206619 norm:0.0014524910366162658 max memory_allocated 22562.45068359375 
[2025-02-28 13:50:43 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.04398175701498985 norm:0.0012757204240188003 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.04395538941025734 norm:0.0011593351373448968 max memory_allocated 22562.45068359375 
[2025-02-28 13:51:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.04391568526625633 norm:0.0011557384859770536 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.043909646570682526 norm:0.0011057434603571892 max memory_allocated 22562.45068359375 
[2025-02-28 13:52:58 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.04389432072639465 norm:0.0010847058147192001 max memory_allocated 22562.45068359375 
[2025-02-28 13:53:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.043916381895542145 norm:0.001117050414904952 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.04386870563030243 norm:0.0010928288102149963 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:40 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.04385973513126373 norm:0.0009712036116980016 max memory_allocated 22562.45068359375 
[2025-02-28 13:54:49 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-02-28 13:55:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.07104671746492386 norm:0.00616845116019249 max memory_allocated 22562.50732421875 
[2025-02-28 13:56:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.057420726865530014 norm:0.0017497374210506678 max memory_allocated 22562.50732421875 
[2025-02-28 13:56:33 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.05143249034881592 norm:0.0009754775674082339 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.04901669919490814 norm:0.0005532780196517706 max memory_allocated 22562.50732421875 
[2025-02-28 13:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.047943972051143646 norm:0.0004787264624610543 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:15 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.04732436686754227 norm:0.00038461724761873484 max memory_allocated 22562.50732421875 
[2025-02-28 13:58:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.04708478972315788 norm:0.000356432021362707 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:22 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.047045763581991196 norm:0.00033553055254742503 max memory_allocated 22562.50732421875 
[2025-02-28 13:59:56 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.046950094401836395 norm:0.0003120078472420573 max memory_allocated 22562.50732421875 
[2025-02-28 14:00:29 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.04689689725637436 norm:0.0002901917905546725 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.04681047052145004 norm:0.0002759789931587875 max memory_allocated 22562.50732421875 
[2025-02-28 14:01:37 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.046827614307403564 norm:0.00028388513601385057 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:11 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.04681029170751572 norm:0.000289755203993991 max memory_allocated 22562.50732421875 
[2025-02-28 14:02:44 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.046838365495204926 norm:0.0002739496121648699 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.04689590632915497 norm:0.00029805771191604435 max memory_allocated 22562.50732421875 
[2025-02-28 14:03:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.046867791563272476 norm:0.00025776505935937166 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.046859703958034515 norm:0.000264384550973773 max memory_allocated 22562.50732421875 
[2025-02-28 14:04:59 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.046805329620838165 norm:0.0002591786324046552 max memory_allocated 22562.50732421875 
[2025-02-28 14:05:33 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.046788230538368225 norm:0.00026818635524250567 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.04678208380937576 norm:0.0002725202648434788 max memory_allocated 22562.50732421875 
[2025-02-28 14:06:16 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-02-28 14:06:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.07904700189828873 norm:0.0035190945491194725 max memory_allocated 22562.67919921875 
[2025-02-28 14:07:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.06322859972715378 norm:0.001333840424194932 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.05551304668188095 norm:0.0007095304317772388 max memory_allocated 22562.67919921875 
[2025-02-28 14:08:35 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.05276241526007652 norm:0.00042683922220021486 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.05139731988310814 norm:0.00033207936212420464 max memory_allocated 22562.67919921875 
[2025-02-28 14:09:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.050757844001054764 norm:0.0002885526046156883 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.050573334097862244 norm:0.00026676588458940387 max memory_allocated 22562.67919921875 
[2025-02-28 14:10:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.050380103290081024 norm:0.0002640708698891103 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:23 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.050315044820308685 norm:0.00025777798146009445 max memory_allocated 22562.67919921875 
[2025-02-28 14:11:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.05023850128054619 norm:0.00024349808518309146 max memory_allocated 22562.67919921875 
[2025-02-28 14:12:31 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.05023830384016037 norm:0.00024403737916145474 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.05013740062713623 norm:0.00022446262300945818 max memory_allocated 22562.67919921875 
[2025-02-28 14:13:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.05009651184082031 norm:0.00022513106523547322 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.05011861398816109 norm:0.00022453318524640054 max memory_allocated 22562.67919921875 
[2025-02-28 14:14:46 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.05009177327156067 norm:0.000229111043154262 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.05012393370270729 norm:0.00023751764092594385 max memory_allocated 22562.67919921875 
[2025-02-28 14:15:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.050094641745090485 norm:0.0002378752687945962 max memory_allocated 22562.67919921875 
[2025-02-28 14:16:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.050087012350559235 norm:0.00023804965894669294 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.05008096992969513 norm:0.00023783095821272582 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:34 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.05007650703191757 norm:0.00023045437410473824 max memory_allocated 22562.67919921875 
[2025-02-28 14:17:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-02-28 14:18:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.07781729847192764 norm:0.003191998926922679 max memory_allocated 22562.85107421875 
[2025-02-28 14:18:54 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.06482291221618652 norm:0.001225433312356472 max memory_allocated 22562.85107421875 
[2025-02-28 14:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.05790122225880623 norm:0.0006679969374090433 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.05531670153141022 norm:0.00042992725502699614 max memory_allocated 22562.85107421875 
[2025-02-28 14:20:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.05411801487207413 norm:0.0003230629663448781 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.05358994007110596 norm:0.0002882758853957057 max memory_allocated 22562.85107421875 
[2025-02-28 14:21:42 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.05337963253259659 norm:0.00027150544337928295 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.05320306867361069 norm:0.00023543027054984123 max memory_allocated 22562.85107421875 
[2025-02-28 14:22:50 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.05309511721134186 norm:0.0002328808041056618 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.05306326970458031 norm:0.00023032570607028902 max memory_allocated 22562.85107421875 
[2025-02-28 14:23:57 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.053009822964668274 norm:0.0002255087165394798 max memory_allocated 22562.85107421875 
[2025-02-28 14:24:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.05297467112541199 norm:0.0002125450992025435 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:05 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.052953898906707764 norm:0.00020780730119440705 max memory_allocated 22562.85107421875 
[2025-02-28 14:25:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.05292868986725807 norm:0.00020386707910802215 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.052956722676754 norm:0.0002214490668848157 max memory_allocated 22562.85107421875 
[2025-02-28 14:26:46 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.05294201523065567 norm:0.00021865918824914843 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.052905451506376266 norm:0.0002229287347290665 max memory_allocated 22562.85107421875 
[2025-02-28 14:27:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.05293562263250351 norm:0.0002453669148962945 max memory_allocated 22562.85107421875 
[2025-02-28 14:28:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.052888672798871994 norm:0.0002141608129022643 max memory_allocated 22562.85107421875 
[2025-02-28 14:29:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.052867740392684937 norm:0.00022339100542012602 max memory_allocated 22562.85107421875 
[2025-02-28 14:29:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-02-28 14:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.08776310086250305 norm:0.0030724983662366867 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.07217106968164444 norm:0.0013546852860599756 max memory_allocated 22563.02294921875 
[2025-02-28 14:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.06414687633514404 norm:0.0007896991446614265 max memory_allocated 22563.02294921875 
[2025-02-28 14:31:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.06098208948969841 norm:0.0005045515135861933 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.0595078244805336 norm:0.00039697150350548327 max memory_allocated 22563.02294921875 
[2025-02-28 14:32:36 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.05876819044351578 norm:0.0003188362461514771 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:10 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.05844726786017418 norm:0.00029559782706201077 max memory_allocated 22563.02294921875 
[2025-02-28 14:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.05829334259033203 norm:0.00028347811894491315 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:17 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.058150891214609146 norm:0.00028710439801216125 max memory_allocated 22563.02294921875 
[2025-02-28 14:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.0579516775906086 norm:0.00026315884315408766 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.057866111397743225 norm:0.0002674585266504437 max memory_allocated 22563.02294921875 
[2025-02-28 14:35:59 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.05777331441640854 norm:0.00026521511608734727 max memory_allocated 22563.02294921875 
[2025-02-28 14:36:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.05771932378411293 norm:0.0002654461422935128 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.0577041320502758 norm:0.000264447124209255 max memory_allocated 22563.02294921875 
[2025-02-28 14:37:40 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.05766911804676056 norm:0.000272383913397789 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.05763789638876915 norm:0.00026431228616274893 max memory_allocated 22563.02294921875 
[2025-02-28 14:38:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.05758704990148544 norm:0.00026580531266517937 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.05759282037615776 norm:0.0002708931569941342 max memory_allocated 22563.02294921875 
[2025-02-28 14:39:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.057706303894519806 norm:0.0003062527975998819 max memory_allocated 22563.02294921875 
[2025-02-28 14:40:28 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.05768520012497902 norm:0.0002957218384835869 max memory_allocated 22563.02294921875 
[2025-02-28 14:40:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-02-28 14:41:15 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.09656299650669098 norm:0.0042435587383806705 max memory_allocated 22563.19482421875 
[2025-02-28 14:41:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.07846230268478394 norm:0.001713098376058042 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.06942243874073029 norm:0.0009424025774933398 max memory_allocated 22563.19482421875 
[2025-02-28 14:42:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.06588750332593918 norm:0.0005804189131595194 max memory_allocated 22563.19482421875 
[2025-02-28 14:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.06423327326774597 norm:0.00044605217408388853 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.0635201632976532 norm:0.00037139689084142447 max memory_allocated 22563.19482421875 
[2025-02-28 14:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.06316149234771729 norm:0.0009892211528494954 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.06295192986726761 norm:0.0003113652055617422 max memory_allocated 22563.19482421875 
[2025-02-28 14:45:44 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.06275364756584167 norm:0.00029103888664394617 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.06261878460645676 norm:0.00029095885111019015 max memory_allocated 22563.19482421875 
[2025-02-28 14:46:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.06251557916402817 norm:0.0002689520479179919 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.062473028898239136 norm:0.00027107723872177303 max memory_allocated 22563.19482421875 
[2025-02-28 14:47:59 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.06252031028270721 norm:0.0002852044708561152 max memory_allocated 22563.19482421875 
[2025-02-28 14:48:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.0624709278345108 norm:0.0002709251712076366 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.06244252249598503 norm:0.00027869181940332055 max memory_allocated 22563.19482421875 
[2025-02-28 14:49:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.06239106133580208 norm:0.0002663852064870298 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.06235985457897186 norm:0.00025466617080383003 max memory_allocated 22563.19482421875 
[2025-02-28 14:50:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.06234150752425194 norm:0.00024797662626951933 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:22 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.062285587191581726 norm:0.0002457688678987324 max memory_allocated 22563.19482421875 
[2025-02-28 14:51:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.0623004175722599 norm:0.00025245078722946346 max memory_allocated 22563.19482421875 
[2025-02-28 14:52:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-02-28 14:52:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.0977318063378334 norm:0.0027195168659090996 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.08230950683355331 norm:0.0013416608562693 max memory_allocated 22563.36669921875 
[2025-02-28 14:53:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.07380816340446472 norm:0.0007738406420685351 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.07043568789958954 norm:0.0005129023338668048 max memory_allocated 22563.36669921875 
[2025-02-28 14:54:56 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.06885332614183426 norm:0.00039346152334474027 max memory_allocated 22563.36669921875 
[2025-02-28 14:55:30 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.0681193545460701 norm:0.00032751515391282737 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.06773902475833893 norm:0.00031428062357008457 max memory_allocated 22563.36669921875 
[2025-02-28 14:56:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.06753472983837128 norm:0.0002940269187092781 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.0674179419875145 norm:0.0002712535497266799 max memory_allocated 22563.36669921875 
[2025-02-28 14:57:45 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.06727724522352219 norm:0.00028149428544566035 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.06720574200153351 norm:0.0002686194784473628 max memory_allocated 22563.36669921875 
[2025-02-28 14:58:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.06716667860746384 norm:0.00025708170142024755 max memory_allocated 22563.36669921875 
[2025-02-28 14:59:26 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.06712467223405838 norm:0.00024853451759554446 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.06706328690052032 norm:0.00024684585514478385 max memory_allocated 22563.36669921875 
[2025-02-28 15:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.06702281534671783 norm:0.00024700022186152637 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.06702134013175964 norm:0.0002607064670883119 max memory_allocated 22563.36669921875 
[2025-02-28 15:01:41 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.06718284636735916 norm:0.00029538830858655274 max memory_allocated 22563.36669921875 
[2025-02-28 15:02:15 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.06713306158781052 norm:0.0002696625597309321 max memory_allocated 22563.36669921875 
[2025-02-28 15:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.0670802965760231 norm:0.00026525359135121107 max memory_allocated 22563.36669921875 
[2025-02-28 15:03:22 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.06706436723470688 norm:0.00026399336638860404 max memory_allocated 22563.36669921875 
[2025-02-28 15:03:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-02-28 15:04:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.10284996032714844 norm:0.0036415306385606527 max memory_allocated 22563.53857421875 
[2025-02-28 15:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.08665149658918381 norm:0.0013969033025205135 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.07769681513309479 norm:0.0006519095622934401 max memory_allocated 22563.53857421875 
[2025-02-28 15:05:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.07431255280971527 norm:0.00041390355909243226 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.07274861633777618 norm:0.00031186710111796856 max memory_allocated 22563.53857421875 
[2025-02-28 15:06:57 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.07200710475444794 norm:0.0002761482901405543 max memory_allocated 22563.53857421875 
[2025-02-28 15:07:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.0716220960021019 norm:0.00025986958644352853 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.0714632123708725 norm:0.00024521633167751133 max memory_allocated 22563.53857421875 
[2025-02-28 15:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.07131222635507584 norm:0.00023040610540192574 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.07120399922132492 norm:0.00023184729798231274 max memory_allocated 22563.53857421875 
[2025-02-28 15:09:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.07113990187644958 norm:0.00023874870385043323 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:19 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.0711028054356575 norm:0.0002308243711013347 max memory_allocated 22563.53857421875 
[2025-02-28 15:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.07104340195655823 norm:0.0002219458547187969 max memory_allocated 22563.53857421875 
[2025-02-28 15:11:26 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.07103601098060608 norm:0.0002232544356957078 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.07099872827529907 norm:0.00022824636835139245 max memory_allocated 22563.53857421875 
[2025-02-28 15:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.07096612453460693 norm:0.00021949973597656935 max memory_allocated 22563.53857421875 
[2025-02-28 15:13:08 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.07096658647060394 norm:0.00021873631339985877 max memory_allocated 22563.53857421875 
[2025-02-28 15:13:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.07086778432130814 norm:0.000218674773350358 max memory_allocated 22563.53857421875 
[2025-02-28 15:14:15 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.07082871347665787 norm:0.00021632648713421077 max memory_allocated 22563.53857421875 
[2025-02-28 15:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.07083796709775925 norm:0.00022514672309625894 max memory_allocated 22563.53857421875 
[2025-02-28 15:14:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-02-28 15:15:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.1021115630865097 norm:0.001773252384737134 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:09 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.08932969719171524 norm:0.0009438411216251552 max memory_allocated 22563.71044921875 
[2025-02-28 15:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.08067150413990021 norm:0.0004855153092648834 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.07731257379055023 norm:0.0003093886480201036 max memory_allocated 22563.71044921875 
[2025-02-28 15:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.07588209211826324 norm:0.0002446513681206852 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.07522350549697876 norm:0.00022005027858540416 max memory_allocated 22563.71044921875 
[2025-02-28 15:18:57 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.07494369149208069 norm:0.00021243176888674498 max memory_allocated 22563.71044921875 
[2025-02-28 15:19:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.07477226108312607 norm:0.00020363961812108755 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.074678935110569 norm:0.00019604864064604044 max memory_allocated 22563.71044921875 
[2025-02-28 15:20:39 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.0746099054813385 norm:0.0002000061795115471 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:12 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.07451070845127106 norm:0.00020092015620321035 max memory_allocated 22563.71044921875 
[2025-02-28 15:21:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.07443537563085556 norm:0.00019629414600785822 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.07437574118375778 norm:0.00019737113325390965 max memory_allocated 22563.71044921875 
[2025-02-28 15:22:53 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.07431775331497192 norm:0.00019442528719082475 max memory_allocated 22563.71044921875 
[2025-02-28 15:23:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.07431364804506302 norm:0.00019825912022497505 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:01 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.07425332814455032 norm:0.00020044932898599654 max memory_allocated 22563.71044921875 
[2025-02-28 15:24:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.07424627989530563 norm:0.0001998779334826395 max memory_allocated 22563.71044921875 
[2025-02-28 15:25:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.07422283291816711 norm:0.00019596861966419965 max memory_allocated 22563.71044921875 
[2025-02-28 15:25:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.07420402020215988 norm:0.00020710311946459115 max memory_allocated 22563.71044921875 
[2025-02-28 15:26:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.07418183982372284 norm:0.00020881318778265268 max memory_allocated 22563.71044921875 
[2025-02-28 15:26:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-02-28 15:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.10584024339914322 norm:0.0023666638880968094 max memory_allocated 22563.88232421875 
[2025-02-28 15:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.09169113636016846 norm:0.001089148223400116 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.08312641084194183 norm:0.0005593433161266148 max memory_allocated 22563.88232421875 
[2025-02-28 15:28:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.07978864759206772 norm:0.00037235001218505204 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:17 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.07828188687562943 norm:0.0002926091547124088 max memory_allocated 22563.88232421875 
[2025-02-28 15:29:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.07750992476940155 norm:0.00025056087179109454 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:24 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.0771966502070427 norm:0.00022450601682066917 max memory_allocated 22563.88232421875 
[2025-02-28 15:30:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.07695372402667999 norm:0.0002237600419903174 max memory_allocated 22563.88232421875 
[2025-02-28 15:31:32 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.07687868177890778 norm:0.00022049948165658861 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.07677305489778519 norm:0.00021537233260460198 max memory_allocated 22563.88232421875 
[2025-02-28 15:32:39 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.07670561969280243 norm:0.0002107438340317458 max memory_allocated 22563.88232421875 
[2025-02-28 15:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.07668080180883408 norm:0.00020776354358531535 max memory_allocated 22563.88232421875 
[2025-02-28 15:33:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.07661560922861099 norm:0.00021016065147705376 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.07656684517860413 norm:0.00020396056061144918 max memory_allocated 22563.88232421875 
[2025-02-28 15:34:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.07655047625303268 norm:0.00020084336574655026 max memory_allocated 22563.88232421875 
[2025-02-28 15:35:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.07652625441551208 norm:0.00020561934798024595 max memory_allocated 22563.88232421875 
[2025-02-28 15:36:02 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.07649575918912888 norm:0.00020836431940551847 max memory_allocated 22563.88232421875 
[2025-02-28 15:36:35 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.07648153603076935 norm:0.00020620579016394913 max memory_allocated 22563.88232421875 
[2025-02-28 15:37:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.07644982635974884 norm:0.00019997754134237766 max memory_allocated 22563.88232421875 
[2025-02-28 15:37:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.0764107033610344 norm:0.00020189864153508097 max memory_allocated 22563.88232421875 
[2025-02-28 15:37:52 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-02-28 15:38:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.10289633274078369 norm:0.0016193162882700562 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.09140840172767639 norm:0.0008103801519609988 max memory_allocated 22564.05419921875 
[2025-02-28 15:39:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.08405720442533493 norm:0.00046807946637272835 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.08119110763072968 norm:0.00030978929135017097 max memory_allocated 22564.05419921875 
[2025-02-28 15:40:44 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.07985492050647736 norm:0.00024629654944874346 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.07921473681926727 norm:0.00021386079606600106 max memory_allocated 22564.05419921875 
[2025-02-28 15:41:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.07892321795225143 norm:0.00020991318160668015 max memory_allocated 22564.05419921875 
[2025-02-28 15:42:25 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.07872837781906128 norm:0.00019447279919404536 max memory_allocated 22564.05419921875 
[2025-02-28 15:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.07863679528236389 norm:0.0001916833280120045 max memory_allocated 22564.05419921875 
[2025-02-28 15:43:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.07850899547338486 norm:0.0001900245260912925 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:06 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.07844817638397217 norm:0.00019458497990854084 max memory_allocated 22564.05419921875 
[2025-02-28 15:44:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.07839810848236084 norm:0.00019362389866728336 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:13 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.07834072411060333 norm:0.00018548678781371564 max memory_allocated 22564.05419921875 
[2025-02-28 15:45:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.07834099978208542 norm:0.0001879598421510309 max memory_allocated 22564.05419921875 
[2025-02-28 15:46:21 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.07832987606525421 norm:0.00017990166088566184 max memory_allocated 22564.05419921875 
[2025-02-28 15:46:55 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.0782885029911995 norm:0.00017988018225878477 max memory_allocated 22564.05419921875 
[2025-02-28 15:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.07825606316328049 norm:0.00017896131612360477 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.07823345065116882 norm:0.00017606063920538872 max memory_allocated 22564.05419921875 
[2025-02-28 15:48:36 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.07821867614984512 norm:0.00018107000505551696 max memory_allocated 22564.05419921875 
[2025-02-28 15:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.07819661498069763 norm:0.0001839464093791321 max memory_allocated 22564.05419921875 
[2025-02-28 15:49:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-02-28 15:49:56 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.10190986096858978 norm:0.0026817379985004663 max memory_allocated 22564.22607421875 
[2025-02-28 15:50:30 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.0900922566652298 norm:0.001107896794565022 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.08301399648189545 norm:0.0005919074756093323 max memory_allocated 22564.22607421875 
[2025-02-28 15:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.08023234456777573 norm:0.00039597100112587214 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:11 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.07887019217014313 norm:0.00030650562257505953 max memory_allocated 22564.22607421875 
[2025-02-28 15:52:44 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.07814214378595352 norm:0.0002625914348755032 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:18 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.07772435247898102 norm:0.0002389657311141491 max memory_allocated 22564.22607421875 
[2025-02-28 15:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.07747706770896912 norm:0.00023049191804602742 max memory_allocated 22564.22607421875 
[2025-02-28 15:54:26 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.07736287266016006 norm:0.0002219673478975892 max memory_allocated 22564.22607421875 
[2025-02-28 15:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.0772755816578865 norm:0.0002011734468396753 max memory_allocated 22564.22607421875 
[2025-02-28 15:55:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.07718344777822495 norm:0.00019673841597978026 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:07 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.07714433968067169 norm:0.00019959802739322186 max memory_allocated 22564.22607421875 
[2025-02-28 15:56:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.07710085064172745 norm:0.00020056641369592398 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.07705006748437881 norm:0.00019534882449079305 max memory_allocated 22564.22607421875 
[2025-02-28 15:57:48 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.07702557742595673 norm:0.00019137380877509713 max memory_allocated 22564.22607421875 
[2025-02-28 15:58:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.07702192664146423 norm:0.00019082151993643492 max memory_allocated 22564.22607421875 
[2025-02-28 15:58:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.07698472589254379 norm:0.00018905993783846498 max memory_allocated 22564.22607421875 
[2025-02-28 15:59:29 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.0769687071442604 norm:0.0001944531686604023 max memory_allocated 22564.22607421875 
[2025-02-28 16:00:03 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.07694870233535767 norm:0.00019627006258815527 max memory_allocated 22564.22607421875 
[2025-02-28 16:00:37 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.07693402469158173 norm:0.00019551400328055024 max memory_allocated 22564.22607421875 
[2025-02-28 16:00:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-02-28 16:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.09842533618211746 norm:0.0014809641288593411 max memory_allocated 22564.39794921875 
[2025-02-28 16:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.08879157900810242 norm:0.000687560299411416 max memory_allocated 22564.39794921875 
[2025-02-28 16:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.0825091227889061 norm:0.0003870163345709443 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.08014768362045288 norm:0.00026272734976373613 max memory_allocated 22564.39794921875 
[2025-02-28 16:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.07904030382633209 norm:0.00021092896349728107 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:11 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.07848776131868362 norm:0.00019138760399073362 max memory_allocated 22564.39794921875 
[2025-02-28 16:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.07819060236215591 norm:0.00017790630226954818 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:19 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.07799848914146423 norm:0.0001652649079915136 max memory_allocated 22564.39794921875 
[2025-02-28 16:05:52 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.07787790894508362 norm:0.00015357737720478326 max memory_allocated 22564.39794921875 
[2025-02-28 16:06:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.07776980102062225 norm:0.00014904196723364294 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:00 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.07770079374313354 norm:0.00014616570842918009 max memory_allocated 22564.39794921875 
[2025-02-28 16:07:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.07766206562519073 norm:0.0001484028616687283 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.07760439068078995 norm:0.00014754313451703638 max memory_allocated 22564.39794921875 
[2025-02-28 16:08:41 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.07761213928461075 norm:0.00014630079385824502 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.07759876549243927 norm:0.00013762606249656528 max memory_allocated 22564.39794921875 
[2025-02-28 16:09:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.07757674902677536 norm:0.00013693947403226048 max memory_allocated 22564.39794921875 
[2025-02-28 16:10:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.07754550129175186 norm:0.00013717262481804937 max memory_allocated 22564.39794921875 
[2025-02-28 16:10:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.07754120230674744 norm:0.00014241297321859747 max memory_allocated 22564.39794921875 
[2025-02-28 16:11:29 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.07749565690755844 norm:0.0001412683050148189 max memory_allocated 22564.39794921875 
[2025-02-28 16:12:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.07749678194522858 norm:0.0001418701431248337 max memory_allocated 22564.39794921875 
[2025-02-28 16:12:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-02-28 16:12:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.10236778110265732 norm:0.0023481932003051043 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.09003428369760513 norm:0.0009108418016694486 max memory_allocated 22564.56982421875 
[2025-02-28 16:13:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.08263679593801498 norm:0.0005147396586835384 max memory_allocated 22564.56982421875 
[2025-02-28 16:14:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.0800253376364708 norm:0.0003469215298537165 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.07874006032943726 norm:0.00027040287386626005 max memory_allocated 22564.56982421875 
[2025-02-28 16:15:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.0780424177646637 norm:0.00022860254102852196 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.0776803120970726 norm:0.00020613381639122963 max memory_allocated 22564.56982421875 
[2025-02-28 16:16:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.07747185230255127 norm:0.00019429068197496235 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:19 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.07732458412647247 norm:0.00018658660701476038 max memory_allocated 22564.56982421875 
[2025-02-28 16:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.07721535116434097 norm:0.0001794410782167688 max memory_allocated 22564.56982421875 
[2025-02-28 16:18:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.07711908966302872 norm:0.0001704538008198142 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:00 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.07702716439962387 norm:0.0001771666284184903 max memory_allocated 22564.56982421875 
[2025-02-28 16:19:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.07695109397172928 norm:0.00016442700871266425 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:08 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.07688320428133011 norm:0.00015702663222327828 max memory_allocated 22564.56982421875 
[2025-02-28 16:20:41 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.07683085650205612 norm:0.00015606429951731116 max memory_allocated 22564.56982421875 
[2025-02-28 16:21:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.07680261880159378 norm:0.00015488437202293426 max memory_allocated 22564.56982421875 
[2025-02-28 16:21:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.07675985991954803 norm:0.00014946202281862497 max memory_allocated 22564.56982421875 
[2025-02-28 16:22:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.07671931385993958 norm:0.00015082157915458083 max memory_allocated 22564.56982421875 
[2025-02-28 16:22:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.07671339064836502 norm:0.00015290439478121698 max memory_allocated 22564.56982421875 
[2025-02-28 16:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.07670369744300842 norm:0.00014931925397831947 max memory_allocated 22564.56982421875 
[2025-02-28 16:23:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-02-28 16:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.10043063759803772 norm:0.002409521723166108 max memory_allocated 22564.74169921875 
[2025-02-28 16:24:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.08945222198963165 norm:0.0008838611538521945 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.08243181556463242 norm:0.00044277822598814964 max memory_allocated 22564.74169921875 
[2025-02-28 16:25:57 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.08007900416851044 norm:0.00031585662509314716 max memory_allocated 22564.74169921875 
[2025-02-28 16:26:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.07888618856668472 norm:0.0002650184906087816 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:04 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.07819227874279022 norm:0.0002323090739082545 max memory_allocated 22564.74169921875 
[2025-02-28 16:27:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.07786495983600616 norm:0.0002054989745374769 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.0776647999882698 norm:0.00019611211610026658 max memory_allocated 22564.74169921875 
[2025-02-28 16:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.07750527560710907 norm:0.00018614419968798757 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:19 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.0773734301328659 norm:0.0001743097964208573 max memory_allocated 22564.74169921875 
[2025-02-28 16:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.0772528201341629 norm:0.00016417219012510031 max memory_allocated 22564.74169921875 
[2025-02-28 16:30:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.07719752937555313 norm:0.00016123928071465343 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.07713226974010468 norm:0.00015421754505950958 max memory_allocated 22564.74169921875 
[2025-02-28 16:31:34 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.07707814872264862 norm:0.00015364171122200787 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.07701317220926285 norm:0.00015349112800322473 max memory_allocated 22564.74169921875 
[2025-02-28 16:32:42 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.07695584744215012 norm:0.00014731813280377537 max memory_allocated 22564.74169921875 
[2025-02-28 16:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.07692916691303253 norm:0.00014278017624747008 max memory_allocated 22564.74169921875 
[2025-02-28 16:33:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.07689778506755829 norm:0.00014644583279732615 max memory_allocated 22564.74169921875 
[2025-02-28 16:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.07686172425746918 norm:0.00014424191613215953 max memory_allocated 22564.74169921875 
[2025-02-28 16:34:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.07683401554822922 norm:0.0001440276246285066 max memory_allocated 22564.74169921875 
[2025-02-28 16:35:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-02-28 16:35:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.09479346871376038 norm:0.0018938282737508416 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.08725342154502869 norm:0.0006196728209033608 max memory_allocated 22564.91357421875 
[2025-02-28 16:36:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.08214101195335388 norm:0.000317644327878952 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.08041183650493622 norm:0.00024241673236247152 max memory_allocated 22564.91357421875 
[2025-02-28 16:37:57 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.07938622683286667 norm:0.00019900259212590754 max memory_allocated 22564.91357421875 
[2025-02-28 16:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.07881077378988266 norm:0.0001786623033694923 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:05 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.07851579785346985 norm:0.00016147777205333114 max memory_allocated 22564.91357421875 
[2025-02-28 16:39:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.07836174964904785 norm:0.00015827995957806706 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.07821831107139587 norm:0.00014728242240380496 max memory_allocated 22564.91357421875 
[2025-02-28 16:40:46 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.07814601808786392 norm:0.00014163923333398998 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:20 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.07806871831417084 norm:0.00013008233509026468 max memory_allocated 22564.91357421875 
[2025-02-28 16:41:54 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.07803075015544891 norm:0.00012825315934605896 max memory_allocated 22564.91357421875 
[2025-02-28 16:42:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.07799965888261795 norm:0.00012873484229203314 max memory_allocated 22564.91357421875 
[2025-02-28 16:43:01 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.07794880121946335 norm:0.00012141864863224328 max memory_allocated 22564.91357421875 
[2025-02-28 16:43:35 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.07792676240205765 norm:0.00011879535304615274 max memory_allocated 22564.91357421875 
[2025-02-28 16:44:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.0779128223657608 norm:0.00012123912893002853 max memory_allocated 22564.91357421875 
[2025-02-28 16:44:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.07789541780948639 norm:0.00012028304627165198 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.07787927240133286 norm:0.00011867658759001642 max memory_allocated 22564.91357421875 
[2025-02-28 16:45:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.07784285396337509 norm:0.00012029699428239837 max memory_allocated 22564.91357421875 
[2025-02-28 16:46:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.07783810049295425 norm:0.00012172549759270623 max memory_allocated 22564.91357421875 
[2025-02-28 16:46:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-02-28 16:47:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.10171247273683548 norm:0.0018467463087290525 max memory_allocated 22565.08544921875 
[2025-02-28 16:47:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.09315460175275803 norm:0.000840577355120331 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.0873836874961853 norm:0.0005151997320353985 max memory_allocated 22565.08544921875 
[2025-02-28 16:48:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.0854317843914032 norm:0.0003605213132686913 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.08423661440610886 norm:0.00028150714933872223 max memory_allocated 22565.08544921875 
[2025-02-28 16:49:58 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.08358665555715561 norm:0.00023934031196404248 max memory_allocated 22565.08544921875 
[2025-02-28 16:50:32 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.08323564380407333 norm:0.00020953296916559339 max memory_allocated 22565.08544921875 
[2025-02-28 16:51:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.08306530117988586 norm:0.00019386781787034124 max memory_allocated 22565.08544921875 
[2025-02-28 16:51:39 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.08294128626585007 norm:0.00017217613640241325 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.08283227682113647 norm:0.0001695065147941932 max memory_allocated 22565.08544921875 
[2025-02-28 16:52:47 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.08273947983980179 norm:0.00015917989367153496 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.08266980946063995 norm:0.00014915243082214147 max memory_allocated 22565.08544921875 
[2025-02-28 16:53:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.08258941769599915 norm:0.00014543422730639577 max memory_allocated 22565.08544921875 
[2025-02-28 16:54:28 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.08255082368850708 norm:0.00013786151248496026 max memory_allocated 22565.08544921875 
[2025-02-28 16:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.08248060196638107 norm:0.000134640620672144 max memory_allocated 22565.08544921875 
[2025-02-28 16:55:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.082435242831707 norm:0.00012795980728697032 max memory_allocated 22565.08544921875 
[2025-02-28 16:56:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.08239427208900452 norm:0.00012860643619205803 max memory_allocated 22565.08544921875 
[2025-02-28 16:56:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.08235612511634827 norm:0.00012813620560336858 max memory_allocated 22565.08544921875 
[2025-02-28 16:57:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.08232378959655762 norm:0.00012466820771805942 max memory_allocated 22565.08544921875 
[2025-02-28 16:57:50 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.08230520039796829 norm:0.0001252998918062076 max memory_allocated 22565.08544921875 
[2025-02-28 16:58:00 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-02-28 16:58:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.10728705674409866 norm:0.002169433981180191 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:10 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.09914421290159225 norm:0.0008292990387417376 max memory_allocated 22565.25732421875 
[2025-02-28 16:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.09300845116376877 norm:0.0004028312105219811 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.09124645590782166 norm:0.00028460315661504865 max memory_allocated 22565.25732421875 
[2025-02-28 17:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.0901680588722229 norm:0.0002183174656238407 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:25 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.08959393203258514 norm:0.00018830499902833253 max memory_allocated 22565.25732421875 
[2025-02-28 17:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.08929528295993805 norm:0.00016488361870869994 max memory_allocated 22565.25732421875 
[2025-02-28 17:02:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.0891353040933609 norm:0.00015517129213549197 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.08899618685245514 norm:0.00015306197747122496 max memory_allocated 22565.25732421875 
[2025-02-28 17:03:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.08889541029930115 norm:0.0001364632771583274 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:13 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.08880431205034256 norm:0.00012778813834302127 max memory_allocated 22565.25732421875 
[2025-02-28 17:04:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.08873677253723145 norm:0.00012161301128799096 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:21 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.08865848183631897 norm:0.00012237460759934038 max memory_allocated 22565.25732421875 
[2025-02-28 17:05:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.08863388746976852 norm:0.000122598183224909 max memory_allocated 22565.25732421875 
[2025-02-28 17:06:28 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.08857515454292297 norm:0.00011817458289442584 max memory_allocated 22565.25732421875 
[2025-02-28 17:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.08853430300951004 norm:0.0001146009162766859 max memory_allocated 22565.25732421875 
[2025-02-28 17:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.08849533647298813 norm:0.00011239412560826167 max memory_allocated 22565.25732421875 
[2025-02-28 17:08:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.08844713866710663 norm:0.00011153511877637357 max memory_allocated 22565.25732421875 
[2025-02-28 17:08:43 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.08841866999864578 norm:0.00011196394916623831 max memory_allocated 22565.25732421875 
[2025-02-28 17:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.08839841932058334 norm:0.00010759058932308108 max memory_allocated 22565.25732421875 
[2025-02-28 17:09:26 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-02-28 17:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.11666443198919296 norm:0.0023216758854687214 max memory_allocated 22565.42919921875 
[2025-02-28 17:10:37 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.1079518273472786 norm:0.0008846816490404308 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.10167915374040604 norm:0.00037875730777159333 max memory_allocated 22565.42919921875 
[2025-02-28 17:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.09987293183803558 norm:0.00025882560294121504 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.09873339533805847 norm:0.00022635677305515856 max memory_allocated 22565.42919921875 
[2025-02-28 17:12:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.09803997725248337 norm:0.00020646871416829526 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.09769970923662186 norm:0.00018926418852061033 max memory_allocated 22565.42919921875 
[2025-02-28 17:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.09749454259872437 norm:0.00018010480562224984 max memory_allocated 22565.42919921875 
[2025-02-28 17:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.09735486656427383 norm:0.0001774036354618147 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.09723460674285889 norm:0.00017776066670194268 max memory_allocated 22565.42919921875 
[2025-02-28 17:15:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.09714251011610031 norm:0.00016382592730224133 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.09706233441829681 norm:0.00015718257054686546 max memory_allocated 22565.42919921875 
[2025-02-28 17:16:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.09698006510734558 norm:0.00014911057951394469 max memory_allocated 22565.42919921875 
[2025-02-28 17:17:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.09688510000705719 norm:0.00014063155686017126 max memory_allocated 22565.42919921875 
[2025-02-28 17:17:55 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.09682098031044006 norm:0.000145211917697452 max memory_allocated 22565.42919921875 
[2025-02-28 17:18:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.09677507728338242 norm:0.0001432127901352942 max memory_allocated 22565.42919921875 
[2025-02-28 17:19:03 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.09672430902719498 norm:0.00014190457295626402 max memory_allocated 22565.42919921875 
[2025-02-28 17:19:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.09669101238250732 norm:0.00014439612277783453 max memory_allocated 22565.42919921875 
[2025-02-28 17:20:10 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.09666623175144196 norm:0.00014245323836803436 max memory_allocated 22565.42919921875 
[2025-02-28 17:20:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.09665071964263916 norm:0.0001371374528389424 max memory_allocated 22565.42919921875 
[2025-02-28 17:20:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-02-28 17:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.12447129189968109 norm:0.001849863212555647 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.11677193641662598 norm:0.0006125880754552782 max memory_allocated 22565.60107421875 
[2025-02-28 17:22:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.11121253669261932 norm:0.0003033133689314127 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.10966050624847412 norm:0.00023985472216736525 max memory_allocated 22565.60107421875 
[2025-02-28 17:23:45 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.1085360199213028 norm:0.00020790367852896452 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.10791167616844177 norm:0.00020152634533587843 max memory_allocated 22565.60107421875 
[2025-02-28 17:24:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.10762673616409302 norm:0.0001789774833014235 max memory_allocated 22565.60107421875 
[2025-02-28 17:25:26 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.10744918137788773 norm:0.00016239284013863653 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.10731390863656998 norm:0.00015062681632116437 max memory_allocated 22565.60107421875 
[2025-02-28 17:26:33 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.10719593614339828 norm:0.00014788763655815274 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.10709265619516373 norm:0.00014623068273067474 max memory_allocated 22565.60107421875 
[2025-02-28 17:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.10701236873865128 norm:0.0001392950362060219 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:14 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.10695487260818481 norm:0.00013445003423839808 max memory_allocated 22565.60107421875 
[2025-02-28 17:28:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.10690591484308243 norm:0.00013349231448955834 max memory_allocated 22565.60107421875 
[2025-02-28 17:29:22 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.10684464871883392 norm:0.0001295292895520106 max memory_allocated 22565.60107421875 
[2025-02-28 17:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.1067834198474884 norm:0.0001252609072253108 max memory_allocated 22565.60107421875 
[2025-02-28 17:30:29 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.10672834515571594 norm:0.00012426229659467936 max memory_allocated 22565.60107421875 
[2025-02-28 17:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.10667156428098679 norm:0.00012173283903393894 max memory_allocated 22565.60107421875 
[2025-02-28 17:31:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.10666776448488235 norm:0.00012029834761051461 max memory_allocated 22565.60107421875 
[2025-02-28 17:32:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.10665366798639297 norm:0.00011641666787909344 max memory_allocated 22565.60107421875 
[2025-02-28 17:32:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-02-28 17:32:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.13995198905467987 norm:0.0015308475121855736 max memory_allocated 22565.77294921875 
[2025-02-28 17:33:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.13175369799137115 norm:0.0005692617269232869 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:05 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.12566237151622772 norm:0.00032876309705898166 max memory_allocated 22565.77294921875 
[2025-02-28 17:34:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.12370098382234573 norm:0.00027818261878564954 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.12252630293369293 norm:0.0002498893882147968 max memory_allocated 22565.77294921875 
[2025-02-28 17:35:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.12185106426477432 norm:0.00021864226437173784 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.12156247347593307 norm:0.00021186773665249348 max memory_allocated 22565.77294921875 
[2025-02-28 17:36:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.12137355655431747 norm:0.00020325763034634292 max memory_allocated 22565.77294921875 
[2025-02-28 17:37:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.12123575806617737 norm:0.00019571284065023065 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.12109872698783875 norm:0.00018392816127743572 max memory_allocated 22565.77294921875 
[2025-02-28 17:38:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.12099767476320267 norm:0.00016155961202457547 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:08 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.1209145039319992 norm:0.0001730301883071661 max memory_allocated 22565.77294921875 
[2025-02-28 17:39:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.12083421647548676 norm:0.0001547441352158785 max memory_allocated 22565.77294921875 
[2025-02-28 17:40:16 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.12074828147888184 norm:0.0001476117322454229 max memory_allocated 22565.77294921875 
[2025-02-28 17:40:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.12067168205976486 norm:0.00015555930440314114 max memory_allocated 22565.77294921875 
[2025-02-28 17:41:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.1206212192773819 norm:0.0001533660979475826 max memory_allocated 22565.77294921875 
[2025-02-28 17:41:57 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.1205577403306961 norm:0.00015391332271974534 max memory_allocated 22565.77294921875 
[2025-02-28 17:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.1205647885799408 norm:0.00014125433517619967 max memory_allocated 22565.77294921875 
[2025-02-28 17:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.12056043744087219 norm:0.00016707224131096154 max memory_allocated 22565.77294921875 
[2025-02-28 17:43:38 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.12048119306564331 norm:0.00016747807967476547 max memory_allocated 22565.77294921875 
[2025-02-28 17:43:47 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-02-28 17:44:24 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.15683086216449738 norm:0.002189587103202939 max memory_allocated 22565.94482421875 
[2025-02-28 17:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.14813974499702454 norm:0.0010583888506516814 max memory_allocated 22565.94482421875 
[2025-02-28 17:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.1411343216896057 norm:0.000642474100459367 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.1390906572341919 norm:0.00046361482236534357 max memory_allocated 22565.94482421875 
[2025-02-28 17:46:39 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.13776788115501404 norm:0.00035728744114749134 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.13713888823986053 norm:0.0002893958881031722 max memory_allocated 22565.94482421875 
[2025-02-28 17:47:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.1368485540151596 norm:0.0002409796870779246 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:20 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.13663478195667267 norm:0.0002158985153073445 max memory_allocated 22565.94482421875 
[2025-02-28 17:48:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.13649336993694305 norm:0.00019394214905332774 max memory_allocated 22565.94482421875 
[2025-02-28 17:49:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.13635005056858063 norm:0.0001805232313927263 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:01 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.13625533878803253 norm:0.00015911899390630424 max memory_allocated 22565.94482421875 
[2025-02-28 17:50:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.1361437290906906 norm:0.00015384754806291312 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.13603322207927704 norm:0.00015142862685024738 max memory_allocated 22565.94482421875 
[2025-02-28 17:51:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.1359766721725464 norm:0.00014208351785782725 max memory_allocated 22565.94482421875 
[2025-02-28 17:52:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.13592498004436493 norm:0.0001387407974107191 max memory_allocated 22565.94482421875 
[2025-02-28 17:52:50 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.13588617742061615 norm:0.00013899111945647746 max memory_allocated 22565.94482421875 
[2025-02-28 17:53:24 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.13583803176879883 norm:0.0001347118814010173 max memory_allocated 22565.94482421875 
[2025-02-28 17:53:57 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.13579946756362915 norm:0.00013229419710114598 max memory_allocated 22565.94482421875 
[2025-02-28 17:54:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.1357751339673996 norm:0.00013365346239879727 max memory_allocated 22565.94482421875 
[2025-02-28 17:55:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.13572455942630768 norm:0.00012970215175300837 max memory_allocated 22565.94482421875 
[2025-02-28 17:55:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-02-28 17:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.17473134398460388 norm:0.002228685189038515 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.16522064805030823 norm:0.0006266621639952064 max memory_allocated 22566.11669921875 
[2025-02-28 17:56:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.15842975676059723 norm:0.000429765903390944 max memory_allocated 22566.11669921875 
[2025-02-28 17:57:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.15620502829551697 norm:0.00029363876092247665 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:06 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.1548512578010559 norm:0.0002644602791406214 max memory_allocated 22566.11669921875 
[2025-02-28 17:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.15423071384429932 norm:0.00023160746786743402 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.15396526455879211 norm:0.00022354218526743352 max memory_allocated 22566.11669921875 
[2025-02-28 17:59:47 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.15378838777542114 norm:0.00021197926253080368 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.15361908078193665 norm:0.000201282455236651 max memory_allocated 22566.11669921875 
[2025-02-28 18:00:54 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.15347567200660706 norm:0.00019615083874668926 max memory_allocated 22566.11669921875 
[2025-02-28 18:01:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.15333159267902374 norm:0.00018615486624184996 max memory_allocated 22566.11669921875 
[2025-02-28 18:02:02 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.15326814353466034 norm:0.00019273612997494638 max memory_allocated 22566.11669921875 
[2025-02-28 18:02:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.15319113433361053 norm:0.00018700570217333734 max memory_allocated 22566.11669921875 
[2025-02-28 18:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.15313053131103516 norm:0.00018399459077045321 max memory_allocated 22566.11669921875 
[2025-02-28 18:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.15306636691093445 norm:0.00018158448801841587 max memory_allocated 22566.11669921875 
[2025-02-28 18:04:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.1529988795518875 norm:0.00018309950246475637 max memory_allocated 22566.11669921875 
[2025-02-28 18:04:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.15294837951660156 norm:0.00016821411554701626 max memory_allocated 22566.11669921875 
[2025-02-28 18:05:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.15288981795310974 norm:0.00016707896429579705 max memory_allocated 22566.11669921875 
[2025-02-28 18:05:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.15283457934856415 norm:0.00015475257532671094 max memory_allocated 22566.11669921875 
[2025-02-28 18:06:32 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.1527988761663437 norm:0.00015672494191676378 max memory_allocated 22566.11669921875 
[2025-02-28 18:06:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-02-28 18:07:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.1985836625099182 norm:0.0014816621551290154 max memory_allocated 22566.28857421875 
[2025-02-28 18:07:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.18887387216091156 norm:0.0007964461692608893 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.18061088025569916 norm:0.0004744715988636017 max memory_allocated 22566.28857421875 
[2025-02-28 18:08:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.17807315289974213 norm:0.00035752577241510153 max memory_allocated 22566.28857421875 
[2025-02-28 18:09:33 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.1766262650489807 norm:0.00030084114405326545 max memory_allocated 22566.28857421875 
[2025-02-28 18:10:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.1760079562664032 norm:0.00027756349300034344 max memory_allocated 22566.28857421875 
[2025-02-28 18:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.17568416893482208 norm:0.0002456637448631227 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:14 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.1754744052886963 norm:0.00022420701861847192 max memory_allocated 22566.28857421875 
[2025-02-28 18:11:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.17522379755973816 norm:0.00020930527534801513 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:21 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.17515842616558075 norm:0.0002183693286497146 max memory_allocated 22566.28857421875 
[2025-02-28 18:12:55 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.17492413520812988 norm:0.0001861552445916459 max memory_allocated 22566.28857421875 
[2025-02-28 18:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.1748778223991394 norm:0.00018396425002720207 max memory_allocated 22566.28857421875 
[2025-02-28 18:14:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.1747848391532898 norm:0.0001820873440010473 max memory_allocated 22566.28857421875 
[2025-02-28 18:14:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.17471367120742798 norm:0.00018088857177644968 max memory_allocated 22566.28857421875 
[2025-02-28 18:15:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.174627885222435 norm:0.0001810127723729238 max memory_allocated 22566.28857421875 
[2025-02-28 18:15:44 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.17454002797603607 norm:0.00016946705000009388 max memory_allocated 22566.28857421875 
[2025-02-28 18:16:17 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.17448128759860992 norm:0.00017329450929537416 max memory_allocated 22566.28857421875 
[2025-02-28 18:16:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.17443633079528809 norm:0.00016869345563463867 max memory_allocated 22566.28857421875 
[2025-02-28 18:17:25 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.17439880967140198 norm:0.00016936319298110902 max memory_allocated 22566.28857421875 
[2025-02-28 18:17:58 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.1743396669626236 norm:0.00017161204596050084 max memory_allocated 22566.28857421875 
[2025-02-28 18:18:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-02-28 18:18:45 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.22374840080738068 norm:0.0024582999758422375 max memory_allocated 22566.46044921875 
[2025-02-28 18:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.21317242085933685 norm:0.0011377023765817285 max memory_allocated 22566.46044921875 
[2025-02-28 18:19:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.20442168414592743 norm:0.0005757831386290491 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.20148307085037231 norm:0.00043079128954559565 max memory_allocated 22566.46044921875 
[2025-02-28 18:20:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.19994565844535828 norm:0.00034069109824486077 max memory_allocated 22566.46044921875 
[2025-02-28 18:21:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.19933028519153595 norm:0.0002840372908394784 max memory_allocated 22566.46044921875 
[2025-02-28 18:22:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.1989603340625763 norm:0.00025590561563149095 max memory_allocated 22566.46044921875 
[2025-02-28 18:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.19872447848320007 norm:0.0002486651937942952 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.19851158559322357 norm:0.00022735289530828595 max memory_allocated 22566.46044921875 
[2025-02-28 18:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.19830888509750366 norm:0.00021605819347314537 max memory_allocated 22566.46044921875 
[2025-02-28 18:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.1981526017189026 norm:0.0001992685574805364 max memory_allocated 22566.46044921875 
[2025-02-28 18:24:55 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.19802194833755493 norm:0.00020172088989056647 max memory_allocated 22566.46044921875 
[2025-02-28 18:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.1979152113199234 norm:0.00018484986503608525 max memory_allocated 22566.46044921875 
[2025-02-28 18:26:03 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.19780337810516357 norm:0.00019187628640793264 max memory_allocated 22566.46044921875 
[2025-02-28 18:26:37 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.19771526753902435 norm:0.00019463985518086702 max memory_allocated 22566.46044921875 
[2025-02-28 18:27:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.1976255178451538 norm:0.00019304051238577813 max memory_allocated 22566.46044921875 
[2025-02-28 18:27:44 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.19760426878929138 norm:0.00019958212214987725 max memory_allocated 22566.46044921875 
[2025-02-28 18:28:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.19754573702812195 norm:0.00018984371854458004 max memory_allocated 22566.46044921875 
[2025-02-28 18:28:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.19748251140117645 norm:0.00018831533088814467 max memory_allocated 22566.46044921875 
[2025-02-28 18:29:25 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.1974520981311798 norm:0.0001868810213636607 max memory_allocated 22566.46044921875 
[2025-02-28 18:29:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-02-28 18:30:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.2520805299282074 norm:0.0025657908990979195 max memory_allocated 22566.63232421875 
[2025-02-28 18:30:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.24071575701236725 norm:0.001075776177458465 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.23163823783397675 norm:0.0005394057370722294 max memory_allocated 22566.63232421875 
[2025-02-28 18:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.22868238389492035 norm:0.0003935049462597817 max memory_allocated 22566.63232421875 
[2025-02-28 18:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.2272992581129074 norm:0.00033237371826544404 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.22679874300956726 norm:0.0002850399469025433 max memory_allocated 22566.63232421875 
[2025-02-28 18:33:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.22644895315170288 norm:0.0002561047440394759 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:08 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.22621360421180725 norm:0.00023691856767982244 max memory_allocated 22566.63232421875 
[2025-02-28 18:34:41 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.22599872946739197 norm:0.00022093681036494672 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.2258165180683136 norm:0.00020650617079809308 max memory_allocated 22566.63232421875 
[2025-02-28 18:35:49 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.2256818264722824 norm:0.00019548408454284072 max memory_allocated 22566.63232421875 
[2025-02-28 18:36:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.22558695077896118 norm:0.00019162663375027478 max memory_allocated 22566.63232421875 
[2025-02-28 18:36:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.22547906637191772 norm:0.00018780518439598382 max memory_allocated 22566.63232421875 
[2025-02-28 18:37:30 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.22539162635803223 norm:0.0001813473500078544 max memory_allocated 22566.63232421875 
[2025-02-28 18:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.22530588507652283 norm:0.00018009015184361488 max memory_allocated 22566.63232421875 
[2025-02-28 18:38:37 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.22520747780799866 norm:0.00017798662884160876 max memory_allocated 22566.63232421875 
[2025-02-28 18:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.22515243291854858 norm:0.00017122799181379378 max memory_allocated 22566.63232421875 
[2025-02-28 18:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.22508493065834045 norm:0.0001886301615741104 max memory_allocated 22566.63232421875 
[2025-02-28 18:40:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.22503313422203064 norm:0.00017871963791549206 max memory_allocated 22566.63232421875 
[2025-02-28 18:40:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.22500288486480713 norm:0.0001769598020473495 max memory_allocated 22566.63232421875 
[2025-02-28 18:41:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-02-28 18:41:05 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:41:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.28879791498184204 norm:0.012980700470507145 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.27642807364463806 norm:0.009351647458970547 max memory_allocated 22566.91943359375 
[2025-02-28 18:42:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.2664068341255188 norm:0.006234346888959408 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.26285520195961 norm:0.005098581779748201 max memory_allocated 22566.91943359375 
[2025-02-28 18:43:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.26128241419792175 norm:0.0043126801028847694 max memory_allocated 22566.91943359375 
[2025-02-28 18:44:27 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.26062703132629395 norm:0.0036906832829117775 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.26014119386672974 norm:0.003103045979514718 max memory_allocated 22566.91943359375 
[2025-02-28 18:45:35 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.2597806453704834 norm:0.002708584535866976 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.2596154510974884 norm:0.0026192276272922754 max memory_allocated 22566.91943359375 
[2025-02-28 18:46:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.25944578647613525 norm:0.0025873135309666395 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.25944963097572327 norm:0.0025676721706986427 max memory_allocated 22566.91943359375 
[2025-02-28 18:47:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.25927141308784485 norm:0.002569024683907628 max memory_allocated 22566.91943359375 
[2025-02-28 18:48:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.25907957553863525 norm:0.0022834977135062218 max memory_allocated 22566.91943359375 
[2025-02-28 18:48:58 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.2589624226093292 norm:0.0021289715077728033 max memory_allocated 22566.91943359375 
[2025-02-28 18:49:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.25887250900268555 norm:0.0020851842127740383 max memory_allocated 22566.91943359375 
[2025-02-28 18:50:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.25884488224983215 norm:0.002130913781002164 max memory_allocated 22566.91943359375 
[2025-02-28 18:50:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.2587830722332001 norm:0.002059009624645114 max memory_allocated 22566.91943359375 
[2025-02-28 18:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.25868308544158936 norm:0.00193217140622437 max memory_allocated 22566.91943359375 
[2025-02-28 18:51:47 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.25863224267959595 norm:0.0019057567697018385 max memory_allocated 22566.91943359375 
[2025-02-28 18:52:21 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.25858044624328613 norm:0.0019226717995479703 max memory_allocated 22566.91943359375 
[2025-02-28 18:52:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-02-28 18:52:33 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 18:53:07 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.34269657731056213 norm:0.014800271019339561 max memory_allocated 22567.09130859375 
[2025-02-28 18:53:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.3226948082447052 norm:0.010279442183673382 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.3087940216064453 norm:0.006657878868281841 max memory_allocated 22567.09130859375 
[2025-02-28 18:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.304089218378067 norm:0.00558794941753149 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.3021424114704132 norm:0.004690042696893215 max memory_allocated 22567.09130859375 
[2025-02-28 18:55:56 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.3012758195400238 norm:0.004002825357019901 max memory_allocated 22567.09130859375 
[2025-02-28 18:56:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.3006186783313751 norm:0.0033443314023315907 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.30002230405807495 norm:0.0028237279038876295 max memory_allocated 22567.09130859375 
[2025-02-28 18:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.29955804347991943 norm:0.0026398058980703354 max memory_allocated 22567.09130859375 
[2025-02-28 18:58:11 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.29934900999069214 norm:0.0026813040021806955 max memory_allocated 22567.09130859375 
[2025-02-28 18:58:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.2992329001426697 norm:0.0027324645780026913 max memory_allocated 22567.09130859375 
[2025-02-28 18:59:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.29920461773872375 norm:0.0028611882589757442 max memory_allocated 22567.09130859375 
[2025-02-28 18:59:52 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.299024373292923 norm:0.0025654220953583717 max memory_allocated 22567.09130859375 
[2025-02-28 19:00:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.29890045523643494 norm:0.0024716586340218782 max memory_allocated 22567.09130859375 
[2025-02-28 19:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.29886868596076965 norm:0.0023622072767466307 max memory_allocated 22567.09130859375 
[2025-02-28 19:01:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.29888275265693665 norm:0.002412610687315464 max memory_allocated 22567.09130859375 
[2025-02-28 19:02:08 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.2988378405570984 norm:0.00222978787496686 max memory_allocated 22567.09130859375 
[2025-02-28 19:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.2987532615661621 norm:0.0021752798929810524 max memory_allocated 22567.09130859375 
[2025-02-28 19:03:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.2987886071205139 norm:0.0020447575952857733 max memory_allocated 22567.09130859375 
[2025-02-28 19:03:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.29889270663261414 norm:0.0021691692527383566 max memory_allocated 22567.09130859375 
[2025-02-28 19:03:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-02-28 19:04:02 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:04:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:1.2387917041778564 norm:0.14428238570690155 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:09 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:1.0019069910049438 norm:0.12009947001934052 max memory_allocated 22567.26318359375 
[2025-02-28 19:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.7023088932037354 norm:0.0703096017241478 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.5935968160629272 norm:0.042243294417858124 max memory_allocated 22567.26318359375 
[2025-02-28 19:06:51 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.5544004440307617 norm:0.042980872094631195 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.5345848798751831 norm:0.041568174958229065 max memory_allocated 22567.26318359375 
[2025-02-28 19:07:58 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.5193189978599548 norm:0.04140438511967659 max memory_allocated 22567.26318359375 
[2025-02-28 19:08:32 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.5137665867805481 norm:0.04365707188844681 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.5010719895362854 norm:0.03882507234811783 max memory_allocated 22567.26318359375 
[2025-02-28 19:09:39 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.49935421347618103 norm:0.04237320274114609 max memory_allocated 22567.26318359375 
[2025-02-28 19:10:13 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.48847445845603943 norm:0.0403251126408577 max memory_allocated 22567.26318359375 
[2025-02-28 19:10:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.49745824933052063 norm:0.04680326208472252 max memory_allocated 22567.26318359375 
[2025-02-28 19:11:21 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.4732595384120941 norm:0.03742474690079689 max memory_allocated 22567.26318359375 
[2025-02-28 19:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.46963316202163696 norm:0.036282431334257126 max memory_allocated 22567.26318359375 
[2025-02-28 19:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.46772727370262146 norm:0.03662858158349991 max memory_allocated 22567.26318359375 
[2025-02-28 19:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.4667527377605438 norm:0.036407604813575745 max memory_allocated 22567.26318359375 
[2025-02-28 19:13:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.468679279088974 norm:0.03908384591341019 max memory_allocated 22567.26318359375 
[2025-02-28 19:14:10 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.4642501175403595 norm:0.03760290890932083 max memory_allocated 22567.26318359375 
[2025-02-28 19:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.4654588997364044 norm:0.039886485785245895 max memory_allocated 22567.26318359375 
[2025-02-28 19:15:17 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.4571095407009125 norm:0.03536005690693855 max memory_allocated 22567.26318359375 
[2025-02-28 19:15:27 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-02-28 19:15:30 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-02-28 19:16:03 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:1.0130404233932495 norm:0.09085272252559662 max memory_allocated 22567.43505859375 
[2025-02-28 19:16:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.9177919626235962 norm:0.0630628764629364 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.8471909761428833 norm:0.041703686118125916 max memory_allocated 22567.43505859375 
[2025-02-28 19:17:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.8220494389533997 norm:0.037148065865039825 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.8116048574447632 norm:0.03355598449707031 max memory_allocated 22567.43505859375 
[2025-02-28 19:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.8037603497505188 norm:0.02893523871898651 max memory_allocated 22567.43505859375 
[2025-02-28 19:19:26 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.7942056059837341 norm:0.026863791048526764 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.7886508107185364 norm:0.025816934183239937 max memory_allocated 22567.43505859375 
[2025-02-28 19:20:33 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.7862581610679626 norm:0.024136854335665703 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.7842555046081543 norm:0.022781088948249817 max memory_allocated 22567.43505859375 
[2025-02-28 19:21:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.7822151184082031 norm:0.02267768420279026 max memory_allocated 22567.43505859375 
[2025-02-28 19:22:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.7794080376625061 norm:0.020742550492286682 max memory_allocated 22567.43505859375 
[2025-02-28 19:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.7764668464660645 norm:0.02150006592273712 max memory_allocated 22567.43505859375 
[2025-02-28 19:23:22 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.7760665416717529 norm:0.021152855828404427 max memory_allocated 22567.43505859375 
[2025-02-28 19:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.7752600908279419 norm:0.021662637591362 max memory_allocated 22567.43505859375 
[2025-02-28 19:24:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.7730309367179871 norm:0.020632069557905197 max memory_allocated 22567.43505859375 
[2025-02-28 19:25:04 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.7721239924430847 norm:0.019383205100893974 max memory_allocated 22567.43505859375 
[2025-02-28 19:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.7722933292388916 norm:0.018875908106565475 max memory_allocated 22567.43505859375 
[2025-02-28 19:26:11 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.7718935608863831 norm:0.020745737478137016 max memory_allocated 22567.43505859375 
[2025-02-28 19:26:45 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.7735790610313416 norm:0.02312636747956276 max memory_allocated 22567.43505859375 
[2025-02-28 19:26:55 root] (main_calib_config2.py 380): INFO 21987.742165088654
[2025-02-28 19:27:00 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-02-28 19:28:11 root] (main_calib_config2.py 159): INFO wikitext2 : 5.907449245452881
[2025-02-28 19:28:11 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-02-28 19:30:01 root] (main_calib_config2.py 159): INFO c4 : 7.593510150909424
[2025-02-28 21:14:00 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.907449245452881, 'c4': 7.593510150909424, 'results': {'boolq': {'acc': 0.6730886850152905, 'acc_stderr': 0.008204340208838748}, 'piqa': {'acc': 0.7709466811751904, 'acc_stderr': 0.009804509865175504, 'acc_norm': 0.7736670293797606, 'acc_norm_stderr': 0.009763294246879418}, 'arc_challenge': {'acc': 0.3890784982935154, 'acc_stderr': 0.014247309976045607, 'acc_norm': 0.3924914675767918, 'acc_norm_stderr': 0.014269634635670714}, 'arc_easy': {'acc': 0.6712962962962963, 'acc_stderr': 0.009638903167022175, 'acc_norm': 0.5138888888888888, 'acc_norm_stderr': 0.010255824507190345}, 'winogrande': {'acc': 0.6779794790844514, 'acc_stderr': 0.013132070202071069}, 'hellaswag': {'acc': 0.5431189006174069, 'acc_stderr': 0.004971192387202447, 'acc_norm': 0.7055367456681936, 'acc_norm_stderr': 0.004548695749620958}}, 'versions': {'boolq': 1, 'piqa': 0, 'arc_challenge': 0, 'arc_easy': 0, 'winogrande': 0, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
