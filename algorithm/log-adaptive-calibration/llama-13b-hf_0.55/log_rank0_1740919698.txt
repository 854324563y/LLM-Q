[2025-03-02 12:48:18 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.55', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.55.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.55.pkl
[2025-03-02 12:52:34 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:38 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.01596866548061371 norm:0.013358383439481258 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:16 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.009213106706738472 norm:0.007150002755224705 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:06 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.006206510588526726 norm:0.00432625925168395 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.005320644937455654 norm:0.0035214063245803118 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0049349055625498295 norm:0.0028270669281482697 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.004723678808659315 norm:0.0023865753319114447 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.004610427655279636 norm:0.0020822505466639996 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:13 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.004463368095457554 norm:0.0018170063849538565 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:03 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.004347270354628563 norm:0.0016462334897369146 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:52 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.004302681889384985 norm:0.0015079660806804895 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:42 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.004258851986378431 norm:0.0013845525681972504 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:31 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.004230029881000519 norm:0.0012933270772919059 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:21 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.004206924699246883 norm:0.0011822613887488842 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:10 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.004159944131970406 norm:0.0010258121183142066 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:00 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.0041731721721589565 norm:0.0010130243608728051 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:50 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.004151425790041685 norm:0.0009626112878322601 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:39 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.0041322181932628155 norm:0.00093655358068645 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.004144271835684776 norm:0.0008823128300718963 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.004095795564353466 norm:0.0008517127716913819 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.004077502992004156 norm:0.0008129095076583326 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:27 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:17 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.028162911534309387 norm:0.01664436236023903 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:06 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.016397712752223015 norm:0.009042569436132908 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:55 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.011707778088748455 norm:0.005770914722234011 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:45 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.010341132059693336 norm:0.004710328299552202 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:35 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.009810172952711582 norm:0.0040961094200611115 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:24 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.009532208554446697 norm:0.00370243052020669 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:14 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.009288085624575615 norm:0.003370335791260004 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:04 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.00910918228328228 norm:0.003140955464914441 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.00896459724754095 norm:0.002938191406428814 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:43 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.008832338266074657 norm:0.002666069194674492 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:33 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.008719461970031261 norm:0.002429589629173279 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.00860625971108675 norm:0.0022270684130489826 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.008508650586009026 norm:0.002055681310594082 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.008428137749433517 norm:0.0018540405435487628 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.008358310908079147 norm:0.0016817583236843348 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.00830765999853611 norm:0.0015317922225221992 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.00825502723455429 norm:0.0014094553189352155 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.008238716050982475 norm:0.0013028000248596072 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.008245059289038181 norm:0.0013116865884512663 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.008258243091404438 norm:0.0013418359449133277 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:17 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:27:07 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.037095025181770325 norm:0.013210589066147804 max memory_allocated 29268.02001953125 
[2025-03-02 13:27:57 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.027782373130321503 norm:0.00928572379052639 max memory_allocated 29268.02001953125 
[2025-03-02 13:28:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.023536864668130875 norm:0.006503320299088955 max memory_allocated 29268.02001953125 
[2025-03-02 13:29:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.022224318236112595 norm:0.005130962934345007 max memory_allocated 29268.02001953125 
[2025-03-02 13:30:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.02089959755539894 norm:0.0050294650718569756 max memory_allocated 29268.02001953125 
[2025-03-02 13:31:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.02032197266817093 norm:0.004952351097017527 max memory_allocated 29268.02001953125 
[2025-03-02 13:32:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.01989160105586052 norm:0.004922563675791025 max memory_allocated 29268.02001953125 
[2025-03-02 13:32:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.01935710199177265 norm:0.004779051057994366 max memory_allocated 29268.02001953125 
[2025-03-02 13:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.019094131886959076 norm:0.004663098603487015 max memory_allocated 29268.02001953125 
[2025-03-02 13:34:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.01884491741657257 norm:0.004307732917368412 max memory_allocated 29268.02001953125 
[2025-03-02 13:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.018694018945097923 norm:0.004397538956254721 max memory_allocated 29268.02001953125 
[2025-03-02 13:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.018764793872833252 norm:0.004477163311094046 max memory_allocated 29268.02001953125 
[2025-03-02 13:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.018474441021680832 norm:0.00415071239694953 max memory_allocated 29268.02001953125 
[2025-03-02 13:37:52 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.018461856991052628 norm:0.0039961617439985275 max memory_allocated 29268.02001953125 
[2025-03-02 13:38:42 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.018674036487936974 norm:0.00410526804625988 max memory_allocated 29268.02001953125 
[2025-03-02 13:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.018324745818972588 norm:0.003770071780309081 max memory_allocated 29268.02001953125 
[2025-03-02 13:40:21 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.01835968717932701 norm:0.0036823926493525505 max memory_allocated 29268.02001953125 
[2025-03-02 13:41:11 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.01837829314172268 norm:0.0038354084827005863 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:01 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.0183433648198843 norm:0.003599782707169652 max memory_allocated 29268.02001953125 
[2025-03-02 13:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.018292371183633804 norm:0.003560086013749242 max memory_allocated 29268.02001953125 
[2025-03-02 13:43:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:43:58 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.038085658103227615 norm:0.0031253243796527386 max memory_allocated 29268.43798828125 
[2025-03-02 13:44:48 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.028871571645140648 norm:0.0010824062628671527 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:37 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.024441732093691826 norm:0.0005598171264864504 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.022921577095985413 norm:0.0003370008780620992 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.02220659703016281 norm:0.00030041008722037077 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:06 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.021680228412151337 norm:0.00021003381698392332 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.021327465772628784 norm:0.0001949807337950915 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:45 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.02113090455532074 norm:0.00018071127124130726 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:34 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.021041763946413994 norm:0.00019156488997396082 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:24 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.020991628989577293 norm:0.00015909744251985103 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:13 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.020919326692819595 norm:0.00014429836301133037 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:03 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.020865514874458313 norm:0.00014132977230474353 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:52 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.02084096148610115 norm:0.00014883611584082246 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:42 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.020826902240514755 norm:0.0001507389679318294 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:31 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.02084335684776306 norm:0.0001644441217649728 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:21 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.02084052562713623 norm:0.00013987679267302155 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:10 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.02085155062377453 norm:0.00013630643661599606 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:00 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.02084636688232422 norm:0.00013983763346914202 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.02084418013691902 norm:0.00014561852731276304 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:39 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.020859945565462112 norm:0.00016458053141832352 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:00:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.0477302111685276 norm:0.006252712104469538 max memory_allocated 29268.62548828125 
[2025-03-02 14:01:36 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.036145828664302826 norm:0.001759636914357543 max memory_allocated 29268.62548828125 
[2025-03-02 14:02:25 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.030749408528208733 norm:0.0009722578106448054 max memory_allocated 29268.62548828125 
[2025-03-02 14:03:15 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.028870288282632828 norm:0.0006819004192948341 max memory_allocated 29268.62548828125 
[2025-03-02 14:04:04 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.02784024551510811 norm:0.0005206048372201622 max memory_allocated 29268.62548828125 
[2025-03-02 14:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.02719474956393242 norm:0.00044601867557503283 max memory_allocated 29268.62548828125 
[2025-03-02 14:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.026841867715120316 norm:0.00039373987237922847 max memory_allocated 29268.62548828125 
[2025-03-02 14:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.026642248034477234 norm:0.0003123833448626101 max memory_allocated 29268.62548828125 
[2025-03-02 14:07:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.02653537504374981 norm:0.0002949794288724661 max memory_allocated 29268.62548828125 
[2025-03-02 14:08:12 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.0264514721930027 norm:0.0002717918832786381 max memory_allocated 29268.62548828125 
[2025-03-02 14:09:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.026389239355921745 norm:0.00024641529307700694 max memory_allocated 29268.62548828125 
[2025-03-02 14:09:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.026333915069699287 norm:0.00020018430950585753 max memory_allocated 29268.62548828125 
[2025-03-02 14:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.02628117799758911 norm:0.00020090409088879824 max memory_allocated 29268.62548828125 
[2025-03-02 14:11:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.02630065195262432 norm:0.00022136615007184446 max memory_allocated 29268.62548828125 
[2025-03-02 14:12:19 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.026309525594115257 norm:0.00022985685791354626 max memory_allocated 29268.62548828125 
[2025-03-02 14:13:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.026262175291776657 norm:0.00018971707322634757 max memory_allocated 29268.62548828125 
[2025-03-02 14:13:58 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.026266103610396385 norm:0.0001908027334138751 max memory_allocated 29268.62548828125 
[2025-03-02 14:14:48 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.02626125141978264 norm:0.00017092486086767167 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:37 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.026235733181238174 norm:0.00014953012578189373 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:27 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.02621340937912464 norm:0.00015920157602522522 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:17:35 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.05571720004081726 norm:0.004984197206795216 max memory_allocated 29268.81298828125 
[2025-03-02 14:18:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.041573189198970795 norm:0.0015482292510569096 max memory_allocated 29268.81298828125 
[2025-03-02 14:19:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.03527223318815231 norm:0.000817852676846087 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:03 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.033021681010723114 norm:0.0005271790432743728 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.03179208189249039 norm:0.0003917407593689859 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.031123412773013115 norm:0.00032342394115403295 max memory_allocated 29268.81298828125 
[2025-03-02 14:22:32 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.03074083849787712 norm:0.0002845473645720631 max memory_allocated 29268.81298828125 
[2025-03-02 14:23:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.03050544671714306 norm:0.0002504639560356736 max memory_allocated 29268.81298828125 
[2025-03-02 14:24:11 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.030355870723724365 norm:0.0002197936555603519 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:01 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.030245045199990273 norm:0.0001981645036721602 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.03018796071410179 norm:0.00018598433234728873 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:40 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.0301508828997612 norm:0.00020952844351995736 max memory_allocated 29268.81298828125 
[2025-03-02 14:27:30 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.030109286308288574 norm:0.0001909397979034111 max memory_allocated 29268.81298828125 
[2025-03-02 14:28:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.030034665018320084 norm:0.00016483705257996917 max memory_allocated 29268.81298828125 
[2025-03-02 14:29:09 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.029999569058418274 norm:0.00017571520584169775 max memory_allocated 29268.81298828125 
[2025-03-02 14:29:59 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.02997758984565735 norm:0.0001674015074968338 max memory_allocated 29268.81298828125 
[2025-03-02 14:30:48 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.029951009899377823 norm:0.00016728363698348403 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:38 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.030015025287866592 norm:0.00020976824453100562 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:27 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.029999900609254837 norm:0.0001918033667607233 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:17 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.0299675390124321 norm:0.00015972208348102868 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:34:25 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.065569669008255 norm:0.0021627272944897413 max memory_allocated 29269.00048828125 
[2025-03-02 14:35:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.05153913050889969 norm:0.0013085963437333703 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:03 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.04363936185836792 norm:0.0010612417245283723 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.04061342030763626 norm:0.0009529796661809087 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.039089515805244446 norm:0.000825626659207046 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.03821266070008278 norm:0.0006983642233535647 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.037769343703985214 norm:0.0006667962297797203 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.03746451437473297 norm:0.0007308698259294033 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:00 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.03722965717315674 norm:0.0006363338325172663 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.037055760622024536 norm:0.0007780282758176327 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:39 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.03698788210749626 norm:0.0008660632302053273 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:29 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.03690752759575844 norm:0.0008716440643183887 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:19 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.03678950294852257 norm:0.0008225575438700616 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:08 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.0366949737071991 norm:0.0008124731248244643 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:58 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.0366753526031971 norm:0.0008171693771146238 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.036691807210445404 norm:0.0008017215877771378 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.03670133277773857 norm:0.0007972632884047925 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.036663804203271866 norm:0.000731762673240155 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.036694902926683426 norm:0.0007499500643461943 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:05 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.0366591215133667 norm:0.0007015806040726602 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:51:13 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.058963872492313385 norm:0.0014150659553706646 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:03 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.04932629317045212 norm:0.0006575541337952018 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:52 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.04351809620857239 norm:0.0003389657649677247 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:42 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.04152441769838333 norm:0.0002125714672729373 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:32 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.04055790230631828 norm:0.0001666325406404212 max memory_allocated 29269.18798828125 
[2025-03-02 14:55:21 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.03996070846915245 norm:0.00015037092089187354 max memory_allocated 29269.18798828125 
[2025-03-02 14:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.03968562185764313 norm:0.00014657271094620228 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.039518654346466064 norm:0.0001417333842255175 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:50 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.039420753717422485 norm:0.0001350017701042816 max memory_allocated 29269.18798828125 
[2025-03-02 14:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.039377421140670776 norm:0.00013307368499226868 max memory_allocated 29269.18798828125 
[2025-03-02 14:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.0393143855035305 norm:0.00012974103447049856 max memory_allocated 29269.18798828125 
[2025-03-02 15:00:19 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.039279550313949585 norm:0.00013032903370913118 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:09 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.0392577201128006 norm:0.00013161574315745384 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.03922716900706291 norm:0.00012953674013260752 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:48 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.039210960268974304 norm:0.0001316764100920409 max memory_allocated 29269.18798828125 
[2025-03-02 15:03:38 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.03919220343232155 norm:0.00013009218673687428 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:27 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.039164699614048004 norm:0.00012640896602533758 max memory_allocated 29269.18798828125 
[2025-03-02 15:05:17 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.03916265442967415 norm:0.00013078947085887194 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:07 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.0391719788312912 norm:0.00012872176012024283 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:56 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.03916337713599205 norm:0.00013222415873315185 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:11 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:08:04 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.0638323426246643 norm:0.0016477478202432394 max memory_allocated 29269.37548828125 
[2025-03-02 15:08:54 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.05354931578040123 norm:0.000673870905302465 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:44 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.047994378954172134 norm:0.00035324631608091295 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:33 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.045877326279878616 norm:0.0002507028984837234 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:23 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.044794343411922455 norm:0.00020992939244024456 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:13 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.04418976977467537 norm:0.000182299452717416 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:02 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.04384518414735794 norm:0.0001680206914898008 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:52 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.043661437928676605 norm:0.000160203839186579 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:42 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.04357017204165459 norm:0.00016042438801378012 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.04351421445608139 norm:0.0001501234364695847 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.04346686229109764 norm:0.00014976877719163895 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:11 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.04341408237814903 norm:0.00015961540339048952 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.04338992387056351 norm:0.00014428998110815883 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.04336906969547272 norm:0.00014917284715920687 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:40 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.043366689234972 norm:0.00017466441204305738 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.04333706945180893 norm:0.0001544089027447626 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.04331977665424347 norm:0.00016467709792777896 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.04329628869891167 norm:0.00015128085215110332 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:58 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.04329962283372879 norm:0.00015009849448688328 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:48 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.043296344578266144 norm:0.0001479595375712961 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.065823495388031 norm:0.0013179300585761666 max memory_allocated 29269.56298828125 
[2025-03-02 15:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.056791361421346664 norm:0.0005740064079873264 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.0512537844479084 norm:0.0002979288110509515 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.049242302775382996 norm:0.00019611559400800616 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.048323795199394226 norm:0.0001618358219275251 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.047749750316143036 norm:0.0001415018195984885 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:53 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.04746810719370842 norm:0.00013033651339355856 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:43 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.04731772094964981 norm:0.00012793084897566587 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.0472194142639637 norm:0.00012046206393279135 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:22 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.04717164859175682 norm:0.00012126695946790278 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:12 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.04713026434183121 norm:0.00011692856787703931 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:02 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.04709713160991669 norm:0.00011658236326184124 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.047056932002305984 norm:0.00011990634084213525 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.047043316066265106 norm:0.00012065824557794258 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.04703029617667198 norm:0.00011767641990445554 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.04700703173875809 norm:0.00011817678023362532 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.04698754474520683 norm:0.00011775035090977326 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:00 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.04699455201625824 norm:0.00011818786151707172 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:49 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.04697335511445999 norm:0.0001191689952975139 max memory_allocated 29269.56298828125 
[2025-03-02 15:40:39 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.04696448892354965 norm:0.00011594712850637734 max memory_allocated 29269.56298828125 
[2025-03-02 15:40:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:41:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.06882204860448837 norm:0.001139979693107307 max memory_allocated 29269.75048828125 
[2025-03-02 15:42:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.06024612486362457 norm:0.0004729594220407307 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:26 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.054895494133234024 norm:0.00025974877644330263 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.052922964096069336 norm:0.00018181500490754843 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.05198146775364876 norm:0.00014978565741330385 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:55 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.05151215195655823 norm:0.00013481700443662703 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.05124489590525627 norm:0.00012156191223766655 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.051108650863170624 norm:0.00011508772877277806 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:24 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.05101201683282852 norm:0.00011743393406504765 max memory_allocated 29269.75048828125 
[2025-03-02 15:49:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.05094458535313606 norm:0.00011211942182853818 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.05090305954217911 norm:0.00010635900980560109 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.05087342485785484 norm:0.00010634438513079658 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:42 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.05084716156125069 norm:0.00010242163989460096 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:31 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.05083858221769333 norm:0.00010336519335396588 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:20 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.05081646144390106 norm:0.00010351449600420892 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:10 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.05080849677324295 norm:0.0001046335746650584 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:59 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.05080682039260864 norm:0.00010455105802975595 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:49 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.05080621317028999 norm:0.00010412830306449905 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:38 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.050784505903720856 norm:0.00010464087245054543 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:28 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.050783220678567886 norm:0.00010591647151159123 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:42 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:58:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.0744030624628067 norm:0.0012078613508492708 max memory_allocated 29269.93798828125 
[2025-03-02 15:59:25 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.06545702368021011 norm:0.0005291511188261211 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.05943383648991585 norm:0.0002786186523735523 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:04 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.05741135776042938 norm:0.0001830781257012859 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:54 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.05648704618215561 norm:0.00014565885066986084 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:43 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.055936042219400406 norm:0.0001265385653823614 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:33 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.05569098889827728 norm:0.00011870158778037876 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:22 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.055577442049980164 norm:0.00011704978533089161 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:12 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.055467549711465836 norm:0.00011268224625382572 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.055408865213394165 norm:0.00011099305265815929 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.05534648895263672 norm:0.00010849293175851926 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.05532045289874077 norm:0.00010980363003909588 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.05529657378792763 norm:0.00010647455928847194 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.05526801198720932 norm:0.00010470453707966954 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.055242642760276794 norm:0.00010487619147170335 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:58 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.05524003878235817 norm:0.00010473612928763032 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:48 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.055224962532520294 norm:0.00010423780622659251 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:37 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.055202458053827286 norm:0.00010575103806331754 max memory_allocated 29269.93798828125 
[2025-03-02 16:13:27 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.05520067736506462 norm:0.00010640975960996002 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:16 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.05519919469952583 norm:0.00010658748215064406 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:15:24 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.07767218351364136 norm:0.0009757986990734935 max memory_allocated 29270.12548828125 
[2025-03-02 16:16:14 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.06929821521043777 norm:0.00044706155313178897 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:04 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.06325878202915192 norm:0.0002625340421218425 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.06122623756527901 norm:0.00018910731887444854 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:43 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.060322608798742294 norm:0.0001554101036163047 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:33 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.059785809367895126 norm:0.00013807692448608577 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.05952413007616997 norm:0.00013002390915062279 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.05934955179691315 norm:0.00012499705189839005 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:02 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.059262797236442566 norm:0.00012180069461464882 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.05920037627220154 norm:0.00011667751823551953 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:41 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.059157077223062515 norm:0.0001141321481554769 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:31 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.05911276116967201 norm:0.00011230053496547043 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.059077441692352295 norm:0.00011228195216972381 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.05905849486589432 norm:0.00011081735283369198 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:00 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.05902903899550438 norm:0.0001105589180951938 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.05899762734770775 norm:0.00011053134221583605 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.05898148939013481 norm:0.00011060157703468576 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:29 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.05896289646625519 norm:0.00010950050636893138 max memory_allocated 29270.12548828125 
[2025-03-02 16:30:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.058960530906915665 norm:0.0001105226474464871 max memory_allocated 29270.12548828125 
[2025-03-02 16:31:08 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.0589311346411705 norm:0.00010849509271793067 max memory_allocated 29270.12548828125 
[2025-03-02 16:31:22 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:32:16 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.08050058037042618 norm:0.0007337944698520005 max memory_allocated 29270.31298828125 
[2025-03-02 16:33:06 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.0726449117064476 norm:0.00037731765769422054 max memory_allocated 29270.31298828125 
[2025-03-02 16:33:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.06681990623474121 norm:0.00023949101159814745 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.06476712226867676 norm:0.00017861553351394832 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.06376013904809952 norm:0.00014899452798999846 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.06317188590765 norm:0.00013529849820770323 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.0628424659371376 norm:0.000122456083772704 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.06265730410814285 norm:0.00011642315075732768 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.06254369020462036 norm:0.00011301186168566346 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.06246119365096092 norm:0.00011040348908863962 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.062388841062784195 norm:0.00010889943223446608 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.062343720346689224 norm:0.00010584882693365216 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.06232413277029991 norm:0.00010450480476720259 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.062309034168720245 norm:0.00010370325617259368 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.062298040837049484 norm:0.00010091553122038022 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.06226380169391632 norm:0.00010019588808063418 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.0622362419962883 norm:0.00010090129944728687 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.0622236393392086 norm:0.00010080885112984106 max memory_allocated 29270.31298828125 
[2025-03-02 16:47:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.06221028417348862 norm:0.00010093522723764181 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.06218825653195381 norm:9.9879689514637e-05 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.08610352873802185 norm:0.0011508335592225194 max memory_allocated 29270.50048828125 
[2025-03-02 16:49:57 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.07727377116680145 norm:0.0005688150995410979 max memory_allocated 29270.50048828125 
[2025-03-02 16:50:47 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.07081927359104156 norm:0.00033055810490623116 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.06867115199565887 norm:0.00023179502750281245 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:26 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.06758331507444382 norm:0.00018508610082790256 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:16 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.06695687770843506 norm:0.00015630919369868934 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:06 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.06662892550230026 norm:0.000140005984576419 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:55 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.06645199656486511 norm:0.00012841098941862583 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:45 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.06635840237140656 norm:0.00012352975318208337 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:35 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.06627944111824036 norm:0.00011770251148846 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:24 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.06621310114860535 norm:0.0001136790233431384 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:14 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.06615888327360153 norm:0.00011190587974851951 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:04 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.06611182540655136 norm:0.00010917955660261214 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.06606648862361908 norm:0.00010846809891518205 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:43 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.06604578346014023 norm:0.00010734520037658513 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:33 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.06602951884269714 norm:0.00010898170148720965 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:22 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.06600993126630783 norm:0.00010817809379659593 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:12 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.06597443670034409 norm:0.00010523811943130568 max memory_allocated 29270.50048828125 
[2025-03-02 17:04:02 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.06594844907522202 norm:0.00010577090142760426 max memory_allocated 29270.50048828125 
[2025-03-02 17:04:51 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.06593814492225647 norm:0.0001065690812538378 max memory_allocated 29270.50048828125 
[2025-03-02 17:05:06 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:05:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.08857650309801102 norm:0.0008322071516886353 max memory_allocated 29270.68798828125 
[2025-03-02 17:06:49 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.08110115677118301 norm:0.0003714051563292742 max memory_allocated 29270.68798828125 
[2025-03-02 17:07:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.07578302174806595 norm:0.0002490973274689168 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.07375587522983551 norm:0.0001955726620508358 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:17 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.07263442128896713 norm:0.00016508583212271333 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.07197627425193787 norm:0.00014997737889643759 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:56 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.07161727547645569 norm:0.00013877919991500676 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:46 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.07141873240470886 norm:0.00012772053014487028 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.07130560278892517 norm:0.00012036289990646765 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:25 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.07121708989143372 norm:0.00011489567987155169 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:15 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.07113471627235413 norm:0.00011066757724620402 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:04 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.07105103880167007 norm:0.00010775576811283827 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:54 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.07102373987436295 norm:0.0001048669291776605 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:43 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.070986308157444 norm:0.00010316356201656163 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:33 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.07095696032047272 norm:0.0001029928243951872 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:22 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.07094167917966843 norm:0.00010416255099698901 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:12 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.07092509418725967 norm:0.00010324730101274326 max memory_allocated 29270.68798828125 
[2025-03-02 17:20:01 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.07088654488325119 norm:0.00010159552766708657 max memory_allocated 29270.68798828125 
[2025-03-02 17:20:51 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.07087439298629761 norm:0.00010190095053985715 max memory_allocated 29270.68798828125 
[2025-03-02 17:21:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.07086987048387527 norm:9.948547085514292e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:21:55 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:22:48 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.09245222061872482 norm:0.0011541679268702865 max memory_allocated 29270.87548828125 
[2025-03-02 17:23:38 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.0857297033071518 norm:0.0005569427157752216 max memory_allocated 29270.87548828125 
[2025-03-02 17:24:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.08051711320877075 norm:0.0003347891033627093 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:17 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.07867220789194107 norm:0.0002378714707447216 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.07754752039909363 norm:0.00018327597354073077 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:56 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.07691192626953125 norm:0.00014744699001312256 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:45 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.07663477957248688 norm:0.00012692711607087404 max memory_allocated 29270.87548828125 
[2025-03-02 17:28:35 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.07649310678243637 norm:0.0001174163116957061 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:24 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.07638709247112274 norm:0.0001094475228455849 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:14 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.07632418721914291 norm:0.00010457151074660942 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.0762791857123375 norm:0.00010170770838158205 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.07623286545276642 norm:9.83026038738899e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.07618879526853561 norm:9.655635949457064e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:33:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.07615161687135696 norm:9.5678711659275e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:21 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.07612381875514984 norm:9.40117533900775e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:11 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.07610061764717102 norm:9.447480988455936e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:01 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.07608217000961304 norm:9.503880573902279e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:50 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.07606659829616547 norm:9.498417057329789e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:37:40 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.07605382800102234 norm:9.51225811149925e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:38:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.07605357468128204 norm:9.600476187188178e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:38:44 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:39:37 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.1017058938741684 norm:0.00154590280726552 max memory_allocated 29271.06298828125 
[2025-03-02 17:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.09360093623399734 norm:0.0007006258820183575 max memory_allocated 29271.06298828125 
[2025-03-02 17:41:16 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.08736183494329453 norm:0.0004072430601809174 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:06 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.08527520298957825 norm:0.00028289525653235614 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:55 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.08408936858177185 norm:0.00021395696967374533 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:45 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.08345998078584671 norm:0.00017447893333155662 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:34 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.08315819501876831 norm:0.00014977410319261253 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:24 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.08298623561859131 norm:0.0001331229868810624 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:13 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.08287370204925537 norm:0.0001225444138981402 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:03 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.0828038901090622 norm:0.00011547350732143968 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.0827367976307869 norm:0.0001104211260098964 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:42 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.08267419040203094 norm:0.0001076222033589147 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.08262751251459122 norm:0.00010611295874696225 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.08258598297834396 norm:0.00010192014451604337 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.08254380524158478 norm:0.00010079328785650432 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.0825120061635971 norm:9.881827281787992e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:49 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.08248663693666458 norm:9.903879254125059e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.08247436583042145 norm:9.881649020826444e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:54:28 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.08245722949504852 norm:9.790265175979584e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.08243322372436523 norm:9.895151742966846e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:55:32 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:56:26 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.11177127808332443 norm:0.0014609612990170717 max memory_allocated 29271.25048828125 
[2025-03-02 17:57:15 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.10315296798944473 norm:0.000627944536972791 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:05 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.09655742347240448 norm:0.00035038008354604244 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:54 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.0943705216050148 norm:0.00024779452360235155 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.09315699338912964 norm:0.00019644769781734794 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.09254904836416245 norm:0.00016561448865104467 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.09227437525987625 norm:0.0001494048337917775 max memory_allocated 29271.25048828125 
[2025-03-02 18:02:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.09211637079715729 norm:0.00013980039511807263 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.09200112521648407 norm:0.00013135289191268384 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.09189767390489578 norm:0.00012573369895108044 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:41 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.09180185198783875 norm:0.000122072160593234 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.09173848479986191 norm:0.000119488024211023 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.09166287630796432 norm:0.0001166203073807992 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:09 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.09160434454679489 norm:0.00011562318104552105 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.09156031906604767 norm:0.00011378874478396028 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:48 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.09153205156326294 norm:0.00011244061170145869 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:38 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.09149881452322006 norm:0.00011137835099361837 max memory_allocated 29271.25048828125 
[2025-03-02 18:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.09147639572620392 norm:0.00011115279630757868 max memory_allocated 29271.25048828125 
[2025-03-02 18:11:17 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.0914599746465683 norm:0.0001110649318434298 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.09145931899547577 norm:0.00011292772978777066 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:13:15 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.12193523347377777 norm:0.0009824562584981322 max memory_allocated 29271.43798828125 
[2025-03-02 18:14:04 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.11378428339958191 norm:0.00045736817992292345 max memory_allocated 29271.43798828125 
[2025-03-02 18:14:54 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.10687921196222305 norm:0.0002779056958388537 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:43 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.10457088053226471 norm:0.00020544693688862026 max memory_allocated 29271.43798828125 
[2025-03-02 18:16:33 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.10338515043258667 norm:0.00017207523342221975 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.10283742100000381 norm:0.0001475220051361248 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.10256892442703247 norm:0.00013180001405999064 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.10236750543117523 norm:0.00012481615704018623 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.10226978361606598 norm:0.00012242479715496302 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.10217613726854324 norm:0.0001190277689602226 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:30 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.10209976136684418 norm:0.00011313623690512031 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:19 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.10203111916780472 norm:0.00011222360626561567 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.101978600025177 norm:0.00010970496805384755 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:58 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.10194921493530273 norm:0.00010840612958418205 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.10190820693969727 norm:0.00010935562022496015 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:37 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.10187225043773651 norm:0.00010767905041575432 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:27 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.1018381342291832 norm:0.00010787285282276571 max memory_allocated 29271.43798828125 
[2025-03-02 18:27:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.10181032866239548 norm:0.00010669996845535934 max memory_allocated 29271.43798828125 
[2025-03-02 18:28:06 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.10178427398204803 norm:0.00010752162779681385 max memory_allocated 29271.43798828125 
[2025-03-02 18:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.10176243633031845 norm:0.00010566272248979658 max memory_allocated 29271.43798828125 
[2025-03-02 18:29:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:30:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.13563960790634155 norm:0.000996729708276689 max memory_allocated 29271.62548828125 
[2025-03-02 18:30:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.12592317163944244 norm:0.0004822860937565565 max memory_allocated 29271.62548828125 
[2025-03-02 18:31:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.11805123090744019 norm:0.0002852887846529484 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:33 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.11557569354772568 norm:0.00021358384401537478 max memory_allocated 29271.62548828125 
[2025-03-02 18:33:23 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.11430594325065613 norm:0.00018023191660176963 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:13 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.11377914994955063 norm:0.00015841556887608021 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:02 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.1135026216506958 norm:0.00014506836305372417 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:52 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.11330918222665787 norm:0.00013334226969163865 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:42 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.11315296590328217 norm:0.00012834303197450936 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.11302272230386734 norm:0.0001225179003085941 max memory_allocated 29271.62548828125 
[2025-03-02 18:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.11292710900306702 norm:0.00011974239896517247 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.11283616721630096 norm:0.00011809246643679217 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:00 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.11277425289154053 norm:0.00011485240247566253 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.11271290481090546 norm:0.0001150242387666367 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:40 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.11268065869808197 norm:0.00011394500324968249 max memory_allocated 29271.62548828125 
[2025-03-02 18:42:29 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.11265147477388382 norm:0.00011329101835144684 max memory_allocated 29271.62548828125 
[2025-03-02 18:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.11261029541492462 norm:0.00011153737432323396 max memory_allocated 29271.62548828125 
[2025-03-02 18:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.11256380379199982 norm:0.00011007045395672321 max memory_allocated 29271.62548828125 
[2025-03-02 18:44:58 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.11252360045909882 norm:0.00011025129788322374 max memory_allocated 29271.62548828125 
[2025-03-02 18:45:48 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.11249484866857529 norm:0.00010973057942464948 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:03 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:46:56 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.15344475209712982 norm:0.0011547338217496872 max memory_allocated 29271.81298828125 
[2025-03-02 18:47:46 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.1424853801727295 norm:0.0006091085379011929 max memory_allocated 29271.81298828125 
[2025-03-02 18:48:36 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.1335630863904953 norm:0.0003847327025141567 max memory_allocated 29271.81298828125 
[2025-03-02 18:49:25 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.13084036111831665 norm:0.0002840083616320044 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:15 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.12943711876869202 norm:0.0002238911110907793 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:04 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.12888620793819427 norm:0.00019252595666330308 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:54 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.12859231233596802 norm:0.00017016357742249966 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:44 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.12837588787078857 norm:0.00016012285777833313 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:34 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.12821075320243835 norm:0.00015324044215958565 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.12807025015354156 norm:0.00014374442980624735 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:13 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.12796911597251892 norm:0.00013856033910997212 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:03 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.12788227200508118 norm:0.0001345231430605054 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.1278233528137207 norm:0.0001328090438619256 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:42 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.12774085998535156 norm:0.00013137135829310864 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.12768438458442688 norm:0.00013071941793896258 max memory_allocated 29271.81298828125 
[2025-03-02 18:59:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.12762175500392914 norm:0.00012831008643843234 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.12756475806236267 norm:0.00012669397983700037 max memory_allocated 29271.81298828125 
[2025-03-02 19:01:01 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.12751121819019318 norm:0.00012625724775716662 max memory_allocated 29271.81298828125 
[2025-03-02 19:01:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.12747198343276978 norm:0.0001252227375516668 max memory_allocated 29271.81298828125 
[2025-03-02 19:02:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.12743651866912842 norm:0.00012518532457761467 max memory_allocated 29271.81298828125 
[2025-03-02 19:02:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:03:48 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.1722346842288971 norm:0.0011011473834514618 max memory_allocated 29272.00048828125 
[2025-03-02 19:04:37 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.1610165536403656 norm:0.0005809587310068309 max memory_allocated 29272.00048828125 
[2025-03-02 19:05:27 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.151542067527771 norm:0.00036936893593519926 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:17 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.14867964386940002 norm:0.00028766359901055694 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:06 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.147300124168396 norm:0.00024031980137806386 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:56 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.1467776745557785 norm:0.00021890732750762254 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:46 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.1464715301990509 norm:0.00020222285820636898 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:35 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.14625079929828644 norm:0.0001918142952490598 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:25 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.14605963230133057 norm:0.00018592618289403617 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:15 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.14593994617462158 norm:0.00018330698367208242 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:04 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.14580431580543518 norm:0.00017915530770551413 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:54 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.14568646252155304 norm:0.00017434275650884956 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:44 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.14557433128356934 norm:0.00017216290871147066 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:33 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.1454814374446869 norm:0.0001673613442108035 max memory_allocated 29272.00048828125 
[2025-03-02 19:15:23 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.14539578557014465 norm:0.00016567415150348097 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:13 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.145338237285614 norm:0.00016546710685361177 max memory_allocated 29272.00048828125 
[2025-03-02 19:17:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.14529049396514893 norm:0.00016571729793213308 max memory_allocated 29272.00048828125 
[2025-03-02 19:17:52 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.14524269104003906 norm:0.00016162858810275793 max memory_allocated 29272.00048828125 
[2025-03-02 19:18:42 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.14520159363746643 norm:0.00016224102000705898 max memory_allocated 29272.00048828125 
[2025-03-02 19:19:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.14516638219356537 norm:0.00016073790902737528 max memory_allocated 29272.00048828125 
[2025-03-02 19:19:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:20:40 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.19530165195465088 norm:0.0013278564438223839 max memory_allocated 29272.18798828125 
[2025-03-02 19:21:29 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.18321198225021362 norm:0.0006839582929387689 max memory_allocated 29272.18798828125 
[2025-03-02 19:22:19 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.1730908453464508 norm:0.00041674741078168154 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:09 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.16999199986457825 norm:0.0003254908660892397 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:58 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.1684747040271759 norm:0.0002700647455640137 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:48 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.16793565452098846 norm:0.00024272999144159257 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:38 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.16763493418693542 norm:0.00022387514763977379 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.1673591285943985 norm:0.0002085594751406461 max memory_allocated 29272.18798828125 
[2025-03-02 19:27:17 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.16715320944786072 norm:0.0002021930122282356 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:07 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.16700522601604462 norm:0.00019619637168943882 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.16687420010566711 norm:0.00018839935364667326 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:46 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.16674160957336426 norm:0.000185124488780275 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.16661298274993896 norm:0.00018162398191634566 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.16650152206420898 norm:0.00017726043006405234 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.16642899811267853 norm:0.00017524998111184686 max memory_allocated 29272.18798828125 
[2025-03-02 19:33:05 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.16634207963943481 norm:0.00017302710330113769 max memory_allocated 29272.18798828125 
[2025-03-02 19:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.1662748157978058 norm:0.00017023914551828057 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.16621538996696472 norm:0.0001680219720583409 max memory_allocated 29272.18798828125 
[2025-03-02 19:35:34 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.16615957021713257 norm:0.000167520935065113 max memory_allocated 29272.18798828125 
[2025-03-02 19:36:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.16610461473464966 norm:0.000165187448146753 max memory_allocated 29272.18798828125 
[2025-03-02 19:36:38 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.21714162826538086 norm:0.001505206455476582 max memory_allocated 29272.37548828125 
[2025-03-02 19:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.2051175832748413 norm:0.0007815008866600692 max memory_allocated 29272.37548828125 
[2025-03-02 19:39:11 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.19468575716018677 norm:0.0004905525711365044 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:01 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.19135522842407227 norm:0.00035569677129387856 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.1898629367351532 norm:0.00028051971457898617 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:40 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.18933795392513275 norm:0.0002388524153502658 max memory_allocated 29272.37548828125 
[2025-03-02 19:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.18901365995407104 norm:0.00021443728473968804 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.1887824684381485 norm:0.00020165106980130076 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.18855690956115723 norm:0.0001924689277075231 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.18842282891273499 norm:0.00017962748825084418 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:49 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.18824206292629242 norm:0.0001733627577777952 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.18808570504188538 norm:0.00016945073730312288 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.18798746168613434 norm:0.0001671725622145459 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:18 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.187881201505661 norm:0.00016395187412854284 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.18777722120285034 norm:0.00016301473078783602 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:57 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.18771710991859436 norm:0.00016343726019840688 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.18765628337860107 norm:0.0001616294466657564 max memory_allocated 29272.37548828125 
[2025-03-02 19:51:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.18758857250213623 norm:0.00016077457985375077 max memory_allocated 29272.37548828125 
[2025-03-02 19:52:26 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.1875319480895996 norm:0.00016019438044168055 max memory_allocated 29272.37548828125 
[2025-03-02 19:53:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.18748514354228973 norm:0.0001587177684996277 max memory_allocated 29272.37548828125 
[2025-03-02 19:53:30 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:54:23 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.244057759642601 norm:0.0010983324609696865 max memory_allocated 29272.56298828125 
[2025-03-02 19:55:13 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.23111267387866974 norm:0.0005999132408760488 max memory_allocated 29272.56298828125 
[2025-03-02 19:56:02 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.2194182276725769 norm:0.00037837063428014517 max memory_allocated 29272.56298828125 
[2025-03-02 19:56:52 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.2159315049648285 norm:0.00029464723775163293 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:41 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.2145247608423233 norm:0.00025182735407724977 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:31 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.21400834619998932 norm:0.00022728179465048015 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.21364212036132812 norm:0.00020981786656193435 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.21336990594863892 norm:0.00020419791690073907 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:00 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.21311329305171967 norm:0.00018957266001962125 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.212968647480011 norm:0.00018436289974488318 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.21277925372123718 norm:0.0001839105534600094 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.21261736750602722 norm:0.0001792239781934768 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.2124805748462677 norm:0.00017497094813734293 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:07 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.21237021684646606 norm:0.00017343199579045177 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.2122717946767807 norm:0.0001700977300060913 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:46 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.2122010439634323 norm:0.0001706950570223853 max memory_allocated 29272.56298828125 
[2025-03-02 20:07:36 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.2121223360300064 norm:0.00016909711121115834 max memory_allocated 29272.56298828125 
[2025-03-02 20:08:26 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.21205443143844604 norm:0.00016826284991111606 max memory_allocated 29272.56298828125 
[2025-03-02 20:09:15 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.2119796872138977 norm:0.00016809263615868986 max memory_allocated 29272.56298828125 
[2025-03-02 20:10:05 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.21193504333496094 norm:0.00016685001901350915 max memory_allocated 29272.56298828125 
[2025-03-02 20:10:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:11:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.27006715536117554 norm:0.001280909520573914 max memory_allocated 29272.75048828125 
[2025-03-02 20:12:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.256626695394516 norm:0.0005810011643916368 max memory_allocated 29272.75048828125 
[2025-03-02 20:12:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.24446800351142883 norm:0.00034281809348613024 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:41 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.24084916710853577 norm:0.0002619533333927393 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.2395232617855072 norm:0.0002231223916169256 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:20 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.23903223872184753 norm:0.0002028184972004965 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:10 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.2386959195137024 norm:0.00019111164147034287 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.23845481872558594 norm:0.000181851617526263 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:49 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.23826314508914948 norm:0.00017678792937658727 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:39 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.23809370398521423 norm:0.00017352236318401992 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.23792192339897156 norm:0.0001704803726170212 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.23776713013648987 norm:0.00016746856272220612 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.23765021562576294 norm:0.00016557068738620728 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.2375512719154358 norm:0.00016370824596378952 max memory_allocated 29272.75048828125 
[2025-03-02 20:22:47 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.237457275390625 norm:0.00016199624224100262 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:36 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.23738418519496918 norm:0.0001617241359781474 max memory_allocated 29272.75048828125 
[2025-03-02 20:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.23730503022670746 norm:0.00016069129924289882 max memory_allocated 29272.75048828125 
[2025-03-02 20:25:15 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.23722201585769653 norm:0.0001590596220921725 max memory_allocated 29272.75048828125 
[2025-03-02 20:26:05 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.2371523082256317 norm:0.00015784385323058814 max memory_allocated 29272.75048828125 
[2025-03-02 20:26:54 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.2371121197938919 norm:0.00015825167065486312 max memory_allocated 29272.75048828125 
[2025-03-02 20:27:08 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:28:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.30410322546958923 norm:0.0010198497911915183 max memory_allocated 29272.93798828125 
[2025-03-02 20:28:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.2888198792934418 norm:0.0005306023522280157 max memory_allocated 29272.93798828125 
[2025-03-02 20:29:42 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.2746976613998413 norm:0.0003409143246244639 max memory_allocated 29272.93798828125 
[2025-03-02 20:30:31 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.27069950103759766 norm:0.00027098425198346376 max memory_allocated 29272.93798828125 
[2025-03-02 20:31:21 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.2692891061306 norm:0.00023557135136798024 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:11 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.268721342086792 norm:0.00021585372451227158 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:00 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.268354594707489 norm:0.00020515630603767931 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:50 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.2680701017379761 norm:0.00019739105482585728 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:40 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.26784348487854004 norm:0.00019209945457987487 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:29 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.267622172832489 norm:0.00018623164214659482 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:19 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.26741769909858704 norm:0.000183980941073969 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:09 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.26723524928092957 norm:0.00017991567438002676 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:58 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.2670937478542328 norm:0.00018257048213854432 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:48 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.266967236995697 norm:0.00018172498675994575 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:38 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.2668452560901642 norm:0.00018195809388998896 max memory_allocated 29272.93798828125 
[2025-03-02 20:40:27 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.2667626440525055 norm:0.00018147194350603968 max memory_allocated 29272.93798828125 
[2025-03-02 20:41:17 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.266668438911438 norm:0.00017994899826589972 max memory_allocated 29272.93798828125 
[2025-03-02 20:42:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.266589492559433 norm:0.00017716200090944767 max memory_allocated 29272.93798828125 
[2025-03-02 20:42:57 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.2665000557899475 norm:0.00017610006034374237 max memory_allocated 29272.93798828125 
[2025-03-02 20:43:46 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.2664478123188019 norm:0.0001766383065842092 max memory_allocated 29272.93798828125 
[2025-03-02 20:44:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:44:54 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.33672767877578735 norm:0.0012363300193101168 max memory_allocated 29273.12548828125 
[2025-03-02 20:45:44 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.3202255368232727 norm:0.0006149036926217377 max memory_allocated 29273.12548828125 
[2025-03-02 20:46:34 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.30541712045669556 norm:0.0004584732814691961 max memory_allocated 29273.12548828125 
[2025-03-02 20:47:24 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.30106401443481445 norm:0.00034571101423352957 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:13 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.2995976507663727 norm:0.00030663947109133005 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:03 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.2990570664405823 norm:0.00030026043532416224 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:53 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.29868027567863464 norm:0.00027355761267244816 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:42 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.29836395382881165 norm:0.0002562596055213362 max memory_allocated 29273.12548828125 
[2025-03-02 20:51:32 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.2981460988521576 norm:0.0002891185285989195 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:22 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.29787904024124146 norm:0.0003393034276086837 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:11 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.29768580198287964 norm:0.0002978925476782024 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.29748135805130005 norm:0.00025768677005544305 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:51 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.2973232865333557 norm:0.00023704470368102193 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.29723647236824036 norm:0.00023483844415750355 max memory_allocated 29273.12548828125 
[2025-03-02 20:56:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.29715943336486816 norm:0.00023527696612291038 max memory_allocated 29273.12548828125 
[2025-03-02 20:57:20 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.29702338576316833 norm:0.00024318152281921357 max memory_allocated 29273.12548828125 
[2025-03-02 20:58:10 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.2968960404396057 norm:0.00024407307500950992 max memory_allocated 29273.12548828125 
[2025-03-02 20:58:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.29681432247161865 norm:0.00024873242364265025 max memory_allocated 29273.12548828125 
[2025-03-02 20:59:49 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.2967742681503296 norm:0.0002636574499774724 max memory_allocated 29273.12548828125 
[2025-03-02 21:00:39 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.29674357175827026 norm:0.0002693643618840724 max memory_allocated 29273.12548828125 
[2025-03-02 21:00:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 21:01:47 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.3667357265949249 norm:0.0018206071108579636 max memory_allocated 29273.31298828125 
[2025-03-02 21:02:36 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.35066425800323486 norm:0.0009410326601937413 max memory_allocated 29273.31298828125 
[2025-03-02 21:03:26 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.33540064096450806 norm:0.0005600298754870892 max memory_allocated 29273.31298828125 
[2025-03-02 21:04:16 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.33113032579421997 norm:0.00039196654688566923 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.32979893684387207 norm:0.0003064144984818995 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:55 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.3293226659297943 norm:0.00026354193687438965 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.32896360754966736 norm:0.00023538606183137745 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:34 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.3286789059638977 norm:0.00021378303063102067 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:24 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.32843416929244995 norm:0.0002009095624089241 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.32820239663124084 norm:0.00019263247668277472 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:03 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.32802456617355347 norm:0.00018712122982833534 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:53 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.3278602659702301 norm:0.00018088141223415732 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.32770881056785583 norm:0.00017975531227421016 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:32 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.32756873965263367 norm:0.00017788930563256145 max memory_allocated 29273.31298828125 
[2025-03-02 21:13:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.3274517059326172 norm:0.00017577645485289395 max memory_allocated 29273.31298828125 
[2025-03-02 21:14:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.3273467421531677 norm:0.00017488350567873567 max memory_allocated 29273.31298828125 
[2025-03-02 21:15:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.327251672744751 norm:0.00017314493015874177 max memory_allocated 29273.31298828125 
[2025-03-02 21:15:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.327144056558609 norm:0.00017135465168394148 max memory_allocated 29273.31298828125 
[2025-03-02 21:16:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.3270459771156311 norm:0.0001705033064354211 max memory_allocated 29273.31298828125 
[2025-03-02 21:17:30 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.32695674896240234 norm:0.00017052881594281644 max memory_allocated 29273.31298828125 
[2025-03-02 21:17:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.40366479754447937 norm:0.001752996351569891 max memory_allocated 29273.50048828125 
[2025-03-02 21:19:28 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.3867919147014618 norm:0.0008864324190653861 max memory_allocated 29273.50048828125 
[2025-03-02 21:20:18 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.3708548843860626 norm:0.0005314876325428486 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:07 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.3662721514701843 norm:0.0003885173937305808 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:57 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.364912211894989 norm:0.00031471269903704524 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.36435869336128235 norm:0.00028049456886947155 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.3639559745788574 norm:0.00025954379816539586 max memory_allocated 29273.50048828125 
[2025-03-02 21:24:26 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.3636050820350647 norm:0.00024880332057364285 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.3633519113063812 norm:0.000239947039517574 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.3631143271923065 norm:0.00022324630117509514 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.3628849983215332 norm:0.00021663964434992522 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.3626730442047119 norm:0.0002107994951074943 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:35 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.36251556873321533 norm:0.00020913206390105188 max memory_allocated 29273.50048828125 
[2025-03-02 21:29:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.36237218976020813 norm:0.00020875275367870927 max memory_allocated 29273.50048828125 
[2025-03-02 21:30:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.3622385263442993 norm:0.00020692437828984112 max memory_allocated 29273.50048828125 
[2025-03-02 21:31:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.3621193766593933 norm:0.00020975047664251179 max memory_allocated 29273.50048828125 
[2025-03-02 21:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.3620145916938782 norm:0.0002112618094542995 max memory_allocated 29273.50048828125 
[2025-03-02 21:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.3619594871997833 norm:0.00021076874691061676 max memory_allocated 29273.50048828125 
[2025-03-02 21:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.3618728518486023 norm:0.0002101529244100675 max memory_allocated 29273.50048828125 
[2025-03-02 21:34:22 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.36177197098731995 norm:0.0002110312634613365 max memory_allocated 29273.50048828125 
[2025-03-02 21:34:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:35:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.44214022159576416 norm:0.002022325526922941 max memory_allocated 29273.68798828125 
[2025-03-02 21:36:20 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.4241027534008026 norm:0.0009693823521956801 max memory_allocated 29273.68798828125 
[2025-03-02 21:37:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.40743762254714966 norm:0.0005753052537329495 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.40254512429237366 norm:0.000400275836000219 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.401204377412796 norm:0.00031871869578026235 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:39 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.40062040090560913 norm:0.0002771620638668537 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:29 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.400228351354599 norm:0.000246557523496449 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.3998655676841736 norm:0.00023356988094747066 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.3995722234249115 norm:0.00022042664932087064 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.3993074893951416 norm:0.00021418003598228097 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:48 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.3990783095359802 norm:0.00021168251987546682 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.3988652229309082 norm:0.0002082102873828262 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.3987107276916504 norm:0.0002030862815445289 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:17 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.398579478263855 norm:0.00019992212764918804 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:06 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.3984401822090149 norm:0.00019920687191188335 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:56 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.39831089973449707 norm:0.00019630674796644598 max memory_allocated 29273.68798828125 
[2025-03-02 21:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.3982093930244446 norm:0.00019339669961482286 max memory_allocated 29273.68798828125 
[2025-03-02 21:49:36 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.3981226086616516 norm:0.00019460073963273317 max memory_allocated 29273.68798828125 
[2025-03-02 21:50:25 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.3980386257171631 norm:0.00019258471729699522 max memory_allocated 29273.68798828125 
[2025-03-02 21:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.39796382188796997 norm:0.00019606485147960484 max memory_allocated 29273.68798828125 
[2025-03-02 21:51:29 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:52:23 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.4797389507293701 norm:0.0024878906551748514 max memory_allocated 29273.87548828125 
[2025-03-02 21:53:13 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.461559534072876 norm:0.001238514669239521 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:02 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.44431889057159424 norm:0.0007317955605685711 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:52 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.43950727581977844 norm:0.0005037290975451469 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:42 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.438244104385376 norm:0.0003896963316947222 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:32 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.4376915693283081 norm:0.0003240251389797777 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:21 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.437236487865448 norm:0.0002830401645042002 max memory_allocated 29273.87548828125 
[2025-03-02 21:58:11 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.43690112233161926 norm:0.0002587648050393909 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:01 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.43662384152412415 norm:0.0002380959631409496 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:50 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.43634557723999023 norm:0.00022478918253909796 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:40 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.43612104654312134 norm:0.00021540749003179371 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:30 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.43591737747192383 norm:0.00020947630400769413 max memory_allocated 29273.87548828125 
[2025-03-02 22:02:20 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.4357316195964813 norm:0.0002038592065218836 max memory_allocated 29273.87548828125 
[2025-03-02 22:03:09 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.4355636239051819 norm:0.00019996929040644318 max memory_allocated 29273.87548828125 
[2025-03-02 22:03:59 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.4354286193847656 norm:0.00020007233251817524 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:49 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.43530625104904175 norm:0.00019742580479942262 max memory_allocated 29273.87548828125 
[2025-03-02 22:05:38 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.4352113604545593 norm:0.00019619023078121245 max memory_allocated 29273.87548828125 
[2025-03-02 22:06:28 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.43509387969970703 norm:0.00019677354430314153 max memory_allocated 29273.87548828125 
[2025-03-02 22:07:17 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.43503424525260925 norm:0.0001955993939191103 max memory_allocated 29273.87548828125 
[2025-03-02 22:08:07 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.43493416905403137 norm:0.00019499761401675642 max memory_allocated 29273.87548828125 
[2025-03-02 22:08:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:09:15 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.5261499285697937 norm:0.0014323836658149958 max memory_allocated 29274.06298828125 
[2025-03-02 22:10:04 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.5067049264907837 norm:0.0007732721278443933 max memory_allocated 29274.06298828125 
[2025-03-02 22:10:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.4887661039829254 norm:0.0004955396871082485 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.483784556388855 norm:0.0003687459393404424 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.4824552536010742 norm:0.0003092690894845873 max memory_allocated 29274.06298828125 
[2025-03-02 22:13:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.4818746745586395 norm:0.0002809888101182878 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.4813973903656006 norm:0.0002648474182933569 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:03 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.48099640011787415 norm:0.00025147220003418624 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:52 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.4806792140007019 norm:0.00024349516024813056 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:42 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.48041653633117676 norm:0.0002395169867668301 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:31 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.4801519513130188 norm:0.00023756863083690405 max memory_allocated 29274.06298828125 
[2025-03-02 22:18:21 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.4799099862575531 norm:0.00023879592481534928 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:10 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.47972726821899414 norm:0.00023120551486499608 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:00 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.47955429553985596 norm:0.00023067486472427845 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:49 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.4794151484966278 norm:0.00023302090994548053 max memory_allocated 29274.06298828125 
[2025-03-02 22:21:39 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.47929781675338745 norm:0.00023621162108611315 max memory_allocated 29274.06298828125 
[2025-03-02 22:22:29 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.47916179895401 norm:0.00023627400514669716 max memory_allocated 29274.06298828125 
[2025-03-02 22:23:18 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.47904160618782043 norm:0.00023321302433032542 max memory_allocated 29274.06298828125 
[2025-03-02 22:24:08 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.47893789410591125 norm:0.00023097166558727622 max memory_allocated 29274.06298828125 
[2025-03-02 22:24:57 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.47884324193000793 norm:0.00023125307052396238 max memory_allocated 29274.06298828125 
[2025-03-02 22:25:12 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:26:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.5843073129653931 norm:0.0020183445885777473 max memory_allocated 29274.25048828125 
[2025-03-02 22:26:55 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.5620706677436829 norm:0.0010382725158706307 max memory_allocated 29274.25048828125 
[2025-03-02 22:27:45 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.5411883592605591 norm:0.0006031448137946427 max memory_allocated 29274.25048828125 
[2025-03-02 22:28:34 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.5357707738876343 norm:0.0004404369683470577 max memory_allocated 29274.25048828125 
[2025-03-02 22:29:24 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.5344927906990051 norm:0.0003705218550749123 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:14 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.5338598489761353 norm:0.00033243995858356357 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:03 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.5333212614059448 norm:0.0003100078902207315 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:53 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.5328192710876465 norm:0.0002861518878489733 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:43 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.5326077938079834 norm:0.00027429329929873347 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:33 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.5323417782783508 norm:0.00027193358982913196 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:23 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.5320514440536499 norm:0.00026642135344445705 max memory_allocated 29274.25048828125 
[2025-03-02 22:35:12 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.5318195223808289 norm:0.0002626267960295081 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:02 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.5316081047058105 norm:0.0002661010075826198 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:52 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.5314012169837952 norm:0.00026440987130627036 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:41 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.5312389135360718 norm:0.0002533394144847989 max memory_allocated 29274.25048828125 
[2025-03-02 22:38:31 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.5310144424438477 norm:0.00025110557908192277 max memory_allocated 29274.25048828125 
[2025-03-02 22:39:21 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.5308108329772949 norm:0.00024845427833497524 max memory_allocated 29274.25048828125 
[2025-03-02 22:40:11 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.530732274055481 norm:0.0002486914163455367 max memory_allocated 29274.25048828125 
[2025-03-02 22:41:00 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.5306280851364136 norm:0.0002458314411342144 max memory_allocated 29274.25048828125 
[2025-03-02 22:41:50 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.5305522680282593 norm:0.00025046890368685126 max memory_allocated 29274.25048828125 
[2025-03-02 22:42:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:42:58 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.6450216174125671 norm:0.0034955351147800684 max memory_allocated 29274.43798828125 
[2025-03-02 22:43:48 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.6198848485946655 norm:0.0018333059269934893 max memory_allocated 29274.43798828125 
[2025-03-02 22:44:38 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.5973411798477173 norm:0.0011051067849621177 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:27 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.5918184518814087 norm:0.000775782042182982 max memory_allocated 29274.43798828125 
[2025-03-02 22:46:17 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.5904561281204224 norm:0.0006047681672498584 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:07 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.5896695852279663 norm:0.0005151710356585681 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:56 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.5890858173370361 norm:0.0004570669261738658 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:46 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.5885780453681946 norm:0.00041755932033993304 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:36 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.5881859660148621 norm:0.0003904791665263474 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:26 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.5878321528434753 norm:0.0003741334076039493 max memory_allocated 29274.43798828125 
[2025-03-02 22:51:15 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.5875440835952759 norm:0.00036322552477940917 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:05 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.5872830748558044 norm:0.0003546104417182505 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:55 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.5870545506477356 norm:0.0003463124739937484 max memory_allocated 29274.43798828125 
[2025-03-02 22:53:44 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.5868504643440247 norm:0.00034322417923249304 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:34 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.5866124033927917 norm:0.0003380019043106586 max memory_allocated 29274.43798828125 
[2025-03-02 22:55:24 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.5864363312721252 norm:0.00033801599056459963 max memory_allocated 29274.43798828125 
[2025-03-02 22:56:14 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.5862995982170105 norm:0.00033526058541610837 max memory_allocated 29274.43798828125 
[2025-03-02 22:57:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.5861791968345642 norm:0.0003313714696560055 max memory_allocated 29274.43798828125 
[2025-03-02 22:57:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.5860797762870789 norm:0.00032902942621149123 max memory_allocated 29274.43798828125 
[2025-03-02 22:58:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.5859405398368835 norm:0.0003288096049800515 max memory_allocated 29274.43798828125 
[2025-03-02 22:58:57 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 22:59:01 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 22:59:51 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.7139319181442261 norm:0.0148671455681324 max memory_allocated 29274.77001953125 
[2025-03-02 23:00:41 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.685611367225647 norm:0.011373467743396759 max memory_allocated 29274.77001953125 
[2025-03-02 23:01:31 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.6599851846694946 norm:0.008454818278551102 max memory_allocated 29274.77001953125 
[2025-03-02 23:02:21 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.6541628837585449 norm:0.006963164079934359 max memory_allocated 29274.77001953125 
[2025-03-02 23:03:11 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.6524941325187683 norm:0.005614020396023989 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.6512349247932434 norm:0.004590428434312344 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.6505647897720337 norm:0.004399762488901615 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:40 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.6500518321990967 norm:0.004226142540574074 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:30 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.6495850682258606 norm:0.0040131984278559685 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:20 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.6491425633430481 norm:0.0038585392758250237 max memory_allocated 29274.77001953125 
[2025-03-02 23:08:10 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.6487105488777161 norm:0.0036532839294523 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:00 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.648036003112793 norm:0.003518521087244153 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:50 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.6474923491477966 norm:0.0034436166752129793 max memory_allocated 29274.77001953125 
[2025-03-02 23:10:40 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.647310733795166 norm:0.0034297569654881954 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:30 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.6469385623931885 norm:0.0033180215395987034 max memory_allocated 29274.77001953125 
[2025-03-02 23:12:19 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.6467146277427673 norm:0.003265008330345154 max memory_allocated 29274.77001953125 
[2025-03-02 23:13:09 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.6465927958488464 norm:0.003273148089647293 max memory_allocated 29274.77001953125 
[2025-03-02 23:13:59 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.6464224457740784 norm:0.00330115994438529 max memory_allocated 29274.77001953125 
[2025-03-02 23:14:49 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.6462911367416382 norm:0.0032339494209736586 max memory_allocated 29274.77001953125 
[2025-03-02 23:15:39 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.6462370157241821 norm:0.0032682165037840605 max memory_allocated 29274.77001953125 
[2025-03-02 23:15:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:15:57 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.8211877942085266 norm:0.021632544696331024 max memory_allocated 29274.95751953125 
[2025-03-02 23:17:37 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.7824212312698364 norm:0.014019790105521679 max memory_allocated 29274.95751953125 
[2025-03-02 23:18:27 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.7476188540458679 norm:0.010664246045053005 max memory_allocated 29274.95751953125 
[2025-03-02 23:19:17 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.7389077544212341 norm:0.01067640632390976 max memory_allocated 29274.95751953125 
[2025-03-02 23:20:07 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.7363519072532654 norm:0.009968314319849014 max memory_allocated 29274.95751953125 
[2025-03-02 23:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.7346407771110535 norm:0.008803026750683784 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:47 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.7333210110664368 norm:0.008115199394524097 max memory_allocated 29274.95751953125 
[2025-03-02 23:22:36 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.7325125932693481 norm:0.007457266561686993 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:26 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.7319722175598145 norm:0.006968671455979347 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:16 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.7315430641174316 norm:0.006472937297075987 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:06 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.7312656044960022 norm:0.006051893811672926 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:56 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.7311961650848389 norm:0.005995995365083218 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:46 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.7307724356651306 norm:0.005606598220765591 max memory_allocated 29274.95751953125 
[2025-03-02 23:27:36 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.7300487756729126 norm:0.0052897026762366295 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:26 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.7297645807266235 norm:0.0050086770206689835 max memory_allocated 29274.95751953125 
[2025-03-02 23:29:16 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.7297151684761047 norm:0.00494639715179801 max memory_allocated 29274.95751953125 
[2025-03-02 23:30:06 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.7296350002288818 norm:0.004786505829542875 max memory_allocated 29274.95751953125 
[2025-03-02 23:30:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.7294940948486328 norm:0.004646864254027605 max memory_allocated 29274.95751953125 
[2025-03-02 23:31:45 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.7296064496040344 norm:0.005129482597112656 max memory_allocated 29274.95751953125 
[2025-03-02 23:32:35 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.729507565498352 norm:0.005033750087022781 max memory_allocated 29274.95751953125 
[2025-03-02 23:32:50 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:32:54 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:33:44 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:1.03487229347229 norm:0.046961914747953415 max memory_allocated 29275.14501953125 
[2025-03-02 23:34:33 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.9713412523269653 norm:0.032365862280130386 max memory_allocated 29275.14501953125 
[2025-03-02 23:35:23 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.9254934787750244 norm:0.02354533225297928 max memory_allocated 29275.14501953125 
[2025-03-02 23:36:13 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.9114900827407837 norm:0.020218471065163612 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:03 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.9049171209335327 norm:0.017345163971185684 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.9009445905685425 norm:0.015582704916596413 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:43 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.898267924785614 norm:0.014047595672309399 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:32 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.8963809013366699 norm:0.013226112350821495 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.894313395023346 norm:0.012467879801988602 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:12 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.8933018445968628 norm:0.01233571395277977 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.8924648761749268 norm:0.012073773890733719 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:52 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.8918840289115906 norm:0.012234634719789028 max memory_allocated 29275.14501953125 
[2025-03-02 23:43:42 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.8904637694358826 norm:0.011749761179089546 max memory_allocated 29275.14501953125 
[2025-03-02 23:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.8895652890205383 norm:0.011209509335458279 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.8893647193908691 norm:0.011060607619583607 max memory_allocated 29275.14501953125 
[2025-03-02 23:46:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.8885788917541504 norm:0.010421870276331902 max memory_allocated 29275.14501953125 
[2025-03-02 23:47:01 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.8881756663322449 norm:0.00985644105821848 max memory_allocated 29275.14501953125 
[2025-03-02 23:47:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.8874125480651855 norm:0.009533679112792015 max memory_allocated 29275.14501953125 
[2025-03-02 23:48:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.8875086903572083 norm:0.009403861127793789 max memory_allocated 29275.14501953125 
[2025-03-02 23:49:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.8874189257621765 norm:0.009099920280277729 max memory_allocated 29275.14501953125 
[2025-03-02 23:49:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:49:49 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:50:39 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:1.6233404874801636 norm:0.06943400204181671 max memory_allocated 29275.33251953125 
[2025-03-02 23:51:29 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:1.5630590915679932 norm:0.052023909986019135 max memory_allocated 29275.33251953125 
[2025-03-02 23:52:19 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:1.517798900604248 norm:0.04549267888069153 max memory_allocated 29275.33251953125 
[2025-03-02 23:53:09 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:1.4849560260772705 norm:0.045504000037908554 max memory_allocated 29275.33251953125 
[2025-03-02 23:53:58 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:1.4711620807647705 norm:0.04616174474358559 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:1.4625824689865112 norm:0.04601093754172325 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:38 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:1.4565603733062744 norm:0.04752764478325844 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:28 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:1.4510458707809448 norm:0.04526463523507118 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:18 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:1.4472899436950684 norm:0.043852344155311584 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:08 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:1.4405362606048584 norm:0.04030006751418114 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:1.436245083808899 norm:0.03835875913500786 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:47 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:1.4344727993011475 norm:0.036659788340330124 max memory_allocated 29275.33251953125 
[2025-03-03 00:00:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:1.4333770275115967 norm:0.03684680163860321 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:27 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:1.4320529699325562 norm:0.03693217411637306 max memory_allocated 29275.33251953125 
[2025-03-03 00:02:17 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:1.4302170276641846 norm:0.035640012472867966 max memory_allocated 29275.33251953125 
[2025-03-03 00:03:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:1.4296623468399048 norm:0.03641745075583458 max memory_allocated 29275.33251953125 
[2025-03-03 00:03:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:1.4292489290237427 norm:0.03671515733003616 max memory_allocated 29275.33251953125 
[2025-03-03 00:04:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:1.4283835887908936 norm:0.03441397473216057 max memory_allocated 29275.33251953125 
[2025-03-03 00:05:36 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:1.4260369539260864 norm:0.03471216559410095 max memory_allocated 29275.33251953125 
[2025-03-03 00:06:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:1.4266808032989502 norm:0.03365274518728256 max memory_allocated 29275.33251953125 
[2025-03-03 00:06:41 root] (main_calib_config2.py 372): INFO 40450.317371845245
[2025-03-03 00:06:51 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:08:48 root] (main_calib_config2.py 159): INFO wikitext2 : 5.292180061340332
[2025-03-03 00:08:48 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:11:48 root] (main_calib_config2.py 159): INFO c4 : 6.85538911819458
[2025-03-03 02:16:20 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.292180061340332, 'c4': 6.85538911819458, 'results': {'piqa': {'acc': 0.7856365614798694, 'acc_stderr': 0.009574842136050973, 'acc_norm': 0.7867247007616975, 'acc_norm_stderr': 0.009557121225861352}, 'arc_easy': {'acc': 0.726010101010101, 'acc_stderr': 0.009151805901544015, 'acc_norm': 0.5858585858585859, 'acc_norm_stderr': 0.01010738767300252}, 'arc_challenge': {'acc': 0.42662116040955633, 'acc_stderr': 0.014453185592920293, 'acc_norm': 0.4283276450511945, 'acc_norm_stderr': 0.014460496367599012}, 'boolq': {'acc': 0.6944954128440367, 'acc_stderr': 0.008056308685164819}, 'winogrande': {'acc': 0.6866614048934491, 'acc_stderr': 0.013036512096747981}, 'hellaswag': {'acc': 0.5819557857000598, 'acc_stderr': 0.004922294797766666, 'acc_norm': 0.7496514638518224, 'acc_norm_stderr': 0.004323283757933833}}, 'versions': {'piqa': 0, 'arc_easy': 0, 'arc_challenge': 0, 'boolq': 1, 'winogrande': 0, 'hellaswag': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
