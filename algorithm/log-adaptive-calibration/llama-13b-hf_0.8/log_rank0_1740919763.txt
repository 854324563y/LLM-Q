[2025-03-02 12:49:23 root] (main_calib_config2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-adaptive-calibration/llama-13b-hf_0.8', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.8.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-02 12:52:30 root] (main_calib_config2.py 343): INFO === start quantization ===
[2025-03-02 12:52:30 root] (main_calib_config2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 82): INFO Starting ...
[2025-03-02 12:52:31 root] (abq_llm_calib_config2.py 89): INFO Loaded quant_map from log-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.8.pkl
[2025-03-02 12:52:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 0 ===
[2025-03-02 12:52:40 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 12:53:29 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 0 loss:0.005262813530862331 norm:0.0046740807592868805 max memory_allocated 29268.02001953125 
[2025-03-02 12:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 1 loss:0.0032287442591041327 norm:0.003279367694631219 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:08 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 2 loss:0.0027286065742373466 norm:0.0025622588582336903 max memory_allocated 29268.02001953125 
[2025-03-02 12:55:58 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 3 loss:0.0024797089863568544 norm:0.0021460563875734806 max memory_allocated 29268.02001953125 
[2025-03-02 12:56:48 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 4 loss:0.0023158739786595106 norm:0.0017190396320074797 max memory_allocated 29268.02001953125 
[2025-03-02 12:57:37 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 5 loss:0.002217377768829465 norm:0.001552131725475192 max memory_allocated 29268.02001953125 
[2025-03-02 12:58:27 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 6 loss:0.002120071789249778 norm:0.0013592669274657965 max memory_allocated 29268.02001953125 
[2025-03-02 12:59:17 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 7 loss:0.002053637523204088 norm:0.0012387477327138186 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:07 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 8 loss:0.0020100390538573265 norm:0.0011067565064877272 max memory_allocated 29268.02001953125 
[2025-03-02 13:00:56 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 9 loss:0.0019811121746897697 norm:0.0010340440785512328 max memory_allocated 29268.02001953125 
[2025-03-02 13:01:46 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 10 loss:0.0019659355748444796 norm:0.0009750858880579472 max memory_allocated 29268.02001953125 
[2025-03-02 13:02:36 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 11 loss:0.0019130052533000708 norm:0.0008310004486702383 max memory_allocated 29268.02001953125 
[2025-03-02 13:03:26 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 12 loss:0.0019098821794614196 norm:0.0008209856459870934 max memory_allocated 29268.02001953125 
[2025-03-02 13:04:15 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 13 loss:0.0019047607202082872 norm:0.0008311518467962742 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:05 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 14 loss:0.001895293709821999 norm:0.0007493095472455025 max memory_allocated 29268.02001953125 
[2025-03-02 13:05:55 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 15 loss:0.0018855561502277851 norm:0.0007458790787495673 max memory_allocated 29268.02001953125 
[2025-03-02 13:06:45 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 16 loss:0.001929286401718855 norm:0.0007522816304117441 max memory_allocated 29268.02001953125 
[2025-03-02 13:07:34 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 17 loss:0.001878038514405489 norm:0.000746155739761889 max memory_allocated 29268.02001953125 
[2025-03-02 13:08:24 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 18 loss:0.0018573401030153036 norm:0.0006734792841598392 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:14 root] (abq_llm_calib_config2.py 396): INFO layer 0 iter 19 loss:0.0018715584883466363 norm:0.0006818181718699634 max memory_allocated 29268.02001953125 
[2025-03-02 13:09:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 1 ===
[2025-03-02 13:09:32 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:10:22 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 0 loss:0.008493084460496902 norm:0.00498958770185709 max memory_allocated 29268.02001953125 
[2025-03-02 13:11:12 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 1 loss:0.006342526990920305 norm:0.004371311515569687 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:02 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 2 loss:0.005691738333553076 norm:0.003430502489209175 max memory_allocated 29268.02001953125 
[2025-03-02 13:12:51 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 3 loss:0.005332686007022858 norm:0.0027476479299366474 max memory_allocated 29268.02001953125 
[2025-03-02 13:13:41 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 4 loss:0.005166494287550449 norm:0.00231082527898252 max memory_allocated 29268.02001953125 
[2025-03-02 13:14:31 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 5 loss:0.005047746933996677 norm:0.0019072628347203135 max memory_allocated 29268.02001953125 
[2025-03-02 13:15:21 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 6 loss:0.004936193116009235 norm:0.0016513378359377384 max memory_allocated 29268.02001953125 
[2025-03-02 13:16:11 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 7 loss:0.0048647914081811905 norm:0.0013829866657033563 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:00 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 8 loss:0.004780630115419626 norm:0.0012062696041539311 max memory_allocated 29268.02001953125 
[2025-03-02 13:17:50 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 9 loss:0.004709039814770222 norm:0.0011133989319205284 max memory_allocated 29268.02001953125 
[2025-03-02 13:18:40 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 10 loss:0.004656153731048107 norm:0.0011131961364299059 max memory_allocated 29268.02001953125 
[2025-03-02 13:19:30 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 11 loss:0.004598606843501329 norm:0.0010841370094567537 max memory_allocated 29268.02001953125 
[2025-03-02 13:20:20 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 12 loss:0.004694583360105753 norm:0.001252950867637992 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:09 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 13 loss:0.004608789924532175 norm:0.0009899468859657645 max memory_allocated 29268.02001953125 
[2025-03-02 13:21:59 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 14 loss:0.004576395731419325 norm:0.0009697687346488237 max memory_allocated 29268.02001953125 
[2025-03-02 13:22:49 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 15 loss:0.004614797420799732 norm:0.0010104664834216237 max memory_allocated 29268.02001953125 
[2025-03-02 13:23:39 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 16 loss:0.004511857405304909 norm:0.0007779686129651964 max memory_allocated 29268.02001953125 
[2025-03-02 13:24:29 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 17 loss:0.004468286409974098 norm:0.0007657004753127694 max memory_allocated 29268.02001953125 
[2025-03-02 13:25:19 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 18 loss:0.0045664068311452866 norm:0.0009175878949463367 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:08 root] (abq_llm_calib_config2.py 396): INFO layer 1 iter 19 loss:0.0045217471197247505 norm:0.0007844556239433587 max memory_allocated 29268.02001953125 
[2025-03-02 13:26:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 2 ===
[2025-03-02 13:26:27 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 13:27:17 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 0 loss:0.02435174211859703 norm:0.010562058538198471 max memory_allocated 29268.39501953125 
[2025-03-02 13:28:06 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 1 loss:0.018051527440547943 norm:0.008192816749215126 max memory_allocated 29268.39501953125 
[2025-03-02 13:28:56 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 2 loss:0.015599921345710754 norm:0.007881039753556252 max memory_allocated 29268.39501953125 
[2025-03-02 13:29:46 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 3 loss:0.01420816034078598 norm:0.007387484423816204 max memory_allocated 29268.39501953125 
[2025-03-02 13:30:36 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 4 loss:0.01311448123306036 norm:0.006600081920623779 max memory_allocated 29268.39501953125 
[2025-03-02 13:31:26 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 5 loss:0.012204762548208237 norm:0.005680615082383156 max memory_allocated 29268.39501953125 
[2025-03-02 13:32:15 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 6 loss:0.011679144576191902 norm:0.005461270920932293 max memory_allocated 29268.39501953125 
[2025-03-02 13:33:05 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 7 loss:0.011225920170545578 norm:0.004998763091862202 max memory_allocated 29268.39501953125 
[2025-03-02 13:33:55 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 8 loss:0.01105642318725586 norm:0.004692159127444029 max memory_allocated 29268.39501953125 
[2025-03-02 13:34:45 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 9 loss:0.01078396663069725 norm:0.003925800323486328 max memory_allocated 29268.39501953125 
[2025-03-02 13:35:35 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 10 loss:0.010703789070248604 norm:0.004071398638188839 max memory_allocated 29268.39501953125 
[2025-03-02 13:36:25 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 11 loss:0.010686899535357952 norm:0.004269663710147142 max memory_allocated 29268.39501953125 
[2025-03-02 13:37:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 12 loss:0.010548255406320095 norm:0.0037374570965766907 max memory_allocated 29268.39501953125 
[2025-03-02 13:38:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 13 loss:0.010589201003313065 norm:0.0040219686925411224 max memory_allocated 29268.39501953125 
[2025-03-02 13:38:54 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 14 loss:0.010564766824245453 norm:0.004178021568804979 max memory_allocated 29268.39501953125 
[2025-03-02 13:39:44 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 15 loss:0.010558350011706352 norm:0.003921908792108297 max memory_allocated 29268.39501953125 
[2025-03-02 13:40:34 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 16 loss:0.01050272025167942 norm:0.003729025600478053 max memory_allocated 29268.39501953125 
[2025-03-02 13:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 17 loss:0.010378298349678516 norm:0.0036314683966338634 max memory_allocated 29268.39501953125 
[2025-03-02 13:42:14 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 18 loss:0.010283567011356354 norm:0.0032292164396494627 max memory_allocated 29268.39501953125 
[2025-03-02 13:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 2 iter 19 loss:0.010217804461717606 norm:0.003304550889879465 max memory_allocated 29268.39501953125 
[2025-03-02 13:43:18 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 3 ===
[2025-03-02 13:44:12 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 0 loss:0.01766994595527649 norm:0.0016019147587940097 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:01 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 1 loss:0.014333061873912811 norm:0.0006510820821858943 max memory_allocated 29268.43798828125 
[2025-03-02 13:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 2 loss:0.013289897702634335 norm:0.0003239253128413111 max memory_allocated 29268.43798828125 
[2025-03-02 13:46:40 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 3 loss:0.012773633934557438 norm:0.00023654110555071384 max memory_allocated 29268.43798828125 
[2025-03-02 13:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 4 loss:0.012357166036963463 norm:0.0001535128685645759 max memory_allocated 29268.43798828125 
[2025-03-02 13:48:20 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 5 loss:0.011983356438577175 norm:0.00015032866213005036 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:09 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 6 loss:0.011767079122364521 norm:0.00016428936214651912 max memory_allocated 29268.43798828125 
[2025-03-02 13:49:59 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 7 loss:0.011575162410736084 norm:0.00012420212442521006 max memory_allocated 29268.43798828125 
[2025-03-02 13:50:49 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 8 loss:0.011517073027789593 norm:0.00012809422332793474 max memory_allocated 29268.43798828125 
[2025-03-02 13:51:38 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 9 loss:0.011541868560016155 norm:0.0001506448315922171 max memory_allocated 29268.43798828125 
[2025-03-02 13:52:28 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 10 loss:0.011473835445940495 norm:0.00010691313946153969 max memory_allocated 29268.43798828125 
[2025-03-02 13:53:18 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 11 loss:0.01146557368338108 norm:0.00011147966142743826 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:07 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 12 loss:0.011448601260781288 norm:0.00010963110980810598 max memory_allocated 29268.43798828125 
[2025-03-02 13:54:57 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 13 loss:0.011418727226555347 norm:0.00010053177538793534 max memory_allocated 29268.43798828125 
[2025-03-02 13:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 14 loss:0.011413502506911755 norm:9.906961349770427e-05 max memory_allocated 29268.43798828125 
[2025-03-02 13:56:36 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 15 loss:0.011402868665754795 norm:0.00010590381862130016 max memory_allocated 29268.43798828125 
[2025-03-02 13:57:26 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 16 loss:0.011407025158405304 norm:0.000111877299787011 max memory_allocated 29268.43798828125 
[2025-03-02 13:58:16 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 17 loss:0.011385681107640266 norm:0.00012665096437558532 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:05 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 18 loss:0.011383351869881153 norm:0.00012806386803276837 max memory_allocated 29268.43798828125 
[2025-03-02 13:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 3 iter 19 loss:0.011384373530745506 norm:0.00014444062253460288 max memory_allocated 29268.43798828125 
[2025-03-02 14:00:10 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 4 ===
[2025-03-02 14:01:03 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 0 loss:0.024411845952272415 norm:0.0029474589973688126 max memory_allocated 29268.62548828125 
[2025-03-02 14:01:53 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 1 loss:0.019248615950345993 norm:0.0008887457079254091 max memory_allocated 29268.62548828125 
[2025-03-02 14:02:42 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 2 loss:0.017500264570116997 norm:0.0005640001036226749 max memory_allocated 29268.62548828125 
[2025-03-02 14:03:32 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 3 loss:0.016607265919446945 norm:0.00042810727609321475 max memory_allocated 29268.62548828125 
[2025-03-02 14:04:22 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 4 loss:0.01596423052251339 norm:0.0003096595755778253 max memory_allocated 29268.62548828125 
[2025-03-02 14:05:11 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 5 loss:0.015492522157728672 norm:0.0002589196083135903 max memory_allocated 29268.62548828125 
[2025-03-02 14:06:01 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 6 loss:0.01528843678534031 norm:0.000231677942792885 max memory_allocated 29268.62548828125 
[2025-03-02 14:06:51 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 7 loss:0.015174048021435738 norm:0.0002055245713563636 max memory_allocated 29268.62548828125 
[2025-03-02 14:07:40 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 8 loss:0.015120330266654491 norm:0.00018679036293178797 max memory_allocated 29268.62548828125 
[2025-03-02 14:08:30 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 9 loss:0.015127522870898247 norm:0.0001567342405905947 max memory_allocated 29268.62548828125 
[2025-03-02 14:09:20 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 10 loss:0.015041868202388287 norm:0.00013300636783242226 max memory_allocated 29268.62548828125 
[2025-03-02 14:10:09 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 11 loss:0.0150835532695055 norm:0.0001906198012875393 max memory_allocated 29268.62548828125 
[2025-03-02 14:10:59 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 12 loss:0.01500038243830204 norm:0.00012514146510511637 max memory_allocated 29268.62548828125 
[2025-03-02 14:11:49 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 13 loss:0.014989985153079033 norm:0.00012593274004757404 max memory_allocated 29268.62548828125 
[2025-03-02 14:12:38 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 14 loss:0.014964297413825989 norm:0.00010689189366530627 max memory_allocated 29268.62548828125 
[2025-03-02 14:13:28 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 15 loss:0.014940186403691769 norm:0.00011268453090451658 max memory_allocated 29268.62548828125 
[2025-03-02 14:14:18 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 16 loss:0.014929202385246754 norm:0.00011496063234517351 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:08 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 17 loss:0.014921361580491066 norm:0.00011977498070336878 max memory_allocated 29268.62548828125 
[2025-03-02 14:15:57 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 18 loss:0.014961326494812965 norm:0.0001595125359017402 max memory_allocated 29268.62548828125 
[2025-03-02 14:16:47 root] (abq_llm_calib_config2.py 396): INFO layer 4 iter 19 loss:0.015074030496180058 norm:0.00015676897601224482 max memory_allocated 29268.62548828125 
[2025-03-02 14:17:02 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 5 ===
[2025-03-02 14:17:55 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 0 loss:0.03157420828938484 norm:0.003215731820091605 max memory_allocated 29268.81298828125 
[2025-03-02 14:18:45 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 1 loss:0.023433079943060875 norm:0.0010477898176759481 max memory_allocated 29268.81298828125 
[2025-03-02 14:19:34 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 2 loss:0.020969484001398087 norm:0.0005841695819981396 max memory_allocated 29268.81298828125 
[2025-03-02 14:20:24 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 3 loss:0.01980895921587944 norm:0.00038810301339253783 max memory_allocated 29268.81298828125 
[2025-03-02 14:21:14 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 4 loss:0.01905326172709465 norm:0.00029382077627815306 max memory_allocated 29268.81298828125 
[2025-03-02 14:22:04 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 5 loss:0.018571071326732635 norm:0.00024401851987931877 max memory_allocated 29268.81298828125 
[2025-03-02 14:22:53 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 6 loss:0.018312649801373482 norm:0.00020705875067505985 max memory_allocated 29268.81298828125 
[2025-03-02 14:23:43 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 7 loss:0.018175851553678513 norm:0.0002054411161225289 max memory_allocated 29268.81298828125 
[2025-03-02 14:24:33 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 8 loss:0.01808946393430233 norm:0.00017423013923689723 max memory_allocated 29268.81298828125 
[2025-03-02 14:25:22 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 9 loss:0.0180374663323164 norm:0.00016076164320111275 max memory_allocated 29268.81298828125 
[2025-03-02 14:26:12 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 10 loss:0.018011389300227165 norm:0.0001832382840802893 max memory_allocated 29268.81298828125 
[2025-03-02 14:27:02 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 11 loss:0.01801254041492939 norm:0.00016976892948150635 max memory_allocated 29268.81298828125 
[2025-03-02 14:27:51 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 12 loss:0.01794474571943283 norm:0.00014053967606741935 max memory_allocated 29268.81298828125 
[2025-03-02 14:28:41 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 13 loss:0.017890678718686104 norm:0.00013615685747936368 max memory_allocated 29268.81298828125 
[2025-03-02 14:29:31 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 14 loss:0.01785420812666416 norm:0.00015162938507273793 max memory_allocated 29268.81298828125 
[2025-03-02 14:30:20 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 15 loss:0.017877530306577682 norm:0.00015546333452221006 max memory_allocated 29268.81298828125 
[2025-03-02 14:31:10 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 16 loss:0.01785883866250515 norm:0.00016894357395358384 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:00 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 17 loss:0.017889123409986496 norm:0.00012694875476881862 max memory_allocated 29268.81298828125 
[2025-03-02 14:32:49 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 18 loss:0.01783028058707714 norm:0.00013385519559960812 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:39 root] (abq_llm_calib_config2.py 396): INFO layer 5 iter 19 loss:0.017819277942180634 norm:0.00012316145875956863 max memory_allocated 29268.81298828125 
[2025-03-02 14:33:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 6 ===
[2025-03-02 14:34:47 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 0 loss:0.036236442625522614 norm:0.0020890471059828997 max memory_allocated 29269.00048828125 
[2025-03-02 14:35:37 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 1 loss:0.029461752623319626 norm:0.0012347898446023464 max memory_allocated 29269.00048828125 
[2025-03-02 14:36:26 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 2 loss:0.02648968994617462 norm:0.0008391113951802254 max memory_allocated 29269.00048828125 
[2025-03-02 14:37:16 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 3 loss:0.024589868262410164 norm:0.0006734806811437011 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 4 loss:0.023386038839817047 norm:0.0005841114325448871 max memory_allocated 29269.00048828125 
[2025-03-02 14:38:55 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 5 loss:0.022699281573295593 norm:0.0005082327406853437 max memory_allocated 29269.00048828125 
[2025-03-02 14:39:45 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 6 loss:0.022325653582811356 norm:0.00046236696653068066 max memory_allocated 29269.00048828125 
[2025-03-02 14:40:35 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 7 loss:0.02214638702571392 norm:0.0004370685201138258 max memory_allocated 29269.00048828125 
[2025-03-02 14:41:24 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 8 loss:0.022046029567718506 norm:0.00043092112173326313 max memory_allocated 29269.00048828125 
[2025-03-02 14:42:14 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 9 loss:0.021910030394792557 norm:0.000382699363399297 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:04 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 10 loss:0.021929562091827393 norm:0.0004612504271790385 max memory_allocated 29269.00048828125 
[2025-03-02 14:43:53 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 11 loss:0.02185027301311493 norm:0.0003945857170037925 max memory_allocated 29269.00048828125 
[2025-03-02 14:44:43 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 12 loss:0.021803012117743492 norm:0.0003874815010931343 max memory_allocated 29269.00048828125 
[2025-03-02 14:45:32 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 13 loss:0.02175990864634514 norm:0.0003820674028247595 max memory_allocated 29269.00048828125 
[2025-03-02 14:46:22 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 14 loss:0.021713167428970337 norm:0.00039249038673006 max memory_allocated 29269.00048828125 
[2025-03-02 14:47:12 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 15 loss:0.021692054346203804 norm:0.0003678334760479629 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:02 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 16 loss:0.021679427474737167 norm:0.00038651496288366616 max memory_allocated 29269.00048828125 
[2025-03-02 14:48:51 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 17 loss:0.021697618067264557 norm:0.0003701845125760883 max memory_allocated 29269.00048828125 
[2025-03-02 14:49:41 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 18 loss:0.021676717326045036 norm:0.0003652402956504375 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:31 root] (abq_llm_calib_config2.py 396): INFO layer 6 iter 19 loss:0.02164817787706852 norm:0.0003573199501261115 max memory_allocated 29269.00048828125 
[2025-03-02 14:50:45 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 7 ===
[2025-03-02 14:51:39 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 0 loss:0.03393525257706642 norm:0.0013675875961780548 max memory_allocated 29269.18798828125 
[2025-03-02 14:52:28 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 1 loss:0.02874176576733589 norm:0.0006326687289401889 max memory_allocated 29269.18798828125 
[2025-03-02 14:53:18 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 2 loss:0.026794904842972755 norm:0.00034560781205073 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:08 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 3 loss:0.02572484314441681 norm:0.00021940283477306366 max memory_allocated 29269.18798828125 
[2025-03-02 14:54:57 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 4 loss:0.02500217594206333 norm:0.00017929423484019935 max memory_allocated 29269.18798828125 
[2025-03-02 14:55:47 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 5 loss:0.024632815271615982 norm:0.0001648518955335021 max memory_allocated 29269.18798828125 
[2025-03-02 14:56:37 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 6 loss:0.024378368631005287 norm:0.00014996762911323458 max memory_allocated 29269.18798828125 
[2025-03-02 14:57:26 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 7 loss:0.024244442582130432 norm:0.0001434878504369408 max memory_allocated 29269.18798828125 
[2025-03-02 14:58:16 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 8 loss:0.02417583204805851 norm:0.00013782392488792539 max memory_allocated 29269.18798828125 
[2025-03-02 14:59:06 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 9 loss:0.024147147312760353 norm:0.00014814699534326792 max memory_allocated 29269.18798828125 
[2025-03-02 14:59:55 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 10 loss:0.024124378338456154 norm:0.00014553630899172276 max memory_allocated 29269.18798828125 
[2025-03-02 15:00:45 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 11 loss:0.02409369684755802 norm:0.00013945225509814918 max memory_allocated 29269.18798828125 
[2025-03-02 15:01:35 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 12 loss:0.024039484560489655 norm:0.00013743157614953816 max memory_allocated 29269.18798828125 
[2025-03-02 15:02:24 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 13 loss:0.02400670386850834 norm:0.000136920454679057 max memory_allocated 29269.18798828125 
[2025-03-02 15:03:14 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 14 loss:0.02398303523659706 norm:0.00013706345635000616 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:04 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 15 loss:0.02398139052093029 norm:0.00013749822392128408 max memory_allocated 29269.18798828125 
[2025-03-02 15:04:54 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 16 loss:0.023998873308300972 norm:0.00014910403115209192 max memory_allocated 29269.18798828125 
[2025-03-02 15:05:43 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 17 loss:0.024015165865421295 norm:0.00014706782530993223 max memory_allocated 29269.18798828125 
[2025-03-02 15:06:33 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 18 loss:0.024003127589821815 norm:0.00013681392010767013 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:23 root] (abq_llm_calib_config2.py 396): INFO layer 7 iter 19 loss:0.02399246022105217 norm:0.00014307883975561708 max memory_allocated 29269.18798828125 
[2025-03-02 15:07:37 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 8 ===
[2025-03-02 15:08:31 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 0 loss:0.037714872509241104 norm:0.0015284251421689987 max memory_allocated 29269.37548828125 
[2025-03-02 15:09:21 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 1 loss:0.032013434916734695 norm:0.0006368381436914206 max memory_allocated 29269.37548828125 
[2025-03-02 15:10:10 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 2 loss:0.030076326802372932 norm:0.00034697804949246347 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:00 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 3 loss:0.028982002288103104 norm:0.0002447335282340646 max memory_allocated 29269.37548828125 
[2025-03-02 15:11:50 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 4 loss:0.028221342712640762 norm:0.00020097654487472028 max memory_allocated 29269.37548828125 
[2025-03-02 15:12:39 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 5 loss:0.027741670608520508 norm:0.00017952042981050909 max memory_allocated 29269.37548828125 
[2025-03-02 15:13:29 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 6 loss:0.027480516582727432 norm:0.00016428300295956433 max memory_allocated 29269.37548828125 
[2025-03-02 15:14:19 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 7 loss:0.02734462171792984 norm:0.00016303571464959532 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:09 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 8 loss:0.027233310043811798 norm:0.0001503356616012752 max memory_allocated 29269.37548828125 
[2025-03-02 15:15:59 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 9 loss:0.027188781648874283 norm:0.0001415172591805458 max memory_allocated 29269.37548828125 
[2025-03-02 15:16:49 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 10 loss:0.027173440903425217 norm:0.00014417542843148112 max memory_allocated 29269.37548828125 
[2025-03-02 15:17:38 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 11 loss:0.0271598007529974 norm:0.00013897971075493842 max memory_allocated 29269.37548828125 
[2025-03-02 15:18:28 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 12 loss:0.027142202481627464 norm:0.00013922979997005314 max memory_allocated 29269.37548828125 
[2025-03-02 15:19:18 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 13 loss:0.027120226994156837 norm:0.00014301457849796861 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:08 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 14 loss:0.027114558964967728 norm:0.00013449102698359638 max memory_allocated 29269.37548828125 
[2025-03-02 15:20:57 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 15 loss:0.027087025344371796 norm:0.00013345040497370064 max memory_allocated 29269.37548828125 
[2025-03-02 15:21:47 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 16 loss:0.027054522186517715 norm:0.00013167721044737846 max memory_allocated 29269.37548828125 
[2025-03-02 15:22:37 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 17 loss:0.027031496167182922 norm:0.00013353160466067493 max memory_allocated 29269.37548828125 
[2025-03-02 15:23:27 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 18 loss:0.02701658383011818 norm:0.00013244652654975653 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:17 root] (abq_llm_calib_config2.py 396): INFO layer 8 iter 19 loss:0.026997096836566925 norm:0.0001306450431002304 max memory_allocated 29269.37548828125 
[2025-03-02 15:24:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 9 ===
[2025-03-02 15:25:25 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 0 loss:0.03872781619429588 norm:0.0012384416768327355 max memory_allocated 29269.56298828125 
[2025-03-02 15:26:14 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 1 loss:0.03400523215532303 norm:0.0005403771647252142 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:04 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 2 loss:0.03213503211736679 norm:0.00028851605020463467 max memory_allocated 29269.56298828125 
[2025-03-02 15:27:54 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 3 loss:0.031124524772167206 norm:0.00019743628217838705 max memory_allocated 29269.56298828125 
[2025-03-02 15:28:44 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 4 loss:0.030445577576756477 norm:0.00016343044990208 max memory_allocated 29269.56298828125 
[2025-03-02 15:29:33 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 5 loss:0.030022580176591873 norm:0.0001478924386901781 max memory_allocated 29269.56298828125 
[2025-03-02 15:30:23 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 6 loss:0.029772566631436348 norm:0.00013868382666260004 max memory_allocated 29269.56298828125 
[2025-03-02 15:31:13 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 7 loss:0.029645301401615143 norm:0.00013398451847024262 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:03 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 8 loss:0.029584497213363647 norm:0.00012932377285324037 max memory_allocated 29269.56298828125 
[2025-03-02 15:32:52 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 9 loss:0.029553048312664032 norm:0.00013311253860592842 max memory_allocated 29269.56298828125 
[2025-03-02 15:33:42 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 10 loss:0.02953392267227173 norm:0.0001311339292442426 max memory_allocated 29269.56298828125 
[2025-03-02 15:34:32 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 11 loss:0.02950308471918106 norm:0.00012692331802099943 max memory_allocated 29269.56298828125 
[2025-03-02 15:35:21 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 12 loss:0.029499495401978493 norm:0.0001286870101466775 max memory_allocated 29269.56298828125 
[2025-03-02 15:36:11 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 13 loss:0.029476840049028397 norm:0.00012957044236827642 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:01 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 14 loss:0.02945966087281704 norm:0.00013022891653236002 max memory_allocated 29269.56298828125 
[2025-03-02 15:37:51 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 15 loss:0.029447011649608612 norm:0.00012691831216216087 max memory_allocated 29269.56298828125 
[2025-03-02 15:38:41 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 16 loss:0.029442723840475082 norm:0.00012880605936516076 max memory_allocated 29269.56298828125 
[2025-03-02 15:39:30 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 17 loss:0.02943401411175728 norm:0.0001353379775537178 max memory_allocated 29269.56298828125 
[2025-03-02 15:40:20 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 18 loss:0.029434561729431152 norm:0.00014100476983003318 max memory_allocated 29269.56298828125 
[2025-03-02 15:41:10 root] (abq_llm_calib_config2.py 396): INFO layer 9 iter 19 loss:0.02943222038447857 norm:0.00014971429482102394 max memory_allocated 29269.56298828125 
[2025-03-02 15:41:24 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 10 ===
[2025-03-02 15:42:18 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 0 loss:0.04029148817062378 norm:0.0010380110470578074 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:08 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 1 loss:0.03612160682678223 norm:0.000415623391745612 max memory_allocated 29269.75048828125 
[2025-03-02 15:43:58 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 2 loss:0.03459445387125015 norm:0.00024052374646998942 max memory_allocated 29269.75048828125 
[2025-03-02 15:44:47 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 3 loss:0.033684246242046356 norm:0.0001841497578425333 max memory_allocated 29269.75048828125 
[2025-03-02 15:45:37 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 4 loss:0.03300769627094269 norm:0.00015541850007139146 max memory_allocated 29269.75048828125 
[2025-03-02 15:46:27 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 5 loss:0.032594047486782074 norm:0.00013855998986400664 max memory_allocated 29269.75048828125 
[2025-03-02 15:47:16 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 6 loss:0.03234652057290077 norm:0.0001297685957979411 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:06 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 7 loss:0.032224565744400024 norm:0.00012500555021688342 max memory_allocated 29269.75048828125 
[2025-03-02 15:48:56 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 8 loss:0.03212849795818329 norm:0.00011725677904905751 max memory_allocated 29269.75048828125 
[2025-03-02 15:49:46 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 9 loss:0.03209403157234192 norm:0.00011856003402499482 max memory_allocated 29269.75048828125 
[2025-03-02 15:50:35 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 10 loss:0.03204131871461868 norm:0.0001167930822703056 max memory_allocated 29269.75048828125 
[2025-03-02 15:51:25 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 11 loss:0.03202342614531517 norm:0.00011431512393755838 max memory_allocated 29269.75048828125 
[2025-03-02 15:52:15 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 12 loss:0.03197961673140526 norm:0.00011022925173165277 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:05 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 13 loss:0.03194979578256607 norm:0.00010856763401534408 max memory_allocated 29269.75048828125 
[2025-03-02 15:53:54 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 14 loss:0.031949110329151154 norm:0.00011042786354664713 max memory_allocated 29269.75048828125 
[2025-03-02 15:54:44 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 15 loss:0.03196243196725845 norm:0.00011141664435854182 max memory_allocated 29269.75048828125 
[2025-03-02 15:55:34 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 16 loss:0.031966958194971085 norm:0.0001103612084989436 max memory_allocated 29269.75048828125 
[2025-03-02 15:56:23 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 17 loss:0.032004423439502716 norm:0.00011331903078826144 max memory_allocated 29269.75048828125 
[2025-03-02 15:57:13 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 18 loss:0.031987980008125305 norm:0.000113181937194895 max memory_allocated 29269.75048828125 
[2025-03-02 15:58:03 root] (abq_llm_calib_config2.py 396): INFO layer 10 iter 19 loss:0.03197424113750458 norm:0.00011103848373750225 max memory_allocated 29269.75048828125 
[2025-03-02 15:58:17 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 11 ===
[2025-03-02 15:59:11 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 0 loss:0.04373518377542496 norm:0.0010900358902290463 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:01 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 1 loss:0.039622511714696884 norm:0.00047860207268968225 max memory_allocated 29269.93798828125 
[2025-03-02 16:00:51 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 2 loss:0.037628479301929474 norm:0.0002611943637020886 max memory_allocated 29269.93798828125 
[2025-03-02 16:01:40 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 3 loss:0.03661132603883743 norm:0.00017890980234369636 max memory_allocated 29269.93798828125 
[2025-03-02 16:02:30 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 4 loss:0.0359262153506279 norm:0.00014717578596901149 max memory_allocated 29269.93798828125 
[2025-03-02 16:03:20 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 5 loss:0.03546653315424919 norm:0.00012990256072953343 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:09 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 6 loss:0.035242609679698944 norm:0.0001243944134330377 max memory_allocated 29269.93798828125 
[2025-03-02 16:04:59 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 7 loss:0.035117730498313904 norm:0.00012141979823354632 max memory_allocated 29269.93798828125 
[2025-03-02 16:05:49 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 8 loss:0.035058122128248215 norm:0.00011833876487798989 max memory_allocated 29269.93798828125 
[2025-03-02 16:06:38 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 9 loss:0.03500666096806526 norm:0.00011279396858299151 max memory_allocated 29269.93798828125 
[2025-03-02 16:07:28 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 10 loss:0.03495604917407036 norm:0.00010998694051522762 max memory_allocated 29269.93798828125 
[2025-03-02 16:08:18 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 11 loss:0.03494096174836159 norm:0.00010877862951019779 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:07 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 12 loss:0.0349118746817112 norm:0.00011124490993097425 max memory_allocated 29269.93798828125 
[2025-03-02 16:09:57 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 13 loss:0.034889597445726395 norm:0.0001080557267414406 max memory_allocated 29269.93798828125 
[2025-03-02 16:10:47 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 14 loss:0.03487499803304672 norm:0.00010667520837159827 max memory_allocated 29269.93798828125 
[2025-03-02 16:11:36 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 15 loss:0.03486655652523041 norm:0.00010527529229875654 max memory_allocated 29269.93798828125 
[2025-03-02 16:12:26 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 16 loss:0.03486244007945061 norm:0.0001081839291146025 max memory_allocated 29269.93798828125 
[2025-03-02 16:13:15 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 17 loss:0.03488157317042351 norm:0.00010769355139927939 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:05 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 18 loss:0.03489536792039871 norm:0.00010789842053782195 max memory_allocated 29269.93798828125 
[2025-03-02 16:14:55 root] (abq_llm_calib_config2.py 396): INFO layer 11 iter 19 loss:0.03492555022239685 norm:0.00011295425792923197 max memory_allocated 29269.93798828125 
[2025-03-02 16:15:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 12 ===
[2025-03-02 16:16:03 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 0 loss:0.04383355751633644 norm:0.0008773473091423512 max memory_allocated 29270.12548828125 
[2025-03-02 16:16:53 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 1 loss:0.04086272418498993 norm:0.0003968020319007337 max memory_allocated 29270.12548828125 
[2025-03-02 16:17:42 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 2 loss:0.03943406045436859 norm:0.0002440546522848308 max memory_allocated 29270.12548828125 
[2025-03-02 16:18:32 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 3 loss:0.038491733372211456 norm:0.0001772258256096393 max memory_allocated 29270.12548828125 
[2025-03-02 16:19:22 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 4 loss:0.037755586206912994 norm:0.00014479979290626943 max memory_allocated 29270.12548828125 
[2025-03-02 16:20:12 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 5 loss:0.037339095026254654 norm:0.00012924736074637622 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:01 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 6 loss:0.03712792694568634 norm:0.00012317235814407468 max memory_allocated 29270.12548828125 
[2025-03-02 16:21:51 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 7 loss:0.0370231568813324 norm:0.00011789760901592672 max memory_allocated 29270.12548828125 
[2025-03-02 16:22:40 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 8 loss:0.036949872970581055 norm:0.00011546789028216153 max memory_allocated 29270.12548828125 
[2025-03-02 16:23:30 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 9 loss:0.03689674288034439 norm:0.00011042448750231415 max memory_allocated 29270.12548828125 
[2025-03-02 16:24:20 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 10 loss:0.036864541471004486 norm:0.00010890085104620084 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:10 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 11 loss:0.036838553845882416 norm:0.00010630162432789803 max memory_allocated 29270.12548828125 
[2025-03-02 16:25:59 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 12 loss:0.03682476654648781 norm:0.00010495519381947815 max memory_allocated 29270.12548828125 
[2025-03-02 16:26:49 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 13 loss:0.03681887686252594 norm:0.00010293546802131459 max memory_allocated 29270.12548828125 
[2025-03-02 16:27:39 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 14 loss:0.036795925348997116 norm:0.00010645505972206593 max memory_allocated 29270.12548828125 
[2025-03-02 16:28:28 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 15 loss:0.03679712489247322 norm:0.00010735511023085564 max memory_allocated 29270.12548828125 
[2025-03-02 16:29:18 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 16 loss:0.0367899015545845 norm:0.00010648337774910033 max memory_allocated 29270.12548828125 
[2025-03-02 16:30:07 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 17 loss:0.036779895424842834 norm:0.00010723320156103 max memory_allocated 29270.12548828125 
[2025-03-02 16:30:57 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 18 loss:0.036779001355171204 norm:0.00010960544750560075 max memory_allocated 29270.12548828125 
[2025-03-02 16:31:47 root] (abq_llm_calib_config2.py 396): INFO layer 12 iter 19 loss:0.036766357719898224 norm:0.00010746720363385975 max memory_allocated 29270.12548828125 
[2025-03-02 16:32:01 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 13 ===
[2025-03-02 16:32:55 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 0 loss:0.045674826949834824 norm:0.0006651212461292744 max memory_allocated 29270.31298828125 
[2025-03-02 16:33:45 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 1 loss:0.042933687567710876 norm:0.0003394268569536507 max memory_allocated 29270.31298828125 
[2025-03-02 16:34:35 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 2 loss:0.041510455310344696 norm:0.00022669127793051302 max memory_allocated 29270.31298828125 
[2025-03-02 16:35:24 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 3 loss:0.04055221006274223 norm:0.00017142044089268893 max memory_allocated 29270.31298828125 
[2025-03-02 16:36:14 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 4 loss:0.039829738438129425 norm:0.0001424070360371843 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:04 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 5 loss:0.039375804364681244 norm:0.00012980710016563535 max memory_allocated 29270.31298828125 
[2025-03-02 16:37:53 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 6 loss:0.039124682545661926 norm:0.0001195162913063541 max memory_allocated 29270.31298828125 
[2025-03-02 16:38:43 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 7 loss:0.038998693227767944 norm:0.00011669856030493975 max memory_allocated 29270.31298828125 
[2025-03-02 16:39:33 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 8 loss:0.038934722542762756 norm:0.00011191106750629842 max memory_allocated 29270.31298828125 
[2025-03-02 16:40:22 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 9 loss:0.03888595104217529 norm:0.0001128295625676401 max memory_allocated 29270.31298828125 
[2025-03-02 16:41:12 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 10 loss:0.03883152827620506 norm:0.00010791046224767342 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:02 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 11 loss:0.038799989968538284 norm:0.00010949558054562658 max memory_allocated 29270.31298828125 
[2025-03-02 16:42:51 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 12 loss:0.038788843899965286 norm:0.00010995916818501428 max memory_allocated 29270.31298828125 
[2025-03-02 16:43:41 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 13 loss:0.038774773478507996 norm:0.00010934395686490461 max memory_allocated 29270.31298828125 
[2025-03-02 16:44:31 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 14 loss:0.03876788914203644 norm:0.00010806760838022456 max memory_allocated 29270.31298828125 
[2025-03-02 16:45:20 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 15 loss:0.038757771253585815 norm:0.00010677690443117172 max memory_allocated 29270.31298828125 
[2025-03-02 16:46:10 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 16 loss:0.038725219666957855 norm:0.00010455292067490518 max memory_allocated 29270.31298828125 
[2025-03-02 16:47:00 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 17 loss:0.03871676325798035 norm:0.00010270337224937975 max memory_allocated 29270.31298828125 
[2025-03-02 16:47:49 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 18 loss:0.038725003600120544 norm:0.00010388420196250081 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:39 root] (abq_llm_calib_config2.py 396): INFO layer 13 iter 19 loss:0.03871893137693405 norm:0.00010622683475958183 max memory_allocated 29270.31298828125 
[2025-03-02 16:48:54 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 14 ===
[2025-03-02 16:49:48 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 0 loss:0.049219291657209396 norm:0.0010193928610533476 max memory_allocated 29270.50048828125 
[2025-03-02 16:50:38 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 1 loss:0.0457732267677784 norm:0.0005037597729824483 max memory_allocated 29270.50048828125 
[2025-03-02 16:51:27 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 2 loss:0.044056255370378494 norm:0.00030998961301520467 max memory_allocated 29270.50048828125 
[2025-03-02 16:52:17 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 3 loss:0.042974211275577545 norm:0.00022103333321865648 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:07 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 4 loss:0.04219018295407295 norm:0.0001716258266242221 max memory_allocated 29270.50048828125 
[2025-03-02 16:53:56 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 5 loss:0.041718170046806335 norm:0.0001496632321504876 max memory_allocated 29270.50048828125 
[2025-03-02 16:54:46 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 6 loss:0.04148419201374054 norm:0.00013527472037822008 max memory_allocated 29270.50048828125 
[2025-03-02 16:55:36 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 7 loss:0.04133356362581253 norm:0.00012529967352747917 max memory_allocated 29270.50048828125 
[2025-03-02 16:56:25 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 8 loss:0.04124819487333298 norm:0.00012121909821871668 max memory_allocated 29270.50048828125 
[2025-03-02 16:57:15 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 9 loss:0.04121111333370209 norm:0.00011736594751710072 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:05 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 10 loss:0.0411904901266098 norm:0.00011319201439619064 max memory_allocated 29270.50048828125 
[2025-03-02 16:58:54 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 11 loss:0.04116638004779816 norm:0.00010963466775137931 max memory_allocated 29270.50048828125 
[2025-03-02 16:59:44 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 12 loss:0.04113968461751938 norm:0.00011092800559708849 max memory_allocated 29270.50048828125 
[2025-03-02 17:00:34 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 13 loss:0.04112345352768898 norm:0.0001102667665691115 max memory_allocated 29270.50048828125 
[2025-03-02 17:01:23 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 14 loss:0.041112981736660004 norm:0.00010983530955854803 max memory_allocated 29270.50048828125 
[2025-03-02 17:02:13 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 15 loss:0.04109030216932297 norm:0.00011133067891933024 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:03 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 16 loss:0.04108110070228577 norm:0.0001098237480618991 max memory_allocated 29270.50048828125 
[2025-03-02 17:03:53 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 17 loss:0.04108421131968498 norm:0.00010857771121663973 max memory_allocated 29270.50048828125 
[2025-03-02 17:04:42 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 18 loss:0.041080232709646225 norm:0.00010878013563342392 max memory_allocated 29270.50048828125 
[2025-03-02 17:05:32 root] (abq_llm_calib_config2.py 396): INFO layer 14 iter 19 loss:0.0410604253411293 norm:0.00010805153578985482 max memory_allocated 29270.50048828125 
[2025-03-02 17:05:46 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 15 ===
[2025-03-02 17:06:40 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 0 loss:0.05145680159330368 norm:0.000787346507422626 max memory_allocated 29270.68798828125 
[2025-03-02 17:07:30 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 1 loss:0.04846092313528061 norm:0.00032474385807290673 max memory_allocated 29270.68798828125 
[2025-03-02 17:08:19 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 2 loss:0.047120559960603714 norm:0.00022922483913134784 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:09 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 3 loss:0.046112120151519775 norm:0.00018332870968151838 max memory_allocated 29270.68798828125 
[2025-03-02 17:09:59 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 4 loss:0.04530688375234604 norm:0.00015304422413464636 max memory_allocated 29270.68798828125 
[2025-03-02 17:10:48 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 5 loss:0.04478868097066879 norm:0.0001364204363198951 max memory_allocated 29270.68798828125 
[2025-03-02 17:11:38 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 6 loss:0.044523946940898895 norm:0.00012799250544048846 max memory_allocated 29270.68798828125 
[2025-03-02 17:12:28 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 7 loss:0.04441143944859505 norm:0.00012064447946613654 max memory_allocated 29270.68798828125 
[2025-03-02 17:13:18 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 8 loss:0.04434587433934212 norm:0.00011229234223719686 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:07 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 9 loss:0.04427922144532204 norm:0.00011118314432678744 max memory_allocated 29270.68798828125 
[2025-03-02 17:14:57 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 10 loss:0.04424189031124115 norm:0.00011022252874681726 max memory_allocated 29270.68798828125 
[2025-03-02 17:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 11 loss:0.04421359673142433 norm:0.00010499972268007696 max memory_allocated 29270.68798828125 
[2025-03-02 17:16:36 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 12 loss:0.04416981339454651 norm:0.00010035473678726703 max memory_allocated 29270.68798828125 
[2025-03-02 17:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 13 loss:0.04414134472608566 norm:9.827288158703595e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 14 loss:0.04413112998008728 norm:9.899323049467057e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:05 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 15 loss:0.04413652420043945 norm:9.979885362554342e-05 max memory_allocated 29270.68798828125 
[2025-03-02 17:19:55 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 16 loss:0.044129855930805206 norm:0.00010150093294214457 max memory_allocated 29270.68798828125 
[2025-03-02 17:20:45 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 17 loss:0.044135335832834244 norm:0.00010380729509051889 max memory_allocated 29270.68798828125 
[2025-03-02 17:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 18 loss:0.04413001611828804 norm:0.00010229434701614082 max memory_allocated 29270.68798828125 
[2025-03-02 17:22:24 root] (abq_llm_calib_config2.py 396): INFO layer 15 iter 19 loss:0.04412756487727165 norm:0.00010084774839924648 max memory_allocated 29270.68798828125 
[2025-03-02 17:22:39 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 16 ===
[2025-03-02 17:23:32 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 0 loss:0.053888823837041855 norm:0.0010720450663939118 max memory_allocated 29270.87548828125 
[2025-03-02 17:24:22 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 1 loss:0.05156117305159569 norm:0.0005226153880357742 max memory_allocated 29270.87548828125 
[2025-03-02 17:25:12 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 2 loss:0.05035725608468056 norm:0.00032436949550174177 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:02 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 3 loss:0.049404844641685486 norm:0.00022990260913502425 max memory_allocated 29270.87548828125 
[2025-03-02 17:26:51 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 4 loss:0.048597149550914764 norm:0.0001748061622492969 max memory_allocated 29270.87548828125 
[2025-03-02 17:27:41 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 5 loss:0.04813898727297783 norm:0.00014237053983379155 max memory_allocated 29270.87548828125 
[2025-03-02 17:28:31 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 6 loss:0.04795755073428154 norm:0.00012548525410238653 max memory_allocated 29270.87548828125 
[2025-03-02 17:29:20 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 7 loss:0.047889046370983124 norm:0.00011746160453185439 max memory_allocated 29270.87548828125 
[2025-03-02 17:30:10 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 8 loss:0.047826237976551056 norm:0.00010956819460261613 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:00 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 9 loss:0.047786418348550797 norm:0.00010563561954768375 max memory_allocated 29270.87548828125 
[2025-03-02 17:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 10 loss:0.04775307700037956 norm:0.00010355923586757854 max memory_allocated 29270.87548828125 
[2025-03-02 17:32:39 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 11 loss:0.04773687198758125 norm:0.00010284679592587054 max memory_allocated 29270.87548828125 
[2025-03-02 17:33:29 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 12 loss:0.047713302075862885 norm:0.00010182838013861328 max memory_allocated 29270.87548828125 
[2025-03-02 17:34:18 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 13 loss:0.047703009098768234 norm:9.995467553380877e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:08 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 14 loss:0.047695428133010864 norm:9.884408791549504e-05 max memory_allocated 29270.87548828125 
[2025-03-02 17:35:58 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 15 loss:0.04768452048301697 norm:0.00010149754234589636 max memory_allocated 29270.87548828125 
[2025-03-02 17:36:47 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 16 loss:0.0476686954498291 norm:0.0001007642931654118 max memory_allocated 29270.87548828125 
[2025-03-02 17:37:37 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 17 loss:0.04766332730650902 norm:0.00010039312473963946 max memory_allocated 29270.87548828125 
[2025-03-02 17:38:27 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 18 loss:0.047660984098911285 norm:0.00010337388084735721 max memory_allocated 29270.87548828125 
[2025-03-02 17:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 16 iter 19 loss:0.04765886068344116 norm:0.00010312015365343541 max memory_allocated 29270.87548828125 
[2025-03-02 17:39:31 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 17 ===
[2025-03-02 17:40:25 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 0 loss:0.05895211175084114 norm:0.0014205087209120393 max memory_allocated 29271.06298828125 
[2025-03-02 17:41:14 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 1 loss:0.056114841252565384 norm:0.000647009233944118 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:04 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 2 loss:0.05463273823261261 norm:0.0003898917930200696 max memory_allocated 29271.06298828125 
[2025-03-02 17:42:53 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 3 loss:0.05345278978347778 norm:0.0002663790655788034 max memory_allocated 29271.06298828125 
[2025-03-02 17:43:43 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 4 loss:0.05254693329334259 norm:0.00019679171964526176 max memory_allocated 29271.06298828125 
[2025-03-02 17:44:33 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 5 loss:0.05207384377717972 norm:0.00015841318236198276 max memory_allocated 29271.06298828125 
[2025-03-02 17:45:23 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 6 loss:0.05187695473432541 norm:0.00013693120854441077 max memory_allocated 29271.06298828125 
[2025-03-02 17:46:12 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 7 loss:0.051767900586128235 norm:0.00011959839321207255 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:02 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 8 loss:0.0516977421939373 norm:0.00010982189996866509 max memory_allocated 29271.06298828125 
[2025-03-02 17:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 9 loss:0.051657628268003464 norm:0.0001038426926243119 max memory_allocated 29271.06298828125 
[2025-03-02 17:48:41 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 10 loss:0.05162151902914047 norm:9.937628055922687e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:49:31 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 11 loss:0.05160699039697647 norm:9.768587915459648e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:50:21 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 12 loss:0.05159071832895279 norm:9.575024159858003e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:51:10 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 13 loss:0.05157070234417915 norm:9.481834422331303e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:00 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 14 loss:0.05156037211418152 norm:9.424247400602326e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:52:50 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 15 loss:0.05156734585762024 norm:9.6790878160391e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:53:39 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 16 loss:0.051544249057769775 norm:9.415581007488072e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:54:29 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 17 loss:0.0515313595533371 norm:9.532804688205943e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:55:19 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 18 loss:0.051522139459848404 norm:9.435948595637456e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:56:08 root] (abq_llm_calib_config2.py 396): INFO layer 17 iter 19 loss:0.051526039838790894 norm:9.734565537655726e-05 max memory_allocated 29271.06298828125 
[2025-03-02 17:56:23 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 18 ===
[2025-03-02 17:57:16 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 0 loss:0.06502397358417511 norm:0.0013060395140200853 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:06 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 1 loss:0.06203525513410568 norm:0.0005570636712945998 max memory_allocated 29271.25048828125 
[2025-03-02 17:58:56 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 2 loss:0.06044970452785492 norm:0.00032897735945880413 max memory_allocated 29271.25048828125 
[2025-03-02 17:59:45 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 3 loss:0.059226538985967636 norm:0.00022766346228308976 max memory_allocated 29271.25048828125 
[2025-03-02 18:00:35 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 4 loss:0.05832196772098541 norm:0.00017842312809079885 max memory_allocated 29271.25048828125 
[2025-03-02 18:01:24 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 5 loss:0.057907283306121826 norm:0.00015415613597724587 max memory_allocated 29271.25048828125 
[2025-03-02 18:02:14 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 6 loss:0.05772223323583603 norm:0.00014145577733870596 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:04 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 7 loss:0.05760212615132332 norm:0.00012897125270683318 max memory_allocated 29271.25048828125 
[2025-03-02 18:03:53 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 8 loss:0.05753054469823837 norm:0.0001242987927980721 max memory_allocated 29271.25048828125 
[2025-03-02 18:04:43 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 9 loss:0.05747940018773079 norm:0.00011979979171883315 max memory_allocated 29271.25048828125 
[2025-03-02 18:05:33 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 10 loss:0.057426851242780685 norm:0.0001163299020845443 max memory_allocated 29271.25048828125 
[2025-03-02 18:06:22 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 11 loss:0.05741356685757637 norm:0.00011713341518770903 max memory_allocated 29271.25048828125 
[2025-03-02 18:07:12 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 12 loss:0.057377930730581284 norm:0.00011534940858837217 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:02 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 13 loss:0.05733099207282066 norm:0.00011072208872064948 max memory_allocated 29271.25048828125 
[2025-03-02 18:08:51 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 14 loss:0.05731957033276558 norm:0.00011185399489477277 max memory_allocated 29271.25048828125 
[2025-03-02 18:09:40 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 15 loss:0.057321567088365555 norm:0.00011195597471669316 max memory_allocated 29271.25048828125 
[2025-03-02 18:10:30 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 16 loss:0.05731835588812828 norm:0.00011252498370595276 max memory_allocated 29271.25048828125 
[2025-03-02 18:11:20 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 17 loss:0.057332877069711685 norm:0.00011602060840232298 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:10 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 18 loss:0.05732889100909233 norm:0.00011490048200357705 max memory_allocated 29271.25048828125 
[2025-03-02 18:12:59 root] (abq_llm_calib_config2.py 396): INFO layer 18 iter 19 loss:0.05731796473264694 norm:0.0001153322373284027 max memory_allocated 29271.25048828125 
[2025-03-02 18:13:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 19 ===
[2025-03-02 18:14:07 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 0 loss:0.07024264335632324 norm:0.0008842091774567962 max memory_allocated 29271.43798828125 
[2025-03-02 18:14:57 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 1 loss:0.06810533255338669 norm:0.00040310053736902773 max memory_allocated 29271.43798828125 
[2025-03-02 18:15:47 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 2 loss:0.06667743623256683 norm:0.0002579106076154858 max memory_allocated 29271.43798828125 
[2025-03-02 18:16:36 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 3 loss:0.06540574133396149 norm:0.00018454452219884843 max memory_allocated 29271.43798828125 
[2025-03-02 18:17:26 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 4 loss:0.0645100399851799 norm:0.00015094074478838593 max memory_allocated 29271.43798828125 
[2025-03-02 18:18:16 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 5 loss:0.0641738548874855 norm:0.00012993827112950385 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:05 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 6 loss:0.06405907869338989 norm:0.00011908952728845179 max memory_allocated 29271.43798828125 
[2025-03-02 18:19:55 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 7 loss:0.06398025900125504 norm:0.00011028583685401827 max memory_allocated 29271.43798828125 
[2025-03-02 18:20:45 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 8 loss:0.06393368542194366 norm:0.00010892857244471088 max memory_allocated 29271.43798828125 
[2025-03-02 18:21:34 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 9 loss:0.06387481093406677 norm:0.00010589764133328572 max memory_allocated 29271.43798828125 
[2025-03-02 18:22:24 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 10 loss:0.06384547054767609 norm:0.00010367103095632046 max memory_allocated 29271.43798828125 
[2025-03-02 18:23:14 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 11 loss:0.06380102038383484 norm:0.00010200549877481535 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:03 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 12 loss:0.06380251795053482 norm:0.00010465640662005171 max memory_allocated 29271.43798828125 
[2025-03-02 18:24:53 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 13 loss:0.06379195302724838 norm:0.00010386179201304913 max memory_allocated 29271.43798828125 
[2025-03-02 18:25:43 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 14 loss:0.06377894431352615 norm:0.00010375673446105793 max memory_allocated 29271.43798828125 
[2025-03-02 18:26:32 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 15 loss:0.06379371136426926 norm:0.00010455114534124732 max memory_allocated 29271.43798828125 
[2025-03-02 18:27:22 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 16 loss:0.06379061192274094 norm:0.00010514302994124591 max memory_allocated 29271.43798828125 
[2025-03-02 18:28:12 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 17 loss:0.06377558410167694 norm:0.000105313491076231 max memory_allocated 29271.43798828125 
[2025-03-02 18:29:01 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 18 loss:0.06378971040248871 norm:0.00010933844896499068 max memory_allocated 29271.43798828125 
[2025-03-02 18:29:51 root] (abq_llm_calib_config2.py 396): INFO layer 19 iter 19 loss:0.06378570199012756 norm:0.00011054451169911772 max memory_allocated 29271.43798828125 
[2025-03-02 18:30:05 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 20 ===
[2025-03-02 18:30:59 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 0 loss:0.0781371220946312 norm:0.0008123045554384589 max memory_allocated 29271.62548828125 
[2025-03-02 18:31:49 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 1 loss:0.0753365308046341 norm:0.00037510553374886513 max memory_allocated 29271.62548828125 
[2025-03-02 18:32:38 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 2 loss:0.07375174015760422 norm:0.0002520972630009055 max memory_allocated 29271.62548828125 
[2025-03-02 18:33:28 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 3 loss:0.07231077551841736 norm:0.0001885164820123464 max memory_allocated 29271.62548828125 
[2025-03-02 18:34:18 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 4 loss:0.07135704159736633 norm:0.00015571978292427957 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:08 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 5 loss:0.0710388794541359 norm:0.0001380166650051251 max memory_allocated 29271.62548828125 
[2025-03-02 18:35:57 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 6 loss:0.07090175896883011 norm:0.00012577854795381427 max memory_allocated 29271.62548828125 
[2025-03-02 18:36:47 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 7 loss:0.0707990974187851 norm:0.00011641850869636983 max memory_allocated 29271.62548828125 
[2025-03-02 18:37:36 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 8 loss:0.07071938365697861 norm:0.00011206288763787597 max memory_allocated 29271.62548828125 
[2025-03-02 18:38:26 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 9 loss:0.07064691931009293 norm:0.00010979808575939387 max memory_allocated 29271.62548828125 
[2025-03-02 18:39:16 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 10 loss:0.0705961063504219 norm:0.0001047921396093443 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:06 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 11 loss:0.07055602967739105 norm:0.00010152547474717721 max memory_allocated 29271.62548828125 
[2025-03-02 18:40:56 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 12 loss:0.0705379843711853 norm:0.00010192734043812379 max memory_allocated 29271.62548828125 
[2025-03-02 18:41:45 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 13 loss:0.07052106410264969 norm:0.00010369312803959474 max memory_allocated 29271.62548828125 
[2025-03-02 18:42:35 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 14 loss:0.07048511505126953 norm:0.00010058120096800849 max memory_allocated 29271.62548828125 
[2025-03-02 18:43:25 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 15 loss:0.07046426832675934 norm:0.00010080695938086137 max memory_allocated 29271.62548828125 
[2025-03-02 18:44:14 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 16 loss:0.07045436650514603 norm:0.00010181073594139889 max memory_allocated 29271.62548828125 
[2025-03-02 18:45:04 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 17 loss:0.07044486701488495 norm:9.975174907594919e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:45:54 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 18 loss:0.07044374942779541 norm:9.888867498375475e-05 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:44 root] (abq_llm_calib_config2.py 396): INFO layer 20 iter 19 loss:0.07044967263936996 norm:0.00010101668885909021 max memory_allocated 29271.62548828125 
[2025-03-02 18:46:58 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 21 ===
[2025-03-02 18:47:52 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 0 loss:0.08919942378997803 norm:0.001249241759069264 max memory_allocated 29271.81298828125 
[2025-03-02 18:48:41 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 1 loss:0.08591720461845398 norm:0.0006172144785523415 max memory_allocated 29271.81298828125 
[2025-03-02 18:49:31 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 2 loss:0.08385685086250305 norm:0.0003890377120114863 max memory_allocated 29271.81298828125 
[2025-03-02 18:50:21 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 3 loss:0.08206501603126526 norm:0.0002735075540840626 max memory_allocated 29271.81298828125 
[2025-03-02 18:51:11 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 4 loss:0.08103524148464203 norm:0.0002106045139953494 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:00 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 5 loss:0.08070731163024902 norm:0.00017284070781897753 max memory_allocated 29271.81298828125 
[2025-03-02 18:52:50 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 6 loss:0.0805772915482521 norm:0.00015134950808715075 max memory_allocated 29271.81298828125 
[2025-03-02 18:53:40 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 7 loss:0.08049647510051727 norm:0.00013642216799780726 max memory_allocated 29271.81298828125 
[2025-03-02 18:54:30 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 8 loss:0.0804395079612732 norm:0.00012656970648095012 max memory_allocated 29271.81298828125 
[2025-03-02 18:55:19 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 9 loss:0.08038607239723206 norm:0.00011965790326939896 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:09 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 10 loss:0.08033600449562073 norm:0.00011242862819926813 max memory_allocated 29271.81298828125 
[2025-03-02 18:56:59 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 11 loss:0.0803067535161972 norm:0.0001094654289772734 max memory_allocated 29271.81298828125 
[2025-03-02 18:57:48 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 12 loss:0.08028309047222137 norm:0.00010434704745421186 max memory_allocated 29271.81298828125 
[2025-03-02 18:58:38 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 13 loss:0.08026088029146194 norm:9.993374987971038e-05 max memory_allocated 29271.81298828125 
[2025-03-02 18:59:28 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 14 loss:0.08024399727582932 norm:9.888108615996316e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:00:18 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 15 loss:0.08023804426193237 norm:9.87418825388886e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:01:07 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 16 loss:0.0802251398563385 norm:9.611536370357499e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:01:57 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 17 loss:0.08021896332502365 norm:9.499680163571611e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:02:47 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 18 loss:0.08022098988294601 norm:9.396222594659775e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:03:37 root] (abq_llm_calib_config2.py 396): INFO layer 21 iter 19 loss:0.08021457493305206 norm:9.398617112310603e-05 max memory_allocated 29271.81298828125 
[2025-03-02 19:03:51 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 22 ===
[2025-03-02 19:04:45 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 0 loss:0.09886827319860458 norm:0.0009716243366710842 max memory_allocated 29272.00048828125 
[2025-03-02 19:05:34 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 1 loss:0.0965290367603302 norm:0.0005090152262710035 max memory_allocated 29272.00048828125 
[2025-03-02 19:06:24 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 2 loss:0.09461291134357452 norm:0.00032059603836387396 max memory_allocated 29272.00048828125 
[2025-03-02 19:07:14 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 3 loss:0.09283234179019928 norm:0.00022285855084192008 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:03 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 4 loss:0.09185981750488281 norm:0.0001728024217300117 max memory_allocated 29272.00048828125 
[2025-03-02 19:08:53 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 5 loss:0.09159177541732788 norm:0.0001448707189410925 max memory_allocated 29272.00048828125 
[2025-03-02 19:09:43 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 6 loss:0.09149462729692459 norm:0.00012849103950429708 max memory_allocated 29272.00048828125 
[2025-03-02 19:10:32 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 7 loss:0.09142179042100906 norm:0.00011770529090426862 max memory_allocated 29272.00048828125 
[2025-03-02 19:11:22 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 8 loss:0.09136933088302612 norm:0.00011128529877169058 max memory_allocated 29272.00048828125 
[2025-03-02 19:12:12 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 9 loss:0.09132201224565506 norm:0.00010688627662602812 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:01 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 10 loss:0.09127622097730637 norm:0.00010365515481680632 max memory_allocated 29272.00048828125 
[2025-03-02 19:13:51 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 11 loss:0.09123693406581879 norm:0.00010274910891894251 max memory_allocated 29272.00048828125 
[2025-03-02 19:14:41 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 12 loss:0.09123383462429047 norm:0.00010155018389923498 max memory_allocated 29272.00048828125 
[2025-03-02 19:15:31 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 13 loss:0.09123270213603973 norm:0.0001002010831143707 max memory_allocated 29272.00048828125 
[2025-03-02 19:16:20 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 14 loss:0.09122388064861298 norm:0.00010039211338153109 max memory_allocated 29272.00048828125 
[2025-03-02 19:17:10 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 15 loss:0.09121070802211761 norm:9.98092582449317e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:18:00 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 16 loss:0.09120560437440872 norm:9.827796020545065e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:18:49 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 17 loss:0.09120071679353714 norm:9.83693462330848e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:19:39 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 18 loss:0.09120230376720428 norm:9.909459186019376e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:20:29 root] (abq_llm_calib_config2.py 396): INFO layer 22 iter 19 loss:0.09118174016475677 norm:9.848077752394602e-05 max memory_allocated 29272.00048828125 
[2025-03-02 19:20:43 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 23 ===
[2025-03-02 19:21:37 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 0 loss:0.11267523467540741 norm:0.001173369586467743 max memory_allocated 29272.18798828125 
[2025-03-02 19:22:27 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 1 loss:0.10998868197202682 norm:0.0005996005493216217 max memory_allocated 29272.18798828125 
[2025-03-02 19:23:16 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 2 loss:0.10797547549009323 norm:0.00037714684731326997 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:06 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 3 loss:0.10598008334636688 norm:0.000267053343122825 max memory_allocated 29272.18798828125 
[2025-03-02 19:24:56 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 4 loss:0.10497595369815826 norm:0.00020860240329056978 max memory_allocated 29272.18798828125 
[2025-03-02 19:25:45 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 5 loss:0.10471489280462265 norm:0.0001776229910319671 max memory_allocated 29272.18798828125 
[2025-03-02 19:26:35 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 6 loss:0.10458531230688095 norm:0.00016158242942765355 max memory_allocated 29272.18798828125 
[2025-03-02 19:27:25 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 7 loss:0.10450045764446259 norm:0.00014996134268585593 max memory_allocated 29272.18798828125 
[2025-03-02 19:28:15 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 8 loss:0.10442166775465012 norm:0.00014124812150839716 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:04 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 9 loss:0.10438569635152817 norm:0.00013376613787841052 max memory_allocated 29272.18798828125 
[2025-03-02 19:29:54 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 10 loss:0.10436464846134186 norm:0.00013361498713493347 max memory_allocated 29272.18798828125 
[2025-03-02 19:30:44 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 11 loss:0.10432308167219162 norm:0.00012804934522137046 max memory_allocated 29272.18798828125 
[2025-03-02 19:31:33 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 12 loss:0.10427499562501907 norm:0.0001272360677830875 max memory_allocated 29272.18798828125 
[2025-03-02 19:32:23 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 13 loss:0.10427257418632507 norm:0.00012544094352051616 max memory_allocated 29272.18798828125 
[2025-03-02 19:33:13 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 14 loss:0.10424071550369263 norm:0.0001241343270521611 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:02 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 15 loss:0.10421822965145111 norm:0.00012422942381817847 max memory_allocated 29272.18798828125 
[2025-03-02 19:34:52 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 16 loss:0.10421561449766159 norm:0.0001244954182766378 max memory_allocated 29272.18798828125 
[2025-03-02 19:35:42 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 17 loss:0.10422579944133759 norm:0.00012387691822368652 max memory_allocated 29272.18798828125 
[2025-03-02 19:36:31 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 18 loss:0.1042221412062645 norm:0.00012441290891729295 max memory_allocated 29272.18798828125 
[2025-03-02 19:37:21 root] (abq_llm_calib_config2.py 396): INFO layer 23 iter 19 loss:0.10422057658433914 norm:0.00012286740820854902 max memory_allocated 29272.18798828125 
[2025-03-02 19:37:35 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 24 ===
[2025-03-02 19:38:29 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 0 loss:0.12482453137636185 norm:0.0013042157515883446 max memory_allocated 29272.37548828125 
[2025-03-02 19:39:19 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 1 loss:0.12211115658283234 norm:0.0006707117427140474 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:08 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 2 loss:0.12004220485687256 norm:0.0004282953159417957 max memory_allocated 29272.37548828125 
[2025-03-02 19:40:58 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 3 loss:0.11828573048114777 norm:0.00030437661916948855 max memory_allocated 29272.37548828125 
[2025-03-02 19:41:48 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 4 loss:0.11756420135498047 norm:0.0002316248428542167 max memory_allocated 29272.37548828125 
[2025-03-02 19:42:38 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 5 loss:0.11730828881263733 norm:0.00019368492939975113 max memory_allocated 29272.37548828125 
[2025-03-02 19:43:27 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 6 loss:0.11717280000448227 norm:0.00017071241745725274 max memory_allocated 29272.37548828125 
[2025-03-02 19:44:17 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 7 loss:0.1171213760972023 norm:0.00015450973296537995 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:07 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 8 loss:0.11706028878688812 norm:0.00014681283209938556 max memory_allocated 29272.37548828125 
[2025-03-02 19:45:56 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 9 loss:0.11701229959726334 norm:0.00013573393516708165 max memory_allocated 29272.37548828125 
[2025-03-02 19:46:46 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 10 loss:0.1169872134923935 norm:0.0001324064505752176 max memory_allocated 29272.37548828125 
[2025-03-02 19:47:36 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 11 loss:0.1169646829366684 norm:0.00012807289022020996 max memory_allocated 29272.37548828125 
[2025-03-02 19:48:25 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 12 loss:0.11694841086864471 norm:0.00012772096670232713 max memory_allocated 29272.37548828125 
[2025-03-02 19:49:15 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 13 loss:0.11693165451288223 norm:0.00012605928350239992 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:05 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 14 loss:0.11691196262836456 norm:0.00012317177606746554 max memory_allocated 29272.37548828125 
[2025-03-02 19:50:55 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 15 loss:0.11691045761108398 norm:0.00012367348244879395 max memory_allocated 29272.37548828125 
[2025-03-02 19:51:44 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 16 loss:0.1169012039899826 norm:0.00012112841795897111 max memory_allocated 29272.37548828125 
[2025-03-02 19:52:34 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 17 loss:0.11689687520265579 norm:0.00012158248864579946 max memory_allocated 29272.37548828125 
[2025-03-02 19:53:24 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 18 loss:0.11689641326665878 norm:0.00012290726590435952 max memory_allocated 29272.37548828125 
[2025-03-02 19:54:13 root] (abq_llm_calib_config2.py 396): INFO layer 24 iter 19 loss:0.11688221991062164 norm:0.00012190188863314688 max memory_allocated 29272.37548828125 
[2025-03-02 19:54:28 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 25 ===
[2025-03-02 19:55:22 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 0 loss:0.14104989171028137 norm:0.0009676900808699429 max memory_allocated 29272.56298828125 
[2025-03-02 19:56:11 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 1 loss:0.13885213434696198 norm:0.0005195390549488366 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:01 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 2 loss:0.1366967409849167 norm:0.00033772396272979677 max memory_allocated 29272.56298828125 
[2025-03-02 19:57:51 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 3 loss:0.1344815492630005 norm:0.0002452396438457072 max memory_allocated 29272.56298828125 
[2025-03-02 19:58:40 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 4 loss:0.13363517820835114 norm:0.00019460587645880878 max memory_allocated 29272.56298828125 
[2025-03-02 19:59:30 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 5 loss:0.13338536024093628 norm:0.00016704926383681595 max memory_allocated 29272.56298828125 
[2025-03-02 20:00:20 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 6 loss:0.13325627148151398 norm:0.00014794731396250427 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:10 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 7 loss:0.13317188620567322 norm:0.00013836764264851809 max memory_allocated 29272.56298828125 
[2025-03-02 20:01:59 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 8 loss:0.133114755153656 norm:0.00012937946303281933 max memory_allocated 29272.56298828125 
[2025-03-02 20:02:49 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 9 loss:0.13306915760040283 norm:0.00012380887346807867 max memory_allocated 29272.56298828125 
[2025-03-02 20:03:39 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 10 loss:0.1330356001853943 norm:0.00012132332631153986 max memory_allocated 29272.56298828125 
[2025-03-02 20:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 11 loss:0.1330174058675766 norm:0.00011874700430780649 max memory_allocated 29272.56298828125 
[2025-03-02 20:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 12 loss:0.13300356268882751 norm:0.0001157997758127749 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 13 loss:0.1329839676618576 norm:0.00011469774472061545 max memory_allocated 29272.56298828125 
[2025-03-02 20:06:57 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 14 loss:0.1329699009656906 norm:0.0001125983108067885 max memory_allocated 29272.56298828125 
[2025-03-02 20:07:47 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 15 loss:0.13296553492546082 norm:0.00011455727508291602 max memory_allocated 29272.56298828125 
[2025-03-02 20:08:37 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 16 loss:0.13295933604240417 norm:0.00011322867794660851 max memory_allocated 29272.56298828125 
[2025-03-02 20:09:27 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 17 loss:0.13295519351959229 norm:0.00011333369184285402 max memory_allocated 29272.56298828125 
[2025-03-02 20:10:16 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 18 loss:0.13294216990470886 norm:0.00011470476601971313 max memory_allocated 29272.56298828125 
[2025-03-02 20:11:06 root] (abq_llm_calib_config2.py 396): INFO layer 25 iter 19 loss:0.1329386830329895 norm:0.00011320595513097942 max memory_allocated 29272.56298828125 
[2025-03-02 20:11:21 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 26 ===
[2025-03-02 20:12:14 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 0 loss:0.1552051603794098 norm:0.0010554965119808912 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:04 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 1 loss:0.15277090668678284 norm:0.0004553999751806259 max memory_allocated 29272.75048828125 
[2025-03-02 20:13:54 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 2 loss:0.1507747918367386 norm:0.00028698163805529475 max memory_allocated 29272.75048828125 
[2025-03-02 20:14:43 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 3 loss:0.14894595742225647 norm:0.0002102003782056272 max memory_allocated 29272.75048828125 
[2025-03-02 20:15:33 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 4 loss:0.1483258455991745 norm:0.00017276372818741947 max memory_allocated 29272.75048828125 
[2025-03-02 20:16:23 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 5 loss:0.1481272280216217 norm:0.0001519946235930547 max memory_allocated 29272.75048828125 
[2025-03-02 20:17:13 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 6 loss:0.14801988005638123 norm:0.00013832721742801368 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:02 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 7 loss:0.14793702960014343 norm:0.00013094357564114034 max memory_allocated 29272.75048828125 
[2025-03-02 20:18:52 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 8 loss:0.1478680670261383 norm:0.00012407432950567454 max memory_allocated 29272.75048828125 
[2025-03-02 20:19:42 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 9 loss:0.14783160388469696 norm:0.00012308299483265728 max memory_allocated 29272.75048828125 
[2025-03-02 20:20:31 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 10 loss:0.1478070169687271 norm:0.00011958973482251167 max memory_allocated 29272.75048828125 
[2025-03-02 20:21:21 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 11 loss:0.14778469502925873 norm:0.00011712301056832075 max memory_allocated 29272.75048828125 
[2025-03-02 20:22:11 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 12 loss:0.14777669310569763 norm:0.00011656717106234282 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:01 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 13 loss:0.14776206016540527 norm:0.0001166388756246306 max memory_allocated 29272.75048828125 
[2025-03-02 20:23:50 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 14 loss:0.1477506458759308 norm:0.00011634660040726885 max memory_allocated 29272.75048828125 
[2025-03-02 20:24:40 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 15 loss:0.147749662399292 norm:0.00011771029676310718 max memory_allocated 29272.75048828125 
[2025-03-02 20:25:29 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 16 loss:0.14774443209171295 norm:0.00011704092321451753 max memory_allocated 29272.75048828125 
[2025-03-02 20:26:19 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 17 loss:0.14775772392749786 norm:0.00011725963122444227 max memory_allocated 29272.75048828125 
[2025-03-02 20:27:09 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 18 loss:0.14777283370494843 norm:0.00011799114145105705 max memory_allocated 29272.75048828125 
[2025-03-02 20:27:59 root] (abq_llm_calib_config2.py 396): INFO layer 26 iter 19 loss:0.147772416472435 norm:0.00011898006778210402 max memory_allocated 29272.75048828125 
[2025-03-02 20:28:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 27 ===
[2025-03-02 20:29:07 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 0 loss:0.17397207021713257 norm:0.0008560880087316036 max memory_allocated 29272.93798828125 
[2025-03-02 20:29:56 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 1 loss:0.17135098576545715 norm:0.00043886154890060425 max memory_allocated 29272.93798828125 
[2025-03-02 20:30:46 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 2 loss:0.16912606358528137 norm:0.0002952630165964365 max memory_allocated 29272.93798828125 
[2025-03-02 20:31:36 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 3 loss:0.16717636585235596 norm:0.00022830290254205465 max memory_allocated 29272.93798828125 
[2025-03-02 20:32:26 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 4 loss:0.16652052104473114 norm:0.00019282320863567293 max memory_allocated 29272.93798828125 
[2025-03-02 20:33:15 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 5 loss:0.16627734899520874 norm:0.00017088618187699467 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:05 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 6 loss:0.16615967452526093 norm:0.00016223406419157982 max memory_allocated 29272.93798828125 
[2025-03-02 20:34:55 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 7 loss:0.1660490483045578 norm:0.0001514618197688833 max memory_allocated 29272.93798828125 
[2025-03-02 20:35:45 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 8 loss:0.16599880158901215 norm:0.0001456712489016354 max memory_allocated 29272.93798828125 
[2025-03-02 20:36:34 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 9 loss:0.1659373939037323 norm:0.00013836233119945973 max memory_allocated 29272.93798828125 
[2025-03-02 20:37:24 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 10 loss:0.165878027677536 norm:0.00013858983584214002 max memory_allocated 29272.93798828125 
[2025-03-02 20:38:14 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 11 loss:0.16583764553070068 norm:0.0001365211355732754 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:03 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 12 loss:0.16582122445106506 norm:0.00013554601173382252 max memory_allocated 29272.93798828125 
[2025-03-02 20:39:53 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 13 loss:0.16581274569034576 norm:0.0001354902924504131 max memory_allocated 29272.93798828125 
[2025-03-02 20:40:43 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 14 loss:0.16581574082374573 norm:0.00013990423758514225 max memory_allocated 29272.93798828125 
[2025-03-02 20:41:33 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 15 loss:0.16579671204090118 norm:0.00013613105693366379 max memory_allocated 29272.93798828125 
[2025-03-02 20:42:22 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 16 loss:0.16579653322696686 norm:0.00013688729086425155 max memory_allocated 29272.93798828125 
[2025-03-02 20:43:12 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 17 loss:0.16580379009246826 norm:0.00013669239706359804 max memory_allocated 29272.93798828125 
[2025-03-02 20:44:02 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 18 loss:0.16579808294773102 norm:0.00013741510338149965 max memory_allocated 29272.93798828125 
[2025-03-02 20:44:52 root] (abq_llm_calib_config2.py 396): INFO layer 27 iter 19 loss:0.16579808294773102 norm:0.00014379454660229385 max memory_allocated 29272.93798828125 
[2025-03-02 20:45:07 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 28 ===
[2025-03-02 20:46:01 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 0 loss:0.1944362223148346 norm:0.0011123411823064089 max memory_allocated 29273.12548828125 
[2025-03-02 20:46:50 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 1 loss:0.19224296510219574 norm:0.0005784803652204573 max memory_allocated 29273.12548828125 
[2025-03-02 20:47:40 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 2 loss:0.18975812196731567 norm:0.00040934354183264077 max memory_allocated 29273.12548828125 
[2025-03-02 20:48:30 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 3 loss:0.18716615438461304 norm:0.0003447594936005771 max memory_allocated 29273.12548828125 
[2025-03-02 20:49:19 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 4 loss:0.1864488422870636 norm:0.0003119272005278617 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:09 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 5 loss:0.18625745177268982 norm:0.0002486383600626141 max memory_allocated 29273.12548828125 
[2025-03-02 20:50:59 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 6 loss:0.18615411221981049 norm:0.0002399394870735705 max memory_allocated 29273.12548828125 
[2025-03-02 20:51:48 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 7 loss:0.18606141209602356 norm:0.00023521107505075634 max memory_allocated 29273.12548828125 
[2025-03-02 20:52:38 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 8 loss:0.1860082596540451 norm:0.00022950541460886598 max memory_allocated 29273.12548828125 
[2025-03-02 20:53:28 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 9 loss:0.1859697550535202 norm:0.00023172951478045434 max memory_allocated 29273.12548828125 
[2025-03-02 20:54:18 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 10 loss:0.18594369292259216 norm:0.00022175998310558498 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:07 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 11 loss:0.18591684103012085 norm:0.0002256616426166147 max memory_allocated 29273.12548828125 
[2025-03-02 20:55:57 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 12 loss:0.18590237200260162 norm:0.00022523551888298243 max memory_allocated 29273.12548828125 
[2025-03-02 20:56:46 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 13 loss:0.18589836359024048 norm:0.00022538856137543917 max memory_allocated 29273.12548828125 
[2025-03-02 20:57:36 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 14 loss:0.1858898103237152 norm:0.00021580731845460832 max memory_allocated 29273.12548828125 
[2025-03-02 20:58:26 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 15 loss:0.1858823001384735 norm:0.00021414313232526183 max memory_allocated 29273.12548828125 
[2025-03-02 20:59:16 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 16 loss:0.18588219583034515 norm:0.0002026392612606287 max memory_allocated 29273.12548828125 
[2025-03-02 21:00:05 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 17 loss:0.18586504459381104 norm:0.00017637261771596968 max memory_allocated 29273.12548828125 
[2025-03-02 21:00:55 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 18 loss:0.18587523698806763 norm:0.0001928249839693308 max memory_allocated 29273.12548828125 
[2025-03-02 21:01:45 root] (abq_llm_calib_config2.py 396): INFO layer 28 iter 19 loss:0.18586191534996033 norm:0.00018338784866500646 max memory_allocated 29273.12548828125 
[2025-03-02 21:01:59 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 29 ===
[2025-03-02 21:02:53 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 0 loss:0.2117779403924942 norm:0.0015625949017703533 max memory_allocated 29273.31298828125 
[2025-03-02 21:03:43 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 1 loss:0.2091071456670761 norm:0.0007923414232209325 max memory_allocated 29273.31298828125 
[2025-03-02 21:04:32 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 2 loss:0.2067030817270279 norm:0.0004883716464973986 max memory_allocated 29273.31298828125 
[2025-03-02 21:05:22 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 3 loss:0.204714834690094 norm:0.00033843741402961314 max memory_allocated 29273.31298828125 
[2025-03-02 21:06:12 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 4 loss:0.2041388303041458 norm:0.0002601242740638554 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:02 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 5 loss:0.20396175980567932 norm:0.0002152467059204355 max memory_allocated 29273.31298828125 
[2025-03-02 21:07:51 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 6 loss:0.20385144650936127 norm:0.00018565419304650277 max memory_allocated 29273.31298828125 
[2025-03-02 21:08:41 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 7 loss:0.20377212762832642 norm:0.00016829624655656517 max memory_allocated 29273.31298828125 
[2025-03-02 21:09:31 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 8 loss:0.20370152592658997 norm:0.00015559385064989328 max memory_allocated 29273.31298828125 
[2025-03-02 21:10:20 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 9 loss:0.2036629170179367 norm:0.00014906116120982915 max memory_allocated 29273.31298828125 
[2025-03-02 21:11:10 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 10 loss:0.20365270972251892 norm:0.00014735979493707418 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:00 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 11 loss:0.20363740622997284 norm:0.00014431041199713945 max memory_allocated 29273.31298828125 
[2025-03-02 21:12:50 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 12 loss:0.20360825955867767 norm:0.00013896108430344611 max memory_allocated 29273.31298828125 
[2025-03-02 21:13:39 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 13 loss:0.2036101073026657 norm:0.00013803719775751233 max memory_allocated 29273.31298828125 
[2025-03-02 21:14:29 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 14 loss:0.20359772443771362 norm:0.0001403147616656497 max memory_allocated 29273.31298828125 
[2025-03-02 21:15:19 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 15 loss:0.2035996913909912 norm:0.00013910520647186786 max memory_allocated 29273.31298828125 
[2025-03-02 21:16:09 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 16 loss:0.2035922408103943 norm:0.00013781538291368634 max memory_allocated 29273.31298828125 
[2025-03-02 21:16:59 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 17 loss:0.20358291268348694 norm:0.00013747265620622784 max memory_allocated 29273.31298828125 
[2025-03-02 21:17:49 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 18 loss:0.2035856693983078 norm:0.00013522258086595684 max memory_allocated 29273.31298828125 
[2025-03-02 21:18:38 root] (abq_llm_calib_config2.py 396): INFO layer 29 iter 19 loss:0.20359408855438232 norm:0.00013484933879226446 max memory_allocated 29273.31298828125 
[2025-03-02 21:18:53 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 30 ===
[2025-03-02 21:19:47 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 0 loss:0.23483797907829285 norm:0.0015095173148438334 max memory_allocated 29273.50048828125 
[2025-03-02 21:20:37 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 1 loss:0.23162741959095 norm:0.0007508097332902253 max memory_allocated 29273.50048828125 
[2025-03-02 21:21:27 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 2 loss:0.22879314422607422 norm:0.00046767210005782545 max memory_allocated 29273.50048828125 
[2025-03-02 21:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 3 loss:0.22668105363845825 norm:0.0003319287206977606 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 4 loss:0.2260761708021164 norm:0.00026501817046664655 max memory_allocated 29273.50048828125 
[2025-03-02 21:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 5 loss:0.22584004700183868 norm:0.00022500597697217017 max memory_allocated 29273.50048828125 
[2025-03-02 21:24:46 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 6 loss:0.2256840616464615 norm:0.0002012270560953766 max memory_allocated 29273.50048828125 
[2025-03-02 21:25:36 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 7 loss:0.22557201981544495 norm:0.00019717009854502976 max memory_allocated 29273.50048828125 
[2025-03-02 21:26:25 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 8 loss:0.22548989951610565 norm:0.0001758532307576388 max memory_allocated 29273.50048828125 
[2025-03-02 21:27:15 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 9 loss:0.22542454302310944 norm:0.00016958205378614366 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:05 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 10 loss:0.22540093958377838 norm:0.0001692106161499396 max memory_allocated 29273.50048828125 
[2025-03-02 21:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 11 loss:0.22537243366241455 norm:0.0001628933969186619 max memory_allocated 29273.50048828125 
[2025-03-02 21:29:45 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 12 loss:0.22533762454986572 norm:0.00016036612214520574 max memory_allocated 29273.50048828125 
[2025-03-02 21:30:34 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 13 loss:0.22533492743968964 norm:0.00016024848446249962 max memory_allocated 29273.50048828125 
[2025-03-02 21:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 14 loss:0.22532451152801514 norm:0.00016092017176561058 max memory_allocated 29273.50048828125 
[2025-03-02 21:32:14 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 15 loss:0.22529873251914978 norm:0.00016140795196406543 max memory_allocated 29273.50048828125 
[2025-03-02 21:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 16 loss:0.2252897471189499 norm:0.00016552736633457243 max memory_allocated 29273.50048828125 
[2025-03-02 21:33:53 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 17 loss:0.2252984344959259 norm:0.00016653066268190742 max memory_allocated 29273.50048828125 
[2025-03-02 21:34:43 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 18 loss:0.225272998213768 norm:0.0001645128650125116 max memory_allocated 29273.50048828125 
[2025-03-02 21:35:33 root] (abq_llm_calib_config2.py 396): INFO layer 30 iter 19 loss:0.22526103258132935 norm:0.00016713119111955166 max memory_allocated 29273.50048828125 
[2025-03-02 21:35:48 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 31 ===
[2025-03-02 21:36:41 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 0 loss:0.25746095180511475 norm:0.0017659300938248634 max memory_allocated 29273.68798828125 
[2025-03-02 21:37:31 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 1 loss:0.25403136014938354 norm:0.000832227582577616 max memory_allocated 29273.68798828125 
[2025-03-02 21:38:21 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 2 loss:0.2509484589099884 norm:0.0005020670359954238 max memory_allocated 29273.68798828125 
[2025-03-02 21:39:10 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 3 loss:0.24872562289237976 norm:0.0003449392970651388 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:00 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 4 loss:0.24817021191120148 norm:0.000264989270363003 max memory_allocated 29273.68798828125 
[2025-03-02 21:40:50 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 5 loss:0.2479446828365326 norm:0.0002224985510110855 max memory_allocated 29273.68798828125 
[2025-03-02 21:41:40 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 6 loss:0.24781900644302368 norm:0.00019849538512062281 max memory_allocated 29273.68798828125 
[2025-03-02 21:42:30 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 7 loss:0.24771356582641602 norm:0.00017970846965909004 max memory_allocated 29273.68798828125 
[2025-03-02 21:43:19 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 8 loss:0.24765357375144958 norm:0.0001769179361872375 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:09 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 9 loss:0.24763138592243195 norm:0.00016989890718832612 max memory_allocated 29273.68798828125 
[2025-03-02 21:44:59 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 10 loss:0.24760757386684418 norm:0.0001650133344810456 max memory_allocated 29273.68798828125 
[2025-03-02 21:45:49 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 11 loss:0.24754762649536133 norm:0.0001676410174695775 max memory_allocated 29273.68798828125 
[2025-03-02 21:46:38 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 12 loss:0.24753481149673462 norm:0.00016551377484574914 max memory_allocated 29273.68798828125 
[2025-03-02 21:47:28 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 13 loss:0.2475479245185852 norm:0.00016060816415119916 max memory_allocated 29273.68798828125 
[2025-03-02 21:48:18 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 14 loss:0.24754579365253448 norm:0.00015822588466107845 max memory_allocated 29273.68798828125 
[2025-03-02 21:49:08 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 15 loss:0.24754184484481812 norm:0.0001574027701281011 max memory_allocated 29273.68798828125 
[2025-03-02 21:49:58 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 16 loss:0.24753817915916443 norm:0.00015740186790935695 max memory_allocated 29273.68798828125 
[2025-03-02 21:50:47 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 17 loss:0.24753610789775848 norm:0.00015910487854853272 max memory_allocated 29273.68798828125 
[2025-03-02 21:51:37 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 18 loss:0.24753089249134064 norm:0.00015977090515661985 max memory_allocated 29273.68798828125 
[2025-03-02 21:52:27 root] (abq_llm_calib_config2.py 396): INFO layer 31 iter 19 loss:0.2475157082080841 norm:0.00016062520444393158 max memory_allocated 29273.68798828125 
[2025-03-02 21:52:41 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 32 ===
[2025-03-02 21:53:35 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 0 loss:0.2794185280799866 norm:0.0021551132667809725 max memory_allocated 29273.87548828125 
[2025-03-02 21:54:25 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 1 loss:0.2764515280723572 norm:0.0010640195105224848 max memory_allocated 29273.87548828125 
[2025-03-02 21:55:14 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 2 loss:0.2736404836177826 norm:0.0006442960002459586 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:04 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 3 loss:0.27157774567604065 norm:0.0004386858781799674 max memory_allocated 29273.87548828125 
[2025-03-02 21:56:54 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 4 loss:0.2709985077381134 norm:0.0003291867906227708 max memory_allocated 29273.87548828125 
[2025-03-02 21:57:43 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 5 loss:0.2707679271697998 norm:0.00026760646142065525 max memory_allocated 29273.87548828125 
[2025-03-02 21:58:33 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 6 loss:0.27061980962753296 norm:0.0002302000648342073 max memory_allocated 29273.87548828125 
[2025-03-02 21:59:23 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 7 loss:0.2705385982990265 norm:0.00020555204537231475 max memory_allocated 29273.87548828125 
[2025-03-02 22:00:12 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 8 loss:0.27046093344688416 norm:0.0001896895992103964 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:02 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 9 loss:0.27039778232574463 norm:0.00017944190767593682 max memory_allocated 29273.87548828125 
[2025-03-02 22:01:52 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 10 loss:0.2703539729118347 norm:0.00017109261534642428 max memory_allocated 29273.87548828125 
[2025-03-02 22:02:41 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 11 loss:0.270318865776062 norm:0.000168809769093059 max memory_allocated 29273.87548828125 
[2025-03-02 22:03:31 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 12 loss:0.27030330896377563 norm:0.0001644460717216134 max memory_allocated 29273.87548828125 
[2025-03-02 22:04:21 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 13 loss:0.270293653011322 norm:0.00016179389785975218 max memory_allocated 29273.87548828125 
[2025-03-02 22:05:10 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 14 loss:0.2702789306640625 norm:0.00016015554137993604 max memory_allocated 29273.87548828125 
[2025-03-02 22:06:00 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 15 loss:0.270283579826355 norm:0.00015890109352767467 max memory_allocated 29273.87548828125 
[2025-03-02 22:06:50 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 16 loss:0.2702726125717163 norm:0.00015837866521906108 max memory_allocated 29273.87548828125 
[2025-03-02 22:07:39 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 17 loss:0.27027690410614014 norm:0.00015818029351066798 max memory_allocated 29273.87548828125 
[2025-03-02 22:08:29 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 18 loss:0.2702667713165283 norm:0.00016162106476258487 max memory_allocated 29273.87548828125 
[2025-03-02 22:09:19 root] (abq_llm_calib_config2.py 396): INFO layer 32 iter 19 loss:0.27026867866516113 norm:0.00016130397852975875 max memory_allocated 29273.87548828125 
[2025-03-02 22:09:33 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 33 ===
[2025-03-02 22:10:27 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 0 loss:0.3086039423942566 norm:0.0012441695434972644 max memory_allocated 29274.06298828125 
[2025-03-02 22:11:17 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 1 loss:0.3048099875450134 norm:0.0006595246377401054 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:06 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 2 loss:0.30134692788124084 norm:0.00043694747728295624 max memory_allocated 29274.06298828125 
[2025-03-02 22:12:56 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 3 loss:0.2991214990615845 norm:0.0003235364565625787 max memory_allocated 29274.06298828125 
[2025-03-02 22:13:46 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 4 loss:0.29850679636001587 norm:0.00026671262457966805 max memory_allocated 29274.06298828125 
[2025-03-02 22:14:35 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 5 loss:0.2982032299041748 norm:0.00023509339371230453 max memory_allocated 29274.06298828125 
[2025-03-02 22:15:25 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 6 loss:0.298027366399765 norm:0.00021897781698498875 max memory_allocated 29274.06298828125 
[2025-03-02 22:16:15 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 7 loss:0.2979220747947693 norm:0.0002074804506264627 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:05 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 8 loss:0.29783785343170166 norm:0.00020211111404933035 max memory_allocated 29274.06298828125 
[2025-03-02 22:17:54 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 9 loss:0.29780155420303345 norm:0.00019653384515549988 max memory_allocated 29274.06298828125 
[2025-03-02 22:18:44 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 10 loss:0.2977631092071533 norm:0.00019358930876478553 max memory_allocated 29274.06298828125 
[2025-03-02 22:19:34 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 11 loss:0.297707736492157 norm:0.00019294972298666835 max memory_allocated 29274.06298828125 
[2025-03-02 22:20:23 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 12 loss:0.29768791794776917 norm:0.00019600064842961729 max memory_allocated 29274.06298828125 
[2025-03-02 22:21:13 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 13 loss:0.29766368865966797 norm:0.00019225306459702551 max memory_allocated 29274.06298828125 
[2025-03-02 22:22:03 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 14 loss:0.29762697219848633 norm:0.00018966868810821325 max memory_allocated 29274.06298828125 
[2025-03-02 22:22:52 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 15 loss:0.29764819145202637 norm:0.00018772637122310698 max memory_allocated 29274.06298828125 
[2025-03-02 22:23:42 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 16 loss:0.2976093590259552 norm:0.00018720279331319034 max memory_allocated 29274.06298828125 
[2025-03-02 22:24:32 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 17 loss:0.2975999414920807 norm:0.00018574656860437244 max memory_allocated 29274.06298828125 
[2025-03-02 22:25:21 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 18 loss:0.2976036071777344 norm:0.00018730289593804628 max memory_allocated 29274.06298828125 
[2025-03-02 22:26:10 root] (abq_llm_calib_config2.py 396): INFO layer 33 iter 19 loss:0.297568678855896 norm:0.0001908508565975353 max memory_allocated 29274.06298828125 
[2025-03-02 22:26:25 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 34 ===
[2025-03-02 22:27:19 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 0 loss:0.3424021601676941 norm:0.0016482509672641754 max memory_allocated 29274.25048828125 
[2025-03-02 22:28:08 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 1 loss:0.33778566122055054 norm:0.000811241043265909 max memory_allocated 29274.25048828125 
[2025-03-02 22:28:58 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 2 loss:0.33365580439567566 norm:0.0005155678954906762 max memory_allocated 29274.25048828125 
[2025-03-02 22:29:48 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 3 loss:0.3313358724117279 norm:0.0003752361808437854 max memory_allocated 29274.25048828125 
[2025-03-02 22:30:38 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 4 loss:0.3307502567768097 norm:0.00030574933043681085 max memory_allocated 29274.25048828125 
[2025-03-02 22:31:27 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 5 loss:0.33043065667152405 norm:0.0002623341279104352 max memory_allocated 29274.25048828125 
[2025-03-02 22:32:17 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 6 loss:0.33021920919418335 norm:0.00023755426809657365 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:07 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 7 loss:0.33010584115982056 norm:0.00022241403348743916 max memory_allocated 29274.25048828125 
[2025-03-02 22:33:57 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 8 loss:0.33003106713294983 norm:0.00021251403086353093 max memory_allocated 29274.25048828125 
[2025-03-02 22:34:47 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 9 loss:0.32994428277015686 norm:0.00020429649157449603 max memory_allocated 29274.25048828125 
[2025-03-02 22:35:37 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 10 loss:0.3298809826374054 norm:0.00020850141299888492 max memory_allocated 29274.25048828125 
[2025-03-02 22:36:26 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 11 loss:0.3298468589782715 norm:0.00020182541629765183 max memory_allocated 29274.25048828125 
[2025-03-02 22:37:16 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 12 loss:0.3298022150993347 norm:0.00019762750889640301 max memory_allocated 29274.25048828125 
[2025-03-02 22:38:06 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 13 loss:0.3297805190086365 norm:0.00020002384553663433 max memory_allocated 29274.25048828125 
[2025-03-02 22:38:56 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 14 loss:0.3297746181488037 norm:0.0002006462891586125 max memory_allocated 29274.25048828125 
[2025-03-02 22:39:46 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 15 loss:0.3297678828239441 norm:0.00019828758377116174 max memory_allocated 29274.25048828125 
[2025-03-02 22:40:36 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 16 loss:0.32974162697792053 norm:0.00020045146811753511 max memory_allocated 29274.25048828125 
[2025-03-02 22:41:25 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 17 loss:0.32971519231796265 norm:0.00020055061031598598 max memory_allocated 29274.25048828125 
[2025-03-02 22:42:15 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 18 loss:0.329709529876709 norm:0.000202215785975568 max memory_allocated 29274.25048828125 
[2025-03-02 22:43:05 root] (abq_llm_calib_config2.py 396): INFO layer 34 iter 19 loss:0.32970210909843445 norm:0.0002039384562522173 max memory_allocated 29274.25048828125 
[2025-03-02 22:43:19 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 35 ===
[2025-03-02 22:44:13 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 0 loss:0.37749335169792175 norm:0.003011602908372879 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:03 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 1 loss:0.3719516694545746 norm:0.0015721521340310574 max memory_allocated 29274.43798828125 
[2025-03-02 22:45:53 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 2 loss:0.3671923279762268 norm:0.0009679013746790588 max memory_allocated 29274.43798828125 
[2025-03-02 22:46:43 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 3 loss:0.3647018074989319 norm:0.0006704815896227956 max memory_allocated 29274.43798828125 
[2025-03-02 22:47:32 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 4 loss:0.36393383145332336 norm:0.0005052866763435304 max memory_allocated 29274.43798828125 
[2025-03-02 22:48:22 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 5 loss:0.3634868264198303 norm:0.00040617669583298266 max memory_allocated 29274.43798828125 
[2025-03-02 22:49:12 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 6 loss:0.36324113607406616 norm:0.00035236412077210844 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:02 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 7 loss:0.36307603120803833 norm:0.0003128547396045178 max memory_allocated 29274.43798828125 
[2025-03-02 22:50:52 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 8 loss:0.36297258734703064 norm:0.0002869145246222615 max memory_allocated 29274.43798828125 
[2025-03-02 22:51:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 9 loss:0.36287039518356323 norm:0.00026875350158661604 max memory_allocated 29274.43798828125 
[2025-03-02 22:52:31 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 10 loss:0.3628099858760834 norm:0.00026252964744344354 max memory_allocated 29274.43798828125 
[2025-03-02 22:53:21 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 11 loss:0.3627355098724365 norm:0.0002515925734769553 max memory_allocated 29274.43798828125 
[2025-03-02 22:54:11 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 12 loss:0.3627055883407593 norm:0.0002482309064362198 max memory_allocated 29274.43798828125 
[2025-03-02 22:55:01 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 13 loss:0.36266636848449707 norm:0.00024456740356981754 max memory_allocated 29274.43798828125 
[2025-03-02 22:55:51 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 14 loss:0.3626174330711365 norm:0.00024127410142682493 max memory_allocated 29274.43798828125 
[2025-03-02 22:56:41 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 15 loss:0.3625985383987427 norm:0.00024003560247365385 max memory_allocated 29274.43798828125 
[2025-03-02 22:57:30 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 16 loss:0.3625893294811249 norm:0.00024034657690208405 max memory_allocated 29274.43798828125 
[2025-03-02 22:58:20 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 17 loss:0.36257845163345337 norm:0.00023823634546715766 max memory_allocated 29274.43798828125 
[2025-03-02 22:59:10 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 18 loss:0.3625650405883789 norm:0.00023822064395062625 max memory_allocated 29274.43798828125 
[2025-03-02 23:00:00 root] (abq_llm_calib_config2.py 396): INFO layer 35 iter 19 loss:0.36254122853279114 norm:0.0002426982537144795 max memory_allocated 29274.43798828125 
[2025-03-02 23:00:14 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 36 ===
[2025-03-02 23:00:18 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:01:08 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 0 loss:0.41493430733680725 norm:0.007840591482818127 max memory_allocated 29274.77001953125 
[2025-03-02 23:01:58 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 1 loss:0.4094827473163605 norm:0.006352983880788088 max memory_allocated 29274.77001953125 
[2025-03-02 23:02:48 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 2 loss:0.4046708345413208 norm:0.005065455101430416 max memory_allocated 29274.77001953125 
[2025-03-02 23:03:38 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 3 loss:0.402080237865448 norm:0.0040700859390199184 max memory_allocated 29274.77001953125 
[2025-03-02 23:04:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 4 loss:0.4013388454914093 norm:0.003355358261615038 max memory_allocated 29274.77001953125 
[2025-03-02 23:05:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 5 loss:0.40080785751342773 norm:0.0028928364627063274 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:08 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 6 loss:0.40049874782562256 norm:0.0026920780073851347 max memory_allocated 29274.77001953125 
[2025-03-02 23:06:58 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 7 loss:0.4002493619918823 norm:0.002503541763871908 max memory_allocated 29274.77001953125 
[2025-03-02 23:07:48 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 8 loss:0.40017274022102356 norm:0.002379549201577902 max memory_allocated 29274.77001953125 
[2025-03-02 23:08:38 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 9 loss:0.40018925070762634 norm:0.002451377920806408 max memory_allocated 29274.77001953125 
[2025-03-02 23:09:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 10 loss:0.4001525640487671 norm:0.002334419172257185 max memory_allocated 29274.77001953125 
[2025-03-02 23:10:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 11 loss:0.40003153681755066 norm:0.0022540539503097534 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:08 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 12 loss:0.39995908737182617 norm:0.002186279511079192 max memory_allocated 29274.77001953125 
[2025-03-02 23:11:58 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 13 loss:0.3999236524105072 norm:0.002161239041015506 max memory_allocated 29274.77001953125 
[2025-03-02 23:12:48 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 14 loss:0.3999100625514984 norm:0.0021039387211203575 max memory_allocated 29274.77001953125 
[2025-03-02 23:13:38 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 15 loss:0.3998510241508484 norm:0.0020844016689807177 max memory_allocated 29274.77001953125 
[2025-03-02 23:14:28 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 16 loss:0.3998178243637085 norm:0.0020055158529430628 max memory_allocated 29274.77001953125 
[2025-03-02 23:15:18 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 17 loss:0.39980465173721313 norm:0.001992060337215662 max memory_allocated 29274.77001953125 
[2025-03-02 23:16:08 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 18 loss:0.3998482823371887 norm:0.0020189678762108088 max memory_allocated 29274.77001953125 
[2025-03-02 23:16:58 root] (abq_llm_calib_config2.py 396): INFO layer 36 iter 19 loss:0.3998587131500244 norm:0.0020405338145792484 max memory_allocated 29274.77001953125 
[2025-03-02 23:17:13 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 37 ===
[2025-03-02 23:17:17 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:18:07 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 0 loss:0.4739270806312561 norm:0.0117645263671875 max memory_allocated 29274.95751953125 
[2025-03-02 23:18:56 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 1 loss:0.46500056982040405 norm:0.008738246746361256 max memory_allocated 29274.95751953125 
[2025-03-02 23:19:46 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 2 loss:0.45548397302627563 norm:0.006162760313600302 max memory_allocated 29274.95751953125 
[2025-03-02 23:20:36 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 3 loss:0.45153969526290894 norm:0.005933362990617752 max memory_allocated 29274.95751953125 
[2025-03-02 23:21:26 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 4 loss:0.45040181279182434 norm:0.0051718950271606445 max memory_allocated 29274.95751953125 
[2025-03-02 23:22:16 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 5 loss:0.4496569037437439 norm:0.0048789773136377335 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:06 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 6 loss:0.4491516351699829 norm:0.004460780415683985 max memory_allocated 29274.95751953125 
[2025-03-02 23:23:56 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 7 loss:0.4487442970275879 norm:0.004379632882773876 max memory_allocated 29274.95751953125 
[2025-03-02 23:24:45 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 8 loss:0.44853779673576355 norm:0.003958730027079582 max memory_allocated 29274.95751953125 
[2025-03-02 23:25:35 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 9 loss:0.4483848214149475 norm:0.0038282619789242744 max memory_allocated 29274.95751953125 
[2025-03-02 23:26:25 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 10 loss:0.44822320342063904 norm:0.003698000917211175 max memory_allocated 29274.95751953125 
[2025-03-02 23:27:15 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 11 loss:0.44819098711013794 norm:0.003708519972860813 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:05 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 12 loss:0.4480600655078888 norm:0.00350347813218832 max memory_allocated 29274.95751953125 
[2025-03-02 23:28:55 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 13 loss:0.44813472032546997 norm:0.0036693327128887177 max memory_allocated 29274.95751953125 
[2025-03-02 23:29:45 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 14 loss:0.4482578933238983 norm:0.0038123889826238155 max memory_allocated 29274.95751953125 
[2025-03-02 23:30:35 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 15 loss:0.4484092593193054 norm:0.004004175774753094 max memory_allocated 29274.95751953125 
[2025-03-02 23:31:24 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 16 loss:0.4481876492500305 norm:0.0038458146154880524 max memory_allocated 29274.95751953125 
[2025-03-02 23:32:14 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 17 loss:0.4483179450035095 norm:0.004016134422272444 max memory_allocated 29274.95751953125 
[2025-03-02 23:33:04 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 18 loss:0.44857579469680786 norm:0.003963321913033724 max memory_allocated 29274.95751953125 
[2025-03-02 23:33:54 root] (abq_llm_calib_config2.py 396): INFO layer 37 iter 19 loss:0.44829434156417847 norm:0.0034280610270798206 max memory_allocated 29274.95751953125 
[2025-03-02 23:34:09 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 38 ===
[2025-03-02 23:34:13 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:35:03 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 0 loss:0.6768845319747925 norm:0.038739293813705444 max memory_allocated 29275.14501953125 
[2025-03-02 23:35:53 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 1 loss:0.6339298486709595 norm:0.028280990198254585 max memory_allocated 29275.14501953125 
[2025-03-02 23:36:43 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 2 loss:0.6068347096443176 norm:0.021262668073177338 max memory_allocated 29275.14501953125 
[2025-03-02 23:37:32 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 3 loss:0.5916597247123718 norm:0.018284721300005913 max memory_allocated 29275.14501953125 
[2025-03-02 23:38:22 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 4 loss:0.582982063293457 norm:0.01480240747332573 max memory_allocated 29275.14501953125 
[2025-03-02 23:39:12 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 5 loss:0.5770599842071533 norm:0.012553549371659756 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:02 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 6 loss:0.5737634301185608 norm:0.011028517968952656 max memory_allocated 29275.14501953125 
[2025-03-02 23:40:52 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 7 loss:0.5711984634399414 norm:0.009714100509881973 max memory_allocated 29275.14501953125 
[2025-03-02 23:41:42 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 8 loss:0.5695134997367859 norm:0.009101885370910168 max memory_allocated 29275.14501953125 
[2025-03-02 23:42:31 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 9 loss:0.5684640407562256 norm:0.009018052369356155 max memory_allocated 29275.14501953125 
[2025-03-02 23:43:21 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 10 loss:0.567626953125 norm:0.009003076702356339 max memory_allocated 29275.14501953125 
[2025-03-02 23:44:11 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 11 loss:0.5668926239013672 norm:0.008785695768892765 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:01 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 12 loss:0.566246509552002 norm:0.008657451719045639 max memory_allocated 29275.14501953125 
[2025-03-02 23:45:51 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 13 loss:0.5654066801071167 norm:0.007947305217385292 max memory_allocated 29275.14501953125 
[2025-03-02 23:46:41 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 14 loss:0.5650357604026794 norm:0.007949153892695904 max memory_allocated 29275.14501953125 
[2025-03-02 23:47:30 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 15 loss:0.5647183656692505 norm:0.007628571707755327 max memory_allocated 29275.14501953125 
[2025-03-02 23:48:20 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 16 loss:0.5646454691886902 norm:0.007708321791142225 max memory_allocated 29275.14501953125 
[2025-03-02 23:49:10 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 17 loss:0.564301609992981 norm:0.007372993975877762 max memory_allocated 29275.14501953125 
[2025-03-02 23:50:00 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 18 loss:0.564069390296936 norm:0.007295355666428804 max memory_allocated 29275.14501953125 
[2025-03-02 23:50:50 root] (abq_llm_calib_config2.py 396): INFO layer 38 iter 19 loss:0.5638446807861328 norm:0.007039650343358517 max memory_allocated 29275.14501953125 
[2025-03-02 23:51:04 root] (abq_llm_calib_config2.py 239): INFO === Start quantize layer 39 ===
[2025-03-02 23:51:08 root] (abq_llm_calib_config2.py 314): INFO use compensation vector
[2025-03-02 23:51:58 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 0 loss:1.0326801538467407 norm:0.05309794098138809 max memory_allocated 29275.33251953125 
[2025-03-02 23:52:48 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 1 loss:0.9672969579696655 norm:0.03298085182905197 max memory_allocated 29275.33251953125 
[2025-03-02 23:53:38 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 2 loss:0.9347094893455505 norm:0.02370879054069519 max memory_allocated 29275.33251953125 
[2025-03-02 23:54:28 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 3 loss:0.9150571227073669 norm:0.01954713650047779 max memory_allocated 29275.33251953125 
[2025-03-02 23:55:18 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 4 loss:0.9040058851242065 norm:0.016592783853411674 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:07 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 5 loss:0.8958388566970825 norm:0.015426392666995525 max memory_allocated 29275.33251953125 
[2025-03-02 23:56:57 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 6 loss:0.8905271291732788 norm:0.014696848578751087 max memory_allocated 29275.33251953125 
[2025-03-02 23:57:47 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 7 loss:0.887451171875 norm:0.01518895011395216 max memory_allocated 29275.33251953125 
[2025-03-02 23:58:37 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 8 loss:0.8856286406517029 norm:0.01491717528551817 max memory_allocated 29275.33251953125 
[2025-03-02 23:59:27 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 9 loss:0.8824272155761719 norm:0.013472666032612324 max memory_allocated 29275.33251953125 
[2025-03-03 00:00:17 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 10 loss:0.8803657293319702 norm:0.01338183507323265 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 11 loss:0.8784840703010559 norm:0.013011880218982697 max memory_allocated 29275.33251953125 
[2025-03-03 00:01:56 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 12 loss:0.8779589533805847 norm:0.012584145180881023 max memory_allocated 29275.33251953125 
[2025-03-03 00:02:46 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 13 loss:0.8768826723098755 norm:0.012303264811635017 max memory_allocated 29275.33251953125 
[2025-03-03 00:03:36 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 14 loss:0.8760483860969543 norm:0.012635174207389355 max memory_allocated 29275.33251953125 
[2025-03-03 00:04:26 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 15 loss:0.8748043775558472 norm:0.011760435998439789 max memory_allocated 29275.33251953125 
[2025-03-03 00:05:16 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 16 loss:0.8747541308403015 norm:0.012303860858082771 max memory_allocated 29275.33251953125 
[2025-03-03 00:06:06 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 17 loss:0.8743337988853455 norm:0.012050425633788109 max memory_allocated 29275.33251953125 
[2025-03-03 00:06:55 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 18 loss:0.8734960556030273 norm:0.01151121687144041 max memory_allocated 29275.33251953125 
[2025-03-03 00:07:45 root] (abq_llm_calib_config2.py 396): INFO layer 39 iter 19 loss:0.872940182685852 norm:0.011592946946620941 max memory_allocated 29275.33251953125 
[2025-03-03 00:08:00 root] (main_calib_config2.py 372): INFO 40529.9869556427
[2025-03-03 00:08:10 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-03 00:10:08 root] (main_calib_config2.py 159): INFO wikitext2 : 5.226556777954102
[2025-03-03 00:10:08 root] (main_calib_config2.py 115): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-03 00:13:09 root] (main_calib_config2.py 159): INFO c4 : 6.766438961029053
[2025-03-03 02:18:04 root] (main_calib_config2.py 170): INFO {'wikitext2': 5.226556777954102, 'c4': 6.766438961029053, 'results': {'boolq': {'acc': 0.6688073394495413, 'acc_stderr': 0.008231583858517822}, 'hellaswag': {'acc': 0.5852419836685919, 'acc_stderr': 0.004916733258140296, 'acc_norm': 0.755327623979287, 'acc_norm_stderr': 0.004290142029921663}, 'winogrande': {'acc': 0.6827150749802684, 'acc_stderr': 0.013080598411332118}, 'piqa': {'acc': 0.7883569096844396, 'acc_stderr': 0.009530351270479397, 'acc_norm': 0.7829162132752993, 'acc_norm_stderr': 0.009618708415756788}, 'arc_challenge': {'acc': 0.4283276450511945, 'acc_stderr': 0.014460496367599015, 'acc_norm': 0.42918088737201365, 'acc_norm_stderr': 0.014464085894870655}, 'arc_easy': {'acc': 0.7276936026936027, 'acc_stderr': 0.009134218447652682, 'acc_norm': 0.5803872053872053, 'acc_norm_stderr': 0.010126315840891546}}, 'versions': {'boolq': 1, 'hellaswag': 0, 'winogrande': 0, 'piqa': 0, 'arc_challenge': 0, 'arc_easy': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
