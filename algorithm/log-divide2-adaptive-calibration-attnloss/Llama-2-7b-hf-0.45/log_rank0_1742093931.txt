[2025-03-16 02:58:51 root] (main_calib_config3.py 283): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-divide2-adaptive-calibration-attnloss/Llama-2-7b-hf-0.45', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-divide2-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.45.pkl', blocks_pkl='./log-divide2/Llama-2-7b-hf-w4a4/Llama-2-7b-hf_blocks.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-16 02:58:58 root] (main_calib_config3.py 350): INFO === start quantization ===
[2025-03-16 02:58:58 root] (main_calib_config3.py 356): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-16 02:58:58 root] (abq_llm_calib_config3.py 82): INFO Starting ...
[2025-03-16 02:58:58 root] (abq_llm_calib_config3.py 89): INFO Loaded quant_map from log-divide2-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.45.pkl
[2025-03-16 02:58:58 root] (abq_llm_calib_config3.py 96): INFO Loaded blocks from ./log-divide2/Llama-2-7b-hf-w4a4/Llama-2-7b-hf_blocks.pkl: [(0, 1), (1, 2), (2, 3), (3, 4), (4, 6), (6, 8), (8, 10), (10, 11), (11, 13), (13, 15), (15, 17), (17, 19), (19, 21), (21, 23), (23, 25), (25, 27), (27, 29), (29, 30), (30, 31), (31, 32)]
[2025-03-16 02:58:58 root] (abq_llm_calib_config3.py 102): INFO Processed blocks: [[0], [1], [2], [3], [4, 5], [6, 7], [8, 9], [10], [11, 12], [13, 14], [15, 16], [17, 18], [19, 20], [21, 22], [23, 24], [25, 26], [27, 28], [29], [30], [31]]
[2025-03-16 02:58:59 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 0 with layers [0] ===
[2025-03-16 02:58:59 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-16 02:59:29 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 0 loss:0.008308044634759426 norm:0.01283178385347128 max memory_allocated 34633.880859375 
[2025-03-16 02:59:56 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 1 loss:0.004624516237527132 norm:0.007592895999550819 max memory_allocated 34633.880859375 
[2025-03-16 03:00:22 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 2 loss:0.0031226298306137323 norm:0.005292136687785387 max memory_allocated 34633.880859375 
[2025-03-16 03:00:49 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 3 loss:0.00257560214959085 norm:0.004187874495983124 max memory_allocated 34633.880859375 
[2025-03-16 03:01:16 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 4 loss:0.002414178801700473 norm:0.003462668973952532 max memory_allocated 34633.880859375 
[2025-03-16 03:01:43 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 5 loss:0.0023077516816556454 norm:0.0029456315096467733 max memory_allocated 34633.880859375 
[2025-03-16 03:02:10 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 6 loss:0.002263115020468831 norm:0.002637614496052265 max memory_allocated 34633.880859375 
[2025-03-16 03:02:37 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 7 loss:0.0022089642006903887 norm:0.0023967106826603413 max memory_allocated 34633.880859375 
[2025-03-16 03:03:04 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 8 loss:0.0021747350692749023 norm:0.002067222958430648 max memory_allocated 34633.880859375 
[2025-03-16 03:03:31 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 9 loss:0.00211614859290421 norm:0.001800770522095263 max memory_allocated 34633.880859375 
[2025-03-16 03:03:58 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 10 loss:0.0020775131415575743 norm:0.001601334079168737 max memory_allocated 34633.880859375 
[2025-03-16 03:04:25 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 11 loss:0.0020921663381159306 norm:0.0014141459250822663 max memory_allocated 34633.880859375 
[2025-03-16 03:04:52 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 12 loss:0.0020837881602346897 norm:0.0012948352377861738 max memory_allocated 34633.880859375 
[2025-03-16 03:05:19 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 13 loss:0.002077151322737336 norm:0.0011660916497930884 max memory_allocated 34633.880859375 
[2025-03-16 03:05:46 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 14 loss:0.0020744078792631626 norm:0.0011700369650498033 max memory_allocated 34633.880859375 
[2025-03-16 03:06:13 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 15 loss:0.0020017423667013645 norm:0.0010277517139911652 max memory_allocated 34633.880859375 
[2025-03-16 03:06:40 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 16 loss:0.0019806965719908476 norm:0.0009244356770068407 max memory_allocated 34633.880859375 
[2025-03-16 03:07:07 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 17 loss:0.0019748061895370483 norm:0.0008857278735376894 max memory_allocated 34633.880859375 
[2025-03-16 03:07:34 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 18 loss:0.0019506942480802536 norm:0.0008941451669670641 max memory_allocated 34633.880859375 
[2025-03-16 03:08:01 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 19 loss:0.0019514854066073895 norm:0.000811669509857893 max memory_allocated 34633.880859375 
[2025-03-16 03:08:34 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 1 with layers [1] ===
[2025-03-16 03:08:35 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-16 03:09:04 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 0 loss:0.02811942994594574 norm:0.024772651493549347 max memory_allocated 35100.7724609375 
[2025-03-16 03:09:31 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 1 loss:0.017022989690303802 norm:0.014217107556760311 max memory_allocated 35100.7724609375 
[2025-03-16 03:09:58 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 2 loss:0.01269824244081974 norm:0.009550893679261208 max memory_allocated 35100.7724609375 
[2025-03-16 03:10:25 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 3 loss:0.011336817406117916 norm:0.012880713678896427 max memory_allocated 35100.7724609375 
[2025-03-16 03:10:52 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 4 loss:0.010511713102459908 norm:0.009888132102787495 max memory_allocated 35100.7724609375 
[2025-03-16 03:11:19 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 5 loss:0.010044561699032784 norm:0.008013379760086536 max memory_allocated 35100.7724609375 
[2025-03-16 03:11:46 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 6 loss:0.010298424400389194 norm:0.008421109989285469 max memory_allocated 35100.7724609375 
[2025-03-16 03:12:13 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 7 loss:0.010494190268218517 norm:0.008478648960590363 max memory_allocated 35100.7724609375 
[2025-03-16 03:12:40 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 8 loss:0.009436463937163353 norm:0.008250758051872253 max memory_allocated 35100.7724609375 
[2025-03-16 03:13:07 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 9 loss:0.009163402020931244 norm:0.007720480673015118 max memory_allocated 35100.7724609375 
[2025-03-16 03:13:34 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 10 loss:0.009019150398671627 norm:0.0072352527640759945 max memory_allocated 35100.7724609375 
[2025-03-16 03:14:01 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 11 loss:0.00953727401793003 norm:0.008603397756814957 max memory_allocated 35100.7724609375 
[2025-03-16 03:14:28 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 12 loss:0.009239481762051582 norm:0.00796583667397499 max memory_allocated 35100.7724609375 
[2025-03-16 03:14:55 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 13 loss:0.009185954928398132 norm:0.008115066215395927 max memory_allocated 35100.7724609375 
[2025-03-16 03:15:22 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 14 loss:0.009045885875821114 norm:0.007353545632213354 max memory_allocated 35100.7724609375 
[2025-03-16 03:15:49 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 15 loss:0.00987364910542965 norm:0.008376100100576878 max memory_allocated 35100.7724609375 
[2025-03-16 03:16:16 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 16 loss:0.009029907174408436 norm:0.007417944725602865 max memory_allocated 35100.7724609375 
[2025-03-16 03:16:42 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 17 loss:0.009116151370108128 norm:0.007183887530118227 max memory_allocated 35100.7724609375 
[2025-03-16 03:17:09 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 18 loss:0.009248221293091774 norm:0.007138457149267197 max memory_allocated 35100.7724609375 
[2025-03-16 03:17:36 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 19 loss:0.009264810010790825 norm:0.007380855269730091 max memory_allocated 35100.7724609375 
[2025-03-16 03:18:09 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 2 with layers [2] ===
[2025-03-16 03:18:09 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-16 03:18:39 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 0 loss:0.026827994734048843 norm:0.013365215621888638 max memory_allocated 35101.8349609375 
[2025-03-16 03:19:06 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 1 loss:0.01800558716058731 norm:0.008641108870506287 max memory_allocated 35101.8349609375 
[2025-03-16 03:19:33 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 2 loss:0.014370562508702278 norm:0.0060331434942781925 max memory_allocated 35101.8349609375 
[2025-03-16 03:20:00 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 3 loss:0.013171251863241196 norm:0.004647336434572935 max memory_allocated 35101.8349609375 
[2025-03-16 03:20:27 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 4 loss:0.012499566189944744 norm:0.0038784625940024853 max memory_allocated 35101.8349609375 
[2025-03-16 03:20:54 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 5 loss:0.012021901085972786 norm:0.0033635967411100864 max memory_allocated 35101.8349609375 
[2025-03-16 03:21:20 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 6 loss:0.011785428039729595 norm:0.002908590016886592 max memory_allocated 35101.8349609375 
[2025-03-16 03:21:47 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 7 loss:0.0116339810192585 norm:0.00252906559035182 max memory_allocated 35101.8349609375 
[2025-03-16 03:22:14 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 8 loss:0.011521688662469387 norm:0.0021270557772368193 max memory_allocated 35101.8349609375 
[2025-03-16 03:22:41 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 9 loss:0.011457458138465881 norm:0.0017940693069249392 max memory_allocated 35101.8349609375 
[2025-03-16 03:23:08 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 10 loss:0.01141289435327053 norm:0.0014921356923878193 max memory_allocated 35101.8349609375 
[2025-03-16 03:23:35 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 11 loss:0.011378628201782703 norm:0.0012695851037278771 max memory_allocated 35101.8349609375 
[2025-03-16 03:24:02 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 12 loss:0.011398158967494965 norm:0.001336580840870738 max memory_allocated 35101.8349609375 
[2025-03-16 03:24:29 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 13 loss:0.011402521282434464 norm:0.0012981194304302335 max memory_allocated 35101.8349609375 
[2025-03-16 03:24:56 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 14 loss:0.01138080470263958 norm:0.001215900992974639 max memory_allocated 35101.8349609375 
[2025-03-16 03:25:23 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 15 loss:0.011405627243220806 norm:0.00117480696644634 max memory_allocated 35101.8349609375 
[2025-03-16 03:25:50 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 16 loss:0.011456532403826714 norm:0.0011186596238985658 max memory_allocated 35101.8349609375 
[2025-03-16 03:26:17 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 17 loss:0.01143263466656208 norm:0.0010954538593068719 max memory_allocated 35101.8349609375 
[2025-03-16 03:26:44 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 18 loss:0.011414442211389542 norm:0.001023339107632637 max memory_allocated 35101.8349609375 
[2025-03-16 03:27:11 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 19 loss:0.011399512179195881 norm:0.0010271951323375106 max memory_allocated 35101.8349609375 
[2025-03-16 03:27:44 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 3 with layers [3] ===
[2025-03-16 03:28:14 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 0 loss:0.029548393562436104 norm:0.003239538986235857 max memory_allocated 35101.8349609375 
[2025-03-16 03:28:40 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 1 loss:0.02198982983827591 norm:0.0007632048800587654 max memory_allocated 35101.8349609375 
[2025-03-16 03:29:07 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 2 loss:0.017896082252264023 norm:0.00043408191413618624 max memory_allocated 35101.8349609375 
[2025-03-16 03:29:34 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 3 loss:0.0163213349878788 norm:0.0002662401820998639 max memory_allocated 35101.8349609375 
[2025-03-16 03:30:01 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 4 loss:0.01559554785490036 norm:0.0002502166316844523 max memory_allocated 35101.8349609375 
[2025-03-16 03:30:28 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 5 loss:0.015211832709610462 norm:0.00025093505973927677 max memory_allocated 35101.8349609375 
[2025-03-16 03:30:55 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 6 loss:0.015002134256064892 norm:0.0002211230166722089 max memory_allocated 35101.8349609375 
[2025-03-16 03:31:22 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 7 loss:0.014958033338189125 norm:0.00024571872199885547 max memory_allocated 35101.8349609375 
[2025-03-16 03:31:48 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 8 loss:0.014948445372283459 norm:0.00026138342218473554 max memory_allocated 35101.8349609375 
[2025-03-16 03:32:15 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 9 loss:0.014890824444591999 norm:0.00025262642884626985 max memory_allocated 35101.8349609375 
[2025-03-16 03:32:42 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 10 loss:0.01487245224416256 norm:0.0002018601808231324 max memory_allocated 35101.8349609375 
[2025-03-16 03:33:09 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 11 loss:0.01484375074505806 norm:0.00020681621390394866 max memory_allocated 35101.8349609375 
[2025-03-16 03:33:36 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 12 loss:0.014899198897182941 norm:0.00021961788297630847 max memory_allocated 35101.8349609375 
[2025-03-16 03:34:03 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 13 loss:0.014866027049720287 norm:0.00020898600632790476 max memory_allocated 35101.8349609375 
[2025-03-16 03:34:30 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 14 loss:0.014807642437517643 norm:0.00019139700452797115 max memory_allocated 35101.8349609375 
[2025-03-16 03:34:57 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 15 loss:0.014816679060459137 norm:0.000191634549992159 max memory_allocated 35101.8349609375 
[2025-03-16 03:35:23 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 16 loss:0.014861817471683025 norm:0.0002079800033243373 max memory_allocated 35101.8349609375 
[2025-03-16 03:35:50 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 17 loss:0.014833508059382439 norm:0.0001975185878109187 max memory_allocated 35101.8349609375 
[2025-03-16 03:36:17 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 18 loss:0.014856671914458275 norm:0.000209023171919398 max memory_allocated 35101.8349609375 
[2025-03-16 03:36:44 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3]) iter 19 loss:0.014866950921714306 norm:0.00021414006187114865 max memory_allocated 35101.8349609375 
[2025-03-16 03:37:16 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 4 with layers [4, 5] ===
[2025-03-16 03:38:16 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 0 loss:0.05469726026058197 norm:0.0021656055469065905 max memory_allocated 41281.3134765625 
[2025-03-16 03:39:09 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 1 loss:0.03977882117033005 norm:0.0006163435755297542 max memory_allocated 41281.3134765625 
[2025-03-16 03:40:02 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 2 loss:0.03096318617463112 norm:0.0003535511204972863 max memory_allocated 41281.3134765625 
[2025-03-16 03:40:56 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 3 loss:0.02769431658089161 norm:0.00029459677170962095 max memory_allocated 41281.3134765625 
[2025-03-16 03:41:49 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 4 loss:0.02594469115138054 norm:0.0002702452475205064 max memory_allocated 41281.3134765625 
[2025-03-16 03:42:42 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 5 loss:0.02488698624074459 norm:0.0002552480436861515 max memory_allocated 41281.3134765625 
[2025-03-16 03:43:36 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 6 loss:0.02434307150542736 norm:0.00024753279285505414 max memory_allocated 41281.3134765625 
[2025-03-16 03:44:29 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 7 loss:0.02403074875473976 norm:0.0002271826087962836 max memory_allocated 41281.3134765625 
[2025-03-16 03:45:22 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 8 loss:0.02387155592441559 norm:0.0002572398807387799 max memory_allocated 41281.3134765625 
[2025-03-16 03:46:16 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 9 loss:0.023766884580254555 norm:0.0002536223328206688 max memory_allocated 41281.3134765625 
[2025-03-16 03:47:09 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 10 loss:0.02371797151863575 norm:0.0002541388676036149 max memory_allocated 41281.3134765625 
[2025-03-16 03:48:02 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 11 loss:0.023642096668481827 norm:0.00023368207621388137 max memory_allocated 41281.3134765625 
[2025-03-16 03:48:56 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 12 loss:0.02360314503312111 norm:0.0002535944804549217 max memory_allocated 41281.3134765625 
[2025-03-16 03:49:49 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 13 loss:0.023535821586847305 norm:0.00024460541317239404 max memory_allocated 41281.3134765625 
[2025-03-16 03:50:43 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 14 loss:0.023537181317806244 norm:0.00023449787113349885 max memory_allocated 41281.3134765625 
[2025-03-16 03:51:36 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 15 loss:0.02356727607548237 norm:0.0002572659286670387 max memory_allocated 41281.3134765625 
[2025-03-16 03:52:29 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 16 loss:0.023521117866039276 norm:0.00024310490698553622 max memory_allocated 41281.3134765625 
[2025-03-16 03:53:23 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 17 loss:0.023489676415920258 norm:0.0002544145390857011 max memory_allocated 41281.3134765625 
[2025-03-16 03:54:16 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 18 loss:0.02352176606655121 norm:0.00027504589525051415 max memory_allocated 41281.3134765625 
[2025-03-16 03:55:10 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [4, 5]) iter 19 loss:0.02344338968396187 norm:0.0002531851641833782 max memory_allocated 41281.3134765625 
[2025-03-16 03:56:15 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 5 with layers [6, 7] ===
[2025-03-16 03:57:15 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 0 loss:0.06538058072328568 norm:0.0017899286467581987 max memory_allocated 41281.4384765625 
[2025-03-16 03:58:09 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 1 loss:0.04857012629508972 norm:0.0006679649814032018 max memory_allocated 41281.4384765625 
[2025-03-16 03:59:02 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 2 loss:0.03819011524319649 norm:0.0003751266049221158 max memory_allocated 41281.4384765625 
[2025-03-16 03:59:55 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 3 loss:0.03419259563088417 norm:0.00030456745298579335 max memory_allocated 41281.4384765625 
[2025-03-16 04:00:49 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 4 loss:0.03221932426095009 norm:0.0002866221475414932 max memory_allocated 41281.4384765625 
[2025-03-16 04:01:42 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 5 loss:0.031110310927033424 norm:0.0002797253546305001 max memory_allocated 41281.4384765625 
[2025-03-16 04:02:36 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 6 loss:0.030449923127889633 norm:0.00024931933148764074 max memory_allocated 41281.4384765625 
[2025-03-16 04:03:29 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 7 loss:0.03000401146709919 norm:0.0002456320507917553 max memory_allocated 41281.4384765625 
[2025-03-16 04:04:22 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 8 loss:0.029722601175308228 norm:0.00024055734684225172 max memory_allocated 41281.4384765625 
[2025-03-16 04:05:16 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 9 loss:0.0295476745814085 norm:0.0002477393136359751 max memory_allocated 41281.4384765625 
[2025-03-16 04:06:09 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 10 loss:0.029384329915046692 norm:0.0002571761724539101 max memory_allocated 41281.4384765625 
[2025-03-16 04:07:02 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 11 loss:0.029308689758181572 norm:0.0002346598485019058 max memory_allocated 41281.4384765625 
[2025-03-16 04:07:56 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 12 loss:0.029214205220341682 norm:0.00025319118867628276 max memory_allocated 41281.4384765625 
[2025-03-16 04:08:49 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 13 loss:0.02913634106516838 norm:0.00023607253388036042 max memory_allocated 41281.4384765625 
[2025-03-16 04:09:43 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 14 loss:0.029074180871248245 norm:0.00023577295360155404 max memory_allocated 41281.4384765625 
[2025-03-16 04:10:36 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 15 loss:0.02900056354701519 norm:0.00023242564930114895 max memory_allocated 41281.4384765625 
[2025-03-16 04:11:29 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 16 loss:0.028927544131875038 norm:0.00023236039851326495 max memory_allocated 41281.4384765625 
[2025-03-16 04:12:23 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 17 loss:0.02887275442481041 norm:0.0002269486867589876 max memory_allocated 41281.4384765625 
[2025-03-16 04:13:16 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 18 loss:0.0288552176207304 norm:0.00023426581174135208 max memory_allocated 41281.4384765625 
[2025-03-16 04:14:10 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [6, 7]) iter 19 loss:0.028881587088108063 norm:0.0002469560131430626 max memory_allocated 41281.4384765625 
[2025-03-16 04:15:15 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 6 with layers [8, 9] ===
[2025-03-16 04:16:15 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 0 loss:0.06989628076553345 norm:0.0019466064404696226 max memory_allocated 41281.5634765625 
[2025-03-16 04:17:09 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 1 loss:0.05393197387456894 norm:0.0008125340100377798 max memory_allocated 41281.5634765625 
[2025-03-16 04:18:02 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 2 loss:0.043470170348882675 norm:0.00039395212661474943 max memory_allocated 41281.5634765625 
[2025-03-16 04:18:56 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 3 loss:0.03926088288426399 norm:0.00028323932201601565 max memory_allocated 41281.5634765625 
[2025-03-16 04:19:49 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 4 loss:0.03718617558479309 norm:0.00025956888566724956 max memory_allocated 41281.5634765625 
[2025-03-16 04:20:42 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 5 loss:0.03599505126476288 norm:0.0002480217954143882 max memory_allocated 41281.5634765625 
[2025-03-16 04:21:36 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 6 loss:0.03539155051112175 norm:0.0002369955473113805 max memory_allocated 41281.5634765625 
[2025-03-16 04:22:29 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 7 loss:0.03501356765627861 norm:0.0002158655843231827 max memory_allocated 41281.5634765625 
[2025-03-16 04:23:22 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 8 loss:0.03486553579568863 norm:0.00022118203924037516 max memory_allocated 41281.5634765625 
[2025-03-16 04:24:16 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 9 loss:0.03473113477230072 norm:0.000216223910683766 max memory_allocated 41281.5634765625 
[2025-03-16 04:25:09 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 10 loss:0.03458746150135994 norm:0.0002185088669648394 max memory_allocated 41281.5634765625 
[2025-03-16 04:26:03 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 11 loss:0.03450160101056099 norm:0.00021949510846752673 max memory_allocated 41281.5634765625 
[2025-03-16 04:26:56 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 12 loss:0.03439823165535927 norm:0.00022050600091461092 max memory_allocated 41281.5634765625 
[2025-03-16 04:27:49 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 13 loss:0.034297555685043335 norm:0.00020885939011350274 max memory_allocated 41281.5634765625 
[2025-03-16 04:28:43 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 14 loss:0.03421236202120781 norm:0.00021053872478660196 max memory_allocated 41281.5634765625 
[2025-03-16 04:29:36 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 15 loss:0.03415238857269287 norm:0.00020074807980563492 max memory_allocated 41281.5634765625 
[2025-03-16 04:30:29 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 16 loss:0.03413967043161392 norm:0.00020395108731463552 max memory_allocated 41281.5634765625 
[2025-03-16 04:31:23 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 17 loss:0.03410561755299568 norm:0.00020103219139855355 max memory_allocated 41281.5634765625 
[2025-03-16 04:32:16 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 18 loss:0.03407466411590576 norm:0.0002052202180493623 max memory_allocated 41281.5634765625 
[2025-03-16 04:33:10 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [8, 9]) iter 19 loss:0.03402436152100563 norm:0.0002058434038190171 max memory_allocated 41281.5634765625 
[2025-03-16 04:34:17 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 7 with layers [10] ===
[2025-03-16 04:34:47 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 0 loss:0.05175232142210007 norm:0.0009972726693376899 max memory_allocated 41281.5634765625 
[2025-03-16 04:35:14 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 1 loss:0.043250128626823425 norm:0.0006086507928557694 max memory_allocated 41281.5634765625 
[2025-03-16 04:35:40 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 2 loss:0.03674129396677017 norm:0.0003064708143938333 max memory_allocated 41281.5634765625 
[2025-03-16 04:36:07 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 3 loss:0.034415774047374725 norm:0.0001768682268448174 max memory_allocated 41281.5634765625 
[2025-03-16 04:36:34 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 4 loss:0.033484045416116714 norm:0.00014538277173414826 max memory_allocated 41281.5634765625 
[2025-03-16 04:37:01 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 5 loss:0.03307105228304863 norm:0.00013511773431673646 max memory_allocated 41281.5634765625 
[2025-03-16 04:37:28 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 6 loss:0.03288107365369797 norm:0.0001262015721295029 max memory_allocated 41281.5634765625 
[2025-03-16 04:37:55 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 7 loss:0.032773733139038086 norm:0.00012546039943117648 max memory_allocated 41281.5634765625 
[2025-03-16 04:38:22 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 8 loss:0.032658182084560394 norm:0.00012281042290851474 max memory_allocated 41281.5634765625 
[2025-03-16 04:38:48 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 9 loss:0.032588277012109756 norm:0.00012613805301953107 max memory_allocated 41281.5634765625 
[2025-03-16 04:39:15 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 10 loss:0.03249447047710419 norm:0.00012128166417824104 max memory_allocated 41281.5634765625 
[2025-03-16 04:39:42 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 11 loss:0.03239941969513893 norm:0.00011914163769688457 max memory_allocated 41281.5634765625 
[2025-03-16 04:40:09 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 12 loss:0.032349638640880585 norm:0.00011745648953365162 max memory_allocated 41281.5634765625 
[2025-03-16 04:40:36 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 13 loss:0.03233078122138977 norm:0.00012002772564301267 max memory_allocated 41281.5634765625 
[2025-03-16 04:41:03 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 14 loss:0.03231170400977135 norm:0.00011866851127706468 max memory_allocated 41281.5634765625 
[2025-03-16 04:41:30 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 15 loss:0.03226195648312569 norm:0.00011956911475863308 max memory_allocated 41281.5634765625 
[2025-03-16 04:41:57 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 16 loss:0.032207563519477844 norm:0.00011640136654023081 max memory_allocated 41281.5634765625 
[2025-03-16 04:42:23 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 17 loss:0.03217514976859093 norm:0.00011976646783296019 max memory_allocated 41281.5634765625 
[2025-03-16 04:42:50 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 18 loss:0.032171957194805145 norm:0.00011932062625419348 max memory_allocated 41281.5634765625 
[2025-03-16 04:43:17 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [10]) iter 19 loss:0.032149165868759155 norm:0.00012107088696211576 max memory_allocated 41281.5634765625 
[2025-03-16 04:43:50 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 8 with layers [11, 12] ===
[2025-03-16 04:44:48 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 0 loss:0.07405110448598862 norm:0.0014583092415705323 max memory_allocated 41281.7509765625 
[2025-03-16 04:45:42 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 1 loss:0.05894986167550087 norm:0.0007867575623095036 max memory_allocated 41281.7509765625 
[2025-03-16 04:46:35 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 2 loss:0.04837625473737717 norm:0.0004215277440380305 max memory_allocated 41281.7509765625 
[2025-03-16 04:47:28 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 3 loss:0.04401041939854622 norm:0.0002901092520914972 max memory_allocated 41281.7509765625 
[2025-03-16 04:48:22 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 4 loss:0.04194657504558563 norm:0.00023478451475966722 max memory_allocated 41281.7509765625 
[2025-03-16 04:49:15 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 5 loss:0.04082079231739044 norm:0.0002147593768313527 max memory_allocated 41281.7509765625 
[2025-03-16 04:50:08 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 6 loss:0.040225595235824585 norm:0.00020154114463366568 max memory_allocated 41281.7509765625 
[2025-03-16 04:51:02 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 7 loss:0.039843592792749405 norm:0.000195782384253107 max memory_allocated 41281.7509765625 
[2025-03-16 04:51:55 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 8 loss:0.03957030549645424 norm:0.0001935144973685965 max memory_allocated 41281.7509765625 
[2025-03-16 04:52:49 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 9 loss:0.03938821330666542 norm:0.0001873378932941705 max memory_allocated 41281.7509765625 
[2025-03-16 04:53:42 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 10 loss:0.03929215297102928 norm:0.0001882790820673108 max memory_allocated 41281.7509765625 
[2025-03-16 04:54:35 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 11 loss:0.03922049701213837 norm:0.00018835882656276226 max memory_allocated 41281.7509765625 
[2025-03-16 04:55:29 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 12 loss:0.0391552597284317 norm:0.0001881073840195313 max memory_allocated 41281.7509765625 
[2025-03-16 04:56:22 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 13 loss:0.03906390070915222 norm:0.00018451143114361912 max memory_allocated 41281.7509765625 
[2025-03-16 04:57:15 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 14 loss:0.03893565759062767 norm:0.00017222763563040644 max memory_allocated 41281.7509765625 
[2025-03-16 04:58:09 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 15 loss:0.03888368606567383 norm:0.00016890668484847993 max memory_allocated 41281.7509765625 
[2025-03-16 04:59:02 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 16 loss:0.03883359581232071 norm:0.00016779813449829817 max memory_allocated 41281.7509765625 
[2025-03-16 04:59:56 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 17 loss:0.03876969963312149 norm:0.00017758434114512056 max memory_allocated 41281.7509765625 
[2025-03-16 05:00:49 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 18 loss:0.03872323036193848 norm:0.00018460936553310603 max memory_allocated 41281.7509765625 
[2025-03-16 05:01:43 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [11, 12]) iter 19 loss:0.03867475688457489 norm:0.000180565140908584 max memory_allocated 41281.7509765625 
[2025-03-16 05:02:51 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 9 with layers [13, 14] ===
[2025-03-16 05:03:49 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 0 loss:0.06765817850828171 norm:0.0013000443577766418 max memory_allocated 41281.8759765625 
[2025-03-16 05:04:42 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 1 loss:0.055222295224666595 norm:0.0005439425585791469 max memory_allocated 41281.8759765625 
[2025-03-16 05:05:36 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 2 loss:0.046378348022699356 norm:0.0002910467446781695 max memory_allocated 41281.8759765625 
[2025-03-16 05:06:29 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 3 loss:0.0429810956120491 norm:0.00020979395776521415 max memory_allocated 41281.8759765625 
[2025-03-16 05:07:22 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 4 loss:0.041316092014312744 norm:0.00018493825336918235 max memory_allocated 41281.8759765625 
[2025-03-16 05:08:16 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 5 loss:0.040357012301683426 norm:0.00017519253015052527 max memory_allocated 41281.8759765625 
[2025-03-16 05:09:09 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 6 loss:0.039804115891456604 norm:0.00016647839220240712 max memory_allocated 41281.8759765625 
[2025-03-16 05:10:03 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 7 loss:0.03946631774306297 norm:0.00017137732356786728 max memory_allocated 41281.8759765625 
[2025-03-16 05:10:56 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 8 loss:0.03915676474571228 norm:0.00016138314094860107 max memory_allocated 41281.8759765625 
[2025-03-16 05:11:49 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 9 loss:0.03894437849521637 norm:0.0001546323037473485 max memory_allocated 41281.8759765625 
[2025-03-16 05:12:43 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 10 loss:0.03879576921463013 norm:0.00014636199921369553 max memory_allocated 41281.8759765625 
[2025-03-16 05:13:36 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 11 loss:0.03868834674358368 norm:0.00014421052765101194 max memory_allocated 41281.8759765625 
[2025-03-16 05:14:30 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 12 loss:0.03859603777527809 norm:0.00014754547737538815 max memory_allocated 41281.8759765625 
[2025-03-16 05:15:23 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 13 loss:0.038560651242733 norm:0.00014747519162483513 max memory_allocated 41281.8759765625 
[2025-03-16 05:16:16 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 14 loss:0.038512591272592545 norm:0.0001425859227310866 max memory_allocated 41281.8759765625 
[2025-03-16 05:17:10 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 15 loss:0.038456495851278305 norm:0.00013848624075762928 max memory_allocated 41281.8759765625 
[2025-03-16 05:18:03 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 16 loss:0.03841312229633331 norm:0.0001421039632987231 max memory_allocated 41281.8759765625 
[2025-03-16 05:18:57 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 17 loss:0.03834813833236694 norm:0.0001390255056321621 max memory_allocated 41281.8759765625 
[2025-03-16 05:19:50 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 18 loss:0.03831446170806885 norm:0.00014042423572391272 max memory_allocated 41281.8759765625 
[2025-03-16 05:20:43 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [13, 14]) iter 19 loss:0.038281284272670746 norm:0.00013511453289538622 max memory_allocated 41281.8759765625 
[2025-03-16 05:21:51 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 10 with layers [15, 16] ===
[2025-03-16 05:22:49 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 0 loss:0.06901954859495163 norm:0.0012685030233114958 max memory_allocated 41282.0009765625 
[2025-03-16 05:23:43 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 1 loss:0.05642209202051163 norm:0.0004980639205314219 max memory_allocated 41282.0009765625 
[2025-03-16 05:24:36 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 2 loss:0.047073446214199066 norm:0.0002880832180380821 max memory_allocated 41282.0009765625 
[2025-03-16 05:25:29 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 3 loss:0.043685197830200195 norm:0.00023242503812070936 max memory_allocated 41282.0009765625 
[2025-03-16 05:26:23 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 4 loss:0.0419161394238472 norm:0.00019744204473681748 max memory_allocated 41282.0009765625 
[2025-03-16 05:27:16 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 5 loss:0.04089459031820297 norm:0.00018386903684586287 max memory_allocated 41282.0009765625 
[2025-03-16 05:28:10 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 6 loss:0.040237993001937866 norm:0.0001740962907206267 max memory_allocated 41282.0009765625 
[2025-03-16 05:29:03 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 7 loss:0.039819732308387756 norm:0.00017184588068630546 max memory_allocated 41282.0009765625 
[2025-03-16 05:29:56 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 8 loss:0.03953177109360695 norm:0.00016421021427959204 max memory_allocated 41282.0009765625 
[2025-03-16 05:30:50 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 9 loss:0.03931218013167381 norm:0.0001574361667735502 max memory_allocated 41282.0009765625 
[2025-03-16 05:31:43 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 10 loss:0.03914010897278786 norm:0.00015313536277972162 max memory_allocated 41282.0009765625 
[2025-03-16 05:32:36 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 11 loss:0.038970112800598145 norm:0.0001498578058090061 max memory_allocated 41282.0009765625 
[2025-03-16 05:33:30 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 12 loss:0.038867972791194916 norm:0.00014163590094540268 max memory_allocated 41282.0009765625 
[2025-03-16 05:34:23 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 13 loss:0.03876876085996628 norm:0.0001382535556331277 max memory_allocated 41282.0009765625 
[2025-03-16 05:35:16 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 14 loss:0.03868599608540535 norm:0.000144704565173015 max memory_allocated 41282.0009765625 
[2025-03-16 05:36:10 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 15 loss:0.03859235346317291 norm:0.00013590551679953933 max memory_allocated 41282.0009765625 
[2025-03-16 05:37:03 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 16 loss:0.038525260984897614 norm:0.0001331132516497746 max memory_allocated 41282.0009765625 
[2025-03-16 05:37:57 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 17 loss:0.03848223760724068 norm:0.00013217766536399722 max memory_allocated 41282.0009765625 
[2025-03-16 05:38:50 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 18 loss:0.03842281922698021 norm:0.00013002744526602328 max memory_allocated 41282.0009765625 
[2025-03-16 05:39:43 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [15, 16]) iter 19 loss:0.03836615011096001 norm:0.00012438178237061948 max memory_allocated 41282.0009765625 
[2025-03-16 05:40:47 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 11 with layers [17, 18] ===
[2025-03-16 05:41:45 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 0 loss:0.0674593448638916 norm:0.0012203153455629945 max memory_allocated 41282.1259765625 
[2025-03-16 05:42:38 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 1 loss:0.05700411647558212 norm:0.0004596493672579527 max memory_allocated 41282.1259765625 
[2025-03-16 05:43:32 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 2 loss:0.048851944506168365 norm:0.0002527274191379547 max memory_allocated 41282.1259765625 
[2025-03-16 05:44:25 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 3 loss:0.046076565980911255 norm:0.00018654965970199555 max memory_allocated 41282.1259765625 
[2025-03-16 05:45:19 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 4 loss:0.04438791424036026 norm:0.00016286541358567774 max memory_allocated 41282.1259765625 
[2025-03-16 05:46:12 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 5 loss:0.04334965720772743 norm:0.00015660389908589423 max memory_allocated 41282.1259765625 
[2025-03-16 05:47:05 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 6 loss:0.04279828816652298 norm:0.00014869493315927684 max memory_allocated 41282.1259765625 
[2025-03-16 05:47:59 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 7 loss:0.04246018826961517 norm:0.000148592924233526 max memory_allocated 41282.1259765625 
[2025-03-16 05:48:52 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 8 loss:0.042211562395095825 norm:0.00013792584650218487 max memory_allocated 41282.1259765625 
[2025-03-16 05:49:46 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 9 loss:0.04201043024659157 norm:0.00013046115054748952 max memory_allocated 41282.1259765625 
[2025-03-16 05:50:39 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 10 loss:0.041842374950647354 norm:0.0001248096232302487 max memory_allocated 41282.1259765625 
[2025-03-16 05:51:32 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 11 loss:0.04172835126519203 norm:0.00012176329619251192 max memory_allocated 41282.1259765625 
[2025-03-16 05:52:25 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 12 loss:0.04162577539682388 norm:0.00011894207273144275 max memory_allocated 41282.1259765625 
[2025-03-16 05:53:19 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 13 loss:0.041545867919921875 norm:0.00011767358228098601 max memory_allocated 41282.1259765625 
[2025-03-16 05:54:12 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 14 loss:0.04145261272788048 norm:0.00011923906276933849 max memory_allocated 41282.1259765625 
[2025-03-16 05:55:06 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 15 loss:0.041367385536432266 norm:0.00011263125634286553 max memory_allocated 41282.1259765625 
[2025-03-16 05:55:59 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 16 loss:0.04131026938557625 norm:0.00011600655852816999 max memory_allocated 41282.1259765625 
[2025-03-16 05:56:53 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 17 loss:0.0412760004401207 norm:0.00011465082934591919 max memory_allocated 41282.1259765625 
[2025-03-16 05:57:46 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 18 loss:0.04123302176594734 norm:0.00010798128641908988 max memory_allocated 41282.1259765625 
[2025-03-16 05:58:39 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [17, 18]) iter 19 loss:0.04119528830051422 norm:0.0001084360119421035 max memory_allocated 41282.1259765625 
[2025-03-16 05:59:44 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 12 with layers [19, 20] ===
[2025-03-16 06:00:42 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 0 loss:0.07844960689544678 norm:0.0014540214324370027 max memory_allocated 41282.2509765625 
[2025-03-16 06:01:35 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 1 loss:0.06706073880195618 norm:0.0006273090257309377 max memory_allocated 41282.2509765625 
[2025-03-16 06:02:29 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 2 loss:0.05728494003415108 norm:0.0002664154162630439 max memory_allocated 41282.2509765625 
[2025-03-16 06:03:22 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 3 loss:0.0543665736913681 norm:0.0002210455568274483 max memory_allocated 41282.2509765625 
[2025-03-16 06:04:15 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 4 loss:0.05251709371805191 norm:0.00018683089001569897 max memory_allocated 41282.2509765625 
[2025-03-16 06:05:09 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 5 loss:0.051294490694999695 norm:0.000179062393726781 max memory_allocated 41282.2509765625 
[2025-03-16 06:06:02 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 6 loss:0.05063365772366524 norm:0.00017653997929301113 max memory_allocated 41282.2509765625 
[2025-03-16 06:06:55 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 7 loss:0.050275739282369614 norm:0.00017006945563480258 max memory_allocated 41282.2509765625 
[2025-03-16 06:07:49 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 8 loss:0.05004291981458664 norm:0.00016713312652427703 max memory_allocated 41282.2509765625 
[2025-03-16 06:08:42 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 9 loss:0.04981451854109764 norm:0.00016151656745932996 max memory_allocated 41282.2509765625 
[2025-03-16 06:09:36 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 10 loss:0.04963722079992294 norm:0.00015293974138330668 max memory_allocated 41282.2509765625 
[2025-03-16 06:10:29 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 11 loss:0.04947276413440704 norm:0.000145452402648516 max memory_allocated 41282.2509765625 
[2025-03-16 06:11:23 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 12 loss:0.0493321493268013 norm:0.00014172279043123126 max memory_allocated 41282.2509765625 
[2025-03-16 06:12:16 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 13 loss:0.04920358955860138 norm:0.00013921261415816844 max memory_allocated 41282.2509765625 
[2025-03-16 06:13:09 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 14 loss:0.04909250885248184 norm:0.00014300172915682197 max memory_allocated 41282.2509765625 
[2025-03-16 06:14:03 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 15 loss:0.049004554748535156 norm:0.00013730072532780468 max memory_allocated 41282.2509765625 
[2025-03-16 06:14:56 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 16 loss:0.048912182450294495 norm:0.00013433114509098232 max memory_allocated 41282.2509765625 
[2025-03-16 06:15:50 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 17 loss:0.048833392560482025 norm:0.000133294946863316 max memory_allocated 41282.2509765625 
[2025-03-16 06:16:43 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 18 loss:0.04875531792640686 norm:0.00013571910676546395 max memory_allocated 41282.2509765625 
[2025-03-16 06:17:37 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [19, 20]) iter 19 loss:0.04869863763451576 norm:0.00013744343596044928 max memory_allocated 41282.2509765625 
[2025-03-16 06:18:40 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 13 with layers [21, 22] ===
[2025-03-16 06:19:38 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 0 loss:0.09171728044748306 norm:0.0011435974156484008 max memory_allocated 41282.3759765625 
[2025-03-16 06:20:32 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 1 loss:0.08002008497714996 norm:0.00045622739708051085 max memory_allocated 41282.3759765625 
[2025-03-16 06:21:25 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 2 loss:0.06995314359664917 norm:0.0002545416646171361 max memory_allocated 41282.3759765625 
[2025-03-16 06:22:18 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 3 loss:0.06690073013305664 norm:0.00021901818399783224 max memory_allocated 41282.3759765625 
[2025-03-16 06:23:12 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 4 loss:0.06491003930568695 norm:0.0002214365522377193 max memory_allocated 41282.3759765625 
[2025-03-16 06:24:05 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 5 loss:0.06374970823526382 norm:0.00018789400928653777 max memory_allocated 41282.3759765625 
[2025-03-16 06:24:58 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 6 loss:0.06317929923534393 norm:0.00018369271128904074 max memory_allocated 41282.3759765625 
[2025-03-16 06:25:52 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 7 loss:0.0628560483455658 norm:0.0001748610520735383 max memory_allocated 41282.3759765625 
[2025-03-16 06:26:45 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 8 loss:0.06259170174598694 norm:0.0001681439607637003 max memory_allocated 41282.3759765625 
[2025-03-16 06:27:38 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 9 loss:0.06233325973153114 norm:0.0001703106245258823 max memory_allocated 41282.3759765625 
[2025-03-16 06:28:32 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 10 loss:0.06212431192398071 norm:0.00016241343109868467 max memory_allocated 41282.3759765625 
[2025-03-16 06:29:25 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 11 loss:0.061944711953401566 norm:0.00015322428953368217 max memory_allocated 41282.3759765625 
[2025-03-16 06:30:18 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 12 loss:0.061833664774894714 norm:0.00015551350952591747 max memory_allocated 41282.3759765625 
[2025-03-16 06:31:12 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 13 loss:0.061665941029787064 norm:0.00015071341476868838 max memory_allocated 41282.3759765625 
[2025-03-16 06:32:05 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 14 loss:0.06151340529322624 norm:0.00014321590424515307 max memory_allocated 41282.3759765625 
[2025-03-16 06:32:59 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 15 loss:0.06137543544173241 norm:0.00014552778156939894 max memory_allocated 41282.3759765625 
[2025-03-16 06:33:52 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 16 loss:0.061301834881305695 norm:0.0001499039790360257 max memory_allocated 41282.3759765625 
[2025-03-16 06:34:45 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 17 loss:0.061208225786685944 norm:0.00014119026309344918 max memory_allocated 41282.3759765625 
[2025-03-16 06:35:39 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 18 loss:0.061106570065021515 norm:0.00013643890270031989 max memory_allocated 41282.3759765625 
[2025-03-16 06:36:32 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [21, 22]) iter 19 loss:0.06102875620126724 norm:0.00013691406638827175 max memory_allocated 41282.3759765625 
[2025-03-16 06:37:37 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 14 with layers [23, 24] ===
[2025-03-16 06:38:35 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 0 loss:0.1188913956284523 norm:0.0030733083840459585 max memory_allocated 41282.5009765625 
[2025-03-16 06:39:28 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 1 loss:0.10137727856636047 norm:0.0006273629842326045 max memory_allocated 41282.5009765625 
[2025-03-16 06:40:22 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 2 loss:0.08857396990060806 norm:0.0003302339173387736 max memory_allocated 41282.5009765625 
[2025-03-16 06:41:15 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 3 loss:0.08481017500162125 norm:0.0002650912501849234 max memory_allocated 41282.5009765625 
[2025-03-16 06:42:09 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 4 loss:0.0824032723903656 norm:0.0002286325761815533 max memory_allocated 41282.5009765625 
[2025-03-16 06:43:02 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 5 loss:0.08133526891469955 norm:0.0002097724354825914 max memory_allocated 41282.5009765625 
[2025-03-16 06:43:55 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 6 loss:0.08080840110778809 norm:0.00020689168013632298 max memory_allocated 41282.5009765625 
[2025-03-16 06:44:49 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 7 loss:0.08044524490833282 norm:0.00020657459390349686 max memory_allocated 41282.5009765625 
[2025-03-16 06:45:42 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 8 loss:0.08012210577726364 norm:0.0002039333339780569 max memory_allocated 41282.5009765625 
[2025-03-16 06:46:36 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 9 loss:0.07984957098960876 norm:0.00017581108841113746 max memory_allocated 41282.5009765625 
[2025-03-16 06:47:29 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 10 loss:0.07959219068288803 norm:0.0001762164756655693 max memory_allocated 41282.5009765625 
[2025-03-16 06:48:22 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 11 loss:0.0794111043214798 norm:0.00018677410844247788 max memory_allocated 41282.5009765625 
[2025-03-16 06:49:16 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 12 loss:0.07922062277793884 norm:0.00017202075105160475 max memory_allocated 41282.5009765625 
[2025-03-16 06:50:09 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 13 loss:0.07904398441314697 norm:0.0001627118035685271 max memory_allocated 41282.5009765625 
[2025-03-16 06:51:02 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 14 loss:0.0789480060338974 norm:0.00016933010192587972 max memory_allocated 41282.5009765625 
[2025-03-16 06:51:56 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 15 loss:0.07881373167037964 norm:0.00016329454956576228 max memory_allocated 41282.5009765625 
[2025-03-16 06:52:49 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 16 loss:0.07869700342416763 norm:0.00015882201842032373 max memory_allocated 41282.5009765625 
[2025-03-16 06:53:43 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 17 loss:0.07859659194946289 norm:0.00014844629913568497 max memory_allocated 41282.5009765625 
[2025-03-16 06:54:36 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 18 loss:0.07851612567901611 norm:0.0001571207685628906 max memory_allocated 41282.5009765625 
[2025-03-16 06:55:29 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [23, 24]) iter 19 loss:0.07842379808425903 norm:0.00015994199202395976 max memory_allocated 41282.5009765625 
[2025-03-16 06:56:34 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 15 with layers [25, 26] ===
[2025-03-16 06:57:33 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 0 loss:0.14841881394386292 norm:0.0021435124799609184 max memory_allocated 41282.6259765625 
[2025-03-16 06:58:26 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 1 loss:0.13012664020061493 norm:0.0007246325840242207 max memory_allocated 41282.6259765625 
[2025-03-16 06:59:19 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 2 loss:0.11443042755126953 norm:0.00036026499583385885 max memory_allocated 41282.6259765625 
[2025-03-16 07:00:12 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 3 loss:0.10957265645265579 norm:0.0003023561730515212 max memory_allocated 41282.6259765625 
[2025-03-16 07:01:06 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 4 loss:0.10699128359556198 norm:0.0002811143349390477 max memory_allocated 41282.6259765625 
[2025-03-16 07:01:59 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 5 loss:0.10588391870260239 norm:0.00025980049395002425 max memory_allocated 41282.6259765625 
[2025-03-16 07:02:53 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 6 loss:0.10529579967260361 norm:0.00025015874416567385 max memory_allocated 41282.6259765625 
[2025-03-16 07:03:46 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 7 loss:0.1048521026968956 norm:0.00022933339641895145 max memory_allocated 41282.6259765625 
[2025-03-16 07:04:39 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 8 loss:0.10447853058576584 norm:0.00022645741410087794 max memory_allocated 41282.6259765625 
[2025-03-16 07:05:33 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 9 loss:0.10414901375770569 norm:0.00021629077673424035 max memory_allocated 41282.6259765625 
[2025-03-16 07:06:26 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 10 loss:0.10382737219333649 norm:0.00021774016204290092 max memory_allocated 41282.6259765625 
[2025-03-16 07:07:20 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 11 loss:0.10354943573474884 norm:0.00019649876048788428 max memory_allocated 41282.6259765625 
[2025-03-16 07:08:13 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 12 loss:0.10332473367452621 norm:0.00020753541321028024 max memory_allocated 41282.6259765625 
[2025-03-16 07:09:06 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 13 loss:0.10313282907009125 norm:0.00019982716185040772 max memory_allocated 41282.6259765625 
[2025-03-16 07:10:00 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 14 loss:0.1029825210571289 norm:0.0001845465594669804 max memory_allocated 41282.6259765625 
[2025-03-16 07:10:53 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 15 loss:0.10284660756587982 norm:0.00018571785767562687 max memory_allocated 41282.6259765625 
[2025-03-16 07:11:46 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 16 loss:0.10268012434244156 norm:0.0001843768695835024 max memory_allocated 41282.6259765625 
[2025-03-16 07:12:40 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 17 loss:0.10256507992744446 norm:0.0001830563705880195 max memory_allocated 41282.6259765625 
[2025-03-16 07:13:33 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 18 loss:0.10249170660972595 norm:0.00017719645984470844 max memory_allocated 41282.6259765625 
[2025-03-16 07:14:27 root] (abq_llm_calib_config3.py 464): INFO block 15 (layers [25, 26]) iter 19 loss:0.10239265114068985 norm:0.00017783127259463072 max memory_allocated 41282.6259765625 
[2025-03-16 07:15:34 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 16 with layers [27, 28] ===
[2025-03-16 07:15:34 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-16 07:16:32 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 0 loss:0.1840515434741974 norm:0.016275016590952873 max memory_allocated 41282.7509765625 
[2025-03-16 07:17:25 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 1 loss:0.16419000923633575 norm:0.011448190547525883 max memory_allocated 41282.7509765625 
[2025-03-16 07:18:19 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 2 loss:0.14729644358158112 norm:0.007054932881146669 max memory_allocated 41282.7509765625 
[2025-03-16 07:19:12 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 3 loss:0.14159004390239716 norm:0.00554511696100235 max memory_allocated 41282.7509765625 
[2025-03-16 07:20:06 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 4 loss:0.13918553292751312 norm:0.004767024889588356 max memory_allocated 41282.7509765625 
[2025-03-16 07:20:59 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 5 loss:0.13820630311965942 norm:0.004059245809912682 max memory_allocated 41282.7509765625 
[2025-03-16 07:21:53 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 6 loss:0.13752946257591248 norm:0.003500083927065134 max memory_allocated 41282.7509765625 
[2025-03-16 07:22:46 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 7 loss:0.1369660496711731 norm:0.003009270876646042 max memory_allocated 41282.7509765625 
[2025-03-16 07:23:40 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 8 loss:0.1364896148443222 norm:0.002664174186065793 max memory_allocated 41282.7509765625 
[2025-03-16 07:24:33 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 9 loss:0.13624678552150726 norm:0.0027154141571372747 max memory_allocated 41282.7509765625 
[2025-03-16 07:25:27 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 10 loss:0.1360815018415451 norm:0.0029260169249027967 max memory_allocated 41282.7509765625 
[2025-03-16 07:26:20 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 11 loss:0.13579080998897552 norm:0.002766598714515567 max memory_allocated 41282.7509765625 
[2025-03-16 07:27:14 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 12 loss:0.13551034033298492 norm:0.0025149404536932707 max memory_allocated 41282.7509765625 
[2025-03-16 07:28:07 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 13 loss:0.13530558347702026 norm:0.0024547684006392956 max memory_allocated 41282.7509765625 
[2025-03-16 07:29:01 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 14 loss:0.1350569725036621 norm:0.0022637234069406986 max memory_allocated 41282.7509765625 
[2025-03-16 07:29:54 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 15 loss:0.13488134741783142 norm:0.00222428678534925 max memory_allocated 41282.7509765625 
[2025-03-16 07:30:48 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 16 loss:0.13473208248615265 norm:0.0021443951409310102 max memory_allocated 41282.7509765625 
[2025-03-16 07:31:41 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 17 loss:0.13460034132003784 norm:0.002127488376572728 max memory_allocated 41282.7509765625 
[2025-03-16 07:32:35 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 18 loss:0.13448606431484222 norm:0.0020118143875151873 max memory_allocated 41282.7509765625 
[2025-03-16 07:33:28 root] (abq_llm_calib_config3.py 464): INFO block 16 (layers [27, 28]) iter 19 loss:0.13436360657215118 norm:0.0019710008054971695 max memory_allocated 41282.7509765625 
[2025-03-16 07:34:35 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 17 with layers [29] ===
[2025-03-16 07:34:35 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-16 07:35:05 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 0 loss:0.17871156334877014 norm:0.01196290459483862 max memory_allocated 41282.7509765625 
[2025-03-16 07:35:31 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 1 loss:0.16570737957954407 norm:0.00885123573243618 max memory_allocated 41282.7509765625 
[2025-03-16 07:35:58 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 2 loss:0.15540511906147003 norm:0.005656158551573753 max memory_allocated 41282.7509765625 
[2025-03-16 07:36:25 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 3 loss:0.15230481326580048 norm:0.004763882607221603 max memory_allocated 41282.7509765625 
[2025-03-16 07:36:52 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 4 loss:0.15122148394584656 norm:0.004061221145093441 max memory_allocated 41282.7509765625 
[2025-03-16 07:37:19 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 5 loss:0.15073463320732117 norm:0.003506259061396122 max memory_allocated 41282.7509765625 
[2025-03-16 07:37:46 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 6 loss:0.15033304691314697 norm:0.002971164183691144 max memory_allocated 41282.7509765625 
[2025-03-16 07:38:13 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 7 loss:0.14998112618923187 norm:0.00251153321005404 max memory_allocated 41282.7509765625 
[2025-03-16 07:38:40 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 8 loss:0.1497727334499359 norm:0.002379047218710184 max memory_allocated 41282.7509765625 
[2025-03-16 07:39:07 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 9 loss:0.1495998054742813 norm:0.0022905636578798294 max memory_allocated 41282.7509765625 
[2025-03-16 07:39:34 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 10 loss:0.14946548640727997 norm:0.0022487076930701733 max memory_allocated 41282.7509765625 
[2025-03-16 07:40:01 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 11 loss:0.14945915341377258 norm:0.0022699881810694933 max memory_allocated 41282.7509765625 
[2025-03-16 07:40:28 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 12 loss:0.1493503898382187 norm:0.002388001885265112 max memory_allocated 41282.7509765625 
[2025-03-16 07:40:55 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 13 loss:0.14925776422023773 norm:0.00204380857758224 max memory_allocated 41282.7509765625 
[2025-03-16 07:41:22 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 14 loss:0.14905592799186707 norm:0.0020784197840839624 max memory_allocated 41282.7509765625 
[2025-03-16 07:41:49 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 15 loss:0.14896325767040253 norm:0.0018805485451593995 max memory_allocated 41282.7509765625 
[2025-03-16 07:42:16 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 16 loss:0.14888115227222443 norm:0.0019186383578926325 max memory_allocated 41282.7509765625 
[2025-03-16 07:42:43 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 17 loss:0.14878225326538086 norm:0.0017630212241783738 max memory_allocated 41282.7509765625 
[2025-03-16 07:43:10 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 18 loss:0.14869384467601776 norm:0.0017761812778189778 max memory_allocated 41282.7509765625 
[2025-03-16 07:43:37 root] (abq_llm_calib_config3.py 464): INFO block 17 (layers [29]) iter 19 loss:0.14865903556346893 norm:0.0017494404455646873 max memory_allocated 41282.7509765625 
[2025-03-16 07:44:10 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 18 with layers [30] ===
[2025-03-16 07:44:10 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-16 07:44:39 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 0 loss:0.2548469007015228 norm:0.033808622509241104 max memory_allocated 41282.7509765625 
[2025-03-16 07:45:06 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 1 loss:0.22241538763046265 norm:0.019487271085381508 max memory_allocated 41282.7509765625 
[2025-03-16 07:45:33 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 2 loss:0.2027590423822403 norm:0.013105819001793861 max memory_allocated 41282.7509765625 
[2025-03-16 07:46:00 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 3 loss:0.19813141226768494 norm:0.012128095142543316 max memory_allocated 41282.7509765625 
[2025-03-16 07:46:27 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 4 loss:0.19673587381839752 norm:0.010800903663039207 max memory_allocated 41282.7509765625 
[2025-03-16 07:46:54 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 5 loss:0.19613398611545563 norm:0.01081586629152298 max memory_allocated 41282.7509765625 
[2025-03-16 07:47:21 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 6 loss:0.19542580842971802 norm:0.009619928896427155 max memory_allocated 41282.7509765625 
[2025-03-16 07:47:48 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 7 loss:0.1948510706424713 norm:0.009051098488271236 max memory_allocated 41282.7509765625 
[2025-03-16 07:48:15 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 8 loss:0.1944582611322403 norm:0.008569691330194473 max memory_allocated 41282.7509765625 
[2025-03-16 07:48:42 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 9 loss:0.1940322369337082 norm:0.008495954796671867 max memory_allocated 41282.7509765625 
[2025-03-16 07:49:09 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 10 loss:0.193720743060112 norm:0.008108259178698063 max memory_allocated 41282.7509765625 
[2025-03-16 07:49:36 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 11 loss:0.19389767944812775 norm:0.008050299249589443 max memory_allocated 41282.7509765625 
[2025-03-16 07:50:03 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 12 loss:0.19430121779441833 norm:0.008317891508340836 max memory_allocated 41282.7509765625 
[2025-03-16 07:50:30 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 13 loss:0.19384650886058807 norm:0.00790849793702364 max memory_allocated 41282.7509765625 
[2025-03-16 07:50:57 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 14 loss:0.19351831078529358 norm:0.007963542826473713 max memory_allocated 41282.7509765625 
[2025-03-16 07:51:24 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 15 loss:0.1930314004421234 norm:0.0074345869943499565 max memory_allocated 41282.7509765625 
[2025-03-16 07:51:51 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 16 loss:0.1933813840150833 norm:0.007373823318630457 max memory_allocated 41282.7509765625 
[2025-03-16 07:52:18 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 17 loss:0.19281917810440063 norm:0.007109240163117647 max memory_allocated 41282.7509765625 
[2025-03-16 07:52:45 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 18 loss:0.19314634799957275 norm:0.007101575378328562 max memory_allocated 41282.7509765625 
[2025-03-16 07:53:12 root] (abq_llm_calib_config3.py 464): INFO block 18 (layers [30]) iter 19 loss:0.19343911111354828 norm:0.007151603698730469 max memory_allocated 41282.7509765625 
[2025-03-16 07:53:45 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 19 with layers [31] ===
[2025-03-16 07:53:45 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-16 07:54:15 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 0 loss:0.427137553691864 norm:0.05969347059726715 max memory_allocated 41282.7509765625 
[2025-03-16 07:54:41 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 1 loss:0.37510502338409424 norm:0.04245121777057648 max memory_allocated 41282.7509765625 
[2025-03-16 07:55:08 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 2 loss:0.336130827665329 norm:0.026319503784179688 max memory_allocated 41282.7509765625 
[2025-03-16 07:55:35 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 3 loss:0.32657578587532043 norm:0.023373620584607124 max memory_allocated 41282.7509765625 
[2025-03-16 07:56:02 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 4 loss:0.32273685932159424 norm:0.020926078781485558 max memory_allocated 41282.7509765625 
[2025-03-16 07:56:29 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 5 loss:0.3202696442604065 norm:0.01907888427376747 max memory_allocated 41282.7509765625 
[2025-03-16 07:56:56 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 6 loss:0.31802287697792053 norm:0.01720050349831581 max memory_allocated 41282.7509765625 
[2025-03-16 07:57:23 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 7 loss:0.3164701759815216 norm:0.01588577777147293 max memory_allocated 41282.7509765625 
[2025-03-16 07:57:50 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 8 loss:0.31543293595314026 norm:0.014517501927912235 max memory_allocated 41282.7509765625 
[2025-03-16 07:58:17 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 9 loss:0.31449830532073975 norm:0.014424631372094154 max memory_allocated 41282.7509765625 
[2025-03-16 07:58:44 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 10 loss:0.3137701749801636 norm:0.013493534177541733 max memory_allocated 41282.7509765625 
[2025-03-16 07:59:11 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 11 loss:0.3133891224861145 norm:0.013285229913890362 max memory_allocated 41282.7509765625 
[2025-03-16 07:59:38 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 12 loss:0.31275317072868347 norm:0.012755938805639744 max memory_allocated 41282.7509765625 
[2025-03-16 08:00:05 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 13 loss:0.3119073510169983 norm:0.012418675236403942 max memory_allocated 41282.7509765625 
[2025-03-16 08:00:32 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 14 loss:0.31145530939102173 norm:0.012243250384926796 max memory_allocated 41282.7509765625 
[2025-03-16 08:00:59 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 15 loss:0.31057143211364746 norm:0.011520719155669212 max memory_allocated 41282.7509765625 
[2025-03-16 08:01:26 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 16 loss:0.3105674088001251 norm:0.011779779568314552 max memory_allocated 41282.7509765625 
[2025-03-16 08:01:53 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 17 loss:0.3098337650299072 norm:0.011059205047786236 max memory_allocated 41282.7509765625 
[2025-03-16 08:02:20 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 18 loss:0.30977657437324524 norm:0.010605394840240479 max memory_allocated 41282.7509765625 
[2025-03-16 08:02:47 root] (abq_llm_calib_config3.py 464): INFO block 19 (layers [31]) iter 19 loss:0.3094974756240845 norm:0.011034756898880005 max memory_allocated 41282.7509765625 
[2025-03-16 08:03:23 root] (main_calib_config3.py 379): INFO 18265.804326295853
[2025-03-16 08:03:28 root] (main_calib_config3.py 117): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-16 08:04:14 root] (main_calib_config3.py 161): INFO wikitext2 : 5.634474754333496
[2025-03-16 08:04:14 root] (main_calib_config3.py 117): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-16 08:05:25 root] (main_calib_config3.py 161): INFO c4 : 7.192984104156494
[2025-03-16 08:44:15 root] (main_calib_config3.py 172): INFO {'wikitext2': 5.634474754333496, 'c4': 7.192984104156494, 'results': {'arc_challenge': {'acc': 0.4035836177474403, 'acc_stderr': 0.014337158914268447, 'acc_norm': 0.40017064846416384, 'acc_norm_stderr': 0.014317197787809172}, 'winogrande': {'acc': 0.6779794790844514, 'acc_stderr': 0.013132070202071059}, 'boolq': {'acc': 0.718348623853211, 'acc_stderr': 0.007867126084150695}, 'hellaswag': {'acc': 0.552778331009759, 'acc_stderr': 0.004961904949171391, 'acc_norm': 0.7142003584943238, 'acc_norm_stderr': 0.004508710891053851}, 'arc_easy': {'acc': 0.6835016835016835, 'acc_stderr': 0.009543851857323891, 'acc_norm': 0.5235690235690236, 'acc_norm_stderr': 0.010248378585554037}, 'piqa': {'acc': 0.7763873775843307, 'acc_stderr': 0.009721489519176299, 'acc_norm': 0.7709466811751904, 'acc_norm_stderr': 0.009804509865175504}}, 'versions': {'arc_challenge': 0, 'winogrande': 0, 'boolq': 1, 'hellaswag': 0, 'arc_easy': 0, 'piqa': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
[2025-03-16 08:44:15 root] (main_calib_config3.py 175): INFO 40.36,68.35,71.83,55.28,77.64,67.80
