[2025-03-22 01:18:15 root] (main_calibration_a2.py 274): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-calibration-compensation-lwc-loss/Llama-2-7b-hf-w4a4-kl', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, scale_calibration=True, compensation_calibration=True, rank=1, loss_type='kl')
[2025-03-22 01:21:13 root] (main_calibration_a2.py 341): INFO === start quantization ===
[2025-03-22 01:21:13 root] (main_calibration_a2.py 347): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-22 01:21:13 root] (abq_llm_calibration_a2.py 62): INFO Starting ...
[2025-03-22 01:21:16 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 0 ===
[2025-03-22 01:21:20 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:21:53 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 0 loss:4.6571962286634516e-08 norm:2.2468176652523653e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:22:26 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 1 loss:3.5616686488992855e-08 norm:1.4594969677261815e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:23:00 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 2 loss:3.2253382187263924e-08 norm:1.3707157187070607e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:23:33 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 3 loss:3.03970324466718e-08 norm:1.4003052939415284e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:24:07 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 4 loss:2.87041750368644e-08 norm:1.3093474748870904e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:24:40 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 5 loss:2.8171033505941523e-08 norm:1.3887895278230644e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:25:13 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 6 loss:2.791066933127695e-08 norm:1.4651424073974795e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:25:46 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 7 loss:2.71454769773527e-08 norm:1.583628517209945e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:26:19 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 8 loss:2.7041478389833173e-08 norm:1.7138347629952477e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:26:52 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 9 loss:2.6160353883142307e-08 norm:1.6844253991621372e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:27:25 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 10 loss:2.6555378340731295e-08 norm:1.8683632418969864e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:27:58 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 11 loss:2.6767505545421955e-08 norm:2.029766221767204e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:28:31 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 12 loss:2.6688269372243667e-08 norm:2.014021660556864e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:29:04 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 13 loss:2.621161776517056e-08 norm:1.9296560793691242e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:29:37 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 14 loss:2.569572465915826e-08 norm:1.8739337193096617e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:30:10 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 15 loss:2.491095685286382e-08 norm:1.7457544743137987e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:30:43 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 16 loss:2.4519803076827884e-08 norm:1.7540333629995075e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:31:16 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 17 loss:2.4291896494332832e-08 norm:1.7478910763202293e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:31:49 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 18 loss:2.4426213940387242e-08 norm:1.8221131270479418e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:32:22 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 19 loss:2.406061661019976e-08 norm:1.7808034158406372e-08 max memory_allocated 22722.10595703125 
[2025-03-22 01:32:31 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 1 ===
[2025-03-22 01:32:34 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:33:06 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 0 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:33:38 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 1 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:34:10 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 2 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:34:42 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 3 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:35:14 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 4 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:35:46 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 5 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:36:18 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 6 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:36:50 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 7 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:37:22 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 8 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:37:54 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 9 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:38:26 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 10 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:38:58 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 11 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:39:30 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 12 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:40:02 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 13 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:40:34 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 14 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:41:06 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 15 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:41:38 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 16 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:42:10 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 17 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:42:42 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 18 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:43:14 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 19 loss:4.774363787873881e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:43:23 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 2 ===
[2025-03-22 01:43:26 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:43:59 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 0 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:44:31 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 1 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:45:03 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 2 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:45:35 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 3 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:46:07 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 4 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:46:39 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 5 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:47:11 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 6 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:47:43 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 7 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:48:15 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 8 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:48:48 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 9 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:49:20 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 10 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:49:52 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 11 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:50:24 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 12 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:50:56 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 13 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:51:28 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 14 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:52:00 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 15 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:52:32 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 16 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:53:04 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 17 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:53:37 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 18 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:54:09 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 19 loss:4.143685600865865e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:54:18 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 3 ===
[2025-03-22 01:54:54 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 0 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:55:26 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 1 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:55:58 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 2 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:56:30 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 3 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:57:02 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 4 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:57:34 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 5 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:58:06 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 6 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:58:38 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 7 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:59:10 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 8 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 01:59:42 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 9 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:00:14 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 10 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:00:46 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 11 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:01:18 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 12 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:01:50 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 13 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:02:22 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 14 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:02:54 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 15 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:03:26 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 16 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:03:58 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 17 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:04:30 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 18 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:05:02 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 19 loss:5.151056029717438e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:05:11 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 4 ===
[2025-03-22 02:05:47 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 0 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:06:19 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 1 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:06:51 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 2 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:07:23 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 3 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:07:55 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 4 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:08:27 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 5 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:08:59 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 6 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:09:31 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 7 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:10:03 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 8 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:10:35 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 9 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:11:07 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 10 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:11:39 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 11 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:12:11 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 12 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:12:43 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 13 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:13:15 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 14 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:13:47 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 15 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:14:19 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 16 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:14:51 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 17 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:15:23 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 18 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:15:55 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 19 loss:6.969762125663692e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:16:04 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 5 ===
[2025-03-22 02:16:40 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 0 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:17:12 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 1 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:17:44 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 2 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:18:16 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 3 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:18:48 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 4 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:19:20 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 5 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:19:52 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 6 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:20:24 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 7 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:20:57 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 8 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:21:29 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 9 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:22:01 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 10 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:22:33 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 11 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:23:05 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 12 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:23:37 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 13 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:24:09 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 14 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:24:41 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 15 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:25:13 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 16 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:25:45 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 17 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:26:17 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 18 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:26:49 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 19 loss:8.763136065681465e-06 norm:nan max memory_allocated 22722.10595703125 
[2025-03-22 02:26:58 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 6 ===
[2025-03-22 02:27:34 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 0 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:28:06 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 1 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:28:38 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 2 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:29:10 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 3 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:29:43 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 4 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:30:15 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 5 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:30:47 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 6 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:31:19 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 7 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:31:51 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 8 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:32:23 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 9 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:32:55 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 10 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:33:27 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 11 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:33:59 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 12 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:34:31 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 13 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:35:03 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 14 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:35:35 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 15 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:36:08 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 16 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:36:40 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 17 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:37:12 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 18 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:37:44 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 19 loss:1.2459064237191342e-05 norm:nan max memory_allocated 22722.19580078125 
[2025-03-22 02:37:53 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 7 ===
[2025-03-22 02:38:29 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 0 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:39:01 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 1 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:39:33 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 2 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:40:05 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 3 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:40:37 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 4 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:41:09 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 5 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:41:41 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 6 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:42:14 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 7 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:42:46 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 8 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:43:18 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 9 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:43:50 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 10 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:44:22 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 11 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:44:54 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 12 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:45:26 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 13 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:45:58 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 14 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:46:30 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 15 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:47:02 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 16 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:47:35 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 17 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:48:07 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 18 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:48:39 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 19 loss:1.7515249055577442e-05 norm:nan max memory_allocated 22722.36767578125 
[2025-03-22 02:48:48 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 8 ===
[2025-03-22 02:49:24 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 0 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:49:56 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 1 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:50:28 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 2 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:51:00 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 3 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:51:32 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 4 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:52:04 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 5 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:52:36 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 6 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:53:09 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 7 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:53:41 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 8 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:54:13 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 9 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:54:45 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 10 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:55:17 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 11 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:55:49 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 12 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:56:21 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 13 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:56:53 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 14 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:57:25 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 15 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:57:57 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 16 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:58:30 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 17 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:59:02 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 18 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:59:34 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 19 loss:2.2706775780534372e-05 norm:nan max memory_allocated 22722.53955078125 
[2025-03-22 02:59:43 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 9 ===
[2025-03-22 03:00:19 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 0 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:00:51 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 1 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:01:23 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 2 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:01:55 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 3 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:02:27 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 4 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:02:59 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 5 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:03:32 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 6 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:04:04 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 7 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:04:36 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 8 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:05:08 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 9 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:05:40 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 10 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:06:12 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 11 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:06:44 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 12 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:07:16 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 13 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:07:48 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 14 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:08:20 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 15 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:08:53 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 16 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:09:25 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 17 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:09:57 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 18 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:10:29 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 19 loss:2.886264701373875e-05 norm:nan max memory_allocated 22722.71142578125 
[2025-03-22 03:10:38 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 10 ===
[2025-03-22 03:11:14 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 0 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:11:46 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 1 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:12:18 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 2 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:12:50 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 3 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:13:22 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 4 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:13:54 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 5 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:14:26 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 6 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:14:59 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 7 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:15:31 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 8 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:16:03 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 9 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:16:35 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 10 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:17:07 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 11 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:17:39 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 12 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:18:11 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 13 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:18:43 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 14 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:19:15 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 15 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:19:47 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 16 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:20:20 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 17 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:20:52 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 18 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:21:24 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 19 loss:3.367914177943021e-05 norm:nan max memory_allocated 22722.88330078125 
[2025-03-22 03:21:33 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 11 ===
[2025-03-22 03:22:09 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 0 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:22:41 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 1 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:23:13 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 2 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:23:45 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 3 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:24:17 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 4 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:24:49 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 5 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:25:22 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 6 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:25:54 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 7 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:26:26 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 8 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:26:58 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 9 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:27:30 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 10 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:28:02 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 11 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:28:34 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 12 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:29:06 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 13 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:29:38 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 14 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:30:11 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 15 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:30:43 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 16 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:31:15 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 17 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:31:47 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 18 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:32:19 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 19 loss:4.9227244744542986e-05 norm:nan max memory_allocated 22723.05517578125 
[2025-03-22 03:32:28 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 12 ===
[2025-03-22 03:33:04 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 0 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:33:36 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 1 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:34:08 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 2 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:34:40 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 3 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:35:13 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 4 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:35:45 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 5 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:36:17 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 6 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:36:49 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 7 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:37:21 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 8 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:37:53 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 9 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:38:26 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 10 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:38:58 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 11 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:39:30 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 12 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:40:02 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 13 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:40:34 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 14 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:41:06 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 15 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:41:38 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 16 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:42:10 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 17 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:42:43 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 18 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:43:15 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 19 loss:6.412291986634955e-05 norm:nan max memory_allocated 22723.22705078125 
[2025-03-22 03:43:24 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 13 ===
[2025-03-22 03:44:00 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 0 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:44:32 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 1 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:45:04 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 2 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:45:36 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 3 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:46:08 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 4 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:46:40 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 5 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:47:12 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 6 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:47:44 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 7 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:48:17 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 8 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:48:49 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 9 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:49:21 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 10 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:49:53 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 11 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:50:25 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 12 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:50:57 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 13 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:51:29 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 14 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:52:01 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 15 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:52:33 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 16 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:53:06 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 17 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:53:38 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 18 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:54:10 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 19 loss:0.000159133443958126 norm:nan max memory_allocated 22723.39892578125 
[2025-03-22 03:54:19 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 14 ===
[2025-03-22 03:54:55 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 0 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 03:55:27 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 1 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 03:55:59 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 2 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 03:56:31 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 3 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 03:57:03 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 4 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 03:57:36 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 5 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 03:58:08 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 6 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 03:58:40 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 7 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 03:59:12 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 8 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 03:59:44 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 9 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 04:00:16 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 10 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 04:00:48 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 11 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 04:01:20 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 12 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 04:01:53 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 13 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 04:02:25 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 14 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 04:02:57 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 15 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 04:03:29 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 16 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 04:04:01 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 17 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 04:04:33 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 18 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 04:05:05 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 19 loss:0.00023165291349869221 norm:nan max memory_allocated 22723.57080078125 
[2025-03-22 04:05:14 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 15 ===
[2025-03-22 04:05:50 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 0 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:06:22 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 1 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:06:55 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 2 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:07:27 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 3 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:07:59 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 4 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:08:31 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 5 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:09:03 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 6 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:09:35 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 7 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:10:07 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 8 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:10:39 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 9 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:11:12 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 10 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:11:44 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 11 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:12:16 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 12 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:12:48 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 13 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:13:20 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 14 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:13:52 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 15 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:14:24 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 16 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:14:56 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 17 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:15:28 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 18 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:16:00 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 19 loss:0.00044554920168593526 norm:nan max memory_allocated 22723.74267578125 
[2025-03-22 04:16:10 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 16 ===
[2025-03-22 04:16:45 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 0 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:17:18 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 1 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:17:50 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 2 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:18:22 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 3 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:18:54 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 4 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:19:26 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 5 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:19:58 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 6 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:20:30 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 7 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:21:02 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 8 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:21:35 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 9 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:22:07 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 10 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:22:39 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 11 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:23:11 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 12 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:23:43 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 13 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:24:15 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 14 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:24:47 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 15 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:25:19 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 16 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:25:52 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 17 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:26:24 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 18 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:26:56 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 19 loss:0.0007330976659432054 norm:nan max memory_allocated 22723.91455078125 
[2025-03-22 04:27:05 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 17 ===
[2025-03-22 04:27:41 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 0 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:28:13 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 1 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:28:45 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 2 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:29:17 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 3 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:29:49 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 4 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:30:22 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 5 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:30:54 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 6 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:31:26 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 7 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:31:58 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 8 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:32:30 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 9 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:33:02 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 10 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:33:34 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 11 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:34:07 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 12 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:34:39 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 13 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:35:11 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 14 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:35:43 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 15 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:36:15 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 16 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:36:47 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 17 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:37:19 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 18 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:37:52 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 19 loss:0.0010938718914985657 norm:nan max memory_allocated 22724.08642578125 
[2025-03-22 04:38:01 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 18 ===
[2025-03-22 04:38:37 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 0 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:39:09 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 1 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:39:41 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 2 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:40:13 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 3 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:40:45 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 4 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:41:17 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 5 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:41:49 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 6 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:42:21 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 7 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:42:54 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 8 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:43:26 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 9 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:43:58 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 10 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:44:30 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 11 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:45:02 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 12 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:45:34 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 13 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:46:06 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 14 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:46:38 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 15 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:47:10 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 16 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:47:43 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 17 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:48:15 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 18 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:48:47 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 19 loss:0.0015994701534509659 norm:nan max memory_allocated 22724.25830078125 
[2025-03-22 04:48:56 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 19 ===
[2025-03-22 04:49:32 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 0 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:50:04 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 1 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:50:37 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 2 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:51:09 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 3 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:51:41 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 4 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:52:13 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 5 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:52:45 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 6 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:53:17 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 7 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:53:49 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 8 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:54:21 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 9 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:54:53 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 10 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:55:26 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 11 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:55:58 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 12 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:56:30 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 13 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:57:02 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 14 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:57:34 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 15 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:58:06 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 16 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:58:38 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 17 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:59:10 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 18 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:59:43 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 19 loss:0.0019947162363678217 norm:nan max memory_allocated 22724.43017578125 
[2025-03-22 04:59:52 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 20 ===
[2025-03-22 05:00:28 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 0 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:01:00 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 1 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:01:32 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 2 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:02:04 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 3 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:02:36 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 4 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:03:08 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 5 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:03:40 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 6 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:04:12 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 7 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:04:45 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 8 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:05:17 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 9 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:05:49 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 10 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:06:21 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 11 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:06:53 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 12 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:07:25 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 13 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:07:57 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 14 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:08:29 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 15 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:09:01 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 16 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:09:34 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 17 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:10:06 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 18 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:10:38 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 19 loss:0.002322044689208269 norm:nan max memory_allocated 22724.60205078125 
[2025-03-22 05:10:47 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 21 ===
[2025-03-22 05:11:23 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 0 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:11:55 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 1 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:12:27 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 2 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:12:59 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 3 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:13:31 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 4 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:14:03 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 5 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:14:35 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 6 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:15:07 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 7 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:15:40 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 8 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:16:12 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 9 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:16:44 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 10 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:17:16 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 11 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:17:48 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 12 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:18:20 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 13 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:18:52 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 14 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:19:24 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 15 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:19:56 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 16 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:20:29 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 17 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:21:01 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 18 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:21:33 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 19 loss:0.0025895151775330305 norm:nan max memory_allocated 22724.77392578125 
[2025-03-22 05:21:42 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 22 ===
[2025-03-22 05:22:18 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 0 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:22:50 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 1 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:23:22 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 2 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:23:54 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 3 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:24:26 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 4 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:24:59 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 5 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:25:31 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 6 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:26:03 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 7 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:26:35 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 8 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:27:07 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 9 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:27:39 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 10 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:28:11 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 11 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:28:43 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 12 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:29:16 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 13 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:29:48 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 14 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:30:20 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 15 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:30:52 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 16 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:31:24 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 17 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:31:56 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 18 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:32:28 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 19 loss:0.0020543988794088364 norm:nan max memory_allocated 22724.94580078125 
[2025-03-22 05:32:38 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 23 ===
[2025-03-22 05:33:13 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 0 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:33:46 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 1 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:34:18 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 2 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:34:50 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 3 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:35:22 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 4 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:35:54 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 5 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:36:26 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 6 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:36:58 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 7 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:37:30 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 8 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:38:02 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 9 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:38:35 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 10 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:39:07 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 11 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:39:39 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 12 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:40:11 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 13 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:40:43 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 14 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:41:15 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 15 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:41:47 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 16 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:42:19 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 17 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:42:51 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 18 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:43:24 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 19 loss:0.0019571413286030293 norm:nan max memory_allocated 22725.11767578125 
[2025-03-22 05:43:33 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 24 ===
[2025-03-22 05:44:09 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 0 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:44:41 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 1 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:45:13 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 2 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:45:45 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 3 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:46:17 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 4 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:46:49 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 5 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:47:21 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 6 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:47:53 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 7 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:48:26 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 8 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:48:58 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 9 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:49:30 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 10 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:50:02 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 11 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:50:34 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 12 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:51:06 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 13 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:51:38 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 14 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:52:10 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 15 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:52:42 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 16 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:53:14 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 17 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:53:46 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 18 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:54:19 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 19 loss:0.0016284105367958546 norm:nan max memory_allocated 22725.28955078125 
[2025-03-22 05:54:28 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 25 ===
[2025-03-22 05:55:04 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 0 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 05:55:36 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 1 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 05:56:08 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 2 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 05:56:40 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 3 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 05:57:12 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 4 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 05:57:44 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 5 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 05:58:16 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 6 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 05:58:48 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 7 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 05:59:21 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 8 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 05:59:53 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 9 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 06:00:25 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 10 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 06:00:57 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 11 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 06:01:29 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 12 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 06:02:01 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 13 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 06:02:33 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 14 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 06:03:05 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 15 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 06:03:37 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 16 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 06:04:09 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 17 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 06:04:42 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 18 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 06:05:14 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 19 loss:0.0021037657279521227 norm:nan max memory_allocated 22725.46142578125 
[2025-03-22 06:05:23 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 26 ===
[2025-03-22 06:05:59 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 0 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:06:31 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 1 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:07:03 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 2 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:07:35 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 3 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:08:07 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 4 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:08:39 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 5 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:09:11 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 6 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:09:44 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 7 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:10:16 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 8 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:10:48 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 9 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:11:20 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 10 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:11:52 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 11 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:12:24 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 12 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:12:56 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 13 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:13:28 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 14 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:14:00 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 15 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:14:33 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 16 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:15:05 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 17 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:15:37 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 18 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:16:09 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 19 loss:0.002038857899606228 norm:nan max memory_allocated 22725.63330078125 
[2025-03-22 06:16:18 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 27 ===
[2025-03-22 06:16:54 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 0 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:17:26 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 1 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:17:58 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 2 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:18:30 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 3 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:19:03 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 4 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:19:35 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 5 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:20:07 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 6 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:20:39 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 7 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:21:11 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 8 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:21:43 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 9 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:22:15 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 10 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:22:47 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 11 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:23:20 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 12 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:23:52 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 13 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:24:24 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 14 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:24:56 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 15 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:25:28 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 16 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:26:00 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 17 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:26:32 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 18 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:27:04 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 19 loss:0.0024975817650556564 norm:nan max memory_allocated 22725.80517578125 
[2025-03-22 06:27:14 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 28 ===
[2025-03-22 06:27:17 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:27:50 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 0 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:28:22 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 1 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:28:54 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 2 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:29:26 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 3 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:29:58 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 4 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:30:31 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 5 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:31:03 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 6 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:31:35 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 7 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:32:07 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 8 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:32:40 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 9 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:33:12 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 10 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:33:44 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 11 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:34:16 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 12 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:34:49 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 13 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:35:21 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 14 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:35:53 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 15 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:36:25 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 16 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:36:57 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 17 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:37:30 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 18 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:38:02 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 19 loss:0.002357575111091137 norm:nan max memory_allocated 22725.97705078125 
[2025-03-22 06:38:11 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 29 ===
[2025-03-22 06:38:14 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:38:47 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 0 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:39:19 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 1 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:39:52 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 2 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:40:24 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 3 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:40:56 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 4 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:41:28 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 5 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:42:01 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 6 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:42:33 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 7 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:43:05 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 8 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:43:37 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 9 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:44:09 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 10 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:44:42 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 11 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:45:14 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 12 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:45:46 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 13 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:46:18 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 14 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:46:51 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 15 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:47:23 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 16 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:47:55 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 17 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:48:27 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 18 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:49:00 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 19 loss:0.0025128424167633057 norm:nan max memory_allocated 22726.14892578125 
[2025-03-22 06:49:09 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 30 ===
[2025-03-22 06:49:12 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:49:46 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 0 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:50:18 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 1 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:50:51 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 2 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:51:23 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 3 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:51:55 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 4 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:52:27 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 5 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:52:59 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 6 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:53:32 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 7 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:54:04 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 8 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:54:36 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 9 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:55:08 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 10 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:55:41 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 11 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:56:13 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 12 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:56:45 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 13 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:57:17 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 14 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:57:50 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 15 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:58:22 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 16 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:58:54 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 17 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:59:26 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 18 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 06:59:58 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 19 loss:0.0035196689423173666 norm:nan max memory_allocated 22726.32080078125 
[2025-03-22 07:00:08 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 31 ===
[2025-03-22 07:00:11 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 07:00:44 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 0 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:01:16 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 1 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:01:48 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 2 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:02:21 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 3 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:02:53 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 4 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:03:25 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 5 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:03:57 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 6 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:04:30 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 7 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:05:02 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 8 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:05:34 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 9 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:06:07 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 10 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:06:39 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 11 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:07:12 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 12 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:07:44 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 13 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:08:16 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 14 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:08:49 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 15 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:09:21 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 16 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:09:53 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 17 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:10:26 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 18 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:10:58 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 19 loss:0.02059110626578331 norm:nan max memory_allocated 22726.49267578125 
[2025-03-22 07:11:07 root] (main_calibration_a2.py 370): INFO 20994.74470257759
[2025-03-22 07:11:14 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-22 07:12:23 root] (main_calibration_a2.py 158): INFO wikitext2 : 254.87078857421875
[2025-03-22 07:12:23 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-22 07:14:10 root] (main_calibration_a2.py 158): INFO c4 : 251.234375
[2025-03-22 08:54:02 root] (main_calibration_a2.py 169): INFO {'wikitext2': 254.87078857421875, 'c4': 251.234375, 'results': {'arc_challenge': {'acc': 0.2295221843003413, 'acc_stderr': 0.012288926760890767, 'acc_norm': 0.2525597269624573, 'acc_norm_stderr': 0.012696728980207706}, 'arc_easy': {'acc': 0.3468013468013468, 'acc_stderr': 0.009766326091716005, 'acc_norm': 0.3253367003367003, 'acc_norm_stderr': 0.0096134277089962}, 'hellaswag': {'acc': 0.3045210117506473, 'acc_stderr': 0.004592637369905781, 'acc_norm': 0.3586934873531169, 'acc_norm_stderr': 0.004786368011500458}, 'winogrande': {'acc': 0.500394632991318, 'acc_stderr': 0.014052481306049516}, 'piqa': {'acc': 0.5865070729053319, 'acc_stderr': 0.011489895831821131, 'acc_norm': 0.5712731229597389, 'acc_norm_stderr': 0.01154669443571219}, 'boolq': {'acc': 0.6055045871559633, 'acc_stderr': 0.00854815202577093}}, 'versions': {'arc_challenge': 0, 'arc_easy': 0, 'hellaswag': 0, 'winogrande': 0, 'piqa': 0, 'boolq': 1}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
[2025-03-22 08:54:02 root] (main_calibration_a2.py 172): INFO 22.95,34.68,60.55,30.45,58.65,50.04
