[2025-03-22 02:22:29 root] (main_calibration_a2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-calibration-compensation-lwc-loss/llama-7b-hf-w4a4-mse+kl', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, scale_calibration=True, compensation_calibration=True, rank=1, loss_type='mse+kl')
[2025-03-22 02:23:37 root] (main_calibration_a2.py 343): INFO === start quantization ===
[2025-03-22 02:23:37 root] (main_calibration_a2.py 349): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-22 02:23:37 root] (abq_llm_calibration_a2.py 62): INFO Starting ...
[2025-03-22 02:23:40 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 0 ===
[2025-03-22 02:23:44 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 02:24:16 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 0 loss:0.0003904147888533771 norm:0.00020974334620404989 max memory_allocated 22751.10595703125 
[2025-03-22 02:24:49 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 1 loss:0.0002694875583983958 norm:0.00014212451060302556 max memory_allocated 22751.10595703125 
[2025-03-22 02:25:22 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 2 loss:0.00022981554502621293 norm:0.0001053427840815857 max memory_allocated 22751.10595703125 
[2025-03-22 02:25:56 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 3 loss:0.00021055112301837653 norm:9.085543570108712e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:26:29 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 4 loss:0.0002016735525103286 norm:8.189226355170831e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:27:03 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 5 loss:0.00019661436090245843 norm:7.376287976512685e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:27:36 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 6 loss:0.00019379917648620903 norm:6.479590956587344e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:28:10 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 7 loss:0.00019112677546218038 norm:5.8952111430699006e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:28:43 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 8 loss:0.00019036608864553273 norm:5.551156573346816e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:29:16 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 9 loss:0.00018617343448568135 norm:4.917869227938354e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:29:50 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 10 loss:0.00018390761397313327 norm:4.5562217565020546e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:30:24 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 11 loss:0.0001821778278099373 norm:4.143381374888122e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:30:57 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 12 loss:0.00018129115051124245 norm:3.9024802390486e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:31:31 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 13 loss:0.00017975900846067816 norm:3.5291734093334526e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:32:04 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 14 loss:0.00017985345039051026 norm:3.304050551378168e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:32:38 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 15 loss:0.00017903870320878923 norm:3.069737431360409e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:33:11 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 16 loss:0.000178087706444785 norm:2.8246497095096856e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:33:45 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 17 loss:0.00017811005818657577 norm:2.7319765649735928e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:34:19 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 18 loss:0.00017869121802505106 norm:2.5530396669637412e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:34:52 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 19 loss:0.00017933823983184993 norm:2.4516473786206916e-05 max memory_allocated 22751.10595703125 
[2025-03-22 02:35:01 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 1 ===
[2025-03-22 02:35:04 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 02:35:38 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 0 loss:0.00241034384816885 norm:0.0010792240500450134 max memory_allocated 22751.27783203125 
[2025-03-22 02:36:12 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 1 loss:0.001565443817526102 norm:0.00036416188231669366 max memory_allocated 22751.27783203125 
[2025-03-22 02:36:45 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 2 loss:0.001260731602087617 norm:0.0002087625180138275 max memory_allocated 22751.27783203125 
[2025-03-22 02:37:19 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 3 loss:0.0011379738571122289 norm:0.0001798142329789698 max memory_allocated 22751.27783203125 
[2025-03-22 02:37:53 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 4 loss:0.0010702770669013262 norm:0.0001515811018180102 max memory_allocated 22751.27783203125 
[2025-03-22 02:38:26 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 5 loss:0.0010317632695659995 norm:0.0001311644446104765 max memory_allocated 22751.27783203125 
[2025-03-22 02:38:59 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 6 loss:0.001007810584269464 norm:0.00011967754107899964 max memory_allocated 22751.27783203125 
[2025-03-22 02:39:33 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 7 loss:0.0009904946200549603 norm:0.00011042826372431591 max memory_allocated 22751.27783203125 
[2025-03-22 02:40:07 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 8 loss:0.0009772535413503647 norm:9.734355990076438e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:40:41 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 9 loss:0.0009680608054623008 norm:8.738727046875283e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:41:14 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 10 loss:0.0009624140220694244 norm:8.422830433119088e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:41:48 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 11 loss:0.0009588956600055099 norm:7.682567229494452e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:42:22 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 12 loss:0.0009538535377942026 norm:6.882208253955469e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:42:55 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 13 loss:0.0009497690480202436 norm:6.229523569345474e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:43:29 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 14 loss:0.000945941312238574 norm:5.773420707555488e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:44:03 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 15 loss:0.0009431059588678181 norm:5.495421646628529e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:44:37 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 16 loss:0.0009400185663253069 norm:5.1422575779724866e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:45:10 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 17 loss:0.0009388783946633339 norm:4.919822822557762e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:45:44 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 18 loss:0.0009372198837809265 norm:4.840374458581209e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:46:18 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 19 loss:0.000936981406994164 norm:4.7274454118451104e-05 max memory_allocated 22751.27783203125 
[2025-03-22 02:46:27 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 2 ===
[2025-03-22 02:46:30 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 02:47:03 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 0 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:47:35 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 1 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:48:08 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 2 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:48:40 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 3 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:49:13 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 4 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:49:45 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 5 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:50:17 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 6 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:50:50 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 7 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:51:22 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 8 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:51:55 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 9 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:52:27 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 10 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:52:59 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 11 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:53:32 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 12 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:54:04 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 13 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:54:36 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 14 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:55:09 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 15 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:55:41 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 16 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:56:13 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 17 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:56:46 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 18 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:57:18 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 19 loss:0.36413511633872986 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:57:27 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 3 ===
[2025-03-22 02:58:03 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 0 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:58:35 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 1 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:59:08 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 2 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 02:59:40 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 3 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:00:13 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 4 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:00:45 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 5 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:01:17 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 6 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:01:50 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 7 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:02:22 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 8 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:02:54 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 9 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:03:26 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 10 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:03:59 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 11 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:04:31 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 12 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:05:03 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 13 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:05:35 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 14 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:06:08 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 15 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:06:40 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 16 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:07:12 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 17 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:07:45 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 18 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:08:17 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 19 loss:0.15486447513103485 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:08:26 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 4 ===
[2025-03-22 03:09:02 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 0 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:09:35 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 1 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:10:07 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 2 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:10:40 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 3 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:11:12 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 4 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:11:44 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 5 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:12:17 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 6 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:12:49 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 7 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:13:21 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 8 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:13:53 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 9 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:14:26 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 10 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:14:58 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 11 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:15:30 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 12 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:16:03 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 13 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:16:35 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 14 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:17:08 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 15 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:17:40 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 16 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:18:12 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 17 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:18:45 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 18 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:19:17 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 19 loss:0.16658541560173035 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:19:26 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 5 ===
[2025-03-22 03:20:03 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 0 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:20:35 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 1 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:21:07 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 2 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:21:40 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 3 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:22:12 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 4 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:22:44 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 5 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:23:17 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 6 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:23:49 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 7 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:24:21 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 8 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:24:54 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 9 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:25:26 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 10 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:25:58 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 11 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:26:31 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 12 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:27:03 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 13 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:27:35 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 14 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:28:08 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 15 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:28:40 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 16 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:29:12 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 17 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:29:45 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 18 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:30:17 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 19 loss:0.18001693487167358 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:30:26 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 6 ===
[2025-03-22 03:31:02 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 0 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:31:35 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 1 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:32:07 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 2 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:32:40 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 3 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:33:12 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 4 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:33:45 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 5 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:34:17 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 6 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:34:50 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 7 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:35:22 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 8 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:35:55 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 9 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:36:27 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 10 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:36:59 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 11 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:37:32 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 12 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:38:04 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 13 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:38:37 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 14 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:39:09 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 15 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:39:42 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 16 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:40:14 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 17 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:40:47 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 18 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:41:19 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 19 loss:0.19507627189159393 norm:nan max memory_allocated 22751.27783203125 
[2025-03-22 03:41:28 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 7 ===
[2025-03-22 03:42:04 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 0 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:42:37 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 1 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:43:09 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 2 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:43:42 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 3 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:44:14 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 4 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:44:47 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 5 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:45:19 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 6 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:45:51 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 7 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:46:24 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 8 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:46:56 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 9 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:47:29 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 10 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:48:01 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 11 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:48:33 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 12 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:49:05 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 13 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:49:38 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 14 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:50:10 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 15 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:50:42 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 16 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:51:15 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 17 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:51:47 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 18 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:52:20 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 19 loss:0.21338433027267456 norm:nan max memory_allocated 22751.36767578125 
[2025-03-22 03:52:29 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 8 ===
[2025-03-22 03:53:05 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 0 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:53:38 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 1 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:54:10 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 2 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:54:42 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 3 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:55:15 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 4 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:55:47 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 5 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:56:19 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 6 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:56:52 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 7 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:57:24 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 8 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:57:56 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 9 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:58:28 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 10 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:59:01 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 11 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 03:59:33 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 12 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 04:00:06 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 13 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 04:00:38 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 14 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 04:01:10 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 15 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 04:01:43 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 16 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 04:02:15 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 17 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 04:02:48 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 18 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 04:03:20 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 19 loss:0.23218934237957 norm:nan max memory_allocated 22751.53955078125 
[2025-03-22 04:03:29 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 9 ===
[2025-03-22 04:04:06 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 0 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:04:38 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 1 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:05:11 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 2 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:05:43 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 3 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:06:15 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 4 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:06:48 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 5 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:07:20 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 6 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:07:53 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 7 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:08:25 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 8 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:08:58 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 9 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:09:30 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 10 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:10:03 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 11 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:10:35 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 12 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:11:08 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 13 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:11:41 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 14 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:12:13 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 15 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:12:45 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 16 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:13:18 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 17 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:13:50 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 18 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:14:23 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 19 loss:0.2592184543609619 norm:nan max memory_allocated 22751.71142578125 
[2025-03-22 04:14:32 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 10 ===
[2025-03-22 04:15:08 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 0 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:15:41 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 1 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:16:13 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 2 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:16:46 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 3 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:17:18 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 4 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:17:51 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 5 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:18:23 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 6 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:18:56 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 7 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:19:28 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 8 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:20:01 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 9 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:20:33 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 10 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:21:05 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 11 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:21:37 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 12 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:22:10 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 13 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:22:42 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 14 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:23:14 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 15 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:23:47 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 16 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:24:19 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 17 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:24:52 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 18 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:25:24 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 19 loss:0.28797000646591187 norm:nan max memory_allocated 22751.88330078125 
[2025-03-22 04:25:33 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 11 ===
[2025-03-22 04:26:10 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 0 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:26:42 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 1 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:27:15 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 2 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:27:47 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 3 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:28:20 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 4 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:28:52 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 5 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:29:25 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 6 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:29:57 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 7 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:30:30 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 8 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:31:02 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 9 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:31:34 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 10 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:32:07 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 11 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:32:39 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 12 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:33:11 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 13 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:33:44 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 14 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:34:16 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 15 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:34:49 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 16 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:35:21 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 17 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:35:54 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 18 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:36:26 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 19 loss:0.3226938843727112 norm:nan max memory_allocated 22752.05517578125 
[2025-03-22 04:36:35 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 12 ===
[2025-03-22 04:37:11 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 0 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:37:44 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 1 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:38:16 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 2 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:38:48 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 3 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:39:21 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 4 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:39:53 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 5 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:40:26 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 6 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:40:58 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 7 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:41:30 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 8 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:42:02 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 9 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:42:35 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 10 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:43:07 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 11 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:43:39 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 12 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:44:12 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 13 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:44:44 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 14 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:45:17 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 15 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:45:49 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 16 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:46:21 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 17 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:46:54 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 18 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:47:26 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 19 loss:0.36570391058921814 norm:nan max memory_allocated 22752.22705078125 
[2025-03-22 04:47:35 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 13 ===
[2025-03-22 04:48:12 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 0 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:48:44 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 1 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:49:16 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 2 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:49:49 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 3 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:50:21 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 4 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:50:54 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 5 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:51:26 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 6 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:51:59 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 7 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:52:31 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 8 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:53:04 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 9 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:53:36 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 10 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:54:09 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 11 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:54:41 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 12 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:55:14 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 13 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:55:46 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 14 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:56:18 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 15 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:56:51 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 16 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:57:23 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 17 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:57:56 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 18 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:58:28 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 19 loss:0.4134148955345154 norm:nan max memory_allocated 22752.39892578125 
[2025-03-22 04:58:38 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 14 ===
[2025-03-22 04:59:13 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 0 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 04:59:46 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 1 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:00:18 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 2 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:00:50 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 3 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:01:23 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 4 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:01:55 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 5 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:02:27 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 6 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:03:00 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 7 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:03:32 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 8 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:04:04 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 9 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:04:37 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 10 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:05:09 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 11 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:05:42 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 12 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:06:14 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 13 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:06:47 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 14 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:07:19 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 15 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:07:52 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 16 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:08:24 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 17 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:08:56 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 18 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:09:29 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 19 loss:0.48328572511672974 norm:nan max memory_allocated 22752.57080078125 
[2025-03-22 05:09:38 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 15 ===
[2025-03-22 05:10:14 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 0 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:10:47 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 1 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:11:19 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 2 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:11:51 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 3 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:12:24 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 4 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:12:56 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 5 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:13:28 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 6 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:14:01 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 7 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:14:33 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 8 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:15:06 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 9 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:15:38 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 10 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:16:11 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 11 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:16:43 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 12 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:17:15 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 13 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:17:48 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 14 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:18:21 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 15 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:18:53 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 16 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:19:25 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 17 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:19:58 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 18 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:20:30 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 19 loss:0.5572446584701538 norm:nan max memory_allocated 22752.74267578125 
[2025-03-22 05:20:39 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 16 ===
[2025-03-22 05:21:16 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 0 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:21:48 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 1 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:22:20 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 2 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:22:53 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 3 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:23:25 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 4 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:23:58 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 5 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:24:30 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 6 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:25:03 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 7 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:25:35 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 8 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:26:07 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 9 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:26:40 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 10 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:27:12 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 11 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:27:45 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 12 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:28:17 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 13 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:28:49 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 14 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:29:22 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 15 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:29:54 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 16 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:30:26 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 17 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:30:59 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 18 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:31:31 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 19 loss:0.6800334453582764 norm:nan max memory_allocated 22752.91455078125 
[2025-03-22 05:31:40 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 17 ===
[2025-03-22 05:32:16 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 0 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:32:49 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 1 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:33:21 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 2 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:33:54 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 3 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:34:26 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 4 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:34:58 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 5 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:35:31 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 6 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:36:03 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 7 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:36:35 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 8 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:37:08 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 9 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:37:40 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 10 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:38:13 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 11 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:38:45 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 12 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:39:18 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 13 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:39:50 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 14 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:40:23 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 15 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:40:55 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 16 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:41:28 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 17 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:42:00 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 18 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:42:33 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 19 loss:0.8395891785621643 norm:nan max memory_allocated 22753.08642578125 
[2025-03-22 05:42:42 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 18 ===
[2025-03-22 05:43:18 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 0 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:43:50 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 1 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:44:22 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 2 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:44:55 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 3 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:45:27 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 4 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:46:00 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 5 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:46:32 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 6 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:47:05 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 7 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:47:37 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 8 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:48:10 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 9 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:48:42 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 10 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:49:15 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 11 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:49:47 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 12 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:50:20 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 13 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:50:52 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 14 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:51:24 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 15 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:51:57 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 16 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:52:29 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 17 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:53:02 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 18 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:53:34 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 19 loss:1.0098035335540771 norm:nan max memory_allocated 22753.25830078125 
[2025-03-22 05:53:44 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 19 ===
[2025-03-22 05:54:20 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 0 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 05:54:52 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 1 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 05:55:25 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 2 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 05:55:57 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 3 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 05:56:29 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 4 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 05:57:02 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 5 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 05:57:34 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 6 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 05:58:07 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 7 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 05:58:39 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 8 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 05:59:12 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 9 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 05:59:44 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 10 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 06:00:17 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 11 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 06:00:49 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 12 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 06:01:21 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 13 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 06:01:54 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 14 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 06:02:26 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 15 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 06:02:59 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 16 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 06:03:31 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 17 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 06:04:04 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 18 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 06:04:36 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 19 loss:1.2422192096710205 norm:nan max memory_allocated 22753.43017578125 
[2025-03-22 06:04:45 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 20 ===
[2025-03-22 06:05:21 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 0 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:05:54 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 1 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:06:26 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 2 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:06:59 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 3 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:07:31 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 4 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:08:04 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 5 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:08:36 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 6 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:09:08 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 7 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:09:41 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 8 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:10:13 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 9 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:10:45 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 10 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:11:18 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 11 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:11:50 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 12 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:12:23 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 13 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:12:55 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 14 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:13:27 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 15 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:14:00 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 16 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:14:32 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 17 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:15:04 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 18 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:15:37 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 19 loss:1.527004361152649 norm:nan max memory_allocated 22753.60205078125 
[2025-03-22 06:15:46 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 21 ===
[2025-03-22 06:16:22 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 0 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:16:55 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 1 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:17:27 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 2 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:17:59 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 3 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:18:32 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 4 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:19:04 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 5 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:19:37 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 6 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:20:09 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 7 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:20:41 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 8 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:21:14 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 9 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:21:46 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 10 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:22:18 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 11 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:22:51 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 12 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:23:23 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 13 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:23:56 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 14 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:24:28 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 15 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:25:00 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 16 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:25:33 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 17 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:26:05 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 18 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:26:38 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 19 loss:1.852774739265442 norm:nan max memory_allocated 22753.77392578125 
[2025-03-22 06:26:47 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 22 ===
[2025-03-22 06:27:23 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 0 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:27:55 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 1 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:28:28 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 2 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:29:00 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 3 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:29:33 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 4 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:30:05 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 5 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:30:38 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 6 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:31:10 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 7 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:31:43 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 8 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:32:15 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 9 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:32:47 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 10 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:33:20 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 11 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:33:52 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 12 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:34:25 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 13 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:34:57 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 14 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:35:29 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 15 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:36:02 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 16 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:36:34 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 17 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:37:07 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 18 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:37:39 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 19 loss:2.1807522773742676 norm:nan max memory_allocated 22753.94580078125 
[2025-03-22 06:37:49 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 23 ===
[2025-03-22 06:38:25 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 0 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:38:57 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 1 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:39:30 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 2 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:40:02 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 3 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:40:35 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 4 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:41:07 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 5 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:41:40 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 6 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:42:12 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 7 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:42:44 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 8 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:43:17 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 9 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:43:49 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 10 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:44:22 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 11 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:44:54 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 12 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:45:27 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 13 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:45:59 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 14 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:46:32 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 15 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:47:04 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 16 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:47:37 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 17 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:48:09 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 18 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:48:41 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 19 loss:2.6303927898406982 norm:nan max memory_allocated 22754.11767578125 
[2025-03-22 06:48:51 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 24 ===
[2025-03-22 06:49:27 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 0 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:49:59 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 1 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:50:32 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 2 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:51:04 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 3 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:51:37 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 4 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:52:09 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 5 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:52:42 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 6 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:53:14 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 7 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:53:47 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 8 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:54:19 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 9 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:54:52 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 10 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:55:24 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 11 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:55:56 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 12 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:56:29 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 13 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:57:01 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 14 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:57:33 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 15 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:58:06 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 16 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:58:38 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 17 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:59:11 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 18 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:59:43 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 19 loss:3.0328774452209473 norm:nan max memory_allocated 22754.28955078125 
[2025-03-22 06:59:53 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 25 ===
[2025-03-22 07:00:29 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 0 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:01:01 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 1 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:01:34 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 2 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:02:06 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 3 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:02:38 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 4 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:03:11 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 5 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:03:43 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 6 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:04:16 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 7 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:04:48 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 8 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:05:21 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 9 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:05:53 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 10 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:06:26 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 11 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:06:58 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 12 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:07:31 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 13 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:08:03 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 14 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:08:35 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 15 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:09:08 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 16 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:09:40 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 17 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:10:13 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 18 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:10:45 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 19 loss:3.4834654331207275 norm:nan max memory_allocated 22754.46142578125 
[2025-03-22 07:10:55 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 26 ===
[2025-03-22 07:11:31 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 0 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:12:03 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 1 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:12:36 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 2 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:13:08 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 3 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:13:40 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 4 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:14:13 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 5 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:14:45 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 6 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:15:18 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 7 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:15:50 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 8 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:16:23 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 9 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:16:55 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 10 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:17:28 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 11 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:18:00 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 12 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:18:32 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 13 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:19:05 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 14 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:19:37 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 15 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:20:10 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 16 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:20:42 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 17 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:21:14 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 18 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:21:47 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 19 loss:4.005566120147705 norm:nan max memory_allocated 22754.63330078125 
[2025-03-22 07:21:56 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 27 ===
[2025-03-22 07:22:32 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 0 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:23:04 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 1 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:23:37 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 2 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:24:09 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 3 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:24:42 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 4 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:25:14 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 5 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:25:47 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 6 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:26:19 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 7 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:26:52 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 8 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:27:24 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 9 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:27:57 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 10 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:28:29 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 11 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:29:02 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 12 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:29:34 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 13 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:30:07 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 14 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:30:40 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 15 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:31:12 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 16 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:31:45 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 17 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:32:17 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 18 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:32:50 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 19 loss:4.518591403961182 norm:nan max memory_allocated 22754.80517578125 
[2025-03-22 07:32:59 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 28 ===
[2025-03-22 07:33:02 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 07:33:35 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 0 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:34:08 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 1 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:34:40 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 2 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:35:13 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 3 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:35:46 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 4 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:36:18 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 5 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:36:50 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 6 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:37:23 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 7 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:37:56 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 8 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:38:28 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 9 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:39:01 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 10 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:39:34 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 11 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:40:06 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 12 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:40:39 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 13 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:41:11 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 14 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:41:44 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 15 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:42:16 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 16 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:42:49 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 17 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:43:22 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 18 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:43:54 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 19 loss:5.233530044555664 norm:nan max memory_allocated 22754.97705078125 
[2025-03-22 07:44:04 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 29 ===
[2025-03-22 07:44:07 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 07:44:41 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 0 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:45:13 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 1 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:45:46 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 2 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:46:19 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 3 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:46:51 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 4 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:47:24 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 5 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:47:57 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 6 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:48:29 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 7 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:49:02 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 8 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:49:35 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 9 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:50:07 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 10 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:50:40 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 11 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:51:12 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 12 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:51:45 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 13 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:52:18 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 14 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:52:50 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 15 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:53:23 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 16 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:53:56 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 17 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:54:28 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 18 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:55:01 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 19 loss:6.182106971740723 norm:nan max memory_allocated 22755.14892578125 
[2025-03-22 07:55:10 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 30 ===
[2025-03-22 07:55:13 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 07:55:46 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 0 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 07:56:19 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 1 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 07:56:52 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 2 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 07:57:24 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 3 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 07:57:57 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 4 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 07:58:29 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 5 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 07:59:02 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 6 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 07:59:34 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 7 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:00:07 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 8 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:00:40 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 9 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:01:12 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 10 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:01:45 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 11 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:02:18 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 12 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:02:50 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 13 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:03:23 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 14 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:03:55 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 15 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:04:27 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 16 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:05:00 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 17 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:05:32 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 18 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:06:05 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 19 loss:7.840509414672852 norm:nan max memory_allocated 22755.32080078125 
[2025-03-22 08:06:14 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 31 ===
[2025-03-22 08:06:17 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 08:06:50 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 0 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:07:23 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 1 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:07:56 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 2 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:08:28 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 3 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:09:01 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 4 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:09:34 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 5 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:10:07 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 6 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:10:39 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 7 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:11:12 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 8 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:11:45 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 9 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:12:17 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 10 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:12:50 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 11 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:13:23 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 12 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:13:56 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 13 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:14:29 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 14 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:15:01 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 15 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:15:34 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 16 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:16:07 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 17 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:16:40 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 18 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:17:13 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 19 loss:17.839670181274414 norm:nan max memory_allocated 22755.49267578125 
[2025-03-22 08:17:23 root] (main_calibration_a2.py 372): INFO 21225.796429395676
[2025-03-22 08:17:36 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-22 08:18:46 root] (main_calibration_a2.py 158): INFO wikitext2 : 21.340852737426758
[2025-03-22 08:18:46 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-22 08:20:34 root] (main_calibration_a2.py 158): INFO c4 : 27.232545852661133
[2025-03-22 09:59:28 root] (main_calibration_a2.py 169): INFO {'wikitext2': 21.340852737426758, 'c4': 27.232545852661133, 'results': {'arc_easy': {'acc': 0.4364478114478115, 'acc_stderr': 0.010176569980111044, 'acc_norm': 0.3859427609427609, 'acc_norm_stderr': 0.009989277329503951}, 'piqa': {'acc': 0.6463547334058759, 'acc_stderr': 0.011154877708188671, 'acc_norm': 0.6420021762785637, 'acc_norm_stderr': 0.011185460416617296}, 'arc_challenge': {'acc': 0.25170648464163825, 'acc_stderr': 0.012682496334042963, 'acc_norm': 0.30802047781569963, 'acc_norm_stderr': 0.013491429517292038}, 'boolq': {'acc': 0.5880733944954128, 'acc_stderr': 0.008608316516029644}, 'hellaswag': {'acc': 0.3710416251742681, 'acc_stderr': 0.004820962855749734, 'acc_norm': 0.4778928500298745, 'acc_norm_stderr': 0.0049849017528463945}, 'winogrande': {'acc': 0.5035516969218626, 'acc_stderr': 0.01405213114691586}}, 'versions': {'arc_easy': 0, 'piqa': 0, 'arc_challenge': 0, 'boolq': 1, 'hellaswag': 0, 'winogrande': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
[2025-03-22 09:59:28 root] (main_calibration_a2.py 172): INFO 25.17,43.64,58.81,37.10,64.64,50.36
