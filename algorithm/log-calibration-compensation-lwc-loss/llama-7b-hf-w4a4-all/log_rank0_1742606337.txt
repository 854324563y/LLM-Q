[2025-03-22 01:18:57 root] (main_calibration_a2.py 274): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-calibration-compensation-lwc-loss/llama-7b-hf-w4a4-all', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, scale_calibration=True, compensation_calibration=True, rank=1, loss_type='all')
[2025-03-22 01:22:58 root] (main_calibration_a2.py 341): INFO === start quantization ===
[2025-03-22 01:22:58 root] (main_calibration_a2.py 347): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-22 01:22:58 root] (abq_llm_calibration_a2.py 62): INFO Starting ...
[2025-03-22 01:23:01 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 0 ===
[2025-03-22 01:23:05 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:23:38 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 0 loss:0.06943751126527786 norm:0.041762158274650574 max memory_allocated 22719.10693359375 
[2025-03-22 01:24:12 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 1 loss:0.04491109400987625 norm:0.02130313590168953 max memory_allocated 22719.10693359375 
[2025-03-22 01:24:46 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 2 loss:0.036851316690444946 norm:0.016264745965600014 max memory_allocated 22719.10693359375 
[2025-03-22 01:25:20 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 3 loss:0.03345769643783569 norm:0.01427533384412527 max memory_allocated 22719.10693359375 
[2025-03-22 01:25:54 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 4 loss:0.031851876527071 norm:0.012314675375819206 max memory_allocated 22719.10693359375 
[2025-03-22 01:26:27 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 5 loss:0.0307584498077631 norm:0.010657336562871933 max memory_allocated 22719.10693359375 
[2025-03-22 01:27:01 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 6 loss:0.029957376420497894 norm:0.009182295762002468 max memory_allocated 22719.10693359375 
[2025-03-22 01:27:35 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 7 loss:0.029572822153568268 norm:0.008040153421461582 max memory_allocated 22719.10693359375 
[2025-03-22 01:28:09 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 8 loss:0.029331330209970474 norm:0.007063419558107853 max memory_allocated 22719.10693359375 
[2025-03-22 01:28:43 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 9 loss:0.02900254726409912 norm:0.006129042245447636 max memory_allocated 22719.10693359375 
[2025-03-22 01:29:16 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 10 loss:0.028883080929517746 norm:0.005505513399839401 max memory_allocated 22719.10693359375 
[2025-03-22 01:29:50 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 11 loss:0.028791021555662155 norm:0.004881266504526138 max memory_allocated 22719.10693359375 
[2025-03-22 01:30:24 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 12 loss:0.028523972257971764 norm:0.004418819211423397 max memory_allocated 22719.10693359375 
[2025-03-22 01:30:58 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 13 loss:0.028549592941999435 norm:0.004147158470004797 max memory_allocated 22719.10693359375 
[2025-03-22 01:31:32 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 14 loss:0.028454769402742386 norm:0.003940406255424023 max memory_allocated 22719.10693359375 
[2025-03-22 01:32:05 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 15 loss:0.02840692177414894 norm:0.0036971711087971926 max memory_allocated 22719.10693359375 
[2025-03-22 01:32:39 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 16 loss:0.028342822566628456 norm:0.0035777282901108265 max memory_allocated 22719.10693359375 
[2025-03-22 01:33:13 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 17 loss:0.028353096917271614 norm:0.0033282171934843063 max memory_allocated 22719.10693359375 
[2025-03-22 01:33:47 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 18 loss:0.028264328837394714 norm:0.0032498259097337723 max memory_allocated 22719.10693359375 
[2025-03-22 01:34:20 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 19 loss:0.028197532519698143 norm:0.003219687845557928 max memory_allocated 22719.10693359375 
[2025-03-22 01:34:30 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 1 ===
[2025-03-22 01:34:33 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:35:06 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 0 loss:0.24772891402244568 norm:0.13142523169517517 max memory_allocated 22719.27880859375 
[2025-03-22 01:35:40 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 1 loss:0.14232484996318817 norm:0.04069852456450462 max memory_allocated 22719.27880859375 
[2025-03-22 01:36:14 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 2 loss:0.10755010694265366 norm:0.019693534821271896 max memory_allocated 22719.27880859375 
[2025-03-22 01:36:48 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 3 loss:0.09365551173686981 norm:0.016724424436688423 max memory_allocated 22719.27880859375 
[2025-03-22 01:37:22 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 4 loss:0.08658867329359055 norm:0.014664679765701294 max memory_allocated 22719.27880859375 
[2025-03-22 01:37:55 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 5 loss:0.08221474289894104 norm:0.01290217600762844 max memory_allocated 22719.27880859375 
[2025-03-22 01:38:29 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 6 loss:0.07963287830352783 norm:0.011448659002780914 max memory_allocated 22719.27880859375 
[2025-03-22 01:39:03 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 7 loss:0.07783735543489456 norm:0.010167377069592476 max memory_allocated 22719.27880859375 
[2025-03-22 01:39:37 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 8 loss:0.07646489143371582 norm:0.009137551300227642 max memory_allocated 22719.27880859375 
[2025-03-22 01:40:11 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 9 loss:0.07539564371109009 norm:0.008466490544378757 max memory_allocated 22719.27880859375 
[2025-03-22 01:40:45 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 10 loss:0.07466971129179001 norm:0.007803558837622404 max memory_allocated 22719.27880859375 
[2025-03-22 01:41:18 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 11 loss:0.07410067319869995 norm:0.006970346439629793 max memory_allocated 22719.27880859375 
[2025-03-22 01:41:52 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 12 loss:0.07366733253002167 norm:0.006478810682892799 max memory_allocated 22719.27880859375 
[2025-03-22 01:42:26 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 13 loss:0.07330899685621262 norm:0.006105155684053898 max memory_allocated 22719.27880859375 
[2025-03-22 01:43:00 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 14 loss:0.07308854162693024 norm:0.005765778012573719 max memory_allocated 22719.27880859375 
[2025-03-22 01:43:34 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 15 loss:0.07280586659908295 norm:0.005384034477174282 max memory_allocated 22719.27880859375 
[2025-03-22 01:44:08 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 16 loss:0.07260698080062866 norm:0.005231363233178854 max memory_allocated 22719.27880859375 
[2025-03-22 01:44:42 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 17 loss:0.07244816422462463 norm:0.005072183907032013 max memory_allocated 22719.27880859375 
[2025-03-22 01:45:16 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 18 loss:0.07229726016521454 norm:0.004905572161078453 max memory_allocated 22719.27880859375 
[2025-03-22 01:45:49 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 19 loss:0.07220952212810516 norm:0.004828757606446743 max memory_allocated 22719.27880859375 
[2025-03-22 01:45:59 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 2 ===
[2025-03-22 01:46:02 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:46:35 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 0 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:47:08 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 1 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:47:41 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 2 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:48:13 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 3 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:48:46 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 4 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:49:19 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 5 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:49:52 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 6 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:50:24 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 7 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:50:57 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 8 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:51:30 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 9 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:52:03 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 10 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:52:35 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 11 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:53:08 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 12 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:53:41 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 13 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:54:14 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 14 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:54:47 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 15 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:55:19 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 16 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:55:52 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 17 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:56:25 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 18 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:56:58 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 19 loss:0.31553909182548523 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:57:07 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 3 ===
[2025-03-22 01:57:43 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 0 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:58:16 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 1 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:58:49 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 2 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:59:21 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 3 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 01:59:54 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 4 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:00:27 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 5 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:00:59 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 6 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:01:32 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 7 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:02:05 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 8 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:02:37 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 9 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:03:10 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 10 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:03:43 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 11 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:04:15 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 12 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:04:48 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 13 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:05:21 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 14 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:05:53 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 15 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:06:26 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 16 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:06:58 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 17 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:07:31 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 18 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:08:04 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 19 loss:0.3849237859249115 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:08:13 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 4 ===
[2025-03-22 02:08:49 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 0 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:09:22 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 1 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:09:55 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 2 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:10:28 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 3 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:11:00 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 4 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:11:33 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 5 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:12:06 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 6 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:12:39 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 7 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:13:11 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 8 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:13:44 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 9 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:14:17 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 10 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:14:49 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 11 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:15:22 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 12 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:15:55 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 13 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:16:28 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 14 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:17:00 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 15 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:17:33 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 16 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:18:06 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 17 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:18:38 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 18 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:19:11 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 19 loss:0.519957423210144 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:19:20 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 5 ===
[2025-03-22 02:19:57 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 0 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:20:30 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 1 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:21:02 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 2 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:21:35 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 3 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:22:08 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 4 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:22:41 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 5 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:23:13 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 6 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:23:46 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 7 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:24:19 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 8 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:24:51 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 9 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:25:24 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 10 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:25:57 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 11 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:26:30 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 12 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:27:02 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 13 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:27:35 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 14 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:28:08 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 15 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:28:41 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 16 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:29:13 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 17 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:29:46 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 18 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:30:19 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 19 loss:0.6422828435897827 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:30:28 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 6 ===
[2025-03-22 02:31:05 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 0 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:31:37 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 1 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:32:10 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 2 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:32:43 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 3 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:33:16 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 4 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:33:48 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 5 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:34:21 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 6 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:34:54 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 7 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:35:27 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 8 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:36:00 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 9 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:36:32 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 10 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:37:05 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 11 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:37:38 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 12 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:38:11 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 13 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:38:43 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 14 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:39:16 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 15 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:39:49 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 16 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:40:22 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 17 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:40:54 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 18 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:41:27 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 19 loss:0.7149540781974792 norm:nan max memory_allocated 22719.27880859375 
[2025-03-22 02:41:36 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 7 ===
[2025-03-22 02:42:13 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 0 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:42:46 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 1 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:43:19 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 2 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:43:51 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 3 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:44:24 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 4 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:44:57 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 5 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:45:30 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 6 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:46:02 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 7 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:46:35 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 8 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:47:08 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 9 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:47:41 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 10 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:48:13 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 11 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:48:46 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 12 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:49:19 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 13 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:49:52 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 14 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:50:25 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 15 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:50:57 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 16 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:51:30 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 17 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:52:03 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 18 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:52:36 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 19 loss:0.7848606109619141 norm:nan max memory_allocated 22719.36865234375 
[2025-03-22 02:52:45 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 8 ===
[2025-03-22 02:53:21 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 0 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:53:54 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 1 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:54:27 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 2 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:55:00 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 3 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:55:33 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 4 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:56:05 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 5 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:56:38 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 6 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:57:11 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 7 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:57:44 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 8 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:58:16 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 9 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:58:49 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 10 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:59:22 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 11 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 02:59:55 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 12 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 03:00:27 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 13 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 03:01:00 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 14 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 03:01:33 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 15 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 03:02:06 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 16 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 03:02:39 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 17 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 03:03:11 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 18 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 03:03:44 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 19 loss:0.8373695015907288 norm:nan max memory_allocated 22719.54052734375 
[2025-03-22 03:03:53 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 9 ===
[2025-03-22 03:04:30 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 0 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:05:03 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 1 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:05:35 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 2 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:06:08 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 3 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:06:41 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 4 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:07:14 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 5 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:07:46 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 6 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:08:19 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 7 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:08:52 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 8 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:09:25 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 9 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:09:57 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 10 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:10:30 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 11 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:11:03 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 12 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:11:36 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 13 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:12:09 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 14 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:12:41 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 15 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:13:14 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 16 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:13:47 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 17 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:14:20 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 18 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:14:52 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 19 loss:0.9320574402809143 norm:nan max memory_allocated 22719.71240234375 
[2025-03-22 03:15:02 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 10 ===
[2025-03-22 03:15:39 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 0 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:16:11 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 1 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:16:44 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 2 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:17:17 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 3 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:17:50 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 4 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:18:22 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 5 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:18:55 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 6 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:19:28 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 7 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:20:01 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 8 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:20:34 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 9 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:21:06 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 10 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:21:39 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 11 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:22:12 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 12 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:22:45 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 13 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:23:17 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 14 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:23:50 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 15 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:24:23 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 16 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:24:56 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 17 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:25:28 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 18 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:26:01 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 19 loss:0.9664953947067261 norm:nan max memory_allocated 22719.88427734375 
[2025-03-22 03:26:11 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 11 ===
[2025-03-22 03:26:47 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 0 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:27:20 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 1 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:27:53 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 2 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:28:25 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 3 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:28:58 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 4 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:29:31 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 5 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:30:04 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 6 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:30:37 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 7 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:31:09 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 8 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:31:42 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 9 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:32:15 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 10 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:32:48 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 11 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:33:20 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 12 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:33:53 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 13 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:34:26 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 14 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:34:59 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 15 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:35:31 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 16 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:36:04 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 17 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:36:37 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 18 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:37:10 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 19 loss:1.0027382373809814 norm:nan max memory_allocated 22720.05615234375 
[2025-03-22 03:37:19 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 12 ===
[2025-03-22 03:37:56 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 0 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:38:28 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 1 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:39:01 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 2 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:39:34 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 3 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:40:07 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 4 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:40:39 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 5 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:41:12 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 6 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:41:45 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 7 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:42:18 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 8 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:42:51 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 9 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:43:23 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 10 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:43:56 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 11 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:44:29 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 12 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:45:02 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 13 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:45:34 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 14 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:46:07 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 15 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:46:40 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 16 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:47:13 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 17 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:47:45 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 18 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:48:18 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 19 loss:1.0241179466247559 norm:nan max memory_allocated 22720.22802734375 
[2025-03-22 03:48:27 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 13 ===
[2025-03-22 03:49:04 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 0 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:49:37 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 1 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:50:10 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 2 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:50:42 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 3 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:51:15 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 4 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:51:48 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 5 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:52:21 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 6 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:52:53 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 7 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:53:26 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 8 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:53:59 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 9 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:54:32 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 10 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:55:04 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 11 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:55:37 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 12 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:56:10 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 13 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:56:43 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 14 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:57:16 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 15 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:57:48 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 16 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:58:21 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 17 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:58:54 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 18 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:59:27 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 19 loss:1.051262378692627 norm:nan max memory_allocated 22720.39990234375 
[2025-03-22 03:59:36 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 14 ===
[2025-03-22 04:00:12 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 0 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:00:45 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 1 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:01:18 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 2 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:01:51 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 3 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:02:23 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 4 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:02:56 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 5 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:03:29 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 6 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:04:02 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 7 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:04:35 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 8 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:05:07 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 9 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:05:40 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 10 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:06:13 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 11 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:06:45 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 12 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:07:18 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 13 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:07:51 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 14 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:08:24 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 15 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:08:56 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 16 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:09:29 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 17 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:10:02 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 18 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:10:35 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 19 loss:1.1244715452194214 norm:nan max memory_allocated 22720.57177734375 
[2025-03-22 04:10:44 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 15 ===
[2025-03-22 04:11:21 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 0 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:11:53 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 1 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:12:26 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 2 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:12:59 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 3 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:13:32 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 4 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:14:04 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 5 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:14:37 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 6 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:15:10 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 7 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:15:43 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 8 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:16:15 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 9 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:16:48 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 10 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:17:21 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 11 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:17:54 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 12 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:18:26 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 13 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:18:59 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 14 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:19:32 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 15 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:20:05 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 16 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:20:37 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 17 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:21:10 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 18 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:21:43 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 19 loss:1.142195463180542 norm:nan max memory_allocated 22720.74365234375 
[2025-03-22 04:21:52 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 16 ===
[2025-03-22 04:22:29 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 0 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:23:02 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 1 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:23:34 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 2 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:24:07 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 3 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:24:40 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 4 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:25:13 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 5 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:25:45 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 6 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:26:18 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 7 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:26:51 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 8 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:27:24 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 9 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:27:56 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 10 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:28:29 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 11 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:29:02 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 12 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:29:35 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 13 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:30:07 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 14 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:30:40 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 15 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:31:13 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 16 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:31:46 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 17 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:32:18 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 18 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:32:51 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 19 loss:1.2506446838378906 norm:nan max memory_allocated 22720.91552734375 
[2025-03-22 04:33:00 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 17 ===
[2025-03-22 04:33:37 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 0 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:34:10 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 1 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:34:42 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 2 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:35:15 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 3 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:35:48 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 4 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:36:21 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 5 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:36:53 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 6 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:37:26 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 7 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:37:59 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 8 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:38:32 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 9 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:39:04 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 10 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:39:37 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 11 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:40:10 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 12 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:40:43 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 13 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:41:15 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 14 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:41:48 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 15 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:42:21 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 16 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:42:54 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 17 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:43:26 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 18 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:43:59 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 19 loss:1.3799337148666382 norm:nan max memory_allocated 22721.08740234375 
[2025-03-22 04:44:09 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 18 ===
[2025-03-22 04:44:45 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 0 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:45:18 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 1 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:45:51 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 2 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:46:24 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 3 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:46:56 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 4 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:47:29 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 5 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:48:02 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 6 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:48:35 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 7 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:49:07 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 8 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:49:40 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 9 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:50:13 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 10 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:50:46 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 11 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:51:19 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 12 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:51:51 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 13 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:52:24 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 14 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:52:57 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 15 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:53:30 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 16 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:54:02 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 17 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:54:35 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 18 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:55:08 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 19 loss:1.4989280700683594 norm:nan max memory_allocated 22721.25927734375 
[2025-03-22 04:55:17 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 19 ===
[2025-03-22 04:55:54 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 0 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 04:56:26 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 1 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 04:56:59 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 2 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 04:57:32 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 3 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 04:58:05 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 4 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 04:58:37 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 5 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 04:59:10 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 6 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 04:59:43 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 7 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:00:16 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 8 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:00:48 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 9 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:01:21 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 10 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:01:54 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 11 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:02:27 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 12 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:02:59 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 13 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:03:32 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 14 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:04:05 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 15 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:04:38 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 16 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:05:10 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 17 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:05:43 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 18 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:06:16 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 19 loss:1.699402928352356 norm:nan max memory_allocated 22721.43115234375 
[2025-03-22 05:06:25 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 20 ===
[2025-03-22 05:07:01 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 0 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:07:34 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 1 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:08:07 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 2 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:08:40 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 3 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:09:12 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 4 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:09:45 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 5 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:10:18 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 6 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:10:51 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 7 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:11:23 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 8 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:11:56 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 9 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:12:29 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 10 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:13:02 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 11 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:13:34 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 12 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:14:07 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 13 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:14:40 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 14 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:15:12 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 15 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:15:45 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 16 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:16:18 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 17 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:16:51 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 18 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:17:23 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 19 loss:1.9685602188110352 norm:nan max memory_allocated 22721.60302734375 
[2025-03-22 05:17:33 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 21 ===
[2025-03-22 05:18:09 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 0 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:18:42 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 1 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:19:15 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 2 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:19:47 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 3 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:20:20 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 4 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:20:53 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 5 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:21:26 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 6 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:21:59 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 7 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:22:31 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 8 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:23:04 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 9 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:23:37 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 10 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:24:09 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 11 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:24:42 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 12 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:25:15 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 13 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:25:48 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 14 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:26:20 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 15 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:26:53 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 16 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:27:26 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 17 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:27:59 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 18 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:28:31 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 19 loss:2.266836404800415 norm:nan max memory_allocated 22721.77490234375 
[2025-03-22 05:28:41 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 22 ===
[2025-03-22 05:29:17 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 0 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:29:50 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 1 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:30:23 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 2 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:30:55 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 3 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:31:28 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 4 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:32:01 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 5 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:32:34 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 6 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:33:06 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 7 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:33:39 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 8 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:34:12 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 9 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:34:45 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 10 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:35:17 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 11 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:35:50 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 12 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:36:23 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 13 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:36:56 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 14 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:37:28 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 15 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:38:01 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 16 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:38:34 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 17 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:39:07 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 18 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:39:39 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 19 loss:2.5920214653015137 norm:nan max memory_allocated 22721.94677734375 
[2025-03-22 05:39:49 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 23 ===
[2025-03-22 05:40:25 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 0 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:40:58 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 1 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:41:31 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 2 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:42:03 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 3 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:42:36 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 4 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:43:09 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 5 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:43:42 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 6 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:44:14 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 7 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:44:47 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 8 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:45:20 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 9 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:45:53 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 10 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:46:25 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 11 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:46:58 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 12 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:47:31 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 13 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:48:04 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 14 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:48:36 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 15 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:49:09 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 16 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:49:42 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 17 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:50:15 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 18 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:50:47 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 19 loss:3.0214831829071045 norm:nan max memory_allocated 22722.11865234375 
[2025-03-22 05:50:57 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 24 ===
[2025-03-22 05:51:33 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 0 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:52:06 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 1 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:52:38 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 2 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:53:11 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 3 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:53:44 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 4 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:54:17 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 5 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:54:49 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 6 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:55:22 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 7 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:55:55 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 8 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:56:28 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 9 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:57:00 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 10 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:57:33 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 11 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:58:06 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 12 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:58:39 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 13 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:59:11 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 14 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 05:59:44 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 15 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 06:00:17 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 16 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 06:00:50 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 17 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 06:01:22 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 18 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 06:01:55 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 19 loss:3.419365644454956 norm:nan max memory_allocated 22722.29052734375 
[2025-03-22 06:02:04 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 25 ===
[2025-03-22 06:02:41 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 0 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:03:14 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 1 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:03:46 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 2 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:04:19 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 3 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:04:52 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 4 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:05:25 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 5 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:05:57 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 6 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:06:30 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 7 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:07:03 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 8 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:07:36 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 9 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:08:09 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 10 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:08:41 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 11 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:09:14 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 12 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:09:47 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 13 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:10:19 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 14 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:10:52 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 15 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:11:25 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 16 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:11:58 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 17 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:12:31 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 18 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:13:03 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 19 loss:3.876840114593506 norm:nan max memory_allocated 22722.46240234375 
[2025-03-22 06:13:13 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 26 ===
[2025-03-22 06:13:49 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 0 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:14:22 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 1 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:14:55 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 2 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:15:27 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 3 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:16:00 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 4 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:16:33 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 5 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:17:06 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 6 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:17:38 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 7 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:18:11 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 8 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:18:44 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 9 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:19:17 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 10 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:19:49 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 11 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:20:22 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 12 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:20:55 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 13 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:21:28 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 14 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:22:00 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 15 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:22:33 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 16 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:23:06 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 17 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:23:39 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 18 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:24:11 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 19 loss:4.41290807723999 norm:nan max memory_allocated 22722.63427734375 
[2025-03-22 06:24:21 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 27 ===
[2025-03-22 06:24:57 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 0 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:25:30 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 1 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:26:03 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 2 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:26:35 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 3 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:27:08 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 4 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:27:41 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 5 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:28:14 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 6 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:28:46 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 7 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:29:19 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 8 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:29:52 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 9 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:30:25 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 10 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:30:57 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 11 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:31:30 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 12 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:32:03 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 13 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:32:36 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 14 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:33:09 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 15 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:33:41 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 16 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:34:14 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 17 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:34:47 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 18 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:35:20 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 19 loss:4.937484264373779 norm:nan max memory_allocated 22722.80615234375 
[2025-03-22 06:35:29 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 28 ===
[2025-03-22 06:35:32 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:36:05 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 0 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:36:38 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 1 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:37:11 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 2 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:37:44 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 3 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:38:17 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 4 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:38:50 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 5 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:39:23 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 6 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:39:56 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 7 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:40:29 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 8 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:41:01 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 9 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:41:34 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 10 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:42:07 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 11 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:42:40 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 12 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:43:13 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 13 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:43:46 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 14 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:44:19 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 15 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:44:52 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 16 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:45:25 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 17 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:45:58 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 18 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:46:30 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 19 loss:5.655698299407959 norm:nan max memory_allocated 22722.97802734375 
[2025-03-22 06:46:40 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 29 ===
[2025-03-22 06:46:43 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:47:16 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 0 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:47:49 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 1 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:48:22 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 2 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:48:55 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 3 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:49:28 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 4 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:50:01 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 5 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:50:34 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 6 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:51:07 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 7 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:51:40 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 8 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:52:13 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 9 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:52:45 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 10 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:53:18 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 11 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:53:51 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 12 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:54:24 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 13 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:54:57 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 14 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:55:30 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 15 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:56:03 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 16 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:56:36 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 17 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:57:09 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 18 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:57:42 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 19 loss:6.621808052062988 norm:nan max memory_allocated 22723.14990234375 
[2025-03-22 06:57:51 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 30 ===
[2025-03-22 06:57:54 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:58:28 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 0 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 06:59:00 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 1 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 06:59:33 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 2 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:00:06 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 3 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:00:39 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 4 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:01:12 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 5 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:01:45 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 6 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:02:18 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 7 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:02:51 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 8 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:03:24 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 9 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:03:57 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 10 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:04:30 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 11 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:05:02 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 12 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:05:35 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 13 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:06:08 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 14 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:06:41 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 15 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:07:14 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 16 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:07:47 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 17 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:08:20 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 18 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:08:53 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 19 loss:8.402563095092773 norm:nan max memory_allocated 22723.32177734375 
[2025-03-22 07:09:02 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 31 ===
[2025-03-22 07:09:05 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 07:09:39 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 0 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:10:12 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 1 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:10:45 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 2 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:11:18 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 3 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:11:51 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 4 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:12:25 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 5 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:12:58 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 6 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:13:31 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 7 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:14:04 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 8 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:14:37 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 9 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:15:10 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 10 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:15:43 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 11 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:16:16 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 12 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:16:50 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 13 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:17:23 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 14 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:17:56 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 15 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:18:29 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 16 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:19:02 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 17 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:19:36 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 18 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:20:09 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 19 loss:18.56317901611328 norm:nan max memory_allocated 22723.49365234375 
[2025-03-22 07:20:19 root] (main_calibration_a2.py 370): INFO 21440.814054965973
[2025-03-22 07:20:32 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-22 07:21:44 root] (main_calibration_a2.py 158): INFO wikitext2 : 21.914518356323242
[2025-03-22 07:21:44 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-22 07:23:33 root] (main_calibration_a2.py 158): INFO c4 : 27.29588508605957
[2025-03-22 09:03:15 root] (main_calibration_a2.py 169): INFO {'wikitext2': 21.914518356323242, 'c4': 27.29588508605957, 'results': {'piqa': {'acc': 0.6213275299238302, 'acc_stderr': 0.011317163404516847, 'acc_norm': 0.6256800870511425, 'acc_norm_stderr': 0.01129127680119499}, 'boolq': {'acc': 0.5801223241590214, 'acc_stderr': 0.008632045504781754}, 'arc_easy': {'acc': 0.41624579124579125, 'acc_stderr': 0.010114819404500878, 'acc_norm': 0.37542087542087543, 'acc_norm_stderr': 0.009936218527114307}, 'hellaswag': {'acc': 0.36735710017924716, 'acc_stderr': 0.004810996652324735, 'acc_norm': 0.4682334196375224, 'acc_norm_stderr': 0.004979700695747951}, 'winogrande': {'acc': 0.5043409629044988, 'acc_stderr': 0.014051956064076896}, 'arc_challenge': {'acc': 0.2593856655290102, 'acc_stderr': 0.012808273573927106, 'acc_norm': 0.2935153583617747, 'acc_norm_stderr': 0.013307250444941118}}, 'versions': {'piqa': 0, 'boolq': 1, 'arc_easy': 0, 'hellaswag': 0, 'winogrande': 0, 'arc_challenge': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
[2025-03-22 09:03:15 root] (main_calibration_a2.py 172): INFO 25.94,41.62,58.01,36.74,62.13,50.43
