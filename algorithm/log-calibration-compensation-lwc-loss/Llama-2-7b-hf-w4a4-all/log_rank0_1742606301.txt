[2025-03-22 01:18:21 root] (main_calibration_a2.py 274): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-calibration-compensation-lwc-loss/Llama-2-7b-hf-w4a4-all', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, scale_calibration=True, compensation_calibration=True, rank=1, loss_type='all')
[2025-03-22 01:21:13 root] (main_calibration_a2.py 341): INFO === start quantization ===
[2025-03-22 01:21:13 root] (main_calibration_a2.py 347): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-22 01:21:13 root] (abq_llm_calibration_a2.py 62): INFO Starting ...
[2025-03-22 01:21:16 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 0 ===
[2025-03-22 01:21:20 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:21:53 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 0 loss:0.056586213409900665 norm:0.04852999001741409 max memory_allocated 22722.10693359375 
[2025-03-22 01:22:27 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 1 loss:0.032382506877183914 norm:0.023833956569433212 max memory_allocated 22722.10693359375 
[2025-03-22 01:23:00 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 2 loss:0.02511078491806984 norm:0.017480025067925453 max memory_allocated 22722.10693359375 
[2025-03-22 01:23:34 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 3 loss:0.02242877706885338 norm:0.0156006570905447 max memory_allocated 22722.10693359375 
[2025-03-22 01:24:08 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 4 loss:0.02101660892367363 norm:0.013515413738787174 max memory_allocated 22722.10693359375 
[2025-03-22 01:24:41 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 5 loss:0.02018037438392639 norm:0.013002011924982071 max memory_allocated 22722.10693359375 
[2025-03-22 01:25:15 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 6 loss:0.019854631274938583 norm:0.010030122473835945 max memory_allocated 22722.10693359375 
[2025-03-22 01:25:48 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 7 loss:0.01966404914855957 norm:0.008590612560510635 max memory_allocated 22722.10693359375 
[2025-03-22 01:26:22 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 8 loss:0.019298208877444267 norm:0.00729016400873661 max memory_allocated 22722.10693359375 
[2025-03-22 01:26:55 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 9 loss:0.01907772198319435 norm:0.0067197601310908794 max memory_allocated 22722.10693359375 
[2025-03-22 01:27:28 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 10 loss:0.01888306438922882 norm:0.006062248256057501 max memory_allocated 22722.10693359375 
[2025-03-22 01:28:01 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 11 loss:0.018820736557245255 norm:0.005836690776050091 max memory_allocated 22722.10693359375 
[2025-03-22 01:28:35 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 12 loss:0.018842153251171112 norm:0.0058697061613202095 max memory_allocated 22722.10693359375 
[2025-03-22 01:29:08 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 13 loss:0.01887562870979309 norm:0.005426203366369009 max memory_allocated 22722.10693359375 
[2025-03-22 01:29:41 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 14 loss:0.018866846337914467 norm:0.004841720685362816 max memory_allocated 22722.10693359375 
[2025-03-22 01:30:15 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 15 loss:0.018768930807709694 norm:0.004454529378563166 max memory_allocated 22722.10693359375 
[2025-03-22 01:30:48 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 16 loss:0.018736721947789192 norm:0.004357798025012016 max memory_allocated 22722.10693359375 
[2025-03-22 01:31:22 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 17 loss:0.018723171204328537 norm:0.004316725302487612 max memory_allocated 22722.10693359375 
[2025-03-22 01:31:55 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 18 loss:0.018506890162825584 norm:0.0038993777707219124 max memory_allocated 22722.10693359375 
[2025-03-22 01:32:28 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 19 loss:0.018570363521575928 norm:0.0036964991595596075 max memory_allocated 22722.10693359375 
[2025-03-22 01:32:37 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 1 ===
[2025-03-22 01:32:40 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:33:13 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 0 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:33:46 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 1 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:34:18 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 2 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:34:50 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 3 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:35:22 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 4 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:35:55 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 5 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:36:27 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 6 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:36:59 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 7 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:37:31 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 8 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:38:04 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 9 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:38:36 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 10 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:39:08 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 11 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:39:40 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 12 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:40:12 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 13 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:40:45 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 14 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:41:17 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 15 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:41:49 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 16 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:42:21 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 17 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:42:54 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 18 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:43:26 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 19 loss:0.41353103518486023 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:43:35 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 2 ===
[2025-03-22 01:43:38 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:44:11 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 0 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:44:43 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 1 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:45:16 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 2 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:45:48 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 3 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:46:21 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 4 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:46:53 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 5 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:47:25 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 6 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:47:58 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 7 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:48:30 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 8 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:49:03 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 9 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:49:35 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 10 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:50:07 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 11 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:50:40 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 12 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:51:12 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 13 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:51:44 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 14 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:52:17 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 15 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:52:49 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 16 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:53:22 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 17 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:53:54 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 18 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:54:26 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 19 loss:0.5938748121261597 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:54:35 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 3 ===
[2025-03-22 01:55:12 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 0 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:55:44 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 1 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:56:16 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 2 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:56:49 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 3 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:57:21 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 4 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:57:53 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 5 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:58:25 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 6 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:58:58 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 7 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 01:59:30 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 8 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:00:02 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 9 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:00:35 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 10 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:01:07 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 11 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:01:39 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 12 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:02:12 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 13 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:02:44 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 14 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:03:16 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 15 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:03:48 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 16 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:04:21 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 17 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:04:53 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 18 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:05:25 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 19 loss:0.6443170309066772 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:05:34 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 4 ===
[2025-03-22 02:06:10 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 0 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:06:43 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 1 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:07:15 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 2 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:07:47 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 3 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:08:20 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 4 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:08:52 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 5 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:09:24 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 6 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:09:57 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 7 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:10:29 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 8 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:11:01 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 9 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:11:34 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 10 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:12:06 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 11 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:12:38 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 12 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:13:11 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 13 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:13:43 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 14 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:14:15 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 15 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:14:47 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 16 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:15:20 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 17 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:15:52 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 18 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:16:24 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 19 loss:0.7860963940620422 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:16:33 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 5 ===
[2025-03-22 02:17:10 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 0 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:17:42 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 1 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:18:14 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 2 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:18:47 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 3 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:19:19 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 4 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:19:51 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 5 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:20:24 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 6 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:20:56 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 7 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:21:28 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 8 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:22:01 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 9 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:22:33 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 10 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:23:05 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 11 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:23:38 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 12 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:24:10 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 13 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:24:42 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 14 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:25:15 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 15 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:25:47 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 16 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:26:19 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 17 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:26:52 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 18 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:27:24 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 19 loss:0.8500640988349915 norm:nan max memory_allocated 22722.10693359375 
[2025-03-22 02:27:33 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 6 ===
[2025-03-22 02:28:09 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 0 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:28:42 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 1 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:29:14 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 2 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:29:46 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 3 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:30:19 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 4 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:30:51 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 5 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:31:24 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 6 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:31:56 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 7 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:32:28 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 8 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:33:01 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 9 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:33:33 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 10 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:34:05 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 11 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:34:38 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 12 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:35:10 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 13 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:35:42 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 14 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:36:15 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 15 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:36:47 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 16 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:37:20 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 17 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:37:52 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 18 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:38:24 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 19 loss:1.0398061275482178 norm:nan max memory_allocated 22722.19677734375 
[2025-03-22 02:38:33 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 7 ===
[2025-03-22 02:39:10 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 0 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:39:42 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 1 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:40:14 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 2 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:40:47 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 3 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:41:19 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 4 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:41:51 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 5 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:42:24 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 6 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:42:56 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 7 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:43:29 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 8 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:44:01 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 9 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:44:33 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 10 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:45:06 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 11 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:45:38 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 12 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:46:10 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 13 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:46:43 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 14 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:47:15 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 15 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:47:47 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 16 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:48:20 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 17 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:48:52 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 18 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:49:25 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 19 loss:1.1673239469528198 norm:nan max memory_allocated 22722.36865234375 
[2025-03-22 02:49:34 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 8 ===
[2025-03-22 02:50:10 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 0 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:50:42 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 1 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:51:15 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 2 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:51:47 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 3 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:52:19 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 4 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:52:52 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 5 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:53:24 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 6 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:53:56 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 7 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:54:29 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 8 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:55:01 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 9 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:55:34 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 10 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:56:06 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 11 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:56:38 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 12 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:57:11 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 13 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:57:43 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 14 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:58:15 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 15 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:58:48 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 16 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:59:20 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 17 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 02:59:52 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 18 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 03:00:25 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 19 loss:1.2066045999526978 norm:nan max memory_allocated 22722.54052734375 
[2025-03-22 03:00:34 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 9 ===
[2025-03-22 03:01:10 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 0 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:01:42 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 1 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:02:15 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 2 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:02:47 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 3 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:03:20 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 4 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:03:52 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 5 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:04:24 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 6 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:04:57 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 7 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:05:29 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 8 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:06:01 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 9 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:06:34 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 10 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:07:06 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 11 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:07:39 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 12 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:08:11 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 13 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:08:43 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 14 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:09:16 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 15 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:09:48 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 16 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:10:20 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 17 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:10:53 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 18 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:11:25 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 19 loss:1.2866538763046265 norm:nan max memory_allocated 22722.71240234375 
[2025-03-22 03:11:34 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 10 ===
[2025-03-22 03:12:10 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 0 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:12:43 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 1 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:13:15 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 2 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:13:47 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 3 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:14:20 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 4 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:14:52 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 5 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:15:25 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 6 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:15:57 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 7 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:16:29 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 8 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:17:02 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 9 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:17:34 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 10 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:18:06 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 11 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:18:39 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 12 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:19:11 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 13 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:19:43 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 14 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:20:16 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 15 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:20:48 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 16 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:21:21 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 17 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:21:53 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 18 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:22:25 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 19 loss:1.2936710119247437 norm:nan max memory_allocated 22722.88427734375 
[2025-03-22 03:22:34 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 11 ===
[2025-03-22 03:23:11 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 0 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:23:43 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 1 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:24:15 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 2 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:24:48 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 3 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:25:20 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 4 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:25:53 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 5 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:26:25 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 6 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:26:57 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 7 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:27:30 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 8 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:28:02 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 9 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:28:34 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 10 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:29:07 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 11 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:29:39 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 12 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:30:11 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 13 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:30:44 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 14 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:31:16 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 15 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:31:49 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 16 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:32:21 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 17 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:32:53 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 18 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:33:26 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 19 loss:1.3576340675354004 norm:nan max memory_allocated 22723.05615234375 
[2025-03-22 03:33:35 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 12 ===
[2025-03-22 03:34:11 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 0 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:34:43 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 1 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:35:16 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 2 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:35:48 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 3 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:36:20 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 4 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:36:53 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 5 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:37:25 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 6 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:37:58 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 7 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:38:30 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 8 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:39:02 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 9 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:39:35 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 10 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:40:07 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 11 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:40:39 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 12 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:41:12 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 13 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:41:44 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 14 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:42:17 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 15 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:42:49 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 16 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:43:21 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 17 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:43:54 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 18 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:44:26 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 19 loss:1.3531169891357422 norm:nan max memory_allocated 22723.22802734375 
[2025-03-22 03:44:35 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 13 ===
[2025-03-22 03:45:11 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 0 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:45:44 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 1 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:46:16 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 2 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:46:48 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 3 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:47:21 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 4 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:47:53 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 5 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:48:25 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 6 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:48:58 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 7 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:49:30 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 8 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:50:03 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 9 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:50:35 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 10 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:51:07 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 11 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:51:40 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 12 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:52:12 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 13 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:52:44 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 14 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:53:17 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 15 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:53:49 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 16 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:54:21 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 17 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:54:54 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 18 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:55:26 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 19 loss:1.4517394304275513 norm:nan max memory_allocated 22723.39990234375 
[2025-03-22 03:55:35 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 14 ===
[2025-03-22 03:56:11 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 0 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 03:56:44 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 1 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 03:57:16 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 2 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 03:57:49 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 3 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 03:58:21 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 4 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 03:58:53 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 5 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 03:59:26 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 6 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 03:59:58 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 7 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:00:30 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 8 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:01:03 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 9 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:01:35 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 10 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:02:08 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 11 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:02:40 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 12 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:03:12 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 13 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:03:45 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 14 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:04:17 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 15 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:04:49 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 16 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:05:22 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 17 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:05:54 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 18 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:06:26 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 19 loss:1.380429983139038 norm:nan max memory_allocated 22723.57177734375 
[2025-03-22 04:06:36 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 15 ===
[2025-03-22 04:07:12 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 0 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:07:44 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 1 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:08:17 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 2 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:08:49 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 3 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:09:21 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 4 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:09:54 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 5 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:10:26 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 6 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:10:58 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 7 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:11:31 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 8 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:12:03 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 9 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:12:35 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 10 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:13:08 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 11 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:13:40 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 12 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:14:13 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 13 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:14:45 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 14 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:15:17 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 15 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:15:50 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 16 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:16:22 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 17 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:16:54 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 18 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:17:27 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 19 loss:1.4584664106369019 norm:nan max memory_allocated 22723.74365234375 
[2025-03-22 04:17:36 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 16 ===
[2025-03-22 04:18:12 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 0 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:18:44 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 1 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:19:17 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 2 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:19:49 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 3 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:20:21 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 4 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:20:54 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 5 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:21:26 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 6 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:21:58 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 7 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:22:31 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 8 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:23:03 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 9 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:23:36 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 10 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:24:08 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 11 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:24:40 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 12 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:25:13 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 13 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:25:45 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 14 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:26:17 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 15 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:26:50 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 16 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:27:22 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 17 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:27:54 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 18 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:28:27 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 19 loss:1.480966567993164 norm:nan max memory_allocated 22723.91552734375 
[2025-03-22 04:28:36 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 17 ===
[2025-03-22 04:29:12 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 0 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:29:45 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 1 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:30:17 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 2 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:30:49 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 3 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:31:22 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 4 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:31:54 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 5 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:32:26 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 6 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:32:59 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 7 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:33:31 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 8 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:34:04 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 9 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:34:36 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 10 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:35:08 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 11 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:35:41 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 12 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:36:13 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 13 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:36:45 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 14 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:37:18 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 15 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:37:50 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 16 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:38:23 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 17 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:38:55 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 18 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:39:27 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 19 loss:1.492884635925293 norm:nan max memory_allocated 22724.08740234375 
[2025-03-22 04:39:36 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 18 ===
[2025-03-22 04:40:13 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 0 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:40:45 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 1 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:41:17 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 2 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:41:50 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 3 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:42:22 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 4 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:42:54 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 5 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:43:27 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 6 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:43:59 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 7 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:44:31 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 8 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:45:04 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 9 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:45:36 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 10 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:46:09 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 11 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:46:41 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 12 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:47:13 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 13 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:47:46 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 14 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:48:18 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 15 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:48:50 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 16 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:49:23 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 17 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:49:55 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 18 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:50:27 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 19 loss:1.585645079612732 norm:nan max memory_allocated 22724.25927734375 
[2025-03-22 04:50:37 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 19 ===
[2025-03-22 04:51:13 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 0 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:51:45 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 1 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:52:17 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 2 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:52:50 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 3 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:53:22 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 4 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:53:55 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 5 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:54:27 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 6 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:54:59 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 7 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:55:32 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 8 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:56:04 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 9 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:56:36 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 10 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:57:09 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 11 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:57:41 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 12 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:58:13 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 13 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:58:46 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 14 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:59:18 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 15 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 04:59:51 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 16 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 05:00:23 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 17 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 05:00:55 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 18 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 05:01:28 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 19 loss:1.6242797374725342 norm:nan max memory_allocated 22724.43115234375 
[2025-03-22 05:01:37 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 20 ===
[2025-03-22 05:02:13 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 0 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:02:45 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 1 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:03:18 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 2 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:03:50 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 3 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:04:22 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 4 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:04:55 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 5 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:05:27 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 6 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:05:59 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 7 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:06:32 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 8 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:07:04 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 9 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:07:36 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 10 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:08:09 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 11 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:08:41 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 12 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:09:14 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 13 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:09:46 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 14 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:10:18 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 15 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:10:51 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 16 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:11:23 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 17 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:11:55 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 18 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:12:28 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 19 loss:1.7164602279663086 norm:nan max memory_allocated 22724.60302734375 
[2025-03-22 05:12:37 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 21 ===
[2025-03-22 05:13:13 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 0 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:13:45 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 1 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:14:18 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 2 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:14:50 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 3 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:15:22 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 4 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:15:55 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 5 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:16:27 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 6 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:16:59 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 7 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:17:32 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 8 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:18:04 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 9 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:18:37 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 10 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:19:09 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 11 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:19:41 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 12 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:20:14 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 13 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:20:46 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 14 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:21:18 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 15 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:21:51 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 16 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:22:23 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 17 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:22:56 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 18 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:23:28 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 19 loss:1.8347766399383545 norm:nan max memory_allocated 22724.77490234375 
[2025-03-22 05:23:37 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 22 ===
[2025-03-22 05:24:13 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 0 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:24:46 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 1 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:25:18 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 2 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:25:50 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 3 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:26:23 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 4 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:26:55 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 5 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:27:28 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 6 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:28:00 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 7 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:28:32 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 8 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:29:05 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 9 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:29:37 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 10 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:30:09 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 11 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:30:42 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 12 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:31:14 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 13 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:31:47 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 14 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:32:19 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 15 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:32:51 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 16 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:33:24 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 17 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:33:56 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 18 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:34:28 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 19 loss:1.9640530347824097 norm:nan max memory_allocated 22724.94677734375 
[2025-03-22 05:34:38 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 23 ===
[2025-03-22 05:35:14 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 0 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:35:46 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 1 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:36:18 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 2 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:36:51 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 3 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:37:23 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 4 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:37:56 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 5 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:38:28 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 6 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:39:00 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 7 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:39:33 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 8 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:40:05 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 9 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:40:37 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 10 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:41:10 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 11 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:41:42 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 12 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:42:15 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 13 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:42:47 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 14 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:43:19 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 15 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:43:52 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 16 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:44:24 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 17 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:44:56 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 18 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:45:29 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 19 loss:2.151745319366455 norm:nan max memory_allocated 22725.11865234375 
[2025-03-22 05:45:38 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 24 ===
[2025-03-22 05:46:14 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 0 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:46:47 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 1 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:47:19 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 2 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:47:51 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 3 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:48:24 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 4 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:48:56 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 5 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:49:28 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 6 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:50:01 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 7 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:50:33 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 8 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:51:05 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 9 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:51:38 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 10 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:52:10 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 11 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:52:42 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 12 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:53:15 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 13 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:53:47 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 14 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:54:20 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 15 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:54:52 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 16 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:55:24 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 17 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:55:57 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 18 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:56:29 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 19 loss:2.3528428077697754 norm:nan max memory_allocated 22725.29052734375 
[2025-03-22 05:56:38 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 25 ===
[2025-03-22 05:57:14 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 0 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 05:57:47 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 1 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 05:58:19 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 2 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 05:58:51 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 3 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 05:59:24 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 4 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 05:59:56 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 5 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:00:29 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 6 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:01:01 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 7 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:01:33 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 8 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:02:06 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 9 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:02:38 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 10 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:03:10 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 11 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:03:43 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 12 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:04:15 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 13 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:04:47 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 14 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:05:20 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 15 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:05:52 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 16 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:06:25 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 17 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:06:57 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 18 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:07:29 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 19 loss:2.611208200454712 norm:nan max memory_allocated 22725.46240234375 
[2025-03-22 06:07:38 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 26 ===
[2025-03-22 06:08:14 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 0 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:08:47 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 1 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:09:19 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 2 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:09:52 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 3 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:10:24 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 4 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:10:56 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 5 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:11:29 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 6 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:12:01 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 7 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:12:33 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 8 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:13:06 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 9 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:13:38 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 10 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:14:11 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 11 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:14:43 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 12 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:15:15 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 13 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:15:48 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 14 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:16:20 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 15 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:16:52 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 16 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:17:25 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 17 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:17:57 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 18 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:18:30 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 19 loss:2.9110496044158936 norm:nan max memory_allocated 22725.63427734375 
[2025-03-22 06:18:39 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 27 ===
[2025-03-22 06:19:15 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 0 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:19:47 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 1 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:20:20 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 2 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:20:52 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 3 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:21:24 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 4 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:21:57 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 5 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:22:29 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 6 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:23:01 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 7 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:23:34 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 8 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:24:06 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 9 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:24:38 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 10 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:25:11 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 11 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:25:43 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 12 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:26:16 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 13 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:26:48 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 14 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:27:20 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 15 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:27:53 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 16 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:28:25 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 17 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:28:57 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 18 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:29:30 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 19 loss:3.253652334213257 norm:nan max memory_allocated 22725.80615234375 
[2025-03-22 06:29:39 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 28 ===
[2025-03-22 06:29:42 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:30:15 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 0 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:30:48 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 1 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:31:20 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 2 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:31:53 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 3 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:32:25 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 4 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:32:58 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 5 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:33:30 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 6 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:34:02 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 7 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:34:35 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 8 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:35:07 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 9 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:35:40 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 10 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:36:12 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 11 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:36:45 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 12 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:37:17 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 13 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:37:50 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 14 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:38:22 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 15 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:38:55 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 16 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:39:27 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 17 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:40:00 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 18 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:40:32 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 19 loss:3.6663918495178223 norm:nan max memory_allocated 22725.97802734375 
[2025-03-22 06:40:41 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 29 ===
[2025-03-22 06:40:44 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:41:17 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 0 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:41:50 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 1 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:42:22 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 2 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:42:55 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 3 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:43:27 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 4 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:44:00 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 5 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:44:32 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 6 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:45:05 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 7 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:45:37 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 8 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:46:10 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 9 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:46:42 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 10 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:47:15 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 11 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:47:47 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 12 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:48:19 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 13 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:48:52 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 14 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:49:24 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 15 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:49:57 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 16 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:50:29 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 17 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:51:02 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 18 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:51:34 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 19 loss:4.197843551635742 norm:nan max memory_allocated 22726.14990234375 
[2025-03-22 06:51:43 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 30 ===
[2025-03-22 06:51:47 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:52:20 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 0 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:52:52 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 1 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:53:25 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 2 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:53:57 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 3 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:54:30 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 4 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:55:02 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 5 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:55:34 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 6 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:56:07 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 7 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:56:39 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 8 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:57:12 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 9 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:57:44 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 10 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:58:17 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 11 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:58:49 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 12 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:59:22 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 13 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 06:59:54 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 14 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 07:00:27 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 15 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 07:00:59 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 16 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 07:01:31 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 17 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 07:02:04 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 18 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 07:02:36 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 19 loss:6.013947486877441 norm:nan max memory_allocated 22726.32177734375 
[2025-03-22 07:02:46 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 31 ===
[2025-03-22 07:02:49 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 07:03:22 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 0 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:03:54 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 1 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:04:27 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 2 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:04:59 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 3 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:05:32 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 4 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:06:04 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 5 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:06:37 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 6 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:07:10 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 7 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:07:42 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 8 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:08:15 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 9 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:08:47 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 10 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:09:20 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 11 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:09:52 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 12 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:10:25 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 13 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:10:57 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 14 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:11:30 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 15 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:12:03 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 16 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:12:35 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 17 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:13:08 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 18 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:13:40 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 19 loss:12.002828598022461 norm:nan max memory_allocated 22726.49365234375 
[2025-03-22 07:13:50 root] (main_calibration_a2.py 370): INFO 21156.831949710846
[2025-03-22 07:13:55 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-22 07:15:04 root] (main_calibration_a2.py 158): INFO wikitext2 : 81.42998504638672
[2025-03-22 07:15:04 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-22 07:16:50 root] (main_calibration_a2.py 158): INFO c4 : 101.48695373535156
