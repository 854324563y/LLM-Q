[2025-03-22 14:58:10 root] (main_calibration_a2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-calibration-compensation-lwc-loss/Llama-2-7b-hf-w4a4-all', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, scale_calibration=True, compensation_calibration=True, rank=1, loss_type='all')
[2025-03-22 14:59:06 root] (main_calibration_a2.py 343): INFO === start quantization ===
[2025-03-22 14:59:06 root] (main_calibration_a2.py 349): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-22 14:59:06 root] (abq_llm_calibration_a2.py 62): INFO Starting ...
[2025-03-22 14:59:08 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 0 ===
[2025-03-22 14:59:11 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 14:59:28 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 0 loss:3.804273562835192e-11 norm:1.0137251281461257e-12 max memory_allocated 26052.77783203125 
[2025-03-22 14:59:43 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 1 loss:3.818372354413846e-11 norm:1.013670701197067e-12 max memory_allocated 26052.77783203125 
[2025-03-22 14:59:59 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 2 loss:3.826489819447332e-11 norm:1.0136201773758291e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:00:14 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 3 loss:3.818092370044823e-11 norm:1.01383213890055e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:00:30 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 4 loss:3.7993674179004344e-11 norm:1.013988697694257e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:00:45 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 5 loss:3.8451242190262747e-11 norm:1.0138149000860075e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:01:01 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 6 loss:3.8266136787035165e-11 norm:1.014036727850498e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:01:17 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 7 loss:3.8199450547171665e-11 norm:1.0142301495180694e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:01:33 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 8 loss:3.823121680346375e-11 norm:1.0142474967528292e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:01:48 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 9 loss:3.802129444618885e-11 norm:1.014285335408649e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:02:04 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 10 loss:3.8002875152320925e-11 norm:1.0141746383668382e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:02:20 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 11 loss:3.803565448712298e-11 norm:1.0142237527252518e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:02:35 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 12 loss:3.7861120488758004e-11 norm:1.0100488154196618e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:02:51 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 13 loss:3.7754212950380506e-11 norm:1.009687667676007e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:03:07 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 14 loss:3.820395041986835e-11 norm:1.0098880282374822e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:03:23 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 15 loss:3.833548062326386e-11 norm:1.009814627750405e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:03:38 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 16 loss:3.8153428333354e-11 norm:1.0094821029441037e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:03:54 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 17 loss:3.8057303836103173e-11 norm:1.0098586463586079e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:04:09 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 18 loss:3.806965853669908e-11 norm:1.010525213854252e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:04:25 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 19 loss:3.8013391046032297e-11 norm:1.0105903744048184e-12 max memory_allocated 26052.77783203125 
[2025-03-22 15:04:34 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 1 ===
[2025-03-22 15:04:37 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 15:04:53 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 0 loss:6.246025363587648e-10 norm:2.5498124445189063e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:05:08 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 1 loss:6.246502204376725e-10 norm:2.5435615419455715e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:05:24 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 2 loss:6.244872952088087e-10 norm:2.5515537599440918e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:05:40 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 3 loss:6.241317462851725e-10 norm:2.5438862821802743e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:05:56 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 4 loss:6.24252594061403e-10 norm:2.5337565379146554e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:06:11 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 5 loss:6.240559180525906e-10 norm:2.5376232365426077e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:06:27 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 6 loss:6.240661876155684e-10 norm:2.5262299196970872e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:06:43 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 7 loss:6.239918581840698e-10 norm:2.5176765186540884e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:06:59 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 8 loss:6.238517480383621e-10 norm:2.5090650043746443e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:07:14 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 9 loss:6.240647443256364e-10 norm:2.507271820717527e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:07:30 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 10 loss:6.239697647458797e-10 norm:2.4997830194717352e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:07:46 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 11 loss:6.233789040521742e-10 norm:2.501871279592116e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:08:01 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 12 loss:6.236262617420607e-10 norm:2.5333055098109014e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:08:17 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 13 loss:6.23379570185989e-10 norm:2.542006535821706e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:08:33 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 14 loss:6.23394447174519e-10 norm:2.5407847700775754e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:08:48 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 15 loss:6.235348348759828e-10 norm:2.5579259196883974e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:09:04 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 16 loss:6.234012195349692e-10 norm:2.5659563016033893e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:09:20 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 17 loss:6.232501181813177e-10 norm:2.5572852863087192e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:09:36 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 18 loss:6.233763505392176e-10 norm:2.5489017146940185e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:09:51 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 19 loss:6.229252114131612e-10 norm:2.540641828863155e-11 max memory_allocated 26696.69873046875 
[2025-03-22 15:10:01 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 2 ===
[2025-03-22 15:10:03 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 15:10:19 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 0 loss:4.6476625215063905e-08 norm:7.374148847105744e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:10:35 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 1 loss:4.6927976171673436e-08 norm:6.234228688839494e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:10:51 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 2 loss:4.8231335370019224e-08 norm:5.760225629813931e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:11:07 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 3 loss:4.8101277627665695e-08 norm:4.94756191571355e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:11:22 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 4 loss:4.7676611103497635e-08 norm:4.273000620003131e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:11:38 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 5 loss:4.8618474579598114e-08 norm:4.186258450999958e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:11:54 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 6 loss:4.9640842547660213e-08 norm:4.160348954229676e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:12:10 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 7 loss:4.9710472183051024e-08 norm:3.7881240366743896e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:12:26 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 8 loss:5.0162768161499116e-08 norm:3.705677542598096e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:12:42 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 9 loss:5.0776726823187346e-08 norm:3.6432907801753345e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:12:58 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 10 loss:5.1433573844406055e-08 norm:3.5129463782368475e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:13:14 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 11 loss:5.1937348644059966e-08 norm:3.3214289096861194e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:13:29 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 12 loss:5.147934700744372e-08 norm:3.052036401385294e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:13:45 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 13 loss:5.091571964044306e-08 norm:2.7435986815760316e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:14:01 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 14 loss:4.952459420337618e-08 norm:2.257095843560819e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:14:17 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 15 loss:4.919364826605488e-08 norm:2.0409662848663856e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:14:33 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 16 loss:4.926297947349667e-08 norm:1.944311378565544e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:14:48 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 17 loss:4.941747988596035e-08 norm:1.9316246380185476e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:15:04 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 18 loss:4.959397514880948e-08 norm:1.895965606735217e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:15:20 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 19 loss:4.956785204512926e-08 norm:1.7851147227077035e-09 max memory_allocated 26696.90185546875 
[2025-03-22 15:15:29 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 3 ===
[2025-03-22 15:15:48 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 0 loss:1.552109019087311e-08 norm:5.1821369417837104e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:16:04 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 1 loss:1.5016976107062874e-08 norm:4.344109072462743e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:16:20 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 2 loss:1.550201922384531e-08 norm:4.182209245584545e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:16:35 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 3 loss:1.5781944640025358e-08 norm:4.194180558414473e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:16:51 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 4 loss:1.567492446952201e-08 norm:4.208635662195093e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:17:07 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 5 loss:1.4990790830893275e-08 norm:3.582563357085178e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:17:23 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 6 loss:1.4803330117274527e-08 norm:3.4108813551370076e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:17:39 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 7 loss:1.494833057336109e-08 norm:3.4206291132932165e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:17:55 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 8 loss:1.5462230606999583e-08 norm:3.4975333740305814e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:18:11 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 9 loss:1.602999510907921e-08 norm:3.4870395460018244e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:18:26 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 10 loss:1.6774443167832942e-08 norm:3.4749847444004445e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:18:42 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 11 loss:1.6660488100228577e-08 norm:3.3746050398519856e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:18:58 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 12 loss:1.7013105590990563e-08 norm:3.379952762117e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:19:13 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 13 loss:1.7281267972180103e-08 norm:3.434222239917517e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:19:29 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 14 loss:1.6935743474277842e-08 norm:3.1732652061577937e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:19:45 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 15 loss:1.6508721500940737e-08 norm:2.8548219344060044e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:20:01 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 16 loss:1.644159475233664e-08 norm:2.6886561865779868e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:20:16 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 17 loss:1.6441042305359588e-08 norm:2.5805597658745683e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:20:32 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 18 loss:1.6643788569581375e-08 norm:2.5463589015117805e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:20:48 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 19 loss:1.6960198578885866e-08 norm:2.538697474463447e-09 max memory_allocated 26697.10498046875 
[2025-03-22 15:20:57 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 4 ===
[2025-03-22 15:21:16 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 0 loss:1.4974997242234167e-08 norm:3.1749576301365323e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:21:32 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 1 loss:1.4943932313826735e-08 norm:2.9697997394606546e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:21:48 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 2 loss:1.4876055942636413e-08 norm:2.7887996356668054e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:22:04 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 3 loss:1.4512939294775151e-08 norm:2.410758481730113e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:22:19 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 4 loss:1.3944244869890099e-08 norm:2.1763730817525584e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:22:35 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 5 loss:1.3771336959678138e-08 norm:1.9491968039631047e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:22:51 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 6 loss:1.3353421479678218e-08 norm:1.8656589606536045e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:23:07 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 7 loss:1.3424043210363834e-08 norm:1.937439986221534e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:23:22 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 8 loss:1.3830254275148945e-08 norm:2.003075039169744e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:23:38 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 9 loss:1.450687125981176e-08 norm:2.1892894164210475e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:23:54 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 10 loss:1.4894719235769571e-08 norm:2.3960873285489015e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:24:09 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 11 loss:1.5036842881954726e-08 norm:2.5179778262440777e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:24:25 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 12 loss:1.464139653961638e-08 norm:2.3637136692400418e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:24:41 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 13 loss:1.391107051773588e-08 norm:2.067568782848639e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:24:57 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 14 loss:1.3767500917083453e-08 norm:2.0075667794827723e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:25:13 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 15 loss:1.3543923316206019e-08 norm:2.00505545500107e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:25:28 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 16 loss:1.3250680552800986e-08 norm:1.944122196562148e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:25:44 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 17 loss:1.3046993707632737e-08 norm:1.8938670631740706e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:26:00 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 18 loss:1.2989888276138117e-08 norm:1.9341837020903085e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:26:16 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 19 loss:1.287679829431454e-08 norm:1.9566048781172185e-09 max memory_allocated 26697.30810546875 
[2025-03-22 15:26:25 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 5 ===
[2025-03-22 15:26:44 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 0 loss:1.2936371085459086e-08 norm:2.2677653088720717e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:27:00 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 1 loss:1.2436116136882447e-08 norm:1.957246364980847e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:27:15 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 2 loss:1.208654953899213e-08 norm:1.7417098874261683e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:27:31 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 3 loss:1.2291222262206247e-08 norm:1.7533472451702892e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:27:47 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 4 loss:1.267228100232387e-08 norm:1.8403865098548522e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:28:03 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 5 loss:1.3097125162175871e-08 norm:1.9394703620889686e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:28:19 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 6 loss:1.3291655776015432e-08 norm:2.066940840705911e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:28:35 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 7 loss:1.3452672753544448e-08 norm:2.1028392360733505e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:28:51 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 8 loss:1.3244514818211428e-08 norm:2.0330821470793126e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:29:07 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 9 loss:1.3072948945591634e-08 norm:1.9718575661187288e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:29:22 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 10 loss:1.3060635239980911e-08 norm:1.9947621332505605e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:29:38 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 11 loss:1.2993394804539093e-08 norm:1.922279002641858e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:29:54 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 12 loss:1.2860602360831308e-08 norm:1.8218531128155746e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:30:10 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 13 loss:1.264242932563775e-08 norm:1.691640827417018e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:30:26 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 14 loss:1.2339336663558242e-08 norm:1.5168375444574167e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:30:42 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 15 loss:1.2131579296692507e-08 norm:1.4334939901772259e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:30:58 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 16 loss:1.1962473678295282e-08 norm:1.3728803649470933e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:31:14 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 17 loss:1.1753192197261342e-08 norm:1.2970161611391973e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:31:29 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 18 loss:1.1765274088304523e-08 norm:1.2853512698640657e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:31:45 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 19 loss:1.1727176563169905e-08 norm:1.2700551721422926e-09 max memory_allocated 26697.51123046875 
[2025-03-22 15:31:55 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 6 ===
[2025-03-22 15:32:13 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 0 loss:1.455488263246707e-08 norm:2.730891290880777e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:32:29 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 1 loss:1.4175791207549082e-08 norm:2.4239872331577317e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:32:45 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 2 loss:1.3907534679447053e-08 norm:2.2433099822194436e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:33:01 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 3 loss:1.3477647442527996e-08 norm:1.9744945678468184e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:33:17 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 4 loss:1.3189721315143288e-08 norm:1.8342461993725578e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:33:33 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 5 loss:1.31867823327525e-08 norm:1.76640657656435e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:33:48 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 6 loss:1.3197728243596885e-08 norm:1.7292937082302728e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:34:04 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 7 loss:1.3203195869948559e-08 norm:1.674263616635585e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:34:20 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 8 loss:1.30626816030599e-08 norm:1.6101633359966172e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:34:35 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 9 loss:1.3172027024666022e-08 norm:1.6246874956493684e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:34:51 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 10 loss:1.3352474681482818e-08 norm:1.6228203225665538e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:35:07 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 11 loss:1.3251386654644648e-08 norm:1.5752761317600061e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:35:23 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 12 loss:1.3165029955075624e-08 norm:1.5212783255336149e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:35:39 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 13 loss:1.3138763854669833e-08 norm:1.4777524759423954e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:35:55 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 14 loss:1.3106592255951455e-08 norm:1.450738973396426e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:36:10 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 15 loss:1.3077376515013839e-08 norm:1.431488705350148e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:36:26 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 16 loss:1.3170568635700874e-08 norm:1.4459690111934265e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:36:42 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 17 loss:1.3354404693188826e-08 norm:1.457857834452625e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:36:58 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 18 loss:1.3496745054908388e-08 norm:1.4640737511228963e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:37:14 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 19 loss:1.35962254788069e-08 norm:1.4620800126152744e-09 max memory_allocated 26697.71435546875 
[2025-03-22 15:37:23 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 7 ===
[2025-03-22 15:37:42 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 0 loss:1.2146669448043212e-08 norm:2.563520951071041e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:37:58 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 1 loss:1.1988791293049417e-08 norm:2.411736366170203e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:38:13 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 2 loss:1.176371089428585e-08 norm:2.2544073274843868e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:38:29 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 3 loss:1.1472305772031177e-08 norm:2.07816919228776e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:38:45 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 4 loss:1.1370604013904995e-08 norm:1.9777015580757507e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:39:01 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 5 loss:1.1441046332549831e-08 norm:1.8996009210070497e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:39:17 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 6 loss:1.156485573972077e-08 norm:1.85830495436079e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:39:32 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 7 loss:1.1510372210921105e-08 norm:1.7747459057915194e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:39:48 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 8 loss:1.1452970127834305e-08 norm:1.7399076623902943e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:40:04 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 9 loss:1.1454151405132507e-08 norm:1.7350096914725555e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:40:20 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 10 loss:1.1507836461532861e-08 norm:1.660305004591578e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:40:36 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 11 loss:1.1760771911895063e-08 norm:1.6891399390317474e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:40:52 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 12 loss:1.1641614783286514e-08 norm:1.6499628330279847e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:41:07 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 13 loss:1.1630258534012228e-08 norm:1.595374166107888e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:41:23 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 14 loss:1.154984019535732e-08 norm:1.5355027249697173e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:41:39 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 15 loss:1.1665133747840173e-08 norm:1.531411886190881e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:41:55 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 16 loss:1.1618665141099882e-08 norm:1.4889690591601834e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:42:10 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 17 loss:1.1577432346143723e-08 norm:1.4586346575029552e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:42:26 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 18 loss:1.1862187676570102e-08 norm:1.5252460405790202e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:42:42 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 19 loss:1.2081572187128131e-08 norm:1.5589748381117374e-09 max memory_allocated 26697.91748046875 
[2025-03-22 15:42:51 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 8 ===
[2025-03-22 15:43:10 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 0 loss:1.0827966967497105e-08 norm:1.5353897042658105e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:43:26 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 1 loss:1.0638940395324425e-08 norm:1.4753331889494348e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:43:42 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 2 loss:1.0606725275863482e-08 norm:1.4354711863617808e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:43:58 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 3 loss:1.0787599258321734e-08 norm:1.3660521602787412e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:44:13 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 4 loss:1.0712079223651472e-08 norm:1.317964404279337e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:44:29 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 5 loss:1.0659588767225614e-08 norm:1.27683041917237e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:44:45 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 6 loss:1.0819622531244022e-08 norm:1.2732234155876654e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:45:01 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 7 loss:1.0835490726890384e-08 norm:1.240509917010968e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:45:17 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 8 loss:1.0903085545521662e-08 norm:1.244573333281096e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:45:33 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 9 loss:1.082599521140537e-08 norm:1.1977278058239449e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:45:49 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 10 loss:1.084687806240936e-08 norm:1.188199205692797e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:46:04 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 11 loss:1.0858601129370982e-08 norm:1.1784291320537932e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:46:20 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 12 loss:1.0788699711383742e-08 norm:1.168646956983821e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:46:36 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 13 loss:1.0834993346975352e-08 norm:1.160248452869439e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:46:52 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 14 loss:1.0890495616422413e-08 norm:1.172572372531988e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:47:08 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 15 loss:1.0828821395136856e-08 norm:1.1254375209546197e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:47:24 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 16 loss:1.0942167172345307e-08 norm:1.126630344572277e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:47:39 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 17 loss:1.0972983410795223e-08 norm:1.135167626564737e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:47:55 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 18 loss:1.0994242849449165e-08 norm:1.127497872843719e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:48:11 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 19 loss:1.1171930047737533e-08 norm:1.1604995853176092e-09 max memory_allocated 26698.12060546875 
[2025-03-22 15:48:20 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 9 ===
[2025-03-22 15:48:39 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 0 loss:1.0689643836769847e-08 norm:2.408389043750958e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:48:55 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 1 loss:1.0668566474691943e-08 norm:2.178630831295436e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:49:10 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 2 loss:1.0344569645326374e-08 norm:1.9547985452561534e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:49:26 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 3 loss:1.0039666875627518e-08 norm:1.8443151450497908e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:49:42 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 4 loss:9.957636493140853e-09 norm:1.765633195205396e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:49:58 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 5 loss:9.8532444425814e-09 norm:1.7701451415774727e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:50:14 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 6 loss:9.829831171259684e-09 norm:1.7533443585904251e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:50:30 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 7 loss:9.79495329289648e-09 norm:1.7452747025359372e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:50:46 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 8 loss:9.772347375758272e-09 norm:1.7382348893590915e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:51:02 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 9 loss:9.774463904932418e-09 norm:1.7280451514167794e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:51:18 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 10 loss:9.757095575935182e-09 norm:1.7624863790643985e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:51:33 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 11 loss:9.80979031339757e-09 norm:1.7560843890152e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:51:49 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 12 loss:9.82901227075672e-09 norm:1.7542579611173892e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:52:05 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 13 loss:9.70775904107768e-09 norm:1.6877456099351207e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:52:21 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 14 loss:9.567344250172027e-09 norm:1.6523670209878105e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:52:37 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 15 loss:9.504585563036017e-09 norm:1.6378221001644988e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:52:53 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 16 loss:9.55528101087566e-09 norm:1.6412354808537089e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:53:09 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 17 loss:9.59695700686325e-09 norm:1.6271273217682847e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:53:25 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 18 loss:9.521386346023064e-09 norm:1.6045937911712826e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:53:40 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 19 loss:9.356812213923149e-09 norm:1.5649801454742374e-09 max memory_allocated 26698.32373046875 
[2025-03-22 15:53:50 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 10 ===
[2025-03-22 15:54:08 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 0 loss:7.669613388827656e-09 norm:1.003277350086762e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:54:24 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 1 loss:7.68058860955989e-09 norm:1.002692151530482e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:54:40 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 2 loss:7.69267671785201e-09 norm:1.0058975874471798e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:54:56 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 3 loss:7.695041048805251e-09 norm:1.0070739797640726e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:55:12 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 4 loss:7.674201718543827e-09 norm:1.0044711729051414e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:55:28 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 5 loss:7.723275352589098e-09 norm:1.0104915793007763e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:55:44 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 6 loss:7.73890729277582e-09 norm:1.0123683003016026e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:56:00 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 7 loss:7.750937669470659e-09 norm:1.0130156713472616e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:56:16 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 8 loss:7.743776286872617e-09 norm:1.0183481835568386e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:56:31 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 9 loss:7.727780193533818e-09 norm:1.0151768314869969e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:56:47 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 10 loss:7.712087857214556e-09 norm:1.0128708982648504e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:57:03 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 11 loss:7.707773086451652e-09 norm:1.0099671099439433e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:57:19 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 12 loss:7.677909863446075e-09 norm:1.008125916079905e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:57:35 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 13 loss:7.673976121225223e-09 norm:1.0075046352753247e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:57:51 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 14 loss:7.668127466331498e-09 norm:1.0070470013445743e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:58:07 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 15 loss:7.67531993517423e-09 norm:1.009124228623648e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:58:22 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 16 loss:7.72869235277085e-09 norm:1.012356865004449e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:58:38 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 17 loss:7.696107751087311e-09 norm:1.0069250988564704e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:58:54 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 18 loss:7.67496466380635e-09 norm:1.0089887814146437e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:59:10 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 19 loss:7.646343114231513e-09 norm:1.004069494214832e-09 max memory_allocated 26698.52685546875 
[2025-03-22 15:59:20 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 11 ===
[2025-03-22 15:59:39 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 0 loss:1.0922148518943686e-08 norm:1.7328591894738565e-09 max memory_allocated 26698.72998046875 
[2025-03-22 15:59:55 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 1 loss:1.1035145242033195e-08 norm:1.735997123830657e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:00:10 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 2 loss:1.1039344549601537e-08 norm:1.711944142002153e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:00:26 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 3 loss:1.0981567655221625e-08 norm:1.6899412980109219e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:00:42 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 4 loss:1.1056863868930122e-08 norm:1.72320080427113e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:00:58 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 5 loss:1.1107379016550567e-08 norm:1.7244398131666117e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:01:14 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 6 loss:1.1164894786475088e-08 norm:1.721661924136697e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:01:30 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 7 loss:1.1162533120057105e-08 norm:1.7124188733674828e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:01:46 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 8 loss:1.1109700714939663e-08 norm:1.685998674005873e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:02:01 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 9 loss:1.1131025878796663e-08 norm:1.6702734750850823e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:02:17 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 10 loss:1.1097054830599973e-08 norm:1.6588267426342895e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:02:33 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 11 loss:1.1030178548310232e-08 norm:1.6420241832904026e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:02:49 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 12 loss:1.0854539489457693e-08 norm:1.5793151231235925e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:03:05 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 13 loss:1.078947864385782e-08 norm:1.5318212254200603e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:03:20 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 14 loss:1.0774534153767945e-08 norm:1.5036172307247853e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:03:36 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 15 loss:1.0803171690554336e-08 norm:1.4860999097976446e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:03:52 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 16 loss:1.0865634614276587e-08 norm:1.5013990051215842e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:04:08 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 17 loss:1.083094325338152e-08 norm:1.488758671897017e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:04:24 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 18 loss:1.0811646689035115e-08 norm:1.4877341580898928e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:04:40 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 19 loss:1.0797813310148285e-08 norm:1.4823327010304865e-09 max memory_allocated 26698.72998046875 
[2025-03-22 16:04:49 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 12 ===
[2025-03-22 16:05:08 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 0 loss:1.0063543776084316e-08 norm:1.8289303405083501e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:05:24 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 1 loss:1.0006098172254951e-08 norm:1.8032433324322028e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:05:40 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 2 loss:9.888581509187588e-09 norm:1.7549347530732007e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:05:55 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 3 loss:9.880984919163893e-09 norm:1.7464989454651914e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:06:11 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 4 loss:9.89082860058943e-09 norm:1.7595445100937468e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:06:27 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 5 loss:9.884303153739893e-09 norm:1.7544075081588062e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:06:43 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 6 loss:9.863457606229531e-09 norm:1.7512511440997969e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:06:59 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 7 loss:9.826996105744001e-09 norm:1.7453459788541181e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:07:15 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 8 loss:9.818597490607317e-09 norm:1.7433203769456895e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:07:31 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 9 loss:9.801596867475837e-09 norm:1.7367596250039696e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:07:47 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 10 loss:9.791079946808168e-09 norm:1.7366321714007427e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:08:03 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 11 loss:9.825272151431363e-09 norm:1.7383873229803726e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:08:19 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 12 loss:9.804365319610042e-09 norm:1.6938442870539916e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:08:35 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 13 loss:9.766884190298697e-09 norm:1.6806002145486332e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:08:50 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 14 loss:9.760601216157738e-09 norm:1.6705016259166428e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:09:06 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 15 loss:9.714513637959499e-09 norm:1.6561072513354702e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:09:22 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 16 loss:9.698887026843295e-09 norm:1.6600091301555153e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:09:38 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 17 loss:9.673700063217439e-09 norm:1.6506586097975173e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:09:54 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 18 loss:9.689153479541801e-09 norm:1.6513823641872705e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:10:10 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 19 loss:9.687864732654816e-09 norm:1.63506430617133e-09 max memory_allocated 26698.93310546875 
[2025-03-22 16:10:19 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 13 ===
[2025-03-22 16:10:38 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 0 loss:1.0350886370247281e-08 norm:2.802206466867574e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:10:53 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 1 loss:1.0248015769320773e-08 norm:2.805621734935926e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:11:09 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 2 loss:1.0267329209057152e-08 norm:2.8592612721922706e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:11:25 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 3 loss:1.0237788394817926e-08 norm:2.8433864152077604e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:11:41 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 4 loss:1.014018380374182e-08 norm:2.80786083273199e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:11:57 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 5 loss:1.0096590230546099e-08 norm:2.7760944654176e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:12:13 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 6 loss:1.000494709302302e-08 norm:2.7274211777950086e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:12:29 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 7 loss:1.0058175625715648e-08 norm:2.727567727234259e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:12:45 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 8 loss:1.005986138835624e-08 norm:2.743757887557763e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:13:00 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 9 loss:1.0085725143937907e-08 norm:2.7472180086363096e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:13:16 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 10 loss:1.0079265422291428e-08 norm:2.7409536862421646e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:13:32 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 11 loss:1.0056942834069105e-08 norm:2.715267122255227e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:13:48 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 12 loss:9.966112379800052e-09 norm:2.6800823782480165e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:14:04 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 13 loss:9.936649725261759e-09 norm:2.677953858665205e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:14:20 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 14 loss:9.919858712237328e-09 norm:2.645021313085749e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:14:35 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 15 loss:9.879064677420502e-09 norm:2.6278623721509575e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:14:51 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 16 loss:9.84853087970805e-09 norm:2.62206412138255e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:15:07 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 17 loss:9.863556194034118e-09 norm:2.596468151594422e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:15:23 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 18 loss:9.886349516818882e-09 norm:2.6152484622343763e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:15:39 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 19 loss:9.843985182556025e-09 norm:2.5974689066288192e-09 max memory_allocated 26699.13623046875 
[2025-03-22 16:15:48 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 14 ===
[2025-03-22 16:16:07 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 0 loss:1.1332266680597058e-08 norm:2.058526460402277e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:16:23 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 1 loss:1.1352386586338525e-08 norm:2.043038405119546e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:16:39 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 2 loss:1.1358882723300212e-08 norm:2.0213359874787784e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:16:54 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 3 loss:1.1444790004588867e-08 norm:2.0143842149877855e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:17:10 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 4 loss:1.1467477634141687e-08 norm:2.016812050698036e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:17:26 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 5 loss:1.1462440774323568e-08 norm:2.000488441566972e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:17:42 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 6 loss:1.158194340433738e-08 norm:2.0367849629110424e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:17:58 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 7 loss:1.1559333934485494e-08 norm:2.044048708071955e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:18:14 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 8 loss:1.1571687608125103e-08 norm:2.0429895553064625e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:18:30 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 9 loss:1.1638385366552484e-08 norm:2.0582313631223315e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:18:46 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 10 loss:1.165747143261342e-08 norm:2.0557879842897364e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:19:01 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 11 loss:1.1658375598244675e-08 norm:2.0638699638197977e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:19:17 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 12 loss:1.1681093425863764e-08 norm:2.0748625040312163e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:19:33 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 13 loss:1.172870156551653e-08 norm:2.0619608243066523e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:19:49 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 14 loss:1.1736075222756881e-08 norm:2.0526682575905397e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:20:05 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 15 loss:1.1724837989390835e-08 norm:2.0529495881049797e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:20:21 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 16 loss:1.1720288739525131e-08 norm:2.0496506714096085e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:20:37 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 17 loss:1.1664423205104413e-08 norm:2.0259998123606238e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:20:53 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 18 loss:1.1602214300410196e-08 norm:2.0096744268727207e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:21:09 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 19 loss:1.1539606603605534e-08 norm:1.987880526854724e-09 max memory_allocated 26699.33935546875 
[2025-03-22 16:21:18 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 15 ===
[2025-03-22 16:21:37 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 0 loss:1.2257459047759767e-08 norm:3.26254534499526e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:21:53 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 1 loss:1.2149869554889392e-08 norm:3.1507241260442242e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:22:09 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 2 loss:1.2189568465714729e-08 norm:3.1213456264111983e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:22:24 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 3 loss:1.2070701771449421e-08 norm:3.002192050516328e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:22:40 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 4 loss:1.1881389205825599e-08 norm:2.8502009641329096e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:22:56 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 5 loss:1.1900363361405653e-08 norm:2.791128883572469e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:23:12 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 6 loss:1.196259891145246e-08 norm:2.778718366513999e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:23:28 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 7 loss:1.1867037130741664e-08 norm:2.670499377188662e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:23:44 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 8 loss:1.1850067593854874e-08 norm:2.6231405936272267e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:24:00 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 9 loss:1.1840644020821856e-08 norm:2.5543298587393792e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:24:16 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 10 loss:1.1877786754155295e-08 norm:2.526077791387138e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:24:32 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 11 loss:1.1868047877783283e-08 norm:2.4643955764958037e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:24:48 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 12 loss:1.1735784788413639e-08 norm:2.3901605139542426e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:25:04 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 13 loss:1.168996188738447e-08 norm:2.3420985151290097e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:25:19 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 14 loss:1.1670218569292956e-08 norm:2.3068504884093954e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:25:35 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 15 loss:1.1587756532094318e-08 norm:2.287167788495026e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:25:51 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 16 loss:1.1552195644526364e-08 norm:2.2701316382267578e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:26:07 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 17 loss:1.1587428794257448e-08 norm:2.2606367888755585e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:26:22 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 18 loss:1.1466358529332865e-08 norm:2.214294303470865e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:26:38 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 19 loss:1.1466754656908051e-08 norm:2.1938957317502172e-09 max memory_allocated 26699.54248046875 
[2025-03-22 16:26:48 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 16 ===
[2025-03-22 16:27:06 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 0 loss:1.686940542811044e-08 norm:6.071408265029277e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:27:22 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 1 loss:1.7118127360049584e-08 norm:5.536631597635733e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:27:38 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 2 loss:1.7060376222843843e-08 norm:4.940469811032244e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:27:54 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 3 loss:1.659531356779098e-08 norm:4.148455801100681e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:28:10 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 4 loss:1.6404063885033793e-08 norm:3.900261447142839e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:28:26 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 5 loss:1.6434027472200796e-08 norm:3.763012124124998e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:28:42 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 6 loss:1.6331286545323564e-08 norm:3.6745062548249052e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:28:58 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 7 loss:1.6387318169108767e-08 norm:3.470000953242902e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:29:14 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 8 loss:1.607909538847707e-08 norm:3.2564722030059556e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:29:30 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 9 loss:1.5981573397993998e-08 norm:3.0810318740748244e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:29:45 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 10 loss:1.5982026368988045e-08 norm:2.9900268927463003e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:30:01 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 11 loss:1.5856867818797582e-08 norm:2.846494373542896e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:30:17 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 12 loss:1.588625231363494e-08 norm:2.7756468234940712e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:30:34 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 13 loss:1.5929073171605523e-08 norm:2.714242830492708e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:30:50 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 14 loss:1.5786213225510437e-08 norm:2.6382940276903355e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:31:06 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 15 loss:1.5817681386920412e-08 norm:2.5942246129062596e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:31:21 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 16 loss:1.5874768166668218e-08 norm:2.5304411899185197e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:31:37 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 17 loss:1.5873643732788878e-08 norm:2.4938626719261947e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:31:53 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 18 loss:1.5578603296262372e-08 norm:2.4335213844040027e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:32:09 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 19 loss:1.547574157712006e-08 norm:2.3959514372506874e-09 max memory_allocated 26699.74560546875 
[2025-03-22 16:32:19 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 17 ===
[2025-03-22 16:32:37 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 0 loss:1.0340948541909256e-08 norm:3.3472198346373716e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:32:53 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 1 loss:1.0332161792803163e-08 norm:3.098750145369422e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:33:09 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 2 loss:1.0405845074501485e-08 norm:2.965606871185855e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:33:25 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 3 loss:1.0781090686862171e-08 norm:2.8825879461180648e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:33:41 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 4 loss:1.0879615430781087e-08 norm:2.703844037554859e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:33:57 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 5 loss:1.1170878444488608e-08 norm:2.548101729615837e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:34:13 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 6 loss:1.123256598845046e-08 norm:2.432495094240039e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:34:29 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 7 loss:1.1294458701627264e-08 norm:2.380654340328192e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:34:45 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 8 loss:1.1384887699250612e-08 norm:2.3234225654533702e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:35:01 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 9 loss:1.1342915939849263e-08 norm:2.2500830088034718e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:35:16 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 10 loss:1.1353215256804106e-08 norm:2.2051021009161786e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:35:32 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 11 loss:1.141753180888827e-08 norm:2.145920330320905e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:35:48 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 12 loss:1.1413931133574806e-08 norm:2.097180873406046e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:36:04 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 13 loss:1.1400051569410152e-08 norm:2.040725588514647e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:36:20 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 14 loss:1.1389351683988025e-08 norm:1.9734698319950894e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:36:36 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 15 loss:1.1556570811421807e-08 norm:1.9594845745984912e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:36:52 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 16 loss:1.1523900056431557e-08 norm:1.908420532714672e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:37:08 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 17 loss:1.165664009761258e-08 norm:1.9174823950862674e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:37:24 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 18 loss:1.1680227451904557e-08 norm:1.8790615730068794e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:37:39 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 19 loss:1.1750330486393068e-08 norm:1.8549085600838566e-09 max memory_allocated 26699.94873046875 
[2025-03-22 16:37:49 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 18 ===
[2025-03-22 16:38:07 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 0 loss:1.1284354783924755e-08 norm:3.0182847332582696e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:38:23 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 1 loss:1.1095895757762264e-08 norm:2.83242895804392e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:38:39 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 2 loss:1.0996357602266471e-08 norm:2.7464985841163525e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:38:55 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 3 loss:1.0969766428559069e-08 norm:2.7144566594472508e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:39:11 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 4 loss:1.088235990209796e-08 norm:2.6676598707808807e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:39:27 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 5 loss:1.083185985351065e-08 norm:2.6293398569521287e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:39:42 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 6 loss:1.106587355081956e-08 norm:2.6345388093318434e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:39:58 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 7 loss:1.1506704034047743e-08 norm:2.6609159320400977e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:40:14 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 8 loss:1.1834644375596781e-08 norm:2.6692013044282703e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:40:30 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 9 loss:1.2446134789456664e-08 norm:2.6324202817562536e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:40:46 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 10 loss:1.2648480485211167e-08 norm:2.5731454744715165e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:41:02 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 11 loss:1.2906197000006614e-08 norm:2.5155253435826808e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:41:18 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 12 loss:1.3163626633172498e-08 norm:2.523300013379526e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:41:34 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 13 loss:1.3514976693329572e-08 norm:2.475933680301523e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:41:49 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 14 loss:1.3623550287888975e-08 norm:2.4217778893387276e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:42:05 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 15 loss:1.379333536277727e-08 norm:2.4077122517951466e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:42:21 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 16 loss:1.3957979660972342e-08 norm:2.41974151826696e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:42:37 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 17 loss:1.3891495953544108e-08 norm:2.395768472496229e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:42:53 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 18 loss:1.3843015622683197e-08 norm:2.3338055932242696e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:43:09 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 19 loss:1.3784464236721305e-08 norm:2.298478518625302e-09 max memory_allocated 26700.15185546875 
[2025-03-22 16:43:18 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 19 ===
[2025-03-22 16:43:37 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 0 loss:1.8509169308345008e-08 norm:3.887119959244956e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:43:53 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 1 loss:1.771409330331153e-08 norm:3.576295259932749e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:44:09 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 2 loss:1.7231748472568142e-08 norm:3.387200298021753e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:44:25 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 3 loss:1.684328410078706e-08 norm:3.2188103293862014e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:44:41 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 4 loss:1.644011682344626e-08 norm:3.0813427365217194e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:44:57 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 5 loss:1.612847100318504e-08 norm:2.942457388854791e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:45:13 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 6 loss:1.589481080088717e-08 norm:2.8883495595266595e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:45:29 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 7 loss:1.5803033548422718e-08 norm:2.828943079791202e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:45:45 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 8 loss:1.567745044894764e-08 norm:2.721525893534249e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:46:01 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 9 loss:1.5454586943519644e-08 norm:2.6624646931594498e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:46:16 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 10 loss:1.5472892300749663e-08 norm:2.6715969436708065e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:46:32 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 11 loss:1.5371380612805297e-08 norm:2.6359929794494974e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:46:48 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 12 loss:1.531251747621809e-08 norm:2.5891715438319807e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:47:04 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 13 loss:1.534003146730356e-08 norm:2.5625839228382574e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:47:20 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 14 loss:1.5126028429790495e-08 norm:2.517192010387248e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:47:36 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 15 loss:1.5064777869611135e-08 norm:2.4221553651671e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:47:52 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 16 loss:1.4828627215024426e-08 norm:2.368105711525459e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:48:08 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 17 loss:1.4725103802959438e-08 norm:2.352674499661589e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:48:24 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 18 loss:1.4600187725477554e-08 norm:2.3277999527948623e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:48:40 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 19 loss:1.4452830932043526e-08 norm:2.3107336044603244e-09 max memory_allocated 26700.35498046875 
[2025-03-22 16:48:49 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 20 ===
[2025-03-22 16:49:08 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 0 loss:1.8825730307980848e-08 norm:5.782990086800055e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:49:24 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 1 loss:1.8634603193845578e-08 norm:5.8359579391265015e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:49:40 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 2 loss:1.87579249910641e-08 norm:5.8823670379126725e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:49:55 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 3 loss:1.8734812812226664e-08 norm:6.024144738603354e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:50:11 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 4 loss:1.8493770070904247e-08 norm:6.1082685576252516e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:50:27 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 5 loss:1.8056335093774578e-08 norm:6.169252220189492e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:50:43 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 6 loss:1.759913992316342e-08 norm:6.235515215280429e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:50:59 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 7 loss:1.7440648036881612e-08 norm:6.421911002973957e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:51:15 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 8 loss:1.674965588449595e-08 norm:6.566134747032493e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:51:31 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 9 loss:1.5842497091966834e-08 norm:6.722666867631233e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:51:47 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 10 loss:1.5864738855952965e-08 norm:6.926943019180953e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:52:02 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 11 loss:1.5188371449426086e-08 norm:6.8014762710788546e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:52:18 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 12 loss:1.4817293170210633e-08 norm:6.809327324219794e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:52:34 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 13 loss:1.4671894810192043e-08 norm:6.9402812385988e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:52:50 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 14 loss:1.3746664251357288e-08 norm:6.714173217403641e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:53:06 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 15 loss:1.3533529852338688e-08 norm:6.7195964348343296e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:53:22 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 16 loss:1.3438700818824145e-08 norm:6.751783132585842e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:53:37 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 17 loss:1.3500251583309364e-08 norm:6.8417485010741075e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:53:53 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 18 loss:1.3403137266720933e-08 norm:6.8849348444643965e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:54:09 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 19 loss:1.3421484368336678e-08 norm:6.9264656232803645e-09 max memory_allocated 26700.55810546875 
[2025-03-22 16:54:18 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 21 ===
[2025-03-22 16:54:38 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 0 loss:2.5307469897484225e-08 norm:7.441546490127848e-09 max memory_allocated 26700.76123046875 
[2025-03-22 16:54:54 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 1 loss:2.2580872283128883e-08 norm:7.242884958458262e-09 max memory_allocated 26700.76123046875 
[2025-03-22 16:55:10 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 2 loss:2.2170056013237627e-08 norm:7.566121063007358e-09 max memory_allocated 26700.76123046875 
[2025-03-22 16:55:25 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 3 loss:2.1622270196530735e-08 norm:8.04859645597844e-09 max memory_allocated 26700.76123046875 
[2025-03-22 16:55:41 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 4 loss:2.2162367940836702e-08 norm:8.833019649046037e-09 max memory_allocated 26700.76123046875 
[2025-03-22 16:55:57 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 5 loss:2.336526527813021e-08 norm:1.0034614028597844e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:56:13 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 6 loss:2.4938517029227114e-08 norm:1.1773143349103066e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:56:29 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 7 loss:2.593388614968717e-08 norm:1.3004724408460788e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:56:45 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 8 loss:2.478415872531059e-08 norm:1.456673093258587e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:57:01 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 9 loss:2.2947919120497318e-08 norm:1.4874943055076528e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:57:17 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 10 loss:1.6154457327388627e-08 norm:1.3760882211499847e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:57:32 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 11 loss:1.2697140228112858e-08 norm:1.2407061156238797e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:57:48 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 12 loss:8.887231395249273e-09 norm:1.0695326402299088e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:58:04 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 13 loss:8.305228504923434e-09 norm:1.1088984841478577e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:58:20 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 14 loss:8.174278143258107e-09 norm:1.1492787166389462e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:58:36 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 15 loss:7.792917422477785e-09 norm:1.2547571870413776e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:58:52 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 16 loss:7.853376615685193e-09 norm:1.3583563607255655e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:59:08 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 17 loss:7.928658618538975e-09 norm:1.4798841263541362e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:59:24 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 18 loss:7.780369237764262e-09 norm:1.5359695737515722e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:59:39 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 19 loss:7.572978688585863e-09 norm:1.6016670656426868e-08 max memory_allocated 26700.76123046875 
[2025-03-22 16:59:49 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 22 ===
[2025-03-22 17:00:07 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 0 loss:2.4115806240843085e-08 norm:6.352144588106512e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:00:23 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 1 loss:2.4043322000011358e-08 norm:6.625775483826146e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:00:39 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 2 loss:2.4430820033671807e-08 norm:6.89760160099695e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:00:55 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 3 loss:2.4765519412994763e-08 norm:7.191080619861623e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:01:11 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 4 loss:2.3803815807355022e-08 norm:7.364672427456753e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:01:27 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 5 loss:2.085135442086994e-08 norm:7.787195777098077e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:01:43 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 6 loss:1.881316791241261e-08 norm:8.743075596839844e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:01:59 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 7 loss:1.4554553118273361e-08 norm:9.223924735124456e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:02:15 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 8 loss:1.1107659680931192e-08 norm:8.815058016864441e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:02:30 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 9 loss:8.933968231872313e-09 norm:9.468925199485057e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:02:46 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 10 loss:8.317926791789887e-09 norm:8.555423036682441e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:03:02 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 11 loss:8.394852812898534e-09 norm:9.052622651495312e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:03:18 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 12 loss:8.256144212737127e-09 norm:9.599903982859814e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:03:34 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 13 loss:7.793655498744556e-09 norm:9.924487898160805e-09 max memory_allocated 26700.96435546875 
[2025-03-22 17:03:50 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 14 loss:7.58391482946763e-09 norm:1.0925458759913909e-08 max memory_allocated 26700.96435546875 
[2025-03-22 17:04:06 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 15 loss:7.431581572348023e-09 norm:1.123887649612243e-08 max memory_allocated 26700.96435546875 
[2025-03-22 17:04:22 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 16 loss:7.509916244430315e-09 norm:1.1565457924689326e-08 max memory_allocated 26700.96435546875 
[2025-03-22 17:04:37 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 17 loss:7.240894550619714e-09 norm:1.1931546417542904e-08 max memory_allocated 26700.96435546875 
[2025-03-22 17:04:53 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 18 loss:7.256349299211706e-09 norm:1.2125429549314504e-08 max memory_allocated 26700.96435546875 
[2025-03-22 17:05:09 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 19 loss:7.263929902023847e-09 norm:1.2221952339075415e-08 max memory_allocated 26700.96435546875 
[2025-03-22 17:05:18 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 23 ===
[2025-03-22 17:05:37 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 0 loss:3.090606170985666e-08 norm:6.196478885556189e-09 max memory_allocated 26701.16748046875 
[2025-03-22 17:05:53 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 1 loss:3.002574544552772e-08 norm:6.948239761328523e-09 max memory_allocated 26701.16748046875 
[2025-03-22 17:06:08 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 2 loss:2.7642643729564043e-08 norm:7.300658744213706e-09 max memory_allocated 26701.16748046875 
[2025-03-22 17:06:24 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 3 loss:2.6834440447487395e-08 norm:7.377847222045375e-09 max memory_allocated 26701.16748046875 
[2025-03-22 17:06:40 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 4 loss:2.6576460143701297e-08 norm:7.93750043470709e-09 max memory_allocated 26701.16748046875 
[2025-03-22 17:06:56 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 5 loss:2.5938511782896967e-08 norm:8.337737611441298e-09 max memory_allocated 26701.16748046875 
[2025-03-22 17:07:12 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 6 loss:2.470418891675763e-08 norm:9.13268749513918e-09 max memory_allocated 26701.16748046875 
[2025-03-22 17:07:28 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 7 loss:2.4142650545400102e-08 norm:1.0772396308311727e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:07:44 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 8 loss:1.9981651888656415e-08 norm:1.2222074019518914e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:07:59 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 9 loss:1.2548384553667802e-08 norm:1.3374062746152049e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:08:15 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 10 loss:9.800206868249006e-09 norm:1.210929934103433e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:08:31 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 11 loss:7.989525485641025e-09 norm:1.4579774720857586e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:08:47 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 12 loss:7.296848014703983e-09 norm:1.6518615808536197e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:09:03 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 13 loss:7.14201187079766e-09 norm:1.950774830561386e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:09:18 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 14 loss:6.606804436870561e-09 norm:2.081880445814477e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:09:34 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 15 loss:6.256817730587727e-09 norm:2.1582822640198174e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:09:50 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 16 loss:6.345454828249331e-09 norm:2.2227780505090777e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:10:06 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 17 loss:6.267554919503482e-09 norm:2.1693349339102497e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:10:22 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 18 loss:6.291252852008711e-09 norm:2.1832828878132204e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:10:38 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 19 loss:6.273705999149115e-09 norm:2.1943305839045024e-08 max memory_allocated 26701.16748046875 
[2025-03-22 17:10:47 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 24 ===
[2025-03-22 17:11:06 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 0 loss:3.087155775460815e-08 norm:7.923675049426038e-09 max memory_allocated 26701.37060546875 
[2025-03-22 17:11:22 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 1 loss:3.1092191932202695e-08 norm:8.43535286065844e-09 max memory_allocated 26701.37060546875 
[2025-03-22 17:11:37 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 2 loss:3.101057544085961e-08 norm:9.02638674915579e-09 max memory_allocated 26701.37060546875 
[2025-03-22 17:11:53 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 3 loss:2.9857165628754956e-08 norm:9.673867040760342e-09 max memory_allocated 26701.37060546875 
[2025-03-22 17:12:09 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 4 loss:2.8119263362214042e-08 norm:1.1013662870595908e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:12:25 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 5 loss:2.75153535511663e-08 norm:1.2973427665485815e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:12:41 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 6 loss:2.0148467783087654e-08 norm:1.4324738728532793e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:12:57 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 7 loss:1.1202333283222288e-08 norm:1.437968766282438e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:13:13 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 8 loss:9.369345299603538e-09 norm:1.4253595637114813e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:13:28 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 9 loss:8.768577863804694e-09 norm:1.741230448715214e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:13:44 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 10 loss:7.074174579457804e-09 norm:1.9808110707231208e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:14:00 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 11 loss:6.72907418675095e-09 norm:1.9787941951676657e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:14:16 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 12 loss:6.829297571897541e-09 norm:2.0791985022583503e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:14:32 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 13 loss:6.8260805896613874e-09 norm:2.0813164525179673e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:14:48 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 14 loss:6.827156617816854e-09 norm:2.08778896393369e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:15:03 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 15 loss:6.824362852597687e-09 norm:2.08876009821779e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:15:19 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 16 loss:6.818499542760037e-09 norm:2.0877305217936737e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:15:35 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 17 loss:6.785223050087552e-09 norm:2.0779816978233612e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:15:51 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 18 loss:6.7815313364860685e-09 norm:2.0786050214383067e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:16:07 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 19 loss:6.776577521350191e-09 norm:2.075891103459071e-08 max memory_allocated 26701.37060546875 
[2025-03-22 17:16:16 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 25 ===
[2025-03-22 17:16:35 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 0 loss:3.9153853492734925e-08 norm:5.3687974066463084e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:16:51 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 1 loss:3.943583948284868e-08 norm:5.4754796252609594e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:17:06 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 2 loss:3.9730192469278336e-08 norm:5.576195505341275e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:17:22 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 3 loss:3.998756525902536e-08 norm:5.57117463273471e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:17:38 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 4 loss:4.03521553948849e-08 norm:5.732810226533047e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:17:54 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 5 loss:4.0373326015696875e-08 norm:5.79879078088652e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:18:10 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 6 loss:4.035642220401314e-08 norm:5.777982536869786e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:18:25 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 7 loss:4.0328036021719527e-08 norm:5.667712965617966e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:18:41 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 8 loss:4.062204794763602e-08 norm:5.605045316769974e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:18:57 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 9 loss:4.0860573591317007e-08 norm:5.668705949091191e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:19:13 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 10 loss:4.0858061822746095e-08 norm:5.668074010145574e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:19:29 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 11 loss:4.0879736928900456e-08 norm:5.747796461008647e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:19:45 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 12 loss:4.108515838652238e-08 norm:5.71695490947377e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:20:01 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 13 loss:4.129785224904481e-08 norm:5.7493450000833946e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:20:17 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 14 loss:4.1420367580258244e-08 norm:5.7321249968822485e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:20:33 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 15 loss:4.155093336066784e-08 norm:5.596125340900926e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:20:48 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 16 loss:4.11109297715484e-08 norm:5.487073018173305e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:21:04 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 17 loss:4.125824304423986e-08 norm:5.465838004425905e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:21:20 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 18 loss:4.1242650183903606e-08 norm:5.354501730892025e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:21:36 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 19 loss:4.107844020495577e-08 norm:5.291331817147693e-09 max memory_allocated 26701.57373046875 
[2025-03-22 17:21:45 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 26 ===
[2025-03-22 17:22:04 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 0 loss:2.3380808400474962e-08 norm:4.415462662166192e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:22:20 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 1 loss:2.1995115062622972e-08 norm:4.547966447887575e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:22:36 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 2 loss:2.2317237835522974e-08 norm:4.768530459386966e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:22:52 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 3 loss:2.3292447082212675e-08 norm:4.950027943095847e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:23:08 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 4 loss:2.361130491124186e-08 norm:5.197844821225317e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:23:23 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 5 loss:2.45852760372145e-08 norm:5.537007297107266e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:23:39 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 6 loss:2.4545025567590528e-08 norm:6.076151581879685e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:23:55 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 7 loss:2.3846197905186273e-08 norm:6.512950623260849e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:24:11 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 8 loss:2.2307764524498452e-08 norm:6.877803215843414e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:24:27 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 9 loss:2.0912583664767226e-08 norm:7.2527708283587344e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:24:43 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 10 loss:1.7697605159128216e-08 norm:7.903653731489158e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:24:59 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 11 loss:1.5213736048735882e-08 norm:9.230494590894978e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:25:15 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 12 loss:1.3441425750215785e-08 norm:9.192075545172429e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:25:30 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 13 loss:9.538529965880116e-09 norm:9.473627216038949e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:25:46 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 14 loss:8.727949918352351e-09 norm:9.934887579277074e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:26:02 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 15 loss:8.424493103120767e-09 norm:1.0080016821234494e-08 max memory_allocated 26701.77685546875 
[2025-03-22 17:26:18 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 16 loss:8.114982463780507e-09 norm:9.591812677456346e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:26:34 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 17 loss:8.099924286852911e-09 norm:9.926274913141242e-09 max memory_allocated 26701.77685546875 
[2025-03-22 17:26:49 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 18 loss:7.799559220700303e-09 norm:1.0098487379650578e-08 max memory_allocated 26701.77685546875 
[2025-03-22 17:27:05 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 19 loss:7.74968889061256e-09 norm:1.033913132886255e-08 max memory_allocated 26701.77685546875 
[2025-03-22 17:27:15 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 27 ===
[2025-03-22 17:27:33 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 0 loss:1.9083119084939426e-08 norm:3.2691487295011257e-09 max memory_allocated 26701.97998046875 
[2025-03-22 17:27:49 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 1 loss:1.841867636187544e-08 norm:3.5278802101856854e-09 max memory_allocated 26701.97998046875 
[2025-03-22 17:28:05 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 2 loss:1.7432666865602187e-08 norm:3.750107335775965e-09 max memory_allocated 26701.97998046875 
[2025-03-22 17:28:21 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 3 loss:1.631054225015305e-08 norm:3.986365015862248e-09 max memory_allocated 26701.97998046875 
[2025-03-22 17:28:37 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 4 loss:1.6672839109332926e-08 norm:4.2234749031422325e-09 max memory_allocated 26701.97998046875 
[2025-03-22 17:28:53 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 5 loss:1.7345334057949913e-08 norm:4.484139282112665e-09 max memory_allocated 26701.97998046875 
[2025-03-22 17:29:09 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 6 loss:1.6643969757978994e-08 norm:4.97113683550765e-09 max memory_allocated 26701.97998046875 
[2025-03-22 17:29:25 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 7 loss:1.5394803654089628e-08 norm:5.989098106340407e-09 max memory_allocated 26701.97998046875 
[2025-03-22 17:29:41 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 8 loss:1.5555665200395197e-08 norm:7.848367289398084e-09 max memory_allocated 26701.97998046875 
[2025-03-22 17:29:57 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 9 loss:1.3405492715889977e-08 norm:9.62527124670487e-09 max memory_allocated 26701.97998046875 
[2025-03-22 17:30:13 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 10 loss:1.1425258072961242e-08 norm:1.0460666111100636e-08 max memory_allocated 26701.97998046875 
[2025-03-22 17:30:28 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 11 loss:1.0791090687689575e-08 norm:1.1480079109560393e-08 max memory_allocated 26701.97998046875 
[2025-03-22 17:30:44 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 12 loss:1.0692698282355195e-08 norm:1.2629729262414457e-08 max memory_allocated 26701.97998046875 
[2025-03-22 17:31:00 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 13 loss:1.0444349385352325e-08 norm:1.3153569788926234e-08 max memory_allocated 26701.97998046875 
[2025-03-22 17:31:16 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 14 loss:1.0556046703413813e-08 norm:1.366656832146873e-08 max memory_allocated 26701.97998046875 
[2025-03-22 17:31:32 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 15 loss:1.0516006732075311e-08 norm:1.4595596731226124e-08 max memory_allocated 26701.97998046875 
[2025-03-22 17:31:48 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 16 loss:1.0374427539261433e-08 norm:1.453175002552598e-08 max memory_allocated 26701.97998046875 
[2025-03-22 17:32:04 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 17 loss:1.0366989044996444e-08 norm:1.4702345119133042e-08 max memory_allocated 26701.97998046875 
[2025-03-22 17:32:20 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 18 loss:1.0361842051054282e-08 norm:1.48905456853754e-08 max memory_allocated 26701.97998046875 
[2025-03-22 17:32:35 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 19 loss:1.0186368193387807e-08 norm:1.502341895331938e-08 max memory_allocated 26701.97998046875 
[2025-03-22 17:32:44 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 28 ===
[2025-03-22 17:32:47 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 17:33:03 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 0 loss:1.7763683857197066e-08 norm:3.6160892058489935e-09 max memory_allocated 26702.18310546875 
[2025-03-22 17:33:19 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 1 loss:1.724372289402254e-08 norm:3.793234615301344e-09 max memory_allocated 26702.18310546875 
[2025-03-22 17:33:35 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 2 loss:1.7023641163405046e-08 norm:4.060718872267444e-09 max memory_allocated 26702.18310546875 
[2025-03-22 17:33:51 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 3 loss:1.6181417095140205e-08 norm:4.304675726984897e-09 max memory_allocated 26702.18310546875 
[2025-03-22 17:34:07 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 4 loss:1.5825158072857448e-08 norm:4.662587649306715e-09 max memory_allocated 26702.18310546875 
[2025-03-22 17:34:23 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 5 loss:1.644373348597128e-08 norm:4.818057952604704e-09 max memory_allocated 26702.18310546875 
[2025-03-22 17:34:39 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 6 loss:1.6268574043465378e-08 norm:5.506997080573228e-09 max memory_allocated 26702.18310546875 
[2025-03-22 17:34:55 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 7 loss:1.6755720366745663e-08 norm:6.0419531600075516e-09 max memory_allocated 26702.18310546875 
[2025-03-22 17:35:11 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 8 loss:1.582047026715827e-08 norm:8.197774903351274e-09 max memory_allocated 26702.18310546875 
[2025-03-22 17:35:26 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 9 loss:1.4153063609967376e-08 norm:1.1659917475981274e-08 max memory_allocated 26702.18310546875 
[2025-03-22 17:35:42 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 10 loss:1.2471486954268585e-08 norm:1.471010957487806e-08 max memory_allocated 26702.18310546875 
[2025-03-22 17:35:58 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 11 loss:1.1157076151846468e-08 norm:1.5540774001010504e-08 max memory_allocated 26702.18310546875 
[2025-03-22 17:36:14 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 12 loss:1.0354956003766347e-08 norm:1.6235793154351086e-08 max memory_allocated 26702.18310546875 
[2025-03-22 17:36:30 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 13 loss:1.0489286772497053e-08 norm:1.636642465996374e-08 max memory_allocated 26702.18310546875 
[2025-03-22 17:36:46 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 14 loss:1.045653874598429e-08 norm:1.713262065550225e-08 max memory_allocated 26702.18310546875 
[2025-03-22 17:37:02 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 15 loss:1.0511882919672644e-08 norm:1.7378862793293592e-08 max memory_allocated 26702.18310546875 
[2025-03-22 17:37:18 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 16 loss:1.051100717575082e-08 norm:1.752509781738354e-08 max memory_allocated 26702.18310546875 
[2025-03-22 17:37:34 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 17 loss:1.0337776856772507e-08 norm:1.7627083792604026e-08 max memory_allocated 26702.18310546875 
[2025-03-22 17:37:50 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 18 loss:1.0364847646826547e-08 norm:1.7970720023186004e-08 max memory_allocated 26702.18310546875 
[2025-03-22 17:38:06 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 19 loss:1.034979213443421e-08 norm:1.797325310803899e-08 max memory_allocated 26702.18310546875 
[2025-03-22 17:38:15 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 29 ===
[2025-03-22 17:38:18 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 17:38:34 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 0 loss:2.0281960999568582e-08 norm:3.762165690091024e-09 max memory_allocated 26702.38623046875 
[2025-03-22 17:38:50 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 1 loss:1.8878246521580877e-08 norm:4.35208491467165e-09 max memory_allocated 26702.38623046875 
[2025-03-22 17:39:06 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 2 loss:1.9220461666691335e-08 norm:4.573888823244943e-09 max memory_allocated 26702.38623046875 
[2025-03-22 17:39:22 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 3 loss:1.928812132234725e-08 norm:5.034399119807631e-09 max memory_allocated 26702.38623046875 
[2025-03-22 17:39:38 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 4 loss:1.775345204180212e-08 norm:7.892704267931094e-09 max memory_allocated 26702.38623046875 
[2025-03-22 17:39:53 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 5 loss:1.3999192027824847e-08 norm:5.4146489958384336e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:40:09 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 6 loss:1.1493232143777732e-08 norm:8.29756885423194e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:40:25 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 7 loss:1.1309848169105408e-08 norm:7.729912709919518e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:40:41 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 8 loss:1.1363055385515963e-08 norm:7.827085823919333e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:40:57 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 9 loss:1.135246385786104e-08 norm:7.443489380420942e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:41:13 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 10 loss:1.0793618443472042e-08 norm:7.629441256540304e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:41:29 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 11 loss:1.0843523412518152e-08 norm:7.338211105434311e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:41:44 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 12 loss:1.0752118306811553e-08 norm:7.803471646639082e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:42:00 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 13 loss:1.0770868641429843e-08 norm:7.835686233192973e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:42:16 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 14 loss:1.0734957811564527e-08 norm:7.804146662238054e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:42:32 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 15 loss:1.0689921836615213e-08 norm:7.034342530687354e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:42:48 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 16 loss:1.0644473746879157e-08 norm:7.985769912011165e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:43:05 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 17 loss:1.0682452256105535e-08 norm:7.912019839295681e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:43:21 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 18 loss:1.0616265200269481e-08 norm:7.650309896689578e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:43:37 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 19 loss:1.0622060564458025e-08 norm:7.500503329538333e-08 max memory_allocated 26702.38623046875 
[2025-03-22 17:43:46 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 30 ===
[2025-03-22 17:43:49 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 17:44:05 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 0 loss:9.079131224609682e-09 norm:2.7022077908611664e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:44:21 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 1 loss:9.082343765953738e-09 norm:2.7343349806585593e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:44:37 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 2 loss:9.144286217122044e-09 norm:2.8228019921527903e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:44:53 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 3 loss:9.165036729541498e-09 norm:2.9317754890456627e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:45:09 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 4 loss:9.132532952094152e-09 norm:2.9247975152912886e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:45:24 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 5 loss:9.081674079425284e-09 norm:2.9216440378121433e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:45:40 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 6 loss:9.035558967696034e-09 norm:3.0544848872438024e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:45:56 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 7 loss:9.055955985104447e-09 norm:3.1785594156730212e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:46:12 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 8 loss:9.011174029183167e-09 norm:3.1813807144231987e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:46:28 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 9 loss:8.925795214054233e-09 norm:3.3080018724263027e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:46:45 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 10 loss:8.97538310340451e-09 norm:3.5128020492436463e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:47:00 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 11 loss:8.872188317354812e-09 norm:3.544746718375791e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:47:16 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 12 loss:8.93741436414075e-09 norm:3.63807695080709e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:47:32 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 13 loss:8.9077643039559e-09 norm:3.618078503464517e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:47:48 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 14 loss:8.881530177973218e-09 norm:3.799596193232446e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:48:04 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 15 loss:8.701782405751146e-09 norm:3.790774361078775e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:48:20 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 16 loss:8.72131700191403e-09 norm:3.849014884593771e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:48:36 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 17 loss:8.815540297746338e-09 norm:3.906687862098579e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:48:52 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 18 loss:8.978727095154682e-09 norm:3.891627908814144e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:49:08 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 19 loss:8.956627439715703e-09 norm:3.903794176807196e-09 max memory_allocated 26702.58935546875 
[2025-03-22 17:49:17 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 31 ===
[2025-03-22 17:49:21 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 17:49:37 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 0 loss:2.1216020940073577e-08 norm:1.5401739883458276e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:49:53 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 1 loss:2.1238147240865146e-08 norm:1.5442248590957774e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:50:09 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 2 loss:2.123842790524577e-08 norm:1.5420871246618617e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:50:25 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 3 loss:2.1258799165480013e-08 norm:1.5381282914006533e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:50:41 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 4 loss:2.1317083209737575e-08 norm:1.5408622155987928e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:50:57 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 5 loss:2.1302104968867752e-08 norm:1.5355817728490706e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:51:13 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 6 loss:2.1236202130126003e-08 norm:1.5146085496908768e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:51:29 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 7 loss:2.129130116657052e-08 norm:1.5238361683600488e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:51:44 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 8 loss:2.1312350995117413e-08 norm:1.5223056148983005e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:52:00 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 9 loss:2.1331310051664332e-08 norm:1.5200463110431883e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:52:16 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 10 loss:2.1246748360681522e-08 norm:1.5012344700693347e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:52:32 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 11 loss:2.1218724555183144e-08 norm:1.4874794729280438e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:52:48 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 12 loss:2.1225217139431152e-08 norm:1.4827514771553751e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:53:04 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 13 loss:2.1147405604438063e-08 norm:1.4666947656394314e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:53:20 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 14 loss:2.1087721790991054e-08 norm:1.4503240830521236e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:53:36 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 15 loss:2.107135443907282e-08 norm:1.4401270176378489e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:53:52 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 16 loss:2.1009224582257957e-08 norm:1.4324886832284278e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:54:08 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 17 loss:2.1009016748507747e-08 norm:1.4246979151977257e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:54:24 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 18 loss:2.0992562355104383e-08 norm:1.4157638394962646e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:54:39 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 19 loss:2.0990810867260734e-08 norm:1.4042970120087261e-09 max memory_allocated 26702.79248046875 
[2025-03-22 17:54:49 root] (main_calibration_a2.py 372): INFO 10542.69388794899
[2025-03-22 17:54:54 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-22 17:56:04 root] (main_calibration_a2.py 158): INFO wikitext2 : nan
[2025-03-22 17:56:04 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-22 17:57:52 root] (main_calibration_a2.py 158): INFO c4 : nan
