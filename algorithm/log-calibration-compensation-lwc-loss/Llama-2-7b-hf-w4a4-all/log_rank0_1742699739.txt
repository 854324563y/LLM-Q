[2025-03-23 03:15:39 root] (main_calibration_a2.py 276): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-calibration-compensation-lwc-loss/Llama-2-7b-hf-w4a4-all', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, scale_calibration=True, compensation_calibration=True, rank=1, loss_type='all')
[2025-03-23 03:16:51 root] (main_calibration_a2.py 343): INFO === start quantization ===
[2025-03-23 03:16:51 root] (main_calibration_a2.py 349): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-23 03:16:51 root] (abq_llm_calibration_a2.py 62): INFO Starting ...
[2025-03-23 03:16:54 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 0 ===
[2025-03-23 03:16:58 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-23 03:17:13 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 0 loss:3.804273562835192e-11 norm:1.0137251281461257e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:17:29 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 1 loss:3.818372354413846e-11 norm:1.013670701197067e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:17:45 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 2 loss:3.826489819447332e-11 norm:1.0136201773758291e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:18:01 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 3 loss:3.818092370044823e-11 norm:1.01383213890055e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:18:17 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 4 loss:3.7993674179004344e-11 norm:1.013988697694257e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:18:33 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 5 loss:3.8451242190262747e-11 norm:1.0138149000860075e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:18:49 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 6 loss:3.8266136787035165e-11 norm:1.014036727850498e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:19:04 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 7 loss:3.8199450547171665e-11 norm:1.0142301495180694e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:19:20 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 8 loss:3.823121680346375e-11 norm:1.0142474967528292e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:19:36 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 9 loss:3.802129444618885e-11 norm:1.014285335408649e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:19:52 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 10 loss:3.8002875152320925e-11 norm:1.0141746383668382e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:20:08 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 11 loss:3.803565448712298e-11 norm:1.0142237527252518e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:20:23 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 12 loss:3.7861120488758004e-11 norm:1.0100488154196618e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:20:39 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 13 loss:3.7754212950380506e-11 norm:1.009687667676007e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:20:55 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 14 loss:3.820395041986835e-11 norm:1.0098880282374822e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:21:11 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 15 loss:3.833548062326386e-11 norm:1.009814627750405e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:21:27 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 16 loss:3.8153428333354e-11 norm:1.0094821029441037e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:21:43 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 17 loss:3.8057303836103173e-11 norm:1.0098586463586079e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:21:59 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 18 loss:3.806965853669908e-11 norm:1.010525213854252e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:22:14 root] (abq_llm_calibration_a2.py 401): INFO layer 0 iter 19 loss:3.8013391046032297e-11 norm:1.0105903744048184e-12 max memory_allocated 26052.77783203125 
[2025-03-23 03:22:23 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 1 ===
[2025-03-23 03:22:27 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-23 03:22:43 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 0 loss:6.246025363587648e-10 norm:2.5498124445189063e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:22:58 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 1 loss:6.246502204376725e-10 norm:2.5435615419455715e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:23:14 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 2 loss:6.244872952088087e-10 norm:2.5515537599440918e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:23:30 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 3 loss:6.241317462851725e-10 norm:2.5438862821802743e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:23:46 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 4 loss:6.24252594061403e-10 norm:2.5337565379146554e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:24:02 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 5 loss:6.240559180525906e-10 norm:2.5376232365426077e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:24:18 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 6 loss:6.240661876155684e-10 norm:2.5262299196970872e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:24:34 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 7 loss:6.239918581840698e-10 norm:2.5176765186540884e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:24:50 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 8 loss:6.238517480383621e-10 norm:2.5090650043746443e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:25:06 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 9 loss:6.240647443256364e-10 norm:2.507271820717527e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:25:22 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 10 loss:6.239697647458797e-10 norm:2.4997830194717352e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:25:38 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 11 loss:6.233789040521742e-10 norm:2.501871279592116e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:25:53 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 12 loss:6.236262617420607e-10 norm:2.5333055098109014e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:26:09 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 13 loss:6.23379570185989e-10 norm:2.542006535821706e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:26:25 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 14 loss:6.23394447174519e-10 norm:2.5407847700775754e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:26:41 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 15 loss:6.235348348759828e-10 norm:2.5579259196883974e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:26:57 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 16 loss:6.234012195349692e-10 norm:2.5659563016033893e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:27:13 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 17 loss:6.232501181813177e-10 norm:2.5572852863087192e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:27:29 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 18 loss:6.233763505392176e-10 norm:2.5489017146940185e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:27:45 root] (abq_llm_calibration_a2.py 401): INFO layer 1 iter 19 loss:6.229252114131612e-10 norm:2.540641828863155e-11 max memory_allocated 26696.69873046875 
[2025-03-23 03:27:54 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 2 ===
[2025-03-23 03:27:57 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-23 03:28:13 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 0 loss:4.6476625215063905e-08 norm:7.374148847105744e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:28:29 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 1 loss:4.6927976171673436e-08 norm:6.234228688839494e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:28:45 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 2 loss:4.8231335370019224e-08 norm:5.760225629813931e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:29:01 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 3 loss:4.8101277627665695e-08 norm:4.94756191571355e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:29:17 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 4 loss:4.7676611103497635e-08 norm:4.273000620003131e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:29:33 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 5 loss:4.8618474579598114e-08 norm:4.186258450999958e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:29:49 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 6 loss:4.9640842547660213e-08 norm:4.160348954229676e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:30:05 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 7 loss:4.9710472183051024e-08 norm:3.7881240366743896e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:30:21 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 8 loss:5.0162768161499116e-08 norm:3.705677542598096e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:30:37 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 9 loss:5.0776726823187346e-08 norm:3.6432907801753345e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:30:53 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 10 loss:5.1433573844406055e-08 norm:3.5129463782368475e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:31:09 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 11 loss:5.1937348644059966e-08 norm:3.3214289096861194e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:31:25 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 12 loss:5.147934700744372e-08 norm:3.052036401385294e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:31:41 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 13 loss:5.091571964044306e-08 norm:2.7435986815760316e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:31:57 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 14 loss:4.952459420337618e-08 norm:2.257095843560819e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:32:13 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 15 loss:4.919364826605488e-08 norm:2.0409662848663856e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:32:29 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 16 loss:4.926297947349667e-08 norm:1.944311378565544e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:32:45 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 17 loss:4.941747988596035e-08 norm:1.9316246380185476e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:33:01 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 18 loss:4.959397514880948e-08 norm:1.895965606735217e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:33:17 root] (abq_llm_calibration_a2.py 401): INFO layer 2 iter 19 loss:4.956785204512926e-08 norm:1.7851147227077035e-09 max memory_allocated 26696.90185546875 
[2025-03-23 03:33:27 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 3 ===
[2025-03-23 03:33:46 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 0 loss:1.552109019087311e-08 norm:5.1821369417837104e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:34:02 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 1 loss:1.5016976107062874e-08 norm:4.344109072462743e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:34:18 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 2 loss:1.550201922384531e-08 norm:4.182209245584545e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:34:34 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 3 loss:1.5781944640025358e-08 norm:4.194180558414473e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:34:50 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 4 loss:1.567492446952201e-08 norm:4.208635662195093e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:35:06 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 5 loss:1.4990790830893275e-08 norm:3.582563357085178e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:35:22 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 6 loss:1.4803330117274527e-08 norm:3.4108813551370076e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:35:38 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 7 loss:1.494833057336109e-08 norm:3.4206291132932165e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:35:54 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 8 loss:1.5462230606999583e-08 norm:3.4975333740305814e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:36:10 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 9 loss:1.602999510907921e-08 norm:3.4870395460018244e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:36:26 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 10 loss:1.6774443167832942e-08 norm:3.4749847444004445e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:36:42 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 11 loss:1.6660488100228577e-08 norm:3.3746050398519856e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:36:58 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 12 loss:1.7013105590990563e-08 norm:3.379952762117e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:37:14 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 13 loss:1.7281267972180103e-08 norm:3.434222239917517e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:37:29 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 14 loss:1.6935743474277842e-08 norm:3.1732652061577937e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:37:45 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 15 loss:1.6508721500940737e-08 norm:2.8548219344060044e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:38:01 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 16 loss:1.644159475233664e-08 norm:2.6886561865779868e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:38:17 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 17 loss:1.6441042305359588e-08 norm:2.5805597658745683e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:38:33 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 18 loss:1.6643788569581375e-08 norm:2.5463589015117805e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:38:49 root] (abq_llm_calibration_a2.py 401): INFO layer 3 iter 19 loss:1.6960198578885866e-08 norm:2.538697474463447e-09 max memory_allocated 26697.10498046875 
[2025-03-23 03:38:59 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 4 ===
[2025-03-23 03:39:18 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 0 loss:1.4974997242234167e-08 norm:3.1749576301365323e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:39:34 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 1 loss:1.4943932313826735e-08 norm:2.9697997394606546e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:39:50 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 2 loss:1.4876055942636413e-08 norm:2.7887996356668054e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:40:06 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 3 loss:1.4512939294775151e-08 norm:2.410758481730113e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:40:22 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 4 loss:1.3944244869890099e-08 norm:2.1763730817525584e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:40:38 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 5 loss:1.3771336959678138e-08 norm:1.9491968039631047e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:40:54 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 6 loss:1.3353421479678218e-08 norm:1.8656589606536045e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:41:10 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 7 loss:1.3424043210363834e-08 norm:1.937439986221534e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:41:26 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 8 loss:1.3830254275148945e-08 norm:2.003075039169744e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:41:42 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 9 loss:1.450687125981176e-08 norm:2.1892894164210475e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:41:58 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 10 loss:1.4894719235769571e-08 norm:2.3960873285489015e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:42:14 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 11 loss:1.5036842881954726e-08 norm:2.5179778262440777e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:42:30 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 12 loss:1.464139653961638e-08 norm:2.3637136692400418e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:42:46 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 13 loss:1.391107051773588e-08 norm:2.067568782848639e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:43:02 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 14 loss:1.3767500917083453e-08 norm:2.0075667794827723e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:43:18 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 15 loss:1.3543923316206019e-08 norm:2.00505545500107e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:43:34 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 16 loss:1.3250680552800986e-08 norm:1.944122196562148e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:43:50 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 17 loss:1.3046993707632737e-08 norm:1.8938670631740706e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:44:06 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 18 loss:1.2989888276138117e-08 norm:1.9341837020903085e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:44:22 root] (abq_llm_calibration_a2.py 401): INFO layer 4 iter 19 loss:1.287679829431454e-08 norm:1.9566048781172185e-09 max memory_allocated 26697.30810546875 
[2025-03-23 03:44:31 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 5 ===
[2025-03-23 03:44:50 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 0 loss:1.2936371085459086e-08 norm:2.2677653088720717e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:45:06 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 1 loss:1.2436116136882447e-08 norm:1.957246364980847e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:45:22 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 2 loss:1.208654953899213e-08 norm:1.7417098874261683e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:45:38 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 3 loss:1.2291222262206247e-08 norm:1.7533472451702892e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:45:54 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 4 loss:1.267228100232387e-08 norm:1.8403865098548522e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:46:10 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 5 loss:1.3097125162175871e-08 norm:1.9394703620889686e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:46:26 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 6 loss:1.3291655776015432e-08 norm:2.066940840705911e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:46:42 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 7 loss:1.3452672753544448e-08 norm:2.1028392360733505e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:46:58 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 8 loss:1.3244514818211428e-08 norm:2.0330821470793126e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:47:14 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 9 loss:1.3072948945591634e-08 norm:1.9718575661187288e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:47:30 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 10 loss:1.3060635239980911e-08 norm:1.9947621332505605e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:47:46 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 11 loss:1.2993394804539093e-08 norm:1.922279002641858e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:48:02 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 12 loss:1.2860602360831308e-08 norm:1.8218531128155746e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:48:18 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 13 loss:1.264242932563775e-08 norm:1.691640827417018e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:48:34 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 14 loss:1.2339336663558242e-08 norm:1.5168375444574167e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:48:50 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 15 loss:1.2131579296692507e-08 norm:1.4334939901772259e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:49:06 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 16 loss:1.1962473678295282e-08 norm:1.3728803649470933e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:49:22 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 17 loss:1.1753192197261342e-08 norm:1.2970161611391973e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:49:38 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 18 loss:1.1765274088304523e-08 norm:1.2853512698640657e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:49:54 root] (abq_llm_calibration_a2.py 401): INFO layer 5 iter 19 loss:1.1727176563169905e-08 norm:1.2700551721422926e-09 max memory_allocated 26697.51123046875 
[2025-03-23 03:50:04 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 6 ===
[2025-03-23 03:50:23 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 0 loss:1.455488263246707e-08 norm:2.730891290880777e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:50:39 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 1 loss:1.4175791207549082e-08 norm:2.4239872331577317e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:50:55 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 2 loss:1.3907534679447053e-08 norm:2.2433099822194436e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:51:11 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 3 loss:1.3477647442527996e-08 norm:1.9744945678468184e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:51:27 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 4 loss:1.3189721315143288e-08 norm:1.8342461993725578e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:51:43 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 5 loss:1.31867823327525e-08 norm:1.76640657656435e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:51:59 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 6 loss:1.3197728243596885e-08 norm:1.7292937082302728e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:52:15 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 7 loss:1.3203195869948559e-08 norm:1.674263616635585e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:52:31 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 8 loss:1.30626816030599e-08 norm:1.6101633359966172e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:52:47 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 9 loss:1.3172027024666022e-08 norm:1.6246874956493684e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:53:03 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 10 loss:1.3352474681482818e-08 norm:1.6228203225665538e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:53:19 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 11 loss:1.3251386654644648e-08 norm:1.5752761317600061e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:53:35 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 12 loss:1.3165029955075624e-08 norm:1.5212783255336149e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:53:51 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 13 loss:1.3138763854669833e-08 norm:1.4777524759423954e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:54:07 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 14 loss:1.3106592255951455e-08 norm:1.450738973396426e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:54:23 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 15 loss:1.3077376515013839e-08 norm:1.431488705350148e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:54:39 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 16 loss:1.3170568635700874e-08 norm:1.4459690111934265e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:54:55 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 17 loss:1.3354404693188826e-08 norm:1.457857834452625e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:55:11 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 18 loss:1.3496745054908388e-08 norm:1.4640737511228963e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:55:27 root] (abq_llm_calibration_a2.py 401): INFO layer 6 iter 19 loss:1.35962254788069e-08 norm:1.4620800126152744e-09 max memory_allocated 26697.71435546875 
[2025-03-23 03:55:37 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 7 ===
[2025-03-23 03:55:56 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 0 loss:1.2146669448043212e-08 norm:2.563520951071041e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:56:12 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 1 loss:1.1988791293049417e-08 norm:2.411736366170203e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:56:28 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 2 loss:1.176371089428585e-08 norm:2.2544073274843868e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:56:44 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 3 loss:1.1472305772031177e-08 norm:2.07816919228776e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:57:00 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 4 loss:1.1370604013904995e-08 norm:1.9777015580757507e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:57:16 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 5 loss:1.1441046332549831e-08 norm:1.8996009210070497e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:57:32 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 6 loss:1.156485573972077e-08 norm:1.85830495436079e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:57:48 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 7 loss:1.1510372210921105e-08 norm:1.7747459057915194e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:58:04 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 8 loss:1.1452970127834305e-08 norm:1.7399076623902943e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:58:20 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 9 loss:1.1454151405132507e-08 norm:1.7350096914725555e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:58:36 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 10 loss:1.1507836461532861e-08 norm:1.660305004591578e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:58:52 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 11 loss:1.1760771911895063e-08 norm:1.6891399390317474e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:59:08 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 12 loss:1.1641614783286514e-08 norm:1.6499628330279847e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:59:24 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 13 loss:1.1630258534012228e-08 norm:1.595374166107888e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:59:40 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 14 loss:1.154984019535732e-08 norm:1.5355027249697173e-09 max memory_allocated 26697.91748046875 
[2025-03-23 03:59:56 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 15 loss:1.1665133747840173e-08 norm:1.531411886190881e-09 max memory_allocated 26697.91748046875 
[2025-03-23 04:00:12 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 16 loss:1.1618665141099882e-08 norm:1.4889690591601834e-09 max memory_allocated 26697.91748046875 
[2025-03-23 04:00:28 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 17 loss:1.1577432346143723e-08 norm:1.4586346575029552e-09 max memory_allocated 26697.91748046875 
[2025-03-23 04:00:44 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 18 loss:1.1862187676570102e-08 norm:1.5252460405790202e-09 max memory_allocated 26697.91748046875 
[2025-03-23 04:01:00 root] (abq_llm_calibration_a2.py 401): INFO layer 7 iter 19 loss:1.2081572187128131e-08 norm:1.5589748381117374e-09 max memory_allocated 26697.91748046875 
[2025-03-23 04:01:10 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 8 ===
[2025-03-23 04:01:29 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 0 loss:1.0827966967497105e-08 norm:1.5353897042658105e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:01:45 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 1 loss:1.0638940395324425e-08 norm:1.4753331889494348e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:02:01 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 2 loss:1.0606725275863482e-08 norm:1.4354711863617808e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:02:17 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 3 loss:1.0787599258321734e-08 norm:1.3660521602787412e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:02:33 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 4 loss:1.0712079223651472e-08 norm:1.317964404279337e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:02:49 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 5 loss:1.0659588767225614e-08 norm:1.27683041917237e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:03:05 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 6 loss:1.0819622531244022e-08 norm:1.2732234155876654e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:03:21 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 7 loss:1.0835490726890384e-08 norm:1.240509917010968e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:03:37 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 8 loss:1.0903085545521662e-08 norm:1.244573333281096e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:03:53 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 9 loss:1.082599521140537e-08 norm:1.1977278058239449e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:04:09 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 10 loss:1.084687806240936e-08 norm:1.188199205692797e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:04:25 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 11 loss:1.0858601129370982e-08 norm:1.1784291320537932e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:04:41 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 12 loss:1.0788699711383742e-08 norm:1.168646956983821e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:04:57 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 13 loss:1.0834993346975352e-08 norm:1.160248452869439e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:05:13 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 14 loss:1.0890495616422413e-08 norm:1.172572372531988e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:05:29 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 15 loss:1.0828821395136856e-08 norm:1.1254375209546197e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:05:45 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 16 loss:1.0942167172345307e-08 norm:1.126630344572277e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:06:01 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 17 loss:1.0972983410795223e-08 norm:1.135167626564737e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:06:17 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 18 loss:1.0994242849449165e-08 norm:1.127497872843719e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:06:34 root] (abq_llm_calibration_a2.py 401): INFO layer 8 iter 19 loss:1.1171930047737533e-08 norm:1.1604995853176092e-09 max memory_allocated 26698.12060546875 
[2025-03-23 04:06:43 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 9 ===
[2025-03-23 04:07:02 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 0 loss:1.0689643836769847e-08 norm:2.408389043750958e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:07:18 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 1 loss:1.0668566474691943e-08 norm:2.178630831295436e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:07:34 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 2 loss:1.0344569645326374e-08 norm:1.9547985452561534e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:07:50 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 3 loss:1.0039666875627518e-08 norm:1.8443151450497908e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:08:06 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 4 loss:9.957636493140853e-09 norm:1.765633195205396e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:08:22 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 5 loss:9.8532444425814e-09 norm:1.7701451415774727e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:08:38 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 6 loss:9.829831171259684e-09 norm:1.7533443585904251e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:08:54 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 7 loss:9.79495329289648e-09 norm:1.7452747025359372e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:09:10 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 8 loss:9.772347375758272e-09 norm:1.7382348893590915e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:09:26 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 9 loss:9.774463904932418e-09 norm:1.7280451514167794e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:09:42 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 10 loss:9.757095575935182e-09 norm:1.7624863790643985e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:09:58 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 11 loss:9.80979031339757e-09 norm:1.7560843890152e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:10:14 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 12 loss:9.82901227075672e-09 norm:1.7542579611173892e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:10:30 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 13 loss:9.70775904107768e-09 norm:1.6877456099351207e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:10:46 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 14 loss:9.567344250172027e-09 norm:1.6523670209878105e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:11:02 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 15 loss:9.504585563036017e-09 norm:1.6378221001644988e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:11:18 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 16 loss:9.55528101087566e-09 norm:1.6412354808537089e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:11:35 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 17 loss:9.59695700686325e-09 norm:1.6271273217682847e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:11:51 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 18 loss:9.521386346023064e-09 norm:1.6045937911712826e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:12:07 root] (abq_llm_calibration_a2.py 401): INFO layer 9 iter 19 loss:9.356812213923149e-09 norm:1.5649801454742374e-09 max memory_allocated 26698.32373046875 
[2025-03-23 04:12:16 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 10 ===
[2025-03-23 04:12:35 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 0 loss:7.669613388827656e-09 norm:1.003277350086762e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:12:51 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 1 loss:7.68058860955989e-09 norm:1.002692151530482e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:13:07 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 2 loss:7.69267671785201e-09 norm:1.0058975874471798e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:13:23 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 3 loss:7.695041048805251e-09 norm:1.0070739797640726e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:13:39 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 4 loss:7.674201718543827e-09 norm:1.0044711729051414e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:13:55 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 5 loss:7.723275352589098e-09 norm:1.0104915793007763e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:14:11 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 6 loss:7.73890729277582e-09 norm:1.0123683003016026e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:14:27 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 7 loss:7.750937669470659e-09 norm:1.0130156713472616e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:14:43 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 8 loss:7.743776286872617e-09 norm:1.0183481835568386e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:14:59 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 9 loss:7.727780193533818e-09 norm:1.0151768314869969e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:15:15 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 10 loss:7.712087857214556e-09 norm:1.0128708982648504e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:15:31 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 11 loss:7.707773086451652e-09 norm:1.0099671099439433e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:15:47 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 12 loss:7.677909863446075e-09 norm:1.008125916079905e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:16:04 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 13 loss:7.673976121225223e-09 norm:1.0075046352753247e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:16:20 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 14 loss:7.668127466331498e-09 norm:1.0070470013445743e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:16:36 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 15 loss:7.67531993517423e-09 norm:1.009124228623648e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:16:52 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 16 loss:7.72869235277085e-09 norm:1.012356865004449e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:17:08 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 17 loss:7.696107751087311e-09 norm:1.0069250988564704e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:17:24 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 18 loss:7.67496466380635e-09 norm:1.0089887814146437e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:17:40 root] (abq_llm_calibration_a2.py 401): INFO layer 10 iter 19 loss:7.646343114231513e-09 norm:1.004069494214832e-09 max memory_allocated 26698.52685546875 
[2025-03-23 04:17:49 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 11 ===
[2025-03-23 04:18:08 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 0 loss:1.0922148518943686e-08 norm:1.7328591894738565e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:18:24 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 1 loss:1.1035145242033195e-08 norm:1.735997123830657e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:18:40 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 2 loss:1.1039344549601537e-08 norm:1.711944142002153e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:18:56 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 3 loss:1.0981567655221625e-08 norm:1.6899412980109219e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:19:12 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 4 loss:1.1056863868930122e-08 norm:1.72320080427113e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:19:28 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 5 loss:1.1107379016550567e-08 norm:1.7244398131666117e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:19:45 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 6 loss:1.1164894786475088e-08 norm:1.721661924136697e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:20:01 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 7 loss:1.1162533120057105e-08 norm:1.7124188733674828e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:20:17 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 8 loss:1.1109700714939663e-08 norm:1.685998674005873e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:20:33 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 9 loss:1.1131025878796663e-08 norm:1.6702734750850823e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:20:49 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 10 loss:1.1097054830599973e-08 norm:1.6588267426342895e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:21:05 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 11 loss:1.1030178548310232e-08 norm:1.6420241832904026e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:21:21 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 12 loss:1.0854539489457693e-08 norm:1.5793151231235925e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:21:37 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 13 loss:1.078947864385782e-08 norm:1.5318212254200603e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:21:53 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 14 loss:1.0774534153767945e-08 norm:1.5036172307247853e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:22:09 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 15 loss:1.0803171690554336e-08 norm:1.4860999097976446e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:22:25 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 16 loss:1.0865634614276587e-08 norm:1.5013990051215842e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:22:41 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 17 loss:1.083094325338152e-08 norm:1.488758671897017e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:22:57 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 18 loss:1.0811646689035115e-08 norm:1.4877341580898928e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:23:13 root] (abq_llm_calibration_a2.py 401): INFO layer 11 iter 19 loss:1.0797813310148285e-08 norm:1.4823327010304865e-09 max memory_allocated 26698.72998046875 
[2025-03-23 04:23:22 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 12 ===
[2025-03-23 04:23:42 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 0 loss:1.0063543776084316e-08 norm:1.8289303405083501e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:23:58 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 1 loss:1.0006098172254951e-08 norm:1.8032433324322028e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:24:14 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 2 loss:9.888581509187588e-09 norm:1.7549347530732007e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:24:30 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 3 loss:9.880984919163893e-09 norm:1.7464989454651914e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:24:46 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 4 loss:9.89082860058943e-09 norm:1.7595445100937468e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:25:02 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 5 loss:9.884303153739893e-09 norm:1.7544075081588062e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:25:18 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 6 loss:9.863457606229531e-09 norm:1.7512511440997969e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:25:34 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 7 loss:9.826996105744001e-09 norm:1.7453459788541181e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:25:50 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 8 loss:9.818597490607317e-09 norm:1.7433203769456895e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:26:06 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 9 loss:9.801596867475837e-09 norm:1.7367596250039696e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:26:22 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 10 loss:9.791079946808168e-09 norm:1.7366321714007427e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:26:38 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 11 loss:9.825272151431363e-09 norm:1.7383873229803726e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:26:54 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 12 loss:9.804365319610042e-09 norm:1.6938442870539916e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:27:10 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 13 loss:9.766884190298697e-09 norm:1.6806002145486332e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:27:26 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 14 loss:9.760601216157738e-09 norm:1.6705016259166428e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:27:42 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 15 loss:9.714513637959499e-09 norm:1.6561072513354702e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:27:59 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 16 loss:9.698887026843295e-09 norm:1.6600091301555153e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:28:15 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 17 loss:9.673700063217439e-09 norm:1.6506586097975173e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:28:31 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 18 loss:9.689153479541801e-09 norm:1.6513823641872705e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:28:47 root] (abq_llm_calibration_a2.py 401): INFO layer 12 iter 19 loss:9.687864732654816e-09 norm:1.63506430617133e-09 max memory_allocated 26698.93310546875 
[2025-03-23 04:28:56 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 13 ===
[2025-03-23 04:29:15 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 0 loss:1.0350886370247281e-08 norm:2.802206466867574e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:29:31 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 1 loss:1.0248015769320773e-08 norm:2.805621734935926e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:29:47 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 2 loss:1.0267329209057152e-08 norm:2.8592612721922706e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:30:03 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 3 loss:1.0237788394817926e-08 norm:2.8433864152077604e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:30:19 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 4 loss:1.014018380374182e-08 norm:2.80786083273199e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:30:35 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 5 loss:1.0096590230546099e-08 norm:2.7760944654176e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:30:51 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 6 loss:1.000494709302302e-08 norm:2.7274211777950086e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:31:07 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 7 loss:1.0058175625715648e-08 norm:2.727567727234259e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:31:23 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 8 loss:1.005986138835624e-08 norm:2.743757887557763e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:31:39 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 9 loss:1.0085725143937907e-08 norm:2.7472180086363096e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:31:56 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 10 loss:1.0079265422291428e-08 norm:2.7409536862421646e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:32:12 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 11 loss:1.0056942834069105e-08 norm:2.715267122255227e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:32:28 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 12 loss:9.966112379800052e-09 norm:2.6800823782480165e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:32:44 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 13 loss:9.936649725261759e-09 norm:2.677953858665205e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:33:00 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 14 loss:9.919858712237328e-09 norm:2.645021313085749e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:33:16 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 15 loss:9.879064677420502e-09 norm:2.6278623721509575e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:33:32 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 16 loss:9.84853087970805e-09 norm:2.62206412138255e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:33:48 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 17 loss:9.863556194034118e-09 norm:2.596468151594422e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:34:04 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 18 loss:9.886349516818882e-09 norm:2.6152484622343763e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:34:20 root] (abq_llm_calibration_a2.py 401): INFO layer 13 iter 19 loss:9.843985182556025e-09 norm:2.5974689066288192e-09 max memory_allocated 26699.13623046875 
[2025-03-23 04:34:29 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 14 ===
[2025-03-23 04:34:48 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 0 loss:1.1332266680597058e-08 norm:2.058526460402277e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:35:04 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 1 loss:1.1352386586338525e-08 norm:2.043038405119546e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:35:20 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 2 loss:1.1358882723300212e-08 norm:2.0213359874787784e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:35:36 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 3 loss:1.1444790004588867e-08 norm:2.0143842149877855e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:35:53 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 4 loss:1.1467477634141687e-08 norm:2.016812050698036e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:36:09 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 5 loss:1.1462440774323568e-08 norm:2.000488441566972e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:36:25 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 6 loss:1.158194340433738e-08 norm:2.0367849629110424e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:36:41 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 7 loss:1.1559333934485494e-08 norm:2.044048708071955e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:36:57 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 8 loss:1.1571687608125103e-08 norm:2.0429895553064625e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:37:13 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 9 loss:1.1638385366552484e-08 norm:2.0582313631223315e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:37:29 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 10 loss:1.165747143261342e-08 norm:2.0557879842897364e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:37:45 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 11 loss:1.1658375598244675e-08 norm:2.0638699638197977e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:38:01 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 12 loss:1.1681093425863764e-08 norm:2.0748625040312163e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:38:17 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 13 loss:1.172870156551653e-08 norm:2.0619608243066523e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:38:33 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 14 loss:1.1736075222756881e-08 norm:2.0526682575905397e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:38:49 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 15 loss:1.1724837989390835e-08 norm:2.0529495881049797e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:39:05 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 16 loss:1.1720288739525131e-08 norm:2.0496506714096085e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:39:21 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 17 loss:1.1664423205104413e-08 norm:2.0259998123606238e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:39:37 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 18 loss:1.1602214300410196e-08 norm:2.0096744268727207e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:39:53 root] (abq_llm_calibration_a2.py 401): INFO layer 14 iter 19 loss:1.1539606603605534e-08 norm:1.987880526854724e-09 max memory_allocated 26699.33935546875 
[2025-03-23 04:40:03 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 15 ===
[2025-03-23 04:40:22 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 0 loss:1.2257459047759767e-08 norm:3.26254534499526e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:40:38 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 1 loss:1.2149869554889392e-08 norm:3.1507241260442242e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:40:54 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 2 loss:1.2189568465714729e-08 norm:3.1213456264111983e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:41:10 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 3 loss:1.2070701771449421e-08 norm:3.002192050516328e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:41:26 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 4 loss:1.1881389205825599e-08 norm:2.8502009641329096e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:41:42 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 5 loss:1.1900363361405653e-08 norm:2.791128883572469e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:41:58 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 6 loss:1.196259891145246e-08 norm:2.778718366513999e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:42:14 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 7 loss:1.1867037130741664e-08 norm:2.670499377188662e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:42:30 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 8 loss:1.1850067593854874e-08 norm:2.6231405936272267e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:42:46 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 9 loss:1.1840644020821856e-08 norm:2.5543298587393792e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:43:02 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 10 loss:1.1877786754155295e-08 norm:2.526077791387138e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:43:18 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 11 loss:1.1868047877783283e-08 norm:2.4643955764958037e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:43:34 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 12 loss:1.1735784788413639e-08 norm:2.3901605139542426e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:43:50 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 13 loss:1.168996188738447e-08 norm:2.3420985151290097e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:44:06 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 14 loss:1.1670218569292956e-08 norm:2.3068504884093954e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:44:22 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 15 loss:1.1587756532094318e-08 norm:2.287167788495026e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:44:38 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 16 loss:1.1552195644526364e-08 norm:2.2701316382267578e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:44:55 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 17 loss:1.1587428794257448e-08 norm:2.2606367888755585e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:45:11 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 18 loss:1.1466358529332865e-08 norm:2.214294303470865e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:45:27 root] (abq_llm_calibration_a2.py 401): INFO layer 15 iter 19 loss:1.1466754656908051e-08 norm:2.1938957317502172e-09 max memory_allocated 26699.54248046875 
[2025-03-23 04:45:36 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 16 ===
[2025-03-23 04:45:55 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 0 loss:1.686940542811044e-08 norm:6.071408265029277e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:46:11 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 1 loss:1.7118127360049584e-08 norm:5.536631597635733e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:46:27 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 2 loss:1.7060376222843843e-08 norm:4.940469811032244e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:46:43 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 3 loss:1.659531356779098e-08 norm:4.148455801100681e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:46:59 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 4 loss:1.6404063885033793e-08 norm:3.900261447142839e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:47:15 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 5 loss:1.6434027472200796e-08 norm:3.763012124124998e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:47:31 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 6 loss:1.6331286545323564e-08 norm:3.6745062548249052e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:47:48 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 7 loss:1.6387318169108767e-08 norm:3.470000953242902e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:48:04 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 8 loss:1.607909538847707e-08 norm:3.2564722030059556e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:48:20 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 9 loss:1.5981573397993998e-08 norm:3.0810318740748244e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:48:36 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 10 loss:1.5982026368988045e-08 norm:2.9900268927463003e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:48:52 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 11 loss:1.5856867818797582e-08 norm:2.846494373542896e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:49:08 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 12 loss:1.588625231363494e-08 norm:2.7756468234940712e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:49:24 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 13 loss:1.5929073171605523e-08 norm:2.714242830492708e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:49:40 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 14 loss:1.5786213225510437e-08 norm:2.6382940276903355e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:49:56 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 15 loss:1.5817681386920412e-08 norm:2.5942246129062596e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:50:12 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 16 loss:1.5874768166668218e-08 norm:2.5304411899185197e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:50:28 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 17 loss:1.5873643732788878e-08 norm:2.4938626719261947e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:50:44 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 18 loss:1.5578603296262372e-08 norm:2.4335213844040027e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:51:00 root] (abq_llm_calibration_a2.py 401): INFO layer 16 iter 19 loss:1.547574157712006e-08 norm:2.3959514372506874e-09 max memory_allocated 26699.74560546875 
[2025-03-23 04:51:10 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 17 ===
[2025-03-23 04:51:29 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 0 loss:1.0340948541909256e-08 norm:3.3472198346373716e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:51:45 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 1 loss:1.0332161792803163e-08 norm:3.098750145369422e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:52:01 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 2 loss:1.0405845074501485e-08 norm:2.965606871185855e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:52:17 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 3 loss:1.0781090686862171e-08 norm:2.8825879461180648e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:52:33 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 4 loss:1.0879615430781087e-08 norm:2.703844037554859e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:52:49 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 5 loss:1.1170878444488608e-08 norm:2.548101729615837e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:53:05 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 6 loss:1.123256598845046e-08 norm:2.432495094240039e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:53:21 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 7 loss:1.1294458701627264e-08 norm:2.380654340328192e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:53:37 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 8 loss:1.1384887699250612e-08 norm:2.3234225654533702e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:53:53 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 9 loss:1.1342915939849263e-08 norm:2.2500830088034718e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:54:09 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 10 loss:1.1353215256804106e-08 norm:2.2051021009161786e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:54:25 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 11 loss:1.141753180888827e-08 norm:2.145920330320905e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:54:41 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 12 loss:1.1413931133574806e-08 norm:2.097180873406046e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:54:57 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 13 loss:1.1400051569410152e-08 norm:2.040725588514647e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:55:13 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 14 loss:1.1389351683988025e-08 norm:1.9734698319950894e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:55:30 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 15 loss:1.1556570811421807e-08 norm:1.9594845745984912e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:55:46 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 16 loss:1.1523900056431557e-08 norm:1.908420532714672e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:56:02 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 17 loss:1.165664009761258e-08 norm:1.9174823950862674e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:56:18 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 18 loss:1.1680227451904557e-08 norm:1.8790615730068794e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:56:34 root] (abq_llm_calibration_a2.py 401): INFO layer 17 iter 19 loss:1.1750330486393068e-08 norm:1.8549085600838566e-09 max memory_allocated 26699.94873046875 
[2025-03-23 04:56:43 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 18 ===
[2025-03-23 04:57:02 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 0 loss:1.1284354783924755e-08 norm:3.0182847332582696e-09 max memory_allocated 26700.15185546875 
[2025-03-23 04:57:18 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 1 loss:1.1095895757762264e-08 norm:2.83242895804392e-09 max memory_allocated 26700.15185546875 
[2025-03-23 04:57:34 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 2 loss:1.0996357602266471e-08 norm:2.7464985841163525e-09 max memory_allocated 26700.15185546875 
[2025-03-23 04:57:50 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 3 loss:1.0969766428559069e-08 norm:2.7144566594472508e-09 max memory_allocated 26700.15185546875 
[2025-03-23 04:58:06 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 4 loss:1.088235990209796e-08 norm:2.6676598707808807e-09 max memory_allocated 26700.15185546875 
[2025-03-23 04:58:22 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 5 loss:1.083185985351065e-08 norm:2.6293398569521287e-09 max memory_allocated 26700.15185546875 
[2025-03-23 04:58:38 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 6 loss:1.106587355081956e-08 norm:2.6345388093318434e-09 max memory_allocated 26700.15185546875 
[2025-03-23 04:58:55 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 7 loss:1.1506704034047743e-08 norm:2.6609159320400977e-09 max memory_allocated 26700.15185546875 
[2025-03-23 04:59:11 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 8 loss:1.1834644375596781e-08 norm:2.6692013044282703e-09 max memory_allocated 26700.15185546875 
[2025-03-23 04:59:27 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 9 loss:1.2446134789456664e-08 norm:2.6324202817562536e-09 max memory_allocated 26700.15185546875 
[2025-03-23 04:59:43 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 10 loss:1.2648480485211167e-08 norm:2.5731454744715165e-09 max memory_allocated 26700.15185546875 
[2025-03-23 04:59:59 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 11 loss:1.2906197000006614e-08 norm:2.5155253435826808e-09 max memory_allocated 26700.15185546875 
[2025-03-23 05:00:15 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 12 loss:1.3163626633172498e-08 norm:2.523300013379526e-09 max memory_allocated 26700.15185546875 
[2025-03-23 05:00:31 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 13 loss:1.3514976693329572e-08 norm:2.475933680301523e-09 max memory_allocated 26700.15185546875 
[2025-03-23 05:00:47 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 14 loss:1.3623550287888975e-08 norm:2.4217778893387276e-09 max memory_allocated 26700.15185546875 
[2025-03-23 05:01:03 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 15 loss:1.379333536277727e-08 norm:2.4077122517951466e-09 max memory_allocated 26700.15185546875 
[2025-03-23 05:01:19 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 16 loss:1.3957979660972342e-08 norm:2.41974151826696e-09 max memory_allocated 26700.15185546875 
[2025-03-23 05:01:35 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 17 loss:1.3891495953544108e-08 norm:2.395768472496229e-09 max memory_allocated 26700.15185546875 
[2025-03-23 05:01:51 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 18 loss:1.3843015622683197e-08 norm:2.3338055932242696e-09 max memory_allocated 26700.15185546875 
[2025-03-23 05:02:07 root] (abq_llm_calibration_a2.py 401): INFO layer 18 iter 19 loss:1.3784464236721305e-08 norm:2.298478518625302e-09 max memory_allocated 26700.15185546875 
[2025-03-23 05:02:16 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 19 ===
[2025-03-23 05:02:36 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 0 loss:1.8509169308345008e-08 norm:3.887119959244956e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:02:52 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 1 loss:1.771409330331153e-08 norm:3.576295259932749e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:03:08 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 2 loss:1.7231748472568142e-08 norm:3.387200298021753e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:03:24 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 3 loss:1.684328410078706e-08 norm:3.2188103293862014e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:03:40 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 4 loss:1.644011682344626e-08 norm:3.0813427365217194e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:03:56 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 5 loss:1.612847100318504e-08 norm:2.942457388854791e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:04:12 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 6 loss:1.589481080088717e-08 norm:2.8883495595266595e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:04:28 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 7 loss:1.5803033548422718e-08 norm:2.828943079791202e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:04:44 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 8 loss:1.567745044894764e-08 norm:2.721525893534249e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:05:00 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 9 loss:1.5454586943519644e-08 norm:2.6624646931594498e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:05:16 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 10 loss:1.5472892300749663e-08 norm:2.6715969436708065e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:05:32 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 11 loss:1.5371380612805297e-08 norm:2.6359929794494974e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:05:48 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 12 loss:1.531251747621809e-08 norm:2.5891715438319807e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:06:04 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 13 loss:1.534003146730356e-08 norm:2.5625839228382574e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:06:20 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 14 loss:1.5126028429790495e-08 norm:2.517192010387248e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:06:36 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 15 loss:1.5064777869611135e-08 norm:2.4221553651671e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:06:52 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 16 loss:1.4828627215024426e-08 norm:2.368105711525459e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:07:08 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 17 loss:1.4725103802959438e-08 norm:2.352674499661589e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:07:24 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 18 loss:1.4600187725477554e-08 norm:2.3277999527948623e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:07:40 root] (abq_llm_calibration_a2.py 401): INFO layer 19 iter 19 loss:1.4452830932043526e-08 norm:2.3107336044603244e-09 max memory_allocated 26700.35498046875 
[2025-03-23 05:07:50 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 20 ===
[2025-03-23 05:08:09 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 0 loss:1.8825730307980848e-08 norm:5.782990086800055e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:08:25 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 1 loss:1.8634603193845578e-08 norm:5.8359579391265015e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:08:41 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 2 loss:1.87579249910641e-08 norm:5.8823670379126725e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:08:57 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 3 loss:1.8734812812226664e-08 norm:6.024144738603354e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:09:13 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 4 loss:1.8493770070904247e-08 norm:6.1082685576252516e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:09:29 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 5 loss:1.8056335093774578e-08 norm:6.169252220189492e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:09:45 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 6 loss:1.759913992316342e-08 norm:6.235515215280429e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:10:01 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 7 loss:1.7440648036881612e-08 norm:6.421911002973957e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:10:17 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 8 loss:1.674965588449595e-08 norm:6.566134747032493e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:10:33 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 9 loss:1.5842497091966834e-08 norm:6.722666867631233e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:10:49 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 10 loss:1.5864738855952965e-08 norm:6.926943019180953e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:11:05 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 11 loss:1.5188371449426086e-08 norm:6.8014762710788546e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:11:21 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 12 loss:1.4817293170210633e-08 norm:6.809327324219794e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:11:37 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 13 loss:1.4671894810192043e-08 norm:6.9402812385988e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:11:53 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 14 loss:1.3746664251357288e-08 norm:6.714173217403641e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:12:09 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 15 loss:1.3533529852338688e-08 norm:6.7195964348343296e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:12:25 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 16 loss:1.3438700818824145e-08 norm:6.751783132585842e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:12:41 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 17 loss:1.3500251583309364e-08 norm:6.8417485010741075e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:12:57 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 18 loss:1.3403137266720933e-08 norm:6.8849348444643965e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:13:14 root] (abq_llm_calibration_a2.py 401): INFO layer 20 iter 19 loss:1.3421484368336678e-08 norm:6.9264656232803645e-09 max memory_allocated 26700.55810546875 
[2025-03-23 05:13:23 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 21 ===
[2025-03-23 05:13:42 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 0 loss:2.5307469897484225e-08 norm:7.441546490127848e-09 max memory_allocated 26700.76123046875 
[2025-03-23 05:13:58 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 1 loss:2.2580872283128883e-08 norm:7.242884958458262e-09 max memory_allocated 26700.76123046875 
[2025-03-23 05:14:14 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 2 loss:2.2170056013237627e-08 norm:7.566121063007358e-09 max memory_allocated 26700.76123046875 
[2025-03-23 05:14:30 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 3 loss:2.1622270196530735e-08 norm:8.04859645597844e-09 max memory_allocated 26700.76123046875 
[2025-03-23 05:14:46 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 4 loss:2.2162367940836702e-08 norm:8.833019649046037e-09 max memory_allocated 26700.76123046875 
[2025-03-23 05:15:02 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 5 loss:2.336526527813021e-08 norm:1.0034614028597844e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:15:18 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 6 loss:2.4938517029227114e-08 norm:1.1773143349103066e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:15:34 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 7 loss:2.593388614968717e-08 norm:1.3004724408460788e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:15:50 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 8 loss:2.478415872531059e-08 norm:1.456673093258587e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:16:06 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 9 loss:2.2947919120497318e-08 norm:1.4874943055076528e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:16:22 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 10 loss:1.6154457327388627e-08 norm:1.3760882211499847e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:16:38 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 11 loss:1.2697140228112858e-08 norm:1.2407061156238797e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:16:54 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 12 loss:8.887231395249273e-09 norm:1.0695326402299088e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:17:10 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 13 loss:8.305228504923434e-09 norm:1.1088984841478577e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:17:26 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 14 loss:8.174278143258107e-09 norm:1.1492787166389462e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:17:43 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 15 loss:7.792917422477785e-09 norm:1.2547571870413776e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:17:59 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 16 loss:7.853376615685193e-09 norm:1.3583563607255655e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:18:15 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 17 loss:7.928658618538975e-09 norm:1.4798841263541362e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:18:31 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 18 loss:7.780369237764262e-09 norm:1.5359695737515722e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:18:47 root] (abq_llm_calibration_a2.py 401): INFO layer 21 iter 19 loss:7.572978688585863e-09 norm:1.6016670656426868e-08 max memory_allocated 26700.76123046875 
[2025-03-23 05:18:56 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 22 ===
[2025-03-23 05:19:15 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 0 loss:2.4115806240843085e-08 norm:6.352144588106512e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:19:31 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 1 loss:2.4043322000011358e-08 norm:6.625775483826146e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:19:47 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 2 loss:2.4430820033671807e-08 norm:6.89760160099695e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:20:03 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 3 loss:2.4765519412994763e-08 norm:7.191080619861623e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:20:19 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 4 loss:2.3803815807355022e-08 norm:7.364672427456753e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:20:35 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 5 loss:2.085135442086994e-08 norm:7.787195777098077e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:20:51 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 6 loss:1.881316791241261e-08 norm:8.743075596839844e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:21:07 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 7 loss:1.4554553118273361e-08 norm:9.223924735124456e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:21:23 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 8 loss:1.1107659680931192e-08 norm:8.815058016864441e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:21:39 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 9 loss:8.933968231872313e-09 norm:9.468925199485057e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:21:55 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 10 loss:8.317926791789887e-09 norm:8.555423036682441e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:22:11 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 11 loss:8.394852812898534e-09 norm:9.052622651495312e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:22:27 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 12 loss:8.256144212737127e-09 norm:9.599903982859814e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:22:44 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 13 loss:7.793655498744556e-09 norm:9.924487898160805e-09 max memory_allocated 26700.96435546875 
[2025-03-23 05:23:00 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 14 loss:7.58391482946763e-09 norm:1.0925458759913909e-08 max memory_allocated 26700.96435546875 
[2025-03-23 05:23:16 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 15 loss:7.431581572348023e-09 norm:1.123887649612243e-08 max memory_allocated 26700.96435546875 
[2025-03-23 05:23:32 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 16 loss:7.509916244430315e-09 norm:1.1565457924689326e-08 max memory_allocated 26700.96435546875 
[2025-03-23 05:23:48 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 17 loss:7.240894550619714e-09 norm:1.1931546417542904e-08 max memory_allocated 26700.96435546875 
[2025-03-23 05:24:04 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 18 loss:7.256349299211706e-09 norm:1.2125429549314504e-08 max memory_allocated 26700.96435546875 
[2025-03-23 05:24:20 root] (abq_llm_calibration_a2.py 401): INFO layer 22 iter 19 loss:7.263929902023847e-09 norm:1.2221952339075415e-08 max memory_allocated 26700.96435546875 
[2025-03-23 05:24:29 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 23 ===
[2025-03-23 05:24:48 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 0 loss:3.090606170985666e-08 norm:6.196478885556189e-09 max memory_allocated 26701.16748046875 
[2025-03-23 05:25:04 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 1 loss:3.002574544552772e-08 norm:6.948239761328523e-09 max memory_allocated 26701.16748046875 
[2025-03-23 05:25:20 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 2 loss:2.7642643729564043e-08 norm:7.300658744213706e-09 max memory_allocated 26701.16748046875 
[2025-03-23 05:25:36 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 3 loss:2.6834440447487395e-08 norm:7.377847222045375e-09 max memory_allocated 26701.16748046875 
[2025-03-23 05:25:52 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 4 loss:2.6576460143701297e-08 norm:7.93750043470709e-09 max memory_allocated 26701.16748046875 
[2025-03-23 05:26:08 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 5 loss:2.5938511782896967e-08 norm:8.337737611441298e-09 max memory_allocated 26701.16748046875 
[2025-03-23 05:26:24 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 6 loss:2.470418891675763e-08 norm:9.13268749513918e-09 max memory_allocated 26701.16748046875 
[2025-03-23 05:26:40 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 7 loss:2.4142650545400102e-08 norm:1.0772396308311727e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:26:56 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 8 loss:1.9981651888656415e-08 norm:1.2222074019518914e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:27:12 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 9 loss:1.2548384553667802e-08 norm:1.3374062746152049e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:27:28 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 10 loss:9.800206868249006e-09 norm:1.210929934103433e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:27:44 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 11 loss:7.989525485641025e-09 norm:1.4579774720857586e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:28:00 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 12 loss:7.296848014703983e-09 norm:1.6518615808536197e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:28:16 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 13 loss:7.14201187079766e-09 norm:1.950774830561386e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:28:32 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 14 loss:6.606804436870561e-09 norm:2.081880445814477e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:28:48 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 15 loss:6.256817730587727e-09 norm:2.1582822640198174e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:29:04 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 16 loss:6.345454828249331e-09 norm:2.2227780505090777e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:29:20 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 17 loss:6.267554919503482e-09 norm:2.1693349339102497e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:29:36 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 18 loss:6.291252852008711e-09 norm:2.1832828878132204e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:29:53 root] (abq_llm_calibration_a2.py 401): INFO layer 23 iter 19 loss:6.273705999149115e-09 norm:2.1943305839045024e-08 max memory_allocated 26701.16748046875 
[2025-03-23 05:30:02 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 24 ===
[2025-03-23 05:30:21 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 0 loss:3.087155775460815e-08 norm:7.923675049426038e-09 max memory_allocated 26701.37060546875 
[2025-03-23 05:30:37 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 1 loss:3.1092191932202695e-08 norm:8.43535286065844e-09 max memory_allocated 26701.37060546875 
[2025-03-23 05:30:53 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 2 loss:3.101057544085961e-08 norm:9.02638674915579e-09 max memory_allocated 26701.37060546875 
[2025-03-23 05:31:09 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 3 loss:2.9857165628754956e-08 norm:9.673867040760342e-09 max memory_allocated 26701.37060546875 
[2025-03-23 05:31:25 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 4 loss:2.8119263362214042e-08 norm:1.1013662870595908e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:31:41 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 5 loss:2.75153535511663e-08 norm:1.2973427665485815e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:31:57 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 6 loss:2.0148467783087654e-08 norm:1.4324738728532793e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:32:13 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 7 loss:1.1202333283222288e-08 norm:1.437968766282438e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:32:29 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 8 loss:9.369345299603538e-09 norm:1.4253595637114813e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:32:45 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 9 loss:8.768577863804694e-09 norm:1.741230448715214e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:33:01 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 10 loss:7.074174579457804e-09 norm:1.9808110707231208e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:33:17 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 11 loss:6.72907418675095e-09 norm:1.9787941951676657e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:33:33 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 12 loss:6.829297571897541e-09 norm:2.0791985022583503e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:33:49 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 13 loss:6.8260805896613874e-09 norm:2.0813164525179673e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:34:05 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 14 loss:6.827156617816854e-09 norm:2.08778896393369e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:34:21 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 15 loss:6.824362852597687e-09 norm:2.08876009821779e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:34:37 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 16 loss:6.818499542760037e-09 norm:2.0877305217936737e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:34:53 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 17 loss:6.785223050087552e-09 norm:2.0779816978233612e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:35:09 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 18 loss:6.7815313364860685e-09 norm:2.0786050214383067e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:35:25 root] (abq_llm_calibration_a2.py 401): INFO layer 24 iter 19 loss:6.776577521350191e-09 norm:2.075891103459071e-08 max memory_allocated 26701.37060546875 
[2025-03-23 05:35:35 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 25 ===
[2025-03-23 05:35:54 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 0 loss:3.9153853492734925e-08 norm:5.3687974066463084e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:36:10 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 1 loss:3.943583948284868e-08 norm:5.4754796252609594e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:36:26 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 2 loss:3.9730192469278336e-08 norm:5.576195505341275e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:36:42 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 3 loss:3.998756525902536e-08 norm:5.57117463273471e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:36:58 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 4 loss:4.03521553948849e-08 norm:5.732810226533047e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:37:14 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 5 loss:4.0373326015696875e-08 norm:5.79879078088652e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:37:30 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 6 loss:4.035642220401314e-08 norm:5.777982536869786e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:37:46 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 7 loss:4.0328036021719527e-08 norm:5.667712965617966e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:38:02 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 8 loss:4.062204794763602e-08 norm:5.605045316769974e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:38:18 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 9 loss:4.0860573591317007e-08 norm:5.668705949091191e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:38:34 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 10 loss:4.0858061822746095e-08 norm:5.668074010145574e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:38:50 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 11 loss:4.0879736928900456e-08 norm:5.747796461008647e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:39:06 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 12 loss:4.108515838652238e-08 norm:5.71695490947377e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:39:22 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 13 loss:4.129785224904481e-08 norm:5.7493450000833946e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:39:38 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 14 loss:4.1420367580258244e-08 norm:5.7321249968822485e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:39:54 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 15 loss:4.155093336066784e-08 norm:5.596125340900926e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:40:10 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 16 loss:4.11109297715484e-08 norm:5.487073018173305e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:40:26 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 17 loss:4.125824304423986e-08 norm:5.465838004425905e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:40:42 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 18 loss:4.1242650183903606e-08 norm:5.354501730892025e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:40:58 root] (abq_llm_calibration_a2.py 401): INFO layer 25 iter 19 loss:4.107844020495577e-08 norm:5.291331817147693e-09 max memory_allocated 26701.57373046875 
[2025-03-23 05:41:08 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 26 ===
[2025-03-23 05:41:27 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 0 loss:2.3380808400474962e-08 norm:4.415462662166192e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:41:43 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 1 loss:2.1995115062622972e-08 norm:4.547966447887575e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:41:59 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 2 loss:2.2317237835522974e-08 norm:4.768530459386966e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:42:15 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 3 loss:2.3292447082212675e-08 norm:4.950027943095847e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:42:31 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 4 loss:2.361130491124186e-08 norm:5.197844821225317e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:42:48 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 5 loss:2.45852760372145e-08 norm:5.537007297107266e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:43:04 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 6 loss:2.4545025567590528e-08 norm:6.076151581879685e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:43:20 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 7 loss:2.3846197905186273e-08 norm:6.512950623260849e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:43:36 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 8 loss:2.2307764524498452e-08 norm:6.877803215843414e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:43:52 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 9 loss:2.0912583664767226e-08 norm:7.2527708283587344e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:44:08 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 10 loss:1.7697605159128216e-08 norm:7.903653731489158e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:44:24 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 11 loss:1.5213736048735882e-08 norm:9.230494590894978e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:44:40 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 12 loss:1.3441425750215785e-08 norm:9.192075545172429e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:44:56 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 13 loss:9.538529965880116e-09 norm:9.473627216038949e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:45:12 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 14 loss:8.727949918352351e-09 norm:9.934887579277074e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:45:28 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 15 loss:8.424493103120767e-09 norm:1.0080016821234494e-08 max memory_allocated 26701.77685546875 
[2025-03-23 05:45:44 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 16 loss:8.114982463780507e-09 norm:9.591812677456346e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:46:00 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 17 loss:8.099924286852911e-09 norm:9.926274913141242e-09 max memory_allocated 26701.77685546875 
[2025-03-23 05:46:16 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 18 loss:7.799559220700303e-09 norm:1.0098487379650578e-08 max memory_allocated 26701.77685546875 
[2025-03-23 05:46:32 root] (abq_llm_calibration_a2.py 401): INFO layer 26 iter 19 loss:7.74968889061256e-09 norm:1.033913132886255e-08 max memory_allocated 26701.77685546875 
[2025-03-23 05:46:41 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 27 ===
[2025-03-23 05:47:00 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 0 loss:1.9083119084939426e-08 norm:3.2691487295011257e-09 max memory_allocated 26701.97998046875 
[2025-03-23 05:47:16 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 1 loss:1.841867636187544e-08 norm:3.5278802101856854e-09 max memory_allocated 26701.97998046875 
[2025-03-23 05:47:32 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 2 loss:1.7432666865602187e-08 norm:3.750107335775965e-09 max memory_allocated 26701.97998046875 
[2025-03-23 05:47:48 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 3 loss:1.631054225015305e-08 norm:3.986365015862248e-09 max memory_allocated 26701.97998046875 
[2025-03-23 05:48:04 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 4 loss:1.6672839109332926e-08 norm:4.2234749031422325e-09 max memory_allocated 26701.97998046875 
[2025-03-23 05:48:20 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 5 loss:1.7345334057949913e-08 norm:4.484139282112665e-09 max memory_allocated 26701.97998046875 
[2025-03-23 05:48:36 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 6 loss:1.6643969757978994e-08 norm:4.97113683550765e-09 max memory_allocated 26701.97998046875 
[2025-03-23 05:48:52 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 7 loss:1.5394803654089628e-08 norm:5.989098106340407e-09 max memory_allocated 26701.97998046875 
[2025-03-23 05:49:09 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 8 loss:1.5555665200395197e-08 norm:7.848367289398084e-09 max memory_allocated 26701.97998046875 
[2025-03-23 05:49:25 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 9 loss:1.3405492715889977e-08 norm:9.62527124670487e-09 max memory_allocated 26701.97998046875 
[2025-03-23 05:49:41 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 10 loss:1.1425258072961242e-08 norm:1.0460666111100636e-08 max memory_allocated 26701.97998046875 
[2025-03-23 05:49:57 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 11 loss:1.0791090687689575e-08 norm:1.1480079109560393e-08 max memory_allocated 26701.97998046875 
[2025-03-23 05:50:13 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 12 loss:1.0692698282355195e-08 norm:1.2629729262414457e-08 max memory_allocated 26701.97998046875 
[2025-03-23 05:50:29 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 13 loss:1.0444349385352325e-08 norm:1.3153569788926234e-08 max memory_allocated 26701.97998046875 
[2025-03-23 05:50:45 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 14 loss:1.0556046703413813e-08 norm:1.366656832146873e-08 max memory_allocated 26701.97998046875 
[2025-03-23 05:51:01 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 15 loss:1.0516006732075311e-08 norm:1.4595596731226124e-08 max memory_allocated 26701.97998046875 
[2025-03-23 05:51:17 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 16 loss:1.0374427539261433e-08 norm:1.453175002552598e-08 max memory_allocated 26701.97998046875 
[2025-03-23 05:51:33 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 17 loss:1.0366989044996444e-08 norm:1.4702345119133042e-08 max memory_allocated 26701.97998046875 
[2025-03-23 05:51:49 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 18 loss:1.0361842051054282e-08 norm:1.48905456853754e-08 max memory_allocated 26701.97998046875 
[2025-03-23 05:52:05 root] (abq_llm_calibration_a2.py 401): INFO layer 27 iter 19 loss:1.0186368193387807e-08 norm:1.502341895331938e-08 max memory_allocated 26701.97998046875 
[2025-03-23 05:52:14 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 28 ===
[2025-03-23 05:52:17 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-23 05:52:34 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 0 loss:1.7763683857197066e-08 norm:3.6160892058489935e-09 max memory_allocated 26702.18310546875 
[2025-03-23 05:52:50 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 1 loss:1.724372289402254e-08 norm:3.793234615301344e-09 max memory_allocated 26702.18310546875 
[2025-03-23 05:53:06 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 2 loss:1.7023641163405046e-08 norm:4.060718872267444e-09 max memory_allocated 26702.18310546875 
[2025-03-23 05:53:22 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 3 loss:1.6181417095140205e-08 norm:4.304675726984897e-09 max memory_allocated 26702.18310546875 
[2025-03-23 05:53:38 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 4 loss:1.5825158072857448e-08 norm:4.662587649306715e-09 max memory_allocated 26702.18310546875 
[2025-03-23 05:53:54 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 5 loss:1.644373348597128e-08 norm:4.818057952604704e-09 max memory_allocated 26702.18310546875 
[2025-03-23 05:54:10 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 6 loss:1.6268574043465378e-08 norm:5.506997080573228e-09 max memory_allocated 26702.18310546875 
[2025-03-23 05:54:26 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 7 loss:1.6755720366745663e-08 norm:6.0419531600075516e-09 max memory_allocated 26702.18310546875 
[2025-03-23 05:54:42 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 8 loss:1.582047026715827e-08 norm:8.197774903351274e-09 max memory_allocated 26702.18310546875 
[2025-03-23 05:54:58 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 9 loss:1.4153063609967376e-08 norm:1.1659917475981274e-08 max memory_allocated 26702.18310546875 
[2025-03-23 05:55:14 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 10 loss:1.2471486954268585e-08 norm:1.471010957487806e-08 max memory_allocated 26702.18310546875 
[2025-03-23 05:55:31 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 11 loss:1.1157076151846468e-08 norm:1.5540774001010504e-08 max memory_allocated 26702.18310546875 
[2025-03-23 05:55:47 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 12 loss:1.0354956003766347e-08 norm:1.6235793154351086e-08 max memory_allocated 26702.18310546875 
[2025-03-23 05:56:03 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 13 loss:1.0489286772497053e-08 norm:1.636642465996374e-08 max memory_allocated 26702.18310546875 
[2025-03-23 05:56:19 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 14 loss:1.045653874598429e-08 norm:1.713262065550225e-08 max memory_allocated 26702.18310546875 
[2025-03-23 05:56:35 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 15 loss:1.0511882919672644e-08 norm:1.7378862793293592e-08 max memory_allocated 26702.18310546875 
[2025-03-23 05:56:51 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 16 loss:1.051100717575082e-08 norm:1.752509781738354e-08 max memory_allocated 26702.18310546875 
[2025-03-23 05:57:07 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 17 loss:1.0337776856772507e-08 norm:1.7627083792604026e-08 max memory_allocated 26702.18310546875 
[2025-03-23 05:57:23 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 18 loss:1.0364847646826547e-08 norm:1.7970720023186004e-08 max memory_allocated 26702.18310546875 
[2025-03-23 05:57:39 root] (abq_llm_calibration_a2.py 401): INFO layer 28 iter 19 loss:1.034979213443421e-08 norm:1.797325310803899e-08 max memory_allocated 26702.18310546875 
[2025-03-23 05:57:49 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 29 ===
[2025-03-23 05:57:52 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-23 05:58:08 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 0 loss:2.0281960999568582e-08 norm:3.762165690091024e-09 max memory_allocated 26702.38623046875 
[2025-03-23 05:58:24 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 1 loss:1.8878246521580877e-08 norm:4.35208491467165e-09 max memory_allocated 26702.38623046875 
[2025-03-23 05:58:40 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 2 loss:1.9220461666691335e-08 norm:4.573888823244943e-09 max memory_allocated 26702.38623046875 
[2025-03-23 05:58:56 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 3 loss:1.928812132234725e-08 norm:5.034399119807631e-09 max memory_allocated 26702.38623046875 
[2025-03-23 05:59:12 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 4 loss:1.775345204180212e-08 norm:7.892704267931094e-09 max memory_allocated 26702.38623046875 
[2025-03-23 05:59:28 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 5 loss:1.3999192027824847e-08 norm:5.4146489958384336e-08 max memory_allocated 26702.38623046875 
[2025-03-23 05:59:44 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 6 loss:1.1493232143777732e-08 norm:8.29756885423194e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:00:00 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 7 loss:1.1309848169105408e-08 norm:7.729912709919518e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:00:16 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 8 loss:1.1363055385515963e-08 norm:7.827085823919333e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:00:33 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 9 loss:1.135246385786104e-08 norm:7.443489380420942e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:00:49 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 10 loss:1.0793618443472042e-08 norm:7.629441256540304e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:01:05 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 11 loss:1.0843523412518152e-08 norm:7.338211105434311e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:01:21 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 12 loss:1.0752118306811553e-08 norm:7.803471646639082e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:01:37 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 13 loss:1.0770868641429843e-08 norm:7.835686233192973e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:01:53 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 14 loss:1.0734957811564527e-08 norm:7.804146662238054e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:02:09 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 15 loss:1.0689921836615213e-08 norm:7.034342530687354e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:02:25 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 16 loss:1.0644473746879157e-08 norm:7.985769912011165e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:02:41 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 17 loss:1.0682452256105535e-08 norm:7.912019839295681e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:02:57 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 18 loss:1.0616265200269481e-08 norm:7.650309896689578e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:03:13 root] (abq_llm_calibration_a2.py 401): INFO layer 29 iter 19 loss:1.0622060564458025e-08 norm:7.500503329538333e-08 max memory_allocated 26702.38623046875 
[2025-03-23 06:03:23 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 30 ===
[2025-03-23 06:03:26 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-23 06:03:42 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 0 loss:9.079131224609682e-09 norm:2.7022077908611664e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:03:58 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 1 loss:9.082343765953738e-09 norm:2.7343349806585593e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:04:14 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 2 loss:9.144286217122044e-09 norm:2.8228019921527903e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:04:30 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 3 loss:9.165036729541498e-09 norm:2.9317754890456627e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:04:46 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 4 loss:9.132532952094152e-09 norm:2.9247975152912886e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:05:03 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 5 loss:9.081674079425284e-09 norm:2.9216440378121433e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:05:19 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 6 loss:9.035558967696034e-09 norm:3.0544848872438024e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:05:35 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 7 loss:9.055955985104447e-09 norm:3.1785594156730212e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:05:51 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 8 loss:9.011174029183167e-09 norm:3.1813807144231987e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:06:07 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 9 loss:8.925795214054233e-09 norm:3.3080018724263027e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:06:23 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 10 loss:8.97538310340451e-09 norm:3.5128020492436463e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:06:39 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 11 loss:8.872188317354812e-09 norm:3.544746718375791e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:06:55 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 12 loss:8.93741436414075e-09 norm:3.63807695080709e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:07:11 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 13 loss:8.9077643039559e-09 norm:3.618078503464517e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:07:27 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 14 loss:8.881530177973218e-09 norm:3.799596193232446e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:07:43 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 15 loss:8.701782405751146e-09 norm:3.790774361078775e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:08:00 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 16 loss:8.72131700191403e-09 norm:3.849014884593771e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:08:16 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 17 loss:8.815540297746338e-09 norm:3.906687862098579e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:08:32 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 18 loss:8.978727095154682e-09 norm:3.891627908814144e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:08:48 root] (abq_llm_calibration_a2.py 401): INFO layer 30 iter 19 loss:8.956627439715703e-09 norm:3.903794176807196e-09 max memory_allocated 26702.58935546875 
[2025-03-23 06:08:57 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 31 ===
[2025-03-23 06:09:00 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-23 06:09:16 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 0 loss:2.1216020940073577e-08 norm:1.5401739883458276e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:09:32 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 1 loss:2.1238147240865146e-08 norm:1.5442248590957774e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:09:49 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 2 loss:2.123842790524577e-08 norm:1.5420871246618617e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:10:05 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 3 loss:2.1258799165480013e-08 norm:1.5381282914006533e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:10:21 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 4 loss:2.1317083209737575e-08 norm:1.5408622155987928e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:10:37 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 5 loss:2.1302104968867752e-08 norm:1.5355817728490706e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:10:53 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 6 loss:2.1236202130126003e-08 norm:1.5146085496908768e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:11:09 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 7 loss:2.129130116657052e-08 norm:1.5238361683600488e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:11:25 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 8 loss:2.1312350995117413e-08 norm:1.5223056148983005e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:11:41 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 9 loss:2.1331310051664332e-08 norm:1.5200463110431883e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:11:57 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 10 loss:2.1246748360681522e-08 norm:1.5012344700693347e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:12:13 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 11 loss:2.1218724555183144e-08 norm:1.4874794729280438e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:12:30 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 12 loss:2.1225217139431152e-08 norm:1.4827514771553751e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:12:46 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 13 loss:2.1147405604438063e-08 norm:1.4666947656394314e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:13:02 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 14 loss:2.1087721790991054e-08 norm:1.4503240830521236e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:13:18 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 15 loss:2.107135443907282e-08 norm:1.4401270176378489e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:13:34 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 16 loss:2.1009224582257957e-08 norm:1.4324886832284278e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:13:50 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 17 loss:2.1009016748507747e-08 norm:1.4246979151977257e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:14:06 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 18 loss:2.0992562355104383e-08 norm:1.4157638394962646e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:14:22 root] (abq_llm_calibration_a2.py 401): INFO layer 31 iter 19 loss:2.0990810867260734e-08 norm:1.4042970120087261e-09 max memory_allocated 26702.79248046875 
[2025-03-23 06:14:32 root] (main_calibration_a2.py 372): INFO 10661.255177497864
[2025-03-23 06:14:38 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-23 06:15:48 root] (main_calibration_a2.py 158): INFO wikitext2 : nan
[2025-03-23 06:15:48 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-23 06:17:36 root] (main_calibration_a2.py 158): INFO c4 : nan
[2025-03-23 07:53:17 root] (main_calibration_a2.py 169): INFO {'wikitext2': nan, 'c4': nan, 'results': {'arc_easy': {'acc': 0.3947811447811448, 'acc_stderr': 0.010030038935883584, 'acc_norm': 0.3648989898989899, 'acc_norm_stderr': 0.009878157021155649}, 'winogrande': {'acc': 0.47671665351223363, 'acc_stderr': 0.014037241309573645}, 'arc_challenge': {'acc': 0.24914675767918087, 'acc_stderr': 0.012639407111926433, 'acc_norm': 0.28242320819112626, 'acc_norm_stderr': 0.013155456884097222}, 'boolq': {'acc': 0.6082568807339449, 'acc_stderr': 0.008537618477478612}, 'hellaswag': {'acc': 0.3454491137223661, 'acc_stderr': 0.004745426656377574, 'acc_norm': 0.4298944433379805, 'acc_norm_stderr': 0.004940490508240645}, 'piqa': {'acc': 0.6191512513601741, 'acc_stderr': 0.011329743189016752, 'acc_norm': 0.5952121871599565, 'acc_norm_stderr': 0.011452361375057027}}, 'versions': {'arc_easy': 0, 'winogrande': 0, 'arc_challenge': 0, 'boolq': 1, 'hellaswag': 0, 'piqa': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
[2025-03-23 07:53:17 root] (main_calibration_a2.py 172): INFO 24.91,39.48,60.83,34.54,61.92,47.67
