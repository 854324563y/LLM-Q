[2025-03-22 01:18:48 root] (main_calibration_a2.py 274): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-calibration-compensation-lwc-loss/llama-7b-hf-w4a4-kl', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, scale_calibration=True, compensation_calibration=True, rank=1, loss_type='kl')
[2025-03-22 01:22:58 root] (main_calibration_a2.py 341): INFO === start quantization ===
[2025-03-22 01:22:58 root] (main_calibration_a2.py 347): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-22 01:22:58 root] (abq_llm_calibration_a2.py 62): INFO Starting ...
[2025-03-22 01:23:02 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 0 ===
[2025-03-22 01:23:06 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:23:39 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 0 loss:4.434097888861288e-07 norm:2.7410652592152474e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:24:12 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 1 loss:2.631678057696263e-07 norm:3.302827167317446e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:24:46 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 2 loss:2.0913580556225497e-07 norm:3.6504010836324596e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:25:19 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 3 loss:1.9794620698121435e-07 norm:3.5646078799800307e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:25:53 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 4 loss:1.7166428278869716e-07 norm:3.442260378960782e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:26:26 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 5 loss:1.574628072376072e-07 norm:3.449486314366368e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:27:00 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 6 loss:1.5216251370020473e-07 norm:3.9665329154559004e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:27:33 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 7 loss:1.4446713691995683e-07 norm:3.8359627296813414e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:28:06 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 8 loss:1.4236542256185203e-07 norm:3.8205163832572e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:28:40 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 9 loss:1.394287210132461e-07 norm:3.649460893484502e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:29:13 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 10 loss:1.373513924818326e-07 norm:3.8561412907256454e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:29:47 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 11 loss:1.3332629578144406e-07 norm:3.1845490866544424e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:30:20 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 12 loss:1.325972931454089e-07 norm:3.3912814956238435e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:30:53 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 13 loss:1.3412126520506717e-07 norm:3.590941730635677e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:31:27 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 14 loss:1.3295739620389213e-07 norm:3.4385888625365624e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:32:00 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 15 loss:1.2863807796748006e-07 norm:3.3309260061287205e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:32:34 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 16 loss:1.293109761490996e-07 norm:3.3901307006090065e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:33:07 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 17 loss:1.2955163697370153e-07 norm:3.282833063167345e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:33:40 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 18 loss:1.2700658658104658e-07 norm:3.4087446465491666e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:34:14 root] (abq_llm_calibration_a2.py 394): INFO layer 0 iter 19 loss:1.2966214057996694e-07 norm:3.5451779467621236e-07 max memory_allocated 22719.10595703125 
[2025-03-22 01:34:23 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 1 ===
[2025-03-22 01:34:26 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:34:59 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 0 loss:3.0564872304239543e-06 norm:6.693001068924787e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:35:33 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 1 loss:1.8591198340800474e-06 norm:5.97214921072009e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:36:06 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 2 loss:1.6117224959089071e-06 norm:5.555237976295757e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:36:40 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 3 loss:1.4884876691212412e-06 norm:5.742584789913963e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:37:13 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 4 loss:1.3749170193477767e-06 norm:5.045897637501184e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:37:47 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 5 loss:1.3032511105848243e-06 norm:4.843145120503323e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:38:20 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 6 loss:1.2606740256160265e-06 norm:5.226520443102345e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:38:53 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 7 loss:1.2430491551640444e-06 norm:5.783462029285147e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:39:27 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 8 loss:1.2194809642096516e-06 norm:5.061341994405666e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:40:00 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 9 loss:1.2034347491862718e-06 norm:5.45048692401906e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:40:34 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 10 loss:1.194740207210998e-06 norm:5.077808964415453e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:41:07 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 11 loss:1.1807795772256213e-06 norm:5.613085818367836e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:41:40 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 12 loss:1.166523134088493e-06 norm:5.09679182414402e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:42:14 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 13 loss:1.1613078640948515e-06 norm:5.935877993579197e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:42:47 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 14 loss:1.1565145996428328e-06 norm:6.309626314759953e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:43:21 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 15 loss:1.1414205118853715e-06 norm:5.715639872505562e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:43:54 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 16 loss:1.1359795735188527e-06 norm:6.063982596060669e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:44:28 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 17 loss:1.1335467888784478e-06 norm:6.103500709286891e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:45:01 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 18 loss:1.1315136134726345e-06 norm:6.377914019140007e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:45:34 root] (abq_llm_calibration_a2.py 394): INFO layer 1 iter 19 loss:1.1350660997777595e-06 norm:5.90476247452898e-07 max memory_allocated 22719.27783203125 
[2025-03-22 01:45:44 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 2 ===
[2025-03-22 01:45:47 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 01:46:20 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 0 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:46:52 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 1 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:47:24 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 2 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:47:57 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 3 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:48:29 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 4 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:49:01 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 5 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:49:34 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 6 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:50:06 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 7 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:50:39 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 8 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:51:11 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 9 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:51:43 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 10 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:52:16 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 11 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:52:48 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 12 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:53:20 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 13 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:53:53 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 14 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:54:25 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 15 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:54:58 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 16 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:55:30 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 17 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:56:02 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 18 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:56:35 root] (abq_llm_calibration_a2.py 394): INFO layer 2 iter 19 loss:0.00012380983389448375 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:56:44 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 3 ===
[2025-03-22 01:57:20 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 0 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:57:52 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 1 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:58:24 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 2 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:58:57 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 3 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 01:59:29 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 4 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:00:01 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 5 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:00:33 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 6 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:01:06 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 7 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:01:38 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 8 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:02:10 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 9 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:02:43 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 10 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:03:15 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 11 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:03:47 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 12 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:04:20 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 13 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:04:52 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 14 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:05:24 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 15 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:05:56 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 16 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:06:29 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 17 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:07:01 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 18 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:07:33 root] (abq_llm_calibration_a2.py 394): INFO layer 3 iter 19 loss:0.00012302404502406716 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:07:42 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 4 ===
[2025-03-22 02:08:19 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 0 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:08:51 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 1 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:09:23 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 2 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:09:56 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 3 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:10:28 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 4 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:11:00 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 5 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:11:33 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 6 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:12:05 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 7 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:12:38 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 8 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:13:10 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 9 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:13:42 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 10 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:14:15 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 11 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:14:47 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 12 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:15:19 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 13 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:15:52 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 14 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:16:24 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 15 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:16:57 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 16 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:17:29 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 17 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:18:01 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 18 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:18:34 root] (abq_llm_calibration_a2.py 394): INFO layer 4 iter 19 loss:0.00013455933367367834 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:18:43 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 5 ===
[2025-03-22 02:19:19 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 0 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:19:51 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 1 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:20:24 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 2 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:20:56 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 3 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:21:29 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 4 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:22:01 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 5 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:22:33 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 6 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:23:06 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 7 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:23:38 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 8 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:24:10 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 9 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:24:43 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 10 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:25:15 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 11 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:25:48 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 12 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:26:20 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 13 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:26:52 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 14 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:27:25 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 15 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:27:57 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 16 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:28:29 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 17 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:29:02 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 18 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:29:34 root] (abq_llm_calibration_a2.py 394): INFO layer 5 iter 19 loss:0.0001407800882589072 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:29:44 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 6 ===
[2025-03-22 02:30:20 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 0 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:30:52 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 1 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:31:25 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 2 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:31:57 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 3 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:32:29 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 4 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:33:02 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 5 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:33:34 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 6 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:34:07 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 7 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:34:39 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 8 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:35:11 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 9 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:35:44 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 10 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:36:16 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 11 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:36:49 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 12 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:37:21 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 13 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:37:54 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 14 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:38:26 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 15 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:38:58 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 16 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:39:31 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 17 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:40:03 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 18 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:40:36 root] (abq_llm_calibration_a2.py 394): INFO layer 6 iter 19 loss:0.00015410227933898568 norm:nan max memory_allocated 22719.27783203125 
[2025-03-22 02:40:45 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 7 ===
[2025-03-22 02:41:21 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 0 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:41:53 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 1 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:42:26 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 2 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:42:58 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 3 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:43:31 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 4 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:44:03 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 5 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:44:36 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 6 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:45:08 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 7 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:45:40 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 8 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:46:13 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 9 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:46:45 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 10 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:47:18 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 11 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:47:50 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 12 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:48:22 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 13 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:48:55 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 14 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:49:27 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 15 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:50:00 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 16 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:50:32 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 17 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:51:04 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 18 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:51:37 root] (abq_llm_calibration_a2.py 394): INFO layer 7 iter 19 loss:0.00017849155119620264 norm:nan max memory_allocated 22719.36767578125 
[2025-03-22 02:51:46 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 8 ===
[2025-03-22 02:52:22 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 0 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:52:55 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 1 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:53:27 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 2 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:54:00 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 3 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:54:32 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 4 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:55:04 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 5 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:55:37 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 6 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:56:09 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 7 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:56:42 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 8 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:57:14 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 9 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:57:46 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 10 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:58:19 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 11 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:58:51 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 12 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:59:24 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 13 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 02:59:56 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 14 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 03:00:28 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 15 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 03:01:01 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 16 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 03:01:33 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 17 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 03:02:05 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 18 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 03:02:38 root] (abq_llm_calibration_a2.py 394): INFO layer 8 iter 19 loss:0.00018977379659190774 norm:nan max memory_allocated 22719.53955078125 
[2025-03-22 03:02:47 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 9 ===
[2025-03-22 03:03:23 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 0 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:03:56 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 1 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:04:28 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 2 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:05:01 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 3 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:05:33 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 4 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:06:05 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 5 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:06:38 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 6 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:07:10 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 7 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:07:43 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 8 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:08:15 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 9 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:08:47 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 10 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:09:20 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 11 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:09:52 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 12 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:10:25 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 13 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:10:57 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 14 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:11:30 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 15 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:12:02 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 16 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:12:34 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 17 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:13:07 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 18 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:13:39 root] (abq_llm_calibration_a2.py 394): INFO layer 9 iter 19 loss:0.0002079931291518733 norm:nan max memory_allocated 22719.71142578125 
[2025-03-22 03:13:48 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 10 ===
[2025-03-22 03:14:25 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 0 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:14:57 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 1 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:15:30 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 2 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:16:02 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 3 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:16:34 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 4 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:17:07 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 5 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:17:39 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 6 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:18:12 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 7 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:18:44 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 8 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:19:16 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 9 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:19:49 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 10 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:20:21 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 11 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:20:54 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 12 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:21:26 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 13 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:21:58 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 14 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:22:31 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 15 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:23:03 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 16 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:23:36 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 17 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:24:08 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 18 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:24:40 root] (abq_llm_calibration_a2.py 394): INFO layer 10 iter 19 loss:0.00023601987049914896 norm:nan max memory_allocated 22719.88330078125 
[2025-03-22 03:24:50 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 11 ===
[2025-03-22 03:25:26 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 0 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:25:59 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 1 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:26:31 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 2 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:27:03 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 3 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:27:36 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 4 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:28:08 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 5 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:28:41 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 6 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:29:13 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 7 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:29:45 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 8 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:30:18 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 9 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:30:50 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 10 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:31:23 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 11 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:31:55 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 12 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:32:27 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 13 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:33:00 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 14 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:33:32 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 15 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:34:05 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 16 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:34:37 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 17 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:35:09 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 18 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:35:42 root] (abq_llm_calibration_a2.py 394): INFO layer 11 iter 19 loss:0.00026125385193154216 norm:nan max memory_allocated 22720.05517578125 
[2025-03-22 03:35:51 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 12 ===
[2025-03-22 03:36:27 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 0 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:37:00 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 1 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:37:32 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 2 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:38:05 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 3 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:38:37 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 4 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:39:10 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 5 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:39:42 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 6 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:40:14 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 7 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:40:47 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 8 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:41:19 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 9 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:41:52 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 10 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:42:24 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 11 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:42:56 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 12 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:43:29 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 13 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:44:01 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 14 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:44:34 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 15 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:45:06 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 16 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:45:38 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 17 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:46:11 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 18 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:46:43 root] (abq_llm_calibration_a2.py 394): INFO layer 12 iter 19 loss:0.00028937135357409716 norm:nan max memory_allocated 22720.22705078125 
[2025-03-22 03:46:52 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 13 ===
[2025-03-22 03:47:29 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 0 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:48:01 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 1 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:48:34 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 2 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:49:06 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 3 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:49:38 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 4 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:50:11 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 5 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:50:43 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 6 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:51:16 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 7 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:51:48 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 8 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:52:20 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 9 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:52:53 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 10 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:53:25 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 11 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:53:58 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 12 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:54:30 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 13 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:55:03 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 14 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:55:35 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 15 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:56:07 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 16 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:56:40 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 17 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:57:12 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 18 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:57:44 root] (abq_llm_calibration_a2.py 394): INFO layer 13 iter 19 loss:0.00032312804250977933 norm:nan max memory_allocated 22720.39892578125 
[2025-03-22 03:57:54 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 14 ===
[2025-03-22 03:58:30 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 0 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 03:59:03 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 1 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 03:59:35 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 2 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:00:07 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 3 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:00:40 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 4 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:01:12 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 5 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:01:44 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 6 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:02:17 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 7 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:02:49 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 8 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:03:22 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 9 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:03:54 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 10 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:04:26 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 11 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:04:59 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 12 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:05:31 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 13 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:06:03 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 14 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:06:36 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 15 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:07:08 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 16 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:07:41 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 17 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:08:13 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 18 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:08:45 root] (abq_llm_calibration_a2.py 394): INFO layer 14 iter 19 loss:0.00038669249624945223 norm:nan max memory_allocated 22720.57080078125 
[2025-03-22 04:08:55 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 15 ===
[2025-03-22 04:09:31 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 0 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:10:04 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 1 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:10:36 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 2 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:11:08 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 3 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:11:41 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 4 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:12:13 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 5 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:12:46 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 6 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:13:18 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 7 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:13:50 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 8 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:14:23 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 9 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:14:55 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 10 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:15:28 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 11 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:16:00 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 12 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:16:32 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 13 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:17:05 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 14 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:17:37 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 15 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:18:10 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 16 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:18:42 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 17 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:19:15 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 18 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:19:47 root] (abq_llm_calibration_a2.py 394): INFO layer 15 iter 19 loss:0.0004961154190823436 norm:nan max memory_allocated 22720.74267578125 
[2025-03-22 04:19:56 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 16 ===
[2025-03-22 04:20:32 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 0 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:21:05 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 1 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:21:37 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 2 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:22:10 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 3 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:22:42 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 4 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:23:14 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 5 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:23:47 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 6 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:24:19 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 7 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:24:52 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 8 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:25:24 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 9 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:25:56 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 10 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:26:29 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 11 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:27:01 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 12 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:27:34 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 13 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:28:06 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 14 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:28:38 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 15 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:29:11 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 16 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:29:43 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 17 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:30:16 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 18 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:30:48 root] (abq_llm_calibration_a2.py 394): INFO layer 16 iter 19 loss:0.0007995310588739812 norm:nan max memory_allocated 22720.91455078125 
[2025-03-22 04:30:57 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 17 ===
[2025-03-22 04:31:34 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 0 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:32:06 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 1 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:32:38 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 2 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:33:11 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 3 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:33:43 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 4 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:34:15 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 5 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:34:48 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 6 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:35:20 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 7 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:35:53 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 8 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:36:25 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 9 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:36:57 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 10 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:37:30 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 11 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:38:02 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 12 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:38:35 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 13 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:39:07 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 14 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:39:39 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 15 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:40:12 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 16 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:40:44 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 17 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:41:17 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 18 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:41:49 root] (abq_llm_calibration_a2.py 394): INFO layer 17 iter 19 loss:0.001342878444120288 norm:nan max memory_allocated 22721.08642578125 
[2025-03-22 04:41:58 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 18 ===
[2025-03-22 04:42:35 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 0 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:43:07 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 1 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:43:39 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 2 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:44:12 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 3 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:44:44 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 4 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:45:17 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 5 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:45:49 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 6 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:46:21 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 7 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:46:54 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 8 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:47:26 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 9 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:47:59 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 10 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:48:31 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 11 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:49:04 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 12 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:49:36 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 13 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:50:08 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 14 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:50:41 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 15 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:51:13 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 16 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:51:46 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 17 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:52:18 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 18 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:52:50 root] (abq_llm_calibration_a2.py 394): INFO layer 18 iter 19 loss:0.0017166055040434003 norm:nan max memory_allocated 22721.25830078125 
[2025-03-22 04:53:00 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 19 ===
[2025-03-22 04:53:36 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 0 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 04:54:08 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 1 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 04:54:41 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 2 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 04:55:13 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 3 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 04:55:45 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 4 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 04:56:18 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 5 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 04:56:50 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 6 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 04:57:22 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 7 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 04:57:55 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 8 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 04:58:27 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 9 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 04:58:59 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 10 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 04:59:32 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 11 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 05:00:04 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 12 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 05:00:36 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 13 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 05:01:09 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 14 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 05:01:41 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 15 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 05:02:13 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 16 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 05:02:46 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 17 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 05:03:18 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 18 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 05:03:50 root] (abq_llm_calibration_a2.py 394): INFO layer 19 iter 19 loss:0.0022752340883016586 norm:nan max memory_allocated 22721.43017578125 
[2025-03-22 05:04:00 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 20 ===
[2025-03-22 05:04:36 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 0 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:05:09 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 1 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:05:41 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 2 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:06:14 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 3 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:06:46 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 4 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:07:18 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 5 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:07:51 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 6 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:08:23 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 7 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:08:55 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 8 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:09:28 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 9 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:10:00 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 10 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:10:33 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 11 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:11:05 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 12 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:11:37 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 13 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:12:10 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 14 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:12:42 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 15 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:13:14 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 16 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:13:47 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 17 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:14:19 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 18 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:14:52 root] (abq_llm_calibration_a2.py 394): INFO layer 20 iter 19 loss:0.002575512044131756 norm:nan max memory_allocated 22721.60205078125 
[2025-03-22 05:15:01 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 21 ===
[2025-03-22 05:15:37 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 0 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:16:09 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 1 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:16:42 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 2 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:17:14 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 3 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:17:46 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 4 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:18:19 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 5 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:18:51 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 6 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:19:23 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 7 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:19:56 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 8 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:20:28 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 9 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:21:01 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 10 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:21:33 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 11 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:22:05 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 12 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:22:38 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 13 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:23:10 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 14 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:23:42 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 15 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:24:15 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 16 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:24:47 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 17 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:25:19 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 18 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:25:52 root] (abq_llm_calibration_a2.py 394): INFO layer 21 iter 19 loss:0.0027585122734308243 norm:nan max memory_allocated 22721.77392578125 
[2025-03-22 05:26:01 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 22 ===
[2025-03-22 05:26:37 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 0 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:27:10 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 1 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:27:42 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 2 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:28:14 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 3 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:28:47 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 4 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:29:19 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 5 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:29:52 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 6 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:30:24 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 7 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:30:56 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 8 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:31:29 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 9 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:32:01 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 10 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:32:34 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 11 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:33:06 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 12 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:33:38 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 13 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:34:11 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 14 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:34:43 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 15 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:35:16 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 16 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:35:48 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 17 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:36:20 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 18 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:36:53 root] (abq_llm_calibration_a2.py 394): INFO layer 22 iter 19 loss:0.0029679513536393642 norm:nan max memory_allocated 22721.94580078125 
[2025-03-22 05:37:02 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 23 ===
[2025-03-22 05:37:38 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 0 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:38:11 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 1 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:38:43 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 2 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:39:15 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 3 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:39:48 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 4 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:40:20 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 5 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:40:53 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 6 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:41:25 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 7 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:41:57 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 8 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:42:30 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 9 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:43:02 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 10 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:43:35 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 11 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:44:07 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 12 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:44:39 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 13 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:45:12 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 14 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:45:44 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 15 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:46:17 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 16 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:46:49 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 17 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:47:21 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 18 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:47:54 root] (abq_llm_calibration_a2.py 394): INFO layer 23 iter 19 loss:0.0031918822787702084 norm:nan max memory_allocated 22722.11767578125 
[2025-03-22 05:48:03 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 24 ===
[2025-03-22 05:48:39 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 0 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:49:12 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 1 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:49:44 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 2 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:50:17 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 3 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:50:49 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 4 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:51:21 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 5 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:51:54 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 6 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:52:26 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 7 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:52:59 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 8 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:53:31 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 9 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:54:03 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 10 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:54:36 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 11 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:55:08 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 12 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:55:41 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 13 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:56:13 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 14 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:56:45 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 15 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:57:18 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 16 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:57:50 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 17 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:58:22 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 18 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:58:55 root] (abq_llm_calibration_a2.py 394): INFO layer 24 iter 19 loss:0.003138527739793062 norm:nan max memory_allocated 22722.28955078125 
[2025-03-22 05:59:04 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 25 ===
[2025-03-22 05:59:41 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 0 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:00:14 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 1 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:00:46 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 2 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:01:19 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 3 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:01:51 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 4 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:02:23 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 5 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:02:56 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 6 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:03:28 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 7 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:04:01 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 8 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:04:33 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 9 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:05:05 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 10 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:05:38 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 11 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:06:10 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 12 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:06:43 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 13 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:07:15 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 14 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:07:48 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 15 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:08:20 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 16 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:08:52 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 17 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:09:25 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 18 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:09:57 root] (abq_llm_calibration_a2.py 394): INFO layer 25 iter 19 loss:0.0032257146667689085 norm:nan max memory_allocated 22722.46142578125 
[2025-03-22 06:10:06 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 26 ===
[2025-03-22 06:10:43 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 0 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:11:15 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 1 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:11:47 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 2 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:12:20 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 3 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:12:52 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 4 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:13:25 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 5 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:13:57 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 6 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:14:29 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 7 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:15:02 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 8 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:15:34 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 9 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:16:07 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 10 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:16:39 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 11 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:17:11 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 12 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:17:44 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 13 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:18:16 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 14 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:18:48 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 15 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:19:21 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 16 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:19:53 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 17 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:20:26 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 18 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:20:58 root] (abq_llm_calibration_a2.py 394): INFO layer 26 iter 19 loss:0.003301078686490655 norm:nan max memory_allocated 22722.63330078125 
[2025-03-22 06:21:07 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 27 ===
[2025-03-22 06:21:44 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 0 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:22:16 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 1 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:22:48 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 2 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:23:21 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 3 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:23:53 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 4 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:24:26 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 5 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:24:58 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 6 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:25:30 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 7 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:26:03 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 8 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:26:35 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 9 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:27:08 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 10 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:27:40 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 11 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:28:13 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 12 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:28:45 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 13 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:29:17 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 14 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:29:50 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 15 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:30:22 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 16 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:30:54 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 17 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:31:27 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 18 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:31:59 root] (abq_llm_calibration_a2.py 394): INFO layer 27 iter 19 loss:0.003589729778468609 norm:nan max memory_allocated 22722.80517578125 
[2025-03-22 06:32:09 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 28 ===
[2025-03-22 06:32:12 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:32:46 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 0 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:33:18 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 1 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:33:51 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 2 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:34:23 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 3 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:34:56 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 4 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:35:28 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 5 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:36:01 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 6 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:36:33 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 7 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:37:06 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 8 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:37:39 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 9 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:38:11 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 10 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:38:44 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 11 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:39:16 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 12 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:39:49 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 13 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:40:21 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 14 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:40:54 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 15 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:41:26 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 16 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:41:59 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 17 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:42:31 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 18 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:43:04 root] (abq_llm_calibration_a2.py 394): INFO layer 28 iter 19 loss:0.0037221733946353197 norm:nan max memory_allocated 22722.97705078125 
[2025-03-22 06:43:13 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 29 ===
[2025-03-22 06:43:16 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:43:49 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 0 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:44:22 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 1 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:44:55 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 2 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:45:27 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 3 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:46:00 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 4 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:46:32 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 5 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:47:05 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 6 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:47:38 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 7 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:48:10 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 8 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:48:43 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 9 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:49:15 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 10 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:49:48 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 11 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:50:21 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 12 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:50:53 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 13 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:51:26 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 14 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:51:58 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 15 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:52:31 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 16 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:53:04 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 17 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:53:36 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 18 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:54:09 root] (abq_llm_calibration_a2.py 394): INFO layer 29 iter 19 loss:0.004481349606066942 norm:nan max memory_allocated 22723.14892578125 
[2025-03-22 06:54:18 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 30 ===
[2025-03-22 06:54:21 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 06:54:54 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 0 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 06:55:27 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 1 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 06:56:00 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 2 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 06:56:32 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 3 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 06:57:05 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 4 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 06:57:37 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 5 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 06:58:10 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 6 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 06:58:42 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 7 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 06:59:15 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 8 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 06:59:48 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 9 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 07:00:20 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 10 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 07:00:53 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 11 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 07:01:25 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 12 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 07:01:58 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 13 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 07:02:31 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 14 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 07:03:03 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 15 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 07:03:36 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 16 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 07:04:08 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 17 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 07:04:41 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 18 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 07:05:13 root] (abq_llm_calibration_a2.py 394): INFO layer 30 iter 19 loss:0.00639831367880106 norm:nan max memory_allocated 22723.32080078125 
[2025-03-22 07:05:23 root] (abq_llm_calibration_a2.py 212): INFO === Start quantize layer 31 ===
[2025-03-22 07:05:26 root] (abq_llm_calibration_a2.py 276): INFO use compensation vector
[2025-03-22 07:05:59 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 0 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:06:31 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 1 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:07:04 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 2 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:07:36 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 3 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:08:09 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 4 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:08:42 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 5 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:09:14 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 6 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:09:47 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 7 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:10:20 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 8 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:10:52 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 9 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:11:25 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 10 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:11:57 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 11 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:12:30 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 12 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:13:03 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 13 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:13:35 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 14 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:14:08 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 15 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:14:40 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 16 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:15:13 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 17 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:15:46 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 18 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:16:18 root] (abq_llm_calibration_a2.py 394): INFO layer 31 iter 19 loss:0.029819373041391373 norm:nan max memory_allocated 22723.49267578125 
[2025-03-22 07:16:28 root] (main_calibration_a2.py 370): INFO 21210.077124357224
[2025-03-22 07:16:33 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-22 07:17:44 root] (main_calibration_a2.py 158): INFO wikitext2 : 61.546878814697266
[2025-03-22 07:17:44 root] (main_calibration_a2.py 114): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-22 07:19:31 root] (main_calibration_a2.py 158): INFO c4 : 90.37531280517578
[2025-03-22 09:02:19 root] (main_calibration_a2.py 169): INFO {'wikitext2': 61.546878814697266, 'c4': 90.37531280517578, 'results': {'piqa': {'acc': 0.5495103373231773, 'acc_stderr': 0.011608491028638184, 'acc_norm': 0.5429815016322089, 'acc_norm_stderr': 0.011622641132301959}, 'hellaswag': {'acc': 0.29117705636327423, 'acc_stderr': 0.004533764686211992, 'acc_norm': 0.3234415455088628, 'acc_norm_stderr': 0.004668335725410283}, 'winogrande': {'acc': 0.5090765588003157, 'acc_stderr': 0.014050170094497704}, 'boolq': {'acc': 0.5715596330275229, 'acc_stderr': 0.00865502856151977}, 'arc_easy': {'acc': 0.31523569023569026, 'acc_stderr': 0.009533589368505858, 'acc_norm': 0.31313131313131315, 'acc_norm_stderr': 0.009516303879309537}, 'arc_challenge': {'acc': 0.21160409556313994, 'acc_stderr': 0.011935916358632849, 'acc_norm': 0.25341296928327645, 'acc_norm_stderr': 0.012710896778378607}}, 'versions': {'piqa': 0, 'hellaswag': 0, 'winogrande': 0, 'boolq': 1, 'arc_easy': 0, 'arc_challenge': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
[2025-03-22 09:02:19 root] (main_calibration_a2.py 172): INFO 21.16,31.52,57.16,29.12,54.95,50.91
