[2025-03-16 02:49:37 root] (main_calib_config3_cbq.py 280): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-divide-adaptive-calibration-cbq/llama-7b-hf-0.45', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-divide-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.45.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-16 02:51:21 root] (main_calib_config3_cbq.py 347): INFO === start quantization ===
[2025-03-16 02:51:21 root] (main_calib_config3_cbq.py 353): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-16 02:51:21 root] (abq_llm_calib_config3_cbq.py 82): INFO Starting ...
[2025-03-16 02:51:21 root] (abq_llm_calib_config3_cbq.py 89): INFO Loaded quant_map from log-divide-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.45.pkl
[2025-03-16 02:51:26 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 0 to 1 ===
[2025-03-16 02:52:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 0 loss:0.049850884824991226 norm:0.09031206369400024 max memory_allocated 38101.85986328125 
[2025-03-16 02:53:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 1 loss:0.027620842680335045 norm:0.0684484913945198 max memory_allocated 38101.85986328125 
[2025-03-16 02:54:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 2 loss:0.02050013095140457 norm:0.04958860203623772 max memory_allocated 38101.85986328125 
[2025-03-16 02:55:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 3 loss:0.0175398550927639 norm:0.04142065346240997 max memory_allocated 38101.85986328125 
[2025-03-16 02:56:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 4 loss:0.01578584313392639 norm:0.02935643121600151 max memory_allocated 38101.85986328125 
[2025-03-16 02:57:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 5 loss:0.014574320055544376 norm:0.022231468930840492 max memory_allocated 38101.85986328125 
[2025-03-16 02:58:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 6 loss:0.01354715134948492 norm:0.015006409958004951 max memory_allocated 38101.85986328125 
[2025-03-16 02:59:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 7 loss:0.012862922623753548 norm:0.01318986527621746 max memory_allocated 38101.85986328125 
[2025-03-16 03:00:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 8 loss:0.012410087510943413 norm:0.01146581768989563 max memory_allocated 38101.85986328125 
[2025-03-16 03:01:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 9 loss:0.012093105353415012 norm:0.010789046995341778 max memory_allocated 38101.85986328125 
[2025-03-16 03:01:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 10 loss:0.011754028499126434 norm:0.007543160114437342 max memory_allocated 38101.85986328125 
[2025-03-16 03:02:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 11 loss:0.011516610160470009 norm:0.006335989572107792 max memory_allocated 38101.85986328125 
[2025-03-16 03:03:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 12 loss:0.01135846134275198 norm:0.005434098653495312 max memory_allocated 38101.85986328125 
[2025-03-16 03:04:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 13 loss:0.011178188025951385 norm:0.004923748318105936 max memory_allocated 38101.85986328125 
[2025-03-16 03:05:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 14 loss:0.01107545755803585 norm:0.004615012090653181 max memory_allocated 38101.85986328125 
[2025-03-16 03:06:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 15 loss:0.011046222411096096 norm:0.004611781798303127 max memory_allocated 38101.85986328125 
[2025-03-16 03:07:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 16 loss:0.010828698053956032 norm:0.003926041070371866 max memory_allocated 38101.85986328125 
[2025-03-16 03:08:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 17 loss:0.010840593837201595 norm:0.004084818996489048 max memory_allocated 38101.85986328125 
[2025-03-16 03:09:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 18 loss:0.010794561356306076 norm:0.004417083226144314 max memory_allocated 38101.85986328125 
[2025-03-16 03:10:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 19 loss:0.010821787640452385 norm:0.004185497760772705 max memory_allocated 38101.85986328125 
[2025-03-16 03:11:03 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 1 to 2 ===
[2025-03-16 03:12:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 0 loss:0.0645650327205658 norm:0.151251882314682 max memory_allocated 38134.54931640625 
[2025-03-16 03:13:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 1 loss:0.022965019568800926 norm:0.06089837849140167 max memory_allocated 38134.54931640625 
[2025-03-16 03:13:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 2 loss:0.016769548878073692 norm:0.04000448063015938 max memory_allocated 38134.54931640625 
[2025-03-16 03:14:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 3 loss:0.015813251957297325 norm:0.035977307707071304 max memory_allocated 38134.54931640625 
[2025-03-16 03:15:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 4 loss:0.014510736800730228 norm:0.03383537009358406 max memory_allocated 38134.54931640625 
[2025-03-16 03:16:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 5 loss:0.013205775059759617 norm:0.029744736850261688 max memory_allocated 38134.54931640625 
[2025-03-16 03:17:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 6 loss:0.012672596611082554 norm:0.03183818608522415 max memory_allocated 38134.54931640625 
[2025-03-16 03:18:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 7 loss:0.01220543123781681 norm:0.03133927658200264 max memory_allocated 38134.54931640625 
[2025-03-16 03:19:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 8 loss:0.011491147801280022 norm:0.02703125588595867 max memory_allocated 38134.54931640625 
[2025-03-16 03:20:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 9 loss:0.011034738272428513 norm:0.02416515350341797 max memory_allocated 38134.54931640625 
[2025-03-16 03:21:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 10 loss:0.011537190526723862 norm:0.031488969922065735 max memory_allocated 38134.54931640625 
[2025-03-16 03:22:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 11 loss:0.010948434472084045 norm:0.028820782899856567 max memory_allocated 38134.54931640625 
[2025-03-16 03:23:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 12 loss:0.011643846519291401 norm:0.03359537199139595 max memory_allocated 38134.54931640625 
[2025-03-16 03:24:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 13 loss:0.011531943455338478 norm:0.03123355656862259 max memory_allocated 38134.54931640625 
[2025-03-16 03:25:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 14 loss:0.011824086308479309 norm:0.0332566499710083 max memory_allocated 38134.54931640625 
[2025-03-16 03:26:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 15 loss:0.014352812431752682 norm:0.03207867965102196 max memory_allocated 38134.54931640625 
[2025-03-16 03:27:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 16 loss:0.011053577996790409 norm:0.014623334631323814 max memory_allocated 38134.54931640625 
[2025-03-16 03:28:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 17 loss:0.010107265785336494 norm:0.00919298641383648 max memory_allocated 38134.54931640625 
[2025-03-16 03:29:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 18 loss:0.010074550285935402 norm:0.009626678191125393 max memory_allocated 38134.54931640625 
[2025-03-16 03:30:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 19 loss:0.009352104738354683 norm:0.006809910759329796 max memory_allocated 38134.54931640625 
[2025-03-16 03:30:42 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 2 to 3 ===
[2025-03-16 03:31:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 0 loss:0.025844717398285866 norm:0.004258819855749607 max memory_allocated 38134.54931640625 
[2025-03-16 03:32:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 1 loss:0.017610453069210052 norm:0.0025654705241322517 max memory_allocated 38134.54931640625 
[2025-03-16 03:33:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 2 loss:0.014239530079066753 norm:0.001792806200683117 max memory_allocated 38134.54931640625 
[2025-03-16 03:34:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 3 loss:0.012595280073583126 norm:0.0012830260675400496 max memory_allocated 38134.54931640625 
[2025-03-16 03:35:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 4 loss:0.01184492651373148 norm:0.0010700155980885029 max memory_allocated 38134.54931640625 
[2025-03-16 03:36:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 5 loss:0.01144745759665966 norm:0.0008707034285180271 max memory_allocated 38134.54931640625 
[2025-03-16 03:37:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 6 loss:0.01113557443022728 norm:0.0009339306852780282 max memory_allocated 38134.54931640625 
[2025-03-16 03:38:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 7 loss:0.011363236233592033 norm:0.0008143334416672587 max memory_allocated 38134.54931640625 
[2025-03-16 03:39:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 8 loss:0.011495411396026611 norm:0.0006705868290737271 max memory_allocated 38134.54931640625 
[2025-03-16 03:40:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 9 loss:0.01118867751210928 norm:0.0004428562242537737 max memory_allocated 38134.54931640625 
[2025-03-16 03:41:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 10 loss:0.011038798838853836 norm:0.0004239376576151699 max memory_allocated 38134.54931640625 
[2025-03-16 03:42:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 11 loss:0.010943147353827953 norm:0.0004333177930675447 max memory_allocated 38134.54931640625 
[2025-03-16 03:43:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 12 loss:0.010878614149987698 norm:0.0004350561066530645 max memory_allocated 38134.54931640625 
[2025-03-16 03:44:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 13 loss:0.010829882696270943 norm:0.00044593261554837227 max memory_allocated 38134.54931640625 
[2025-03-16 03:45:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 14 loss:0.010775788687169552 norm:0.0004544769471976906 max memory_allocated 38134.54931640625 
[2025-03-16 03:46:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 15 loss:0.01074215117841959 norm:0.00047443326911889017 max memory_allocated 38134.54931640625 
[2025-03-16 03:46:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 16 loss:0.010675677098333836 norm:0.0004752444219775498 max memory_allocated 38134.54931640625 
[2025-03-16 03:47:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 17 loss:0.010613509453833103 norm:0.00048000484821386635 max memory_allocated 38134.54931640625 
[2025-03-16 03:48:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 18 loss:0.010539218783378601 norm:0.0004685578460339457 max memory_allocated 38134.54931640625 
[2025-03-16 03:49:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 19 loss:0.010498703457415104 norm:0.00046072143595665693 max memory_allocated 38134.54931640625 
[2025-03-16 03:50:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 3 to 4 ===
[2025-03-16 03:51:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 0 loss:0.024703744798898697 norm:0.0628986731171608 max memory_allocated 38134.54931640625 
[2025-03-16 03:52:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 1 loss:0.016329649835824966 norm:0.003055400215089321 max memory_allocated 38134.54931640625 
[2025-03-16 03:53:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 2 loss:0.013071209192276001 norm:0.0022956007160246372 max memory_allocated 38134.54931640625 
[2025-03-16 03:54:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 3 loss:0.011806757189333439 norm:0.0017729069804772735 max memory_allocated 38134.54931640625 
[2025-03-16 03:55:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 4 loss:0.011222802102565765 norm:0.0014783833175897598 max memory_allocated 38134.54931640625 
[2025-03-16 03:56:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 5 loss:0.01083358097821474 norm:0.001268013147637248 max memory_allocated 38134.54931640625 
[2025-03-16 03:57:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 6 loss:0.0105538135394454 norm:0.0011177941923961043 max memory_allocated 38134.54931640625 
[2025-03-16 03:58:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 7 loss:0.010314016602933407 norm:0.0009596413001418114 max memory_allocated 38134.54931640625 
[2025-03-16 03:59:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 8 loss:0.010164035484194756 norm:0.000852414988912642 max memory_allocated 38134.54931640625 
[2025-03-16 03:59:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 9 loss:0.010101169347763062 norm:0.0007556966738775373 max memory_allocated 38134.54931640625 
[2025-03-16 04:00:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 10 loss:0.010050500743091106 norm:0.0006749520543962717 max memory_allocated 38134.54931640625 
[2025-03-16 04:01:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 11 loss:0.010018139146268368 norm:0.0006068073562346399 max memory_allocated 38134.54931640625 
[2025-03-16 04:02:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 12 loss:0.009997624903917313 norm:0.0005532767972908914 max memory_allocated 38134.54931640625 
[2025-03-16 04:03:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 13 loss:0.009980500675737858 norm:0.0004908631090074778 max memory_allocated 38134.54931640625 
[2025-03-16 04:04:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 14 loss:0.009959266521036625 norm:0.00045277061872184277 max memory_allocated 38134.54931640625 
[2025-03-16 04:05:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 15 loss:0.009954746812582016 norm:0.0004026230308227241 max memory_allocated 38134.54931640625 
[2025-03-16 04:06:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 16 loss:0.009934023022651672 norm:0.00036949769128113985 max memory_allocated 38134.54931640625 
[2025-03-16 04:07:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 17 loss:0.009904082864522934 norm:0.00034525152295827866 max memory_allocated 38134.54931640625 
[2025-03-16 04:08:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 18 loss:0.009895648807287216 norm:0.0003198535705450922 max memory_allocated 38134.54931640625 
[2025-03-16 04:09:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 19 loss:0.009878222830593586 norm:0.0003070563543587923 max memory_allocated 38134.54931640625 
[2025-03-16 04:09:57 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 4 to 5 ===
[2025-03-16 04:10:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 0 loss:0.03181753307580948 norm:0.0025382039602845907 max memory_allocated 38134.71923828125 
[2025-03-16 04:11:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 1 loss:0.02189713530242443 norm:0.0011821925872936845 max memory_allocated 38134.71923828125 
[2025-03-16 04:12:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 2 loss:0.017568234354257584 norm:0.0006798385293222964 max memory_allocated 38134.71923828125 
[2025-03-16 04:13:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 3 loss:0.015772152692079544 norm:0.00045997818233445287 max memory_allocated 38134.71923828125 
[2025-03-16 04:14:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 4 loss:0.014821899123489857 norm:0.0003509109083097428 max memory_allocated 38134.71923828125 
[2025-03-16 04:15:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 5 loss:0.014179741032421589 norm:0.00028457926237024367 max memory_allocated 38134.71923828125 
[2025-03-16 04:16:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 6 loss:0.013782862573862076 norm:0.0002519006375223398 max memory_allocated 38134.71923828125 
[2025-03-16 04:17:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 7 loss:0.013482649810612202 norm:0.00023150962078943849 max memory_allocated 38134.71923828125 
[2025-03-16 04:18:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 8 loss:0.013327749446034431 norm:0.00023379101185128093 max memory_allocated 38134.71923828125 
[2025-03-16 04:19:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 9 loss:0.013197861611843109 norm:0.00023215811233967543 max memory_allocated 38134.71923828125 
[2025-03-16 04:20:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 10 loss:0.013090440072119236 norm:0.00021882086002733558 max memory_allocated 38134.71923828125 
[2025-03-16 04:21:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 11 loss:0.01300464291125536 norm:0.0002081983257085085 max memory_allocated 38134.71923828125 
[2025-03-16 04:22:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 12 loss:0.012949233874678612 norm:0.000208210592973046 max memory_allocated 38134.71923828125 
[2025-03-16 04:23:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 13 loss:0.012920143082737923 norm:0.00020601028518285602 max memory_allocated 38134.71923828125 
[2025-03-16 04:24:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 14 loss:0.01288283709436655 norm:0.00020802204380743206 max memory_allocated 38134.71923828125 
[2025-03-16 04:25:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 15 loss:0.01287273969501257 norm:0.0002036337391473353 max memory_allocated 38134.71923828125 
[2025-03-16 04:26:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 16 loss:0.012844780460000038 norm:0.00019722319848369807 max memory_allocated 38134.71923828125 
[2025-03-16 04:27:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 17 loss:0.012838668189942837 norm:0.00019851961405947804 max memory_allocated 38134.71923828125 
[2025-03-16 04:28:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 18 loss:0.012837592512369156 norm:0.00019452895503491163 max memory_allocated 38134.71923828125 
[2025-03-16 04:29:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 19 loss:0.012830797582864761 norm:0.00019680063996929675 max memory_allocated 38134.71923828125 
[2025-03-16 04:29:34 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 5 to 6 ===
[2025-03-16 04:30:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 0 loss:0.024396143853664398 norm:0.0015929435612633824 max memory_allocated 38134.89111328125 
[2025-03-16 04:31:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 1 loss:0.01736454851925373 norm:0.0005869223969057202 max memory_allocated 38134.89111328125 
[2025-03-16 04:32:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 2 loss:0.014308799058198929 norm:0.0003201294457539916 max memory_allocated 38134.89111328125 
[2025-03-16 04:33:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 3 loss:0.01308988593518734 norm:0.00022220663959160447 max memory_allocated 38134.89111328125 
[2025-03-16 04:34:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 4 loss:0.012477001175284386 norm:0.0001809977402444929 max memory_allocated 38134.89111328125 
[2025-03-16 04:35:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 5 loss:0.01208430714905262 norm:0.00017078928067348897 max memory_allocated 38134.89111328125 
[2025-03-16 04:36:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 6 loss:0.011800065636634827 norm:0.00016241814591921866 max memory_allocated 38134.89111328125 
[2025-03-16 04:37:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 7 loss:0.011594127863645554 norm:0.0001536131458124146 max memory_allocated 38134.89111328125 
[2025-03-16 04:38:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 8 loss:0.011436386033892632 norm:0.00014333207218442112 max memory_allocated 38134.89111328125 
[2025-03-16 04:39:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 9 loss:0.011311548762023449 norm:0.00013750184734817594 max memory_allocated 38134.89111328125 
[2025-03-16 04:40:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 10 loss:0.011249066330492496 norm:0.00013814185513183475 max memory_allocated 38134.89111328125 
[2025-03-16 04:41:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 11 loss:0.011196635663509369 norm:0.0001386833464493975 max memory_allocated 38134.89111328125 
[2025-03-16 04:42:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 12 loss:0.011144532822072506 norm:0.00013695126108359545 max memory_allocated 38134.89111328125 
[2025-03-16 04:42:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 13 loss:0.011097906157374382 norm:0.00013822127948515117 max memory_allocated 38134.89111328125 
[2025-03-16 04:43:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 14 loss:0.011042569763958454 norm:0.00013892883725930005 max memory_allocated 38134.89111328125 
[2025-03-16 04:44:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 15 loss:0.010995371267199516 norm:0.00013525670510716736 max memory_allocated 38134.89111328125 
[2025-03-16 04:45:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 16 loss:0.010969461873173714 norm:0.00013589859008789062 max memory_allocated 38134.89111328125 
[2025-03-16 04:46:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 17 loss:0.010931449942290783 norm:0.00013059632328804582 max memory_allocated 38134.89111328125 
[2025-03-16 04:47:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 18 loss:0.01092586014419794 norm:0.00013427171506918967 max memory_allocated 38134.89111328125 
[2025-03-16 04:48:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 19 loss:0.010919705033302307 norm:0.00012975359277334064 max memory_allocated 38134.89111328125 
[2025-03-16 04:49:12 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 6 to 7 ===
[2025-03-16 04:50:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 0 loss:0.01910300925374031 norm:0.0007473996374756098 max memory_allocated 38135.06298828125 
[2025-03-16 04:51:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 1 loss:0.013915610499680042 norm:0.00030842554406262934 max memory_allocated 38135.06298828125 
[2025-03-16 04:52:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 2 loss:0.011504839174449444 norm:0.00019385408086236566 max memory_allocated 38135.06298828125 
[2025-03-16 04:53:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 3 loss:0.010494975373148918 norm:0.000134749585413374 max memory_allocated 38135.06298828125 
[2025-03-16 04:54:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 4 loss:0.00997643731534481 norm:0.00011645212362054735 max memory_allocated 38135.06298828125 
[2025-03-16 04:55:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 5 loss:0.009628132916986942 norm:0.0001043181327986531 max memory_allocated 38135.06298828125 
[2025-03-16 04:56:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 6 loss:0.009369943290948868 norm:9.865802712738514e-05 max memory_allocated 38135.06298828125 
[2025-03-16 04:56:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 7 loss:0.00919684674590826 norm:9.213059820467606e-05 max memory_allocated 38135.06298828125 
[2025-03-16 04:57:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 8 loss:0.009074652567505836 norm:8.920218533603474e-05 max memory_allocated 38135.06298828125 
[2025-03-16 04:58:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 9 loss:0.008990815840661526 norm:8.920067921280861e-05 max memory_allocated 38135.06298828125 
[2025-03-16 04:59:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 10 loss:0.008933838456869125 norm:8.783192606642842e-05 max memory_allocated 38135.06298828125 
[2025-03-16 05:00:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 11 loss:0.00890374556183815 norm:8.807705307845026e-05 max memory_allocated 38135.06298828125 
[2025-03-16 05:01:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 12 loss:0.008874314837157726 norm:8.728881948627532e-05 max memory_allocated 38135.06298828125 
[2025-03-16 05:02:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 13 loss:0.008863050490617752 norm:8.542006980860606e-05 max memory_allocated 38135.06298828125 
[2025-03-16 05:03:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 14 loss:0.008840075694024563 norm:8.450380119029433e-05 max memory_allocated 38135.06298828125 
[2025-03-16 05:04:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 15 loss:0.008839262649416924 norm:8.469392923871055e-05 max memory_allocated 38135.06298828125 
[2025-03-16 05:05:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 16 loss:0.008833793923258781 norm:8.232458640122786e-05 max memory_allocated 38135.06298828125 
[2025-03-16 05:06:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 17 loss:0.008846357464790344 norm:8.15881066955626e-05 max memory_allocated 38135.06298828125 
[2025-03-16 05:07:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 18 loss:0.008853177540004253 norm:8.03470320533961e-05 max memory_allocated 38135.06298828125 
[2025-03-16 05:08:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 19 loss:0.008860054425895214 norm:7.928424747660756e-05 max memory_allocated 38135.06298828125 
[2025-03-16 05:08:52 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 7 to 8 ===
[2025-03-16 05:09:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 0 loss:0.021155113354325294 norm:0.001065136631950736 max memory_allocated 38137.23486328125 
[2025-03-16 05:10:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 1 loss:0.01548018492758274 norm:0.0004434110887814313 max memory_allocated 38137.23486328125 
[2025-03-16 05:11:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 2 loss:0.012650608085095882 norm:0.00024792554904706776 max memory_allocated 38137.23486328125 
[2025-03-16 05:12:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 3 loss:0.011430189944803715 norm:0.00017262320034205914 max memory_allocated 38137.23486328125 
[2025-03-16 05:13:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 4 loss:0.01080175582319498 norm:0.00013445626245811582 max memory_allocated 38137.23486328125 
[2025-03-16 05:14:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 5 loss:0.010400617495179176 norm:0.00011386017285985872 max memory_allocated 38137.23486328125 
[2025-03-16 05:15:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 6 loss:0.010147161781787872 norm:0.00010097218910232186 max memory_allocated 38137.23486328125 
[2025-03-16 05:16:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 7 loss:0.009981648065149784 norm:9.493192192167044e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:17:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 8 loss:0.009854156523942947 norm:8.89824004843831e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:18:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 9 loss:0.009799194522202015 norm:8.79085055203177e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:19:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 10 loss:0.009740205481648445 norm:8.533905929652974e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:20:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 11 loss:0.009744876064360142 norm:8.524656732333824e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:21:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 12 loss:0.009732011705636978 norm:8.285811054520309e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:22:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 13 loss:0.009720776230096817 norm:8.029086166061461e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:23:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 14 loss:0.009713174775242805 norm:8.105032611638308e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:24:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 15 loss:0.00970316119492054 norm:8.113704825518653e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:25:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 16 loss:0.009702524170279503 norm:8.078449172899127e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:26:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 17 loss:0.009701612405478954 norm:8.045882714213803e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:27:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 18 loss:0.009695583954453468 norm:8.038902160478756e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:27:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 19 loss:0.00969582051038742 norm:8.203207107726485e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:28:28 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 8 to 9 ===
[2025-03-16 05:29:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 0 loss:0.024516906589269638 norm:0.0011087125167250633 max memory_allocated 38137.23486328125 
[2025-03-16 05:30:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 1 loss:0.017727060243487358 norm:0.00048702050116844475 max memory_allocated 38137.23486328125 
[2025-03-16 05:31:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 2 loss:0.014545110985636711 norm:0.0002719432523008436 max memory_allocated 38137.23486328125 
[2025-03-16 05:32:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 3 loss:0.013190863654017448 norm:0.00018712278688326478 max memory_allocated 38137.23486328125 
[2025-03-16 05:33:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 4 loss:0.012500186450779438 norm:0.0001510346046416089 max memory_allocated 38137.23486328125 
[2025-03-16 05:34:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 5 loss:0.012083056382834911 norm:0.0001327851350652054 max memory_allocated 38137.23486328125 
[2025-03-16 05:35:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 6 loss:0.011801816523075104 norm:0.00012311071623116732 max memory_allocated 38137.23486328125 
[2025-03-16 05:36:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 7 loss:0.011579307727515697 norm:0.000115664501208812 max memory_allocated 38137.23486328125 
[2025-03-16 05:37:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 8 loss:0.011443156749010086 norm:0.00011166073090862483 max memory_allocated 38137.23486328125 
[2025-03-16 05:38:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 9 loss:0.011359835974872112 norm:0.0001096185515052639 max memory_allocated 38137.23486328125 
[2025-03-16 05:39:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 10 loss:0.011307132430374622 norm:0.00010667451715562493 max memory_allocated 38137.23486328125 
[2025-03-16 05:39:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 11 loss:0.01126854307949543 norm:0.00010318857675883919 max memory_allocated 38137.23486328125 
[2025-03-16 05:40:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 12 loss:0.011248904280364513 norm:0.000103725069493521 max memory_allocated 38137.23486328125 
[2025-03-16 05:41:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 13 loss:0.011230813339352608 norm:0.00010046351235359907 max memory_allocated 38137.23486328125 
[2025-03-16 05:42:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 14 loss:0.011230921372771263 norm:9.929921361617744e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:43:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 15 loss:0.011228146031498909 norm:9.631198190618306e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:44:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 16 loss:0.01122579537332058 norm:9.504704212304205e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:45:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 17 loss:0.011236561462283134 norm:9.6046322141774e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:46:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 18 loss:0.011227425187826157 norm:9.319426317233592e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:47:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 19 loss:0.011221791617572308 norm:9.613332076696679e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:48:04 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 9 to 10 ===
[2025-03-16 05:49:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 0 loss:0.021161165088415146 norm:0.0009141858899965882 max memory_allocated 38137.23486328125 
[2025-03-16 05:50:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 1 loss:0.015935633331537247 norm:0.00039207961526699364 max memory_allocated 38137.23486328125 
[2025-03-16 05:50:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 2 loss:0.013380392454564571 norm:0.00022474006982520223 max memory_allocated 38137.23486328125 
[2025-03-16 05:51:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 3 loss:0.012339795008301735 norm:0.00016113244055304676 max memory_allocated 38137.23486328125 
[2025-03-16 05:52:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 4 loss:0.011818446218967438 norm:0.00013184697309043258 max memory_allocated 38137.23486328125 
[2025-03-16 05:53:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 5 loss:0.01145763136446476 norm:0.00011561957944650203 max memory_allocated 38137.23486328125 
[2025-03-16 05:54:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 6 loss:0.011178030632436275 norm:0.00010559079237282276 max memory_allocated 38137.23486328125 
[2025-03-16 05:55:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 7 loss:0.011011423543095589 norm:0.0001004889199975878 max memory_allocated 38137.23486328125 
[2025-03-16 05:56:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 8 loss:0.010874059051275253 norm:9.645019599702209e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:57:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 9 loss:0.010793527588248253 norm:9.617373871151358e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:58:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 10 loss:0.010754837654531002 norm:9.45521896937862e-05 max memory_allocated 38137.23486328125 
[2025-03-16 05:59:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 11 loss:0.010719622485339642 norm:9.225379471899942e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:00:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 12 loss:0.010687656700611115 norm:8.879189408617094e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:01:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 13 loss:0.010688507929444313 norm:8.74983670655638e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:02:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 14 loss:0.010700185783207417 norm:8.583722956245765e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:03:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 15 loss:0.010713253170251846 norm:8.540446287952363e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:04:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 16 loss:0.010698438622057438 norm:8.61186272231862e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:05:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 17 loss:0.010699628852307796 norm:8.516124216839671e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:06:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 18 loss:0.010694297961890697 norm:8.557036926504225e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:07:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 19 loss:0.010691031813621521 norm:8.576013351557776e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:07:39 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 10 to 11 ===
[2025-03-16 06:08:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 0 loss:0.02443847432732582 norm:0.0009537120931781828 max memory_allocated 38137.23486328125 
[2025-03-16 06:09:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 1 loss:0.01843082159757614 norm:0.00043146181269548833 max memory_allocated 38137.23486328125 
[2025-03-16 06:10:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 2 loss:0.015187956392765045 norm:0.00024545277119614184 max memory_allocated 38137.23486328125 
[2025-03-16 06:11:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 3 loss:0.013733664527535439 norm:0.0001616655063116923 max memory_allocated 38137.23486328125 
[2025-03-16 06:12:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 4 loss:0.013130711391568184 norm:0.0001339527079835534 max memory_allocated 38137.23486328125 
[2025-03-16 06:13:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 5 loss:0.012774720788002014 norm:0.00011778423504438251 max memory_allocated 38137.23486328125 
[2025-03-16 06:14:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 6 loss:0.012519755400717258 norm:0.00010589828161755577 max memory_allocated 38137.23486328125 
[2025-03-16 06:15:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 7 loss:0.012344945222139359 norm:0.00010132182796951383 max memory_allocated 38137.23486328125 
[2025-03-16 06:16:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 8 loss:0.012231028638780117 norm:9.761276305653155e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:17:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 9 loss:0.012166929431259632 norm:9.45187421166338e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:18:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 10 loss:0.012147171422839165 norm:9.123695053858683e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:19:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 11 loss:0.012146670371294022 norm:8.898643864085898e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:20:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 12 loss:0.012162069790065289 norm:8.707921369932592e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:21:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 13 loss:0.012147339060902596 norm:8.551179053029045e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:21:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 14 loss:0.012134863995015621 norm:8.567747863708064e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:22:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 15 loss:0.012139669619500637 norm:8.650874951854348e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:23:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 16 loss:0.012138758786022663 norm:8.510998304700479e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:24:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 17 loss:0.012132015079259872 norm:8.428815635852516e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:25:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 18 loss:0.012121095322072506 norm:8.477781375404447e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:26:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 19 loss:0.012112405151128769 norm:8.394817996304482e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:27:15 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 11 to 12 ===
[2025-03-16 06:28:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 0 loss:0.02644810825586319 norm:0.0007649314356967807 max memory_allocated 38137.23486328125 
[2025-03-16 06:29:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 1 loss:0.020123882219195366 norm:0.00035924615804105997 max memory_allocated 38137.23486328125 
[2025-03-16 06:30:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 2 loss:0.016687465831637383 norm:0.00022632484615314752 max memory_allocated 38137.23486328125 
[2025-03-16 06:31:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 3 loss:0.015200047753751278 norm:0.000166589961736463 max memory_allocated 38137.23486328125 
[2025-03-16 06:32:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 4 loss:0.014451656490564346 norm:0.00014451186871156096 max memory_allocated 38137.23486328125 
[2025-03-16 06:33:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 5 loss:0.01398049108684063 norm:0.00013153254985809326 max memory_allocated 38137.23486328125 
[2025-03-16 06:34:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 6 loss:0.013675904832780361 norm:0.00013054217561148107 max memory_allocated 38137.23486328125 
[2025-03-16 06:34:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 7 loss:0.013445298187434673 norm:0.00012090529344277456 max memory_allocated 38137.23486328125 
[2025-03-16 06:35:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 8 loss:0.013311609625816345 norm:0.00011290101247141138 max memory_allocated 38137.23486328125 
[2025-03-16 06:36:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 9 loss:0.013238293118774891 norm:0.00010732753435149789 max memory_allocated 38137.23486328125 
[2025-03-16 06:37:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 10 loss:0.013188013806939125 norm:0.00010129712609341368 max memory_allocated 38137.23486328125 
[2025-03-16 06:38:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 11 loss:0.01318154577165842 norm:0.00010058170300908387 max memory_allocated 38137.23486328125 
[2025-03-16 06:39:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 12 loss:0.01318541169166565 norm:9.78744646999985e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:40:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 13 loss:0.01316012628376484 norm:9.548058005748317e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:41:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 14 loss:0.013149241916835308 norm:9.693874744698405e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:42:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 15 loss:0.013134811073541641 norm:9.547793888486922e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:43:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 16 loss:0.013135183602571487 norm:9.66886873356998e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:44:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 17 loss:0.0131234060972929 norm:9.404610318597406e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:45:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 18 loss:0.013111798092722893 norm:9.802681597648188e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:46:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 19 loss:0.013104098848998547 norm:9.688644058769569e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:46:53 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 12 to 13 ===
[2025-03-16 06:47:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 0 loss:0.024605344980955124 norm:0.0006377930985763669 max memory_allocated 38137.23486328125 
[2025-03-16 06:48:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 1 loss:0.01917637698352337 norm:0.0002906663576141 max memory_allocated 38137.23486328125 
[2025-03-16 06:49:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 2 loss:0.016035156324505806 norm:0.00018799904501065612 max memory_allocated 38137.23486328125 
[2025-03-16 06:50:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 3 loss:0.014929299242794514 norm:0.0001494746102252975 max memory_allocated 38137.23486328125 
[2025-03-16 06:51:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 4 loss:0.014354455284774303 norm:0.00013208264135755599 max memory_allocated 38137.23486328125 
[2025-03-16 06:52:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 5 loss:0.013950214721262455 norm:0.00012128608068451285 max memory_allocated 38137.23486328125 
[2025-03-16 06:53:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 6 loss:0.013676149770617485 norm:0.00011375375470379367 max memory_allocated 38137.23486328125 
[2025-03-16 06:54:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 7 loss:0.01350745465606451 norm:0.00010954630852211267 max memory_allocated 38137.23486328125 
[2025-03-16 06:55:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 8 loss:0.013411635532975197 norm:0.00010642792040016502 max memory_allocated 38137.23486328125 
[2025-03-16 06:56:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 9 loss:0.013339860364794731 norm:0.00010090964497067034 max memory_allocated 38137.23486328125 
[2025-03-16 06:57:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 10 loss:0.013300870545208454 norm:9.90638363873586e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:58:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 11 loss:0.01326221227645874 norm:9.833055810304359e-05 max memory_allocated 38137.23486328125 
[2025-03-16 06:59:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 12 loss:0.01324743963778019 norm:9.687034616945311e-05 max memory_allocated 38137.23486328125 
[2025-03-16 07:00:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 13 loss:0.01326078549027443 norm:9.682166273705661e-05 max memory_allocated 38137.23486328125 
[2025-03-16 07:01:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 14 loss:0.01326831802725792 norm:9.710935410112143e-05 max memory_allocated 38137.23486328125 
[2025-03-16 07:02:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 15 loss:0.013286878354847431 norm:9.839708945946768e-05 max memory_allocated 38137.23486328125 
[2025-03-16 07:03:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 16 loss:0.013293772004544735 norm:9.694344771560282e-05 max memory_allocated 38137.23486328125 
[2025-03-16 07:04:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 17 loss:0.013300911523401737 norm:9.547984518576413e-05 max memory_allocated 38137.23486328125 
[2025-03-16 07:05:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 18 loss:0.013300689868628979 norm:9.37574150157161e-05 max memory_allocated 38137.23486328125 
[2025-03-16 07:05:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 19 loss:0.013300513848662376 norm:9.372185013489798e-05 max memory_allocated 38137.23486328125 
[2025-03-16 07:06:29 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 13 to 14 ===
[2025-03-16 07:07:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 0 loss:0.029348373413085938 norm:0.0011508321622386575 max memory_allocated 38137.23486328125 
[2025-03-16 07:08:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 1 loss:0.022558405995368958 norm:0.0005201554740779102 max memory_allocated 38137.23486328125 
[2025-03-16 07:09:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 2 loss:0.018541714176535606 norm:0.0003042405587621033 max memory_allocated 38137.23486328125 
[2025-03-16 07:10:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 3 loss:0.01701977103948593 norm:0.00021719548385590315 max memory_allocated 38137.23486328125 
[2025-03-16 07:11:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 4 loss:0.01622525043785572 norm:0.00017282163025811315 max memory_allocated 38137.23486328125 
[2025-03-16 07:12:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 5 loss:0.01576547510921955 norm:0.00015227458789013326 max memory_allocated 38137.23486328125 
[2025-03-16 07:13:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 6 loss:0.015469247475266457 norm:0.0001372916594846174 max memory_allocated 38137.23486328125 
[2025-03-16 07:14:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 7 loss:0.015315858647227287 norm:0.00012736517237499356 max memory_allocated 38137.23486328125 
[2025-03-16 07:15:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 8 loss:0.01521829143166542 norm:0.00012339482782408595 max memory_allocated 38137.23486328125 
[2025-03-16 07:16:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 9 loss:0.015184706076979637 norm:0.00012036252155667171 max memory_allocated 38137.23486328125 
[2025-03-16 07:17:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 10 loss:0.015171902254223824 norm:0.00011530383926583454 max memory_allocated 38137.23486328125 
[2025-03-16 07:17:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 11 loss:0.015165265649557114 norm:0.00011129071208415553 max memory_allocated 38137.23486328125 
[2025-03-16 07:18:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 12 loss:0.015145311132073402 norm:0.00011056697985623032 max memory_allocated 38137.23486328125 
[2025-03-16 07:19:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 13 loss:0.015121044591069221 norm:0.00010655990627128631 max memory_allocated 38137.23486328125 
[2025-03-16 07:20:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 14 loss:0.015120020136237144 norm:0.00010701372229959816 max memory_allocated 38137.23486328125 
[2025-03-16 07:21:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 15 loss:0.015106511302292347 norm:0.0001068807760020718 max memory_allocated 38137.23486328125 
[2025-03-16 07:22:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 16 loss:0.015101314522325993 norm:0.00010678426770027727 max memory_allocated 38137.23486328125 
[2025-03-16 07:23:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 17 loss:0.015101801604032516 norm:0.00010788950748974457 max memory_allocated 38137.23486328125 
[2025-03-16 07:24:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 18 loss:0.015102689154446125 norm:0.00010691568604670465 max memory_allocated 38137.23486328125 
[2025-03-16 07:25:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 19 loss:0.015102744102478027 norm:0.00010611071775201708 max memory_allocated 38137.23486328125 
[2025-03-16 07:26:04 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 14 to 15 ===
[2025-03-16 07:27:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 0 loss:0.030039766803383827 norm:0.000901808962225914 max memory_allocated 38137.23486328125 
[2025-03-16 07:28:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 1 loss:0.02368255890905857 norm:0.00041022920049726963 max memory_allocated 38137.23486328125 
[2025-03-16 07:29:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 2 loss:0.01968957856297493 norm:0.0002495418593753129 max memory_allocated 38137.23486328125 
[2025-03-16 07:29:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 3 loss:0.018232280388474464 norm:0.00018753220501821488 max memory_allocated 38137.23486328125 
[2025-03-16 07:30:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 4 loss:0.01748545840382576 norm:0.00016034088912419975 max memory_allocated 38137.23486328125 
[2025-03-16 07:31:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 5 loss:0.01699625328183174 norm:0.00013931977446191013 max memory_allocated 38137.23486328125 
[2025-03-16 07:32:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 6 loss:0.016727065667510033 norm:0.0001334239641437307 max memory_allocated 38137.23486328125 
[2025-03-16 07:33:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 7 loss:0.01663261093199253 norm:0.0001301273878198117 max memory_allocated 38137.23486328125 
[2025-03-16 07:34:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 8 loss:0.016613850370049477 norm:0.00012486352352425456 max memory_allocated 38137.23486328125 
[2025-03-16 07:35:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 9 loss:0.016605708748102188 norm:0.00011939237447222695 max memory_allocated 38137.23486328125 
[2025-03-16 07:36:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 10 loss:0.01657918654382229 norm:0.00011775828897953033 max memory_allocated 38137.23486328125 
[2025-03-16 07:37:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 11 loss:0.016565760597586632 norm:0.00011508968600537628 max memory_allocated 38137.23486328125 
[2025-03-16 07:38:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 12 loss:0.01657775603234768 norm:0.00011554124648682773 max memory_allocated 38137.23486328125 
[2025-03-16 07:39:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 13 loss:0.016548441722989082 norm:0.00011402738164179027 max memory_allocated 38137.23486328125 
[2025-03-16 07:40:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 14 loss:0.016551395878195763 norm:0.0001137119106715545 max memory_allocated 38137.23486328125 
[2025-03-16 07:41:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 15 loss:0.016541387885808945 norm:0.00011343530786689371 max memory_allocated 38137.23486328125 
[2025-03-16 07:42:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 16 loss:0.016539163887500763 norm:0.00011175566760357469 max memory_allocated 38137.23486328125 
[2025-03-16 07:43:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 17 loss:0.016540920361876488 norm:0.00011156049731653184 max memory_allocated 38137.23486328125 
[2025-03-16 07:44:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 18 loss:0.016526460647583008 norm:0.0001107611897168681 max memory_allocated 38137.23486328125 
[2025-03-16 07:45:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 19 loss:0.01651730202138424 norm:0.00011095947411376983 max memory_allocated 38137.23486328125 
[2025-03-16 07:45:40 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 15 to 16 ===
[2025-03-16 07:46:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 0 loss:0.03296077996492386 norm:0.0008769346168264747 max memory_allocated 38137.23486328125 
[2025-03-16 07:47:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 1 loss:0.025976842269301414 norm:0.00041339395102113485 max memory_allocated 38137.23486328125 
[2025-03-16 07:48:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 2 loss:0.021585267037153244 norm:0.00025885552167892456 max memory_allocated 38137.23486328125 
[2025-03-16 07:49:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 3 loss:0.020220713689923286 norm:0.0002026193542405963 max memory_allocated 38137.23486328125 
[2025-03-16 07:50:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 4 loss:0.01948361098766327 norm:0.00017637634300626814 max memory_allocated 38137.23486328125 
[2025-03-16 07:51:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 5 loss:0.019022006541490555 norm:0.0001653623767197132 max memory_allocated 38137.23486328125 
[2025-03-16 07:52:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 6 loss:0.01877700351178646 norm:0.000149331332067959 max memory_allocated 38137.23486328125 
[2025-03-16 07:53:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 7 loss:0.018661528825759888 norm:0.0001427695679012686 max memory_allocated 38137.23486328125 
[2025-03-16 07:54:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 8 loss:0.018621399998664856 norm:0.00014331890270113945 max memory_allocated 38137.23486328125 
[2025-03-16 07:55:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 9 loss:0.018631860613822937 norm:0.0001462355867261067 max memory_allocated 38137.23486328125 
[2025-03-16 07:56:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 10 loss:0.018610205501317978 norm:0.00013550787116400898 max memory_allocated 38137.23486328125 
[2025-03-16 07:57:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 11 loss:0.01862608641386032 norm:0.00015481020091101527 max memory_allocated 38137.23486328125 
[2025-03-16 07:58:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 12 loss:0.018589794635772705 norm:0.0001331630046479404 max memory_allocated 38137.23486328125 
[2025-03-16 07:59:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 13 loss:0.018577538430690765 norm:0.0001390681863995269 max memory_allocated 38137.23486328125 
[2025-03-16 08:00:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 14 loss:0.018541838973760605 norm:0.00013031261914875358 max memory_allocated 38137.23486328125 
[2025-03-16 08:00:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 15 loss:0.01855110377073288 norm:0.00012858427362516522 max memory_allocated 38137.23486328125 
[2025-03-16 08:01:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 16 loss:0.018555406481027603 norm:0.00013725159806199372 max memory_allocated 38137.23486328125 
[2025-03-16 08:02:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 17 loss:0.018551236018538475 norm:0.00012964762572664768 max memory_allocated 38137.23486328125 
[2025-03-16 08:03:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 18 loss:0.018544888123869896 norm:0.00013538252096623182 max memory_allocated 38137.23486328125 
[2025-03-16 08:04:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 19 loss:0.018529551103711128 norm:0.00013649986067321151 max memory_allocated 38137.23486328125 
[2025-03-16 08:05:16 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 16 to 17 ===
[2025-03-16 08:06:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 0 loss:0.041460197418928146 norm:0.0014184750616550446 max memory_allocated 38137.23486328125 
[2025-03-16 08:07:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 1 loss:0.03253540024161339 norm:0.0006411464419215918 max memory_allocated 38137.23486328125 
[2025-03-16 08:08:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 2 loss:0.026819542050361633 norm:0.00038475741166621447 max memory_allocated 38137.23486328125 
[2025-03-16 08:09:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 3 loss:0.02488960698246956 norm:0.0002837359788827598 max memory_allocated 38137.23486328125 
[2025-03-16 08:10:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 4 loss:0.02387944981455803 norm:0.00022893596906214952 max memory_allocated 38137.23486328125 
[2025-03-16 08:11:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 5 loss:0.02336895652115345 norm:0.00019974884344264865 max memory_allocated 38137.23486328125 
[2025-03-16 08:12:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 6 loss:0.023168519139289856 norm:0.00018289238505531102 max memory_allocated 38137.23486328125 
[2025-03-16 08:12:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 7 loss:0.023069925606250763 norm:0.00017251219833269715 max memory_allocated 38137.23486328125 
[2025-03-16 08:13:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 8 loss:0.023013532161712646 norm:0.00017033754556905478 max memory_allocated 38137.23486328125 
[2025-03-16 08:14:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 9 loss:0.02295917272567749 norm:0.00016155319462995976 max memory_allocated 38137.23486328125 
[2025-03-16 08:15:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 10 loss:0.022924911230802536 norm:0.00015820175758562982 max memory_allocated 38137.23486328125 
[2025-03-16 08:16:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 11 loss:0.022883141413331032 norm:0.000158287730300799 max memory_allocated 38137.23486328125 
[2025-03-16 08:17:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 12 loss:0.022848064079880714 norm:0.000157429079990834 max memory_allocated 38137.23486328125 
[2025-03-16 08:18:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 13 loss:0.022816063836216927 norm:0.00015384526341222227 max memory_allocated 38137.23486328125 
[2025-03-16 08:19:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 14 loss:0.022809427231550217 norm:0.00015699959476478398 max memory_allocated 38137.23486328125 
[2025-03-16 08:20:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 15 loss:0.022804804146289825 norm:0.0001571328321006149 max memory_allocated 38137.23486328125 
[2025-03-16 08:21:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 16 loss:0.022773588076233864 norm:0.00015343302220571786 max memory_allocated 38137.23486328125 
[2025-03-16 08:22:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 17 loss:0.022745346650481224 norm:0.000151910848217085 max memory_allocated 38137.23486328125 
[2025-03-16 08:23:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 18 loss:0.022724729031324387 norm:0.00015004428860265762 max memory_allocated 38137.23486328125 
[2025-03-16 08:24:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 19 loss:0.022700630128383636 norm:0.0001495805918239057 max memory_allocated 38137.23486328125 
[2025-03-16 08:24:55 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 17 to 18 ===
[2025-03-16 08:25:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 0 loss:0.04555787891149521 norm:0.0009515497949905694 max memory_allocated 38137.23486328125 
[2025-03-16 08:26:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 1 loss:0.03634033724665642 norm:0.00048805837286636233 max memory_allocated 38137.23486328125 
[2025-03-16 08:27:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 2 loss:0.030248677358031273 norm:0.0003286237479187548 max memory_allocated 38137.23486328125 
[2025-03-16 08:28:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 3 loss:0.02821473963558674 norm:0.0002733680885285139 max memory_allocated 38137.23486328125 
[2025-03-16 08:29:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 4 loss:0.02712482213973999 norm:0.00024870882043614984 max memory_allocated 38137.23486328125 
[2025-03-16 08:30:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 5 loss:0.026669923216104507 norm:0.00022836882271803916 max memory_allocated 38137.23486328125 
[2025-03-16 08:31:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 6 loss:0.026479151099920273 norm:0.00022029610408935696 max memory_allocated 38137.23486328125 
[2025-03-16 08:32:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 7 loss:0.026367640122771263 norm:0.0002139251446351409 max memory_allocated 38137.23486328125 
[2025-03-16 08:33:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 8 loss:0.02627856843173504 norm:0.00020824454259127378 max memory_allocated 38137.23486328125 
[2025-03-16 08:34:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 9 loss:0.026240253821015358 norm:0.000205216056201607 max memory_allocated 38137.23486328125 
[2025-03-16 08:35:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 10 loss:0.026236752048134804 norm:0.00020374641462694854 max memory_allocated 38137.23486328125 
[2025-03-16 08:36:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 11 loss:0.026180483400821686 norm:0.00019779626745730639 max memory_allocated 38137.23486328125 
[2025-03-16 08:37:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 12 loss:0.026171334087848663 norm:0.00019219510431867093 max memory_allocated 38137.23486328125 
[2025-03-16 08:38:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 13 loss:0.026177478954195976 norm:0.00019401292956899852 max memory_allocated 38137.23486328125 
[2025-03-16 08:39:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 14 loss:0.026172563433647156 norm:0.00019067968241870403 max memory_allocated 38137.23486328125 
[2025-03-16 08:40:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 15 loss:0.026151541620492935 norm:0.00018758804071694613 max memory_allocated 38137.23486328125 
[2025-03-16 08:41:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 16 loss:0.026144590228796005 norm:0.0001869272964540869 max memory_allocated 38137.23486328125 
[2025-03-16 08:42:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 17 loss:0.0261328537017107 norm:0.00018232663569506258 max memory_allocated 38137.23486328125 
[2025-03-16 08:43:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 18 loss:0.026131387799978256 norm:0.00018258218187838793 max memory_allocated 38137.23486328125 
[2025-03-16 08:44:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 19 loss:0.026121990755200386 norm:0.00018907568301074207 max memory_allocated 38137.23486328125 
[2025-03-16 08:44:34 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 18 to 19 ===
[2025-03-16 08:45:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 0 loss:0.05085695534944534 norm:0.0011793235316872597 max memory_allocated 38137.23486328125 
[2025-03-16 08:46:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 1 loss:0.041076935827732086 norm:0.0006159273907542229 max memory_allocated 38137.23486328125 
[2025-03-16 08:47:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 2 loss:0.03432219848036766 norm:0.00040775351226329803 max memory_allocated 38137.23486328125 
[2025-03-16 08:48:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 3 loss:0.032058235257864 norm:0.0003297387738712132 max memory_allocated 38137.23486328125 
[2025-03-16 08:49:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 4 loss:0.030908124521374702 norm:0.00029742883634753525 max memory_allocated 38137.23486328125 
[2025-03-16 08:50:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 5 loss:0.03051060065627098 norm:0.0002840447414200753 max memory_allocated 38137.23486328125 
[2025-03-16 08:51:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 6 loss:0.030298180878162384 norm:0.0002702841302379966 max memory_allocated 38137.23486328125 
[2025-03-16 08:52:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 7 loss:0.030157478526234627 norm:0.0002594050602056086 max memory_allocated 38137.23486328125 
[2025-03-16 08:53:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 8 loss:0.030014099553227425 norm:0.0002519017143640667 max memory_allocated 38137.23486328125 
[2025-03-16 08:54:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 9 loss:0.029908176511526108 norm:0.00024834886426106095 max memory_allocated 38137.23486328125 
[2025-03-16 08:55:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 10 loss:0.029830968007445335 norm:0.0002367572160437703 max memory_allocated 38137.23486328125 
[2025-03-16 08:56:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 11 loss:0.029755547642707825 norm:0.00023129968030843884 max memory_allocated 38137.23486328125 
[2025-03-16 08:57:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 12 loss:0.029709527269005775 norm:0.0002221804461441934 max memory_allocated 38137.23486328125 
[2025-03-16 08:57:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 13 loss:0.02966346964240074 norm:0.00022056371381040663 max memory_allocated 38137.23486328125 
[2025-03-16 08:58:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 14 loss:0.02964811958372593 norm:0.00021613924764096737 max memory_allocated 38137.23486328125 
[2025-03-16 08:59:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 15 loss:0.029663650318980217 norm:0.00022321008145809174 max memory_allocated 38137.23486328125 
[2025-03-16 09:00:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 16 loss:0.029633501544594765 norm:0.00021033910161349922 max memory_allocated 38137.23486328125 
[2025-03-16 09:01:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 17 loss:0.029596945270895958 norm:0.00020659751316998154 max memory_allocated 38137.23486328125 
[2025-03-16 09:02:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 18 loss:0.02958202175796032 norm:0.00020316442532930523 max memory_allocated 38137.23486328125 
[2025-03-16 09:03:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 19 loss:0.029569314792752266 norm:0.00020327071251813322 max memory_allocated 38137.23486328125 
[2025-03-16 09:04:10 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 19 to 20 ===
[2025-03-16 09:05:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 0 loss:0.05743926391005516 norm:0.0012105538044124842 max memory_allocated 38137.29736328125 
[2025-03-16 09:06:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 1 loss:0.0465037003159523 norm:0.0006654038443230093 max memory_allocated 38137.29736328125 
[2025-03-16 09:07:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 2 loss:0.038750745356082916 norm:0.0004677416873164475 max memory_allocated 38137.29736328125 
[2025-03-16 09:08:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 3 loss:0.03629010170698166 norm:0.0004055381868965924 max memory_allocated 38137.29736328125 
[2025-03-16 09:09:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 4 loss:0.03521490842103958 norm:0.0003636068431660533 max memory_allocated 38137.29736328125 
[2025-03-16 09:10:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 5 loss:0.034830279648303986 norm:0.0003394469677004963 max memory_allocated 38137.29736328125 
[2025-03-16 09:10:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 6 loss:0.03465813025832176 norm:0.0003340110706631094 max memory_allocated 38137.29736328125 
[2025-03-16 09:11:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 7 loss:0.03437710553407669 norm:0.00030491387587971985 max memory_allocated 38137.29736328125 
[2025-03-16 09:12:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 8 loss:0.034239694476127625 norm:0.0003011393127962947 max memory_allocated 38137.29736328125 
[2025-03-16 09:13:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 9 loss:0.03416423872113228 norm:0.00027910256176255643 max memory_allocated 38137.29736328125 
[2025-03-16 09:14:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 10 loss:0.03408234938979149 norm:0.00026702668401412666 max memory_allocated 38137.29736328125 
[2025-03-16 09:15:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 11 loss:0.033922113478183746 norm:0.0002603896427899599 max memory_allocated 38137.29736328125 
[2025-03-16 09:16:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 12 loss:0.03389916941523552 norm:0.0002756420581135899 max memory_allocated 38137.29736328125 
[2025-03-16 09:17:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 13 loss:0.03379951789975166 norm:0.0002528579789213836 max memory_allocated 38137.29736328125 
[2025-03-16 09:18:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 14 loss:0.033778272569179535 norm:0.00025987057597376406 max memory_allocated 38137.29736328125 
[2025-03-16 09:19:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 15 loss:0.033751241862773895 norm:0.0002738293260335922 max memory_allocated 38137.29736328125 
[2025-03-16 09:20:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 16 loss:0.033685728907585144 norm:0.00026078481459990144 max memory_allocated 38137.29736328125 
[2025-03-16 09:21:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 17 loss:0.033661067485809326 norm:0.0002516228996682912 max memory_allocated 38137.29736328125 
[2025-03-16 09:22:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 18 loss:0.0336245633661747 norm:0.0002458582748658955 max memory_allocated 38137.29736328125 
[2025-03-16 09:23:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 19 loss:0.03365366533398628 norm:0.00026423094095662236 max memory_allocated 38137.29736328125 
[2025-03-16 09:23:49 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 20 to 21 ===
[2025-03-16 09:24:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 0 loss:0.06871223449707031 norm:0.001126886927522719 max memory_allocated 38137.46923828125 
[2025-03-16 09:25:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 1 loss:0.056047454476356506 norm:0.00070420210249722 max memory_allocated 38137.46923828125 
[2025-03-16 09:26:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 2 loss:0.04618462175130844 norm:0.0005872935871593654 max memory_allocated 38137.46923828125 
[2025-03-16 09:27:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 3 loss:0.04294939711689949 norm:0.0005131838843226433 max memory_allocated 38137.46923828125 
[2025-03-16 09:28:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 4 loss:0.0417308583855629 norm:0.0004949176218360662 max memory_allocated 38137.46923828125 
[2025-03-16 09:29:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 5 loss:0.04115734621882439 norm:0.00045391556341201067 max memory_allocated 38137.46923828125 
[2025-03-16 09:30:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 6 loss:0.04062313586473465 norm:0.00042523539741523564 max memory_allocated 38137.46923828125 
[2025-03-16 09:31:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 7 loss:0.04028768837451935 norm:0.00041031200089491904 max memory_allocated 38137.46923828125 
[2025-03-16 09:32:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 8 loss:0.04007799178361893 norm:0.00040676744538359344 max memory_allocated 38137.46923828125 
[2025-03-16 09:33:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 9 loss:0.03976696357131004 norm:0.00040365668246522546 max memory_allocated 38137.46923828125 
[2025-03-16 09:34:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 10 loss:0.03948770463466644 norm:0.00038116902578622103 max memory_allocated 38137.46923828125 
[2025-03-16 09:35:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 11 loss:0.039320409297943115 norm:0.00037471274845302105 max memory_allocated 38137.46923828125 
[2025-03-16 09:36:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 12 loss:0.03924262896180153 norm:0.0003939152811653912 max memory_allocated 38137.46923828125 
[2025-03-16 09:37:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 13 loss:0.03912115842103958 norm:0.00036082242149859667 max memory_allocated 38137.46923828125 
[2025-03-16 09:38:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 14 loss:0.03915443643927574 norm:0.0004114295297767967 max memory_allocated 38137.46923828125 
[2025-03-16 09:39:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 15 loss:0.03904357925057411 norm:0.000381198653485626 max memory_allocated 38137.46923828125 
[2025-03-16 09:40:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 16 loss:0.03891336917877197 norm:0.00040670024463906884 max memory_allocated 38137.46923828125 
[2025-03-16 09:41:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 17 loss:0.038775790482759476 norm:0.00039682764327153563 max memory_allocated 38137.46923828125 
[2025-03-16 09:41:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 18 loss:0.03873191773891449 norm:0.00039820928941480815 max memory_allocated 38137.46923828125 
[2025-03-16 09:42:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 19 loss:0.038611967116594315 norm:0.0003689139266498387 max memory_allocated 38137.46923828125 
[2025-03-16 09:43:25 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 21 to 22 ===
[2025-03-16 09:44:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 0 loss:0.07406032830476761 norm:0.0013818559236824512 max memory_allocated 38137.64111328125 
[2025-03-16 09:45:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 1 loss:0.05932259559631348 norm:0.000783429597504437 max memory_allocated 38137.64111328125 
[2025-03-16 09:46:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 2 loss:0.04865590110421181 norm:0.0005613430985249579 max memory_allocated 38137.64111328125 
[2025-03-16 09:47:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 3 loss:0.04547670856118202 norm:0.0004599963722284883 max memory_allocated 38137.64111328125 
[2025-03-16 09:48:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 4 loss:0.04429357871413231 norm:0.00040272052865475416 max memory_allocated 38137.64111328125 
[2025-03-16 09:49:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 5 loss:0.043803565204143524 norm:0.0003849197528325021 max memory_allocated 38137.64111328125 
[2025-03-16 09:50:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 6 loss:0.04339631274342537 norm:0.00036922559957019985 max memory_allocated 38137.64111328125 
[2025-03-16 09:51:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 7 loss:0.04306263476610184 norm:0.000349293346516788 max memory_allocated 38137.64111328125 
[2025-03-16 09:52:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 8 loss:0.04285798221826553 norm:0.00035299183218739927 max memory_allocated 38137.64111328125 
[2025-03-16 09:53:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 9 loss:0.04267045855522156 norm:0.0003330460167489946 max memory_allocated 38137.64111328125 
[2025-03-16 09:53:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 10 loss:0.04249958693981171 norm:0.0003294565831311047 max memory_allocated 38137.64111328125 
[2025-03-16 09:54:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 11 loss:0.042342230677604675 norm:0.0003282419638708234 max memory_allocated 38137.64111328125 
[2025-03-16 09:55:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 12 loss:0.04221460968255997 norm:0.00032113719498738647 max memory_allocated 38137.64111328125 
[2025-03-16 09:56:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 13 loss:0.04204615205526352 norm:0.00031405029585585 max memory_allocated 38137.64111328125 
[2025-03-16 09:57:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 14 loss:0.041929151862859726 norm:0.00030794538906775415 max memory_allocated 38137.64111328125 
[2025-03-16 09:58:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 15 loss:0.04181232675909996 norm:0.000354319519829005 max memory_allocated 38137.64111328125 
[2025-03-16 09:59:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 16 loss:0.0416504368185997 norm:0.00032222887966781855 max memory_allocated 38137.64111328125 
[2025-03-16 10:00:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 17 loss:0.04156491532921791 norm:0.000316467834636569 max memory_allocated 38137.64111328125 
[2025-03-16 10:01:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 18 loss:0.04150557890534401 norm:0.0003195597673766315 max memory_allocated 38137.64111328125 
[2025-03-16 10:02:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 19 loss:0.04145961254835129 norm:0.0003185648820362985 max memory_allocated 38137.64111328125 
[2025-03-16 10:03:01 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 22 to 23 ===
[2025-03-16 10:04:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 0 loss:0.08400822430849075 norm:0.0017898960504680872 max memory_allocated 38137.81298828125 
[2025-03-16 10:05:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 1 loss:0.06771032512187958 norm:0.0009557409794069827 max memory_allocated 38137.81298828125 
[2025-03-16 10:05:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 2 loss:0.05518803000450134 norm:0.0006541090551763773 max memory_allocated 38137.81298828125 
[2025-03-16 10:06:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 3 loss:0.051392197608947754 norm:0.0005356953479349613 max memory_allocated 38137.81298828125 
[2025-03-16 10:07:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 4 loss:0.050122279673814774 norm:0.00045759999193251133 max memory_allocated 38137.81298828125 
[2025-03-16 10:08:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 5 loss:0.04945598170161247 norm:0.0004244370211381465 max memory_allocated 38137.81298828125 
[2025-03-16 10:09:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 6 loss:0.049011170864105225 norm:0.0004095780896022916 max memory_allocated 38137.81298828125 
[2025-03-16 10:10:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 7 loss:0.04865783080458641 norm:0.0003956120344810188 max memory_allocated 38137.81298828125 
[2025-03-16 10:11:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 8 loss:0.048377182334661484 norm:0.0003763005370274186 max memory_allocated 38137.81298828125 
[2025-03-16 10:12:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 9 loss:0.04806201159954071 norm:0.00037516478914767504 max memory_allocated 38137.81298828125 
[2025-03-16 10:13:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 10 loss:0.047730568796396255 norm:0.00036094122333452106 max memory_allocated 38137.81298828125 
[2025-03-16 10:14:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 11 loss:0.04759224131703377 norm:0.0003498732694424689 max memory_allocated 38137.81298828125 
[2025-03-16 10:15:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 12 loss:0.04741213843226433 norm:0.00034288197639398277 max memory_allocated 38137.81298828125 
[2025-03-16 10:16:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 13 loss:0.04723825678229332 norm:0.00033876378438435495 max memory_allocated 38137.81298828125 
[2025-03-16 10:17:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 14 loss:0.04706506431102753 norm:0.0003344028373248875 max memory_allocated 38137.81298828125 
[2025-03-16 10:18:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 15 loss:0.04696100577712059 norm:0.0003313097986392677 max memory_allocated 38137.81298828125 
[2025-03-16 10:19:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 16 loss:0.04687771573662758 norm:0.0003305760328657925 max memory_allocated 38137.81298828125 
[2025-03-16 10:20:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 17 loss:0.0467984564602375 norm:0.00032927386928349733 max memory_allocated 38137.81298828125 
[2025-03-16 10:21:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 18 loss:0.04670019820332527 norm:0.00032842805376276374 max memory_allocated 38137.81298828125 
[2025-03-16 10:22:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 19 loss:0.046583689749240875 norm:0.00032343939528800547 max memory_allocated 38137.81298828125 
[2025-03-16 10:22:38 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 23 to 24 ===
[2025-03-16 10:23:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 0 loss:0.08985608071088791 norm:0.0014858638169243932 max memory_allocated 38137.98486328125 
[2025-03-16 10:24:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 1 loss:0.07277326285839081 norm:0.0009168369579128921 max memory_allocated 38137.98486328125 
[2025-03-16 10:25:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 2 loss:0.05849866941571236 norm:0.0006216777837835252 max memory_allocated 38137.98486328125 
[2025-03-16 10:26:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 3 loss:0.05446277931332588 norm:0.0005069640465080738 max memory_allocated 38137.98486328125 
[2025-03-16 10:27:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 4 loss:0.05334565415978432 norm:0.00046947947703301907 max memory_allocated 38137.98486328125 
[2025-03-16 10:28:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 5 loss:0.05276830121874809 norm:0.00042817165376618505 max memory_allocated 38137.98486328125 
[2025-03-16 10:29:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 6 loss:0.052320417016744614 norm:0.0004103950341232121 max memory_allocated 38137.98486328125 
[2025-03-16 10:30:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 7 loss:0.0520373098552227 norm:0.0004018648178316653 max memory_allocated 38137.98486328125 
[2025-03-16 10:31:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 8 loss:0.05172121897339821 norm:0.0003825065796263516 max memory_allocated 38137.98486328125 
[2025-03-16 10:32:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 9 loss:0.051515236496925354 norm:0.00038583940477110445 max memory_allocated 38137.98486328125 
[2025-03-16 10:33:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 10 loss:0.051260583102703094 norm:0.00036914850352331996 max memory_allocated 38137.98486328125 
[2025-03-16 10:34:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 11 loss:0.05113722383975983 norm:0.0003685799310915172 max memory_allocated 38137.98486328125 
[2025-03-16 10:35:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 12 loss:0.051029741764068604 norm:0.0003637936897575855 max memory_allocated 38137.98486328125 
[2025-03-16 10:36:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 13 loss:0.05083369091153145 norm:0.00035642110742628574 max memory_allocated 38137.98486328125 
[2025-03-16 10:36:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 14 loss:0.05070606246590614 norm:0.00035138559178449214 max memory_allocated 38137.98486328125 
[2025-03-16 10:37:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 15 loss:0.05060014873743057 norm:0.00034827456693165004 max memory_allocated 38137.98486328125 
[2025-03-16 10:38:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 16 loss:0.050519898533821106 norm:0.00034563717781566083 max memory_allocated 38137.98486328125 
[2025-03-16 10:39:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 17 loss:0.05045027658343315 norm:0.0003440040163695812 max memory_allocated 38137.98486328125 
[2025-03-16 10:40:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 18 loss:0.05039422586560249 norm:0.00034623671672306955 max memory_allocated 38137.98486328125 
[2025-03-16 10:41:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 19 loss:0.050327546894550323 norm:0.00034213397884741426 max memory_allocated 38137.98486328125 
[2025-03-16 10:42:14 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 24 to 25 ===
[2025-03-16 10:43:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 0 loss:0.09844920039176941 norm:0.0017719052266329527 max memory_allocated 38138.15673828125 
[2025-03-16 10:44:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 1 loss:0.07881522178649902 norm:0.000979600939899683 max memory_allocated 38138.15673828125 
[2025-03-16 10:45:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 2 loss:0.06304217129945755 norm:0.0006570045952685177 max memory_allocated 38138.15673828125 
[2025-03-16 10:46:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 3 loss:0.05875474214553833 norm:0.0005439810920506716 max memory_allocated 38138.15673828125 
[2025-03-16 10:47:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 4 loss:0.05764470994472504 norm:0.00047012101276777685 max memory_allocated 38138.15673828125 
[2025-03-16 10:48:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 5 loss:0.05698694288730621 norm:0.00043396264663897455 max memory_allocated 38138.15673828125 
[2025-03-16 10:49:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 6 loss:0.056613218039274216 norm:0.00041546396096237004 max memory_allocated 38138.15673828125 
[2025-03-16 10:49:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 7 loss:0.05629381164908409 norm:0.00038564298301935196 max memory_allocated 38138.15673828125 
[2025-03-16 10:50:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 8 loss:0.0560883991420269 norm:0.0003691942256409675 max memory_allocated 38138.15673828125 
[2025-03-16 10:51:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 9 loss:0.05588328093290329 norm:0.0003707942378241569 max memory_allocated 38138.15673828125 
[2025-03-16 10:52:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 10 loss:0.05566776171326637 norm:0.00037079909816384315 max memory_allocated 38138.15673828125 
[2025-03-16 10:53:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 11 loss:0.055510640144348145 norm:0.0003598134499043226 max memory_allocated 38138.15673828125 
[2025-03-16 10:54:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 12 loss:0.05532396212220192 norm:0.0003560254699550569 max memory_allocated 38138.15673828125 
[2025-03-16 10:55:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 13 loss:0.055280525237321854 norm:0.00036529789213091135 max memory_allocated 38138.15673828125 
[2025-03-16 10:56:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 14 loss:0.055142927914857864 norm:0.0003509828238748014 max memory_allocated 38138.15673828125 
[2025-03-16 10:57:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 15 loss:0.05504987761378288 norm:0.00035049280268140137 max memory_allocated 38138.15673828125 
[2025-03-16 10:58:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 16 loss:0.054953210055828094 norm:0.0003473706019576639 max memory_allocated 38138.15673828125 
[2025-03-16 10:59:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 17 loss:0.05490068718791008 norm:0.00035552511690184474 max memory_allocated 38138.15673828125 
[2025-03-16 11:00:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 18 loss:0.054813630878925323 norm:0.000357695622369647 max memory_allocated 38138.15673828125 
[2025-03-16 11:01:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 19 loss:0.054724328219890594 norm:0.0003544178034644574 max memory_allocated 38138.15673828125 
[2025-03-16 11:01:53 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 25 to 26 ===
[2025-03-16 11:02:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 0 loss:0.1110706478357315 norm:0.006476219743490219 max memory_allocated 38138.32861328125 
[2025-03-16 11:03:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 1 loss:0.0875944197177887 norm:0.00330378208309412 max memory_allocated 38138.32861328125 
[2025-03-16 11:04:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 2 loss:0.07035449147224426 norm:0.002002623863518238 max memory_allocated 38138.32861328125 
[2025-03-16 11:05:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 3 loss:0.06567452102899551 norm:0.001391968922689557 max memory_allocated 38138.32861328125 
[2025-03-16 11:06:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 4 loss:0.0644046813249588 norm:0.001076787244528532 max memory_allocated 38138.32861328125 
[2025-03-16 11:07:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 5 loss:0.06378526985645294 norm:0.000884250330273062 max memory_allocated 38138.32861328125 
[2025-03-16 11:08:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 6 loss:0.06313621997833252 norm:0.000750296632759273 max memory_allocated 38138.32861328125 
[2025-03-16 11:09:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 7 loss:0.06269464641809464 norm:0.0006635055760852993 max memory_allocated 38138.32861328125 
[2025-03-16 11:10:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 8 loss:0.0623335987329483 norm:0.000598229409661144 max memory_allocated 38138.32861328125 
[2025-03-16 11:11:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 9 loss:0.062103673815727234 norm:0.0005537848919630051 max memory_allocated 38138.32861328125 
[2025-03-16 11:12:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 10 loss:0.06187962740659714 norm:0.0005279418546706438 max memory_allocated 38138.32861328125 
[2025-03-16 11:13:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 11 loss:0.061682187020778656 norm:0.0004938466590829194 max memory_allocated 38138.32861328125 
[2025-03-16 11:14:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 12 loss:0.06153061240911484 norm:0.0004775678098667413 max memory_allocated 38138.32861328125 
[2025-03-16 11:15:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 13 loss:0.06140844523906708 norm:0.0004664245352614671 max memory_allocated 38138.32861328125 
[2025-03-16 11:16:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 14 loss:0.0613267719745636 norm:0.0004601330147124827 max memory_allocated 38138.32861328125 
[2025-03-16 11:17:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 15 loss:0.06127142906188965 norm:0.0004528601130004972 max memory_allocated 38138.32861328125 
[2025-03-16 11:18:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 16 loss:0.061228346079587936 norm:0.00044323649490252137 max memory_allocated 38138.32861328125 
[2025-03-16 11:19:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 17 loss:0.06115565821528435 norm:0.00044039631029590964 max memory_allocated 38138.32861328125 
[2025-03-16 11:20:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 18 loss:0.06111602112650871 norm:0.00043835866381414235 max memory_allocated 38138.32861328125 
[2025-03-16 11:20:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 19 loss:0.06103523448109627 norm:0.00042916886741295457 max memory_allocated 38138.32861328125 
[2025-03-16 11:21:29 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 26 to 27 ===
[2025-03-16 11:22:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 0 loss:0.11770428717136383 norm:0.0034616226330399513 max memory_allocated 38138.50048828125 
[2025-03-16 11:23:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 1 loss:0.09334447234869003 norm:0.0018446359317749739 max memory_allocated 38138.50048828125 
[2025-03-16 11:24:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 2 loss:0.07517975568771362 norm:0.001198059064336121 max memory_allocated 38138.50048828125 
[2025-03-16 11:25:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 3 loss:0.07076030224561691 norm:0.0009037721320055425 max memory_allocated 38138.50048828125 
[2025-03-16 11:26:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 4 loss:0.06956148147583008 norm:0.0007590046152472496 max memory_allocated 38138.50048828125 
[2025-03-16 11:27:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 5 loss:0.06894233822822571 norm:0.0006632599979639053 max memory_allocated 38138.50048828125 
[2025-03-16 11:28:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 6 loss:0.06850731372833252 norm:0.000597977836150676 max memory_allocated 38138.50048828125 
[2025-03-16 11:29:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 7 loss:0.06811349838972092 norm:0.000558122294023633 max memory_allocated 38138.50048828125 
[2025-03-16 11:30:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 8 loss:0.06789194792509079 norm:0.0005276634474284947 max memory_allocated 38138.50048828125 
[2025-03-16 11:31:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 9 loss:0.06760375201702118 norm:0.0005066549056209624 max memory_allocated 38138.50048828125 
[2025-03-16 11:32:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 10 loss:0.06736797094345093 norm:0.0004901402280665934 max memory_allocated 38138.50048828125 
[2025-03-16 11:32:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 11 loss:0.06720691919326782 norm:0.0004773974069394171 max memory_allocated 38138.50048828125 
[2025-03-16 11:33:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 12 loss:0.06712841242551804 norm:0.0004828660748898983 max memory_allocated 38138.50048828125 
[2025-03-16 11:34:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 13 loss:0.06703214347362518 norm:0.0004716120020020753 max memory_allocated 38138.50048828125 
[2025-03-16 11:35:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 14 loss:0.06700056791305542 norm:0.0004666982567869127 max memory_allocated 38138.50048828125 
[2025-03-16 11:36:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 15 loss:0.06693135201931 norm:0.0004590373137034476 max memory_allocated 38138.50048828125 
[2025-03-16 11:37:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 16 loss:0.06689538061618805 norm:0.00045750223216600716 max memory_allocated 38138.50048828125 
[2025-03-16 11:38:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 17 loss:0.06691394001245499 norm:0.0004559711378533393 max memory_allocated 38138.50048828125 
[2025-03-16 11:39:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 18 loss:0.06687632948160172 norm:0.0004558345826808363 max memory_allocated 38138.50048828125 
[2025-03-16 11:40:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 19 loss:0.06686795502901077 norm:0.00045396911446005106 max memory_allocated 38138.50048828125 
[2025-03-16 11:41:05 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 27 to 28 ===
[2025-03-16 11:42:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 0 loss:0.1348477303981781 norm:0.019189661368727684 max memory_allocated 38138.84521484375 
[2025-03-16 11:43:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 1 loss:0.10635847598314285 norm:0.013231840915977955 max memory_allocated 38138.84521484375 
[2025-03-16 11:44:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 2 loss:0.08510786294937134 norm:0.008701133541762829 max memory_allocated 38138.84521484375 
[2025-03-16 11:44:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 3 loss:0.07971662282943726 norm:0.007421399466693401 max memory_allocated 38138.84521484375 
[2025-03-16 11:45:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 4 loss:0.07835492491722107 norm:0.006337879691272974 max memory_allocated 38138.84521484375 
[2025-03-16 11:46:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 5 loss:0.0774407908320427 norm:0.005483991466462612 max memory_allocated 38138.84521484375 
[2025-03-16 11:47:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 6 loss:0.07679573446512222 norm:0.0046506598591804504 max memory_allocated 38138.84521484375 
[2025-03-16 11:48:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 7 loss:0.07625866681337357 norm:0.00394001230597496 max memory_allocated 38138.84521484375 
[2025-03-16 11:49:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 8 loss:0.07588589936494827 norm:0.003700453322380781 max memory_allocated 38138.84521484375 
[2025-03-16 11:50:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 9 loss:0.07578891515731812 norm:0.003924238961189985 max memory_allocated 38138.84521484375 
[2025-03-16 11:51:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 10 loss:0.07555404305458069 norm:0.00361882196739316 max memory_allocated 38138.84521484375 
[2025-03-16 11:52:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 11 loss:0.07535569369792938 norm:0.003234524978324771 max memory_allocated 38138.84521484375 
[2025-03-16 11:53:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 12 loss:0.07536899298429489 norm:0.003060118993744254 max memory_allocated 38138.84521484375 
[2025-03-16 11:54:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 13 loss:0.07527928799390793 norm:0.0029944730922579765 max memory_allocated 38138.84521484375 
[2025-03-16 11:55:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 14 loss:0.07520215958356857 norm:0.0029136480297893286 max memory_allocated 38138.84521484375 
[2025-03-16 11:56:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 15 loss:0.07511622458696365 norm:0.00280863419175148 max memory_allocated 38138.84521484375 
[2025-03-16 11:57:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 16 loss:0.075001060962677 norm:0.0028187537100166082 max memory_allocated 38138.84521484375 
[2025-03-16 11:58:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 17 loss:0.07502483576536179 norm:0.0028041498735547066 max memory_allocated 38138.84521484375 
[2025-03-16 11:59:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 18 loss:0.07502465695142746 norm:0.002809041878208518 max memory_allocated 38138.84521484375 
[2025-03-16 12:00:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 19 loss:0.07495123147964478 norm:0.0027000075206160545 max memory_allocated 38138.84521484375 
[2025-03-16 12:00:44 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 28 to 29 ===
[2025-03-16 12:01:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 0 loss:0.15500709414482117 norm:0.019696354866027832 max memory_allocated 38139.18994140625 
[2025-03-16 12:02:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 1 loss:0.12106851488351822 norm:0.013717838563024998 max memory_allocated 38139.18994140625 
[2025-03-16 12:03:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 2 loss:0.09796367585659027 norm:0.008687188848853111 max memory_allocated 38139.18994140625 
[2025-03-16 12:04:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 3 loss:0.09234535694122314 norm:0.005864094477146864 max memory_allocated 38139.18994140625 
[2025-03-16 12:05:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 4 loss:0.09083046019077301 norm:0.004795177839696407 max memory_allocated 38139.18994140625 
[2025-03-16 12:06:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 5 loss:0.08996560424566269 norm:0.004306723829358816 max memory_allocated 38139.18994140625 
[2025-03-16 12:07:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 6 loss:0.08916409313678741 norm:0.0038649239577353 max memory_allocated 38139.18994140625 
[2025-03-16 12:08:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 7 loss:0.08862444758415222 norm:0.0034785615280270576 max memory_allocated 38139.18994140625 
[2025-03-16 12:09:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 8 loss:0.08824050426483154 norm:0.0031185210682451725 max memory_allocated 38139.18994140625 
[2025-03-16 12:10:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 9 loss:0.08796314895153046 norm:0.002784550888463855 max memory_allocated 38139.18994140625 
[2025-03-16 12:11:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 10 loss:0.08781227469444275 norm:0.0027756874915212393 max memory_allocated 38139.18994140625 
[2025-03-16 12:12:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 11 loss:0.08780127763748169 norm:0.00276042683981359 max memory_allocated 38139.18994140625 
[2025-03-16 12:13:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 12 loss:0.08758626878261566 norm:0.002714368049055338 max memory_allocated 38139.18994140625 
[2025-03-16 12:14:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 13 loss:0.08739211410284042 norm:0.0025316153187304735 max memory_allocated 38139.18994140625 
[2025-03-16 12:15:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 14 loss:0.08728185296058655 norm:0.002451042179018259 max memory_allocated 38139.18994140625 
[2025-03-16 12:16:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 15 loss:0.08721274882555008 norm:0.0023247902281582355 max memory_allocated 38139.18994140625 
[2025-03-16 12:17:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 16 loss:0.08713201433420181 norm:0.0023163356818258762 max memory_allocated 38139.18994140625 
[2025-03-16 12:17:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 17 loss:0.08716747909784317 norm:0.002380757825449109 max memory_allocated 38139.18994140625 
[2025-03-16 12:18:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 18 loss:0.08707243949174881 norm:0.0023836276959627867 max memory_allocated 38139.18994140625 
[2025-03-16 12:19:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 19 loss:0.08695442229509354 norm:0.002288136165589094 max memory_allocated 38139.18994140625 
[2025-03-16 12:20:24 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 29 to 30 ===
[2025-03-16 12:21:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 0 loss:0.24304600059986115 norm:0.02729879319667816 max memory_allocated 38139.36181640625 
[2025-03-16 12:22:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 1 loss:0.1841132938861847 norm:0.014539158903062344 max memory_allocated 38139.36181640625 
[2025-03-16 12:23:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 2 loss:0.14623314142227173 norm:0.017412465065717697 max memory_allocated 38139.36181640625 
[2025-03-16 12:24:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 3 loss:0.13798746466636658 norm:0.01747569441795349 max memory_allocated 38139.36181640625 
[2025-03-16 12:25:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 4 loss:0.135341614484787 norm:0.017772896215319633 max memory_allocated 38139.36181640625 
[2025-03-16 12:26:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 5 loss:0.1334046870470047 norm:0.017553923651576042 max memory_allocated 38139.36181640625 
[2025-03-16 12:27:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 6 loss:0.1322755217552185 norm:0.018284626305103302 max memory_allocated 38139.36181640625 
[2025-03-16 12:28:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 7 loss:0.13104239106178284 norm:0.01880021020770073 max memory_allocated 38139.36181640625 
[2025-03-16 12:29:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 8 loss:0.1293049156665802 norm:0.01864832267165184 max memory_allocated 38139.36181640625 
[2025-03-16 12:30:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 9 loss:0.12830252945423126 norm:0.018974311649799347 max memory_allocated 38139.36181640625 
[2025-03-16 12:30:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 10 loss:0.1262352168560028 norm:0.01924290880560875 max memory_allocated 38139.36181640625 
[2025-03-16 12:31:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 11 loss:0.12416337430477142 norm:0.018091343343257904 max memory_allocated 38139.36181640625 
[2025-03-16 12:32:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 12 loss:0.12338060885667801 norm:0.01794944517314434 max memory_allocated 38139.36181640625 
[2025-03-16 12:33:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 13 loss:0.12253366410732269 norm:0.01861095242202282 max memory_allocated 38139.36181640625 
[2025-03-16 12:34:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 14 loss:0.1221112310886383 norm:0.018389292061328888 max memory_allocated 38139.36181640625 
[2025-03-16 12:35:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 15 loss:0.12209111452102661 norm:0.01733565889298916 max memory_allocated 38139.36181640625 
[2025-03-16 12:36:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 16 loss:0.12195616215467453 norm:0.01823902688920498 max memory_allocated 38139.36181640625 
[2025-03-16 12:37:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 17 loss:0.12050724774599075 norm:0.017455607652664185 max memory_allocated 38139.36181640625 
[2025-03-16 12:38:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 18 loss:0.1202186569571495 norm:0.017011672258377075 max memory_allocated 38139.36181640625 
[2025-03-16 12:39:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 19 loss:0.11965491622686386 norm:0.016787724569439888 max memory_allocated 38139.36181640625 
[2025-03-16 12:40:04 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 30 to 31 ===
[2025-03-16 12:41:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 0 loss:0.7167435884475708 norm:0.35649412870407104 max memory_allocated 38139.53369140625 
[2025-03-16 12:42:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 1 loss:0.5186478495597839 norm:0.24067245423793793 max memory_allocated 38139.53369140625 
[2025-03-16 12:43:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 2 loss:0.42665258049964905 norm:0.2026837170124054 max memory_allocated 38139.53369140625 
[2025-03-16 12:43:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 3 loss:0.3653048574924469 norm:0.12822836637496948 max memory_allocated 38139.53369140625 
[2025-03-16 12:44:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 4 loss:0.3368769884109497 norm:0.11517752707004547 max memory_allocated 38139.53369140625 
[2025-03-16 12:45:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 5 loss:0.31865498423576355 norm:0.09845124185085297 max memory_allocated 38139.53369140625 
[2025-03-16 12:46:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 6 loss:0.3071519136428833 norm:0.08797770738601685 max memory_allocated 38139.53369140625 
[2025-03-16 12:47:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 7 loss:0.2976662218570709 norm:0.082333043217659 max memory_allocated 38139.53369140625 
[2025-03-16 12:48:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 8 loss:0.2928614616394043 norm:0.07869047671556473 max memory_allocated 38139.53369140625 
[2025-03-16 12:49:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 9 loss:0.2862623929977417 norm:0.07323961704969406 max memory_allocated 38139.53369140625 
[2025-03-16 12:50:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 10 loss:0.28326210379600525 norm:0.0713576152920723 max memory_allocated 38139.53369140625 
[2025-03-16 12:51:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 11 loss:0.2788490653038025 norm:0.06849084794521332 max memory_allocated 38139.53369140625 
[2025-03-16 12:52:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 12 loss:0.2785699665546417 norm:0.06755682080984116 max memory_allocated 38139.53369140625 
[2025-03-16 12:53:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 13 loss:0.27448421716690063 norm:0.06285695731639862 max memory_allocated 38139.53369140625 
[2025-03-16 12:54:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 14 loss:0.27250853180885315 norm:0.06189978867769241 max memory_allocated 38139.53369140625 
[2025-03-16 12:55:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 15 loss:0.270717978477478 norm:0.060703542083501816 max memory_allocated 38139.53369140625 
[2025-03-16 12:56:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 16 loss:0.2695217728614807 norm:0.060200564563274384 max memory_allocated 38139.53369140625 
[2025-03-16 12:57:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 17 loss:0.26685112714767456 norm:0.0582880862057209 max memory_allocated 38139.53369140625 
[2025-03-16 12:58:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 18 loss:0.265981525182724 norm:0.05700116604566574 max memory_allocated 38139.53369140625 
[2025-03-16 12:59:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 19 loss:0.26933854818344116 norm:0.06332096457481384 max memory_allocated 38139.53369140625 
[2025-03-16 12:59:44 root] (main_calib_config3_cbq.py 376): INFO 36503.34825468063
[2025-03-16 12:59:49 root] (main_calib_config3_cbq.py 117): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-16 13:00:49 root] (main_calib_config3_cbq.py 161): INFO wikitext2 : 1799.468017578125
[2025-03-16 13:00:49 root] (main_calib_config3_cbq.py 117): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-16 13:02:22 root] (main_calib_config3_cbq.py 161): INFO c4 : 1576.9124755859375
[2025-03-16 14:16:29 root] (main_calib_config3_cbq.py 172): INFO {'wikitext2': 1799.468017578125, 'c4': 1576.9124755859375, 'results': {'winogrande': {'acc': 0.5951065509076559, 'acc_stderr': 0.013795927003124929}, 'arc_challenge': {'acc': 0.23720136518771331, 'acc_stderr': 0.012430399829260821, 'acc_norm': 0.26535836177474403, 'acc_norm_stderr': 0.012902554762313964}, 'arc_easy': {'acc': 0.4158249158249158, 'acc_stderr': 0.010113348244647878, 'acc_norm': 0.3787878787878788, 'acc_norm_stderr': 0.009953737656542037}, 'hellaswag': {'acc': 0.4757020513841864, 'acc_stderr': 0.004983886091690525, 'acc_norm': 0.6211909978092014, 'acc_norm_stderr': 0.004840990593494676}, 'piqa': {'acc': 0.6267682263329706, 'acc_stderr': 0.011284653078254898, 'acc_norm': 0.6082698585418934, 'acc_norm_stderr': 0.011389038597720011}, 'boolq': {'acc': 0.3948012232415902, 'acc_stderr': 0.008549304887647413}}, 'versions': {'winogrande': 0, 'arc_challenge': 0, 'arc_easy': 0, 'hellaswag': 0, 'piqa': 0, 'boolq': 1}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
[2025-03-16 14:16:29 root] (main_calib_config3_cbq.py 175): INFO 23.72,41.58,39.48,47.57,62.68,59.51
