[2025-03-16 03:04:56 root] (main_calib_config3_cbq.py 280): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-divide-adaptive-calibration-cbq/Llama-2-7b-hf-0.4', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.4.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-16 03:05:02 root] (main_calib_config3_cbq.py 347): INFO === start quantization ===
[2025-03-16 03:05:02 root] (main_calib_config3_cbq.py 353): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-16 03:05:03 root] (abq_llm_calib_config3_cbq.py 82): INFO Starting ...
[2025-03-16 03:05:03 root] (abq_llm_calib_config3_cbq.py 89): INFO Loaded quant_map from log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.4.pkl
[2025-03-16 03:05:06 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 0 to 1 ===
[2025-03-16 03:06:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 0 loss:0.24648292362689972 norm:0.5575532913208008 max memory_allocated 38105.85986328125 
[2025-03-16 03:07:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 1 loss:0.13415084779262543 norm:0.17575779557228088 max memory_allocated 38105.85986328125 
[2025-03-16 03:08:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 2 loss:0.10874669253826141 norm:0.13989952206611633 max memory_allocated 38105.85986328125 
[2025-03-16 03:08:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 3 loss:0.4490087628364563 norm:1.0142968893051147 max memory_allocated 38105.85986328125 
[2025-03-16 03:09:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 4 loss:0.13636520504951477 norm:0.25398096442222595 max memory_allocated 38105.85986328125 
[2025-03-16 03:10:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 5 loss:0.10776856541633606 norm:0.10958552360534668 max memory_allocated 38105.85986328125 
[2025-03-16 03:11:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 6 loss:0.0890517309308052 norm:0.06811532378196716 max memory_allocated 38105.85986328125 
[2025-03-16 03:12:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 7 loss:0.08404826372861862 norm:0.05414779484272003 max memory_allocated 38105.85986328125 
[2025-03-16 03:13:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 8 loss:0.08641868829727173 norm:0.0736243724822998 max memory_allocated 38105.85986328125 
[2025-03-16 03:14:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 9 loss:0.0837697833776474 norm:0.06404649466276169 max memory_allocated 38105.85986328125 
[2025-03-16 03:15:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 10 loss:0.08594236522912979 norm:0.08083523064851761 max memory_allocated 38105.85986328125 
[2025-03-16 03:16:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 11 loss:0.0805073231458664 norm:0.05482640489935875 max memory_allocated 38105.85986328125 
[2025-03-16 03:17:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 12 loss:0.08249976485967636 norm:0.07350059598684311 max memory_allocated 38105.85986328125 
[2025-03-16 03:18:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 13 loss:0.08252508193254471 norm:0.07090912759304047 max memory_allocated 38105.85986328125 
[2025-03-16 03:19:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 14 loss:0.07996205985546112 norm:0.06285467743873596 max memory_allocated 38105.85986328125 
[2025-03-16 03:20:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 15 loss:0.08031783252954483 norm:0.06402508914470673 max memory_allocated 38105.85986328125 
[2025-03-16 03:21:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 16 loss:0.0778120905160904 norm:0.060911502689123154 max memory_allocated 38105.85986328125 
[2025-03-16 03:22:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 17 loss:0.07724399119615555 norm:0.05789438635110855 max memory_allocated 38105.85986328125 
[2025-03-16 03:23:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 18 loss:0.07822319120168686 norm:0.06514033675193787 max memory_allocated 38105.85986328125 
[2025-03-16 03:24:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 19 loss:0.07746949791908264 norm:0.05331313610076904 max memory_allocated 38105.85986328125 
[2025-03-16 03:24:39 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 1 to 2 ===
[2025-03-16 03:25:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 0 loss:0.6357730031013489 norm:0.37635356187820435 max memory_allocated 38138.54931640625 
[2025-03-16 03:26:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 1 loss:0.287359356880188 norm:0.16998925805091858 max memory_allocated 38138.54931640625 
[2025-03-16 03:27:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 2 loss:0.20594581961631775 norm:0.1192738264799118 max memory_allocated 38138.54931640625 
[2025-03-16 03:28:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 3 loss:0.19886982440948486 norm:0.11272285878658295 max memory_allocated 38138.54931640625 
[2025-03-16 03:29:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 4 loss:0.15599024295806885 norm:0.0767931342124939 max memory_allocated 38138.54931640625 
[2025-03-16 03:30:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 5 loss:0.13872575759887695 norm:0.06534155458211899 max memory_allocated 38138.54931640625 
[2025-03-16 03:31:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 6 loss:0.12844721972942352 norm:0.05810047313570976 max memory_allocated 38138.54931640625 
[2025-03-16 03:32:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 7 loss:0.11715513467788696 norm:0.04409358277916908 max memory_allocated 38138.54931640625 
[2025-03-16 03:33:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 8 loss:0.10794704407453537 norm:0.0411989763379097 max memory_allocated 38138.54931640625 
[2025-03-16 03:34:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 9 loss:0.10153993964195251 norm:0.03349777311086655 max memory_allocated 38138.54931640625 
[2025-03-16 03:35:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 10 loss:0.09763658046722412 norm:0.03378412872552872 max memory_allocated 38138.54931640625 
[2025-03-16 03:36:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 11 loss:0.09285502135753632 norm:0.03197196498513222 max memory_allocated 38138.54931640625 
[2025-03-16 03:37:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 12 loss:0.08896082639694214 norm:0.029916968196630478 max memory_allocated 38138.54931640625 
[2025-03-16 03:38:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 13 loss:0.08477642387151718 norm:0.028035718947649002 max memory_allocated 38138.54931640625 
[2025-03-16 03:38:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 14 loss:0.08276373893022537 norm:0.026141492649912834 max memory_allocated 38138.54931640625 
[2025-03-16 03:39:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 15 loss:0.0815170630812645 norm:0.025345273315906525 max memory_allocated 38138.54931640625 
[2025-03-16 03:40:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 16 loss:0.0816441997885704 norm:0.026730621233582497 max memory_allocated 38138.54931640625 
[2025-03-16 03:41:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 17 loss:0.0801599770784378 norm:0.030163351446390152 max memory_allocated 38138.54931640625 
[2025-03-16 03:42:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 18 loss:0.07604766637086868 norm:0.023277491331100464 max memory_allocated 38138.54931640625 
[2025-03-16 03:43:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 19 loss:0.07481693476438522 norm:0.024446215480566025 max memory_allocated 38138.54931640625 
[2025-03-16 03:44:17 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 2 to 3 ===
[2025-03-16 03:45:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 0 loss:0.070192351937294 norm:0.021388962864875793 max memory_allocated 38139.54833984375 
[2025-03-16 03:46:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 1 loss:0.04150385782122612 norm:0.012458616867661476 max memory_allocated 38139.54833984375 
[2025-03-16 03:47:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 2 loss:0.03202399984002113 norm:0.0067451028153300285 max memory_allocated 38139.54833984375 
[2025-03-16 03:48:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 3 loss:0.027540629729628563 norm:0.005269159097224474 max memory_allocated 38139.54833984375 
[2025-03-16 03:49:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 4 loss:0.02508251741528511 norm:0.00498101906850934 max memory_allocated 38139.54833984375 
[2025-03-16 03:50:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 5 loss:0.023487810045480728 norm:0.004571718163788319 max memory_allocated 38139.54833984375 
[2025-03-16 03:51:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 6 loss:0.022365424782037735 norm:0.004069396294653416 max memory_allocated 38139.54833984375 
[2025-03-16 03:51:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 7 loss:0.02152440696954727 norm:0.0038818311877548695 max memory_allocated 38139.54833984375 
[2025-03-16 03:52:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 8 loss:0.020972993224859238 norm:0.0034653707407414913 max memory_allocated 38139.54833984375 
[2025-03-16 03:53:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 9 loss:0.02052663080394268 norm:0.003182331332936883 max memory_allocated 38139.54833984375 
[2025-03-16 03:54:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 10 loss:0.020171113312244415 norm:0.0032570073381066322 max memory_allocated 38139.54833984375 
[2025-03-16 03:55:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 11 loss:0.019902637228369713 norm:0.0030236185993999243 max memory_allocated 38139.54833984375 
[2025-03-16 03:56:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 12 loss:0.019688840955495834 norm:0.0029370575211942196 max memory_allocated 38139.54833984375 
[2025-03-16 03:57:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 13 loss:0.01952948607504368 norm:0.0027321744710206985 max memory_allocated 38139.54833984375 
[2025-03-16 03:58:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 14 loss:0.019394150003790855 norm:0.002526307012885809 max memory_allocated 38139.54833984375 
[2025-03-16 03:59:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 15 loss:0.01927104964852333 norm:0.0021952323149889708 max memory_allocated 38139.54833984375 
[2025-03-16 04:00:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 16 loss:0.019160833209753036 norm:0.0021306280978024006 max memory_allocated 38139.54833984375 
[2025-03-16 04:01:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 17 loss:0.01913393661379814 norm:0.002215065062046051 max memory_allocated 38139.54833984375 
[2025-03-16 04:02:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 18 loss:0.019087284803390503 norm:0.0020519921090453863 max memory_allocated 38139.54833984375 
[2025-03-16 04:03:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 19 loss:0.019064757972955704 norm:0.0020712970290333033 max memory_allocated 38139.54833984375 
[2025-03-16 04:03:52 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 3 to 4 ===
[2025-03-16 04:04:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 0 loss:0.07644562423229218 norm:0.046683598309755325 max memory_allocated 38139.54833984375 
[2025-03-16 04:05:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 1 loss:0.04103172942996025 norm:0.009009907022118568 max memory_allocated 38139.54833984375 
[2025-03-16 04:06:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 2 loss:0.030421828851103783 norm:0.0051192170940339565 max memory_allocated 38139.54833984375 
[2025-03-16 04:07:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 3 loss:0.024899054318666458 norm:0.0034319499973207712 max memory_allocated 38139.54833984375 
[2025-03-16 04:08:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 4 loss:0.022158073261380196 norm:0.0025097643956542015 max memory_allocated 38139.54833984375 
[2025-03-16 04:09:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 5 loss:0.020339220762252808 norm:0.0019298320403322577 max memory_allocated 38139.54833984375 
[2025-03-16 04:10:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 6 loss:0.019162556156516075 norm:0.0015342276310548186 max memory_allocated 38139.54833984375 
[2025-03-16 04:11:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 7 loss:0.018423747271299362 norm:0.0012765361461788416 max memory_allocated 38139.54833984375 
[2025-03-16 04:12:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 8 loss:0.017867326736450195 norm:0.0010791865643113852 max memory_allocated 38139.54833984375 
[2025-03-16 04:13:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 9 loss:0.017419934272766113 norm:0.0009426571778021753 max memory_allocated 38139.54833984375 
[2025-03-16 04:14:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 10 loss:0.017205502837896347 norm:0.0008358885534107685 max memory_allocated 38139.54833984375 
[2025-03-16 04:15:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 11 loss:0.016864972189068794 norm:0.0007663776632398367 max memory_allocated 38139.54833984375 
[2025-03-16 04:16:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 12 loss:0.01665801741182804 norm:0.0007016744348220527 max memory_allocated 38139.54833984375 
[2025-03-16 04:17:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 13 loss:0.016495462507009506 norm:0.0006437355768866837 max memory_allocated 38139.54833984375 
[2025-03-16 04:18:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 14 loss:0.016351237893104553 norm:0.0005928243044763803 max memory_allocated 38139.54833984375 
[2025-03-16 04:19:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 15 loss:0.016250938177108765 norm:0.0005779705243185163 max memory_allocated 38139.54833984375 
[2025-03-16 04:20:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 16 loss:0.016133155673742294 norm:0.0005486950976774096 max memory_allocated 38139.54833984375 
[2025-03-16 04:21:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 17 loss:0.016071496531367302 norm:0.0005291544366627932 max memory_allocated 38139.54833984375 
[2025-03-16 04:21:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 18 loss:0.015998683869838715 norm:0.0005208244547247887 max memory_allocated 38139.54833984375 
[2025-03-16 04:22:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 19 loss:0.01592031680047512 norm:0.0005589270731434226 max memory_allocated 38139.54833984375 
[2025-03-16 04:23:25 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 4 to 5 ===
[2025-03-16 04:24:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 0 loss:0.03144402801990509 norm:0.003531554713845253 max memory_allocated 38139.54833984375 
[2025-03-16 04:25:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 1 loss:0.019354455173015594 norm:0.0010359750594943762 max memory_allocated 38139.54833984375 
[2025-03-16 04:26:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 2 loss:0.015047622844576836 norm:0.0005469173192977905 max memory_allocated 38139.54833984375 
[2025-03-16 04:27:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 3 loss:0.012917568907141685 norm:0.00035937645589001477 max memory_allocated 38139.54833984375 
[2025-03-16 04:28:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 4 loss:0.012016292661428452 norm:0.00028760256827808917 max memory_allocated 38139.54833984375 
[2025-03-16 04:29:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 5 loss:0.011490240693092346 norm:0.0002494781219866127 max memory_allocated 38139.54833984375 
[2025-03-16 04:30:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 6 loss:0.011153596453368664 norm:0.00022746364993508905 max memory_allocated 38139.54833984375 
[2025-03-16 04:31:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 7 loss:0.010844043456017971 norm:0.00020264030899852514 max memory_allocated 38139.54833984375 
[2025-03-16 04:32:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 8 loss:0.010616333223879337 norm:0.00019650999456644058 max memory_allocated 38139.54833984375 
[2025-03-16 04:32:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 9 loss:0.01049091387540102 norm:0.00020226131891831756 max memory_allocated 38139.54833984375 
[2025-03-16 04:33:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 10 loss:0.010348737239837646 norm:0.00019720697309821844 max memory_allocated 38139.54833984375 
[2025-03-16 04:34:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 11 loss:0.010255897417664528 norm:0.0001838164171203971 max memory_allocated 38139.54833984375 
[2025-03-16 04:35:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 12 loss:0.010151158086955547 norm:0.00018512507085688412 max memory_allocated 38139.54833984375 
[2025-03-16 04:36:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 13 loss:0.01010061614215374 norm:0.00018839525000657886 max memory_allocated 38139.54833984375 
[2025-03-16 04:37:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 14 loss:0.010026630945503712 norm:0.0005665068165399134 max memory_allocated 38139.54833984375 
[2025-03-16 04:38:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 15 loss:0.009992800652980804 norm:0.00019005066133104265 max memory_allocated 38139.54833984375 
[2025-03-16 04:39:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 16 loss:0.009887361899018288 norm:0.00017899998056236655 max memory_allocated 38139.54833984375 
[2025-03-16 04:40:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 17 loss:0.009844643995165825 norm:0.00017604423919692636 max memory_allocated 38139.54833984375 
[2025-03-16 04:41:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 18 loss:0.009796488098800182 norm:0.00017408192798029631 max memory_allocated 38139.54833984375 
[2025-03-16 04:42:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 19 loss:0.009728697128593922 norm:0.00017543320427648723 max memory_allocated 38139.54833984375 
[2025-03-16 04:42:58 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 5 to 6 ===
[2025-03-16 04:43:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 0 loss:0.03092196211218834 norm:0.006591931451112032 max memory_allocated 38139.54833984375 
[2025-03-16 04:44:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 1 loss:0.020828891545534134 norm:0.001998953055590391 max memory_allocated 38139.54833984375 
[2025-03-16 04:45:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 2 loss:0.016383130103349686 norm:0.0011280854232609272 max memory_allocated 38139.54833984375 
[2025-03-16 04:46:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 3 loss:0.014234749600291252 norm:0.0007375875138677657 max memory_allocated 38139.54833984375 
[2025-03-16 04:47:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 4 loss:0.013154876418411732 norm:0.0005489678587764502 max memory_allocated 38139.54833984375 
[2025-03-16 04:48:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 5 loss:0.012466119602322578 norm:0.0004378585144877434 max memory_allocated 38139.54833984375 
[2025-03-16 04:49:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 6 loss:0.011974899098277092 norm:0.0003657006018329412 max memory_allocated 38139.54833984375 
[2025-03-16 04:50:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 7 loss:0.011607677675783634 norm:0.0003119997272733599 max memory_allocated 38139.54833984375 
[2025-03-16 04:51:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 8 loss:0.01138526014983654 norm:0.0002802968374453485 max memory_allocated 38139.54833984375 
[2025-03-16 04:52:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 9 loss:0.011203809641301632 norm:0.0002578354033175856 max memory_allocated 38139.54833984375 
[2025-03-16 04:53:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 10 loss:0.011079194024205208 norm:0.0002368370769545436 max memory_allocated 38139.54833984375 
[2025-03-16 04:54:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 11 loss:0.01095033809542656 norm:0.00021386356092989445 max memory_allocated 38139.54833984375 
[2025-03-16 04:55:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 12 loss:0.010842976160347462 norm:0.00019927571702282876 max memory_allocated 38139.54833984375 
[2025-03-16 04:56:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 13 loss:0.010805457830429077 norm:0.00019107325351797044 max memory_allocated 38139.54833984375 
[2025-03-16 04:57:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 14 loss:0.010760772973299026 norm:0.00018775108037516475 max memory_allocated 38139.54833984375 
[2025-03-16 04:58:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 15 loss:0.010696513578295708 norm:0.0001868677936727181 max memory_allocated 38139.54833984375 
[2025-03-16 04:59:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 16 loss:0.010646265000104904 norm:0.00017972872592508793 max memory_allocated 38139.54833984375 
[2025-03-16 05:00:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 17 loss:0.010602233931422234 norm:0.00017450244922656566 max memory_allocated 38139.54833984375 
[2025-03-16 05:01:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 18 loss:0.01057545468211174 norm:0.000172339758137241 max memory_allocated 38139.54833984375 
[2025-03-16 05:02:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 19 loss:0.010548790916800499 norm:0.00017427494458388537 max memory_allocated 38139.54833984375 
[2025-03-16 05:02:30 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 6 to 7 ===
[2025-03-16 05:03:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 0 loss:0.036758117377758026 norm:0.006412937771528959 max memory_allocated 38139.54833984375 
[2025-03-16 05:04:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 1 loss:0.024187657982110977 norm:0.0024551949463784695 max memory_allocated 38139.54833984375 
[2025-03-16 05:05:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 2 loss:0.019347762688994408 norm:0.0014549089828506112 max memory_allocated 38139.54833984375 
[2025-03-16 05:06:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 3 loss:0.01696925051510334 norm:0.001024013850837946 max memory_allocated 38139.54833984375 
[2025-03-16 05:07:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 4 loss:0.0156636293977499 norm:0.0007775937556289136 max memory_allocated 38139.54833984375 
[2025-03-16 05:08:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 5 loss:0.014845579862594604 norm:0.0006425671163015068 max memory_allocated 38139.54833984375 
[2025-03-16 05:09:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 6 loss:0.014173251576721668 norm:0.0005408398574218154 max memory_allocated 38139.54833984375 
[2025-03-16 05:10:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 7 loss:0.013753030449151993 norm:0.0004602246335707605 max memory_allocated 38139.54833984375 
[2025-03-16 05:11:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 8 loss:0.013472381979227066 norm:0.0004139606317039579 max memory_allocated 38139.54833984375 
[2025-03-16 05:12:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 9 loss:0.013228101655840874 norm:0.00036399284726940095 max memory_allocated 38139.54833984375 
[2025-03-16 05:13:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 10 loss:0.013101886957883835 norm:0.0003412991645745933 max memory_allocated 38139.54833984375 
[2025-03-16 05:13:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 11 loss:0.012960781343281269 norm:0.0021096079144626856 max memory_allocated 38139.54833984375 
[2025-03-16 05:14:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 12 loss:0.012841658666729927 norm:0.00028347247280180454 max memory_allocated 38139.54833984375 
[2025-03-16 05:15:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 13 loss:0.012716134078800678 norm:0.00026265543419867754 max memory_allocated 38139.54833984375 
[2025-03-16 05:16:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 14 loss:0.012638282962143421 norm:0.0002485338773112744 max memory_allocated 38139.54833984375 
[2025-03-16 05:17:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 15 loss:0.012534698471426964 norm:0.00022737382096238434 max memory_allocated 38139.54833984375 
[2025-03-16 05:18:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 16 loss:0.0124517772346735 norm:0.0002226251526735723 max memory_allocated 38139.54833984375 
[2025-03-16 05:19:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 17 loss:0.012397597543895245 norm:0.00020826693798881024 max memory_allocated 38139.54833984375 
[2025-03-16 05:20:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 18 loss:0.01234741322696209 norm:0.00020161965221632272 max memory_allocated 38139.54833984375 
[2025-03-16 05:21:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 19 loss:0.012335547246038914 norm:0.0001943800743902102 max memory_allocated 38139.54833984375 
[2025-03-16 05:22:03 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 7 to 8 ===
[2025-03-16 05:23:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 0 loss:0.03397538140416145 norm:0.002299634739756584 max memory_allocated 38139.54833984375 
[2025-03-16 05:24:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 1 loss:0.022315675392746925 norm:0.0006746011204086244 max memory_allocated 38139.54833984375 
[2025-03-16 05:24:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 2 loss:0.01830488070845604 norm:0.0004485954996198416 max memory_allocated 38139.54833984375 
[2025-03-16 05:25:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 3 loss:0.016167789697647095 norm:0.00036214315332472324 max memory_allocated 38139.54833984375 
[2025-03-16 05:26:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 4 loss:0.01507004164159298 norm:0.00032105285208672285 max memory_allocated 38139.54833984375 
[2025-03-16 05:27:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 5 loss:0.01438081730157137 norm:0.00029692481621168554 max memory_allocated 38139.54833984375 
[2025-03-16 05:28:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 6 loss:0.013892906717956066 norm:0.0002713050926104188 max memory_allocated 38139.54833984375 
[2025-03-16 05:29:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 7 loss:0.013535834848880768 norm:0.00025201099924743176 max memory_allocated 38139.54833984375 
[2025-03-16 05:30:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 8 loss:0.013267513364553452 norm:0.0002380581572651863 max memory_allocated 38139.54833984375 
[2025-03-16 05:31:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 9 loss:0.013090676628053188 norm:0.00023030638112686574 max memory_allocated 38139.54833984375 
[2025-03-16 05:32:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 10 loss:0.012951252982020378 norm:0.0002208221412729472 max memory_allocated 38139.54833984375 
[2025-03-16 05:33:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 11 loss:0.012820776551961899 norm:0.000214435625821352 max memory_allocated 38139.54833984375 
[2025-03-16 05:34:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 12 loss:0.012699786573648453 norm:0.0002017873921431601 max memory_allocated 38139.54833984375 
[2025-03-16 05:35:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 13 loss:0.012581339105963707 norm:0.00019162680837325752 max memory_allocated 38139.54833984375 
[2025-03-16 05:36:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 14 loss:0.012530199252068996 norm:0.00018691798322834074 max memory_allocated 38139.54833984375 
[2025-03-16 05:37:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 15 loss:0.012471510097384453 norm:0.00018263488891534507 max memory_allocated 38139.54833984375 
[2025-03-16 05:38:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 16 loss:0.012432988733053207 norm:0.00018131849355995655 max memory_allocated 38139.54833984375 
[2025-03-16 05:39:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 17 loss:0.012387627735733986 norm:0.00017498017405159771 max memory_allocated 38139.54833984375 
[2025-03-16 05:40:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 18 loss:0.01232767105102539 norm:0.00017107735038734972 max memory_allocated 38139.54833984375 
[2025-03-16 05:41:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 19 loss:0.01228965912014246 norm:0.00016783634782768786 max memory_allocated 38139.54833984375 
[2025-03-16 05:41:35 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 8 to 9 ===
[2025-03-16 05:42:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 0 loss:0.035872045904397964 norm:0.004221667069941759 max memory_allocated 38139.54833984375 
[2025-03-16 05:43:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 1 loss:0.02532639168202877 norm:0.0019398849690333009 max memory_allocated 38139.54833984375 
[2025-03-16 05:44:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 2 loss:0.020803214982151985 norm:0.0012266815174371004 max memory_allocated 38139.54833984375 
[2025-03-16 05:45:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 3 loss:0.018502522259950638 norm:0.0008981214486993849 max memory_allocated 38139.54833984375 
[2025-03-16 05:46:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 4 loss:0.01723674312233925 norm:0.0006863697781227529 max memory_allocated 38139.54833984375 
[2025-03-16 05:47:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 5 loss:0.01638874225318432 norm:0.000568241928704083 max memory_allocated 38139.54833984375 
[2025-03-16 05:48:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 6 loss:0.015836235135793686 norm:0.0004881209461018443 max memory_allocated 38139.54833984375 
[2025-03-16 05:49:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 7 loss:0.01544495951384306 norm:0.0004219309485051781 max memory_allocated 38139.54833984375 
[2025-03-16 05:50:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 8 loss:0.015180539339780807 norm:0.0003744404239114374 max memory_allocated 38139.54833984375 
[2025-03-16 05:51:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 9 loss:0.01497223973274231 norm:0.0003279098018538207 max memory_allocated 38139.54833984375 
[2025-03-16 05:52:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 10 loss:0.014825783669948578 norm:0.000305150548228994 max memory_allocated 38139.54833984375 
[2025-03-16 05:53:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 11 loss:0.014676699414849281 norm:0.0002824602124746889 max memory_allocated 38139.54833984375 
[2025-03-16 05:53:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 12 loss:0.014590218663215637 norm:0.0002663139021024108 max memory_allocated 38139.54833984375 
[2025-03-16 05:54:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 13 loss:0.014514240436255932 norm:0.0002423057158011943 max memory_allocated 38139.54833984375 
[2025-03-16 05:55:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 14 loss:0.01443125493824482 norm:0.0002293018769705668 max memory_allocated 38139.54833984375 
[2025-03-16 05:56:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 15 loss:0.014370299875736237 norm:0.00021312112221494317 max memory_allocated 38139.54833984375 
[2025-03-16 05:57:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 16 loss:0.014316020533442497 norm:0.00020343194773886353 max memory_allocated 38139.54833984375 
[2025-03-16 05:58:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 17 loss:0.014265533536672592 norm:0.00019766106561291963 max memory_allocated 38139.54833984375 
[2025-03-16 05:59:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 18 loss:0.014256303198635578 norm:0.00018928445933852345 max memory_allocated 38139.54833984375 
[2025-03-16 06:00:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 19 loss:0.014203688129782677 norm:0.00018686002294998616 max memory_allocated 38139.54833984375 
[2025-03-16 06:01:07 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 9 to 10 ===
[2025-03-16 06:02:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 0 loss:0.03805410861968994 norm:0.0018385901348665357 max memory_allocated 38139.57861328125 
[2025-03-16 06:03:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 1 loss:0.024953162297606468 norm:0.0007248258916661143 max memory_allocated 38139.57861328125 
[2025-03-16 06:04:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 2 loss:0.020319825038313866 norm:0.0004850706027355045 max memory_allocated 38139.57861328125 
[2025-03-16 06:04:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 3 loss:0.01783519610762596 norm:0.0003729665477294475 max memory_allocated 38139.57861328125 
[2025-03-16 06:05:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 4 loss:0.016529107466340065 norm:0.000310176401399076 max memory_allocated 38139.57861328125 
[2025-03-16 06:06:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 5 loss:0.015731440857052803 norm:0.0002787087287288159 max memory_allocated 38139.57861328125 
[2025-03-16 06:07:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 6 loss:0.015202882699668407 norm:0.0002572097582742572 max memory_allocated 38139.57861328125 
[2025-03-16 06:08:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 7 loss:0.014804045669734478 norm:0.00023997054086066782 max memory_allocated 38139.57861328125 
[2025-03-16 06:09:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 8 loss:0.014546068385243416 norm:0.0002329894487047568 max memory_allocated 38139.57861328125 
[2025-03-16 06:10:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 9 loss:0.014332043938338757 norm:0.00022813980467617512 max memory_allocated 38139.57861328125 
[2025-03-16 06:11:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 10 loss:0.014156519435346127 norm:0.00022312160581350327 max memory_allocated 38139.57861328125 
[2025-03-16 06:12:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 11 loss:0.014005684293806553 norm:0.00021239290072117 max memory_allocated 38139.57861328125 
[2025-03-16 06:13:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 12 loss:0.013903176411986351 norm:0.00021219905465841293 max memory_allocated 38139.57861328125 
[2025-03-16 06:14:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 13 loss:0.013823124580085278 norm:0.00020582460274454206 max memory_allocated 38139.57861328125 
[2025-03-16 06:15:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 14 loss:0.013714640401303768 norm:0.00019449640240054578 max memory_allocated 38139.57861328125 
[2025-03-16 06:16:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 15 loss:0.013622673228383064 norm:0.00018888643535319716 max memory_allocated 38139.57861328125 
[2025-03-16 06:17:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 16 loss:0.013557463884353638 norm:0.00018278237257618457 max memory_allocated 38139.57861328125 
[2025-03-16 06:18:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 17 loss:0.013502966612577438 norm:0.0001773868134478107 max memory_allocated 38139.57861328125 
[2025-03-16 06:19:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 18 loss:0.013459688983857632 norm:0.0001772953401086852 max memory_allocated 38139.57861328125 
[2025-03-16 06:20:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 19 loss:0.013428040780127048 norm:0.00017098970420192927 max memory_allocated 38139.57861328125 
[2025-03-16 06:20:40 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 10 to 11 ===
[2025-03-16 06:21:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 0 loss:0.03811245784163475 norm:0.004655205179005861 max memory_allocated 38139.75048828125 
[2025-03-16 06:22:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 1 loss:0.02680473029613495 norm:0.002039281651377678 max memory_allocated 38139.75048828125 
[2025-03-16 06:23:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 2 loss:0.021927256137132645 norm:0.0011770599521696568 max memory_allocated 38139.75048828125 
[2025-03-16 06:24:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 3 loss:0.019048070535063744 norm:0.0007125693955458701 max memory_allocated 38139.75048828125 
[2025-03-16 06:25:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 4 loss:0.01756925880908966 norm:0.0005661447066813707 max memory_allocated 38139.75048828125 
[2025-03-16 06:26:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 5 loss:0.01665661297738552 norm:0.00045710126869380474 max memory_allocated 38139.75048828125 
[2025-03-16 06:27:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 6 loss:0.01603480987250805 norm:0.0003909048973582685 max memory_allocated 38139.75048828125 
[2025-03-16 06:28:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 7 loss:0.015630805864930153 norm:0.00034384854370728135 max memory_allocated 38139.75048828125 
[2025-03-16 06:29:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 8 loss:0.015312831848859787 norm:0.00031469218083657324 max memory_allocated 38139.75048828125 
[2025-03-16 06:30:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 9 loss:0.01511214580386877 norm:0.0002934361109510064 max memory_allocated 38139.75048828125 
[2025-03-16 06:31:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 10 loss:0.01495477557182312 norm:0.00027112819952890277 max memory_allocated 38139.75048828125 
[2025-03-16 06:32:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 11 loss:0.014857286587357521 norm:0.0002603848115541041 max memory_allocated 38139.75048828125 
[2025-03-16 06:33:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 12 loss:0.014722306281328201 norm:0.00024400105758104473 max memory_allocated 38139.75048828125 
[2025-03-16 06:34:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 13 loss:0.014659552834928036 norm:0.00023842137306928635 max memory_allocated 38139.75048828125 
[2025-03-16 06:34:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 14 loss:0.014570331200957298 norm:0.0002280488988617435 max memory_allocated 38139.75048828125 
[2025-03-16 06:35:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 15 loss:0.014473142102360725 norm:0.00021926956833340228 max memory_allocated 38139.75048828125 
[2025-03-16 06:36:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 16 loss:0.014456037431955338 norm:0.0002111036010319367 max memory_allocated 38139.75048828125 
[2025-03-16 06:37:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 17 loss:0.014422752894461155 norm:0.0002090030611725524 max memory_allocated 38139.75048828125 
[2025-03-16 06:38:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 18 loss:0.01436957623809576 norm:0.00020585423044394702 max memory_allocated 38139.75048828125 
[2025-03-16 06:39:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 19 loss:0.01432257890701294 norm:0.0002034404024016112 max memory_allocated 38139.75048828125 
[2025-03-16 06:40:12 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 11 to 12 ===
[2025-03-16 06:41:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 0 loss:0.033904608339071274 norm:0.001929866150021553 max memory_allocated 38139.92236328125 
[2025-03-16 06:42:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 1 loss:0.0234286617487669 norm:0.000787869154009968 max memory_allocated 38139.92236328125 
[2025-03-16 06:43:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 2 loss:0.019561316817998886 norm:0.0005884227575734258 max memory_allocated 38139.92236328125 
[2025-03-16 06:44:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 3 loss:0.017278406769037247 norm:0.0004484980017878115 max memory_allocated 38139.92236328125 
[2025-03-16 06:45:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 4 loss:0.01598108373582363 norm:0.000369024375686422 max memory_allocated 38139.92236328125 
[2025-03-16 06:45:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 5 loss:0.01519011054188013 norm:0.0003251119633205235 max memory_allocated 38139.92236328125 
[2025-03-16 06:46:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 6 loss:0.014632915146648884 norm:0.0002849428856279701 max memory_allocated 38139.92236328125 
[2025-03-16 06:47:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 7 loss:0.014187358319759369 norm:0.0002607189235277474 max memory_allocated 38139.92236328125 
[2025-03-16 06:48:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 8 loss:0.01390773430466652 norm:0.0002454151399433613 max memory_allocated 38139.92236328125 
[2025-03-16 06:49:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 9 loss:0.013691993430256844 norm:0.00023008411517366767 max memory_allocated 38139.92236328125 
[2025-03-16 06:50:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 10 loss:0.013518172316253185 norm:0.0002126252802554518 max memory_allocated 38139.92236328125 
[2025-03-16 06:51:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 11 loss:0.013343825936317444 norm:0.00020018192299176008 max memory_allocated 38139.92236328125 
[2025-03-16 06:52:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 12 loss:0.013232034631073475 norm:0.00018863713194150478 max memory_allocated 38139.92236328125 
[2025-03-16 06:53:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 13 loss:0.013168655335903168 norm:0.00018715744954533875 max memory_allocated 38139.92236328125 
[2025-03-16 06:54:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 14 loss:0.013103142380714417 norm:0.00018079343135468662 max memory_allocated 38139.92236328125 
[2025-03-16 06:55:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 15 loss:0.013064001686871052 norm:0.00018025920144282281 max memory_allocated 38139.92236328125 
[2025-03-16 06:56:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 16 loss:0.013015207834541798 norm:0.0001741319429129362 max memory_allocated 38139.92236328125 
[2025-03-16 06:57:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 17 loss:0.012964103370904922 norm:0.0001711831137072295 max memory_allocated 38139.92236328125 
[2025-03-16 06:58:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 18 loss:0.012914811260998249 norm:0.00017299527826253325 max memory_allocated 38139.92236328125 
[2025-03-16 06:59:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 19 loss:0.012883300893008709 norm:0.00017057612421922386 max memory_allocated 38139.92236328125 
[2025-03-16 06:59:44 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 12 to 13 ===
[2025-03-16 07:00:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 0 loss:0.028760921210050583 norm:0.001199859892949462 max memory_allocated 38140.09423828125 
[2025-03-16 07:01:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 1 loss:0.020995071157813072 norm:0.0005993780796416104 max memory_allocated 38140.09423828125 
[2025-03-16 07:02:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 2 loss:0.017468441277742386 norm:0.0003988294047303498 max memory_allocated 38140.09423828125 
[2025-03-16 07:03:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 3 loss:0.015524815768003464 norm:0.0002867388539016247 max memory_allocated 38140.09423828125 
[2025-03-16 07:04:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 4 loss:0.014551960863173008 norm:0.00023359019542112947 max memory_allocated 38140.09423828125 
[2025-03-16 07:05:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 5 loss:0.013940134085714817 norm:0.00020173712982796133 max memory_allocated 38140.09423828125 
[2025-03-16 07:06:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 6 loss:0.013498441316187382 norm:0.0001748593640513718 max memory_allocated 38140.09423828125 
[2025-03-16 07:07:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 7 loss:0.013233112171292305 norm:0.0001636185188544914 max memory_allocated 38140.09423828125 
[2025-03-16 07:08:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 8 loss:0.013034501112997532 norm:0.00015607535897288471 max memory_allocated 38140.09423828125 
[2025-03-16 07:09:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 9 loss:0.012895571067929268 norm:0.00014824274694547057 max memory_allocated 38140.09423828125 
[2025-03-16 07:10:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 10 loss:0.012793275527656078 norm:0.0001458769547753036 max memory_allocated 38140.09423828125 
[2025-03-16 07:11:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 11 loss:0.012731758877635002 norm:0.00014387568808160722 max memory_allocated 38140.09423828125 
[2025-03-16 07:12:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 12 loss:0.012660974636673927 norm:0.00013826542999595404 max memory_allocated 38140.09423828125 
[2025-03-16 07:13:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 13 loss:0.012611431069672108 norm:0.0001363818591926247 max memory_allocated 38140.09423828125 
[2025-03-16 07:14:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 14 loss:0.012574275955557823 norm:0.00013618994853459299 max memory_allocated 38140.09423828125 
[2025-03-16 07:14:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 15 loss:0.012551418505609035 norm:0.0001361028989776969 max memory_allocated 38140.09423828125 
[2025-03-16 07:15:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 16 loss:0.0125065166503191 norm:0.00013539587962441146 max memory_allocated 38140.09423828125 
[2025-03-16 07:16:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 17 loss:0.012478114105761051 norm:0.00012999596947338432 max memory_allocated 38140.09423828125 
[2025-03-16 07:17:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 18 loss:0.012463822960853577 norm:0.00012952106771990657 max memory_allocated 38140.09423828125 
[2025-03-16 07:18:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 19 loss:0.012431551702320576 norm:0.00013134046457707882 max memory_allocated 38140.09423828125 
[2025-03-16 07:19:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 13 to 14 ===
[2025-03-16 07:20:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 0 loss:0.031026339158415794 norm:0.001715092221274972 max memory_allocated 38140.26611328125 
[2025-03-16 07:21:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 1 loss:0.023705262690782547 norm:0.0009643698576837778 max memory_allocated 38140.26611328125 
[2025-03-16 07:22:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 2 loss:0.02003466710448265 norm:0.0006952367257326841 max memory_allocated 38140.26611328125 
[2025-03-16 07:23:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 3 loss:0.017980186268687248 norm:0.0005199218867346644 max memory_allocated 38140.26611328125 
[2025-03-16 07:24:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 4 loss:0.016821270808577538 norm:0.0004210664192214608 max memory_allocated 38140.26611328125 
[2025-03-16 07:25:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 5 loss:0.01609005779027939 norm:0.00035212666261941195 max memory_allocated 38140.26611328125 
[2025-03-16 07:26:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 6 loss:0.015569076873362064 norm:0.00030199449975043535 max memory_allocated 38140.26611328125 
[2025-03-16 07:27:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 7 loss:0.015235929749906063 norm:0.0002648802474141121 max memory_allocated 38140.26611328125 
[2025-03-16 07:28:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 8 loss:0.015002941712737083 norm:0.00024313063477165997 max memory_allocated 38140.26611328125 
[2025-03-16 07:28:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 9 loss:0.01480043400079012 norm:0.00023019318177830428 max memory_allocated 38140.26611328125 
[2025-03-16 07:29:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 10 loss:0.014674577862024307 norm:0.0002122177684213966 max memory_allocated 38140.26611328125 
[2025-03-16 07:30:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 11 loss:0.014563960023224354 norm:0.0001996896753553301 max memory_allocated 38140.26611328125 
[2025-03-16 07:31:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 12 loss:0.014476832933723927 norm:0.00019247198360972106 max memory_allocated 38140.26611328125 
[2025-03-16 07:32:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 13 loss:0.014406871050596237 norm:0.00018631551938597113 max memory_allocated 38140.26611328125 
[2025-03-16 07:33:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 14 loss:0.01434076763689518 norm:0.00017977048992179334 max memory_allocated 38140.26611328125 
[2025-03-16 07:34:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 15 loss:0.014297086745500565 norm:0.00017432094318792224 max memory_allocated 38140.26611328125 
[2025-03-16 07:35:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 16 loss:0.014238429255783558 norm:0.0001740246661938727 max memory_allocated 38140.26611328125 
[2025-03-16 07:36:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 17 loss:0.01420006062835455 norm:0.00016832177061587572 max memory_allocated 38140.26611328125 
[2025-03-16 07:37:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 18 loss:0.01417073979973793 norm:0.00016869553655851632 max memory_allocated 38140.26611328125 
[2025-03-16 07:38:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 19 loss:0.014143882319331169 norm:0.0001657134125707671 max memory_allocated 38140.26611328125 
[2025-03-16 07:38:58 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 14 to 15 ===
[2025-03-16 07:40:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 0 loss:0.03983149304986 norm:0.0017413001041859388 max memory_allocated 38140.43798828125 
[2025-03-16 07:40:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 1 loss:0.025721250101923943 norm:0.0007024113438092172 max memory_allocated 38140.43798828125 
[2025-03-16 07:41:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 2 loss:0.020810408517718315 norm:0.00045900201075710356 max memory_allocated 38140.43798828125 
[2025-03-16 07:42:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 3 loss:0.0183662548661232 norm:0.0003483205509837717 max memory_allocated 38140.43798828125 
[2025-03-16 07:43:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 4 loss:0.017083216458559036 norm:0.00028768027550540864 max memory_allocated 38140.43798828125 
[2025-03-16 07:44:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 5 loss:0.01625702902674675 norm:0.00026235845871269703 max memory_allocated 38140.43798828125 
[2025-03-16 07:45:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 6 loss:0.015717467293143272 norm:0.00024146787473000586 max memory_allocated 38140.43798828125 
[2025-03-16 07:46:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 7 loss:0.015341376885771751 norm:0.00021527460194192827 max memory_allocated 38140.43798828125 
[2025-03-16 07:47:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 8 loss:0.015061110258102417 norm:0.00020405017130542547 max memory_allocated 38140.43798828125 
[2025-03-16 07:48:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 9 loss:0.014854121953248978 norm:0.00019272435747552663 max memory_allocated 38140.43798828125 
[2025-03-16 07:49:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 10 loss:0.01470316294580698 norm:0.00018632531282491982 max memory_allocated 38140.43798828125 
[2025-03-16 07:50:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 11 loss:0.014559744857251644 norm:0.00017369176202919334 max memory_allocated 38140.43798828125 
[2025-03-16 07:51:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 12 loss:0.014446130022406578 norm:0.0001672940416028723 max memory_allocated 38140.43798828125 
[2025-03-16 07:52:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 13 loss:0.014360024593770504 norm:0.00016688999312464148 max memory_allocated 38140.43798828125 
[2025-03-16 07:53:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 14 loss:0.014278760179877281 norm:0.00016608530131634325 max memory_allocated 38140.43798828125 
[2025-03-16 07:54:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 15 loss:0.014222451485693455 norm:0.00016418304585386068 max memory_allocated 38140.43798828125 
[2025-03-16 07:55:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 16 loss:0.014147798530757427 norm:0.0001598008966539055 max memory_allocated 38140.43798828125 
[2025-03-16 07:56:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 17 loss:0.014093123376369476 norm:0.0001573032932356 max memory_allocated 38140.43798828125 
[2025-03-16 07:57:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 18 loss:0.014066571369767189 norm:0.00015504950715694577 max memory_allocated 38140.43798828125 
[2025-03-16 07:58:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 19 loss:0.01403449010103941 norm:0.00015070302470121533 max memory_allocated 38140.43798828125 
[2025-03-16 07:58:31 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 15 to 16 ===
[2025-03-16 07:59:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 0 loss:0.028395354747772217 norm:0.0009585724910721183 max memory_allocated 38140.60986328125 
[2025-03-16 08:00:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 1 loss:0.021061137318611145 norm:0.000433824461651966 max memory_allocated 38140.60986328125 
[2025-03-16 08:01:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 2 loss:0.01726633869111538 norm:0.00026359569164924324 max memory_allocated 38140.60986328125 
[2025-03-16 08:02:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 3 loss:0.015663985162973404 norm:0.000192603692994453 max memory_allocated 38140.60986328125 
[2025-03-16 08:03:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 4 loss:0.014797038398683071 norm:0.000159131595864892 max memory_allocated 38140.60986328125 
[2025-03-16 08:04:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 5 loss:0.014225560240447521 norm:0.0001391852565575391 max memory_allocated 38140.60986328125 
[2025-03-16 08:05:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 6 loss:0.013856806792318821 norm:0.00012705218978226185 max memory_allocated 38140.60986328125 
[2025-03-16 08:06:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 7 loss:0.01359266135841608 norm:0.00011866851127706468 max memory_allocated 38140.60986328125 
[2025-03-16 08:07:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 8 loss:0.01341340597718954 norm:0.0001135936108767055 max memory_allocated 38140.60986328125 
[2025-03-16 08:08:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 9 loss:0.013272905722260475 norm:0.00010957888298435137 max memory_allocated 38140.60986328125 
[2025-03-16 08:09:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 10 loss:0.013148644007742405 norm:0.0001056361070368439 max memory_allocated 38140.60986328125 
[2025-03-16 08:09:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 11 loss:0.013058265671133995 norm:0.00010218576790066436 max memory_allocated 38140.60986328125 
[2025-03-16 08:10:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 12 loss:0.01299153920263052 norm:0.00010037427273346111 max memory_allocated 38140.60986328125 
[2025-03-16 08:11:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 13 loss:0.012943564914166927 norm:9.871764632407576e-05 max memory_allocated 38140.60986328125 
[2025-03-16 08:12:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 14 loss:0.01290449034422636 norm:9.682158997748047e-05 max memory_allocated 38140.60986328125 
[2025-03-16 08:13:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 15 loss:0.012867258861660957 norm:9.662222146289423e-05 max memory_allocated 38140.60986328125 
[2025-03-16 08:14:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 16 loss:0.01283971592783928 norm:9.646524995332584e-05 max memory_allocated 38140.60986328125 
[2025-03-16 08:15:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 17 loss:0.01281989086419344 norm:9.446516924072057e-05 max memory_allocated 38140.60986328125 
[2025-03-16 08:16:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 18 loss:0.012792697176337242 norm:9.4352632004302e-05 max memory_allocated 38140.60986328125 
[2025-03-16 08:17:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 19 loss:0.012754308991134167 norm:9.41428734222427e-05 max memory_allocated 38140.60986328125 
[2025-03-16 08:18:05 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 16 to 17 ===
[2025-03-16 08:19:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 0 loss:0.029262691736221313 norm:0.0016100214561447501 max memory_allocated 38140.78173828125 
[2025-03-16 08:20:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 1 loss:0.022992834448814392 norm:0.0007969863363541663 max memory_allocated 38140.78173828125 
[2025-03-16 08:21:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 2 loss:0.019541332498192787 norm:0.0005563153536058962 max memory_allocated 38140.78173828125 
[2025-03-16 08:21:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 3 loss:0.017962681129574776 norm:0.0004315458354540169 max memory_allocated 38140.78173828125 
[2025-03-16 08:22:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 4 loss:0.016916127875447273 norm:0.00030175165738910437 max memory_allocated 38140.78173828125 
[2025-03-16 08:23:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 5 loss:0.016333412379026413 norm:0.0002877422666642815 max memory_allocated 38140.78173828125 
[2025-03-16 08:24:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 6 loss:0.015821993350982666 norm:0.00019421910110395402 max memory_allocated 38140.78173828125 
[2025-03-16 08:25:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 7 loss:0.015475409105420113 norm:0.00019000182510353625 max memory_allocated 38140.78173828125 
[2025-03-16 08:26:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 8 loss:0.015265573747456074 norm:0.00018484490283299237 max memory_allocated 38140.78173828125 
[2025-03-16 08:27:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 9 loss:0.015128396451473236 norm:0.00017751025734469295 max memory_allocated 38140.78173828125 
[2025-03-16 08:28:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 10 loss:0.015063941478729248 norm:0.00018080897280015051 max memory_allocated 38140.78173828125 
[2025-03-16 08:29:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 11 loss:0.015006039291620255 norm:0.00016994282486848533 max memory_allocated 38140.78173828125 
[2025-03-16 08:30:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 12 loss:0.014927946962416172 norm:0.00015392890782095492 max memory_allocated 38140.78173828125 
[2025-03-16 08:31:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 13 loss:0.0148297268897295 norm:0.00014981023559812456 max memory_allocated 38140.78173828125 
[2025-03-16 08:32:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 14 loss:0.014790651388466358 norm:0.00014688698865938932 max memory_allocated 38140.78173828125 
[2025-03-16 08:33:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 15 loss:0.014744501560926437 norm:0.00014618673594668508 max memory_allocated 38140.78173828125 
[2025-03-16 08:34:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 16 loss:0.01473233662545681 norm:0.00014372653095051646 max memory_allocated 38140.78173828125 
[2025-03-16 08:35:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 17 loss:0.014708854258060455 norm:0.0001417913008481264 max memory_allocated 38140.78173828125 
[2025-03-16 08:36:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 18 loss:0.014704329892992973 norm:0.00014334711886476725 max memory_allocated 38140.78173828125 
[2025-03-16 08:37:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 19 loss:0.014685076661407948 norm:0.0001400449691573158 max memory_allocated 38140.78173828125 
[2025-03-16 08:37:40 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 17 to 18 ===
[2025-03-16 08:38:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 0 loss:0.032207902520895004 norm:0.0011889832094311714 max memory_allocated 38140.95361328125 
[2025-03-16 08:39:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 1 loss:0.0229775570333004 norm:0.0005016751820221543 max memory_allocated 38140.95361328125 
[2025-03-16 08:40:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 2 loss:0.01847963035106659 norm:0.00034005046472884715 max memory_allocated 38140.95361328125 
[2025-03-16 08:41:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 3 loss:0.016842857003211975 norm:0.000271022436209023 max memory_allocated 38140.95361328125 
[2025-03-16 08:42:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 4 loss:0.0159797053784132 norm:0.00024472613586112857 max memory_allocated 38140.95361328125 
[2025-03-16 08:43:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 5 loss:0.015344193205237389 norm:0.00021984706108924001 max memory_allocated 38140.95361328125 
[2025-03-16 08:44:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 6 loss:0.014938391745090485 norm:0.00021192127314861864 max memory_allocated 38140.95361328125 
[2025-03-16 08:45:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 7 loss:0.014632346108555794 norm:0.00019453659479040653 max memory_allocated 38140.95361328125 
[2025-03-16 08:46:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 8 loss:0.014422858133912086 norm:0.00018374971114099026 max memory_allocated 38140.95361328125 
[2025-03-16 08:47:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 9 loss:0.014292220585048199 norm:0.00017495291831437498 max memory_allocated 38140.95361328125 
[2025-03-16 08:48:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 10 loss:0.014189391396939754 norm:0.00017151837528217584 max memory_allocated 38140.95361328125 
[2025-03-16 08:49:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 11 loss:0.01411051582545042 norm:0.00016572709137108177 max memory_allocated 38140.95361328125 
[2025-03-16 08:50:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 12 loss:0.014049626886844635 norm:0.0001551725436002016 max memory_allocated 38140.95361328125 
[2025-03-16 08:51:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 13 loss:0.013992426916956902 norm:0.00015288058784790337 max memory_allocated 38140.95361328125 
[2025-03-16 08:51:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 14 loss:0.013928798958659172 norm:0.00014804163947701454 max memory_allocated 38140.95361328125 
[2025-03-16 08:52:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 15 loss:0.013875741511583328 norm:0.00014470085443463176 max memory_allocated 38140.95361328125 
[2025-03-16 08:53:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 16 loss:0.013824287801980972 norm:0.00014148799527902156 max memory_allocated 38140.95361328125 
[2025-03-16 08:54:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 17 loss:0.013797120191156864 norm:0.00013839859457220882 max memory_allocated 38140.95361328125 
[2025-03-16 08:55:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 18 loss:0.013758471235632896 norm:0.00013445180957205594 max memory_allocated 38140.95361328125 
[2025-03-16 08:56:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 19 loss:0.013724368996918201 norm:0.0001296037808060646 max memory_allocated 38140.95361328125 
[2025-03-16 08:57:13 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 18 to 19 ===
[2025-03-16 08:58:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 0 loss:0.031159795820713043 norm:0.0009860207792371511 max memory_allocated 38141.12548828125 
[2025-03-16 08:59:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 1 loss:0.024440934881567955 norm:0.0005074755754321814 max memory_allocated 38141.12548828125 
[2025-03-16 09:00:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 2 loss:0.020175833255052567 norm:0.0003219511709176004 max memory_allocated 38141.12548828125 
[2025-03-16 09:01:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 3 loss:0.01851774752140045 norm:0.0002407410356681794 max memory_allocated 38141.12548828125 
[2025-03-16 09:02:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 4 loss:0.01760004460811615 norm:0.00020028551807627082 max memory_allocated 38141.12548828125 
[2025-03-16 09:02:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 5 loss:0.016983266919851303 norm:0.00017922508413903415 max memory_allocated 38141.12548828125 
[2025-03-16 09:03:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 6 loss:0.01657235436141491 norm:0.00016121506632771343 max memory_allocated 38141.12548828125 
[2025-03-16 09:04:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 7 loss:0.016305997967720032 norm:0.0001477912737755105 max memory_allocated 38141.12548828125 
[2025-03-16 09:05:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 8 loss:0.01613379269838333 norm:0.0001412400888511911 max memory_allocated 38141.12548828125 
[2025-03-16 09:06:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 9 loss:0.0160153117030859 norm:0.0001360852038487792 max memory_allocated 38141.12548828125 
[2025-03-16 09:07:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 10 loss:0.01596185192465782 norm:0.00013232219498604536 max memory_allocated 38141.12548828125 
[2025-03-16 09:08:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 11 loss:0.015911567956209183 norm:0.0001286085316678509 max memory_allocated 38141.12548828125 
[2025-03-16 09:09:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 12 loss:0.015875358134508133 norm:0.0001272389927180484 max memory_allocated 38141.12548828125 
[2025-03-16 09:10:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 13 loss:0.015856651589274406 norm:0.0001254335220437497 max memory_allocated 38141.12548828125 
[2025-03-16 09:11:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 14 loss:0.015822099521756172 norm:0.00012495719420257956 max memory_allocated 38141.12548828125 
[2025-03-16 09:12:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 15 loss:0.015793129801750183 norm:0.00012284671538509429 max memory_allocated 38141.12548828125 
[2025-03-16 09:13:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 16 loss:0.015800632536411285 norm:0.00012429033813532442 max memory_allocated 38141.12548828125 
[2025-03-16 09:14:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 17 loss:0.01576078124344349 norm:0.00012135254655731842 max memory_allocated 38141.12548828125 
[2025-03-16 09:15:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 18 loss:0.015731273218989372 norm:0.00012103468179702759 max memory_allocated 38141.12548828125 
[2025-03-16 09:16:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 19 loss:0.01570975035429001 norm:0.00012117742153350264 max memory_allocated 38141.12548828125 
[2025-03-16 09:16:46 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 19 to 20 ===
[2025-03-16 09:17:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 0 loss:0.034645162522792816 norm:0.001208295812830329 max memory_allocated 38141.29736328125 
[2025-03-16 09:18:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 1 loss:0.025900069624185562 norm:0.00047469159471802413 max memory_allocated 38141.29736328125 
[2025-03-16 09:19:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 2 loss:0.02138437330722809 norm:0.0003105886862613261 max memory_allocated 38141.29736328125 
[2025-03-16 09:20:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 3 loss:0.01970386877655983 norm:0.0002392812166363001 max memory_allocated 38141.29736328125 
[2025-03-16 09:21:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 4 loss:0.01872926950454712 norm:0.00020799798949155957 max memory_allocated 38141.29736328125 
[2025-03-16 09:22:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 5 loss:0.01805829629302025 norm:0.00018907505727838725 max memory_allocated 38141.29736328125 
[2025-03-16 09:23:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 6 loss:0.017608409747481346 norm:0.00018122559413313866 max memory_allocated 38141.29736328125 
[2025-03-16 09:24:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 7 loss:0.01733849197626114 norm:0.0001707708725007251 max memory_allocated 38141.29736328125 
[2025-03-16 09:25:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 8 loss:0.01715388335287571 norm:0.00016108309500850737 max memory_allocated 38141.29736328125 
[2025-03-16 09:26:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 9 loss:0.017016274854540825 norm:0.00015657299081794918 max memory_allocated 38141.29736328125 
[2025-03-16 09:27:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 10 loss:0.01692916266620159 norm:0.00015195563901215792 max memory_allocated 38141.29736328125 
[2025-03-16 09:28:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 11 loss:0.016808325424790382 norm:0.00014731858391314745 max memory_allocated 38141.29736328125 
[2025-03-16 09:29:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 12 loss:0.01670755259692669 norm:0.00014169389032758772 max memory_allocated 38141.29736328125 
[2025-03-16 09:30:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 13 loss:0.016647322103381157 norm:0.00014213533722795546 max memory_allocated 38141.29736328125 
[2025-03-16 09:31:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 14 loss:0.01659540832042694 norm:0.00014006139826960862 max memory_allocated 38141.29736328125 
[2025-03-16 09:32:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 15 loss:0.01654951088130474 norm:0.00013700529234483838 max memory_allocated 38141.29736328125 
[2025-03-16 09:32:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 16 loss:0.016520721837878227 norm:0.00013573512842413038 max memory_allocated 38141.29736328125 
[2025-03-16 09:33:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 17 loss:0.0164751335978508 norm:0.0001349475933238864 max memory_allocated 38141.29736328125 
[2025-03-16 09:34:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 18 loss:0.016441093757748604 norm:0.00013390784442890435 max memory_allocated 38141.29736328125 
[2025-03-16 09:35:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 19 loss:0.016414018347859383 norm:0.00013278471305966377 max memory_allocated 38141.29736328125 
[2025-03-16 09:36:18 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 20 to 21 ===
[2025-03-16 09:37:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 0 loss:0.04097798466682434 norm:0.0026153111830353737 max memory_allocated 38141.46923828125 
[2025-03-16 09:38:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 1 loss:0.02980390004813671 norm:0.0008929009782150388 max memory_allocated 38141.46923828125 
[2025-03-16 09:39:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 2 loss:0.02422959730029106 norm:0.000510615180246532 max memory_allocated 38141.46923828125 
[2025-03-16 09:40:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 3 loss:0.022043565288186073 norm:0.00036838994128629565 max memory_allocated 38141.46923828125 
[2025-03-16 09:41:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 4 loss:0.020887935534119606 norm:0.0003097929002251476 max memory_allocated 38141.46923828125 
[2025-03-16 09:42:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 5 loss:0.020090501755475998 norm:0.0002768073754850775 max memory_allocated 38141.46923828125 
[2025-03-16 09:43:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 6 loss:0.0196150541305542 norm:0.00026184594025835395 max memory_allocated 38141.46923828125 
[2025-03-16 09:43:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 7 loss:0.01934981159865856 norm:0.00024415182997472584 max memory_allocated 38141.46923828125 
[2025-03-16 09:44:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 8 loss:0.01914818584918976 norm:0.00022902323689777404 max memory_allocated 38141.46923828125 
[2025-03-16 09:45:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 9 loss:0.019040804356336594 norm:0.0002178980503231287 max memory_allocated 38141.46923828125 
[2025-03-16 09:46:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 10 loss:0.018968990072607994 norm:0.00020359548216219991 max memory_allocated 38141.46923828125 
[2025-03-16 09:47:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 11 loss:0.01886339671909809 norm:0.00019789357611443847 max memory_allocated 38141.46923828125 
[2025-03-16 09:48:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 12 loss:0.01880069077014923 norm:0.0001916223845910281 max memory_allocated 38141.46923828125 
[2025-03-16 09:49:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 13 loss:0.018748795613646507 norm:0.00018661748617887497 max memory_allocated 38141.46923828125 
[2025-03-16 09:50:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 14 loss:0.018698111176490784 norm:0.00017977127572521567 max memory_allocated 38141.46923828125 
[2025-03-16 09:51:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 15 loss:0.01865488663315773 norm:0.00017607641348149627 max memory_allocated 38141.46923828125 
[2025-03-16 09:52:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 16 loss:0.01855373941361904 norm:0.00017027616559062153 max memory_allocated 38141.46923828125 
[2025-03-16 09:53:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 17 loss:0.018526755273342133 norm:0.00016893084102775902 max memory_allocated 38141.46923828125 
[2025-03-16 09:54:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 18 loss:0.01850435696542263 norm:0.00016348788631148636 max memory_allocated 38141.46923828125 
[2025-03-16 09:55:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 19 loss:0.01846456713974476 norm:0.0001612297783140093 max memory_allocated 38141.46923828125 
[2025-03-16 09:55:51 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 21 to 22 ===
[2025-03-16 09:56:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 0 loss:0.036104388535022736 norm:0.001129386480897665 max memory_allocated 38141.64111328125 
[2025-03-16 09:57:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 1 loss:0.02805689349770546 norm:0.000555551378056407 max memory_allocated 38141.64111328125 
[2025-03-16 09:58:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 2 loss:0.02305367961525917 norm:0.0003795131342485547 max memory_allocated 38141.64111328125 
[2025-03-16 09:59:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 3 loss:0.021067293360829353 norm:0.0003016632399521768 max memory_allocated 38141.64111328125 
[2025-03-16 10:00:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 4 loss:0.01987065188586712 norm:0.0002571702061686665 max memory_allocated 38141.64111328125 
[2025-03-16 10:01:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 5 loss:0.0191306471824646 norm:0.00022977800108492374 max memory_allocated 38141.64111328125 
[2025-03-16 10:02:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 6 loss:0.018680930137634277 norm:0.00020964677969459444 max memory_allocated 38141.64111328125 
[2025-03-16 10:03:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 7 loss:0.01840704120695591 norm:0.00020058742666151375 max memory_allocated 38141.64111328125 
[2025-03-16 10:04:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 8 loss:0.018232395872473717 norm:0.00019064528169110417 max memory_allocated 38141.64111328125 
[2025-03-16 10:05:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 9 loss:0.018059929832816124 norm:0.00018660843488760293 max memory_allocated 38141.64111328125 
[2025-03-16 10:06:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 10 loss:0.017965540289878845 norm:0.00018101348541676998 max memory_allocated 38141.64111328125 
[2025-03-16 10:07:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 11 loss:0.01789085566997528 norm:0.00017749906692188233 max memory_allocated 38141.64111328125 
[2025-03-16 10:08:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 12 loss:0.01781241036951542 norm:0.0001727624039631337 max memory_allocated 38141.64111328125 
[2025-03-16 10:09:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 13 loss:0.017738373950123787 norm:0.00016984899411909282 max memory_allocated 38141.64111328125 
[2025-03-16 10:10:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 14 loss:0.01766602322459221 norm:0.00017283028864767402 max memory_allocated 38141.64111328125 
[2025-03-16 10:11:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 15 loss:0.017623186111450195 norm:0.00016957016487140208 max memory_allocated 38141.64111328125 
[2025-03-16 10:12:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 16 loss:0.017593666911125183 norm:0.0001666838361416012 max memory_allocated 38141.64111328125 
[2025-03-16 10:12:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 17 loss:0.017528843134641647 norm:0.00016301669529639184 max memory_allocated 38141.64111328125 
[2025-03-16 10:13:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 18 loss:0.017492985352873802 norm:0.0001623274729354307 max memory_allocated 38141.64111328125 
[2025-03-16 10:14:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 19 loss:0.017474791035056114 norm:0.00016096796025522053 max memory_allocated 38141.64111328125 
[2025-03-16 10:15:23 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 22 to 23 ===
[2025-03-16 10:16:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 0 loss:0.05168493837118149 norm:0.41192999482154846 max memory_allocated 38141.81298828125 
[2025-03-16 10:17:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 1 loss:0.035959117114543915 norm:0.05285854637622833 max memory_allocated 38141.81298828125 
[2025-03-16 10:18:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 2 loss:0.028787467628717422 norm:0.025248130783438683 max memory_allocated 38141.81298828125 
[2025-03-16 10:19:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 3 loss:0.025842446833848953 norm:0.015581493265926838 max memory_allocated 38141.81298828125 
[2025-03-16 10:20:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 4 loss:0.02423589862883091 norm:0.012974287383258343 max memory_allocated 38141.81298828125 
[2025-03-16 10:21:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 5 loss:0.02325005829334259 norm:0.009991185739636421 max memory_allocated 38141.81298828125 
[2025-03-16 10:22:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 6 loss:0.02269355021417141 norm:0.007907070219516754 max memory_allocated 38141.81298828125 
[2025-03-16 10:23:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 7 loss:0.02226983569562435 norm:0.006930558476597071 max memory_allocated 38141.81298828125 
[2025-03-16 10:24:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 8 loss:0.021932901814579964 norm:0.00533438753336668 max memory_allocated 38141.81298828125 
[2025-03-16 10:24:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 9 loss:0.021564016118645668 norm:0.004704916849732399 max memory_allocated 38141.81298828125 
[2025-03-16 10:25:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 10 loss:0.021333251148462296 norm:0.003981289453804493 max memory_allocated 38141.81298828125 
[2025-03-16 10:26:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 11 loss:0.021239668130874634 norm:0.003975306171923876 max memory_allocated 38141.81298828125 
[2025-03-16 10:27:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 12 loss:0.02108869142830372 norm:0.003451436758041382 max memory_allocated 38141.81298828125 
[2025-03-16 10:28:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 13 loss:0.02100292593240738 norm:0.0031870875973254442 max memory_allocated 38141.81298828125 
[2025-03-16 10:29:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 14 loss:0.020832225680351257 norm:0.0025734086520969868 max memory_allocated 38141.81298828125 
[2025-03-16 10:30:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 15 loss:0.02081838808953762 norm:0.0028680474497377872 max memory_allocated 38141.81298828125 
[2025-03-16 10:31:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 16 loss:0.02067732624709606 norm:0.0021669710986316204 max memory_allocated 38141.81298828125 
[2025-03-16 10:32:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 17 loss:0.020584799349308014 norm:0.002118946984410286 max memory_allocated 38141.81298828125 
[2025-03-16 10:33:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 18 loss:0.020537875592708588 norm:0.0019012345001101494 max memory_allocated 38141.81298828125 
[2025-03-16 10:34:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 19 loss:0.0204600989818573 norm:0.0018347103614360094 max memory_allocated 38141.81298828125 
[2025-03-16 10:34:56 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 23 to 24 ===
[2025-03-16 10:35:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 0 loss:0.041347332298755646 norm:0.007094946689903736 max memory_allocated 38141.98486328125 
[2025-03-16 10:36:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 1 loss:0.03256414085626602 norm:0.0011052069021388888 max memory_allocated 38141.98486328125 
[2025-03-16 10:37:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 2 loss:0.026860227808356285 norm:0.0006259982474148273 max memory_allocated 38141.98486328125 
[2025-03-16 10:38:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 3 loss:0.024618200957775116 norm:0.0004639100225176662 max memory_allocated 38141.98486328125 
[2025-03-16 10:39:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 4 loss:0.023290012031793594 norm:0.0003655828186310828 max memory_allocated 38141.98486328125 
[2025-03-16 10:40:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 5 loss:0.022601628676056862 norm:0.0003031392698176205 max memory_allocated 38141.98486328125 
[2025-03-16 10:41:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 6 loss:0.02226698398590088 norm:0.0002669570967555046 max memory_allocated 38141.98486328125 
[2025-03-16 10:42:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 7 loss:0.022046126425266266 norm:0.00024261164071504027 max memory_allocated 38141.98486328125 
[2025-03-16 10:43:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 8 loss:0.021897071972489357 norm:0.00022689063916914165 max memory_allocated 38141.98486328125 
[2025-03-16 10:44:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 9 loss:0.021780822426080704 norm:0.00021540909074246883 max memory_allocated 38141.98486328125 
[2025-03-16 10:45:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 10 loss:0.021659065037965775 norm:0.00020734392455779016 max memory_allocated 38141.98486328125 
[2025-03-16 10:46:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 11 loss:0.02157232165336609 norm:0.000205360003747046 max memory_allocated 38141.98486328125 
[2025-03-16 10:47:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 12 loss:0.021492846310138702 norm:0.00019974161114078015 max memory_allocated 38141.98486328125 
[2025-03-16 10:48:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 13 loss:0.021422576159238815 norm:0.00019594779587350786 max memory_allocated 38141.98486328125 
[2025-03-16 10:49:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 14 loss:0.021380024030804634 norm:0.00019447198428679258 max memory_allocated 38141.98486328125 
[2025-03-16 10:50:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 15 loss:0.021318739280104637 norm:0.00018552971596363932 max memory_allocated 38141.98486328125 
[2025-03-16 10:51:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 16 loss:0.021271519362926483 norm:0.00018170458497479558 max memory_allocated 38141.98486328125 
[2025-03-16 10:52:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 17 loss:0.021227488294243813 norm:0.00018026951875071973 max memory_allocated 38141.98486328125 
[2025-03-16 10:53:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 18 loss:0.021195752546191216 norm:0.00018089532386511564 max memory_allocated 38141.98486328125 
[2025-03-16 10:53:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 19 loss:0.021178051829338074 norm:0.0001799363672034815 max memory_allocated 38141.98486328125 
[2025-03-16 10:54:30 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 24 to 25 ===
[2025-03-16 10:55:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 0 loss:0.04674211144447327 norm:0.0013200185494497418 max memory_allocated 38142.15673828125 
[2025-03-16 10:56:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 1 loss:0.03498447313904762 norm:0.0006787382299080491 max memory_allocated 38142.15673828125 
[2025-03-16 10:57:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 2 loss:0.027976734563708305 norm:0.00044972484465688467 max memory_allocated 38142.15673828125 
[2025-03-16 10:58:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 3 loss:0.02545599825680256 norm:0.0003575839218683541 max memory_allocated 38142.15673828125 
[2025-03-16 10:59:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 4 loss:0.024089265614748 norm:0.0003046214987989515 max memory_allocated 38142.15673828125 
[2025-03-16 11:00:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 5 loss:0.023369640111923218 norm:0.0002687346423044801 max memory_allocated 38142.15673828125 
[2025-03-16 11:01:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 6 loss:0.023013733327388763 norm:0.00024423940340057015 max memory_allocated 38142.15673828125 
[2025-03-16 11:02:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 7 loss:0.022791285067796707 norm:0.00023248032084666193 max memory_allocated 38142.15673828125 
[2025-03-16 11:03:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 8 loss:0.022624649107456207 norm:0.0002253921120427549 max memory_allocated 38142.15673828125 
[2025-03-16 11:04:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 9 loss:0.022520441561937332 norm:0.00022787028865423054 max memory_allocated 38142.15673828125 
[2025-03-16 11:05:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 10 loss:0.02241242304444313 norm:0.00022199870727490634 max memory_allocated 38142.15673828125 
[2025-03-16 11:05:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 11 loss:0.022312723100185394 norm:0.00021080279839225113 max memory_allocated 38142.15673828125 
[2025-03-16 11:06:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 12 loss:0.022237196564674377 norm:0.00020780447812285274 max memory_allocated 38142.15673828125 
[2025-03-16 11:07:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 13 loss:0.022181011736392975 norm:0.0002078001998597756 max memory_allocated 38142.15673828125 
[2025-03-16 11:08:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 14 loss:0.02215208113193512 norm:0.00020549734472297132 max memory_allocated 38142.15673828125 
[2025-03-16 11:09:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 15 loss:0.022100167348980904 norm:0.00020167636102996767 max memory_allocated 38142.15673828125 
[2025-03-16 11:10:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 16 loss:0.022093379870057106 norm:0.00020389180281199515 max memory_allocated 38142.15673828125 
[2025-03-16 11:11:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 17 loss:0.0220306608825922 norm:0.00020210984803270549 max memory_allocated 38142.15673828125 
[2025-03-16 11:12:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 18 loss:0.022010520100593567 norm:0.00019698248070199043 max memory_allocated 38142.15673828125 
[2025-03-16 11:13:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 19 loss:0.021988242864608765 norm:0.00019359635189175606 max memory_allocated 38142.15673828125 
[2025-03-16 11:14:04 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 25 to 26 ===
[2025-03-16 11:15:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 0 loss:0.05402268096804619 norm:0.0021110535599291325 max memory_allocated 38142.32861328125 
[2025-03-16 11:16:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 1 loss:0.039279744029045105 norm:0.0009619033662602305 max memory_allocated 38142.32861328125 
[2025-03-16 11:17:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 2 loss:0.03154200688004494 norm:0.0005974621744826436 max memory_allocated 38142.32861328125 
[2025-03-16 11:17:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 3 loss:0.028531057760119438 norm:0.00044861939386464655 max memory_allocated 38142.32861328125 
[2025-03-16 11:18:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 4 loss:0.02701890841126442 norm:0.000366554333595559 max memory_allocated 38142.32861328125 
[2025-03-16 11:19:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 5 loss:0.026322312653064728 norm:0.0003113336570095271 max memory_allocated 38142.32861328125 
[2025-03-16 11:20:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 6 loss:0.025973722338676453 norm:0.00028081241180188954 max memory_allocated 38142.32861328125 
[2025-03-16 11:21:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 7 loss:0.02574044093489647 norm:0.0002589375071693212 max memory_allocated 38142.32861328125 
[2025-03-16 11:22:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 8 loss:0.025568194687366486 norm:0.0002480796829331666 max memory_allocated 38142.32861328125 
[2025-03-16 11:23:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 9 loss:0.025409197434782982 norm:0.00023863627575337887 max memory_allocated 38142.32861328125 
[2025-03-16 11:24:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 10 loss:0.02527674287557602 norm:0.00023047617287375033 max memory_allocated 38142.32861328125 
[2025-03-16 11:25:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 11 loss:0.025185588747262955 norm:0.000227750904741697 max memory_allocated 38142.32861328125 
[2025-03-16 11:26:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 12 loss:0.025104662403464317 norm:0.00022453539713751525 max memory_allocated 38142.32861328125 
[2025-03-16 11:27:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 13 loss:0.025025300681591034 norm:0.00021559353626798838 max memory_allocated 38142.32861328125 
[2025-03-16 11:28:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 14 loss:0.02496880479156971 norm:0.0002167336642742157 max memory_allocated 38142.32861328125 
[2025-03-16 11:29:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 15 loss:0.02492392808198929 norm:0.00021272082813084126 max memory_allocated 38142.32861328125 
[2025-03-16 11:30:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 16 loss:0.024902474135160446 norm:0.00020845238759648055 max memory_allocated 38142.32861328125 
[2025-03-16 11:31:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 17 loss:0.024848807603120804 norm:0.0002098311815643683 max memory_allocated 38142.32861328125 
[2025-03-16 11:32:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 18 loss:0.02482624351978302 norm:0.00021070271031931043 max memory_allocated 38142.32861328125 
[2025-03-16 11:33:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 19 loss:0.02482331544160843 norm:0.0002100600686389953 max memory_allocated 38142.32861328125 
[2025-03-16 11:33:37 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 26 to 27 ===
[2025-03-16 11:34:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 0 loss:0.06602521240711212 norm:0.003991550300270319 max memory_allocated 38142.50048828125 
[2025-03-16 11:35:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 1 loss:0.046521831303834915 norm:0.0016869790852069855 max memory_allocated 38142.50048828125 
[2025-03-16 11:36:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 2 loss:0.03719060495495796 norm:0.0010936780599877238 max memory_allocated 38142.50048828125 
[2025-03-16 11:37:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 3 loss:0.03327056020498276 norm:0.0007603070116601884 max memory_allocated 38142.50048828125 
[2025-03-16 11:38:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 4 loss:0.03145739808678627 norm:0.000615743629168719 max memory_allocated 38142.50048828125 
[2025-03-16 11:39:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 5 loss:0.03065148927271366 norm:0.0005261429469101131 max memory_allocated 38142.50048828125 
[2025-03-16 11:40:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 6 loss:0.030166588723659515 norm:0.0004579983069561422 max memory_allocated 38142.50048828125 
[2025-03-16 11:41:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 7 loss:0.02987106703221798 norm:0.0004154751368332654 max memory_allocated 38142.50048828125 
[2025-03-16 11:42:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 8 loss:0.029614942148327827 norm:0.00037354888627305627 max memory_allocated 38142.50048828125 
[2025-03-16 11:43:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 9 loss:0.029431208968162537 norm:0.0003471839299891144 max memory_allocated 38142.50048828125 
[2025-03-16 11:44:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 10 loss:0.02928970754146576 norm:0.00032454420579597354 max memory_allocated 38142.50048828125 
[2025-03-16 11:45:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 11 loss:0.029164116829633713 norm:0.00031134652090258896 max memory_allocated 38142.50048828125 
[2025-03-16 11:46:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 12 loss:0.029033252969384193 norm:0.0002959970443043858 max memory_allocated 38142.50048828125 
[2025-03-16 11:46:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 13 loss:0.02898474596440792 norm:0.0002800985239446163 max memory_allocated 38142.50048828125 
[2025-03-16 11:47:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 14 loss:0.028904493898153305 norm:0.0002715569280553609 max memory_allocated 38142.50048828125 
[2025-03-16 11:48:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 15 loss:0.028819553554058075 norm:0.000263441150309518 max memory_allocated 38142.50048828125 
[2025-03-16 11:49:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 16 loss:0.028768867254257202 norm:0.00025259683025069535 max memory_allocated 38142.50048828125 
[2025-03-16 11:50:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 17 loss:0.02869294211268425 norm:0.0002518839610274881 max memory_allocated 38142.50048828125 
[2025-03-16 11:51:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 18 loss:0.028670724481344223 norm:0.00024535899865441024 max memory_allocated 38142.50048828125 
[2025-03-16 11:52:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 19 loss:0.028651997447013855 norm:0.00024305176339112222 max memory_allocated 38142.50048828125 
[2025-03-16 11:53:10 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 27 to 28 ===
[2025-03-16 11:54:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 0 loss:0.07202338427305222 norm:0.22956588864326477 max memory_allocated 38142.84521484375 
[2025-03-16 11:55:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 1 loss:0.053306616842746735 norm:0.02582927793264389 max memory_allocated 38142.84521484375 
[2025-03-16 11:56:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 2 loss:0.042772579938173294 norm:0.018150141462683678 max memory_allocated 38142.84521484375 
[2025-03-16 11:57:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 3 loss:0.038485340774059296 norm:0.014340521767735481 max memory_allocated 38142.84521484375 
[2025-03-16 11:58:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 4 loss:0.036469243466854095 norm:0.01095345988869667 max memory_allocated 38142.84521484375 
[2025-03-16 11:58:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 5 loss:0.03525537624955177 norm:0.008014777675271034 max memory_allocated 38142.84521484375 
[2025-03-16 11:59:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 6 loss:0.03464600816369057 norm:0.006980394944548607 max memory_allocated 38142.84521484375 
[2025-03-16 12:00:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 7 loss:0.0340728722512722 norm:0.006222737953066826 max memory_allocated 38142.84521484375 
[2025-03-16 12:01:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 8 loss:0.03378812596201897 norm:0.00589678343385458 max memory_allocated 38142.84521484375 
[2025-03-16 12:02:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 9 loss:0.033558789640665054 norm:0.005320881027728319 max memory_allocated 38142.84521484375 
[2025-03-16 12:03:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 10 loss:0.0334271639585495 norm:0.005027143284678459 max memory_allocated 38142.84521484375 
[2025-03-16 12:04:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 11 loss:0.03314767777919769 norm:0.004472810309380293 max memory_allocated 38142.84521484375 
[2025-03-16 12:05:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 12 loss:0.03298978880047798 norm:0.004351204261183739 max memory_allocated 38142.84521484375 
[2025-03-16 12:06:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 13 loss:0.03286585584282875 norm:0.0041515217162668705 max memory_allocated 38142.84521484375 
[2025-03-16 12:07:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 14 loss:0.032682470977306366 norm:0.0034790709614753723 max memory_allocated 38142.84521484375 
[2025-03-16 12:08:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 15 loss:0.032532185316085815 norm:0.003416574327275157 max memory_allocated 38142.84521484375 
[2025-03-16 12:09:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 16 loss:0.03250623121857643 norm:0.003422321053221822 max memory_allocated 38142.84521484375 
[2025-03-16 12:10:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 17 loss:0.03240235894918442 norm:0.0031986073590815067 max memory_allocated 38142.84521484375 
[2025-03-16 12:11:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 18 loss:0.03235235437750816 norm:0.0031099466141313314 max memory_allocated 38142.84521484375 
[2025-03-16 12:12:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 19 loss:0.03220304846763611 norm:0.002750951796770096 max memory_allocated 38142.84521484375 
[2025-03-16 12:12:45 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 28 to 29 ===
[2025-03-16 12:13:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 0 loss:0.09211967140436172 norm:0.012566637247800827 max memory_allocated 38143.18994140625 
[2025-03-16 12:14:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 1 loss:0.06844006478786469 norm:0.009252223186194897 max memory_allocated 38143.18994140625 
[2025-03-16 12:15:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 2 loss:0.055204279720783234 norm:0.006285454146564007 max memory_allocated 38143.18994140625 
[2025-03-16 12:16:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 3 loss:0.04985512048006058 norm:0.004476604983210564 max memory_allocated 38143.18994140625 
[2025-03-16 12:17:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 4 loss:0.046838730573654175 norm:0.0031141135841608047 max memory_allocated 38143.18994140625 
[2025-03-16 12:18:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 5 loss:0.04496006667613983 norm:0.0030828402377665043 max memory_allocated 38143.18994140625 
[2025-03-16 12:19:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 6 loss:0.04394949972629547 norm:0.0032485758420079947 max memory_allocated 38143.18994140625 
[2025-03-16 12:20:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 7 loss:0.0434081070125103 norm:0.0032489255536347628 max memory_allocated 38143.18994140625 
[2025-03-16 12:21:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 8 loss:0.0429614894092083 norm:0.003061597002670169 max memory_allocated 38143.18994140625 
[2025-03-16 12:22:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 9 loss:0.0426926463842392 norm:0.002989257453009486 max memory_allocated 38143.18994140625 
[2025-03-16 12:23:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 10 loss:0.04251106083393097 norm:0.002854570047929883 max memory_allocated 38143.18994140625 
[2025-03-16 12:24:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 11 loss:0.042432837188243866 norm:0.0028554960153996944 max memory_allocated 38143.18994140625 
[2025-03-16 12:25:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 12 loss:0.04230004921555519 norm:0.002658367622643709 max memory_allocated 38143.18994140625 
[2025-03-16 12:26:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 13 loss:0.04221943020820618 norm:0.0026631990913301706 max memory_allocated 38143.18994140625 
[2025-03-16 12:27:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 14 loss:0.04220087453722954 norm:0.00258212024345994 max memory_allocated 38143.18994140625 
[2025-03-16 12:28:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 15 loss:0.04211973026394844 norm:0.0024528049398213625 max memory_allocated 38143.18994140625 
[2025-03-16 12:29:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 16 loss:0.04204845800995827 norm:0.002457410329952836 max memory_allocated 38143.18994140625 
[2025-03-16 12:29:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 17 loss:0.0420854426920414 norm:0.002648378489539027 max memory_allocated 38143.18994140625 
[2025-03-16 12:30:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 18 loss:0.04202020913362503 norm:0.0024145946372300386 max memory_allocated 38143.18994140625 
[2025-03-16 12:31:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 19 loss:0.04197606071829796 norm:0.0022514343727380037 max memory_allocated 38143.18994140625 
[2025-03-16 12:32:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 29 to 30 ===
[2025-03-16 12:32:28 root] (abq_llm_calib_config3_cbq.py 431): INFO Loss is NAN, stopping training
