[2025-03-16 15:00:36 root] (main_calib_config3_cbq.py 280): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-divide-adaptive-calibration-cbq/Llama-2-7b-hf-0.4', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=15, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.4.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-16 15:00:43 root] (main_calib_config3_cbq.py 347): INFO === start quantization ===
[2025-03-16 15:00:43 root] (main_calib_config3_cbq.py 353): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-16 15:00:43 root] (abq_llm_calib_config3_cbq.py 82): INFO Starting ...
[2025-03-16 15:00:43 root] (abq_llm_calib_config3_cbq.py 89): INFO Loaded quant_map from log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.4.pkl
[2025-03-16 15:00:47 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 0 to 1 ===
[2025-03-16 15:01:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 0 loss:0.24648292362689972 norm:0.5575532913208008 max memory_allocated 38105.85986328125 
[2025-03-16 15:02:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 1 loss:0.13415084779262543 norm:0.17575779557228088 max memory_allocated 38105.85986328125 
[2025-03-16 15:03:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 2 loss:0.10874669253826141 norm:0.13989952206611633 max memory_allocated 38105.85986328125 
[2025-03-16 15:04:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 3 loss:0.4490087628364563 norm:1.0142968893051147 max memory_allocated 38105.85986328125 
[2025-03-16 15:05:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 4 loss:0.13636520504951477 norm:0.25398096442222595 max memory_allocated 38105.85986328125 
[2025-03-16 15:06:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 5 loss:0.10776856541633606 norm:0.10958552360534668 max memory_allocated 38105.85986328125 
[2025-03-16 15:07:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 6 loss:0.0890517309308052 norm:0.06811532378196716 max memory_allocated 38105.85986328125 
[2025-03-16 15:08:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 7 loss:0.08404826372861862 norm:0.05414779484272003 max memory_allocated 38105.85986328125 
[2025-03-16 15:09:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 8 loss:0.08641868829727173 norm:0.0736243724822998 max memory_allocated 38105.85986328125 
[2025-03-16 15:10:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 9 loss:0.0837697833776474 norm:0.06404649466276169 max memory_allocated 38105.85986328125 
[2025-03-16 15:11:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 10 loss:0.08594236522912979 norm:0.08083523064851761 max memory_allocated 38105.85986328125 
[2025-03-16 15:12:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 11 loss:0.0805073231458664 norm:0.05482640489935875 max memory_allocated 38105.85986328125 
[2025-03-16 15:13:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 12 loss:0.08249976485967636 norm:0.07350059598684311 max memory_allocated 38105.85986328125 
[2025-03-16 15:14:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 13 loss:0.08252508193254471 norm:0.07090912759304047 max memory_allocated 38105.85986328125 
[2025-03-16 15:15:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 14 loss:0.07996205985546112 norm:0.06285467743873596 max memory_allocated 38105.85986328125 
[2025-03-16 15:15:38 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 1 to 2 ===
[2025-03-16 15:16:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 0 loss:0.5728709697723389 norm:0.3430272042751312 max memory_allocated 38138.54931640625 
[2025-03-16 15:17:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 1 loss:0.3141126036643982 norm:0.18475845456123352 max memory_allocated 38138.54931640625 
[2025-03-16 15:18:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 2 loss:0.2143786996603012 norm:0.10325521975755692 max memory_allocated 38138.54931640625 
[2025-03-16 15:19:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 3 loss:0.17719075083732605 norm:0.0730271115899086 max memory_allocated 38138.54931640625 
[2025-03-16 15:20:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 4 loss:0.15498371422290802 norm:0.06075598672032356 max memory_allocated 38138.54931640625 
[2025-03-16 15:21:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 5 loss:0.1485668569803238 norm:0.056782957166433334 max memory_allocated 38138.54931640625 
[2025-03-16 15:22:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 6 loss:0.13620218634605408 norm:0.05227569118142128 max memory_allocated 38138.54931640625 
[2025-03-16 15:23:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 7 loss:0.12402574717998505 norm:0.041516974568367004 max memory_allocated 38138.54931640625 
[2025-03-16 15:24:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 8 loss:0.11858285963535309 norm:0.03997606784105301 max memory_allocated 38138.54931640625 
[2025-03-16 15:25:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 9 loss:0.11295069009065628 norm:0.040076471865177155 max memory_allocated 38138.54931640625 
[2025-03-16 15:26:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 10 loss:0.10645356774330139 norm:0.03925558924674988 max memory_allocated 38138.54931640625 
[2025-03-16 15:27:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 11 loss:0.10070197284221649 norm:0.03714615851640701 max memory_allocated 38138.54931640625 
[2025-03-16 15:28:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 12 loss:0.0998070240020752 norm:0.04121370241045952 max memory_allocated 38138.54931640625 
[2025-03-16 15:29:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 13 loss:0.09572330117225647 norm:0.03503336384892464 max memory_allocated 38138.54931640625 
[2025-03-16 15:30:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 14 loss:0.09366308152675629 norm:0.03225356340408325 max memory_allocated 38138.54931640625 
[2025-03-16 15:30:31 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 2 to 3 ===
[2025-03-16 15:31:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 0 loss:0.06248623877763748 norm:0.019739802926778793 max memory_allocated 38138.54931640625 
[2025-03-16 15:32:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 1 loss:0.039326976984739304 norm:0.00997251272201538 max memory_allocated 38138.54931640625 
[2025-03-16 15:33:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 2 loss:0.031293485313653946 norm:0.006396986078470945 max memory_allocated 38138.54931640625 
[2025-03-16 15:34:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 3 loss:0.027387071400880814 norm:0.004900805652141571 max memory_allocated 38138.54931640625 
[2025-03-16 15:35:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 4 loss:0.025269296020269394 norm:0.004384811036288738 max memory_allocated 38138.54931640625 
[2025-03-16 15:36:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 5 loss:0.023817121982574463 norm:0.0037954221479594707 max memory_allocated 38138.54931640625 
[2025-03-16 15:37:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 6 loss:0.02275017276406288 norm:0.003288647625595331 max memory_allocated 38138.54931640625 
[2025-03-16 15:38:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 7 loss:0.022018026560544968 norm:0.0030752967577427626 max memory_allocated 38138.54931640625 
[2025-03-16 15:39:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 8 loss:0.021602746099233627 norm:0.002814254956319928 max memory_allocated 38138.54931640625 
[2025-03-16 15:40:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 9 loss:0.021305112168192863 norm:0.0027139538433402777 max memory_allocated 38138.54931640625 
[2025-03-16 15:41:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 10 loss:0.0210222490131855 norm:0.0023743147030472755 max memory_allocated 38138.54931640625 
[2025-03-16 15:42:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 11 loss:0.020836737006902695 norm:0.002003746572881937 max memory_allocated 38138.54931640625 
[2025-03-16 15:42:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 12 loss:0.020632250234484673 norm:0.0018866828177124262 max memory_allocated 38138.54931640625 
[2025-03-16 15:43:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 13 loss:0.020596051588654518 norm:0.0019348340574651957 max memory_allocated 38138.54931640625 
[2025-03-16 15:44:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 14 loss:0.020446425303816795 norm:0.001804456696845591 max memory_allocated 38138.54931640625 
[2025-03-16 15:45:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 3 to 4 ===
[2025-03-16 15:46:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 0 loss:0.07054439187049866 norm:0.05100981146097183 max memory_allocated 38138.54931640625 
[2025-03-16 15:47:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 1 loss:0.04534288868308067 norm:0.010505741462111473 max memory_allocated 38138.54931640625 
[2025-03-16 15:48:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 2 loss:0.03056320548057556 norm:0.005686257034540176 max memory_allocated 38138.54931640625 
[2025-03-16 15:49:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 3 loss:0.02504684031009674 norm:0.003880799515172839 max memory_allocated 38138.54931640625 
[2025-03-16 15:50:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 4 loss:0.022257713600993156 norm:0.0027912070509046316 max memory_allocated 38138.54931640625 
[2025-03-16 15:51:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 5 loss:0.0204815324395895 norm:0.00214180676266551 max memory_allocated 38138.54931640625 
[2025-03-16 15:52:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 6 loss:0.01930401287972927 norm:0.0017168814083561301 max memory_allocated 38138.54931640625 
[2025-03-16 15:53:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 7 loss:0.018430892378091812 norm:0.0014127143658697605 max memory_allocated 38138.54931640625 
[2025-03-16 15:54:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 8 loss:0.01792275719344616 norm:0.001190009992569685 max memory_allocated 38138.54931640625 
[2025-03-16 15:54:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 9 loss:0.01749422773718834 norm:0.001041537499986589 max memory_allocated 38138.54931640625 
[2025-03-16 15:55:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 10 loss:0.017179841175675392 norm:0.0009262984967790544 max memory_allocated 38138.54931640625 
[2025-03-16 15:56:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 11 loss:0.016924934461712837 norm:0.0008246767683885992 max memory_allocated 38138.54931640625 
[2025-03-16 15:57:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 12 loss:0.01675768382847309 norm:0.0007723551825620234 max memory_allocated 38138.54931640625 
[2025-03-16 15:58:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 13 loss:0.016564082354307175 norm:0.00069304188946262 max memory_allocated 38138.54931640625 
[2025-03-16 15:59:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 14 loss:0.016379568725824356 norm:0.000648021581582725 max memory_allocated 38138.54931640625 
[2025-03-16 16:00:13 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 4 to 5 ===
[2025-03-16 16:01:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 0 loss:0.05679416283965111 norm:0.01262133102864027 max memory_allocated 38138.71923828125 
[2025-03-16 16:02:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 1 loss:0.027985401451587677 norm:0.0032469036523252726 max memory_allocated 38138.71923828125 
[2025-03-16 16:03:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 2 loss:0.02076433040201664 norm:0.002051416551694274 max memory_allocated 38138.71923828125 
[2025-03-16 16:04:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 3 loss:0.017061535269021988 norm:0.0015005222521722317 max memory_allocated 38138.71923828125 
[2025-03-16 16:05:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 4 loss:0.014975029043853283 norm:0.0018735985504463315 max memory_allocated 38138.71923828125 
[2025-03-16 16:05:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 5 loss:0.013789585791528225 norm:0.0009480691514909267 max memory_allocated 38138.71923828125 
[2025-03-16 16:06:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 6 loss:0.012968309223651886 norm:0.0007787740905769169 max memory_allocated 38138.71923828125 
[2025-03-16 16:07:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 7 loss:0.012442212551832199 norm:0.000663317390717566 max memory_allocated 38138.71923828125 
[2025-03-16 16:08:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 8 loss:0.012018762528896332 norm:0.000616811215877533 max memory_allocated 38138.71923828125 
[2025-03-16 16:09:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 9 loss:0.011711154133081436 norm:0.0005484222783707082 max memory_allocated 38138.71923828125 
[2025-03-16 16:10:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 10 loss:0.011485110968351364 norm:0.0004767213831655681 max memory_allocated 38138.71923828125 
[2025-03-16 16:11:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 11 loss:0.011329769156873226 norm:0.0004581137327477336 max memory_allocated 38138.71923828125 
[2025-03-16 16:12:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 12 loss:0.011211313307285309 norm:0.00042854249477386475 max memory_allocated 38138.71923828125 
[2025-03-16 16:13:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 13 loss:0.011051751673221588 norm:0.00038123305421322584 max memory_allocated 38138.71923828125 
[2025-03-16 16:14:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 14 loss:0.010935832746326923 norm:0.00037715036887675524 max memory_allocated 38138.71923828125 
[2025-03-16 16:15:03 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 5 to 6 ===
[2025-03-16 16:16:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 0 loss:0.07192796468734741 norm:0.12773431837558746 max memory_allocated 38138.89111328125 
[2025-03-16 16:17:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 1 loss:0.03319438174366951 norm:0.00945519469678402 max memory_allocated 38138.89111328125 
[2025-03-16 16:17:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 2 loss:0.02500113844871521 norm:0.006515912711620331 max memory_allocated 38138.89111328125 
[2025-03-16 16:18:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 3 loss:0.020841075107455254 norm:0.00451630586758256 max memory_allocated 38138.89111328125 
[2025-03-16 16:19:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 4 loss:0.01842486672103405 norm:0.0032315412536263466 max memory_allocated 38138.89111328125 
[2025-03-16 16:20:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 5 loss:0.01666042022407055 norm:0.0023696795105934143 max memory_allocated 38138.89111328125 
[2025-03-16 16:21:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 6 loss:0.015546253882348537 norm:0.002030245028436184 max memory_allocated 38138.89111328125 
[2025-03-16 16:22:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 7 loss:0.01471012458205223 norm:0.0016568235587328672 max memory_allocated 38138.89111328125 
[2025-03-16 16:23:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 8 loss:0.013983896002173424 norm:0.0014598950510844588 max memory_allocated 38138.89111328125 
[2025-03-16 16:24:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 9 loss:0.01349801104515791 norm:0.0012967120856046677 max memory_allocated 38138.89111328125 
[2025-03-16 16:25:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 10 loss:0.013102758675813675 norm:0.0011106267338618636 max memory_allocated 38138.89111328125 
[2025-03-16 16:26:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 11 loss:0.01276085339486599 norm:0.0009710968006402254 max memory_allocated 38138.89111328125 
[2025-03-16 16:27:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 12 loss:0.012447735294699669 norm:0.0009152408456429839 max memory_allocated 38138.89111328125 
[2025-03-16 16:28:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 13 loss:0.012218947522342205 norm:0.0008615666883997619 max memory_allocated 38138.89111328125 
[2025-03-16 16:29:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 14 loss:0.012032493017613888 norm:0.000818504486232996 max memory_allocated 38138.89111328125 
[2025-03-16 16:29:54 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 6 to 7 ===
[2025-03-16 16:30:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 0 loss:0.054896287620067596 norm:0.012805580161511898 max memory_allocated 38139.06298828125 
[2025-03-16 16:31:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 1 loss:0.036551136523485184 norm:0.010352369397878647 max memory_allocated 38139.06298828125 
[2025-03-16 16:32:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 2 loss:0.029103411361575127 norm:0.004027295857667923 max memory_allocated 38139.06298828125 
[2025-03-16 16:33:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 3 loss:0.024627622216939926 norm:0.0029791458509862423 max memory_allocated 38139.06298828125 
[2025-03-16 16:34:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 4 loss:0.021833807229995728 norm:0.0023512800689786673 max memory_allocated 38139.06298828125 
[2025-03-16 16:35:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 5 loss:0.019906172528862953 norm:0.0018858074909076095 max memory_allocated 38139.06298828125 
[2025-03-16 16:36:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 6 loss:0.018589891493320465 norm:0.0015829810872673988 max memory_allocated 38139.06298828125 
[2025-03-16 16:37:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 7 loss:0.017557594925165176 norm:0.0013445279328152537 max memory_allocated 38139.06298828125 
[2025-03-16 16:38:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 8 loss:0.01669624075293541 norm:0.0011475429637357593 max memory_allocated 38139.06298828125 
[2025-03-16 16:39:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 9 loss:0.016029341146349907 norm:0.001020092167891562 max memory_allocated 38139.06298828125 
[2025-03-16 16:40:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 10 loss:0.015513220801949501 norm:0.000917850062251091 max memory_allocated 38139.06298828125 
[2025-03-16 16:41:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 11 loss:0.015020390972495079 norm:0.0008329728152602911 max memory_allocated 38139.06298828125 
[2025-03-16 16:42:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 12 loss:0.014630092307925224 norm:0.0007553974282927811 max memory_allocated 38139.06298828125 
[2025-03-16 16:43:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 13 loss:0.014283739030361176 norm:0.0006792146596126258 max memory_allocated 38139.06298828125 
[2025-03-16 16:44:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 14 loss:0.013954896479845047 norm:0.0006296145729720592 max memory_allocated 38139.06298828125 
[2025-03-16 16:44:44 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 7 to 8 ===
[2025-03-16 16:45:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 0 loss:0.07146817445755005 norm:0.015626121312379837 max memory_allocated 38139.23486328125 
[2025-03-16 16:46:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 1 loss:0.03521887958049774 norm:0.004091136157512665 max memory_allocated 38139.23486328125 
[2025-03-16 16:47:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 2 loss:0.026599017903208733 norm:0.0024783164262771606 max memory_allocated 38139.23486328125 
[2025-03-16 16:48:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 3 loss:0.0224770437926054 norm:0.0016662055859342217 max memory_allocated 38139.23486328125 
[2025-03-16 16:49:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 4 loss:0.019816916435956955 norm:0.001041456125676632 max memory_allocated 38139.23486328125 
[2025-03-16 16:50:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 5 loss:0.017886392772197723 norm:0.0008614056278020144 max memory_allocated 38139.23486328125 
[2025-03-16 16:51:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 6 loss:0.016996487975120544 norm:0.0008491554181091487 max memory_allocated 38139.23486328125 
[2025-03-16 16:52:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 7 loss:0.017025038599967957 norm:0.0009549461537972093 max memory_allocated 38139.23486328125 
[2025-03-16 16:53:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 8 loss:0.015688516199588776 norm:0.0006417022086679935 max memory_allocated 38139.23486328125 
[2025-03-16 16:54:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 9 loss:0.014761250466108322 norm:0.0005554872332140803 max memory_allocated 38139.23486328125 
[2025-03-16 16:55:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 10 loss:0.014275708235800266 norm:0.0005599193973466754 max memory_allocated 38139.23486328125 
[2025-03-16 16:56:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 11 loss:0.0138500165194273 norm:0.0005221688188612461 max memory_allocated 38139.23486328125 
[2025-03-16 16:57:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 12 loss:0.013536416925489902 norm:0.000494971580337733 max memory_allocated 38139.23486328125 
[2025-03-16 16:58:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 13 loss:0.01329122669994831 norm:0.00046913191908970475 max memory_allocated 38139.23486328125 
[2025-03-16 16:59:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 14 loss:0.013171695172786713 norm:0.00048610809608362615 max memory_allocated 38139.23486328125 
[2025-03-16 16:59:35 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 8 to 9 ===
[2025-03-16 17:00:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 0 loss:0.048732858151197433 norm:0.0082561569288373 max memory_allocated 38139.40673828125 
[2025-03-16 17:01:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 1 loss:0.0333724170923233 norm:0.004597546998411417 max memory_allocated 38139.40673828125 
[2025-03-16 17:02:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 2 loss:0.02726825140416622 norm:0.003109268844127655 max memory_allocated 38139.40673828125 
[2025-03-16 17:03:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 3 loss:0.023600898683071136 norm:0.0023914615157991648 max memory_allocated 38139.40673828125 
[2025-03-16 17:04:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 4 loss:0.021174941211938858 norm:0.0018792171031236649 max memory_allocated 38139.40673828125 
[2025-03-16 17:05:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 5 loss:0.019564857706427574 norm:0.0015599854523316026 max memory_allocated 38139.40673828125 
[2025-03-16 17:06:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 6 loss:0.018348049372434616 norm:0.001318058231845498 max memory_allocated 38139.40673828125 
[2025-03-16 17:07:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 7 loss:0.01741458848118782 norm:0.001130331656895578 max memory_allocated 38139.40673828125 
[2025-03-16 17:08:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 8 loss:0.016637157648801804 norm:0.0010111399460583925 max memory_allocated 38139.40673828125 
[2025-03-16 17:09:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 9 loss:0.015992140397429466 norm:0.0009008653578348458 max memory_allocated 38139.40673828125 
[2025-03-16 17:10:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 10 loss:0.015503283590078354 norm:0.0008084331057034433 max memory_allocated 38139.40673828125 
[2025-03-16 17:11:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 11 loss:0.015165717341005802 norm:0.0007309984648600221 max memory_allocated 38139.40673828125 
[2025-03-16 17:12:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 12 loss:0.014838232658803463 norm:0.0006651307339780033 max memory_allocated 38139.40673828125 
[2025-03-16 17:12:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 13 loss:0.01449468545615673 norm:0.0006074577104300261 max memory_allocated 38139.40673828125 
[2025-03-16 17:13:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 14 loss:0.01426054909825325 norm:0.0005775911849923432 max memory_allocated 38139.40673828125 
[2025-03-16 17:14:26 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 9 to 10 ===
[2025-03-16 17:15:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 0 loss:0.050010692328214645 norm:0.003422596026211977 max memory_allocated 38139.57861328125 
[2025-03-16 17:16:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 1 loss:0.028172478079795837 norm:0.0014241909375414252 max memory_allocated 38139.57861328125 
[2025-03-16 17:17:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 2 loss:0.022466495633125305 norm:0.000993375084362924 max memory_allocated 38139.57861328125 
[2025-03-16 17:18:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 3 loss:0.019384335726499557 norm:0.0007914857123978436 max memory_allocated 38139.57861328125 
[2025-03-16 17:19:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 4 loss:0.017361527308821678 norm:0.0006652172305621207 max memory_allocated 38139.57861328125 
[2025-03-16 17:20:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 5 loss:0.016073456034064293 norm:0.00058829749468714 max memory_allocated 38139.57861328125 
[2025-03-16 17:21:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 6 loss:0.015097684226930141 norm:0.0005185128538869321 max memory_allocated 38139.57861328125 
[2025-03-16 17:22:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 7 loss:0.014345950447022915 norm:0.00048248469829559326 max memory_allocated 38139.57861328125 
[2025-03-16 17:23:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 8 loss:0.013883057050406933 norm:0.0004592282639350742 max memory_allocated 38139.57861328125 
[2025-03-16 17:24:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 9 loss:0.013441442511975765 norm:0.000422166456701234 max memory_allocated 38139.57861328125 
[2025-03-16 17:24:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 10 loss:0.013114524073898792 norm:0.00041132085607387125 max memory_allocated 38139.57861328125 
[2025-03-16 17:25:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 11 loss:0.012887823395431042 norm:0.00038991300971247256 max memory_allocated 38139.57861328125 
[2025-03-16 17:26:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 12 loss:0.012688723392784595 norm:0.0003825482272077352 max memory_allocated 38139.57861328125 
[2025-03-16 17:27:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 13 loss:0.01250222884118557 norm:0.000374569179257378 max memory_allocated 38139.57861328125 
[2025-03-16 17:28:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 14 loss:0.012334812432527542 norm:0.0003601046628318727 max memory_allocated 38139.57861328125 
[2025-03-16 17:29:18 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 10 to 11 ===
[2025-03-16 17:30:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 0 loss:0.04994466155767441 norm:0.007691818755120039 max memory_allocated 38139.75048828125 
[2025-03-16 17:31:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 1 loss:0.03380988910794258 norm:0.004004709422588348 max memory_allocated 38139.75048828125 
[2025-03-16 17:32:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 2 loss:0.02724369801580906 norm:0.002657651901245117 max memory_allocated 38139.75048828125 
[2025-03-16 17:33:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 3 loss:0.023384232074022293 norm:0.0018888463964685798 max memory_allocated 38139.75048828125 
[2025-03-16 17:34:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 4 loss:0.02082272246479988 norm:0.0014112087665125728 max memory_allocated 38139.75048828125 
[2025-03-16 17:35:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 5 loss:0.019024481996893883 norm:0.0011983553413301706 max memory_allocated 38139.75048828125 
[2025-03-16 17:36:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 6 loss:0.017742037773132324 norm:0.0010293383384123445 max memory_allocated 38139.75048828125 
[2025-03-16 17:37:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 7 loss:0.01687304675579071 norm:0.0008858057553879917 max memory_allocated 38139.75048828125 
[2025-03-16 17:37:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 8 loss:0.01616518758237362 norm:0.0008048527524806559 max memory_allocated 38139.75048828125 
[2025-03-16 17:38:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 9 loss:0.01568785309791565 norm:0.0007231145864352584 max memory_allocated 38139.75048828125 
[2025-03-16 17:39:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 10 loss:0.015251105651259422 norm:0.0006751576438546181 max memory_allocated 38139.75048828125 
[2025-03-16 17:40:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 11 loss:0.014876553788781166 norm:0.0006172553985379636 max memory_allocated 38139.75048828125 
[2025-03-16 17:41:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 12 loss:0.014613304287195206 norm:0.0005769536946900189 max memory_allocated 38139.75048828125 
[2025-03-16 17:42:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 13 loss:0.0143122598528862 norm:0.0005416335770860314 max memory_allocated 38139.75048828125 
[2025-03-16 17:43:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 14 loss:0.014134334400296211 norm:0.0005020091193728149 max memory_allocated 38139.75048828125 
[2025-03-16 17:44:14 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 11 to 12 ===
[2025-03-16 17:45:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 0 loss:0.039452891796827316 norm:0.003739461535587907 max memory_allocated 38139.92236328125 
[2025-03-16 17:46:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 1 loss:0.02617340348660946 norm:0.0017724158242344856 max memory_allocated 38139.92236328125 
[2025-03-16 17:47:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 2 loss:0.02162664383649826 norm:0.0012413554359227419 max memory_allocated 38139.92236328125 
[2025-03-16 17:48:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 3 loss:0.018904726952314377 norm:0.0009737214422784746 max memory_allocated 38139.92236328125 
[2025-03-16 17:49:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 4 loss:0.016986781731247902 norm:0.0008137229015119374 max memory_allocated 38139.92236328125 
[2025-03-16 17:50:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 5 loss:0.0158389899879694 norm:0.0007075225003063679 max memory_allocated 38139.92236328125 
[2025-03-16 17:51:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 6 loss:0.014891576953232288 norm:0.000626654364168644 max memory_allocated 38139.92236328125 
[2025-03-16 17:52:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 7 loss:0.014219188131392002 norm:0.0005580776487477124 max memory_allocated 38139.92236328125 
[2025-03-16 17:52:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 8 loss:0.013706417754292488 norm:0.000517965410836041 max memory_allocated 38139.92236328125 
[2025-03-16 17:53:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 9 loss:0.013303163461387157 norm:0.00048340726061724126 max memory_allocated 38139.92236328125 
[2025-03-16 17:54:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 10 loss:0.012950221076607704 norm:0.0004574035992845893 max memory_allocated 38139.92236328125 
[2025-03-16 17:55:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 11 loss:0.01267253514379263 norm:0.00043021427700296044 max memory_allocated 38139.92236328125 
[2025-03-16 17:56:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 12 loss:0.012492594309151173 norm:0.0004117249045521021 max memory_allocated 38139.92236328125 
[2025-03-16 17:57:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 13 loss:0.012340608984231949 norm:0.00039061359711922705 max memory_allocated 38139.92236328125 
[2025-03-16 17:58:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 14 loss:0.012172787450253963 norm:0.00037859089206904173 max memory_allocated 38139.92236328125 
[2025-03-16 17:59:10 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 12 to 13 ===
[2025-03-16 18:00:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 0 loss:0.032726626843214035 norm:0.002598866820335388 max memory_allocated 38140.09423828125 
[2025-03-16 18:01:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 1 loss:0.023364312946796417 norm:0.0013676028465852141 max memory_allocated 38140.09423828125 
[2025-03-16 18:02:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 2 loss:0.01911400631070137 norm:0.0009163085487671196 max memory_allocated 38140.09423828125 
[2025-03-16 18:03:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 3 loss:0.016553623601794243 norm:0.0006556540611200035 max memory_allocated 38140.09423828125 
[2025-03-16 18:04:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 4 loss:0.015048847533762455 norm:0.0005310127744451165 max memory_allocated 38140.09423828125 
[2025-03-16 18:04:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 5 loss:0.014094595797359943 norm:0.00044442969374358654 max memory_allocated 38140.09423828125 
[2025-03-16 18:05:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 6 loss:0.013439847156405449 norm:0.0003847367479465902 max memory_allocated 38140.09423828125 
[2025-03-16 18:06:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 7 loss:0.01295356173068285 norm:0.0003524205239955336 max memory_allocated 38140.09423828125 
[2025-03-16 18:07:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 8 loss:0.01260552927851677 norm:0.0003223730018362403 max memory_allocated 38140.09423828125 
[2025-03-16 18:08:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 9 loss:0.012375613674521446 norm:0.0003084453637711704 max memory_allocated 38140.09423828125 
[2025-03-16 18:09:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 10 loss:0.01216929778456688 norm:0.00029499511583708227 max memory_allocated 38140.09423828125 
[2025-03-16 18:10:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 11 loss:0.012037638574838638 norm:0.00028388036298565567 max memory_allocated 38140.09423828125 
[2025-03-16 18:11:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 12 loss:0.011910305358469486 norm:0.0002712077694013715 max memory_allocated 38140.09423828125 
[2025-03-16 18:12:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 13 loss:0.011804135516285896 norm:0.0002620127343107015 max memory_allocated 38140.09423828125 
[2025-03-16 18:13:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 14 loss:0.011710355058312416 norm:0.0002582409360911697 max memory_allocated 38140.09423828125 
[2025-03-16 18:14:01 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 13 to 14 ===
[2025-03-16 18:15:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 0 loss:0.03815806657075882 norm:0.003396894782781601 max memory_allocated 38140.26611328125 
[2025-03-16 18:16:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 1 loss:0.028562240302562714 norm:0.00207632128149271 max memory_allocated 38140.26611328125 
[2025-03-16 18:16:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 2 loss:0.02414337545633316 norm:0.001526471576653421 max memory_allocated 38140.26611328125 
[2025-03-16 18:17:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 3 loss:0.021082241088151932 norm:0.0011417851783335209 max memory_allocated 38140.26611328125 
[2025-03-16 18:18:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 4 loss:0.019362054765224457 norm:0.0009118856396526098 max memory_allocated 38140.26611328125 
[2025-03-16 18:19:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 5 loss:0.01821260154247284 norm:0.0007777942810207605 max memory_allocated 38140.26611328125 
[2025-03-16 18:20:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 6 loss:0.017342524603009224 norm:0.0006896439590491354 max memory_allocated 38140.26611328125 
[2025-03-16 18:21:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 7 loss:0.016665862873196602 norm:0.0006089366506785154 max memory_allocated 38140.26611328125 
[2025-03-16 18:22:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 8 loss:0.01618720404803753 norm:0.000549880787730217 max memory_allocated 38140.26611328125 
[2025-03-16 18:23:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 9 loss:0.015821216627955437 norm:0.0005040931864641607 max memory_allocated 38140.26611328125 
[2025-03-16 18:24:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 10 loss:0.015496404841542244 norm:0.0004685071180574596 max memory_allocated 38140.26611328125 
[2025-03-16 18:25:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 11 loss:0.015269128605723381 norm:0.0004380435566417873 max memory_allocated 38140.26611328125 
[2025-03-16 18:26:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 12 loss:0.015055118128657341 norm:0.0004150068270973861 max memory_allocated 38140.26611328125 
[2025-03-16 18:27:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 13 loss:0.014839356765151024 norm:0.00039531401125714183 max memory_allocated 38140.26611328125 
[2025-03-16 18:28:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 14 loss:0.014700524508953094 norm:0.0003792430798057467 max memory_allocated 38140.26611328125 
[2025-03-16 18:28:52 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 14 to 15 ===
[2025-03-16 18:29:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 0 loss:0.052948080003261566 norm:0.003489739028736949 max memory_allocated 38140.43798828125 
[2025-03-16 18:30:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 1 loss:0.032368071377277374 norm:0.0015395801747217774 max memory_allocated 38140.43798828125 
[2025-03-16 18:31:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 2 loss:0.02477278560400009 norm:0.0008857592474669218 max memory_allocated 38140.43798828125 
[2025-03-16 18:32:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 3 loss:0.02134702354669571 norm:0.0006916060810908675 max memory_allocated 38140.43798828125 
[2025-03-16 18:33:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 4 loss:0.01933230645954609 norm:0.0005811583250761032 max memory_allocated 38140.43798828125 
[2025-03-16 18:34:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 5 loss:0.01803220622241497 norm:0.0005024089477956295 max memory_allocated 38140.43798828125 
[2025-03-16 18:35:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 6 loss:0.017137106508016586 norm:0.00044328259536996484 max memory_allocated 38140.43798828125 
[2025-03-16 18:36:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 7 loss:0.016441965475678444 norm:0.00040787074249237776 max memory_allocated 38140.43798828125 
[2025-03-16 18:37:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 8 loss:0.015939995646476746 norm:0.000388842512620613 max memory_allocated 38140.43798828125 
[2025-03-16 18:38:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 9 loss:0.015552189201116562 norm:0.000375797797460109 max memory_allocated 38140.43798828125 
[2025-03-16 18:39:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 10 loss:0.015168012119829655 norm:0.00034371705260127783 max memory_allocated 38140.43798828125 
[2025-03-16 18:40:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 11 loss:0.014858102425932884 norm:0.00032036533229984343 max memory_allocated 38140.43798828125 
[2025-03-16 18:41:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 12 loss:0.014680076390504837 norm:0.00031032640254125 max memory_allocated 38140.43798828125 
[2025-03-16 18:42:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 13 loss:0.014492559246718884 norm:0.00029790413100272417 max memory_allocated 38140.43798828125 
[2025-03-16 18:43:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 14 loss:0.014330120757222176 norm:0.0002880839165300131 max memory_allocated 38140.43798828125 
[2025-03-16 18:43:42 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 15 to 16 ===
[2025-03-16 18:44:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 0 loss:0.030357372015714645 norm:0.0014285626821219921 max memory_allocated 38140.60986328125 
[2025-03-16 18:45:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 1 loss:0.022188646718859673 norm:0.0007343387696892023 max memory_allocated 38140.60986328125 
[2025-03-16 18:46:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 2 loss:0.01814854145050049 norm:0.0004943741951137781 max memory_allocated 38140.60986328125 
[2025-03-16 18:47:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 3 loss:0.0160338394343853 norm:0.0003712962497957051 max memory_allocated 38140.60986328125 
[2025-03-16 18:48:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 4 loss:0.01498470176011324 norm:0.0003061782044824213 max memory_allocated 38140.60986328125 
[2025-03-16 18:49:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 5 loss:0.014230331405997276 norm:0.0002580898581072688 max memory_allocated 38140.60986328125 
[2025-03-16 18:50:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 6 loss:0.01370356883853674 norm:0.0002333266893401742 max memory_allocated 38140.60986328125 
[2025-03-16 18:51:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 7 loss:0.01332143321633339 norm:0.00021429875050671399 max memory_allocated 38140.60986328125 
[2025-03-16 18:52:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 8 loss:0.013084124773740768 norm:0.00020042680262122303 max memory_allocated 38140.60986328125 
[2025-03-16 18:53:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 9 loss:0.01289144903421402 norm:0.0001927241391967982 max memory_allocated 38140.60986328125 
[2025-03-16 18:54:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 10 loss:0.012718897312879562 norm:0.00018728509894572198 max memory_allocated 38140.60986328125 
[2025-03-16 18:55:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 11 loss:0.012590257450938225 norm:0.00017923992709256709 max memory_allocated 38140.60986328125 
[2025-03-16 18:56:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 12 loss:0.012503526173532009 norm:0.0001719816937111318 max memory_allocated 38140.60986328125 
[2025-03-16 18:57:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 13 loss:0.01244613341987133 norm:0.00017117596871685237 max memory_allocated 38140.60986328125 
[2025-03-16 18:58:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 14 loss:0.012360199354588985 norm:0.00016523264639545232 max memory_allocated 38140.60986328125 
[2025-03-16 18:58:33 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 16 to 17 ===
[2025-03-16 18:59:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 0 loss:0.030026860535144806 norm:0.0021188165992498398 max memory_allocated 38140.78173828125 
[2025-03-16 19:00:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 1 loss:0.023192401975393295 norm:0.0010514160385355353 max memory_allocated 38140.78173828125 
[2025-03-16 19:01:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 2 loss:0.01957588642835617 norm:0.0007436623563989997 max memory_allocated 38140.78173828125 
[2025-03-16 19:02:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 3 loss:0.017624130472540855 norm:0.0005741636268794537 max memory_allocated 38140.78173828125 
[2025-03-16 19:03:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 4 loss:0.016437899321317673 norm:0.00042844944982789457 max memory_allocated 38140.78173828125 
[2025-03-16 19:04:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 5 loss:0.01567423902451992 norm:0.000359631929313764 max memory_allocated 38140.78173828125 
[2025-03-16 19:05:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 6 loss:0.01514639426022768 norm:0.000312805495923385 max memory_allocated 38140.78173828125 
[2025-03-16 19:06:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 7 loss:0.01471002772450447 norm:0.00025884038768708706 max memory_allocated 38140.78173828125 
[2025-03-16 19:07:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 8 loss:0.014370052143931389 norm:0.00025147845735773444 max memory_allocated 38140.78173828125 
[2025-03-16 19:08:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 9 loss:0.014157239347696304 norm:0.00024335310445167124 max memory_allocated 38140.78173828125 
[2025-03-16 19:09:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 10 loss:0.013990134000778198 norm:0.00023054717166814953 max memory_allocated 38140.78173828125 
[2025-03-16 19:10:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 11 loss:0.013866211287677288 norm:0.0002224083582405001 max memory_allocated 38140.78173828125 
[2025-03-16 19:10:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 12 loss:0.0137583427131176 norm:0.0002127139741787687 max memory_allocated 38140.78173828125 
[2025-03-16 19:11:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 13 loss:0.013690588995814323 norm:0.00020957477681804448 max memory_allocated 38140.78173828125 
[2025-03-16 19:12:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 14 loss:0.013635430485010147 norm:0.00020293908892199397 max memory_allocated 38140.78173828125 
[2025-03-16 19:13:23 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 17 to 18 ===
[2025-03-16 19:14:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 0 loss:0.03332309052348137 norm:0.0014198173303157091 max memory_allocated 38140.95361328125 
[2025-03-16 19:15:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 1 loss:0.023604251444339752 norm:0.0006765408325009048 max memory_allocated 38140.95361328125 
[2025-03-16 19:16:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 2 loss:0.018945734947919846 norm:0.000476070650620386 max memory_allocated 38140.95361328125 
[2025-03-16 19:17:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 3 loss:0.016967272385954857 norm:0.0003793402574956417 max memory_allocated 38140.95361328125 
[2025-03-16 19:18:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 4 loss:0.015832843258976936 norm:0.0003331075422465801 max memory_allocated 38140.95361328125 
[2025-03-16 19:19:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 5 loss:0.015037653967738152 norm:0.00029317938606254756 max memory_allocated 38140.95361328125 
[2025-03-16 19:20:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 6 loss:0.01451383251696825 norm:0.00026914148475043476 max memory_allocated 38140.95361328125 
[2025-03-16 19:21:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 7 loss:0.014147465117275715 norm:0.00024746806593611836 max memory_allocated 38140.95361328125 
[2025-03-16 19:22:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 8 loss:0.013886719942092896 norm:0.000231324796914123 max memory_allocated 38140.95361328125 
[2025-03-16 19:22:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 9 loss:0.013699965551495552 norm:0.00021980394376441836 max memory_allocated 38140.95361328125 
[2025-03-16 19:23:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 10 loss:0.013531896285712719 norm:0.00020996878447476774 max memory_allocated 38140.95361328125 
[2025-03-16 19:24:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 11 loss:0.013399637304246426 norm:0.0002034056669799611 max memory_allocated 38140.95361328125 
[2025-03-16 19:25:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 12 loss:0.013287978246808052 norm:0.00019469590915832669 max memory_allocated 38140.95361328125 
[2025-03-16 19:26:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 13 loss:0.013196885585784912 norm:0.00018718151841312647 max memory_allocated 38140.95361328125 
[2025-03-16 19:27:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 14 loss:0.013138478621840477 norm:0.0001799665333237499 max memory_allocated 38140.95361328125 
[2025-03-16 19:28:14 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 18 to 19 ===
[2025-03-16 19:29:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 0 loss:0.032676778733730316 norm:0.0016361363232135773 max memory_allocated 38141.12548828125 
[2025-03-16 19:30:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 1 loss:0.024810748174786568 norm:0.000884667388163507 max memory_allocated 38141.12548828125 
[2025-03-16 19:31:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 2 loss:0.020173408091068268 norm:0.0005435630446299911 max memory_allocated 38141.12548828125 
[2025-03-16 19:32:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 3 loss:0.01830459199845791 norm:0.0003867999475914985 max memory_allocated 38141.12548828125 
[2025-03-16 19:33:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 4 loss:0.0172691959887743 norm:0.0003058988368138671 max memory_allocated 38141.12548828125 
[2025-03-16 19:34:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 5 loss:0.016561273485422134 norm:0.00025802478194236755 max memory_allocated 38141.12548828125 
[2025-03-16 19:34:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 6 loss:0.01605689711868763 norm:0.00023193759261630476 max memory_allocated 38141.12548828125 
[2025-03-16 19:35:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 7 loss:0.015721896663308144 norm:0.00021230129641480744 max memory_allocated 38141.12548828125 
[2025-03-16 19:36:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 8 loss:0.01547936350107193 norm:0.00019433113629929721 max memory_allocated 38141.12548828125 
[2025-03-16 19:37:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 9 loss:0.015316756442189217 norm:0.0001824385253712535 max memory_allocated 38141.12548828125 
[2025-03-16 19:38:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 10 loss:0.01522408053278923 norm:0.0001729689829517156 max memory_allocated 38141.12548828125 
[2025-03-16 19:39:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 11 loss:0.01514398492872715 norm:0.00016693692305125296 max memory_allocated 38141.12548828125 
[2025-03-16 19:40:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 12 loss:0.015094263479113579 norm:0.00016212050104513764 max memory_allocated 38141.12548828125 
[2025-03-16 19:41:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 13 loss:0.01504686288535595 norm:0.0001616062072571367 max memory_allocated 38141.12548828125 
[2025-03-16 19:42:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 14 loss:0.015013465657830238 norm:0.00015543025801889598 max memory_allocated 38141.12548828125 
[2025-03-16 19:43:05 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 19 to 20 ===
[2025-03-16 19:44:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 0 loss:0.03707941994071007 norm:0.0016084207454696298 max memory_allocated 38141.29736328125 
[2025-03-16 19:45:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 1 loss:0.026650872081518173 norm:0.0006705174455419183 max memory_allocated 38141.29736328125 
[2025-03-16 19:46:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 2 loss:0.022007836028933525 norm:0.0004873480065725744 max memory_allocated 38141.29736328125 
[2025-03-16 19:46:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 3 loss:0.01996803656220436 norm:0.00037596572656184435 max memory_allocated 38141.29736328125 
[2025-03-16 19:47:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 4 loss:0.018708907067775726 norm:0.0003352824132889509 max memory_allocated 38141.29736328125 
[2025-03-16 19:48:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 5 loss:0.017841096967458725 norm:0.00029581214766949415 max memory_allocated 38141.29736328125 
[2025-03-16 19:49:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 6 loss:0.01725459098815918 norm:0.0002718126343097538 max memory_allocated 38141.29736328125 
[2025-03-16 19:50:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 7 loss:0.016886133700609207 norm:0.0002488045138306916 max memory_allocated 38141.29736328125 
[2025-03-16 19:51:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 8 loss:0.016566429287195206 norm:0.00022793665993958712 max memory_allocated 38141.29736328125 
[2025-03-16 19:52:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 9 loss:0.016378920525312424 norm:0.00021940041915513575 max memory_allocated 38141.29736328125 
[2025-03-16 19:53:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 10 loss:0.01620463654398918 norm:0.0002060335682472214 max memory_allocated 38141.29736328125 
[2025-03-16 19:54:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 11 loss:0.016078844666481018 norm:0.00020066543947905302 max memory_allocated 38141.29736328125 
[2025-03-16 19:55:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 12 loss:0.01594601385295391 norm:0.00019427845836617053 max memory_allocated 38141.29736328125 
[2025-03-16 19:56:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 13 loss:0.01582789048552513 norm:0.00018422113498672843 max memory_allocated 38141.29736328125 
[2025-03-16 19:57:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 14 loss:0.015738410875201225 norm:0.00017820653738453984 max memory_allocated 38141.29736328125 
[2025-03-16 19:57:56 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 20 to 21 ===
[2025-03-16 19:58:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 0 loss:0.042886413633823395 norm:0.003867560066282749 max memory_allocated 38141.46923828125 
[2025-03-16 19:59:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 1 loss:0.029883164912462234 norm:0.0012037953129038215 max memory_allocated 38141.46923828125 
[2025-03-16 20:00:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 2 loss:0.023705923929810524 norm:0.0007382609182968736 max memory_allocated 38141.46923828125 
[2025-03-16 20:01:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 3 loss:0.021241823211312294 norm:0.0005443840636871755 max memory_allocated 38141.46923828125 
[2025-03-16 20:02:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 4 loss:0.019823800772428513 norm:0.00046489672968164086 max memory_allocated 38141.46923828125 
[2025-03-16 20:03:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 5 loss:0.01892104372382164 norm:0.000406164035666734 max memory_allocated 38141.46923828125 
[2025-03-16 20:04:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 6 loss:0.01831672340631485 norm:0.0003804022853728384 max memory_allocated 38141.46923828125 
[2025-03-16 20:05:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 7 loss:0.01792631298303604 norm:0.0003517072182148695 max memory_allocated 38141.46923828125 
[2025-03-16 20:06:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 8 loss:0.017655793577432632 norm:0.0003292783221695572 max memory_allocated 38141.46923828125 
[2025-03-16 20:07:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 9 loss:0.017423326149582863 norm:0.00031455635325983167 max memory_allocated 38141.46923828125 
[2025-03-16 20:08:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 10 loss:0.017250172793865204 norm:0.00029623901355080307 max memory_allocated 38141.46923828125 
[2025-03-16 20:09:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 11 loss:0.01711108349263668 norm:0.0002838106011040509 max memory_allocated 38141.46923828125 
[2025-03-16 20:10:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 12 loss:0.016978569328784943 norm:0.00028143139206804335 max memory_allocated 38141.46923828125 
[2025-03-16 20:11:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 13 loss:0.016903672367334366 norm:0.0002656349097378552 max memory_allocated 38141.46923828125 
[2025-03-16 20:12:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 14 loss:0.01683988980948925 norm:0.000252337078563869 max memory_allocated 38141.46923828125 
[2025-03-16 20:12:48 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 21 to 22 ===
[2025-03-16 20:13:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 0 loss:0.037504926323890686 norm:0.001984141068533063 max memory_allocated 38141.64111328125 
[2025-03-16 20:14:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 1 loss:0.026509400457143784 norm:0.0008437704527750611 max memory_allocated 38141.64111328125 
[2025-03-16 20:15:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 2 loss:0.021643290296196938 norm:0.0005563519662246108 max memory_allocated 38141.64111328125 
[2025-03-16 20:16:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 3 loss:0.019512850791215897 norm:0.000425501522840932 max memory_allocated 38141.64111328125 
[2025-03-16 20:17:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 4 loss:0.018330581486225128 norm:0.00036237097810953856 max memory_allocated 38141.64111328125 
[2025-03-16 20:18:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 5 loss:0.017535412684082985 norm:0.0003293602785561234 max memory_allocated 38141.64111328125 
[2025-03-16 20:19:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 6 loss:0.017026741057634354 norm:0.00031149841379374266 max memory_allocated 38141.64111328125 
[2025-03-16 20:20:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 7 loss:0.01666847988963127 norm:0.0003028166829608381 max memory_allocated 38141.64111328125 
[2025-03-16 20:21:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 8 loss:0.01638197898864746 norm:0.0002934311341959983 max memory_allocated 38141.64111328125 
[2025-03-16 20:22:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 9 loss:0.016168318688869476 norm:0.000288302602712065 max memory_allocated 38141.64111328125 
[2025-03-16 20:23:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 10 loss:0.015933167189359665 norm:0.00026210705982521176 max memory_allocated 38141.64111328125 
[2025-03-16 20:24:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 11 loss:0.015721675008535385 norm:0.00023684209736529738 max memory_allocated 38141.64111328125 
[2025-03-16 20:25:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 12 loss:0.015570344403386116 norm:0.0002234385465271771 max memory_allocated 38141.64111328125 
[2025-03-16 20:26:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 13 loss:0.015447365120053291 norm:0.00022180832456797361 max memory_allocated 38141.64111328125 
[2025-03-16 20:27:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 14 loss:0.015353059396147728 norm:0.00022123119561001658 max memory_allocated 38141.64111328125 
[2025-03-16 20:27:39 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 22 to 23 ===
[2025-03-16 20:28:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 0 loss:0.03552936762571335 norm:0.002397265052422881 max memory_allocated 38141.81298828125 
[2025-03-16 20:29:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 1 loss:0.026762252673506737 norm:0.0011403540847823024 max memory_allocated 38141.81298828125 
[2025-03-16 20:30:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 2 loss:0.021887842565774918 norm:0.0007305971230380237 max memory_allocated 38141.81298828125 
[2025-03-16 20:31:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 3 loss:0.020072707906365395 norm:0.0005326346145011485 max memory_allocated 38141.81298828125 
[2025-03-16 20:32:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 4 loss:0.018943989649415016 norm:0.00041798941674642265 max memory_allocated 38141.81298828125 
[2025-03-16 20:33:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 5 loss:0.018161123618483543 norm:0.00033849821193143725 max memory_allocated 38141.81298828125 
[2025-03-16 20:34:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 6 loss:0.017705686390399933 norm:0.0002902330888900906 max memory_allocated 38141.81298828125 
[2025-03-16 20:35:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 7 loss:0.017430691048502922 norm:0.0002603049506433308 max memory_allocated 38141.81298828125 
[2025-03-16 20:36:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 8 loss:0.017237260937690735 norm:0.00023396087635774165 max memory_allocated 38141.81298828125 
[2025-03-16 20:37:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 9 loss:0.017085690051317215 norm:0.00021034310339018703 max memory_allocated 38141.81298828125 
[2025-03-16 20:38:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 10 loss:0.016960695385932922 norm:0.00019791722297668457 max memory_allocated 38141.81298828125 
[2025-03-16 20:39:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 11 loss:0.016872769221663475 norm:0.00019191764295101166 max memory_allocated 38141.81298828125 
[2025-03-16 20:40:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 12 loss:0.01682574488222599 norm:0.00018366285075899214 max memory_allocated 38141.81298828125 
[2025-03-16 20:41:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 13 loss:0.01676253415644169 norm:0.0001827093947213143 max memory_allocated 38141.81298828125 
[2025-03-16 20:41:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 14 loss:0.016702016815543175 norm:0.00017123356519732624 max memory_allocated 38141.81298828125 
[2025-03-16 20:42:30 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 23 to 24 ===
[2025-03-16 20:43:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 0 loss:0.03801429271697998 norm:0.0036714007146656513 max memory_allocated 38141.98486328125 
[2025-03-16 20:44:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 1 loss:0.028821343556046486 norm:0.0010030355770140886 max memory_allocated 38141.98486328125 
[2025-03-16 20:45:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 2 loss:0.023493845015764236 norm:0.0005885353311896324 max memory_allocated 38141.98486328125 
[2025-03-16 20:46:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 3 loss:0.02126615308225155 norm:0.00044429278932511806 max memory_allocated 38141.98486328125 
[2025-03-16 20:47:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 4 loss:0.02006661333143711 norm:0.00036592030664905906 max memory_allocated 38141.98486328125 
[2025-03-16 20:48:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 5 loss:0.019225802272558212 norm:0.00031170231522992253 max memory_allocated 38141.98486328125 
[2025-03-16 20:49:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 6 loss:0.01872418262064457 norm:0.0002757494221441448 max memory_allocated 38141.98486328125 
[2025-03-16 20:50:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 7 loss:0.018424300476908684 norm:0.00025722183636389673 max memory_allocated 38141.98486328125 
[2025-03-16 20:51:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 8 loss:0.018238762393593788 norm:0.00023994511866476387 max memory_allocated 38141.98486328125 
[2025-03-16 20:52:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 9 loss:0.018070686608552933 norm:0.0002351300499867648 max memory_allocated 38141.98486328125 
[2025-03-16 20:53:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 10 loss:0.01797795109450817 norm:0.00023716670693829656 max memory_allocated 38141.98486328125 
[2025-03-16 20:53:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 11 loss:0.01787787489593029 norm:0.00022428258671425283 max memory_allocated 38141.98486328125 
[2025-03-16 20:54:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 12 loss:0.017779415473341942 norm:0.00021360440587159246 max memory_allocated 38141.98486328125 
[2025-03-16 20:55:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 13 loss:0.017689090222120285 norm:0.00020884770492557436 max memory_allocated 38141.98486328125 
[2025-03-16 20:56:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 14 loss:0.017600007355213165 norm:0.00021077162818983197 max memory_allocated 38141.98486328125 
[2025-03-16 20:57:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 24 to 25 ===
[2025-03-16 20:58:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 0 loss:0.04000779613852501 norm:0.0018404766451567411 max memory_allocated 38142.15673828125 
[2025-03-16 20:59:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 1 loss:0.03010139800608158 norm:0.0009845176246017218 max memory_allocated 38142.15673828125 
[2025-03-16 21:00:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 2 loss:0.023968255147337914 norm:0.0006747826701030135 max memory_allocated 38142.15673828125 
[2025-03-16 21:01:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 3 loss:0.02131912112236023 norm:0.0005167491617612541 max memory_allocated 38142.15673828125 
[2025-03-16 21:02:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 4 loss:0.01990821398794651 norm:0.0004301396256778389 max memory_allocated 38142.15673828125 
[2025-03-16 21:03:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 5 loss:0.019002756103873253 norm:0.0003645712567958981 max memory_allocated 38142.15673828125 
[2025-03-16 21:04:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 6 loss:0.018408872187137604 norm:0.0003278908843640238 max memory_allocated 38142.15673828125 
[2025-03-16 21:05:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 7 loss:0.0180476326495409 norm:0.00029326294315978885 max memory_allocated 38142.15673828125 
[2025-03-16 21:06:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 8 loss:0.01783037930727005 norm:0.00027877010870724916 max memory_allocated 38142.15673828125 
[2025-03-16 21:06:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 9 loss:0.017655203118920326 norm:0.00026047122082673013 max memory_allocated 38142.15673828125 
[2025-03-16 21:07:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 10 loss:0.017537899315357208 norm:0.0002535648236516863 max memory_allocated 38142.15673828125 
[2025-03-16 21:08:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 11 loss:0.017410680651664734 norm:0.00024279477656818926 max memory_allocated 38142.15673828125 
[2025-03-16 21:09:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 12 loss:0.017312057316303253 norm:0.00023834854073356837 max memory_allocated 38142.15673828125 
[2025-03-16 21:10:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 13 loss:0.017237110063433647 norm:0.00023309604148380458 max memory_allocated 38142.15673828125 
[2025-03-16 21:11:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 14 loss:0.017169050872325897 norm:0.00022940224152989686 max memory_allocated 38142.15673828125 
[2025-03-16 21:12:13 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 25 to 26 ===
[2025-03-16 21:13:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 0 loss:0.04791335016489029 norm:0.0030081449076533318 max memory_allocated 38142.32861328125 
[2025-03-16 21:14:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 1 loss:0.03423506021499634 norm:0.001474864431656897 max memory_allocated 38142.32861328125 
[2025-03-16 21:15:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 2 loss:0.027062365785241127 norm:0.0009060230804607272 max memory_allocated 38142.32861328125 
[2025-03-16 21:16:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 3 loss:0.02412060834467411 norm:0.0006494650151580572 max memory_allocated 38142.32861328125 
[2025-03-16 21:17:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 4 loss:0.022465409711003304 norm:0.0004970565205439925 max memory_allocated 38142.32861328125 
[2025-03-16 21:18:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 5 loss:0.02145065739750862 norm:0.0004014133592136204 max memory_allocated 38142.32861328125 
[2025-03-16 21:18:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 6 loss:0.020956523716449738 norm:0.00034663628321141005 max memory_allocated 38142.32861328125 
[2025-03-16 21:19:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 7 loss:0.020611796528100967 norm:0.0003095461579505354 max memory_allocated 38142.32861328125 
[2025-03-16 21:20:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 8 loss:0.020356934517621994 norm:0.0002828362921718508 max memory_allocated 38142.32861328125 
[2025-03-16 21:21:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 9 loss:0.020161228254437447 norm:0.00025967074907384813 max memory_allocated 38142.32861328125 
[2025-03-16 21:22:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 10 loss:0.02003471925854683 norm:0.00025333563098683953 max memory_allocated 38142.32861328125 
[2025-03-16 21:23:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 11 loss:0.019918732345104218 norm:0.00024430203484371305 max memory_allocated 38142.32861328125 
[2025-03-16 21:24:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 12 loss:0.01979903317987919 norm:0.00023459730437025428 max memory_allocated 38142.32861328125 
[2025-03-16 21:25:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 13 loss:0.019732538610696793 norm:0.00022966539836488664 max memory_allocated 38142.32861328125 
[2025-03-16 21:26:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 14 loss:0.019660795107483864 norm:0.00022566181723959744 max memory_allocated 38142.32861328125 
[2025-03-16 21:27:04 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 26 to 27 ===
[2025-03-16 21:28:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 0 loss:0.05887691304087639 norm:0.005067144520580769 max memory_allocated 38142.50048828125 
[2025-03-16 21:29:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 1 loss:0.04076876863837242 norm:0.0022244900465011597 max memory_allocated 38142.50048828125 
[2025-03-16 21:30:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 2 loss:0.032133009284734726 norm:0.0014292735140770674 max memory_allocated 38142.50048828125 
[2025-03-16 21:30:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 3 loss:0.02817694842815399 norm:0.0009862874867394567 max memory_allocated 38142.50048828125 
[2025-03-16 21:31:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 4 loss:0.026160910725593567 norm:0.0007834587595425546 max memory_allocated 38142.50048828125 
[2025-03-16 21:32:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 5 loss:0.0250007975846529 norm:0.0006660306244157255 max memory_allocated 38142.50048828125 
[2025-03-16 21:33:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 6 loss:0.02431032806634903 norm:0.0005720773478969932 max memory_allocated 38142.50048828125 
[2025-03-16 21:34:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 7 loss:0.023867657408118248 norm:0.0005109297344461083 max memory_allocated 38142.50048828125 
[2025-03-16 21:35:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 8 loss:0.023558713495731354 norm:0.00046729150926694274 max memory_allocated 38142.50048828125 
[2025-03-16 21:36:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 9 loss:0.023319993168115616 norm:0.00043275702046230435 max memory_allocated 38142.50048828125 
[2025-03-16 21:37:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 10 loss:0.023129595443606377 norm:0.0004092108574695885 max memory_allocated 38142.50048828125 
[2025-03-16 21:38:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 11 loss:0.02296256273984909 norm:0.00038265055627562106 max memory_allocated 38142.50048828125 
[2025-03-16 21:39:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 12 loss:0.022892622277140617 norm:0.00036568177165463567 max memory_allocated 38142.50048828125 
[2025-03-16 21:40:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 13 loss:0.022806303575634956 norm:0.0003505735658109188 max memory_allocated 38142.50048828125 
[2025-03-16 21:41:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 14 loss:0.022706465795636177 norm:0.0003409367927815765 max memory_allocated 38142.50048828125 
[2025-03-16 21:41:55 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 27 to 28 ===
[2025-03-16 21:42:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 0 loss:0.0643659234046936 norm:0.26450690627098083 max memory_allocated 38142.84521484375 
[2025-03-16 21:43:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 1 loss:0.046638187021017075 norm:0.02933807298541069 max memory_allocated 38142.84521484375 
[2025-03-16 21:44:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 2 loss:0.03704850375652313 norm:0.023490075021982193 max memory_allocated 38142.84521484375 
[2025-03-16 21:45:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 3 loss:0.03262012079358101 norm:0.01677183248102665 max memory_allocated 38142.84521484375 
[2025-03-16 21:46:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 4 loss:0.029996255412697792 norm:0.011464429087936878 max memory_allocated 38142.84521484375 
[2025-03-16 21:47:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 5 loss:0.028654472902417183 norm:0.010112893767654896 max memory_allocated 38142.84521484375 
[2025-03-16 21:48:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 6 loss:0.027824517339468002 norm:0.008676759898662567 max memory_allocated 38142.84521484375 
[2025-03-16 21:49:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 7 loss:0.02712598443031311 norm:0.006967909634113312 max memory_allocated 38142.84521484375 
[2025-03-16 21:50:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 8 loss:0.02661125361919403 norm:0.0060594468377530575 max memory_allocated 38142.84521484375 
[2025-03-16 21:51:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 9 loss:0.026335138827562332 norm:0.006100974045693874 max memory_allocated 38142.84521484375 
[2025-03-16 21:52:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 10 loss:0.026108268648386 norm:0.005756867118179798 max memory_allocated 38142.84521484375 
[2025-03-16 21:53:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 11 loss:0.02590210549533367 norm:0.005230674520134926 max memory_allocated 38142.84521484375 
[2025-03-16 21:54:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 12 loss:0.02559291012585163 norm:0.00435404758900404 max memory_allocated 38142.84521484375 
[2025-03-16 21:55:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 13 loss:0.02553863823413849 norm:0.0045912195928394794 max memory_allocated 38142.84521484375 
[2025-03-16 21:56:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 14 loss:0.025452371686697006 norm:0.004368899390101433 max memory_allocated 38142.84521484375 
[2025-03-16 21:56:47 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 28 to 29 ===
[2025-03-16 21:57:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 0 loss:0.0790654644370079 norm:0.01343817450106144 max memory_allocated 38143.18994140625 
[2025-03-16 21:58:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 1 loss:0.0576665885746479 norm:0.008738774806261063 max memory_allocated 38143.18994140625 
[2025-03-16 21:59:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 2 loss:0.045834995806217194 norm:0.005827386397868395 max memory_allocated 38143.18994140625 
[2025-03-16 22:00:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 3 loss:0.040553782135248184 norm:0.004269062075763941 max memory_allocated 38143.18994140625 
[2025-03-16 22:01:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 4 loss:0.03751512989401817 norm:0.0034263934940099716 max memory_allocated 38143.18994140625 
[2025-03-16 22:02:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 5 loss:0.03576512634754181 norm:0.003363617928698659 max memory_allocated 38143.18994140625 
[2025-03-16 22:03:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 6 loss:0.03468732908368111 norm:0.0031646336428821087 max memory_allocated 38143.18994140625 
[2025-03-16 22:04:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 7 loss:0.034067653119564056 norm:0.003322992008179426 max memory_allocated 38143.18994140625 
[2025-03-16 22:05:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 8 loss:0.03359425812959671 norm:0.0029009543359279633 max memory_allocated 38143.18994140625 
[2025-03-16 22:06:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 9 loss:0.033266134560108185 norm:0.002694185823202133 max memory_allocated 38143.18994140625 
[2025-03-16 22:07:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 10 loss:0.03304869681596756 norm:0.002672554226592183 max memory_allocated 38143.18994140625 
[2025-03-16 22:08:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 11 loss:0.032912082970142365 norm:0.0026091288309544325 max memory_allocated 38143.18994140625 
[2025-03-16 22:09:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 12 loss:0.03269913047552109 norm:0.002591109136119485 max memory_allocated 38143.18994140625 
[2025-03-16 22:10:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 13 loss:0.032538142055273056 norm:0.0025637925136834383 max memory_allocated 38143.18994140625 
[2025-03-16 22:11:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 14 loss:0.03245265781879425 norm:0.0024281449150294065 max memory_allocated 38143.18994140625 
[2025-03-16 22:11:42 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 29 to 30 ===
[2025-03-16 22:11:48 root] (abq_llm_calib_config3_cbq.py 431): INFO Loss is NAN, stopping training
