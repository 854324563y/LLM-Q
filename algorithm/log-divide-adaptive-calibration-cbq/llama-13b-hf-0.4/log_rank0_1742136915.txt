[2025-03-16 14:55:15 root] (main_calib_config3_cbq.py 280): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-13b-hf', cache_dir='./cache', output_dir='./log-divide-adaptive-calibration-cbq/llama-13b-hf-0.4', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-divide-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.4.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-16 14:58:05 root] (main_calib_config3_cbq.py 347): INFO === start quantization ===
[2025-03-16 14:58:05 root] (main_calib_config3_cbq.py 353): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-16 14:58:06 root] (abq_llm_calib_config3_cbq.py 82): INFO Starting ...
[2025-03-16 14:58:06 root] (abq_llm_calib_config3_cbq.py 89): INFO Loaded quant_map from log-divide-adaptive/llama-13b-hf/quant_map_llama-13b-hf_0.4.pkl
[2025-03-16 14:58:12 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 0 to 1 ===
[2025-03-16 14:59:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 0 loss:0.12250073999166489 norm:0.12126385420560837 max memory_allocated 49619.62158203125 
[2025-03-16 15:01:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 1 loss:0.0837615579366684 norm:0.10372525453567505 max memory_allocated 49619.62158203125 
[2025-03-16 15:02:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 2 loss:0.0696009024977684 norm:0.07363958656787872 max memory_allocated 49619.62158203125 
[2025-03-16 15:03:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 3 loss:0.06319434195756912 norm:0.06197982281446457 max memory_allocated 49619.62158203125 
[2025-03-16 15:05:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 4 loss:0.059772394597530365 norm:0.05404702201485634 max memory_allocated 49619.62158203125 
[2025-03-16 15:06:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 5 loss:0.057354871183633804 norm:0.0481925904750824 max memory_allocated 49619.62158203125 
[2025-03-16 15:08:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 6 loss:0.05507206916809082 norm:0.03746213763952255 max memory_allocated 49619.62158203125 
[2025-03-16 15:09:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 7 loss:0.05360523238778114 norm:0.03219497576355934 max memory_allocated 49619.62158203125 
[2025-03-16 15:11:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 8 loss:0.05256318300962448 norm:0.02905399166047573 max memory_allocated 49619.62158203125 
[2025-03-16 15:12:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 9 loss:0.05147368088364601 norm:0.022568264976143837 max memory_allocated 49619.62158203125 
[2025-03-16 15:13:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 10 loss:0.0509403720498085 norm:0.022876709699630737 max memory_allocated 49619.62158203125 
[2025-03-16 15:15:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 11 loss:0.05053606629371643 norm:0.02079673297703266 max memory_allocated 49619.62158203125 
[2025-03-16 15:16:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 12 loss:0.05013396590948105 norm:0.019219376146793365 max memory_allocated 49619.62158203125 
[2025-03-16 15:18:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 13 loss:0.04979962483048439 norm:0.016891716048121452 max memory_allocated 49619.62158203125 
[2025-03-16 15:19:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 14 loss:0.049379363656044006 norm:0.016041841357946396 max memory_allocated 49619.62158203125 
[2025-03-16 15:20:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 15 loss:0.04918214678764343 norm:0.014719408936798573 max memory_allocated 49619.62158203125 
[2025-03-16 15:22:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 16 loss:0.049047909677028656 norm:0.015319538302719593 max memory_allocated 49619.62158203125 
[2025-03-16 15:23:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 17 loss:0.04886065423488617 norm:0.014332463964819908 max memory_allocated 49619.62158203125 
[2025-03-16 15:25:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 18 loss:0.048525068908929825 norm:0.012123708613216877 max memory_allocated 49619.62158203125 
[2025-03-16 15:26:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 19 loss:0.04848078265786171 norm:0.012571727856993675 max memory_allocated 49619.62158203125 
[2025-03-16 15:27:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 1 to 2 ===
[2025-03-16 15:28:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 0 loss:0.10756409913301468 norm:0.02839326672255993 max memory_allocated 49660.45751953125 
[2025-03-16 15:30:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 1 loss:0.08495573699474335 norm:0.02917211689054966 max memory_allocated 49660.45751953125 
[2025-03-16 15:31:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 2 loss:0.07522418349981308 norm:0.019831467419862747 max memory_allocated 49660.45751953125 
[2025-03-16 15:33:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 3 loss:0.06852555274963379 norm:0.018043112009763718 max memory_allocated 49660.45751953125 
[2025-03-16 15:34:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 4 loss:0.0638449490070343 norm:0.013235215097665787 max memory_allocated 49660.45751953125 
[2025-03-16 15:35:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 5 loss:0.061794713139534 norm:0.012134738266468048 max memory_allocated 49660.45751953125 
[2025-03-16 15:37:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 6 loss:0.06069568172097206 norm:0.01315197441726923 max memory_allocated 49660.45751953125 
[2025-03-16 15:38:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 7 loss:0.05917717143893242 norm:0.012213694863021374 max memory_allocated 49660.45751953125 
[2025-03-16 15:40:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 8 loss:0.058395735919475555 norm:0.011389851570129395 max memory_allocated 49660.45751953125 
[2025-03-16 15:41:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 9 loss:0.056784629821777344 norm:0.008769964799284935 max memory_allocated 49660.45751953125 
[2025-03-16 15:43:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 10 loss:0.056130439043045044 norm:0.008690557442605495 max memory_allocated 49660.45751953125 
[2025-03-16 15:44:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 11 loss:0.05592840164899826 norm:0.010193327441811562 max memory_allocated 49660.45751953125 
[2025-03-16 15:45:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 12 loss:0.05493631958961487 norm:0.008943231776356697 max memory_allocated 49660.45751953125 
[2025-03-16 15:47:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 13 loss:0.054593946784734726 norm:0.009724784642457962 max memory_allocated 49660.45751953125 
[2025-03-16 15:48:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 14 loss:0.054085779935121536 norm:0.008076181635260582 max memory_allocated 49660.45751953125 
[2025-03-16 15:50:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 15 loss:0.05339541286230087 norm:0.007448587100952864 max memory_allocated 49660.45751953125 
[2025-03-16 15:51:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 16 loss:0.05375618115067482 norm:0.008614872582256794 max memory_allocated 49660.45751953125 
[2025-03-16 15:52:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 17 loss:0.05330527946352959 norm:0.0077337538823485374 max memory_allocated 49660.45751953125 
[2025-03-16 15:54:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 18 loss:0.05346706137061119 norm:0.008329605683684349 max memory_allocated 49660.45751953125 
[2025-03-16 15:55:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 19 loss:0.05358683317899704 norm:0.007969974540174007 max memory_allocated 49660.45751953125 
[2025-03-16 15:56:35 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 2 to 3 ===
[2025-03-16 15:58:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 0 loss:0.08512724190950394 norm:0.013319013640284538 max memory_allocated 49660.45751953125 
[2025-03-16 15:59:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 1 loss:0.05297254025936127 norm:0.009699431248009205 max memory_allocated 49660.45751953125 
[2025-03-16 16:00:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 2 loss:0.0385260172188282 norm:0.006391729228198528 max memory_allocated 49660.45751953125 
[2025-03-16 16:02:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 3 loss:0.0333281010389328 norm:0.004064234439283609 max memory_allocated 49660.45751953125 
[2025-03-16 16:03:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 4 loss:0.03062450885772705 norm:0.0036027133464813232 max memory_allocated 49660.45751953125 
[2025-03-16 16:05:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 5 loss:0.029448257759213448 norm:0.003510523121803999 max memory_allocated 49660.45751953125 
[2025-03-16 16:06:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 6 loss:0.028160730376839638 norm:0.004103043116629124 max memory_allocated 49660.45751953125 
[2025-03-16 16:08:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 7 loss:0.027364762499928474 norm:0.0037159419152885675 max memory_allocated 49660.45751953125 
[2025-03-16 16:09:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 8 loss:0.026655957102775574 norm:0.0035936522763222456 max memory_allocated 49660.45751953125 
[2025-03-16 16:10:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 9 loss:0.026345714926719666 norm:0.004194882698357105 max memory_allocated 49660.45751953125 
[2025-03-16 16:12:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 10 loss:0.026170741766691208 norm:0.005116143263876438 max memory_allocated 49660.45751953125 
[2025-03-16 16:13:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 11 loss:0.026837408542633057 norm:0.006341292057186365 max memory_allocated 49660.45751953125 
[2025-03-16 16:15:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 12 loss:0.02618156373500824 norm:0.0049606068059802055 max memory_allocated 49660.45751953125 
[2025-03-16 16:16:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 13 loss:0.0261076632887125 norm:0.004215477034449577 max memory_allocated 49660.45751953125 
[2025-03-16 16:17:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 14 loss:0.026532988995313644 norm:0.005198915489017963 max memory_allocated 49660.45751953125 
[2025-03-16 16:19:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 15 loss:0.025885412469506264 norm:0.003971882630139589 max memory_allocated 49660.45751953125 
[2025-03-16 16:20:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 16 loss:0.026112057268619537 norm:0.004062748048454523 max memory_allocated 49660.45751953125 
[2025-03-16 16:22:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 17 loss:0.026168925687670708 norm:0.003895324422046542 max memory_allocated 49660.45751953125 
[2025-03-16 16:23:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 18 loss:0.026017017662525177 norm:0.004111879039555788 max memory_allocated 49660.45751953125 
[2025-03-16 16:24:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 19 loss:0.025726869702339172 norm:0.0037850530352443457 max memory_allocated 49660.45751953125 
[2025-03-16 16:25:45 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 3 to 4 ===
[2025-03-16 16:27:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 0 loss:0.04312190040946007 norm:0.00504325469955802 max memory_allocated 49661.39892578125 
[2025-03-16 16:28:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 1 loss:0.028129907324910164 norm:0.0017976185772567987 max memory_allocated 49661.39892578125 
[2025-03-16 16:30:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 2 loss:0.022155066952109337 norm:0.0010305718751624227 max memory_allocated 49661.39892578125 
[2025-03-16 16:31:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 3 loss:0.019666533917188644 norm:0.0007104293908923864 max memory_allocated 49661.39892578125 
[2025-03-16 16:32:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 4 loss:0.01847376860678196 norm:0.0005616575363092124 max memory_allocated 49661.39892578125 
[2025-03-16 16:34:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 5 loss:0.017613794654607773 norm:0.0004436889139469713 max memory_allocated 49661.39892578125 
[2025-03-16 16:35:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 6 loss:0.01705368608236313 norm:0.0004016974417027086 max memory_allocated 49661.39892578125 
[2025-03-16 16:37:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 7 loss:0.01666160859167576 norm:0.0003677521017380059 max memory_allocated 49661.39892578125 
[2025-03-16 16:38:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 8 loss:0.01638496294617653 norm:0.00034942038473673165 max memory_allocated 49661.39892578125 
[2025-03-16 16:39:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 9 loss:0.016170073300600052 norm:0.0003253823088016361 max memory_allocated 49661.39892578125 
[2025-03-16 16:41:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 10 loss:0.0160323828458786 norm:0.00030731878359802067 max memory_allocated 49661.39892578125 
[2025-03-16 16:42:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 11 loss:0.01591578871011734 norm:0.00029342170455493033 max memory_allocated 49661.39892578125 
[2025-03-16 16:44:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 12 loss:0.015820633620023727 norm:0.000284785230178386 max memory_allocated 49661.39892578125 
[2025-03-16 16:45:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 13 loss:0.015761621296405792 norm:0.00027743028476834297 max memory_allocated 49661.39892578125 
[2025-03-16 16:47:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 14 loss:0.015699733048677444 norm:0.0002672206610441208 max memory_allocated 49661.39892578125 
[2025-03-16 16:48:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 15 loss:0.015656039118766785 norm:0.0002714913571253419 max memory_allocated 49661.39892578125 
[2025-03-16 16:49:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 16 loss:0.015618343837559223 norm:0.00026330206310376525 max memory_allocated 49661.39892578125 
[2025-03-16 16:51:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 17 loss:0.01558554358780384 norm:0.0002567839983385056 max memory_allocated 49661.39892578125 
[2025-03-16 16:52:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 18 loss:0.015589887276291847 norm:0.000257337698712945 max memory_allocated 49661.39892578125 
[2025-03-16 16:54:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 19 loss:0.015580608509480953 norm:0.00025305713643319905 max memory_allocated 49661.39892578125 
[2025-03-16 16:54:54 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 4 to 5 ===
[2025-03-16 16:56:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 0 loss:0.05132884159684181 norm:0.009061813354492188 max memory_allocated 49661.39892578125 
[2025-03-16 16:57:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 1 loss:0.03398936614394188 norm:0.004088759887963533 max memory_allocated 49661.39892578125 
[2025-03-16 16:59:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 2 loss:0.02693835273385048 norm:0.0024620152544230223 max memory_allocated 49661.39892578125 
[2025-03-16 17:00:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 3 loss:0.023826073855161667 norm:0.001763387001119554 max memory_allocated 49661.39892578125 
[2025-03-16 17:02:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 4 loss:0.0222643855959177 norm:0.001351690269075334 max memory_allocated 49661.39892578125 
[2025-03-16 17:03:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 5 loss:0.021179866045713425 norm:0.0010851023253053427 max memory_allocated 49661.39892578125 
[2025-03-16 17:04:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 6 loss:0.020445801317691803 norm:0.000936084077693522 max memory_allocated 49661.39892578125 
[2025-03-16 17:06:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 7 loss:0.01992560364305973 norm:0.0007978823850862682 max memory_allocated 49661.39892578125 
[2025-03-16 17:07:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 8 loss:0.019592704251408577 norm:0.0006992664420977235 max memory_allocated 49661.39892578125 
[2025-03-16 17:09:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 9 loss:0.019335631281137466 norm:0.0006284590344876051 max memory_allocated 49661.39892578125 
[2025-03-16 17:10:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 10 loss:0.019215216860175133 norm:0.0005854573100805283 max memory_allocated 49661.39892578125 
[2025-03-16 17:11:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 11 loss:0.019094716757535934 norm:0.0005356930196285248 max memory_allocated 49661.39892578125 
[2025-03-16 17:13:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 12 loss:0.01900562271475792 norm:0.0004972745082341135 max memory_allocated 49661.39892578125 
[2025-03-16 17:14:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 13 loss:0.018880169838666916 norm:0.0004603152920026332 max memory_allocated 49661.39892578125 
[2025-03-16 17:16:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 14 loss:0.018893763422966003 norm:0.00043977334280498326 max memory_allocated 49661.39892578125 
[2025-03-16 17:17:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 15 loss:0.01889924518764019 norm:0.0004344905028119683 max memory_allocated 49661.39892578125 
[2025-03-16 17:19:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 16 loss:0.018913686275482178 norm:0.00038506934652104974 max memory_allocated 49661.39892578125 
[2025-03-16 17:20:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 17 loss:0.018874702975153923 norm:0.0003868773637805134 max memory_allocated 49661.39892578125 
[2025-03-16 17:21:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 18 loss:0.01884685643017292 norm:0.0003705128619913012 max memory_allocated 49661.39892578125 
[2025-03-16 17:23:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 19 loss:0.018781710416078568 norm:0.00035194281372241676 max memory_allocated 49661.39892578125 
[2025-03-16 17:24:03 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 5 to 6 ===
[2025-03-16 17:25:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 0 loss:0.09122933447360992 norm:0.010889464057981968 max memory_allocated 49661.77392578125 
[2025-03-16 17:26:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 1 loss:0.053005676716566086 norm:0.004020058084279299 max memory_allocated 49661.77392578125 
[2025-03-16 17:28:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 2 loss:0.03992048278450966 norm:0.0024415114894509315 max memory_allocated 49661.77392578125 
[2025-03-16 17:29:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 3 loss:0.03468465805053711 norm:0.0020362543873488903 max memory_allocated 49661.77392578125 
[2025-03-16 17:31:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 4 loss:0.031552381813526154 norm:0.001629875972867012 max memory_allocated 49661.77392578125 
[2025-03-16 17:32:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 5 loss:0.029455190524458885 norm:0.001493516261689365 max memory_allocated 49661.77392578125 
[2025-03-16 17:34:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 6 loss:0.028343116864562035 norm:0.0014065861469134688 max memory_allocated 49661.77392578125 
[2025-03-16 17:35:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 7 loss:0.027745794504880905 norm:0.0014741502236574888 max memory_allocated 49661.77392578125 
[2025-03-16 17:36:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 8 loss:0.027352090924978256 norm:0.001350113656371832 max memory_allocated 49661.77392578125 
[2025-03-16 17:38:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 9 loss:0.025827715173363686 norm:0.0010917691979557276 max memory_allocated 49661.77392578125 
[2025-03-16 17:39:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 10 loss:0.025583477690815926 norm:0.0010077228071168065 max memory_allocated 49661.77392578125 
[2025-03-16 17:41:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 11 loss:0.02495984174311161 norm:0.000916825607419014 max memory_allocated 49661.77392578125 
[2025-03-16 17:42:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 12 loss:0.025459906086325645 norm:0.001182751846499741 max memory_allocated 49661.77392578125 
[2025-03-16 17:43:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 13 loss:0.02450796589255333 norm:0.001078455476090312 max memory_allocated 49661.77392578125 
[2025-03-16 17:45:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 14 loss:0.024568885564804077 norm:0.0011270692339166999 max memory_allocated 49661.77392578125 
[2025-03-16 17:46:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 15 loss:0.023952482268214226 norm:0.000988048268482089 max memory_allocated 49661.77392578125 
[2025-03-16 17:48:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 16 loss:0.023990448564291 norm:0.0009961557807400823 max memory_allocated 49661.77392578125 
[2025-03-16 17:49:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 17 loss:0.023892048746347427 norm:0.0010662359418347478 max memory_allocated 49661.77392578125 
[2025-03-16 17:51:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 18 loss:0.024285195395350456 norm:0.0011409149738028646 max memory_allocated 49661.77392578125 
[2025-03-16 17:52:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 19 loss:0.02359580062329769 norm:0.0009879833087325096 max memory_allocated 49661.77392578125 
[2025-03-16 17:53:12 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 6 to 7 ===
[2025-03-16 17:54:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 0 loss:0.059209682047367096 norm:0.0033678761683404446 max memory_allocated 49661.77392578125 
[2025-03-16 17:56:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 1 loss:0.03609136864542961 norm:0.001409416669048369 max memory_allocated 49661.77392578125 
[2025-03-16 17:57:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 2 loss:0.028199169784784317 norm:0.0007604503189213574 max memory_allocated 49661.77392578125 
[2025-03-16 17:58:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 3 loss:0.02514239400625229 norm:0.0005752372089773417 max memory_allocated 49661.77392578125 
[2025-03-16 18:00:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 4 loss:0.023689478635787964 norm:0.0004928138805553317 max memory_allocated 49661.77392578125 
[2025-03-16 18:01:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 5 loss:0.02273467369377613 norm:0.0004640922124963254 max memory_allocated 49661.77392578125 
[2025-03-16 18:03:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 6 loss:0.022068578749895096 norm:0.0004410615365486592 max memory_allocated 49661.77392578125 
[2025-03-16 18:04:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 7 loss:0.02149369940161705 norm:0.0004068321723025292 max memory_allocated 49661.77392578125 
[2025-03-16 18:06:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 8 loss:0.02103632502257824 norm:0.00038699095603078604 max memory_allocated 49661.77392578125 
[2025-03-16 18:07:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 9 loss:0.020773181691765785 norm:0.00035574802313931286 max memory_allocated 49661.77392578125 
[2025-03-16 18:08:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 10 loss:0.020693494006991386 norm:0.0003405319876037538 max memory_allocated 49661.77392578125 
[2025-03-16 18:10:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 11 loss:0.02062665857374668 norm:0.0003574646543711424 max memory_allocated 49661.77392578125 
[2025-03-16 18:11:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 12 loss:0.020533403381705284 norm:0.00035596598172560334 max memory_allocated 49661.77392578125 
[2025-03-16 18:13:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 13 loss:0.020344026386737823 norm:0.00034311824128963053 max memory_allocated 49661.77392578125 
[2025-03-16 18:14:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 14 loss:0.020897146314382553 norm:0.00037556246388703585 max memory_allocated 49661.77392578125 
[2025-03-16 18:15:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 15 loss:0.020820334553718567 norm:0.00037853483809158206 max memory_allocated 49661.77392578125 
[2025-03-16 18:17:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 16 loss:0.020135486498475075 norm:0.0003614305751398206 max memory_allocated 49661.77392578125 
[2025-03-16 18:18:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 17 loss:0.020037837326526642 norm:0.00034230202436447144 max memory_allocated 49661.77392578125 
[2025-03-16 18:20:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 18 loss:0.020045584067702293 norm:0.00036858004750683904 max memory_allocated 49661.77392578125 
[2025-03-16 18:21:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 19 loss:0.019902825355529785 norm:0.0003406479663681239 max memory_allocated 49661.77392578125 
[2025-03-16 18:22:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 7 to 8 ===
[2025-03-16 18:23:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 0 loss:0.04396197944879532 norm:0.002540816552937031 max memory_allocated 49661.77392578125 
[2025-03-16 18:25:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 1 loss:0.03109912760555744 norm:0.0010320466244593263 max memory_allocated 49661.77392578125 
[2025-03-16 18:26:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 2 loss:0.02576744370162487 norm:0.0005826394190080464 max memory_allocated 49661.77392578125 
[2025-03-16 18:28:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 3 loss:0.023284267634153366 norm:0.0003915022243745625 max memory_allocated 49661.77392578125 
[2025-03-16 18:29:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 4 loss:0.02204594388604164 norm:0.00032296718563884497 max memory_allocated 49661.77392578125 
[2025-03-16 18:30:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 5 loss:0.02130526676774025 norm:0.0002900758117903024 max memory_allocated 49661.77392578125 
[2025-03-16 18:32:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 6 loss:0.020855464041233063 norm:0.00027129275258630514 max memory_allocated 49661.77392578125 
[2025-03-16 18:33:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 7 loss:0.020519180223345757 norm:0.0002576767292339355 max memory_allocated 49661.77392578125 
[2025-03-16 18:35:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 8 loss:0.020279066637158394 norm:0.0002447505248710513 max memory_allocated 49661.77392578125 
[2025-03-16 18:36:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 9 loss:0.020131798461079597 norm:0.00023819715715944767 max memory_allocated 49661.77392578125 
[2025-03-16 18:38:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 10 loss:0.020017419010400772 norm:0.00023180786229204386 max memory_allocated 49661.77392578125 
[2025-03-16 18:39:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 11 loss:0.019930662587285042 norm:0.000224289033212699 max memory_allocated 49661.77392578125 
[2025-03-16 18:40:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 12 loss:0.01988513581454754 norm:0.00022033390996512026 max memory_allocated 49661.77392578125 
[2025-03-16 18:42:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 13 loss:0.019843777641654015 norm:0.0002170815278077498 max memory_allocated 49661.77392578125 
[2025-03-16 18:43:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 14 loss:0.019830306991934776 norm:0.00021256835316307843 max memory_allocated 49661.77392578125 
[2025-03-16 18:45:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 15 loss:0.019828874617815018 norm:0.00020939804380759597 max memory_allocated 49661.77392578125 
[2025-03-16 18:46:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 16 loss:0.019820863381028175 norm:0.00021086203923914582 max memory_allocated 49661.77392578125 
[2025-03-16 18:47:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 17 loss:0.019852744415402412 norm:0.00021005921007599682 max memory_allocated 49661.77392578125 
[2025-03-16 18:49:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 18 loss:0.01985933631658554 norm:0.0002058652462437749 max memory_allocated 49661.77392578125 
[2025-03-16 18:50:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 19 loss:0.01984439045190811 norm:0.00020689418306574225 max memory_allocated 49661.77392578125 
[2025-03-16 18:51:31 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 8 to 9 ===
[2025-03-16 18:53:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 0 loss:0.051759593188762665 norm:0.0028123471420258284 max memory_allocated 49661.77392578125 
[2025-03-16 18:54:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 1 loss:0.03244679421186447 norm:0.0009999858448281884 max memory_allocated 49661.77392578125 
[2025-03-16 18:55:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 2 loss:0.026805803179740906 norm:0.0006113646668381989 max memory_allocated 49661.77392578125 
[2025-03-16 18:57:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 3 loss:0.024218618869781494 norm:0.0004781919706147164 max memory_allocated 49661.77392578125 
[2025-03-16 18:58:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 4 loss:0.022819140926003456 norm:0.0004116964410059154 max memory_allocated 49661.77392578125 
[2025-03-16 19:00:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 5 loss:0.021922390908002853 norm:0.00037165998946875334 max memory_allocated 49661.77392578125 
[2025-03-16 19:01:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 6 loss:0.021315326914191246 norm:0.0003513760748319328 max memory_allocated 49661.77392578125 
[2025-03-16 19:02:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 7 loss:0.020839540287852287 norm:0.00033333461033180356 max memory_allocated 49661.77392578125 
[2025-03-16 19:04:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 8 loss:0.020506974309682846 norm:0.0003183322842232883 max memory_allocated 49661.77392578125 
[2025-03-16 19:05:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 9 loss:0.02026013657450676 norm:0.0003057013964280486 max memory_allocated 49661.77392578125 
[2025-03-16 19:07:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 10 loss:0.020083636045455933 norm:0.00028796668630093336 max memory_allocated 49661.77392578125 
[2025-03-16 19:08:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 11 loss:0.01992334984242916 norm:0.0002754143497440964 max memory_allocated 49661.77392578125 
[2025-03-16 19:10:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 12 loss:0.019785387441515923 norm:0.0002604163601063192 max memory_allocated 49661.77392578125 
[2025-03-16 19:11:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 13 loss:0.019675053656101227 norm:0.0002504332805983722 max memory_allocated 49661.77392578125 
[2025-03-16 19:12:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 14 loss:0.01960161328315735 norm:0.0002459466631989926 max memory_allocated 49661.77392578125 
[2025-03-16 19:14:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 15 loss:0.019531933590769768 norm:0.00023786633391864598 max memory_allocated 49661.77392578125 
[2025-03-16 19:15:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 16 loss:0.019484257325530052 norm:0.00023159367265179753 max memory_allocated 49661.77392578125 
[2025-03-16 19:17:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 17 loss:0.0194393377751112 norm:0.0002254895807709545 max memory_allocated 49661.77392578125 
[2025-03-16 19:18:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 18 loss:0.0194100234657526 norm:0.00022237098892219365 max memory_allocated 49661.77392578125 
[2025-03-16 19:19:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 19 loss:0.019367769360542297 norm:0.0002176041016355157 max memory_allocated 49661.77392578125 
[2025-03-16 19:20:40 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 9 to 10 ===
[2025-03-16 19:22:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 0 loss:0.041014157235622406 norm:0.0016237023519352078 max memory_allocated 49661.77392578125 
[2025-03-16 19:23:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 1 loss:0.03139042481780052 norm:0.0007349253864958882 max memory_allocated 49661.77392578125 
[2025-03-16 19:25:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 2 loss:0.02677399478852749 norm:0.0004493510059546679 max memory_allocated 49661.77392578125 
[2025-03-16 19:26:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 3 loss:0.024737004190683365 norm:0.0003391386999282986 max memory_allocated 49661.77392578125 
[2025-03-16 19:27:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 4 loss:0.023807112127542496 norm:0.00029045503470115364 max memory_allocated 49661.77392578125 
[2025-03-16 19:29:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 5 loss:0.023249097168445587 norm:0.00025721959536895156 max memory_allocated 49661.77392578125 
[2025-03-16 19:30:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 6 loss:0.022859619930386543 norm:0.00023751234402880073 max memory_allocated 49661.77392578125 
[2025-03-16 19:32:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 7 loss:0.022587619721889496 norm:0.00022910602274350822 max memory_allocated 49661.77392578125 
[2025-03-16 19:33:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 8 loss:0.02239573746919632 norm:0.00022114095918368548 max memory_allocated 49661.77392578125 
[2025-03-16 19:34:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 9 loss:0.022312985733151436 norm:0.00021414538787212223 max memory_allocated 49661.77392578125 
[2025-03-16 19:36:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 10 loss:0.02224935218691826 norm:0.00020752009004354477 max memory_allocated 49661.77392578125 
[2025-03-16 19:37:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 11 loss:0.02222416363656521 norm:0.000200595663045533 max memory_allocated 49661.77392578125 
[2025-03-16 19:39:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 12 loss:0.022228233516216278 norm:0.00019667854940053076 max memory_allocated 49661.77392578125 
[2025-03-16 19:40:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 13 loss:0.022207196801900864 norm:0.00019146666454616934 max memory_allocated 49661.77392578125 
[2025-03-16 19:41:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 14 loss:0.022297434508800507 norm:0.00019048285321332514 max memory_allocated 49661.77392578125 
[2025-03-16 19:43:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 15 loss:0.02226564846932888 norm:0.00018953242397401482 max memory_allocated 49661.77392578125 
[2025-03-16 19:44:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 16 loss:0.022258173674345016 norm:0.0001910039281938225 max memory_allocated 49661.77392578125 
[2025-03-16 19:46:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 17 loss:0.022225718945264816 norm:0.00018854472727980465 max memory_allocated 49661.77392578125 
[2025-03-16 19:47:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 18 loss:0.022234732285141945 norm:0.00018696241022553295 max memory_allocated 49661.77392578125 
[2025-03-16 19:49:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 19 loss:0.022234579548239708 norm:0.00018605835794005543 max memory_allocated 49661.77392578125 
[2025-03-16 19:49:49 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 10 to 11 ===
[2025-03-16 19:51:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 0 loss:0.06680501997470856 norm:0.00329902907833457 max memory_allocated 49661.77392578125 
[2025-03-16 19:52:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 1 loss:0.03800220414996147 norm:0.0009803667198866606 max memory_allocated 49661.77392578125 
[2025-03-16 19:54:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 2 loss:0.030649108812212944 norm:0.0005690663238056004 max memory_allocated 49661.77392578125 
[2025-03-16 19:55:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 3 loss:0.027580557391047478 norm:0.000447489699581638 max memory_allocated 49661.77392578125 
[2025-03-16 19:57:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 4 loss:0.02610446885228157 norm:0.00041197199607267976 max memory_allocated 49661.77392578125 
[2025-03-16 19:58:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 5 loss:0.025193950161337852 norm:0.00041688914643600583 max memory_allocated 49661.77392578125 
[2025-03-16 19:59:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 6 loss:0.024521492421627045 norm:0.00041335917194373906 max memory_allocated 49661.77392578125 
[2025-03-16 20:01:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 7 loss:0.02403603121638298 norm:0.00040284785791300237 max memory_allocated 49661.77392578125 
[2025-03-16 20:02:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 8 loss:0.023662421852350235 norm:0.000381958088837564 max memory_allocated 49661.77392578125 
[2025-03-16 20:04:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 9 loss:0.023394053801894188 norm:0.0003563110076356679 max memory_allocated 49661.77392578125 
[2025-03-16 20:05:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 10 loss:0.023182539269328117 norm:0.0003334441571496427 max memory_allocated 49661.77392578125 
[2025-03-16 20:06:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 11 loss:0.022999245673418045 norm:0.0003109387762378901 max memory_allocated 49661.77392578125 
[2025-03-16 20:08:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 12 loss:0.022875314578413963 norm:0.00029160562553443015 max memory_allocated 49661.77392578125 
[2025-03-16 20:09:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 13 loss:0.022751275449991226 norm:0.00027383072301745415 max memory_allocated 49661.77392578125 
[2025-03-16 20:11:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 14 loss:0.02265472523868084 norm:0.00026001836522482336 max memory_allocated 49661.77392578125 
[2025-03-16 20:12:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 15 loss:0.022574923932552338 norm:0.00025047874078154564 max memory_allocated 49661.77392578125 
[2025-03-16 20:13:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 16 loss:0.022533897310495377 norm:0.0002405193808954209 max memory_allocated 49661.77392578125 
[2025-03-16 20:15:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 17 loss:0.022485267370939255 norm:0.00023396129836328328 max memory_allocated 49661.77392578125 
[2025-03-16 20:16:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 18 loss:0.022432394325733185 norm:0.00023019731452222914 max memory_allocated 49661.77392578125 
[2025-03-16 20:18:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 19 loss:0.022406525909900665 norm:0.00022577667550649494 max memory_allocated 49661.77392578125 
[2025-03-16 20:18:57 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 11 to 12 ===
[2025-03-16 20:20:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 0 loss:0.0435081347823143 norm:0.0014043275732547045 max memory_allocated 49661.89892578125 
[2025-03-16 20:21:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 1 loss:0.03334471583366394 norm:0.0006369311013258994 max memory_allocated 49661.89892578125 
[2025-03-16 20:23:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 2 loss:0.028224708512425423 norm:0.00040051373071037233 max memory_allocated 49661.89892578125 
[2025-03-16 20:24:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 3 loss:0.026026476174592972 norm:0.0003030526568181813 max memory_allocated 49661.89892578125 
[2025-03-16 20:26:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 4 loss:0.025055238977074623 norm:0.0002587303752079606 max memory_allocated 49661.89892578125 
[2025-03-16 20:27:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 5 loss:0.024402529001235962 norm:0.00023202376905828714 max memory_allocated 49661.89892578125 
[2025-03-16 20:28:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 6 loss:0.023941053077578545 norm:0.000216509128222242 max memory_allocated 49661.89892578125 
[2025-03-16 20:30:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 7 loss:0.023621680215001106 norm:0.00020897664944641292 max memory_allocated 49661.89892578125 
[2025-03-16 20:31:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 8 loss:0.02339954674243927 norm:0.00020301424956414849 max memory_allocated 49661.89892578125 
[2025-03-16 20:33:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 9 loss:0.023253899067640305 norm:0.0001962081150850281 max memory_allocated 49661.89892578125 
[2025-03-16 20:34:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 10 loss:0.023155536502599716 norm:0.00019391110981814563 max memory_allocated 49661.89892578125 
[2025-03-16 20:36:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 11 loss:0.02307993918657303 norm:0.00018892592925112695 max memory_allocated 49661.89892578125 
[2025-03-16 20:37:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 12 loss:0.0230314452201128 norm:0.00018580314645078033 max memory_allocated 49661.89892578125 
[2025-03-16 20:38:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 13 loss:0.022982340306043625 norm:0.00018285437545273453 max memory_allocated 49661.89892578125 
[2025-03-16 20:40:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 14 loss:0.022951588034629822 norm:0.00018240741337649524 max memory_allocated 49661.89892578125 
[2025-03-16 20:41:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 15 loss:0.02293032594025135 norm:0.0001819053286453709 max memory_allocated 49661.89892578125 
[2025-03-16 20:43:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 16 loss:0.022896109148859978 norm:0.00018004023877438158 max memory_allocated 49661.89892578125 
[2025-03-16 20:44:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 17 loss:0.022871851921081543 norm:0.0001799902383936569 max memory_allocated 49661.89892578125 
[2025-03-16 20:45:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 18 loss:0.02285473793745041 norm:0.00018006650498136878 max memory_allocated 49661.89892578125 
[2025-03-16 20:47:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 19 loss:0.0228443406522274 norm:0.00017992081120610237 max memory_allocated 49661.89892578125 
[2025-03-16 20:48:02 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 12 to 13 ===
[2025-03-16 20:49:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 0 loss:0.046221811324357986 norm:0.0013398301089182496 max memory_allocated 49662.08642578125 
[2025-03-16 20:50:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 1 loss:0.03616645932197571 norm:0.0006714608753100038 max memory_allocated 49662.08642578125 
[2025-03-16 20:52:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 2 loss:0.03093327209353447 norm:0.00045325778773985803 max memory_allocated 49662.08642578125 
[2025-03-16 20:53:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 3 loss:0.028644748032093048 norm:0.00035832475987263024 max memory_allocated 49662.08642578125 
[2025-03-16 20:55:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 4 loss:0.02750561758875847 norm:0.0003091723774559796 max memory_allocated 49662.08642578125 
[2025-03-16 20:56:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 5 loss:0.02675662934780121 norm:0.0002819057845044881 max memory_allocated 49662.08642578125 
[2025-03-16 20:58:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 6 loss:0.02622445672750473 norm:0.00026127052842639387 max memory_allocated 49662.08642578125 
[2025-03-16 20:59:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 7 loss:0.025871675461530685 norm:0.00025265361182391644 max memory_allocated 49662.08642578125 
[2025-03-16 21:00:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 8 loss:0.02562663145363331 norm:0.00023995609080884606 max memory_allocated 49662.08642578125 
[2025-03-16 21:02:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 9 loss:0.025460733100771904 norm:0.000237879270571284 max memory_allocated 49662.08642578125 
[2025-03-16 21:03:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 10 loss:0.025329547002911568 norm:0.0002336519828531891 max memory_allocated 49662.08642578125 
[2025-03-16 21:05:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 11 loss:0.02524191327393055 norm:0.00023136186064220965 max memory_allocated 49662.08642578125 
[2025-03-16 21:06:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 12 loss:0.025176551192998886 norm:0.00022092496510595083 max memory_allocated 49662.08642578125 
[2025-03-16 21:07:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 13 loss:0.025135207921266556 norm:0.00021433313668239862 max memory_allocated 49662.08642578125 
[2025-03-16 21:09:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 14 loss:0.02509997971355915 norm:0.0002132462541339919 max memory_allocated 49662.08642578125 
[2025-03-16 21:10:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 15 loss:0.025083772838115692 norm:0.0002072096976917237 max memory_allocated 49662.08642578125 
[2025-03-16 21:12:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 16 loss:0.02507248893380165 norm:0.0002059503603959456 max memory_allocated 49662.08642578125 
[2025-03-16 21:13:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 17 loss:0.025062378495931625 norm:0.00020600286370608956 max memory_allocated 49662.08642578125 
[2025-03-16 21:14:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 18 loss:0.025055143982172012 norm:0.00020460027735680342 max memory_allocated 49662.08642578125 
[2025-03-16 21:16:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 19 loss:0.025055192410945892 norm:0.00020460069936234504 max memory_allocated 49662.08642578125 
[2025-03-16 21:17:04 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 13 to 14 ===
[2025-03-16 21:18:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 0 loss:0.05271003395318985 norm:0.0019759817514568567 max memory_allocated 49662.27392578125 
[2025-03-16 21:19:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 1 loss:0.04150032997131348 norm:0.0008869868470355868 max memory_allocated 49662.27392578125 
[2025-03-16 21:21:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 2 loss:0.035036277025938034 norm:0.0005642118630930781 max memory_allocated 49662.27392578125 
[2025-03-16 21:22:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 3 loss:0.032521143555641174 norm:0.0004412753914948553 max memory_allocated 49662.27392578125 
[2025-03-16 21:24:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 4 loss:0.03127250447869301 norm:0.00037144921952858567 max memory_allocated 49662.27392578125 
[2025-03-16 21:25:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 5 loss:0.030469512566924095 norm:0.0003235936746932566 max memory_allocated 49662.27392578125 
[2025-03-16 21:27:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 6 loss:0.029931258410215378 norm:0.00029765471117570996 max memory_allocated 49662.27392578125 
[2025-03-16 21:28:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 7 loss:0.02960076555609703 norm:0.0002792190934997052 max memory_allocated 49662.27392578125 
[2025-03-16 21:29:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 8 loss:0.029425786808133125 norm:0.00027015156229026616 max memory_allocated 49662.27392578125 
[2025-03-16 21:31:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 9 loss:0.029330503195524216 norm:0.0002650363021530211 max memory_allocated 49662.27392578125 
[2025-03-16 21:32:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 10 loss:0.029212109744548798 norm:0.0002538034168537706 max memory_allocated 49662.27392578125 
[2025-03-16 21:34:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 11 loss:0.02918463945388794 norm:0.0002493398205842823 max memory_allocated 49662.27392578125 
[2025-03-16 21:35:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 12 loss:0.02918068878352642 norm:0.00024918169947341084 max memory_allocated 49662.27392578125 
[2025-03-16 21:36:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 13 loss:0.029151352122426033 norm:0.00024175165162887424 max memory_allocated 49662.27392578125 
[2025-03-16 21:38:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 14 loss:0.029132770374417305 norm:0.00024440608103759587 max memory_allocated 49662.27392578125 
[2025-03-16 21:39:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 15 loss:0.0291434358805418 norm:0.00023999082623049617 max memory_allocated 49662.27392578125 
[2025-03-16 21:41:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 16 loss:0.029155222699046135 norm:0.00023746276565361768 max memory_allocated 49662.27392578125 
[2025-03-16 21:42:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 17 loss:0.029135629534721375 norm:0.00023590261116623878 max memory_allocated 49662.27392578125 
[2025-03-16 21:43:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 18 loss:0.029120804741978645 norm:0.00023423896345775574 max memory_allocated 49662.27392578125 
[2025-03-16 21:45:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 19 loss:0.029115043580532074 norm:0.00023432806483469903 max memory_allocated 49662.27392578125 
[2025-03-16 21:46:06 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 14 to 15 ===
[2025-03-16 21:47:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 0 loss:0.06932356208562851 norm:0.002951129339635372 max memory_allocated 49662.46142578125 
[2025-03-16 21:49:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 1 loss:0.04471025615930557 norm:0.0009635066380724311 max memory_allocated 49662.46142578125 
[2025-03-16 21:50:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 2 loss:0.03732024505734444 norm:0.0006437396514229476 max memory_allocated 49662.46142578125 
[2025-03-16 21:51:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 3 loss:0.03443298861384392 norm:0.0005336934700608253 max memory_allocated 49662.46142578125 
[2025-03-16 21:53:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 4 loss:0.032745204865932465 norm:0.000486779201310128 max memory_allocated 49662.46142578125 
[2025-03-16 21:54:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 5 loss:0.03167835250496864 norm:0.0004676255048252642 max memory_allocated 49662.46142578125 
[2025-03-16 21:56:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 6 loss:0.030910976231098175 norm:0.00044918563799001276 max memory_allocated 49662.46142578125 
[2025-03-16 21:57:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 7 loss:0.030385496094822884 norm:0.00041954152402468026 max memory_allocated 49662.46142578125 
[2025-03-16 21:58:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 8 loss:0.030058860778808594 norm:0.0004045738896820694 max memory_allocated 49662.46142578125 
[2025-03-16 22:00:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 9 loss:0.029767204076051712 norm:0.00038498881622217596 max memory_allocated 49662.46142578125 
[2025-03-16 22:01:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 10 loss:0.029565101489424706 norm:0.00037008541403338313 max memory_allocated 49662.46142578125 
[2025-03-16 22:03:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 11 loss:0.02942805178463459 norm:0.0003541072946973145 max memory_allocated 49662.46142578125 
[2025-03-16 22:04:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 12 loss:0.02930431067943573 norm:0.0003412077494431287 max memory_allocated 49662.46142578125 
[2025-03-16 22:05:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 13 loss:0.02919389121234417 norm:0.0003269433800596744 max memory_allocated 49662.46142578125 
[2025-03-16 22:07:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 14 loss:0.02910412847995758 norm:0.00031846979982219636 max memory_allocated 49662.46142578125 
[2025-03-16 22:08:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 15 loss:0.029048126190900803 norm:0.0003101371112279594 max memory_allocated 49662.46142578125 
[2025-03-16 22:10:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 16 loss:0.02896275371313095 norm:0.00030292599694803357 max memory_allocated 49662.46142578125 
[2025-03-16 22:11:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 17 loss:0.028924793004989624 norm:0.00029692851239815354 max memory_allocated 49662.46142578125 
[2025-03-16 22:12:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 18 loss:0.028890006244182587 norm:0.00029186601750552654 max memory_allocated 49662.46142578125 
[2025-03-16 22:14:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 19 loss:0.02886003442108631 norm:0.000287771865259856 max memory_allocated 49662.46142578125 
[2025-03-16 22:15:09 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 15 to 16 ===
[2025-03-16 22:16:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 0 loss:0.052318770438432693 norm:0.0019103055819869041 max memory_allocated 49662.64892578125 
[2025-03-16 22:18:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 1 loss:0.04345050826668739 norm:0.0010209294268861413 max memory_allocated 49662.64892578125 
[2025-03-16 22:19:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 2 loss:0.037688545882701874 norm:0.000677009578794241 max memory_allocated 49662.64892578125 
[2025-03-16 22:20:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 3 loss:0.03533826023340225 norm:0.0005341563373804092 max memory_allocated 49662.64892578125 
[2025-03-16 22:22:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 4 loss:0.03409665450453758 norm:0.00045788369607180357 max memory_allocated 49662.64892578125 
[2025-03-16 22:23:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 5 loss:0.03333409130573273 norm:0.00041786552174016833 max memory_allocated 49662.64892578125 
[2025-03-16 22:25:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 6 loss:0.03287794440984726 norm:0.0003725865390151739 max memory_allocated 49662.64892578125 
[2025-03-16 22:26:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 7 loss:0.03253616765141487 norm:0.00034738623071461916 max memory_allocated 49662.64892578125 
[2025-03-16 22:27:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 8 loss:0.03231067955493927 norm:0.00032646817271597683 max memory_allocated 49662.64892578125 
[2025-03-16 22:29:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 9 loss:0.0321517139673233 norm:0.0003143027424812317 max memory_allocated 49662.64892578125 
[2025-03-16 22:30:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 10 loss:0.032117173075675964 norm:0.0003088870726060122 max memory_allocated 49662.64892578125 
[2025-03-16 22:32:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 11 loss:0.032114334404468536 norm:0.00030461669666692615 max memory_allocated 49662.64892578125 
[2025-03-16 22:33:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 12 loss:0.032077088952064514 norm:0.00028926957747898996 max memory_allocated 49662.64892578125 
[2025-03-16 22:34:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 13 loss:0.03205553814768791 norm:0.0002846370916813612 max memory_allocated 49662.64892578125 
[2025-03-16 22:36:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 14 loss:0.03205250948667526 norm:0.0002811388112604618 max memory_allocated 49662.64892578125 
[2025-03-16 22:37:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 15 loss:0.032059572637081146 norm:0.00027637870516628027 max memory_allocated 49662.64892578125 
[2025-03-16 22:39:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 16 loss:0.032063037157058716 norm:0.0002748001425061375 max memory_allocated 49662.64892578125 
[2025-03-16 22:40:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 17 loss:0.03204640746116638 norm:0.0002740244963206351 max memory_allocated 49662.64892578125 
[2025-03-16 22:42:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 18 loss:0.03205486387014389 norm:0.000271358439931646 max memory_allocated 49662.64892578125 
[2025-03-16 22:43:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 19 loss:0.032060056924819946 norm:0.0002693918067961931 max memory_allocated 49662.64892578125 
[2025-03-16 22:44:14 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 16 to 17 ===
[2025-03-16 22:45:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 0 loss:0.09903328120708466 norm:0.012002943083643913 max memory_allocated 49662.83642578125 
[2025-03-16 22:47:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 1 loss:0.050176411867141724 norm:0.0016919452464208007 max memory_allocated 49663.83642578125 
[2025-03-16 22:48:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 2 loss:0.040344201028347015 norm:0.000846773327793926 max memory_allocated 49663.83642578125 
[2025-03-16 22:50:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 3 loss:0.03692806139588356 norm:0.0006706459680572152 max memory_allocated 49663.83642578125 
[2025-03-16 22:51:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 4 loss:0.03499279171228409 norm:0.0005945080774836242 max memory_allocated 49663.83642578125 
[2025-03-16 22:52:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 5 loss:0.03374927490949631 norm:0.0005516801029443741 max memory_allocated 49663.83642578125 
[2025-03-16 22:54:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 6 loss:0.032947201281785965 norm:0.0005230854148976505 max memory_allocated 49663.83642578125 
[2025-03-16 22:55:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 7 loss:0.03242935240268707 norm:0.00050068594282493 max memory_allocated 49663.83642578125 
[2025-03-16 22:57:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 8 loss:0.032114069908857346 norm:0.0004965621628798544 max memory_allocated 49663.83642578125 
[2025-03-16 22:58:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 9 loss:0.031901679933071136 norm:0.0004997780779376626 max memory_allocated 49663.83642578125 
[2025-03-16 22:59:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 10 loss:0.03166014328598976 norm:0.00048682201304472983 max memory_allocated 49663.83642578125 
[2025-03-16 23:01:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 11 loss:0.03147159144282341 norm:0.00047347843064926565 max memory_allocated 49663.83642578125 
[2025-03-16 23:02:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 12 loss:0.03131350129842758 norm:0.00046038252185098827 max memory_allocated 49663.83642578125 
[2025-03-16 23:04:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 13 loss:0.031190551817417145 norm:0.00044627103488892317 max memory_allocated 49663.83642578125 
[2025-03-16 23:05:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 14 loss:0.031017404049634933 norm:0.00042993127135559916 max memory_allocated 49663.83642578125 
[2025-03-16 23:06:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 15 loss:0.030893247574567795 norm:0.0004068399721290916 max memory_allocated 49663.83642578125 
[2025-03-16 23:08:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 16 loss:0.030789077281951904 norm:0.00039313736488111317 max memory_allocated 49663.83642578125 
[2025-03-16 23:09:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 17 loss:0.03066573105752468 norm:0.00037683910341002047 max memory_allocated 49663.83642578125 
[2025-03-16 23:11:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 18 loss:0.030577480792999268 norm:0.0003672202583402395 max memory_allocated 49663.83642578125 
[2025-03-16 23:12:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 19 loss:0.03051692247390747 norm:0.0003608111583162099 max memory_allocated 49663.83642578125 
[2025-03-16 23:13:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 17 to 18 ===
[2025-03-16 23:14:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 0 loss:0.05673157051205635 norm:0.0023257615976035595 max memory_allocated 49663.83642578125 
[2025-03-16 23:16:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 1 loss:0.04595618695020676 norm:0.0010020697955042124 max memory_allocated 49663.83642578125 
[2025-03-16 23:17:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 2 loss:0.0393529087305069 norm:0.0006387041648849845 max memory_allocated 49663.83642578125 
[2025-03-16 23:19:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 3 loss:0.03686707094311714 norm:0.0004901581560261548 max memory_allocated 49663.83642578125 
[2025-03-16 23:20:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 4 loss:0.03547337278723717 norm:0.00040912642725743353 max memory_allocated 49663.83642578125 
[2025-03-16 23:21:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 5 loss:0.03464639186859131 norm:0.00035910014412365854 max memory_allocated 49663.83642578125 
[2025-03-16 23:23:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 6 loss:0.03418227285146713 norm:0.00032951729372143745 max memory_allocated 49663.83642578125 
[2025-03-16 23:24:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 7 loss:0.03394694998860359 norm:0.0003144669462926686 max memory_allocated 49663.83642578125 
[2025-03-16 23:26:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 8 loss:0.03379198908805847 norm:0.0003013446112163365 max memory_allocated 49663.83642578125 
[2025-03-16 23:27:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 9 loss:0.03363538160920143 norm:0.0002929572365246713 max memory_allocated 49663.83642578125 
[2025-03-16 23:28:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 10 loss:0.03351566195487976 norm:0.00028621937963180244 max memory_allocated 49663.83642578125 
[2025-03-16 23:30:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 11 loss:0.03342036157846451 norm:0.0002766642428468913 max memory_allocated 49663.83642578125 
[2025-03-16 23:31:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 12 loss:0.033353108912706375 norm:0.0002747348917182535 max memory_allocated 49663.83642578125 
[2025-03-16 23:33:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 13 loss:0.03329668566584587 norm:0.0002735844755079597 max memory_allocated 49663.83642578125 
[2025-03-16 23:34:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 14 loss:0.03323487937450409 norm:0.00027054769452661276 max memory_allocated 49663.83642578125 
[2025-03-16 23:36:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 15 loss:0.03318276256322861 norm:0.00027297998894937336 max memory_allocated 49663.83642578125 
[2025-03-16 23:37:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 16 loss:0.03313417732715607 norm:0.0002925101143773645 max memory_allocated 49663.83642578125 
[2025-03-16 23:38:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 17 loss:0.0330553762614727 norm:0.0002631361421663314 max memory_allocated 49663.83642578125 
[2025-03-16 23:40:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 18 loss:0.0330260694026947 norm:0.000260391941992566 max memory_allocated 49663.83642578125 
[2025-03-16 23:41:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 19 loss:0.032989177852869034 norm:0.00025891882251016796 max memory_allocated 49663.83642578125 
[2025-03-16 23:42:27 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 18 to 19 ===
[2025-03-16 23:43:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 0 loss:0.060501471161842346 norm:0.0021201157942414284 max memory_allocated 49664.21142578125 
[2025-03-16 23:45:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 1 loss:0.04988595470786095 norm:0.0009326049475930631 max memory_allocated 49664.21142578125 
[2025-03-16 23:46:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 2 loss:0.04296629875898361 norm:0.0006202217773534358 max memory_allocated 49664.21142578125 
[2025-03-16 23:48:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 3 loss:0.04037000983953476 norm:0.0004907817346975207 max memory_allocated 49664.21142578125 
[2025-03-16 23:49:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 4 loss:0.0388946458697319 norm:0.0004129640874452889 max memory_allocated 49664.21142578125 
[2025-03-16 23:51:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 5 loss:0.03812636807560921 norm:0.0003751211625058204 max memory_allocated 49664.21142578125 
[2025-03-16 23:52:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 6 loss:0.03775133937597275 norm:0.00036432704655453563 max memory_allocated 49664.21142578125 
[2025-03-16 23:53:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 7 loss:0.03749016299843788 norm:0.00033425987930968404 max memory_allocated 49664.21142578125 
[2025-03-16 23:55:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 8 loss:0.03730488196015358 norm:0.0003165715024806559 max memory_allocated 49664.21142578125 
[2025-03-16 23:56:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 9 loss:0.0371839813888073 norm:0.00031127125839702785 max memory_allocated 49664.21142578125 
[2025-03-16 23:58:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 10 loss:0.037083741277456284 norm:0.00030195422004908323 max memory_allocated 49664.21142578125 
[2025-03-16 23:59:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 11 loss:0.03700575605034828 norm:0.00029875501058995724 max memory_allocated 49664.21142578125 
[2025-03-17 00:00:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 12 loss:0.03691240772604942 norm:0.0002907418820541352 max memory_allocated 49664.21142578125 
[2025-03-17 00:02:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 13 loss:0.036837995052337646 norm:0.00028883368941023946 max memory_allocated 49664.21142578125 
[2025-03-17 00:03:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 14 loss:0.036797791719436646 norm:0.0002871858887374401 max memory_allocated 49664.21142578125 
[2025-03-17 00:05:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 15 loss:0.036730051040649414 norm:0.00028390015359036624 max memory_allocated 49664.21142578125 
[2025-03-17 00:06:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 16 loss:0.03668516129255295 norm:0.00027816309011541307 max memory_allocated 49664.21142578125 
[2025-03-17 00:07:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 17 loss:0.03665749728679657 norm:0.00027878995751962066 max memory_allocated 49664.21142578125 
[2025-03-17 00:09:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 18 loss:0.03661298751831055 norm:0.000275139173027128 max memory_allocated 49664.21142578125 
[2025-03-17 00:10:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 19 loss:0.03657963126897812 norm:0.00027181944460608065 max memory_allocated 49664.21142578125 
[2025-03-17 00:11:31 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 19 to 20 ===
[2025-03-17 00:13:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 0 loss:0.06768368929624557 norm:0.001426642993465066 max memory_allocated 49664.21142578125 
[2025-03-17 00:14:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 1 loss:0.055287811905145645 norm:0.0007600081735290587 max memory_allocated 49664.21142578125 
[2025-03-17 00:15:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 2 loss:0.04730798304080963 norm:0.0005388453137129545 max memory_allocated 49664.21142578125 
[2025-03-17 00:17:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 3 loss:0.04440291225910187 norm:0.00045433148625306785 max memory_allocated 49664.21142578125 
[2025-03-17 00:18:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 4 loss:0.042792435735464096 norm:0.00039973363163881004 max memory_allocated 49664.21142578125 
[2025-03-17 00:20:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 5 loss:0.04201232269406319 norm:0.0003544718201737851 max memory_allocated 49664.21142578125 
[2025-03-17 00:21:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 6 loss:0.04162915050983429 norm:0.00033487912151031196 max memory_allocated 49664.21142578125 
[2025-03-17 00:22:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 7 loss:0.04139915481209755 norm:0.00032560029649175704 max memory_allocated 49664.21142578125 
[2025-03-17 00:24:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 8 loss:0.04120468348264694 norm:0.0003120714391116053 max memory_allocated 49664.21142578125 
[2025-03-17 00:25:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 9 loss:0.041050925850868225 norm:0.0003121031040791422 max memory_allocated 49664.21142578125 
[2025-03-17 00:27:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 10 loss:0.040918588638305664 norm:0.0002978236589115113 max memory_allocated 49664.21142578125 
[2025-03-17 00:28:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 11 loss:0.04083094373345375 norm:0.00029184523737058043 max memory_allocated 49664.21142578125 
[2025-03-17 00:29:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 12 loss:0.040734607726335526 norm:0.00028744357405230403 max memory_allocated 49664.21142578125 
[2025-03-17 00:31:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 13 loss:0.040663354098796844 norm:0.00028531881980597973 max memory_allocated 49664.21142578125 
[2025-03-17 00:32:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 14 loss:0.04062221571803093 norm:0.00028437780565582216 max memory_allocated 49664.21142578125 
[2025-03-17 00:34:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 15 loss:0.0406075082719326 norm:0.0002838383661583066 max memory_allocated 49664.21142578125 
[2025-03-17 00:35:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 16 loss:0.04057876765727997 norm:0.00028258637757971883 max memory_allocated 49664.21142578125 
[2025-03-17 00:36:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 17 loss:0.04055191949009895 norm:0.0002803343231789768 max memory_allocated 49664.21142578125 
[2025-03-17 00:38:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 18 loss:0.040557269006967545 norm:0.00028327922336757183 max memory_allocated 49664.21142578125 
[2025-03-17 00:39:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 19 loss:0.040545202791690826 norm:0.0002813786850310862 max memory_allocated 49664.21142578125 
[2025-03-17 00:40:34 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 20 to 21 ===
[2025-03-17 00:42:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 0 loss:0.07411019504070282 norm:0.001585877500474453 max memory_allocated 49664.58642578125 
[2025-03-17 00:43:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 1 loss:0.06078062951564789 norm:0.000899650389328599 max memory_allocated 49664.58642578125 
[2025-03-17 00:44:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 2 loss:0.05189919471740723 norm:0.0006286383140832186 max memory_allocated 49664.58642578125 
[2025-03-17 00:46:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 3 loss:0.048932187259197235 norm:0.0005061887204647064 max memory_allocated 49664.58642578125 
[2025-03-17 00:47:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 4 loss:0.047269511967897415 norm:0.00044026924297213554 max memory_allocated 49664.58642578125 
[2025-03-17 00:49:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 5 loss:0.04656442627310753 norm:0.00040141656063497066 max memory_allocated 49664.58642578125 
[2025-03-17 00:50:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 6 loss:0.046197086572647095 norm:0.0003781818086281419 max memory_allocated 49664.58642578125 
[2025-03-17 00:51:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 7 loss:0.045880503952503204 norm:0.0003575865412130952 max memory_allocated 49664.58642578125 
[2025-03-17 00:53:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 8 loss:0.045642558485269547 norm:0.0003479650476947427 max memory_allocated 49664.58642578125 
[2025-03-17 00:54:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 9 loss:0.04549257457256317 norm:0.00033643655478954315 max memory_allocated 49664.58642578125 
[2025-03-17 00:56:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 10 loss:0.045387547463178635 norm:0.00033045027521438897 max memory_allocated 49664.58642578125 
[2025-03-17 00:57:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 11 loss:0.045254409313201904 norm:0.0003241509839426726 max memory_allocated 49664.58642578125 
[2025-03-17 00:59:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 12 loss:0.045191776007413864 norm:0.00031948130344972014 max memory_allocated 49664.58642578125 
[2025-03-17 01:00:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 13 loss:0.04510033130645752 norm:0.0003181101055815816 max memory_allocated 49664.58642578125 
[2025-03-17 01:01:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 14 loss:0.044998783618211746 norm:0.0003133612044621259 max memory_allocated 49664.58642578125 
[2025-03-17 01:03:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 15 loss:0.044948138296604156 norm:0.0003115855797659606 max memory_allocated 49664.58642578125 
[2025-03-17 01:04:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 16 loss:0.044886358082294464 norm:0.0003096250002272427 max memory_allocated 49664.58642578125 
[2025-03-17 01:06:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 17 loss:0.04482834041118622 norm:0.00030631976551376283 max memory_allocated 49664.58642578125 
[2025-03-17 01:07:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 18 loss:0.044800035655498505 norm:0.00030648033134639263 max memory_allocated 49664.58642578125 
[2025-03-17 01:08:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 19 loss:0.044760968536138535 norm:0.0003051148378290236 max memory_allocated 49664.58642578125 
[2025-03-17 01:09:37 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 21 to 22 ===
[2025-03-17 01:11:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 0 loss:0.0864027738571167 norm:0.002352402312681079 max memory_allocated 49664.58642578125 
[2025-03-17 01:12:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 1 loss:0.06359650194644928 norm:0.0009681108058430254 max memory_allocated 49664.58642578125 
[2025-03-17 01:13:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 2 loss:0.052186205983161926 norm:0.0006699991063214839 max memory_allocated 49664.58642578125 
[2025-03-17 01:15:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 3 loss:0.04840211197733879 norm:0.0005487538292072713 max memory_allocated 49664.58642578125 
[2025-03-17 01:16:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 4 loss:0.046302683651447296 norm:0.0004857586754951626 max memory_allocated 49664.58642578125 
[2025-03-17 01:18:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 5 loss:0.04539873078465462 norm:0.00045148294884711504 max memory_allocated 49664.58642578125 
[2025-03-17 01:19:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 6 loss:0.044828951358795166 norm:0.0004270061617717147 max memory_allocated 49664.58642578125 
[2025-03-17 01:21:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 7 loss:0.04439767077565193 norm:0.00039911025669425726 max memory_allocated 49664.58642578125 
[2025-03-17 01:22:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 8 loss:0.044022731482982635 norm:0.0003807217872235924 max memory_allocated 49664.58642578125 
[2025-03-17 01:23:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 9 loss:0.04373893141746521 norm:0.0003656513581518084 max memory_allocated 49664.58642578125 
[2025-03-17 01:25:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 10 loss:0.04351232945919037 norm:0.0003573230642359704 max memory_allocated 49664.58642578125 
[2025-03-17 01:26:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 11 loss:0.04331279173493385 norm:0.00035174074582755566 max memory_allocated 49664.58642578125 
[2025-03-17 01:28:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 12 loss:0.043162453919649124 norm:0.0003456599952187389 max memory_allocated 49664.58642578125 
[2025-03-17 01:29:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 13 loss:0.043030429631471634 norm:0.000340707425493747 max memory_allocated 49664.58642578125 
[2025-03-17 01:30:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 14 loss:0.04290357977151871 norm:0.00033411604817956686 max memory_allocated 49664.58642578125 
[2025-03-17 01:32:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 15 loss:0.0428040586411953 norm:0.0003328899620100856 max memory_allocated 49664.58642578125 
[2025-03-17 01:33:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 16 loss:0.0426844097673893 norm:0.0003267565043643117 max memory_allocated 49664.58642578125 
[2025-03-17 01:35:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 17 loss:0.0425853356719017 norm:0.0003222113009542227 max memory_allocated 49664.58642578125 
[2025-03-17 01:36:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 18 loss:0.042499106377363205 norm:0.00031990776187740266 max memory_allocated 49664.58642578125 
[2025-03-17 01:37:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 19 loss:0.04241224378347397 norm:0.0003165471716783941 max memory_allocated 49664.58642578125 
[2025-03-17 01:38:41 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 22 to 23 ===
[2025-03-17 01:40:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 0 loss:0.07776647806167603 norm:0.001676417887210846 max memory_allocated 49664.96142578125 
[2025-03-17 01:41:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 1 loss:0.06351881474256516 norm:0.0009385871235281229 max memory_allocated 49664.96142578125 
[2025-03-17 01:43:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 2 loss:0.05336545407772064 norm:0.0006719747325405478 max memory_allocated 49664.96142578125 
[2025-03-17 01:44:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 3 loss:0.049946531653404236 norm:0.000567351933568716 max memory_allocated 49664.96142578125 
[2025-03-17 01:45:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 4 loss:0.04817056283354759 norm:0.0005044247373007238 max memory_allocated 49664.96142578125 
[2025-03-17 01:47:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 5 loss:0.04746552184224129 norm:0.0004665933665819466 max memory_allocated 49664.96142578125 
[2025-03-17 01:48:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 6 loss:0.047074656933546066 norm:0.00045314087765291333 max memory_allocated 49664.96142578125 
[2025-03-17 01:50:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 7 loss:0.04673768952488899 norm:0.00043206667760387063 max memory_allocated 49664.96142578125 
[2025-03-17 01:51:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 8 loss:0.04653647169470787 norm:0.00042375861085020006 max memory_allocated 49664.96142578125 
[2025-03-17 01:52:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 9 loss:0.046383049339056015 norm:0.0004119602672290057 max memory_allocated 49664.96142578125 
[2025-03-17 01:54:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 10 loss:0.04623181000351906 norm:0.00040529525722377 max memory_allocated 49664.96142578125 
[2025-03-17 01:55:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 11 loss:0.04605519026517868 norm:0.00039868601015768945 max memory_allocated 49664.96142578125 
[2025-03-17 01:57:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 12 loss:0.0459398552775383 norm:0.00040968344546854496 max memory_allocated 49664.96142578125 
[2025-03-17 01:58:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 13 loss:0.04579498991370201 norm:0.00038638856494799256 max memory_allocated 49664.96142578125 
[2025-03-17 01:59:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 14 loss:0.04566628485918045 norm:0.00038363863131962717 max memory_allocated 49664.96142578125 
[2025-03-17 02:01:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 15 loss:0.045562293380498886 norm:0.0003798049583565444 max memory_allocated 49664.96142578125 
[2025-03-17 02:02:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 16 loss:0.04545823484659195 norm:0.0003752879274543375 max memory_allocated 49664.96142578125 
[2025-03-17 02:04:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 17 loss:0.045349035412073135 norm:0.00037242122925817966 max memory_allocated 49664.96142578125 
[2025-03-17 02:05:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 18 loss:0.045283276587724686 norm:0.0003720209060702473 max memory_allocated 49664.96142578125 
[2025-03-17 02:06:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 19 loss:0.04518458619713783 norm:0.00036691181594505906 max memory_allocated 49664.96142578125 
[2025-03-17 02:07:45 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 23 to 24 ===
[2025-03-17 02:09:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 0 loss:0.09828148037195206 norm:0.0028133252635598183 max memory_allocated 49665.14892578125 
[2025-03-17 02:10:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 1 loss:0.08144765347242355 norm:0.0015992042608559132 max memory_allocated 49665.14892578125 
[2025-03-17 02:12:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 2 loss:0.06958996504545212 norm:0.0011924257269129157 max memory_allocated 49665.14892578125 
[2025-03-17 02:13:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 3 loss:0.06528769433498383 norm:0.0009894378017634153 max memory_allocated 49665.14892578125 
[2025-03-17 02:14:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 4 loss:0.06316260993480682 norm:0.0008248895173892379 max memory_allocated 49665.14892578125 
[2025-03-17 02:16:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 5 loss:0.062308505177497864 norm:0.0007370479288510978 max memory_allocated 49665.14892578125 
[2025-03-17 02:17:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 6 loss:0.061714716255664825 norm:0.0006848438642919064 max memory_allocated 49665.14892578125 
[2025-03-17 02:19:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 7 loss:0.06132429465651512 norm:0.0006303808186203241 max memory_allocated 49665.14892578125 
[2025-03-17 02:20:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 8 loss:0.061015091836452484 norm:0.0005880401586182415 max memory_allocated 49665.14892578125 
[2025-03-17 02:21:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 9 loss:0.06077098473906517 norm:0.0005587729974649847 max memory_allocated 49665.14892578125 
[2025-03-17 02:23:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 10 loss:0.060567133128643036 norm:0.0005342648364603519 max memory_allocated 49665.14892578125 
[2025-03-17 02:24:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 11 loss:0.06044784560799599 norm:0.0005174708785489202 max memory_allocated 49665.14892578125 
[2025-03-17 02:26:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 12 loss:0.0602988563477993 norm:0.0005107854376547039 max memory_allocated 49665.14892578125 
[2025-03-17 02:27:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 13 loss:0.06033489480614662 norm:0.0005174287362024188 max memory_allocated 49665.14892578125 
[2025-03-17 02:29:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 14 loss:0.06023558974266052 norm:0.0005096856039017439 max memory_allocated 49665.14892578125 
[2025-03-17 02:30:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 15 loss:0.06008480116724968 norm:0.0004954830510541797 max memory_allocated 49665.14892578125 
[2025-03-17 02:31:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 16 loss:0.06005023792386055 norm:0.00048793150926940143 max memory_allocated 49665.14892578125 
[2025-03-17 02:33:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 17 loss:0.059929631650447845 norm:0.00048308155965059996 max memory_allocated 49665.14892578125 
[2025-03-17 02:34:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 18 loss:0.05985533446073532 norm:0.0004785963101312518 max memory_allocated 49665.14892578125 
[2025-03-17 02:36:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 19 loss:0.059836529195308685 norm:0.00047774732229299843 max memory_allocated 49665.14892578125 
[2025-03-17 02:36:51 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 24 to 25 ===
[2025-03-17 02:38:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 0 loss:0.13841085135936737 norm:0.007612565997987986 max memory_allocated 49665.14892578125 
[2025-03-17 02:39:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 1 loss:0.08413254469633102 norm:0.0019895362202078104 max memory_allocated 49665.14892578125 
[2025-03-17 02:41:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 2 loss:0.06635959446430206 norm:0.0010454594157636166 max memory_allocated 49665.33642578125 
[2025-03-17 02:42:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 3 loss:0.060775838792324066 norm:0.0008509457693435252 max memory_allocated 49665.33642578125 
[2025-03-17 02:44:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 4 loss:0.057939495891332626 norm:0.0007516167825087905 max memory_allocated 49665.33642578125 
[2025-03-17 02:45:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 5 loss:0.056654270738363266 norm:0.0006914073601365089 max memory_allocated 49665.33642578125 
[2025-03-17 02:46:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 6 loss:0.0558309331536293 norm:0.0006500262534245849 max memory_allocated 49665.33642578125 
[2025-03-17 02:48:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 7 loss:0.05506342649459839 norm:0.0006261916714720428 max memory_allocated 49665.33642578125 
[2025-03-17 02:49:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 8 loss:0.054456427693367004 norm:0.0006456816918216646 max memory_allocated 49665.33642578125 
[2025-03-17 02:51:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 9 loss:0.05381372943520546 norm:0.0005985074094496667 max memory_allocated 49665.33642578125 
[2025-03-17 02:52:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 10 loss:0.05337192490696907 norm:0.0005733904545195401 max memory_allocated 49665.33642578125 
[2025-03-17 02:53:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 11 loss:0.05301346629858017 norm:0.0005700750043615699 max memory_allocated 49665.33642578125 
[2025-03-17 02:55:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 12 loss:0.05269820988178253 norm:0.0005597710842266679 max memory_allocated 49665.33642578125 
[2025-03-17 02:56:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 13 loss:0.05246242880821228 norm:0.0005494091892614961 max memory_allocated 49665.33642578125 
[2025-03-17 02:58:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 14 loss:0.05221367999911308 norm:0.000530555727891624 max memory_allocated 49665.33642578125 
[2025-03-17 02:59:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 15 loss:0.052024293690919876 norm:0.0005239022430032492 max memory_allocated 49665.33642578125 
[2025-03-17 03:00:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 16 loss:0.051853470504283905 norm:0.0005122671136632562 max memory_allocated 49665.33642578125 
[2025-03-17 03:02:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 17 loss:0.051728349179029465 norm:0.0005025661666877568 max memory_allocated 49665.33642578125 
[2025-03-17 03:03:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 18 loss:0.051631394773721695 norm:0.0004906210815533996 max memory_allocated 49665.33642578125 
[2025-03-17 03:05:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 19 loss:0.05150879546999931 norm:0.0004826866206713021 max memory_allocated 49665.33642578125 
[2025-03-17 03:05:57 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 25 to 26 ===
[2025-03-17 03:07:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 0 loss:0.09246020764112473 norm:0.002987468848004937 max memory_allocated 49665.33642578125 
[2025-03-17 03:08:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 1 loss:0.07502210140228271 norm:0.0017721090698614717 max memory_allocated 49665.33642578125 
[2025-03-17 03:10:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 2 loss:0.06135404855012894 norm:0.0013330591609701514 max memory_allocated 49665.33642578125 
[2025-03-17 03:11:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 3 loss:0.05675141513347626 norm:0.0010718994308263063 max memory_allocated 49665.33642578125 
[2025-03-17 03:13:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 4 loss:0.0549059696495533 norm:0.0009219676721841097 max memory_allocated 49665.33642578125 
[2025-03-17 03:14:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 5 loss:0.054164692759513855 norm:0.000809570134151727 max memory_allocated 49665.33642578125 
[2025-03-17 03:15:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 6 loss:0.05357532948255539 norm:0.0007212331984192133 max memory_allocated 49665.33642578125 
[2025-03-17 03:17:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 7 loss:0.053175318986177444 norm:0.0006706705898977816 max memory_allocated 49665.33642578125 
[2025-03-17 03:18:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 8 loss:0.05299505218863487 norm:0.0006459907745011151 max memory_allocated 49665.33642578125 
[2025-03-17 03:20:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 9 loss:0.05282079428434372 norm:0.0006128412205725908 max memory_allocated 49665.33642578125 
[2025-03-17 03:21:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 10 loss:0.05255671218037605 norm:0.0005700568435713649 max memory_allocated 49665.33642578125 
[2025-03-17 03:23:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 11 loss:0.05236102640628815 norm:0.0005479840910993516 max memory_allocated 49665.33642578125 
[2025-03-17 03:24:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 12 loss:0.05223117023706436 norm:0.0005327961407601833 max memory_allocated 49665.33642578125 
[2025-03-17 03:25:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 13 loss:0.052115824073553085 norm:0.0005184035981073976 max memory_allocated 49665.33642578125 
[2025-03-17 03:27:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 14 loss:0.05195645987987518 norm:0.0005075486842542887 max memory_allocated 49665.33642578125 
[2025-03-17 03:28:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 15 loss:0.05172246694564819 norm:0.0004930598079226911 max memory_allocated 49665.33642578125 
[2025-03-17 03:30:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 16 loss:0.051637306809425354 norm:0.0004834426217712462 max memory_allocated 49665.33642578125 
[2025-03-17 03:31:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 17 loss:0.051484230905771255 norm:0.00047298730351030827 max memory_allocated 49665.33642578125 
[2025-03-17 03:32:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 18 loss:0.05134375020861626 norm:0.0004593177291098982 max memory_allocated 49665.33642578125 
[2025-03-17 03:34:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 19 loss:0.051254838705062866 norm:0.0004526910779532045 max memory_allocated 49665.33642578125 
[2025-03-17 03:35:04 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 26 to 27 ===
[2025-03-17 03:36:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 0 loss:0.17336204648017883 norm:0.013699805364012718 max memory_allocated 49665.33642578125 
[2025-03-17 03:37:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 1 loss:0.09773307293653488 norm:0.0029682409949600697 max memory_allocated 49665.33642578125 
[2025-03-17 03:39:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 2 loss:0.07452812790870667 norm:0.00150759716052562 max memory_allocated 49665.33642578125 
[2025-03-17 03:40:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 3 loss:0.0677807480096817 norm:0.0012152913259342313 max memory_allocated 49665.33642578125 
[2025-03-17 03:42:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 4 loss:0.06485257297754288 norm:0.00106337433680892 max memory_allocated 49665.33642578125 
[2025-03-17 03:43:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 5 loss:0.06350791454315186 norm:0.0009542847983539104 max memory_allocated 49665.33642578125 
[2025-03-17 03:45:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 6 loss:0.06272931396961212 norm:0.0009074723930098116 max memory_allocated 49665.33642578125 
[2025-03-17 03:46:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 7 loss:0.061970170587301254 norm:0.0008509733015671372 max memory_allocated 49665.33642578125 
[2025-03-17 03:47:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 8 loss:0.06126590073108673 norm:0.0007960749207995832 max memory_allocated 49665.33642578125 
[2025-03-17 03:49:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 9 loss:0.06076526641845703 norm:0.0007525166147388518 max memory_allocated 49665.33642578125 
[2025-03-17 03:50:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 10 loss:0.060330938547849655 norm:0.0007162713445723057 max memory_allocated 49665.33642578125 
[2025-03-17 03:52:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 11 loss:0.06002034246921539 norm:0.0007003386272117496 max memory_allocated 49665.33642578125 
[2025-03-17 03:53:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 12 loss:0.05968835949897766 norm:0.0006737961666658521 max memory_allocated 49665.33642578125 
[2025-03-17 03:54:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 13 loss:0.05946846306324005 norm:0.0006603876245208085 max memory_allocated 49665.33642578125 
[2025-03-17 03:56:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 14 loss:0.05927206203341484 norm:0.000642849481664598 max memory_allocated 49665.33642578125 
[2025-03-17 03:57:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 15 loss:0.05912863090634346 norm:0.0006291307508945465 max memory_allocated 49665.33642578125 
[2025-03-17 03:59:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 16 loss:0.058937057852745056 norm:0.000610868853982538 max memory_allocated 49665.33642578125 
[2025-03-17 04:00:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 17 loss:0.05876236781477928 norm:0.0006047514616511762 max memory_allocated 49665.33642578125 
[2025-03-17 04:01:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 18 loss:0.058616604655981064 norm:0.0005904469871893525 max memory_allocated 49665.33642578125 
[2025-03-17 04:03:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 19 loss:0.05849963426589966 norm:0.0005768032278865576 max memory_allocated 49665.33642578125 
[2025-03-17 04:04:08 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 27 to 28 ===
[2025-03-17 04:05:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 0 loss:0.13176186382770538 norm:0.005566837266087532 max memory_allocated 49665.33642578125 
[2025-03-17 04:07:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 1 loss:0.09009597450494766 norm:0.0013025489170104265 max memory_allocated 49665.33642578125 
[2025-03-17 04:08:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 2 loss:0.06982457637786865 norm:0.0008123262668959796 max memory_allocated 49665.33642578125 
[2025-03-17 04:09:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 3 loss:0.06374263763427734 norm:0.0006775499205105007 max memory_allocated 49665.33642578125 
[2025-03-17 04:11:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 4 loss:0.061279699206352234 norm:0.0006187739782035351 max memory_allocated 49665.33642578125 
[2025-03-17 04:12:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 5 loss:0.06020144373178482 norm:0.0006024765316396952 max memory_allocated 49665.33642578125 
[2025-03-17 04:14:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 6 loss:0.05942552536725998 norm:0.0005898001836612821 max memory_allocated 49665.33642578125 
[2025-03-17 04:15:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 7 loss:0.058925073593854904 norm:0.0005973119987174869 max memory_allocated 49665.33642578125 
[2025-03-17 04:16:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 8 loss:0.058281056582927704 norm:0.0005785345565527678 max memory_allocated 49665.33642578125 
[2025-03-17 04:18:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 9 loss:0.05773906037211418 norm:0.0005431326571851969 max memory_allocated 49665.33642578125 
[2025-03-17 04:19:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 10 loss:0.05736129730939865 norm:0.0005306422244757414 max memory_allocated 49665.33642578125 
[2025-03-17 04:21:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 11 loss:0.05701300501823425 norm:0.0005154025857336819 max memory_allocated 49665.33642578125 
[2025-03-17 04:22:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 12 loss:0.05674634501338005 norm:0.0005066964658908546 max memory_allocated 49665.33642578125 
[2025-03-17 04:24:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 13 loss:0.0565217062830925 norm:0.0004964089603163302 max memory_allocated 49665.33642578125 
[2025-03-17 04:25:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 14 loss:0.05632692947983742 norm:0.0004830267862416804 max memory_allocated 49665.33642578125 
[2025-03-17 04:26:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 15 loss:0.05604728311300278 norm:0.00047134383930824697 max memory_allocated 49665.33642578125 
[2025-03-17 04:28:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 16 loss:0.05590835213661194 norm:0.0004678092373069376 max memory_allocated 49665.33642578125 
[2025-03-17 04:29:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 17 loss:0.055780909955501556 norm:0.00046253259642980993 max memory_allocated 49665.33642578125 
[2025-03-17 04:31:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 18 loss:0.05567501112818718 norm:0.00046436188858933747 max memory_allocated 49665.33642578125 
[2025-03-17 04:32:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 19 loss:0.05556023120880127 norm:0.0004614094505086541 max memory_allocated 49665.33642578125 
[2025-03-17 04:33:14 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 28 to 29 ===
[2025-03-17 04:34:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 0 loss:0.11637438088655472 norm:0.003713812679052353 max memory_allocated 49665.33642578125 
[2025-03-17 04:36:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 1 loss:0.09362637996673584 norm:0.0022162916138768196 max memory_allocated 49665.33642578125 
[2025-03-17 04:37:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 2 loss:0.07522013038396835 norm:0.0015609818510711193 max memory_allocated 49665.33642578125 
[2025-03-17 04:39:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 3 loss:0.06971494108438492 norm:0.0013233778299763799 max memory_allocated 49665.33642578125 
[2025-03-17 04:40:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 4 loss:0.06819571554660797 norm:0.001107505988329649 max memory_allocated 49665.33642578125 
[2025-03-17 04:41:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 5 loss:0.06741945445537567 norm:0.0009760319371707737 max memory_allocated 49665.33642578125 
[2025-03-17 04:43:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 6 loss:0.06704184412956238 norm:0.0008827323326840997 max memory_allocated 49665.33642578125 
[2025-03-17 04:44:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 7 loss:0.066769540309906 norm:0.0008303613867610693 max memory_allocated 49665.33642578125 
[2025-03-17 04:46:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 8 loss:0.06646715104579926 norm:0.0007714733947068453 max memory_allocated 49665.33642578125 
[2025-03-17 04:47:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 9 loss:0.06643786281347275 norm:0.0007346528582274914 max memory_allocated 49665.33642578125 
[2025-03-17 04:48:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 10 loss:0.06628328561782837 norm:0.0006847879849374294 max memory_allocated 49665.33642578125 
[2025-03-17 04:50:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 11 loss:0.06607167422771454 norm:0.0006631011492572725 max memory_allocated 49665.33642578125 
[2025-03-17 04:51:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 12 loss:0.06595666706562042 norm:0.0006332187331281602 max memory_allocated 49665.33642578125 
[2025-03-17 04:53:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 13 loss:0.06560070067644119 norm:0.000603186315856874 max memory_allocated 49665.33642578125 
[2025-03-17 04:54:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 14 loss:0.0653771311044693 norm:0.0005807403358630836 max memory_allocated 49665.33642578125 
[2025-03-17 04:55:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 15 loss:0.06526263803243637 norm:0.0005706903175450861 max memory_allocated 49665.33642578125 
[2025-03-17 04:57:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 16 loss:0.06506122648715973 norm:0.0005807731067761779 max memory_allocated 49665.33642578125 
[2025-03-17 04:58:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 17 loss:0.06486958265304565 norm:0.0005598793504759669 max memory_allocated 49665.33642578125 
[2025-03-17 05:00:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 18 loss:0.06489691883325577 norm:0.000539046130143106 max memory_allocated 49665.33642578125 
[2025-03-17 05:01:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 19 loss:0.06471376866102219 norm:0.000531623256392777 max memory_allocated 49665.33642578125 
[2025-03-17 05:02:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 29 to 30 ===
[2025-03-17 05:03:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 0 loss:0.19450636208057404 norm:0.2785913050174713 max memory_allocated 49665.33642578125 
[2025-03-17 05:05:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 1 loss:0.11484180390834808 norm:0.04146474599838257 max memory_allocated 49665.33642578125 
[2025-03-17 05:06:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 2 loss:0.0873822346329689 norm:0.01909995637834072 max memory_allocated 49665.33642578125 
[2025-03-17 05:08:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 3 loss:0.0795365422964096 norm:0.015017815865576267 max memory_allocated 49665.33642578125 
[2025-03-17 05:09:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 4 loss:0.0761798769235611 norm:0.012195800431072712 max memory_allocated 49665.33642578125 
[2025-03-17 05:10:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 5 loss:0.07454866915941238 norm:0.009935537353157997 max memory_allocated 49665.33642578125 
[2025-03-17 05:12:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 6 loss:0.07348313927650452 norm:0.00845562294125557 max memory_allocated 49665.33642578125 
[2025-03-17 05:13:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 7 loss:0.07267504930496216 norm:0.007314423564821482 max memory_allocated 49665.33642578125 
[2025-03-17 05:15:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 8 loss:0.07194779813289642 norm:0.006423001177608967 max memory_allocated 49665.33642578125 
[2025-03-17 05:16:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 9 loss:0.07124461978673935 norm:0.005659237504005432 max memory_allocated 49665.33642578125 
[2025-03-17 05:18:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 10 loss:0.07062571495771408 norm:0.004991310182958841 max memory_allocated 49665.33642578125 
[2025-03-17 05:19:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 11 loss:0.07010608166456223 norm:0.00446342071518302 max memory_allocated 49665.33642578125 
[2025-03-17 05:20:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 12 loss:0.06975653767585754 norm:0.004088974557816982 max memory_allocated 49665.33642578125 
[2025-03-17 05:22:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 13 loss:0.06935693323612213 norm:0.003754023229703307 max memory_allocated 49665.33642578125 
[2025-03-17 05:23:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 14 loss:0.06909410655498505 norm:0.003455823054537177 max memory_allocated 49665.33642578125 
[2025-03-17 05:25:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 15 loss:0.06858328729867935 norm:0.0029669185169041157 max memory_allocated 49665.33642578125 
[2025-03-17 05:26:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 16 loss:0.06831739842891693 norm:0.002636846387758851 max memory_allocated 49665.33642578125 
[2025-03-17 05:27:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 17 loss:0.06810244172811508 norm:0.002372017363086343 max memory_allocated 49665.33642578125 
[2025-03-17 05:29:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 18 loss:0.06788990646600723 norm:0.002104173880070448 max memory_allocated 49665.33642578125 
[2025-03-17 05:30:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 19 loss:0.06767553091049194 norm:0.0018958516884595156 max memory_allocated 49665.33642578125 
[2025-03-17 05:31:28 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 30 to 31 ===
[2025-03-17 05:32:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 0 loss:0.1328778862953186 norm:0.004440925549715757 max memory_allocated 49666.46142578125 
[2025-03-17 05:34:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 1 loss:0.10196205228567123 norm:0.0025299983099102974 max memory_allocated 49666.46142578125 
[2025-03-17 05:35:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 2 loss:0.08090753853321075 norm:0.0018349250312894583 max memory_allocated 49666.46142578125 
[2025-03-17 05:37:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 3 loss:0.0743536576628685 norm:0.0014613460516557097 max memory_allocated 49666.46142578125 
[2025-03-17 05:38:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 4 loss:0.07242552191019058 norm:0.0012783166021108627 max memory_allocated 49666.46142578125 
[2025-03-17 05:40:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 5 loss:0.07143943756818771 norm:0.0011458469089120626 max memory_allocated 49666.46142578125 
[2025-03-17 05:41:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 6 loss:0.0706336572766304 norm:0.0010201645782217383 max memory_allocated 49666.46142578125 
[2025-03-17 05:42:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 7 loss:0.07012396305799484 norm:0.0009275714983232319 max memory_allocated 49666.46142578125 
[2025-03-17 05:44:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 8 loss:0.06963330507278442 norm:0.0008531227940693498 max memory_allocated 49666.46142578125 
[2025-03-17 05:45:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 9 loss:0.06934164464473724 norm:0.0008003131952136755 max memory_allocated 49666.46142578125 
[2025-03-17 05:47:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 10 loss:0.06901644915342331 norm:0.0007494788151234388 max memory_allocated 49666.46142578125 
[2025-03-17 05:48:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 11 loss:0.06873977184295654 norm:0.0007013443391770124 max memory_allocated 49666.46142578125 
[2025-03-17 05:49:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 12 loss:0.06851968169212341 norm:0.000671684741973877 max memory_allocated 49666.46142578125 
[2025-03-17 05:51:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 13 loss:0.06827226281166077 norm:0.0006408521439880133 max memory_allocated 49666.46142578125 
[2025-03-17 05:52:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 14 loss:0.06799371540546417 norm:0.0006140540936030447 max memory_allocated 49666.46142578125 
[2025-03-17 05:54:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 15 loss:0.06771878898143768 norm:0.0005918594542890787 max memory_allocated 49666.46142578125 
