[2025-03-16 03:05:00 root] (main_calib_config3_cbq.py 280): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log-divide-adaptive-calibration-cbq/llama-7b-hf-0.4', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-divide-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.4.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-16 03:05:07 root] (main_calib_config3_cbq.py 347): INFO === start quantization ===
[2025-03-16 03:05:07 root] (main_calib_config3_cbq.py 353): INFO load calibration from ./cache/dataloader_llama_wikitext2_128.cache
[2025-03-16 03:05:07 root] (abq_llm_calib_config3_cbq.py 82): INFO Starting ...
[2025-03-16 03:05:07 root] (abq_llm_calib_config3_cbq.py 89): INFO Loaded quant_map from log-divide-adaptive/llama-7b-hf/quant_map_llama-7b-hf_0.4.pkl
[2025-03-16 03:05:11 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 0 to 1 ===
[2025-03-16 03:06:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 0 loss:0.11962801963090897 norm:0.16096602380275726 max memory_allocated 38101.85986328125 
[2025-03-16 03:07:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 1 loss:0.07944832742214203 norm:0.07487518340349197 max memory_allocated 38101.85986328125 
[2025-03-16 03:08:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 2 loss:0.0678526908159256 norm:0.0807742103934288 max memory_allocated 38101.85986328125 
[2025-03-16 03:09:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 3 loss:0.06105414405465126 norm:0.06088403984904289 max memory_allocated 38101.85986328125 
[2025-03-16 03:10:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 4 loss:0.05775189772248268 norm:0.05105523392558098 max memory_allocated 38101.85986328125 
[2025-03-16 03:10:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 5 loss:0.05522100627422333 norm:0.04302467033267021 max memory_allocated 38101.85986328125 
[2025-03-16 03:11:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 6 loss:0.05311470478773117 norm:0.03551063314080238 max memory_allocated 38101.85986328125 
[2025-03-16 03:12:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 7 loss:0.051682792603969574 norm:0.028617199510335922 max memory_allocated 38101.85986328125 
[2025-03-16 03:13:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 8 loss:0.05074132978916168 norm:0.02595827914774418 max memory_allocated 38101.85986328125 
[2025-03-16 03:14:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 9 loss:0.0499839223921299 norm:0.024750841781497 max memory_allocated 38101.85986328125 
[2025-03-16 03:15:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 10 loss:0.0492706373333931 norm:0.020470011979341507 max memory_allocated 38101.85986328125 
[2025-03-16 03:16:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 11 loss:0.04868239164352417 norm:0.018606381490826607 max memory_allocated 38101.85986328125 
[2025-03-16 03:17:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 12 loss:0.04837222024798393 norm:0.017360782250761986 max memory_allocated 38101.85986328125 
[2025-03-16 03:18:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 13 loss:0.04811456426978111 norm:0.017896341159939766 max memory_allocated 38101.85986328125 
[2025-03-16 03:19:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 14 loss:0.047598157078027725 norm:0.015599822625517845 max memory_allocated 38101.85986328125 
[2025-03-16 03:20:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 15 loss:0.047464519739151 norm:0.015933819115161896 max memory_allocated 38101.85986328125 
[2025-03-16 03:21:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 16 loss:0.047263260930776596 norm:0.01530996523797512 max memory_allocated 38101.85986328125 
[2025-03-16 03:22:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 17 loss:0.047118738293647766 norm:0.015538773499429226 max memory_allocated 38101.85986328125 
[2025-03-16 03:23:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 18 loss:0.04694095253944397 norm:0.01347968727350235 max memory_allocated 38101.85986328125 
[2025-03-16 03:24:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 19 loss:0.046729136258363724 norm:0.01473991759121418 max memory_allocated 38101.85986328125 
[2025-03-16 03:24:49 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 1 to 2 ===
[2025-03-16 03:25:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 0 loss:0.12369183450937271 norm:0.12791390717029572 max memory_allocated 38134.54931640625 
[2025-03-16 03:26:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 1 loss:0.07119245827198029 norm:0.04593449458479881 max memory_allocated 38134.54931640625 
[2025-03-16 03:27:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 2 loss:0.062051981687545776 norm:0.037894126027822495 max memory_allocated 38134.54931640625 
[2025-03-16 03:28:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 3 loss:0.056936733424663544 norm:0.03390461951494217 max memory_allocated 38134.54931640625 
[2025-03-16 03:29:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 4 loss:0.05403082072734833 norm:0.029305901378393173 max memory_allocated 38134.54931640625 
[2025-03-16 03:30:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 5 loss:0.05171780288219452 norm:0.02792591042816639 max memory_allocated 38134.54931640625 
[2025-03-16 03:31:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 6 loss:0.0494457483291626 norm:0.025850214064121246 max memory_allocated 38134.54931640625 
[2025-03-16 03:32:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 7 loss:0.0479297861456871 norm:0.021751198917627335 max memory_allocated 38134.54931640625 
[2025-03-16 03:33:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 8 loss:0.047604288905858994 norm:0.02585206739604473 max memory_allocated 38134.54931640625 
[2025-03-16 03:34:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 9 loss:0.04760967195034027 norm:0.026094956323504448 max memory_allocated 38134.54931640625 
[2025-03-16 03:35:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 10 loss:0.04706050083041191 norm:0.022686969488859177 max memory_allocated 38134.54931640625 
[2025-03-16 03:36:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 11 loss:0.046435147523880005 norm:0.017410853877663612 max memory_allocated 38134.54931640625 
[2025-03-16 03:37:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 12 loss:0.04742066562175751 norm:0.019172461703419685 max memory_allocated 38134.54931640625 
[2025-03-16 03:38:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 13 loss:0.04633031785488129 norm:0.020022373646497726 max memory_allocated 38134.54931640625 
[2025-03-16 03:39:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 14 loss:0.044589798897504807 norm:0.013982048258185387 max memory_allocated 38134.54931640625 
[2025-03-16 03:40:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 15 loss:0.04458969086408615 norm:0.014006366953253746 max memory_allocated 38134.54931640625 
[2025-03-16 03:41:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 16 loss:0.04414092004299164 norm:0.014460892416536808 max memory_allocated 38134.54931640625 
[2025-03-16 03:42:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 17 loss:0.044611670076847076 norm:0.017041251063346863 max memory_allocated 38134.54931640625 
[2025-03-16 03:43:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 18 loss:0.04527541622519493 norm:0.019113073125481606 max memory_allocated 38134.54931640625 
[2025-03-16 03:43:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 19 loss:0.045376621186733246 norm:0.019856033846735954 max memory_allocated 38134.54931640625 
[2025-03-16 03:44:31 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 2 to 3 ===
[2025-03-16 03:45:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 0 loss:0.08385082334280014 norm:0.010149472393095493 max memory_allocated 38134.54931640625 
[2025-03-16 03:46:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 1 loss:0.06817492842674255 norm:0.00688131945207715 max memory_allocated 38134.54931640625 
[2025-03-16 03:47:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 2 loss:0.061158567667007446 norm:0.014394978992640972 max memory_allocated 38134.54931640625 
[2025-03-16 03:48:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 3 loss:0.057922255247831345 norm:0.01434309035539627 max memory_allocated 38134.54931640625 
[2025-03-16 03:49:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 4 loss:0.054307710379362106 norm:0.010132351890206337 max memory_allocated 38134.54931640625 
[2025-03-16 03:50:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 5 loss:0.052418649196624756 norm:0.008506893180310726 max memory_allocated 38134.54931640625 
[2025-03-16 03:51:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 6 loss:0.051730215549468994 norm:0.007941508665680885 max memory_allocated 38134.54931640625 
[2025-03-16 03:52:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 7 loss:0.05139605700969696 norm:0.006668560206890106 max memory_allocated 38134.54931640625 
[2025-03-16 03:53:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 8 loss:0.05155104771256447 norm:0.005475773010402918 max memory_allocated 38134.54931640625 
[2025-03-16 03:54:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 9 loss:0.0519920252263546 norm:0.004655810538679361 max memory_allocated 38134.54931640625 
[2025-03-16 03:55:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 10 loss:0.05161396786570549 norm:0.003845033934339881 max memory_allocated 38134.54931640625 
[2025-03-16 03:56:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 11 loss:0.04919397830963135 norm:0.0029140303377062082 max memory_allocated 38134.54931640625 
[2025-03-16 03:56:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 12 loss:0.04927182197570801 norm:0.003010435961186886 max memory_allocated 38134.54931640625 
[2025-03-16 03:57:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 13 loss:0.04899301752448082 norm:0.002566964365541935 max memory_allocated 38134.54931640625 
[2025-03-16 03:58:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 14 loss:0.04858078435063362 norm:0.0025202948600053787 max memory_allocated 38134.54931640625 
[2025-03-16 03:59:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 15 loss:0.04843243956565857 norm:0.0023186691105365753 max memory_allocated 38134.54931640625 
[2025-03-16 04:00:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 16 loss:0.04828611761331558 norm:0.0025253472849726677 max memory_allocated 38134.54931640625 
[2025-03-16 04:01:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 17 loss:0.04815029352903366 norm:0.0022446077782660723 max memory_allocated 38134.54931640625 
[2025-03-16 04:02:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 18 loss:0.048315003514289856 norm:0.002717797178775072 max memory_allocated 38134.54931640625 
[2025-03-16 04:03:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 19 loss:0.04833861440420151 norm:0.002618304919451475 max memory_allocated 38134.54931640625 
[2025-03-16 04:04:10 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 3 to 4 ===
[2025-03-16 04:05:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 0 loss:0.05179596692323685 norm:0.07891771197319031 max memory_allocated 38134.54931640625 
[2025-03-16 04:06:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 1 loss:0.03737291321158409 norm:0.003570303088054061 max memory_allocated 38134.54931640625 
[2025-03-16 04:07:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 2 loss:0.032407246530056 norm:0.0028621843084692955 max memory_allocated 38134.54931640625 
[2025-03-16 04:08:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 3 loss:0.030392372980713844 norm:0.002284357324242592 max memory_allocated 38134.54931640625 
[2025-03-16 04:09:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 4 loss:0.029379867017269135 norm:0.001920155598782003 max memory_allocated 38134.54931640625 
[2025-03-16 04:10:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 5 loss:0.028618864715099335 norm:0.0015701433876529336 max memory_allocated 38134.54931640625 
[2025-03-16 04:10:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 6 loss:0.028144944459199905 norm:0.0014126397436484694 max memory_allocated 38134.54931640625 
[2025-03-16 04:11:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 7 loss:0.02785378322005272 norm:0.0012334092753008008 max memory_allocated 38134.54931640625 
[2025-03-16 04:12:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 8 loss:0.02765892818570137 norm:0.0010909578995779157 max memory_allocated 38134.54931640625 
[2025-03-16 04:13:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 9 loss:0.027566062286496162 norm:0.0009972251718863845 max memory_allocated 38134.54931640625 
[2025-03-16 04:14:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 10 loss:0.02748304419219494 norm:0.0008955578086897731 max memory_allocated 38134.54931640625 
[2025-03-16 04:15:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 11 loss:0.027400972321629524 norm:0.0008357475744560361 max memory_allocated 38134.54931640625 
[2025-03-16 04:16:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 12 loss:0.027345985174179077 norm:0.0007695858948864043 max memory_allocated 38134.54931640625 
[2025-03-16 04:17:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 13 loss:0.02729695849120617 norm:0.000719655305147171 max memory_allocated 38134.54931640625 
[2025-03-16 04:18:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 14 loss:0.027259647846221924 norm:0.0006937214056961238 max memory_allocated 38134.54931640625 
[2025-03-16 04:19:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 15 loss:0.02720724418759346 norm:0.0006580507615581155 max memory_allocated 38134.54931640625 
[2025-03-16 04:20:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 16 loss:0.027185050770640373 norm:0.0006177003961056471 max memory_allocated 38134.54931640625 
[2025-03-16 04:21:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 17 loss:0.027167078107595444 norm:0.0006028342177160084 max memory_allocated 38134.54931640625 
[2025-03-16 04:22:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 18 loss:0.02711903676390648 norm:0.0005710740806534886 max memory_allocated 38134.54931640625 
[2025-03-16 04:23:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 19 loss:0.027134569361805916 norm:0.0005553423543460667 max memory_allocated 38134.54931640625 
[2025-03-16 04:23:50 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 4 to 5 ===
[2025-03-16 04:24:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 0 loss:0.047686852514743805 norm:0.004916913341730833 max memory_allocated 38134.71923828125 
[2025-03-16 04:25:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 1 loss:0.032575130462646484 norm:0.002394047100096941 max memory_allocated 38134.71923828125 
[2025-03-16 04:26:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 2 loss:0.025897076353430748 norm:0.001501539722084999 max memory_allocated 38134.71923828125 
[2025-03-16 04:27:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 3 loss:0.022804612293839455 norm:0.001083117094822228 max memory_allocated 38134.71923828125 
[2025-03-16 04:28:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 4 loss:0.021140601485967636 norm:0.0008211116073653102 max memory_allocated 38134.71923828125 
[2025-03-16 04:29:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 5 loss:0.020071804523468018 norm:0.0006861835718154907 max memory_allocated 38134.71923828125 
[2025-03-16 04:30:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 6 loss:0.019474176689982414 norm:0.0006139246979728341 max memory_allocated 38134.71923828125 
[2025-03-16 04:31:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 7 loss:0.019007915630936623 norm:0.0005561790312640369 max memory_allocated 38134.71923828125 
[2025-03-16 04:32:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 8 loss:0.018665743991732597 norm:0.0005118946428410709 max memory_allocated 38134.71923828125 
[2025-03-16 04:33:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 9 loss:0.01850997842848301 norm:0.0004852905694860965 max memory_allocated 38134.71923828125 
[2025-03-16 04:34:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 10 loss:0.018406428396701813 norm:0.0004604407004080713 max memory_allocated 38134.71923828125 
[2025-03-16 04:35:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 11 loss:0.018342681229114532 norm:0.0004273240629117936 max memory_allocated 38134.71923828125 
[2025-03-16 04:36:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 12 loss:0.018236858770251274 norm:0.0004117587232030928 max memory_allocated 38134.71923828125 
[2025-03-16 04:37:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 13 loss:0.01816203072667122 norm:0.00040378060657531023 max memory_allocated 38134.71923828125 
[2025-03-16 04:38:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 14 loss:0.018234780058264732 norm:0.00040344471926800907 max memory_allocated 38134.71923828125 
[2025-03-16 04:39:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 15 loss:0.018164612352848053 norm:0.0003896391426678747 max memory_allocated 38134.71923828125 
[2025-03-16 04:40:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 16 loss:0.018153507262468338 norm:0.00038024733657948673 max memory_allocated 38134.71923828125 
[2025-03-16 04:41:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 17 loss:0.018133293837308884 norm:0.0003696467319969088 max memory_allocated 38134.71923828125 
[2025-03-16 04:42:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 18 loss:0.018141014501452446 norm:0.00036633253330364823 max memory_allocated 38134.71923828125 
[2025-03-16 04:42:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 19 loss:0.018166087567806244 norm:0.00035080112866126 max memory_allocated 38134.71923828125 
[2025-03-16 04:43:29 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 5 to 6 ===
[2025-03-16 04:44:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 0 loss:0.06990660727024078 norm:0.006631967145949602 max memory_allocated 38134.89111328125 
[2025-03-16 04:45:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 1 loss:0.03610147535800934 norm:0.0023283548653125763 max memory_allocated 38134.89111328125 
[2025-03-16 04:46:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 2 loss:0.026633307337760925 norm:0.0010768031934276223 max memory_allocated 38134.89111328125 
[2025-03-16 04:47:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 3 loss:0.022681960836052895 norm:0.0007011638372205198 max memory_allocated 38134.89111328125 
[2025-03-16 04:48:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 4 loss:0.02088243141770363 norm:0.0005926158046349883 max memory_allocated 38134.89111328125 
[2025-03-16 04:49:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 5 loss:0.019926512613892555 norm:0.0005294097354635596 max memory_allocated 38134.89111328125 
[2025-03-16 04:50:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 6 loss:0.01929030567407608 norm:0.0004872218705713749 max memory_allocated 38134.89111328125 
[2025-03-16 04:51:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 7 loss:0.018855275586247444 norm:0.00046589470002800226 max memory_allocated 38134.89111328125 
[2025-03-16 04:52:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 8 loss:0.018526194617152214 norm:0.0004423997597768903 max memory_allocated 38134.89111328125 
[2025-03-16 04:53:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 9 loss:0.018286732956767082 norm:0.00042067599133588374 max memory_allocated 38134.89111328125 
[2025-03-16 04:54:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 10 loss:0.018149834126234055 norm:0.00042239236063323915 max memory_allocated 38134.89111328125 
[2025-03-16 04:55:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 11 loss:0.017998287454247475 norm:0.00041027204133570194 max memory_allocated 38134.89111328125 
[2025-03-16 04:55:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 12 loss:0.017860306426882744 norm:0.00039058984839357436 max memory_allocated 38134.89111328125 
[2025-03-16 04:56:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 13 loss:0.017755206674337387 norm:0.0003876736154779792 max memory_allocated 38134.89111328125 
[2025-03-16 04:57:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 14 loss:0.017667945474386215 norm:0.0003809698682744056 max memory_allocated 38134.89111328125 
[2025-03-16 04:58:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 15 loss:0.017597824335098267 norm:0.00038506684359163046 max memory_allocated 38134.89111328125 
[2025-03-16 04:59:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 16 loss:0.01751157082617283 norm:0.0003768152091652155 max memory_allocated 38134.89111328125 
[2025-03-16 05:00:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 17 loss:0.01741461455821991 norm:0.0003664953983388841 max memory_allocated 38134.89111328125 
[2025-03-16 05:01:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 18 loss:0.017350153997540474 norm:0.0003647773992270231 max memory_allocated 38134.89111328125 
[2025-03-16 05:02:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 19 loss:0.01727890968322754 norm:0.0003651597653515637 max memory_allocated 38134.89111328125 
[2025-03-16 05:03:08 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 6 to 7 ===
[2025-03-16 05:04:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 0 loss:0.0324600413441658 norm:0.0015520792221650481 max memory_allocated 38135.06298828125 
[2025-03-16 05:05:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 1 loss:0.023769568651914597 norm:0.0007381353061646223 max memory_allocated 38135.06298828125 
[2025-03-16 05:06:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 2 loss:0.0198711808770895 norm:0.0004312762466724962 max memory_allocated 38135.06298828125 
[2025-03-16 05:07:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 3 loss:0.01821105368435383 norm:0.00030391328618861735 max memory_allocated 38135.06298828125 
[2025-03-16 05:07:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 4 loss:0.01733381859958172 norm:0.0002443674602545798 max memory_allocated 38135.06298828125 
[2025-03-16 05:08:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 5 loss:0.016806883737444878 norm:0.00021683413069695234 max memory_allocated 38135.06298828125 
[2025-03-16 05:09:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 6 loss:0.016450852155685425 norm:0.00019905768567696214 max memory_allocated 38135.06298828125 
[2025-03-16 05:10:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 7 loss:0.016212819144129753 norm:0.00018558226292952895 max memory_allocated 38135.06298828125 
[2025-03-16 05:11:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 8 loss:0.01606113463640213 norm:0.0001765152846928686 max memory_allocated 38135.06298828125 
[2025-03-16 05:12:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 9 loss:0.01597224362194538 norm:0.00017245480557903647 max memory_allocated 38135.06298828125 
[2025-03-16 05:13:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 10 loss:0.015889009460806847 norm:0.00016826936916913837 max memory_allocated 38135.06298828125 
[2025-03-16 05:14:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 11 loss:0.015834204852581024 norm:0.00016716407844796777 max memory_allocated 38135.06298828125 
[2025-03-16 05:15:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 12 loss:0.015809964388608932 norm:0.0001665877061896026 max memory_allocated 38135.06298828125 
[2025-03-16 05:16:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 13 loss:0.015780743211507797 norm:0.00016758174751885235 max memory_allocated 38135.06298828125 
[2025-03-16 05:17:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 14 loss:0.01573912426829338 norm:0.000166086305398494 max memory_allocated 38135.06298828125 
[2025-03-16 05:18:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 15 loss:0.015688486397266388 norm:0.00016621692338958383 max memory_allocated 38135.06298828125 
[2025-03-16 05:19:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 16 loss:0.015656057745218277 norm:0.00016343590687029064 max memory_allocated 38135.06298828125 
[2025-03-16 05:20:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 17 loss:0.01563001610338688 norm:0.00016155703633558005 max memory_allocated 38135.06298828125 
[2025-03-16 05:21:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 18 loss:0.015629835426807404 norm:0.00016123641398735344 max memory_allocated 38135.06298828125 
[2025-03-16 05:22:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 19 loss:0.015651583671569824 norm:0.00015885356697253883 max memory_allocated 38135.06298828125 
[2025-03-16 05:22:47 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 7 to 8 ===
[2025-03-16 05:23:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 0 loss:0.03301176428794861 norm:0.0013715961249545217 max memory_allocated 38135.23486328125 
[2025-03-16 05:24:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 1 loss:0.024268263950943947 norm:0.0005755543825216591 max memory_allocated 38135.23486328125 
[2025-03-16 05:25:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 2 loss:0.02032914198935032 norm:0.00034451435203664005 max memory_allocated 38135.23486328125 
[2025-03-16 05:26:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 3 loss:0.018561722710728645 norm:0.00025493433349765837 max memory_allocated 38135.23486328125 
[2025-03-16 05:27:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 4 loss:0.017717383801937103 norm:0.00021678161283489317 max memory_allocated 38135.23486328125 
[2025-03-16 05:28:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 5 loss:0.017171256244182587 norm:0.0001913751766551286 max memory_allocated 38135.23486328125 
[2025-03-16 05:29:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 6 loss:0.016798317432403564 norm:0.0001769320952007547 max memory_allocated 38135.23486328125 
[2025-03-16 05:30:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 7 loss:0.016565628349781036 norm:0.00016966616385616362 max memory_allocated 38135.23486328125 
[2025-03-16 05:31:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 8 loss:0.016392892226576805 norm:0.00016207367298193276 max memory_allocated 38135.23486328125 
[2025-03-16 05:32:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 9 loss:0.01626657135784626 norm:0.00015798195090610534 max memory_allocated 38135.23486328125 
[2025-03-16 05:33:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 10 loss:0.016191154718399048 norm:0.00015490708756260574 max memory_allocated 38135.23486328125 
[2025-03-16 05:34:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 11 loss:0.01614125445485115 norm:0.0001551151362946257 max memory_allocated 38135.23486328125 
[2025-03-16 05:35:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 12 loss:0.01612250693142414 norm:0.00015615914890076965 max memory_allocated 38135.23486328125 
[2025-03-16 05:36:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 13 loss:0.016109434887766838 norm:0.00015654144226573408 max memory_allocated 38135.23486328125 
[2025-03-16 05:37:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 14 loss:0.016104819253087044 norm:0.0001564426493132487 max memory_allocated 38135.23486328125 
[2025-03-16 05:38:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 15 loss:0.016097843647003174 norm:0.00015164626529440284 max memory_allocated 38135.23486328125 
[2025-03-16 05:39:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 16 loss:0.016094649210572243 norm:0.00015033465751912445 max memory_allocated 38135.23486328125 
[2025-03-16 05:40:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 17 loss:0.016091743484139442 norm:0.00015155832807067782 max memory_allocated 38135.23486328125 
[2025-03-16 05:40:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 18 loss:0.01608881726861 norm:0.00015090285160113126 max memory_allocated 38135.23486328125 
[2025-03-16 05:41:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 19 loss:0.016088364645838737 norm:0.00015171791892498732 max memory_allocated 38135.23486328125 
[2025-03-16 05:42:26 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 8 to 9 ===
[2025-03-16 05:43:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 0 loss:0.03313957527279854 norm:0.0012601773487403989 max memory_allocated 38135.40673828125 
[2025-03-16 05:44:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 1 loss:0.024514270946383476 norm:0.0005752293509431183 max memory_allocated 38135.40673828125 
[2025-03-16 05:45:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 2 loss:0.020555075258016586 norm:0.0003467407950665802 max memory_allocated 38135.40673828125 
[2025-03-16 05:46:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 3 loss:0.01879054494202137 norm:0.00025414652191102505 max memory_allocated 38135.40673828125 
[2025-03-16 05:47:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 4 loss:0.01792491041123867 norm:0.00020939107344020158 max memory_allocated 38135.40673828125 
[2025-03-16 05:48:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 5 loss:0.01739448867738247 norm:0.00018948965589515865 max memory_allocated 38135.40673828125 
[2025-03-16 05:49:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 6 loss:0.017064519226551056 norm:0.00017656353884376585 max memory_allocated 38135.40673828125 
[2025-03-16 05:50:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 7 loss:0.016822874546051025 norm:0.0001651989296078682 max memory_allocated 38135.40673828125 
[2025-03-16 05:51:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 8 loss:0.01664847694337368 norm:0.00015843099390622228 max memory_allocated 38135.40673828125 
[2025-03-16 05:52:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 9 loss:0.016542285680770874 norm:0.00015712797176092863 max memory_allocated 38135.40673828125 
[2025-03-16 05:52:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 10 loss:0.016449052840471268 norm:0.00015209893172141165 max memory_allocated 38135.40673828125 
[2025-03-16 05:53:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 11 loss:0.01639172062277794 norm:0.00015063707542140037 max memory_allocated 38135.40673828125 
[2025-03-16 05:54:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 12 loss:0.016353175044059753 norm:0.00014935777289792895 max memory_allocated 38135.40673828125 
[2025-03-16 05:55:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 13 loss:0.016327902674674988 norm:0.0001499874924775213 max memory_allocated 38135.40673828125 
[2025-03-16 05:56:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 14 loss:0.016322728246450424 norm:0.00015012598305474967 max memory_allocated 38135.40673828125 
[2025-03-16 05:57:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 15 loss:0.016323402523994446 norm:0.0001456815080018714 max memory_allocated 38135.40673828125 
[2025-03-16 05:58:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 16 loss:0.01631900481879711 norm:0.00014219357399269938 max memory_allocated 38135.40673828125 
[2025-03-16 05:59:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 17 loss:0.01632465422153473 norm:0.00014212941459845752 max memory_allocated 38135.40673828125 
[2025-03-16 06:00:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 18 loss:0.016328424215316772 norm:0.00014179381832946092 max memory_allocated 38135.40673828125 
[2025-03-16 06:01:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 19 loss:0.01633729599416256 norm:0.00014225501217879355 max memory_allocated 38135.40673828125 
[2025-03-16 06:02:04 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 9 to 10 ===
[2025-03-16 06:03:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 0 loss:0.03430528566241264 norm:0.001715511200018227 max memory_allocated 38135.57861328125 
[2025-03-16 06:04:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 1 loss:0.027024995535612106 norm:0.0009315642528235912 max memory_allocated 38135.57861328125 
[2025-03-16 06:05:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 2 loss:0.023026376962661743 norm:0.0006304603302851319 max memory_allocated 38135.57861328125 
[2025-03-16 06:05:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 3 loss:0.02105030231177807 norm:0.000490431091748178 max memory_allocated 38135.57861328125 
[2025-03-16 06:06:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 4 loss:0.020048685371875763 norm:0.00040126877138391137 max memory_allocated 38135.57861328125 
[2025-03-16 06:07:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 5 loss:0.01949656940996647 norm:0.0003535574651323259 max memory_allocated 38135.57861328125 
[2025-03-16 06:08:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 6 loss:0.01914501190185547 norm:0.0003181860374752432 max memory_allocated 38135.57861328125 
[2025-03-16 06:09:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 7 loss:0.018897049129009247 norm:0.0002895313664339483 max memory_allocated 38135.57861328125 
[2025-03-16 06:10:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 8 loss:0.018706779927015305 norm:0.0002722085628192872 max memory_allocated 38135.57861328125 
[2025-03-16 06:11:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 9 loss:0.018591823056340218 norm:0.00025890677352435887 max memory_allocated 38135.57861328125 
[2025-03-16 06:12:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 10 loss:0.018528105691075325 norm:0.00024857421522028744 max memory_allocated 38135.57861328125 
[2025-03-16 06:13:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 11 loss:0.01847194693982601 norm:0.00023833892191760242 max memory_allocated 38135.57861328125 
[2025-03-16 06:14:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 12 loss:0.018472187221050262 norm:0.0002313379809493199 max memory_allocated 38135.57861328125 
[2025-03-16 06:15:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 13 loss:0.01844394952058792 norm:0.0002225851349066943 max memory_allocated 38135.57861328125 
[2025-03-16 06:16:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 14 loss:0.01840691640973091 norm:0.00021539816225413233 max memory_allocated 38135.57861328125 
[2025-03-16 06:17:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 15 loss:0.018466569483280182 norm:0.00020948423480149359 max memory_allocated 38135.57861328125 
[2025-03-16 06:18:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 16 loss:0.018509848043322563 norm:0.00020623207092285156 max memory_allocated 38135.57861328125 
[2025-03-16 06:19:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 17 loss:0.018508940935134888 norm:0.0002001637767534703 max memory_allocated 38135.57861328125 
[2025-03-16 06:20:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 18 loss:0.018514834344387054 norm:0.00019879330648109317 max memory_allocated 38135.57861328125 
[2025-03-16 06:21:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 19 loss:0.018481524661183357 norm:0.00019531194993760437 max memory_allocated 38135.57861328125 
[2025-03-16 06:21:43 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 10 to 11 ===
[2025-03-16 06:22:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 0 loss:0.03970485180616379 norm:0.001671717269346118 max memory_allocated 38135.75048828125 
[2025-03-16 06:23:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 1 loss:0.028672371059656143 norm:0.0006681010127067566 max memory_allocated 38135.75048828125 
[2025-03-16 06:24:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 2 loss:0.023892126977443695 norm:0.00044483394594863057 max memory_allocated 38135.75048828125 
[2025-03-16 06:25:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 3 loss:0.021728819236159325 norm:0.0003479690058156848 max memory_allocated 38135.75048828125 
[2025-03-16 06:26:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 4 loss:0.020720990374684334 norm:0.00031247211154550314 max memory_allocated 38135.75048828125 
[2025-03-16 06:27:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 5 loss:0.020180294290184975 norm:0.0003017135604750365 max memory_allocated 38135.75048828125 
[2025-03-16 06:28:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 6 loss:0.01982605643570423 norm:0.0002951118804048747 max memory_allocated 38135.75048828125 
[2025-03-16 06:29:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 7 loss:0.0195666141808033 norm:0.00029086522408761084 max memory_allocated 38135.75048828125 
[2025-03-16 06:30:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 8 loss:0.01936940662562847 norm:0.00028130458667874336 max memory_allocated 38135.75048828125 
[2025-03-16 06:31:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 9 loss:0.019225100055336952 norm:0.00026718186563812196 max memory_allocated 38135.75048828125 
[2025-03-16 06:32:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 10 loss:0.019136618822813034 norm:0.00025908061070367694 max memory_allocated 38135.75048828125 
[2025-03-16 06:33:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 11 loss:0.019078578799962997 norm:0.00024586485233157873 max memory_allocated 38135.75048828125 
[2025-03-16 06:34:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 12 loss:0.01906226947903633 norm:0.0002362359082326293 max memory_allocated 38135.75048828125 
[2025-03-16 06:35:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 13 loss:0.019026391208171844 norm:0.0002297388855367899 max memory_allocated 38135.75048828125 
[2025-03-16 06:36:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 14 loss:0.019006961956620216 norm:0.000223256996832788 max memory_allocated 38135.75048828125 
[2025-03-16 06:37:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 15 loss:0.018987078219652176 norm:0.00022122259542811662 max memory_allocated 38135.75048828125 
[2025-03-16 06:38:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 16 loss:0.018998492509126663 norm:0.0002205649798270315 max memory_allocated 38135.75048828125 
[2025-03-16 06:38:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 17 loss:0.018988894298672676 norm:0.00021738687064498663 max memory_allocated 38135.75048828125 
[2025-03-16 06:39:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 18 loss:0.01899622194468975 norm:0.0002157157432520762 max memory_allocated 38135.75048828125 
[2025-03-16 06:40:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 19 loss:0.0189878698438406 norm:0.00021106275380589068 max memory_allocated 38135.75048828125 
[2025-03-16 06:41:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 11 to 12 ===
[2025-03-16 06:42:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 0 loss:0.03826012462377548 norm:0.0016157964710146189 max memory_allocated 38135.92236328125 
[2025-03-16 06:43:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 1 loss:0.030494436621665955 norm:0.0009068147628568113 max memory_allocated 38135.92236328125 
[2025-03-16 06:44:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 2 loss:0.026092451065778732 norm:0.0006333310157060623 max memory_allocated 38135.92236328125 
[2025-03-16 06:45:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 3 loss:0.024057043716311455 norm:0.0005073320353403687 max memory_allocated 38135.92236328125 
[2025-03-16 06:46:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 4 loss:0.023004790768027306 norm:0.0004317954881116748 max memory_allocated 38135.92236328125 
[2025-03-16 06:47:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 5 loss:0.022380707785487175 norm:0.0003808972251135856 max memory_allocated 38135.92236328125 
[2025-03-16 06:48:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 6 loss:0.021965134888887405 norm:0.0003487631038296968 max memory_allocated 38135.92236328125 
[2025-03-16 06:49:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 7 loss:0.02172819897532463 norm:0.0003238149802200496 max memory_allocated 38135.92236328125 
[2025-03-16 06:50:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 8 loss:0.021547267213463783 norm:0.0003061587340198457 max memory_allocated 38135.92236328125 
[2025-03-16 06:50:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 9 loss:0.0214130450040102 norm:0.0002869310264941305 max memory_allocated 38135.92236328125 
[2025-03-16 06:51:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 10 loss:0.021352918818593025 norm:0.0002727799001149833 max memory_allocated 38135.92236328125 
[2025-03-16 06:52:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 11 loss:0.02129967510700226 norm:0.00026099980459548533 max memory_allocated 38135.92236328125 
[2025-03-16 06:53:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 12 loss:0.021276772022247314 norm:0.00025458226446062326 max memory_allocated 38135.92236328125 
[2025-03-16 06:54:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 13 loss:0.021256228908896446 norm:0.0002446326252538711 max memory_allocated 38135.92236328125 
[2025-03-16 06:55:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 14 loss:0.021280698478221893 norm:0.00023982865968719125 max memory_allocated 38135.92236328125 
[2025-03-16 06:56:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 15 loss:0.021260244771838188 norm:0.0002369952853769064 max memory_allocated 38135.92236328125 
[2025-03-16 06:57:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 16 loss:0.021233990788459778 norm:0.0002319150371477008 max memory_allocated 38135.92236328125 
[2025-03-16 06:58:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 17 loss:0.021237317472696304 norm:0.0002284536458319053 max memory_allocated 38135.92236328125 
[2025-03-16 06:59:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 18 loss:0.021230828016996384 norm:0.00022766921028960496 max memory_allocated 38135.92236328125 
[2025-03-16 07:00:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 19 loss:0.02120516449213028 norm:0.00022478870232589543 max memory_allocated 38135.92236328125 
[2025-03-16 07:01:01 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 12 to 13 ===
[2025-03-16 07:02:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 0 loss:0.040297675877809525 norm:0.0021924946922808886 max memory_allocated 38136.09423828125 
[2025-03-16 07:03:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 1 loss:0.030064404010772705 norm:0.0010374397970736027 max memory_allocated 38136.09423828125 
[2025-03-16 07:03:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 2 loss:0.025246169418096542 norm:0.0007098900387063622 max memory_allocated 38136.09423828125 
[2025-03-16 07:04:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 3 loss:0.023235902190208435 norm:0.0005586112383753061 max memory_allocated 38136.09423828125 
[2025-03-16 07:05:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 4 loss:0.02206774242222309 norm:0.0004912546719424427 max memory_allocated 38136.09423828125 
[2025-03-16 07:06:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 5 loss:0.021382534876465797 norm:0.0004523367097135633 max memory_allocated 38136.09423828125 
[2025-03-16 07:07:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 6 loss:0.020848851650953293 norm:0.00041974952910095453 max memory_allocated 38136.09423828125 
[2025-03-16 07:08:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 7 loss:0.02048124186694622 norm:0.0003847488551400602 max memory_allocated 38136.09423828125 
[2025-03-16 07:09:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 8 loss:0.020257776603102684 norm:0.0003696884377859533 max memory_allocated 38136.09423828125 
[2025-03-16 07:10:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 9 loss:0.020112894475460052 norm:0.00034729455364868045 max memory_allocated 38136.09423828125 
[2025-03-16 07:11:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 10 loss:0.019993426278233528 norm:0.00032558609382249415 max memory_allocated 38136.09423828125 
[2025-03-16 07:12:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 11 loss:0.019920526072382927 norm:0.0003092912374995649 max memory_allocated 38136.09423828125 
[2025-03-16 07:13:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 12 loss:0.019855335354804993 norm:0.00029306160286068916 max memory_allocated 38136.09423828125 
[2025-03-16 07:14:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 13 loss:0.01984083652496338 norm:0.00028433778788894415 max memory_allocated 38136.09423828125 
[2025-03-16 07:15:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 14 loss:0.0199006088078022 norm:0.00028524547815322876 max memory_allocated 38136.09423828125 
[2025-03-16 07:16:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 15 loss:0.019903581589460373 norm:0.0002720611810218543 max memory_allocated 38136.09423828125 
[2025-03-16 07:17:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 16 loss:0.019902348518371582 norm:0.0002632876276038587 max memory_allocated 38136.09423828125 
[2025-03-16 07:18:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 17 loss:0.019925735890865326 norm:0.0002597278216853738 max memory_allocated 38136.09423828125 
[2025-03-16 07:19:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 18 loss:0.019924236461520195 norm:0.0002561503788456321 max memory_allocated 38136.09423828125 
[2025-03-16 07:20:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 19 loss:0.019944503903388977 norm:0.000252507597906515 max memory_allocated 38136.09423828125 
[2025-03-16 07:20:40 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 13 to 14 ===
[2025-03-16 07:21:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 0 loss:0.04432487487792969 norm:0.002034473232924938 max memory_allocated 38136.26611328125 
[2025-03-16 07:22:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 1 loss:0.033801671117544174 norm:0.0009855831740424037 max memory_allocated 38136.26611328125 
[2025-03-16 07:23:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 2 loss:0.028119709342718124 norm:0.0006593427387997508 max memory_allocated 38136.26611328125 
[2025-03-16 07:24:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 3 loss:0.025612888857722282 norm:0.0005180372390896082 max memory_allocated 38136.26611328125 
[2025-03-16 07:25:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 4 loss:0.024395467713475227 norm:0.0004567464638967067 max memory_allocated 38136.26611328125 
[2025-03-16 07:26:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 5 loss:0.023667579516768456 norm:0.0004128950531594455 max memory_allocated 38136.26611328125 
[2025-03-16 07:27:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 6 loss:0.02326890081167221 norm:0.0003878581919707358 max memory_allocated 38136.26611328125 
[2025-03-16 07:28:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 7 loss:0.02302439510822296 norm:0.0003584505175240338 max memory_allocated 38136.26611328125 
[2025-03-16 07:29:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 8 loss:0.02285301312804222 norm:0.00033760638325475156 max memory_allocated 38136.26611328125 
[2025-03-16 07:30:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 9 loss:0.022780003026127815 norm:0.00032005528919398785 max memory_allocated 38136.26611328125 
[2025-03-16 07:31:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 10 loss:0.022731781005859375 norm:0.00031093540019355714 max memory_allocated 38136.26611328125 
[2025-03-16 07:32:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 11 loss:0.022714907303452492 norm:0.00030324491672217846 max memory_allocated 38136.26611328125 
[2025-03-16 07:33:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 12 loss:0.022676510736346245 norm:0.00029448981513269246 max memory_allocated 38136.26611328125 
[2025-03-16 07:34:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 13 loss:0.02268148772418499 norm:0.00028502329951152205 max memory_allocated 38136.26611328125 
[2025-03-16 07:35:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 14 loss:0.022673211991786957 norm:0.00027907342882826924 max memory_allocated 38136.26611328125 
[2025-03-16 07:35:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 15 loss:0.022668030112981796 norm:0.00027474662056192756 max memory_allocated 38136.26611328125 
[2025-03-16 07:36:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 16 loss:0.022676939144730568 norm:0.0002711822744458914 max memory_allocated 38136.26611328125 
[2025-03-16 07:37:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 17 loss:0.022687753662467003 norm:0.0002706244995351881 max memory_allocated 38136.26611328125 
[2025-03-16 07:38:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 18 loss:0.02268666960299015 norm:0.00026526692090556026 max memory_allocated 38136.26611328125 
[2025-03-16 07:39:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 19 loss:0.022758036851882935 norm:0.00026495533529669046 max memory_allocated 38136.26611328125 
[2025-03-16 07:40:19 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 14 to 15 ===
[2025-03-16 07:41:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 0 loss:0.04196567460894585 norm:0.001562019344419241 max memory_allocated 38136.43798828125 
[2025-03-16 07:42:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 1 loss:0.03144899010658264 norm:0.0005810938309878111 max memory_allocated 38136.43798828125 
[2025-03-16 07:43:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 2 loss:0.026501942425966263 norm:0.00041670913924463093 max memory_allocated 38136.43798828125 
[2025-03-16 07:44:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 3 loss:0.024594690650701523 norm:0.0003461034793872386 max memory_allocated 38136.43798828125 
[2025-03-16 07:45:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 4 loss:0.02359548956155777 norm:0.0003210551221854985 max memory_allocated 38136.43798828125 
[2025-03-16 07:46:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 5 loss:0.02294066920876503 norm:0.000304620829410851 max memory_allocated 38136.43798828125 
[2025-03-16 07:47:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 6 loss:0.022519415244460106 norm:0.00028880758327431977 max memory_allocated 38136.43798828125 
[2025-03-16 07:48:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 7 loss:0.022276785224676132 norm:0.00027751154266297817 max memory_allocated 38136.43798828125 
[2025-03-16 07:48:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 8 loss:0.02214348129928112 norm:0.00027684340602718294 max memory_allocated 38136.43798828125 
[2025-03-16 07:49:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 9 loss:0.022047411650419235 norm:0.000268132658675313 max memory_allocated 38136.43798828125 
[2025-03-16 07:50:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 10 loss:0.02199242077767849 norm:0.0002626533678267151 max memory_allocated 38136.43798828125 
[2025-03-16 07:51:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 11 loss:0.021963322535157204 norm:0.0002600250591058284 max memory_allocated 38136.43798828125 
[2025-03-16 07:52:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 12 loss:0.02191385254263878 norm:0.0002510873891878873 max memory_allocated 38136.43798828125 
[2025-03-16 07:53:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 13 loss:0.021927544847130775 norm:0.0002541409048717469 max memory_allocated 38136.43798828125 
[2025-03-16 07:54:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 14 loss:0.021881932392716408 norm:0.0002479713875800371 max memory_allocated 38136.43798828125 
[2025-03-16 07:55:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 15 loss:0.02188016287982464 norm:0.00024817269877530634 max memory_allocated 38136.43798828125 
[2025-03-16 07:56:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 16 loss:0.021860945969820023 norm:0.00024400123220402747 max memory_allocated 38136.43798828125 
[2025-03-16 07:57:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 17 loss:0.02183298021554947 norm:0.00023749077809043229 max memory_allocated 38136.43798828125 
[2025-03-16 07:58:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 18 loss:0.021829357370734215 norm:0.00023736842558719218 max memory_allocated 38136.43798828125 
[2025-03-16 07:59:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 19 loss:0.02182457223534584 norm:0.00023496685025747865 max memory_allocated 38136.43798828125 
[2025-03-16 07:59:58 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 15 to 16 ===
[2025-03-16 08:01:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 0 loss:0.041274961084127426 norm:0.0012813271023333073 max memory_allocated 38136.60986328125 
[2025-03-16 08:01:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 1 loss:0.03170505911111832 norm:0.0005195963894948363 max memory_allocated 38136.60986328125 
[2025-03-16 08:02:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 2 loss:0.026375755667686462 norm:0.00033892379724420607 max memory_allocated 38136.60986328125 
[2025-03-16 08:03:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 3 loss:0.0243564210832119 norm:0.00027211359702050686 max memory_allocated 38136.60986328125 
[2025-03-16 08:04:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 4 loss:0.023213155567646027 norm:0.00023301062174141407 max memory_allocated 38136.60986328125 
[2025-03-16 08:05:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 5 loss:0.02256700024008751 norm:0.00020730850519612432 max memory_allocated 38136.60986328125 
[2025-03-16 08:06:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 6 loss:0.022225990891456604 norm:0.00019323790911585093 max memory_allocated 38136.60986328125 
[2025-03-16 08:07:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 7 loss:0.022038357332348824 norm:0.00018291088053956628 max memory_allocated 38136.60986328125 
[2025-03-16 08:08:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 8 loss:0.021949151530861855 norm:0.00017647165805101395 max memory_allocated 38136.60986328125 
[2025-03-16 08:09:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 9 loss:0.021908648312091827 norm:0.00017112185014411807 max memory_allocated 38136.60986328125 
[2025-03-16 08:10:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 10 loss:0.021886564791202545 norm:0.00016803813923615962 max memory_allocated 38136.60986328125 
[2025-03-16 08:11:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 11 loss:0.021873706951737404 norm:0.0001654811348998919 max memory_allocated 38136.60986328125 
[2025-03-16 08:12:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 12 loss:0.021878676488995552 norm:0.00016244806465692818 max memory_allocated 38136.60986328125 
[2025-03-16 08:13:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 13 loss:0.021858733147382736 norm:0.00015997845912352204 max memory_allocated 38136.60986328125 
[2025-03-16 08:14:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 14 loss:0.021857451647520065 norm:0.00015851808711886406 max memory_allocated 38136.60986328125 
[2025-03-16 08:15:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 15 loss:0.02184896543622017 norm:0.0001585550489835441 max memory_allocated 38136.60986328125 
[2025-03-16 08:16:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 16 loss:0.021852588281035423 norm:0.00015693130262661725 max memory_allocated 38136.60986328125 
[2025-03-16 08:17:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 17 loss:0.021847985684871674 norm:0.0001577689836267382 max memory_allocated 38136.60986328125 
[2025-03-16 08:18:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 18 loss:0.021812908351421356 norm:0.00015579783939756453 max memory_allocated 38136.60986328125 
[2025-03-16 08:19:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 19 loss:0.021821996197104454 norm:0.00015545020869467407 max memory_allocated 38136.60986328125 
[2025-03-16 08:19:38 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 16 to 17 ===
[2025-03-16 08:20:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 0 loss:0.056478697806596756 norm:0.0016388091025874019 max memory_allocated 38136.78173828125 
[2025-03-16 08:21:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 1 loss:0.04322941228747368 norm:0.0007492702570743859 max memory_allocated 38136.78173828125 
[2025-03-16 08:22:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 2 loss:0.03609410673379898 norm:0.0004888885887339711 max memory_allocated 38136.78173828125 
[2025-03-16 08:23:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 3 loss:0.03348410129547119 norm:0.0003828748594969511 max memory_allocated 38136.78173828125 
[2025-03-16 08:24:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 4 loss:0.03207913041114807 norm:0.0003295603673905134 max memory_allocated 38136.78173828125 
[2025-03-16 08:25:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 5 loss:0.03136255219578743 norm:0.0002971300855278969 max memory_allocated 38136.78173828125 
[2025-03-16 08:26:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 6 loss:0.0309723112732172 norm:0.0002713194116950035 max memory_allocated 38136.78173828125 
[2025-03-16 08:27:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 7 loss:0.030754748731851578 norm:0.0002594402467366308 max memory_allocated 38136.78173828125 
[2025-03-16 08:28:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 8 loss:0.03060947358608246 norm:0.00025017725420184433 max memory_allocated 38136.78173828125 
[2025-03-16 08:29:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 9 loss:0.030521217733621597 norm:0.00024258767371065915 max memory_allocated 38136.78173828125 
[2025-03-16 08:30:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 10 loss:0.030437447130680084 norm:0.00023623480228707194 max memory_allocated 38136.78173828125 
[2025-03-16 08:31:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 11 loss:0.030376948416233063 norm:0.00023029249859973788 max memory_allocated 38136.78173828125 
[2025-03-16 08:32:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 12 loss:0.030332304537296295 norm:0.0002268236712552607 max memory_allocated 38136.78173828125 
[2025-03-16 08:33:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 13 loss:0.030296489596366882 norm:0.00022346970217768103 max memory_allocated 38136.78173828125 
[2025-03-16 08:34:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 14 loss:0.03024986945092678 norm:0.00022239013924263418 max memory_allocated 38136.78173828125 
[2025-03-16 08:35:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 15 loss:0.03022049553692341 norm:0.00022086402168497443 max memory_allocated 38136.78173828125 
[2025-03-16 08:35:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 16 loss:0.03022158145904541 norm:0.00022059952607378364 max memory_allocated 38136.78173828125 
[2025-03-16 08:36:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 17 loss:0.030187519267201424 norm:0.00021810918406117707 max memory_allocated 38136.78173828125 
[2025-03-16 08:37:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 18 loss:0.030161425471305847 norm:0.00021671624563168734 max memory_allocated 38136.78173828125 
[2025-03-16 08:38:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 19 loss:0.030143702402710915 norm:0.0002152280358131975 max memory_allocated 38136.78173828125 
[2025-03-16 08:39:20 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 17 to 18 ===
[2025-03-16 08:40:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 0 loss:0.056810859590768814 norm:0.0012244093231856823 max memory_allocated 38136.95361328125 
[2025-03-16 08:41:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 1 loss:0.043936315923929214 norm:0.0005516082746908069 max memory_allocated 38136.95361328125 
[2025-03-16 08:42:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 2 loss:0.03727194666862488 norm:0.0004001647175755352 max memory_allocated 38136.95361328125 
[2025-03-16 08:43:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 3 loss:0.034953244030475616 norm:0.00034218054497614503 max memory_allocated 38136.95361328125 
[2025-03-16 08:44:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 4 loss:0.03363676741719246 norm:0.0003086045035161078 max memory_allocated 38136.95361328125 
[2025-03-16 08:45:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 5 loss:0.033076848834753036 norm:0.0002850677410606295 max memory_allocated 38136.95361328125 
[2025-03-16 08:46:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 6 loss:0.03282582387328148 norm:0.00027397950179874897 max memory_allocated 38136.95361328125 
[2025-03-16 08:47:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 7 loss:0.03264962136745453 norm:0.0002687388041522354 max memory_allocated 38136.95361328125 
[2025-03-16 08:48:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 8 loss:0.03254140540957451 norm:0.0002593061071820557 max memory_allocated 38136.95361328125 
[2025-03-16 08:48:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 9 loss:0.03249296918511391 norm:0.00025417309370823205 max memory_allocated 38136.95361328125 
[2025-03-16 08:49:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 10 loss:0.03240913152694702 norm:0.0002497104287613183 max memory_allocated 38136.95361328125 
[2025-03-16 08:50:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 11 loss:0.032349128276109695 norm:0.0002455513458698988 max memory_allocated 38136.95361328125 
[2025-03-16 08:51:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 12 loss:0.03232301399111748 norm:0.00024615295114926994 max memory_allocated 38136.95361328125 
[2025-03-16 08:52:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 13 loss:0.032304488122463226 norm:0.0002394414768787101 max memory_allocated 38136.95361328125 
[2025-03-16 08:53:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 14 loss:0.03227826952934265 norm:0.0002373207826167345 max memory_allocated 38136.95361328125 
[2025-03-16 08:54:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 15 loss:0.03228449076414108 norm:0.00023473173496313393 max memory_allocated 38136.95361328125 
[2025-03-16 08:55:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 16 loss:0.03225552290678024 norm:0.0002342701336601749 max memory_allocated 38136.95361328125 
[2025-03-16 08:56:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 17 loss:0.03224632889032364 norm:0.00023120555852074176 max memory_allocated 38136.95361328125 
[2025-03-16 08:57:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 18 loss:0.03221932798624039 norm:0.00023159029660746455 max memory_allocated 38136.95361328125 
[2025-03-16 08:58:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 19 loss:0.032221198081970215 norm:0.0002283157518832013 max memory_allocated 38136.95361328125 
[2025-03-16 08:58:59 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 18 to 19 ===
[2025-03-16 09:00:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 0 loss:0.05558709800243378 norm:0.0012652819277718663 max memory_allocated 38137.12548828125 
[2025-03-16 09:00:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 1 loss:0.04414874315261841 norm:0.0006144647486507893 max memory_allocated 38137.12548828125 
[2025-03-16 09:01:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 2 loss:0.037125010043382645 norm:0.00042403218685649335 max memory_allocated 38137.12548828125 
[2025-03-16 09:02:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 3 loss:0.03473328799009323 norm:0.0003422157315071672 max memory_allocated 38137.12548828125 
[2025-03-16 09:03:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 4 loss:0.03350997343659401 norm:0.0003029832732863724 max memory_allocated 38137.12548828125 
[2025-03-16 09:04:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 5 loss:0.03317929431796074 norm:0.0002868928713724017 max memory_allocated 38137.12548828125 
[2025-03-16 09:05:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 6 loss:0.0329289585351944 norm:0.0002719467447604984 max memory_allocated 38137.12548828125 
[2025-03-16 09:06:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 7 loss:0.03282349184155464 norm:0.0002671552065294236 max memory_allocated 38137.12548828125 
[2025-03-16 09:07:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 8 loss:0.03266846388578415 norm:0.0002588393399491906 max memory_allocated 38137.12548828125 
[2025-03-16 09:08:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 9 loss:0.03254079818725586 norm:0.0002466434962116182 max memory_allocated 38137.12548828125 
[2025-03-16 09:09:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 10 loss:0.03248090296983719 norm:0.0002446935686748475 max memory_allocated 38137.12548828125 
[2025-03-16 09:10:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 11 loss:0.03245328739285469 norm:0.00023899623192846775 max memory_allocated 38137.12548828125 
[2025-03-16 09:11:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 12 loss:0.03239987790584564 norm:0.00023522033006884158 max memory_allocated 38137.12548828125 
[2025-03-16 09:12:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 13 loss:0.032369282096624374 norm:0.00023041261010803282 max memory_allocated 38137.12548828125 
[2025-03-16 09:13:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 14 loss:0.03235200047492981 norm:0.00022885324142407626 max memory_allocated 38137.12548828125 
[2025-03-16 09:14:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 15 loss:0.032326579093933105 norm:0.00022618199000135064 max memory_allocated 38137.12548828125 
[2025-03-16 09:15:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 16 loss:0.032308079302310944 norm:0.0002241679758299142 max memory_allocated 38137.12548828125 
[2025-03-16 09:16:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 17 loss:0.032304778695106506 norm:0.0002227101067546755 max memory_allocated 38137.12548828125 
[2025-03-16 09:17:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 18 loss:0.032307617366313934 norm:0.00022044703655410558 max memory_allocated 38137.12548828125 
[2025-03-16 09:18:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 19 loss:0.03225967288017273 norm:0.000219071822357364 max memory_allocated 38137.12548828125 
[2025-03-16 09:18:37 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 19 to 20 ===
[2025-03-16 09:19:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 0 loss:0.06674690544605255 norm:0.0021684584207832813 max memory_allocated 38137.29736328125 
[2025-03-16 09:20:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 1 loss:0.05228079482913017 norm:0.000903804786503315 max memory_allocated 38137.29736328125 
[2025-03-16 09:21:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 2 loss:0.04326336458325386 norm:0.0005535526433959603 max memory_allocated 38137.29736328125 
[2025-03-16 09:22:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 3 loss:0.040256086736917496 norm:0.0004412703274283558 max memory_allocated 38137.29736328125 
[2025-03-16 09:23:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 4 loss:0.038945138454437256 norm:0.00037598403287120163 max memory_allocated 38137.29736328125 
[2025-03-16 09:24:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 5 loss:0.03842054679989815 norm:0.00034712112392298877 max memory_allocated 38137.29736328125 
[2025-03-16 09:25:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 6 loss:0.03814780339598656 norm:0.00032477552304044366 max memory_allocated 38137.29736328125 
[2025-03-16 09:26:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 7 loss:0.037976592779159546 norm:0.00030956638511270285 max memory_allocated 38137.29736328125 
[2025-03-16 09:27:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 8 loss:0.03783164918422699 norm:0.0002950964553747326 max memory_allocated 38137.29736328125 
[2025-03-16 09:28:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 9 loss:0.037688374519348145 norm:0.0002863821282517165 max memory_allocated 38137.29736328125 
[2025-03-16 09:29:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 10 loss:0.037627577781677246 norm:0.00027937343111261725 max memory_allocated 38137.29736328125 
[2025-03-16 09:30:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 11 loss:0.03754107654094696 norm:0.00027042606961913407 max memory_allocated 38137.29736328125 
[2025-03-16 09:31:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 12 loss:0.037487998604774475 norm:0.0002667406224645674 max memory_allocated 38137.29736328125 
[2025-03-16 09:32:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 13 loss:0.03743278235197067 norm:0.00026265293126925826 max memory_allocated 38137.29736328125 
[2025-03-16 09:32:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 14 loss:0.03741118311882019 norm:0.00025905983056873083 max memory_allocated 38137.29736328125 
[2025-03-16 09:33:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 15 loss:0.037387408316135406 norm:0.00026078426162712276 max memory_allocated 38137.29736328125 
[2025-03-16 09:34:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 16 loss:0.03735775500535965 norm:0.0002568031195551157 max memory_allocated 38137.29736328125 
[2025-03-16 09:35:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 17 loss:0.03734403848648071 norm:0.00025371884112246335 max memory_allocated 38137.29736328125 
[2025-03-16 09:36:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 18 loss:0.03735353797674179 norm:0.00025185634149238467 max memory_allocated 38137.29736328125 
[2025-03-16 09:37:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 19 loss:0.037313953042030334 norm:0.00024624395882710814 max memory_allocated 38137.29736328125 
[2025-03-16 09:38:14 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 20 to 21 ===
[2025-03-16 09:39:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 0 loss:0.07667739689350128 norm:0.0015417028916999698 max memory_allocated 38137.46923828125 
[2025-03-16 09:40:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 1 loss:0.06196720153093338 norm:0.0008777165785431862 max memory_allocated 38137.46923828125 
[2025-03-16 09:41:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 2 loss:0.05151426047086716 norm:0.000706008228007704 max memory_allocated 38137.46923828125 
[2025-03-16 09:42:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 3 loss:0.04831172153353691 norm:0.00060122279683128 max memory_allocated 38137.46923828125 
[2025-03-16 09:43:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 4 loss:0.046937473118305206 norm:0.0005762184737250209 max memory_allocated 38137.46923828125 
[2025-03-16 09:44:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 5 loss:0.0462627112865448 norm:0.0005424395203590393 max memory_allocated 38137.46923828125 
[2025-03-16 09:44:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 6 loss:0.045908812433481216 norm:0.0005238399608060718 max memory_allocated 38137.46923828125 
[2025-03-16 09:45:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 7 loss:0.04571758210659027 norm:0.0005186619237065315 max memory_allocated 38137.46923828125 
[2025-03-16 09:46:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 8 loss:0.045425496995449066 norm:0.000519265653565526 max memory_allocated 38137.46923828125 
[2025-03-16 09:47:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 9 loss:0.045219503343105316 norm:0.0005189327639527619 max memory_allocated 38137.46923828125 
[2025-03-16 09:48:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 10 loss:0.04510487616062164 norm:0.000548291951417923 max memory_allocated 38137.46923828125 
[2025-03-16 09:49:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 11 loss:0.0448213629424572 norm:0.0004977400531060994 max memory_allocated 38137.46923828125 
[2025-03-16 09:50:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 12 loss:0.04475748538970947 norm:0.0005096161039546132 max memory_allocated 38137.46923828125 
[2025-03-16 09:51:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 13 loss:0.04471605271100998 norm:0.0004920191131532192 max memory_allocated 38137.46923828125 
[2025-03-16 09:52:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 14 loss:0.04463863745331764 norm:0.0005383050884120166 max memory_allocated 38137.46923828125 
[2025-03-16 09:53:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 15 loss:0.0444362536072731 norm:0.0004748406063299626 max memory_allocated 38137.46923828125 
[2025-03-16 09:54:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 16 loss:0.04459300637245178 norm:0.00046856142580509186 max memory_allocated 38137.46923828125 
[2025-03-16 09:55:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 17 loss:0.044552210718393326 norm:0.0004790209059137851 max memory_allocated 38137.46923828125 
[2025-03-16 09:56:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 18 loss:0.04439762607216835 norm:0.00046475036651827395 max memory_allocated 38137.46923828125 
[2025-03-16 09:57:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 19 loss:0.04435349628329277 norm:0.00048164650797843933 max memory_allocated 38137.46923828125 
[2025-03-16 09:57:52 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 21 to 22 ===
[2025-03-16 09:58:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 0 loss:0.08416496217250824 norm:0.0017662595491856337 max memory_allocated 38137.64111328125 
[2025-03-16 09:59:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 1 loss:0.0664048045873642 norm:0.0009215917671099305 max memory_allocated 38137.64111328125 
[2025-03-16 10:00:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 2 loss:0.0547601617872715 norm:0.0006879973807372153 max memory_allocated 38137.64111328125 
[2025-03-16 10:01:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 3 loss:0.0509624220430851 norm:0.0006142533384263515 max memory_allocated 38137.64111328125 
[2025-03-16 10:02:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 4 loss:0.04955605790019035 norm:0.0005802675150334835 max memory_allocated 38137.64111328125 
[2025-03-16 10:03:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 5 loss:0.0489591583609581 norm:0.0005493626231327653 max memory_allocated 38137.64111328125 
[2025-03-16 10:04:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 6 loss:0.04862888902425766 norm:0.0005191401578485966 max memory_allocated 38137.64111328125 
[2025-03-16 10:05:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 7 loss:0.04826921597123146 norm:0.0005051622865721583 max memory_allocated 38137.64111328125 
[2025-03-16 10:06:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 8 loss:0.04801591485738754 norm:0.0004944269894622266 max memory_allocated 38137.64111328125 
[2025-03-16 10:07:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 9 loss:0.04787415266036987 norm:0.000488241552375257 max memory_allocated 38137.64111328125 
[2025-03-16 10:08:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 10 loss:0.04770559445023537 norm:0.0004961875383742154 max memory_allocated 38137.64111328125 
[2025-03-16 10:09:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 11 loss:0.04755678400397301 norm:0.0004706416220869869 max memory_allocated 38137.64111328125 
[2025-03-16 10:10:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 12 loss:0.047432754188776016 norm:0.00047088737483136356 max memory_allocated 38137.64111328125 
[2025-03-16 10:11:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 13 loss:0.0472986176609993 norm:0.00046261228271760046 max memory_allocated 38137.64111328125 
[2025-03-16 10:12:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 14 loss:0.04721317067742348 norm:0.0004715235554613173 max memory_allocated 38137.64111328125 
[2025-03-16 10:13:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 15 loss:0.04715478792786598 norm:0.00047853574506007135 max memory_allocated 38137.64111328125 
[2025-03-16 10:14:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 16 loss:0.0471000112593174 norm:0.0004720842407550663 max memory_allocated 38137.64111328125 
[2025-03-16 10:15:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 17 loss:0.0470421127974987 norm:0.0004761027230415493 max memory_allocated 38137.64111328125 
[2025-03-16 10:16:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 18 loss:0.047044359147548676 norm:0.00048594342661090195 max memory_allocated 38137.64111328125 
[2025-03-16 10:16:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 19 loss:0.04698818549513817 norm:0.00047690377687104046 max memory_allocated 38137.64111328125 
[2025-03-16 10:17:30 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 22 to 23 ===
[2025-03-16 10:18:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 0 loss:0.089540995657444 norm:0.0022293864749372005 max memory_allocated 38137.81298828125 
[2025-03-16 10:19:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 1 loss:0.07233423739671707 norm:0.001203531981445849 max memory_allocated 38137.81298828125 
[2025-03-16 10:20:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 2 loss:0.05928202345967293 norm:0.0007972451858222485 max memory_allocated 38137.81298828125 
[2025-03-16 10:21:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 3 loss:0.05531793832778931 norm:0.0006468808278441429 max memory_allocated 38137.81298828125 
[2025-03-16 10:22:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 4 loss:0.05401910841464996 norm:0.00055960554163903 max memory_allocated 38137.81298828125 
[2025-03-16 10:23:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 5 loss:0.053407855331897736 norm:0.0005141621804796159 max memory_allocated 38137.81298828125 
[2025-03-16 10:24:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 6 loss:0.053083453327417374 norm:0.0004958316567353904 max memory_allocated 38137.81298828125 
[2025-03-16 10:25:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 7 loss:0.052856411784887314 norm:0.00047268636990338564 max memory_allocated 38137.81298828125 
[2025-03-16 10:26:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 8 loss:0.052572596818208694 norm:0.0004413747519720346 max memory_allocated 38137.81298828125 
[2025-03-16 10:27:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 9 loss:0.052472129464149475 norm:0.00043555948650464416 max memory_allocated 38137.81298828125 
[2025-03-16 10:28:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 10 loss:0.05225767195224762 norm:0.0004187546146567911 max memory_allocated 38137.81298828125 
[2025-03-16 10:29:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 11 loss:0.05219072103500366 norm:0.0004160226962994784 max memory_allocated 38137.81298828125 
[2025-03-16 10:29:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 12 loss:0.05209679156541824 norm:0.0004091773880645633 max memory_allocated 38137.81298828125 
[2025-03-16 10:30:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 13 loss:0.05209657922387123 norm:0.00041055900510400534 max memory_allocated 38137.81298828125 
[2025-03-16 10:31:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 14 loss:0.05212404578924179 norm:0.00040402146987617016 max memory_allocated 38137.81298828125 
[2025-03-16 10:32:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 15 loss:0.052060727030038834 norm:0.000400322925997898 max memory_allocated 38137.81298828125 
[2025-03-16 10:33:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 16 loss:0.05202590674161911 norm:0.0003965070063713938 max memory_allocated 38137.81298828125 
[2025-03-16 10:34:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 17 loss:0.052087508141994476 norm:0.0003990863624494523 max memory_allocated 38137.81298828125 
[2025-03-16 10:35:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 18 loss:0.05210573971271515 norm:0.0003951707622036338 max memory_allocated 38137.81298828125 
[2025-03-16 10:36:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 19 loss:0.052041493356227875 norm:0.00039917315007187426 max memory_allocated 38137.81298828125 
[2025-03-16 10:37:08 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 23 to 24 ===
[2025-03-16 10:38:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 0 loss:0.10302498191595078 norm:0.0029714680276811123 max memory_allocated 38137.98486328125 
[2025-03-16 10:39:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 1 loss:0.08201468735933304 norm:0.0013722542207688093 max memory_allocated 38137.98486328125 
[2025-03-16 10:40:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 2 loss:0.06677624583244324 norm:0.0010281731374561787 max memory_allocated 38137.98486328125 
[2025-03-16 10:41:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 3 loss:0.06214718893170357 norm:0.0008237705333158374 max memory_allocated 38137.98486328125 
[2025-03-16 10:41:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 4 loss:0.060808196663856506 norm:0.0007663567084819078 max memory_allocated 38137.98486328125 
[2025-03-16 10:42:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 5 loss:0.060087576508522034 norm:0.0006811517523601651 max memory_allocated 38137.98486328125 
[2025-03-16 10:43:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 6 loss:0.05976805090904236 norm:0.0006640960345976055 max memory_allocated 38137.98486328125 
[2025-03-16 10:44:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 7 loss:0.05944131687283516 norm:0.0006432249792851508 max memory_allocated 38137.98486328125 
[2025-03-16 10:45:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 8 loss:0.059218551963567734 norm:0.0006282537360675633 max memory_allocated 38137.98486328125 
[2025-03-16 10:46:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 9 loss:0.059059251099824905 norm:0.0006095067365095019 max memory_allocated 38137.98486328125 
[2025-03-16 10:47:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 10 loss:0.05890693888068199 norm:0.0005850351299159229 max memory_allocated 38137.98486328125 
[2025-03-16 10:48:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 11 loss:0.0588885173201561 norm:0.0005879271775484085 max memory_allocated 38137.98486328125 
[2025-03-16 10:49:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 12 loss:0.05886796489357948 norm:0.0005704031209461391 max memory_allocated 38137.98486328125 
[2025-03-16 10:50:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 13 loss:0.05900628864765167 norm:0.0005734473816119134 max memory_allocated 38137.98486328125 
[2025-03-16 10:51:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 14 loss:0.058840904384851456 norm:0.0005584245081990957 max memory_allocated 38137.98486328125 
[2025-03-16 10:52:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 15 loss:0.058886464685201645 norm:0.0005536740645766258 max memory_allocated 38137.98486328125 
[2025-03-16 10:53:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 16 loss:0.058912962675094604 norm:0.0005779584171250463 max memory_allocated 38137.98486328125 
[2025-03-16 10:54:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 17 loss:0.05894395336508751 norm:0.0005594576359726489 max memory_allocated 38137.98486328125 
[2025-03-16 10:55:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 18 loss:0.058930642902851105 norm:0.0005479400279000401 max memory_allocated 38137.98486328125 
[2025-03-16 10:56:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 19 loss:0.05878138914704323 norm:0.0005568304914049804 max memory_allocated 38137.98486328125 
[2025-03-16 10:56:46 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 24 to 25 ===
[2025-03-16 10:57:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 0 loss:0.1079350933432579 norm:0.0021345452405512333 max memory_allocated 38138.15673828125 
[2025-03-16 10:58:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 1 loss:0.0852787122130394 norm:0.001057902816683054 max memory_allocated 38138.15673828125 
[2025-03-16 10:59:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 2 loss:0.06866089254617691 norm:0.0007294791284948587 max memory_allocated 38138.15673828125 
[2025-03-16 11:00:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 3 loss:0.06374431401491165 norm:0.0005884171696379781 max memory_allocated 38138.15673828125 
[2025-03-16 11:01:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 4 loss:0.06255704909563065 norm:0.0005310018314048648 max memory_allocated 38138.15673828125 
[2025-03-16 11:02:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 5 loss:0.06191572919487953 norm:0.0005075056105852127 max memory_allocated 38138.15673828125 
[2025-03-16 11:03:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 6 loss:0.06146583706140518 norm:0.00048168026842176914 max memory_allocated 38138.15673828125 
[2025-03-16 11:04:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 7 loss:0.061094675213098526 norm:0.00046259595546871424 max memory_allocated 38138.15673828125 
[2025-03-16 11:05:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 8 loss:0.06083780899643898 norm:0.00045362155651673675 max memory_allocated 38138.15673828125 
[2025-03-16 11:06:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 9 loss:0.060622330754995346 norm:0.00044957961654290557 max memory_allocated 38138.15673828125 
[2025-03-16 11:07:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 10 loss:0.06043338403105736 norm:0.0004520328075159341 max memory_allocated 38138.15673828125 
[2025-03-16 11:08:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 11 loss:0.06027664244174957 norm:0.0004495050525292754 max memory_allocated 38138.15673828125 
[2025-03-16 11:09:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 12 loss:0.060173213481903076 norm:0.0004502232186496258 max memory_allocated 38138.15673828125 
[2025-03-16 11:10:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 13 loss:0.06008199602365494 norm:0.00045390462037175894 max memory_allocated 38138.15673828125 
[2025-03-16 11:11:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 14 loss:0.060039304196834564 norm:0.00045526964822784066 max memory_allocated 38138.15673828125 
[2025-03-16 11:12:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 15 loss:0.059958141297101974 norm:0.0004541260132100433 max memory_allocated 38138.15673828125 
[2025-03-16 11:13:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 16 loss:0.059917744249105453 norm:0.00045711829443462193 max memory_allocated 38138.15673828125 
[2025-03-16 11:13:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 17 loss:0.05986187607049942 norm:0.00045529595809057355 max memory_allocated 38138.15673828125 
[2025-03-16 11:14:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 18 loss:0.05980566143989563 norm:0.00045547247282229364 max memory_allocated 38138.15673828125 
[2025-03-16 11:15:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 19 loss:0.05977528542280197 norm:0.0004592211334966123 max memory_allocated 38138.15673828125 
[2025-03-16 11:16:24 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 25 to 26 ===
[2025-03-16 11:17:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 0 loss:0.12465210258960724 norm:0.007743306923657656 max memory_allocated 38138.32861328125 
[2025-03-16 11:18:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 1 loss:0.09751632809638977 norm:0.003910280764102936 max memory_allocated 38138.32861328125 
[2025-03-16 11:19:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 2 loss:0.07759052515029907 norm:0.0022794518154114485 max memory_allocated 38138.32861328125 
[2025-03-16 11:20:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 3 loss:0.07132028043270111 norm:0.0016053564613685012 max memory_allocated 38138.32861328125 
[2025-03-16 11:21:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 4 loss:0.06967311352491379 norm:0.0012785176513716578 max memory_allocated 38138.32861328125 
[2025-03-16 11:22:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 5 loss:0.0689527690410614 norm:0.001090891775675118 max memory_allocated 38138.32861328125 
[2025-03-16 11:23:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 6 loss:0.06855213642120361 norm:0.0009620931232348084 max memory_allocated 38138.32861328125 
[2025-03-16 11:24:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 7 loss:0.06838194280862808 norm:0.0008356894832104445 max memory_allocated 38138.32861328125 
[2025-03-16 11:25:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 8 loss:0.0679028108716011 norm:0.0007351862732321024 max memory_allocated 38138.32861328125 
[2025-03-16 11:26:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 9 loss:0.06777699291706085 norm:0.0006763084093108773 max memory_allocated 38138.32861328125 
[2025-03-16 11:26:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 10 loss:0.06761641055345535 norm:0.0006165709346532822 max memory_allocated 38138.32861328125 
[2025-03-16 11:27:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 11 loss:0.0673663318157196 norm:0.0005836414056830108 max memory_allocated 38138.32861328125 
[2025-03-16 11:28:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 12 loss:0.06714314967393875 norm:0.0005632694228552282 max memory_allocated 38138.32861328125 
[2025-03-16 11:29:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 13 loss:0.06699511408805847 norm:0.000551507924683392 max memory_allocated 38138.32861328125 
[2025-03-16 11:30:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 14 loss:0.0670391395688057 norm:0.0005391835002228618 max memory_allocated 38138.32861328125 
[2025-03-16 11:31:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 15 loss:0.06684894859790802 norm:0.0005200832383707166 max memory_allocated 38138.32861328125 
[2025-03-16 11:32:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 16 loss:0.0669366717338562 norm:0.0005232080584391952 max memory_allocated 38138.32861328125 
[2025-03-16 11:33:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 17 loss:0.06686452776193619 norm:0.0005123051814734936 max memory_allocated 38138.32861328125 
[2025-03-16 11:34:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 18 loss:0.06680258363485336 norm:0.0005054629291407764 max memory_allocated 38138.32861328125 
[2025-03-16 11:35:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 19 loss:0.0668572336435318 norm:0.0005007813451811671 max memory_allocated 38138.32861328125 
[2025-03-16 11:36:02 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 26 to 27 ===
[2025-03-16 11:37:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 0 loss:0.13281556963920593 norm:0.004834566731005907 max memory_allocated 38138.50048828125 
[2025-03-16 11:38:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 1 loss:0.1057201474905014 norm:0.002579012420028448 max memory_allocated 38138.50048828125 
[2025-03-16 11:38:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 2 loss:0.08602038025856018 norm:0.0016780324513092637 max memory_allocated 38138.50048828125 
[2025-03-16 11:39:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 3 loss:0.08041293174028397 norm:0.0013086609542369843 max memory_allocated 38138.50048828125 
[2025-03-16 11:40:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 4 loss:0.07885140180587769 norm:0.0011192492675036192 max memory_allocated 38138.50048828125 
[2025-03-16 11:41:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 5 loss:0.07820975035429001 norm:0.0010918034240603447 max memory_allocated 38138.50048828125 
[2025-03-16 11:42:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 6 loss:0.07794995605945587 norm:0.0010036828462034464 max memory_allocated 38138.50048828125 
[2025-03-16 11:43:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 7 loss:0.07783928513526917 norm:0.0009420518763363361 max memory_allocated 38138.50048828125 
[2025-03-16 11:44:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 8 loss:0.07797771692276001 norm:0.0009160101180896163 max memory_allocated 38138.50048828125 
[2025-03-16 11:45:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 9 loss:0.07756725698709488 norm:0.0008934673969633877 max memory_allocated 38138.50048828125 
[2025-03-16 11:46:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 10 loss:0.07767242193222046 norm:0.000895677600055933 max memory_allocated 38138.50048828125 
[2025-03-16 11:47:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 11 loss:0.07816429436206818 norm:0.0008519563125446439 max memory_allocated 38138.50048828125 
[2025-03-16 11:48:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 12 loss:0.07757019996643066 norm:0.0008938657701946795 max memory_allocated 38138.50048828125 
[2025-03-16 11:49:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 13 loss:0.07785946875810623 norm:0.0008760449127294123 max memory_allocated 38138.50048828125 
[2025-03-16 11:50:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 14 loss:0.07755871117115021 norm:0.0009064316400326788 max memory_allocated 38138.50048828125 
[2025-03-16 11:51:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 15 loss:0.07795890420675278 norm:0.0008601324516348541 max memory_allocated 38138.50048828125 
[2025-03-16 11:52:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 16 loss:0.07774431258440018 norm:0.0008646115311421454 max memory_allocated 38138.50048828125 
[2025-03-16 11:53:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 17 loss:0.07799780368804932 norm:0.0008563345763832331 max memory_allocated 38138.50048828125 
[2025-03-16 11:54:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 18 loss:0.07799454778432846 norm:0.0008870312012732029 max memory_allocated 38138.50048828125 
[2025-03-16 11:55:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 19 loss:0.07826384902000427 norm:0.0008888755110092461 max memory_allocated 38138.50048828125 
[2025-03-16 11:55:41 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 27 to 28 ===
[2025-03-16 11:56:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 0 loss:0.14504790306091309 norm:0.018020039424300194 max memory_allocated 38138.84521484375 
[2025-03-16 11:57:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 1 loss:0.11589355766773224 norm:0.014466356486082077 max memory_allocated 38138.84521484375 
[2025-03-16 11:58:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 2 loss:0.09451043605804443 norm:0.010546444915235043 max memory_allocated 38138.84521484375 
[2025-03-16 11:59:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 3 loss:0.08863184601068497 norm:0.008782653138041496 max memory_allocated 38138.84521484375 
[2025-03-16 12:00:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 4 loss:0.08654209226369858 norm:0.007612195331603289 max memory_allocated 38138.84521484375 
[2025-03-16 12:01:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 5 loss:0.08531757444143295 norm:0.00639923382550478 max memory_allocated 38138.84521484375 
[2025-03-16 12:02:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 6 loss:0.08449354767799377 norm:0.005529741290956736 max memory_allocated 38138.84521484375 
[2025-03-16 12:03:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 7 loss:0.08416026830673218 norm:0.0054220836609601974 max memory_allocated 38138.84521484375 
[2025-03-16 12:04:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 8 loss:0.08391405642032623 norm:0.005344817414879799 max memory_allocated 38138.84521484375 
[2025-03-16 12:05:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 9 loss:0.08371345698833466 norm:0.004942348692566156 max memory_allocated 38138.84521484375 
[2025-03-16 12:06:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 10 loss:0.08337771147489548 norm:0.004394717048853636 max memory_allocated 38138.84521484375 
[2025-03-16 12:07:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 11 loss:0.08332538604736328 norm:0.0043365745805203915 max memory_allocated 38138.84521484375 
[2025-03-16 12:08:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 12 loss:0.08326220512390137 norm:0.004200657829642296 max memory_allocated 38138.84521484375 
[2025-03-16 12:09:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 13 loss:0.0832023099064827 norm:0.004085261840373278 max memory_allocated 38138.84521484375 
[2025-03-16 12:10:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 14 loss:0.08324813097715378 norm:0.004135447088629007 max memory_allocated 38138.84521484375 
[2025-03-16 12:11:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 15 loss:0.08348170667886734 norm:0.004208496306091547 max memory_allocated 38138.84521484375 
[2025-03-16 12:11:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 16 loss:0.08342451602220535 norm:0.0041929082944989204 max memory_allocated 38138.84521484375 
[2025-03-16 12:12:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 17 loss:0.08322964608669281 norm:0.003745370777323842 max memory_allocated 38138.84521484375 
[2025-03-16 12:13:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 18 loss:0.08321429044008255 norm:0.0036949769128113985 max memory_allocated 38138.84521484375 
[2025-03-16 12:14:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 19 loss:0.08323367685079575 norm:0.0035503534600138664 max memory_allocated 38138.84521484375 
[2025-03-16 12:15:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 28 to 29 ===
[2025-03-16 12:16:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 0 loss:0.16869494318962097 norm:0.02747162990272045 max memory_allocated 38140.18994140625 
[2025-03-16 12:17:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 1 loss:0.13216447830200195 norm:0.021549083292484283 max memory_allocated 38140.18994140625 
[2025-03-16 12:18:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 2 loss:0.10822875052690506 norm:0.014286024495959282 max memory_allocated 38140.18994140625 
[2025-03-16 12:19:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 3 loss:0.10176889598369598 norm:0.01019453164190054 max memory_allocated 38140.18994140625 
[2025-03-16 12:20:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 4 loss:0.09986714273691177 norm:0.008301883935928345 max memory_allocated 38140.18994140625 
[2025-03-16 12:21:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 5 loss:0.09879186749458313 norm:0.00727499695494771 max memory_allocated 38140.18994140625 
[2025-03-16 12:22:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 6 loss:0.09794279932975769 norm:0.006461324170231819 max memory_allocated 38140.18994140625 
[2025-03-16 12:23:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 7 loss:0.09732820838689804 norm:0.005885446909815073 max memory_allocated 38140.18994140625 
[2025-03-16 12:24:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 8 loss:0.09689558297395706 norm:0.00525716133415699 max memory_allocated 38140.18994140625 
[2025-03-16 12:25:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 9 loss:0.09687213599681854 norm:0.005108915269374847 max memory_allocated 38140.18994140625 
[2025-03-16 12:25:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 10 loss:0.09698978811502457 norm:0.005367017816752195 max memory_allocated 38140.18994140625 
[2025-03-16 12:26:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 11 loss:0.09698069840669632 norm:0.0049945698119699955 max memory_allocated 38140.18994140625 
[2025-03-16 12:27:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 12 loss:0.09663425385951996 norm:0.0045331609435379505 max memory_allocated 38140.18994140625 
[2025-03-16 12:28:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 13 loss:0.0967690646648407 norm:0.004376550670713186 max memory_allocated 38140.18994140625 
[2025-03-16 12:29:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 14 loss:0.09668642282485962 norm:0.004197712987661362 max memory_allocated 38140.18994140625 
[2025-03-16 12:30:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 15 loss:0.0966281145811081 norm:0.0040135737508535385 max memory_allocated 38140.18994140625 
[2025-03-16 12:31:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 16 loss:0.09670402109622955 norm:0.004265645984560251 max memory_allocated 38140.18994140625 
[2025-03-16 12:32:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 17 loss:0.09686015546321869 norm:0.004165865946561098 max memory_allocated 38140.18994140625 
[2025-03-16 12:33:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 18 loss:0.09686937928199768 norm:0.004021770786494017 max memory_allocated 38140.18994140625 
[2025-03-16 12:34:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 19 loss:0.09711237251758575 norm:0.003964944742619991 max memory_allocated 38140.18994140625 
[2025-03-16 12:35:03 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 29 to 30 ===
[2025-03-16 12:36:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 0 loss:0.3072938919067383 norm:0.05170028284192085 max memory_allocated 38140.18994140625 
[2025-03-16 12:37:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 1 loss:0.23889610171318054 norm:0.06679587811231613 max memory_allocated 38140.18994140625 
[2025-03-16 12:38:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 2 loss:0.19069211184978485 norm:0.05703667551279068 max memory_allocated 38140.18994140625 
[2025-03-16 12:38:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 3 loss:0.1817675679922104 norm:0.05398665368556976 max memory_allocated 38140.18994140625 
[2025-03-16 12:39:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 4 loss:0.18320950865745544 norm:0.048206716775894165 max memory_allocated 38140.18994140625 
[2025-03-16 12:40:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 5 loss:0.18630065023899078 norm:0.046606067568063736 max memory_allocated 38140.18994140625 
[2025-03-16 12:41:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 6 loss:0.1931445151567459 norm:0.046368375420570374 max memory_allocated 38140.18994140625 
[2025-03-16 12:42:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 7 loss:0.19520346820354462 norm:0.0520482063293457 max memory_allocated 38140.18994140625 
[2025-03-16 12:43:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 8 loss:0.19095705449581146 norm:0.048967428505420685 max memory_allocated 38140.18994140625 
[2025-03-16 12:44:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 9 loss:0.18502774834632874 norm:0.044636406004428864 max memory_allocated 38140.18994140625 
[2025-03-16 12:45:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 10 loss:0.18005752563476562 norm:0.03637884184718132 max memory_allocated 38140.18994140625 
[2025-03-16 12:46:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 11 loss:0.17711755633354187 norm:0.037405043840408325 max memory_allocated 38140.18994140625 
[2025-03-16 12:47:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 12 loss:0.1749858558177948 norm:0.037885282188653946 max memory_allocated 38140.18994140625 
[2025-03-16 12:48:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 13 loss:0.17228925228118896 norm:0.035196706652641296 max memory_allocated 38140.18994140625 
[2025-03-16 12:49:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 14 loss:0.16975054144859314 norm:0.03278780356049538 max memory_allocated 38140.18994140625 
[2025-03-16 12:50:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 15 loss:0.16828808188438416 norm:0.03099749982357025 max memory_allocated 38140.18994140625 
[2025-03-16 12:51:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 16 loss:0.168752521276474 norm:0.03392300382256508 max memory_allocated 38140.18994140625 
[2025-03-16 12:52:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 17 loss:0.16407766938209534 norm:0.03323258087038994 max memory_allocated 38140.18994140625 
[2025-03-16 12:53:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 18 loss:0.16285765171051025 norm:0.030791718512773514 max memory_allocated 38140.18994140625 
[2025-03-16 12:54:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 19 loss:0.16242149472236633 norm:0.03251420333981514 max memory_allocated 38140.18994140625 
[2025-03-16 12:54:44 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 30 to 31 ===
[2025-03-16 12:55:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 0 loss:1.1424229145050049 norm:0.20921321213245392 max memory_allocated 38140.18994140625 
[2025-03-16 12:56:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 1 loss:0.7576633095741272 norm:0.1566869616508484 max memory_allocated 38140.18994140625 
[2025-03-16 12:57:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 2 loss:0.5814093947410583 norm:0.12298505008220673 max memory_allocated 38140.18994140625 
[2025-03-16 12:58:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 3 loss:0.4981772005558014 norm:0.10198426991701126 max memory_allocated 38140.18994140625 
[2025-03-16 12:59:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 4 loss:0.4600074589252472 norm:0.08973875641822815 max memory_allocated 38140.18994140625 
[2025-03-16 13:00:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 5 loss:0.44451454281806946 norm:0.07492917776107788 max memory_allocated 38140.18994140625 
[2025-03-16 13:01:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 6 loss:0.44625768065452576 norm:0.07134880125522614 max memory_allocated 38140.18994140625 
[2025-03-16 13:02:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 7 loss:0.4382938742637634 norm:0.06490950286388397 max memory_allocated 38140.18994140625 
[2025-03-16 13:03:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 8 loss:0.4297952353954315 norm:0.06368115544319153 max memory_allocated 38140.18994140625 
[2025-03-16 13:04:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 9 loss:0.42421936988830566 norm:0.06405565142631531 max memory_allocated 38140.18994140625 
[2025-03-16 13:05:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 10 loss:0.4225841164588928 norm:0.06679742783308029 max memory_allocated 38140.18994140625 
[2025-03-16 13:06:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 11 loss:0.42179936170578003 norm:0.06573133170604706 max memory_allocated 38140.18994140625 
[2025-03-16 13:07:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 12 loss:0.41999706625938416 norm:0.06362857669591904 max memory_allocated 38140.18994140625 
[2025-03-16 13:08:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 13 loss:0.4150294065475464 norm:0.0622512549161911 max memory_allocated 38140.18994140625 
[2025-03-16 13:09:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 14 loss:0.41288211941719055 norm:0.06795649975538254 max memory_allocated 38140.18994140625 
[2025-03-16 13:10:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 15 loss:0.40602368116378784 norm:0.06422576308250427 max memory_allocated 38140.18994140625 
[2025-03-16 13:11:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 16 loss:0.4033092260360718 norm:0.07187414169311523 max memory_allocated 38140.18994140625 
[2025-03-16 13:11:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 17 loss:0.4040719270706177 norm:0.07278945297002792 max memory_allocated 38140.18994140625 
[2025-03-16 13:12:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 18 loss:0.40017494559288025 norm:0.0707201287150383 max memory_allocated 38140.18994140625 
[2025-03-16 13:13:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 19 loss:0.39553752541542053 norm:0.07265151292085648 max memory_allocated 38140.18994140625 
[2025-03-16 13:14:24 root] (main_calib_config3_cbq.py 376): INFO 36557.04227948189
[2025-03-16 13:14:37 root] (main_calib_config3_cbq.py 117): INFO load calibration from ./cache/testloader_llama_wikitext2_all.cache
[2025-03-16 13:15:37 root] (main_calib_config3_cbq.py 161): INFO wikitext2 : 495.6013488769531
[2025-03-16 13:15:37 root] (main_calib_config3_cbq.py 117): INFO load calibration from ./cache/testloader_llama_c4_all.cache
[2025-03-16 13:17:09 root] (main_calib_config3_cbq.py 161): INFO c4 : 1144.014892578125
[2025-03-16 14:35:04 root] (main_calib_config3_cbq.py 172): INFO {'wikitext2': 495.6013488769531, 'c4': 1144.014892578125, 'results': {'arc_easy': {'acc': 0.45496632996632996, 'acc_stderr': 0.010218084454602589, 'acc_norm': 0.3998316498316498, 'acc_norm_stderr': 0.010051788039412927}, 'winogrande': {'acc': 0.5919494869771112, 'acc_stderr': 0.013812822643745027}, 'hellaswag': {'acc': 0.48287193786098387, 'acc_stderr': 0.004986852842576718, 'acc_norm': 0.637024497112129, 'acc_norm_stderr': 0.004798751281560818}, 'boolq': {'acc': 0.48623853211009177, 'acc_stderr': 0.008741742106878655}, 'arc_challenge': {'acc': 0.24146757679180889, 'acc_stderr': 0.01250656483973943, 'acc_norm': 0.27303754266211605, 'acc_norm_stderr': 0.013019332762635744}, 'piqa': {'acc': 0.6022850924918389, 'acc_stderr': 0.011419114133117221, 'acc_norm': 0.5810663764961915, 'acc_norm_stderr': 0.011511473119995074}}, 'versions': {'arc_easy': 0, 'winogrande': 0, 'hellaswag': 0, 'boolq': 1, 'arc_challenge': 0, 'piqa': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
[2025-03-16 14:35:04 root] (main_calib_config3_cbq.py 175): INFO 24.15,45.50,48.62,48.29,60.23,59.19
