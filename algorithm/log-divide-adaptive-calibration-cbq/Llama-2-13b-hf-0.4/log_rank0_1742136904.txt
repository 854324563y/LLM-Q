[2025-03-16 14:55:04 root] (main_calib_config3_cbq.py 280): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-13b-hf', cache_dir='./cache', output_dir='./log-divide-adaptive-calibration-cbq/Llama-2-13b-hf-0.4', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-divide-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.4.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-16 14:55:05 root] (main_calib_config3_cbq.py 347): INFO === start quantization ===
[2025-03-16 14:55:05 root] (main_calib_config3_cbq.py 353): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-16 14:55:06 root] (abq_llm_calib_config3_cbq.py 82): INFO Starting ...
[2025-03-16 14:55:06 root] (abq_llm_calib_config3_cbq.py 89): INFO Loaded quant_map from log-divide-adaptive/Llama-2-13b-hf/quant_map_Llama-2-13b-hf_0.4.pkl
[2025-03-16 14:55:35 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 0 to 1 ===
[2025-03-16 14:57:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 0 loss:0.16767163574695587 norm:0.2048952579498291 max memory_allocated 49623.62158203125 
[2025-03-16 14:58:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 1 loss:0.1168024018406868 norm:0.13893894851207733 max memory_allocated 49623.62158203125 
[2025-03-16 14:59:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 2 loss:0.09336104989051819 norm:0.10314521193504333 max memory_allocated 49623.62158203125 
[2025-03-16 15:01:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 3 loss:0.08323004096746445 norm:0.07970570027828217 max memory_allocated 49623.62158203125 
[2025-03-16 15:02:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 4 loss:0.07731366902589798 norm:0.06465386599302292 max memory_allocated 49623.62158203125 
[2025-03-16 15:04:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 5 loss:0.07374438643455505 norm:0.057384785264730453 max memory_allocated 49623.62158203125 
[2025-03-16 15:05:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 6 loss:0.07055308669805527 norm:0.04903442785143852 max memory_allocated 49623.62158203125 
[2025-03-16 15:06:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 7 loss:0.06821359694004059 norm:0.04312025383114815 max memory_allocated 49623.62158203125 
[2025-03-16 15:08:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 8 loss:0.06664428859949112 norm:0.04033820703625679 max memory_allocated 49623.62158203125 
[2025-03-16 15:09:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 9 loss:0.06553591042757034 norm:0.035157568752765656 max memory_allocated 49623.62158203125 
[2025-03-16 15:11:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 10 loss:0.06483566761016846 norm:0.03418877720832825 max memory_allocated 49623.62158203125 
[2025-03-16 15:12:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 11 loss:0.06371130794286728 norm:0.031080767512321472 max memory_allocated 49623.62158203125 
[2025-03-16 15:14:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 12 loss:0.06310314685106277 norm:0.029436932876706123 max memory_allocated 49623.62158203125 
[2025-03-16 15:15:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 13 loss:0.06288982927799225 norm:0.028569189831614494 max memory_allocated 49623.62158203125 
[2025-03-16 15:16:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 14 loss:0.0629221647977829 norm:0.025976845994591713 max memory_allocated 49623.62158203125 
[2025-03-16 15:18:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 15 loss:0.0625452846288681 norm:0.023758549243211746 max memory_allocated 49623.62158203125 
[2025-03-16 15:19:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 16 loss:0.0618889257311821 norm:0.023088814690709114 max memory_allocated 49623.62158203125 
[2025-03-16 15:21:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 17 loss:0.061929523944854736 norm:0.02266743592917919 max memory_allocated 49623.62158203125 
[2025-03-16 15:22:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 18 loss:0.062179286032915115 norm:0.022308966144919395 max memory_allocated 49623.62158203125 
[2025-03-16 15:23:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 19 loss:0.061867039650678635 norm:0.02353403903543949 max memory_allocated 49623.62158203125 
[2025-03-16 15:24:39 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 1 to 2 ===
[2025-03-16 15:26:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 0 loss:0.06427298486232758 norm:0.1679466962814331 max memory_allocated 49664.45751953125 
[2025-03-16 15:27:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 1 loss:0.041597604751586914 norm:0.02289707399904728 max memory_allocated 49664.45751953125 
[2025-03-16 15:29:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 2 loss:0.03465692326426506 norm:0.015516004525125027 max memory_allocated 49664.45751953125 
[2025-03-16 15:30:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 3 loss:0.031325820833444595 norm:0.010695267468690872 max memory_allocated 49664.45751953125 
[2025-03-16 15:31:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 4 loss:0.02978573739528656 norm:0.008899852633476257 max memory_allocated 49664.45751953125 
[2025-03-16 15:33:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 5 loss:0.028510980308055878 norm:0.007219905965030193 max memory_allocated 49664.45751953125 
[2025-03-16 15:34:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 6 loss:0.027628598734736443 norm:0.0060263569466769695 max memory_allocated 49664.45751953125 
[2025-03-16 15:36:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 7 loss:0.026982739567756653 norm:0.005362596362829208 max memory_allocated 49664.45751953125 
[2025-03-16 15:37:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 8 loss:0.0264615248888731 norm:0.00472172861918807 max memory_allocated 49664.45751953125 
[2025-03-16 15:38:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 9 loss:0.026105131953954697 norm:0.0043835025280714035 max memory_allocated 49664.45751953125 
[2025-03-16 15:40:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 10 loss:0.025711169466376305 norm:0.003740752814337611 max memory_allocated 49664.45751953125 
[2025-03-16 15:41:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 11 loss:0.025465790182352066 norm:0.003560826415196061 max memory_allocated 49664.45751953125 
[2025-03-16 15:43:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 12 loss:0.025348389521241188 norm:0.0035556319635361433 max memory_allocated 49664.45751953125 
[2025-03-16 15:44:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 13 loss:0.02519925683736801 norm:0.0031744204461574554 max memory_allocated 49664.45751953125 
[2025-03-16 15:45:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 14 loss:0.02503376267850399 norm:0.0029718477744609118 max memory_allocated 49664.45751953125 
[2025-03-16 15:47:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 15 loss:0.02492704428732395 norm:0.00293120089918375 max memory_allocated 49664.45751953125 
[2025-03-16 15:48:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 16 loss:0.024873264133930206 norm:0.00279616704210639 max memory_allocated 49664.45751953125 
[2025-03-16 15:50:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 17 loss:0.024722155183553696 norm:0.002571013756096363 max memory_allocated 49664.45751953125 
[2025-03-16 15:51:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 18 loss:0.024752618744969368 norm:0.0026884006801992655 max memory_allocated 49664.45751953125 
[2025-03-16 15:53:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 19 loss:0.02468506246805191 norm:0.0025824434123933315 max memory_allocated 49664.45751953125 
[2025-03-16 15:53:48 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 2 to 3 ===
[2025-03-16 15:55:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 0 loss:0.07921856641769409 norm:0.5550886392593384 max memory_allocated 49664.45751953125 
[2025-03-16 15:56:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 1 loss:0.044104646891355515 norm:0.03681151196360588 max memory_allocated 49664.45751953125 
[2025-03-16 15:58:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 2 loss:0.033891044557094574 norm:0.02175971493124962 max memory_allocated 49664.45751953125 
[2025-03-16 15:59:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 3 loss:0.029436811804771423 norm:0.021775059401988983 max memory_allocated 49664.45751953125 
[2025-03-16 16:00:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 4 loss:0.026610445231199265 norm:0.016310418024659157 max memory_allocated 49664.45751953125 
[2025-03-16 16:02:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 5 loss:0.02452557347714901 norm:0.013336599804461002 max memory_allocated 49664.45751953125 
[2025-03-16 16:03:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 6 loss:0.023036181926727295 norm:0.01134343259036541 max memory_allocated 49664.45751953125 
[2025-03-16 16:05:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 7 loss:0.021894600242376328 norm:0.00966027844697237 max memory_allocated 49664.45751953125 
[2025-03-16 16:06:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 8 loss:0.021307704970240593 norm:0.008469793014228344 max memory_allocated 49664.45751953125 
[2025-03-16 16:08:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 9 loss:0.02047841250896454 norm:0.00715163629502058 max memory_allocated 49664.45751953125 
[2025-03-16 16:09:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 10 loss:0.02039950154721737 norm:0.007393747568130493 max memory_allocated 49664.45751953125 
[2025-03-16 16:10:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 11 loss:0.020261870697140694 norm:0.006828069221228361 max memory_allocated 49664.45751953125 
[2025-03-16 16:12:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 12 loss:0.019612424075603485 norm:0.0053247492760419846 max memory_allocated 49664.45751953125 
[2025-03-16 16:13:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 13 loss:0.019323721528053284 norm:0.005514375865459442 max memory_allocated 49664.45751953125 
[2025-03-16 16:15:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 14 loss:0.018829822540283203 norm:0.004904631059616804 max memory_allocated 49664.45751953125 
[2025-03-16 16:16:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 15 loss:0.01878472790122032 norm:0.004392444621771574 max memory_allocated 49664.45751953125 
[2025-03-16 16:17:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 16 loss:0.018709979951381683 norm:0.004479491151869297 max memory_allocated 49664.45751953125 
[2025-03-16 16:19:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 17 loss:0.018496863543987274 norm:0.004229497630149126 max memory_allocated 49664.45751953125 
[2025-03-16 16:20:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 18 loss:0.01844911091029644 norm:0.003953176084905863 max memory_allocated 49664.45751953125 
[2025-03-16 16:22:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 19 loss:0.01851261779665947 norm:0.003947168588638306 max memory_allocated 49664.45751953125 
[2025-03-16 16:22:56 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 3 to 4 ===
[2025-03-16 16:24:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 0 loss:0.1459941416978836 norm:0.04456990584731102 max memory_allocated 49666.39892578125 
[2025-03-16 16:25:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 1 loss:0.07124099135398865 norm:0.014362558722496033 max memory_allocated 49666.39892578125 
[2025-03-16 16:27:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 2 loss:0.05120496824383736 norm:0.01419300027191639 max memory_allocated 49666.39892578125 
[2025-03-16 16:28:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 3 loss:0.03999127447605133 norm:0.012723680585622787 max memory_allocated 49666.39892578125 
[2025-03-16 16:30:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 4 loss:0.03851940482854843 norm:0.014867899008095264 max memory_allocated 49666.39892578125 
[2025-03-16 16:31:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 5 loss:0.034600984305143356 norm:0.013613413088023663 max memory_allocated 49666.39892578125 
[2025-03-16 16:32:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 6 loss:0.03406878188252449 norm:0.015081281773746014 max memory_allocated 49666.39892578125 
[2025-03-16 16:34:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 7 loss:0.03350672498345375 norm:0.01771453022956848 max memory_allocated 49666.39892578125 
[2025-03-16 16:35:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 8 loss:0.06460276246070862 norm:0.0251772440969944 max memory_allocated 49666.39892578125 
[2025-03-16 16:37:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 9 loss:0.032840512692928314 norm:0.008589130826294422 max memory_allocated 49666.39892578125 
[2025-03-16 16:38:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 10 loss:0.02585637755692005 norm:0.007863063365221024 max memory_allocated 49666.39892578125 
[2025-03-16 16:39:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 11 loss:0.022372685372829437 norm:0.004993703681975603 max memory_allocated 49666.39892578125 
[2025-03-16 16:41:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 12 loss:0.027873747050762177 norm:0.009495147503912449 max memory_allocated 49666.39892578125 
[2025-03-16 16:42:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 13 loss:0.03875768557190895 norm:0.017992496490478516 max memory_allocated 49666.39892578125 
[2025-03-16 16:44:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 14 loss:0.03180775046348572 norm:0.013694223016500473 max memory_allocated 49666.39892578125 
[2025-03-16 16:45:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 15 loss:0.03635696321725845 norm:0.01957627944648266 max memory_allocated 49666.39892578125 
[2025-03-16 16:47:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 16 loss:0.02815587818622589 norm:0.010829423554241657 max memory_allocated 49666.39892578125 
[2025-03-16 16:48:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 17 loss:0.02395065315067768 norm:0.008072614669799805 max memory_allocated 49666.39892578125 
[2025-03-16 16:49:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 18 loss:0.02670382894575596 norm:0.011772369034588337 max memory_allocated 49666.39892578125 
[2025-03-16 16:51:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 19 loss:0.01766118034720421 norm:0.003096835222095251 max memory_allocated 49666.39892578125 
[2025-03-16 16:51:59 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 4 to 5 ===
[2025-03-16 16:53:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 0 loss:0.0730162113904953 norm:0.01731814816594124 max memory_allocated 49666.39892578125 
[2025-03-16 16:54:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 1 loss:0.036031439900398254 norm:0.005216782446950674 max memory_allocated 49666.39892578125 
[2025-03-16 16:56:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 2 loss:0.024819888174533844 norm:0.002744475146755576 max memory_allocated 49666.39892578125 
[2025-03-16 16:57:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 3 loss:0.020163483917713165 norm:0.0020190400537103415 max memory_allocated 49666.39892578125 
[2025-03-16 16:59:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 4 loss:0.017182866111397743 norm:0.0014831944135949016 max memory_allocated 49666.39892578125 
[2025-03-16 17:00:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 5 loss:0.015055583789944649 norm:0.0012265645200386643 max memory_allocated 49666.39892578125 
[2025-03-16 17:01:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 6 loss:0.01354657020419836 norm:0.0010172621114179492 max memory_allocated 49666.39892578125 
[2025-03-16 17:03:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 7 loss:0.012379905208945274 norm:0.0008081407286226749 max memory_allocated 49666.39892578125 
[2025-03-16 17:04:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 8 loss:0.01159323938190937 norm:0.0007168120355345309 max memory_allocated 49666.39892578125 
[2025-03-16 17:06:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 9 loss:0.010981667786836624 norm:0.0005819540238007903 max memory_allocated 49666.39892578125 
[2025-03-16 17:07:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 10 loss:0.010378092527389526 norm:0.000510882236994803 max memory_allocated 49666.39892578125 
[2025-03-16 17:09:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 11 loss:0.009980029426515102 norm:0.0004719803691841662 max memory_allocated 49666.39892578125 
[2025-03-16 17:10:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 12 loss:0.009639019146561623 norm:0.0004612708289641887 max memory_allocated 49666.39892578125 
[2025-03-16 17:11:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 13 loss:0.00938335433602333 norm:0.00042551365913823247 max memory_allocated 49666.39892578125 
[2025-03-16 17:13:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 14 loss:0.009136645123362541 norm:0.00039903982542455196 max memory_allocated 49666.39892578125 
[2025-03-16 17:14:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 15 loss:0.008967362344264984 norm:0.00038591292104683816 max memory_allocated 49666.39892578125 
[2025-03-16 17:16:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 16 loss:0.008856158703565598 norm:0.0004098823410458863 max memory_allocated 49666.39892578125 
[2025-03-16 17:17:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 17 loss:0.008726689033210278 norm:0.00038525008130818605 max memory_allocated 49666.39892578125 
[2025-03-16 17:18:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 18 loss:0.00862196460366249 norm:0.00036935810931026936 max memory_allocated 49666.39892578125 
[2025-03-16 17:20:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 19 loss:0.008565777912735939 norm:0.0003884409670718014 max memory_allocated 49666.39892578125 
[2025-03-16 17:21:04 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 5 to 6 ===
[2025-03-16 17:22:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 0 loss:0.08506307750940323 norm:0.021375274285674095 max memory_allocated 49666.39892578125 
[2025-03-16 17:24:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 1 loss:0.0378790907561779 norm:0.005633516702800989 max memory_allocated 49666.39892578125 
[2025-03-16 17:25:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 2 loss:0.023048972710967064 norm:0.0025729488115757704 max memory_allocated 49666.39892578125 
[2025-03-16 17:26:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 3 loss:0.016685374081134796 norm:0.0015249982243403792 max memory_allocated 49666.39892578125 
[2025-03-16 17:28:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 4 loss:0.01400158740580082 norm:0.001047926489263773 max memory_allocated 49666.39892578125 
[2025-03-16 17:29:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 5 loss:0.012477660551667213 norm:0.0007654988439753652 max memory_allocated 49666.39892578125 
[2025-03-16 17:31:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 6 loss:0.011485971510410309 norm:0.0006108998786658049 max memory_allocated 49666.39892578125 
[2025-03-16 17:32:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 7 loss:0.010776023380458355 norm:0.0005186119815334678 max memory_allocated 49666.39892578125 
[2025-03-16 17:33:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 8 loss:0.01028449647128582 norm:0.0004724900936707854 max memory_allocated 49666.39892578125 
[2025-03-16 17:35:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 9 loss:0.009915444999933243 norm:0.00041563413105905056 max memory_allocated 49666.39892578125 
[2025-03-16 17:36:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 10 loss:0.009608468040823936 norm:0.0003773882635869086 max memory_allocated 49666.77392578125 
[2025-03-16 17:38:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 11 loss:0.009369480423629284 norm:0.0003734152123797685 max memory_allocated 49666.77392578125 
[2025-03-16 17:39:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 12 loss:0.009140326641499996 norm:0.00033161439932882786 max memory_allocated 49666.77392578125 
[2025-03-16 17:40:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 13 loss:0.008956761099398136 norm:0.0003119523753412068 max memory_allocated 49666.77392578125 
[2025-03-16 17:42:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 14 loss:0.008831024169921875 norm:0.00030320993391796947 max memory_allocated 49666.77392578125 
[2025-03-16 17:43:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 15 loss:0.00870035495609045 norm:0.0002881212567444891 max memory_allocated 49666.77392578125 
[2025-03-16 17:45:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 16 loss:0.008595139719545841 norm:0.000277961342362687 max memory_allocated 49666.77392578125 
[2025-03-16 17:46:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 17 loss:0.00849971454590559 norm:0.00025632453616708517 max memory_allocated 49666.77392578125 
[2025-03-16 17:47:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 18 loss:0.008420833386480808 norm:0.0002365053369430825 max memory_allocated 49666.77392578125 
[2025-03-16 17:49:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 19 loss:0.008377126418054104 norm:0.0002319449558854103 max memory_allocated 49666.77392578125 
[2025-03-16 17:50:10 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 6 to 7 ===
[2025-03-16 17:51:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 0 loss:0.0625266507267952 norm:0.01101023331284523 max memory_allocated 49666.77392578125 
[2025-03-16 17:53:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 1 loss:0.0363335944712162 norm:0.004599903244525194 max memory_allocated 49666.77392578125 
[2025-03-16 17:54:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 2 loss:0.02651297114789486 norm:0.00253113335929811 max memory_allocated 49666.77392578125 
[2025-03-16 17:55:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 3 loss:0.020984211936593056 norm:0.001506119268015027 max memory_allocated 49666.77392578125 
[2025-03-16 17:57:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 4 loss:0.018002761527895927 norm:0.000930083857383579 max memory_allocated 49666.77392578125 
[2025-03-16 17:58:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 5 loss:0.016573121771216393 norm:0.0006030876538716257 max memory_allocated 49666.77392578125 
[2025-03-16 18:00:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 6 loss:0.015561978332698345 norm:0.0004677384567912668 max memory_allocated 49666.77392578125 
[2025-03-16 18:01:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 7 loss:0.014817914925515652 norm:0.00038398129981942475 max memory_allocated 49666.77392578125 
[2025-03-16 18:02:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 8 loss:0.014397773891687393 norm:0.0003514569252729416 max memory_allocated 49666.77392578125 
[2025-03-16 18:04:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 9 loss:0.013994339853525162 norm:0.00032951909815892577 max memory_allocated 49666.77392578125 
[2025-03-16 18:05:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 10 loss:0.013588394969701767 norm:0.0002992649096995592 max memory_allocated 49666.77392578125 
[2025-03-16 18:07:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 11 loss:0.013241690583527088 norm:0.00029386940877884626 max memory_allocated 49666.77392578125 
[2025-03-16 18:08:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 12 loss:0.01309429295361042 norm:0.0002871229953598231 max memory_allocated 49666.77392578125 
[2025-03-16 18:10:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 13 loss:0.01287982240319252 norm:0.0002686715160962194 max memory_allocated 49666.77392578125 
[2025-03-16 18:11:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 14 loss:0.01276255864650011 norm:0.00026296841679140925 max memory_allocated 49666.77392578125 
[2025-03-16 18:12:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 15 loss:0.0126522621139884 norm:0.00025242831907235086 max memory_allocated 49666.77392578125 
[2025-03-16 18:14:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 16 loss:0.012526196427643299 norm:0.00024851251509971917 max memory_allocated 49666.77392578125 
[2025-03-16 18:15:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 17 loss:0.012447269633412361 norm:0.0002460049872752279 max memory_allocated 49666.77392578125 
[2025-03-16 18:17:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 18 loss:0.012381423264741898 norm:0.00022929374244995415 max memory_allocated 49666.77392578125 
[2025-03-16 18:18:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 19 loss:0.012251324951648712 norm:0.00021997695148456842 max memory_allocated 49666.77392578125 
[2025-03-16 18:19:16 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 7 to 8 ===
[2025-03-16 18:20:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 0 loss:0.07017119228839874 norm:0.009713729843497276 max memory_allocated 49666.77392578125 
[2025-03-16 18:22:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 1 loss:0.0401289239525795 norm:0.0038467003032565117 max memory_allocated 49666.77392578125 
[2025-03-16 18:23:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 2 loss:0.030107595026493073 norm:0.002164557809010148 max memory_allocated 49666.77392578125 
[2025-03-16 18:25:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 3 loss:0.02473604865372181 norm:0.0013975356705486774 max memory_allocated 49666.77392578125 
[2025-03-16 18:26:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 4 loss:0.02192920260131359 norm:0.0009789110627025366 max memory_allocated 49666.77392578125 
[2025-03-16 18:27:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 5 loss:0.02017693594098091 norm:0.0007927965489216149 max memory_allocated 49666.77392578125 
[2025-03-16 18:29:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 6 loss:0.019069602712988853 norm:0.0007264380110427737 max memory_allocated 49666.77392578125 
[2025-03-16 18:30:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 7 loss:0.018341779708862305 norm:0.0006892856326885521 max memory_allocated 49666.77392578125 
[2025-03-16 18:32:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 8 loss:0.01788315735757351 norm:0.0006589296390302479 max memory_allocated 49666.77392578125 
[2025-03-16 18:33:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 9 loss:0.017452990636229515 norm:0.0005700038745999336 max memory_allocated 49666.77392578125 
[2025-03-16 18:35:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 10 loss:0.017132634297013283 norm:0.0005155497929081321 max memory_allocated 49666.77392578125 
[2025-03-16 18:36:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 11 loss:0.01689940318465233 norm:0.0005123593145981431 max memory_allocated 49666.77392578125 
[2025-03-16 18:37:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 12 loss:0.01669844426214695 norm:0.00046882854076102376 max memory_allocated 49666.77392578125 
[2025-03-16 18:39:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 13 loss:0.016461534425616264 norm:0.0004369072848930955 max memory_allocated 49666.77392578125 
[2025-03-16 18:40:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 14 loss:0.016323387622833252 norm:0.00044252988300286233 max memory_allocated 49666.77392578125 
[2025-03-16 18:42:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 15 loss:0.016238845884799957 norm:0.00044497597264125943 max memory_allocated 49666.77392578125 
[2025-03-16 18:43:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 16 loss:0.01614837348461151 norm:0.00042332112207077444 max memory_allocated 49666.77392578125 
[2025-03-16 18:44:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 17 loss:0.016059286892414093 norm:0.00042810646118596196 max memory_allocated 49666.77392578125 
[2025-03-16 18:46:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 18 loss:0.01595372147858143 norm:0.000398698408389464 max memory_allocated 49666.77392578125 
[2025-03-16 18:47:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 19 loss:0.015927232801914215 norm:0.0003839411656372249 max memory_allocated 49666.77392578125 
[2025-03-16 18:48:27 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 8 to 9 ===
[2025-03-16 18:50:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 0 loss:0.061990007758140564 norm:0.008625947870314121 max memory_allocated 49666.77392578125 
[2025-03-16 18:51:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 1 loss:0.03854057937860489 norm:0.00311683164909482 max memory_allocated 49666.77392578125 
[2025-03-16 18:52:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 2 loss:0.0303645022213459 norm:0.0017498396337032318 max memory_allocated 49666.77392578125 
[2025-03-16 18:54:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 3 loss:0.026138581335544586 norm:0.0011556311510503292 max memory_allocated 49666.77392578125 
[2025-03-16 18:55:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 4 loss:0.02400059625506401 norm:0.0008734409930184484 max memory_allocated 49666.77392578125 
[2025-03-16 18:57:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 5 loss:0.022636016830801964 norm:0.0007221383275464177 max memory_allocated 49666.77392578125 
[2025-03-16 18:58:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 6 loss:0.021741338074207306 norm:0.0006209592102095485 max memory_allocated 49666.77392578125 
[2025-03-16 18:59:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 7 loss:0.021089736372232437 norm:0.0005492786876857281 max memory_allocated 49666.77392578125 
[2025-03-16 19:01:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 8 loss:0.020712733268737793 norm:0.0005345847457647324 max memory_allocated 49666.77392578125 
[2025-03-16 19:02:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 9 loss:0.020424317568540573 norm:0.0004890970885753632 max memory_allocated 49666.77392578125 
[2025-03-16 19:04:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 10 loss:0.020106518641114235 norm:0.0004742188611999154 max memory_allocated 49666.77392578125 
[2025-03-16 19:05:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 11 loss:0.019876662641763687 norm:0.0004555960185825825 max memory_allocated 49666.77392578125 
[2025-03-16 19:06:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 12 loss:0.019696036353707314 norm:0.00044781534234061837 max memory_allocated 49666.77392578125 
[2025-03-16 19:08:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 13 loss:0.019614605233073235 norm:0.0004370641545392573 max memory_allocated 49666.77392578125 
[2025-03-16 19:09:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 14 loss:0.01948569156229496 norm:0.00042722842772491276 max memory_allocated 49666.77392578125 
[2025-03-16 19:11:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 15 loss:0.019358187913894653 norm:0.00042797840433195233 max memory_allocated 49666.77392578125 
[2025-03-16 19:12:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 16 loss:0.019233811646699905 norm:0.00041303594480268657 max memory_allocated 49666.77392578125 
[2025-03-16 19:13:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 17 loss:0.01914982870221138 norm:0.00040168670238927007 max memory_allocated 49666.77392578125 
[2025-03-16 19:15:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 18 loss:0.01908559910953045 norm:0.000405136524932459 max memory_allocated 49666.77392578125 
[2025-03-16 19:16:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 19 loss:0.018982170149683952 norm:0.00039122303132899106 max memory_allocated 49666.77392578125 
[2025-03-16 19:17:34 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 9 to 10 ===
[2025-03-16 19:19:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 0 loss:0.06752464175224304 norm:0.004759402945637703 max memory_allocated 49666.77392578125 
[2025-03-16 19:20:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 1 loss:0.03782924264669418 norm:0.001587614300660789 max memory_allocated 49666.77392578125 
[2025-03-16 19:21:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 2 loss:0.029401980340480804 norm:0.0008171364897862077 max memory_allocated 49666.77392578125 
[2025-03-16 19:23:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 3 loss:0.025364501401782036 norm:0.000619355880189687 max memory_allocated 49666.77392578125 
[2025-03-16 19:24:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 4 loss:0.02334035187959671 norm:0.0005319564370438457 max memory_allocated 49666.77392578125 
[2025-03-16 19:26:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 5 loss:0.02199096418917179 norm:0.00048236193833872676 max memory_allocated 49666.77392578125 
[2025-03-16 19:27:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 6 loss:0.02101024240255356 norm:0.0004548795404843986 max memory_allocated 49666.77392578125 
[2025-03-16 19:29:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 7 loss:0.02032647654414177 norm:0.0004299718711990863 max memory_allocated 49666.77392578125 
[2025-03-16 19:30:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 8 loss:0.019841812551021576 norm:0.0004115635820198804 max memory_allocated 49666.77392578125 
[2025-03-16 19:31:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 9 loss:0.019475359469652176 norm:0.0003969660319853574 max memory_allocated 49666.77392578125 
[2025-03-16 19:33:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 10 loss:0.019149646162986755 norm:0.0003835192183032632 max memory_allocated 49666.77392578125 
[2025-03-16 19:34:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 11 loss:0.018916474655270576 norm:0.0003784251166507602 max memory_allocated 49666.77392578125 
[2025-03-16 19:36:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 12 loss:0.01873553916811943 norm:0.0003717539366334677 max memory_allocated 49666.77392578125 
[2025-03-16 19:37:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 13 loss:0.018558625131845474 norm:0.00035086486604996026 max memory_allocated 49666.77392578125 
[2025-03-16 19:38:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 14 loss:0.01844784989953041 norm:0.00033576582791283727 max memory_allocated 49666.77392578125 
[2025-03-16 19:40:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 15 loss:0.018345994874835014 norm:0.0003216188051737845 max memory_allocated 49666.77392578125 
[2025-03-16 19:41:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 16 loss:0.018271703273057938 norm:0.00032277387799695134 max memory_allocated 49666.77392578125 
[2025-03-16 19:43:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 17 loss:0.01820588856935501 norm:0.0003164767113048583 max memory_allocated 49666.77392578125 
[2025-03-16 19:44:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 18 loss:0.018140999600291252 norm:0.0003164395166095346 max memory_allocated 49666.77392578125 
[2025-03-16 19:45:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 19 loss:0.01806323044002056 norm:0.000305754947476089 max memory_allocated 49666.77392578125 
[2025-03-16 19:46:41 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 10 to 11 ===
[2025-03-16 19:48:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 0 loss:0.04684797674417496 norm:0.003217362565919757 max memory_allocated 49666.77392578125 
[2025-03-16 19:49:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 1 loss:0.03160775452852249 norm:0.0012828635517507792 max memory_allocated 49666.77392578125 
[2025-03-16 19:51:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 2 loss:0.02547793835401535 norm:0.0007077702903188765 max memory_allocated 49666.77392578125 
[2025-03-16 19:52:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 3 loss:0.022244460880756378 norm:0.00045832223258912563 max memory_allocated 49666.77392578125 
[2025-03-16 19:53:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 4 loss:0.020640140399336815 norm:0.0003435100370552391 max memory_allocated 49666.77392578125 
[2025-03-16 19:55:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 5 loss:0.019748985767364502 norm:0.00028332238434813917 max memory_allocated 49666.77392578125 
[2025-03-16 19:56:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 6 loss:0.019155414775013924 norm:0.0002471389598213136 max memory_allocated 49666.77392578125 
[2025-03-16 19:58:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 7 loss:0.018728889524936676 norm:0.0002239940076833591 max memory_allocated 49666.77392578125 
[2025-03-16 19:59:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 8 loss:0.01844407245516777 norm:0.00020583938749041408 max memory_allocated 49666.77392578125 
[2025-03-16 20:00:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 9 loss:0.018245182931423187 norm:0.00019462833006400615 max memory_allocated 49666.77392578125 
[2025-03-16 20:02:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 10 loss:0.018108051270246506 norm:0.00018600487965159118 max memory_allocated 49666.77392578125 
[2025-03-16 20:03:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 11 loss:0.018016619607806206 norm:0.00017772715364117175 max memory_allocated 49666.77392578125 
[2025-03-16 20:05:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 12 loss:0.017963234335184097 norm:0.00016899425827432424 max memory_allocated 49666.77392578125 
[2025-03-16 20:06:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 13 loss:0.017917515709996223 norm:0.00016463722568005323 max memory_allocated 49666.77392578125 
[2025-03-16 20:07:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 14 loss:0.017888659611344337 norm:0.00016137557395268232 max memory_allocated 49666.77392578125 
[2025-03-16 20:09:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 15 loss:0.017857009544968605 norm:0.00016030538245104253 max memory_allocated 49666.77392578125 
[2025-03-16 20:10:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 16 loss:0.017842832952737808 norm:0.0001583142438903451 max memory_allocated 49666.77392578125 
[2025-03-16 20:12:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 17 loss:0.017827246338129044 norm:0.00015810424520168453 max memory_allocated 49666.77392578125 
[2025-03-16 20:13:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 18 loss:0.017812242731451988 norm:0.00015664454258512706 max memory_allocated 49666.77392578125 
[2025-03-16 20:15:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 19 loss:0.01778976060450077 norm:0.00015507587522733957 max memory_allocated 49666.77392578125 
[2025-03-16 20:15:48 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 11 to 12 ===
[2025-03-16 20:17:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 0 loss:0.04814484342932701 norm:0.003319467417895794 max memory_allocated 49666.89892578125 
[2025-03-16 20:18:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 1 loss:0.030903663486242294 norm:0.0011513318167999387 max memory_allocated 49666.89892578125 
[2025-03-16 20:20:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 2 loss:0.02482975274324417 norm:0.0006134024006314576 max memory_allocated 49666.89892578125 
[2025-03-16 20:21:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 3 loss:0.021623793989419937 norm:0.00039511689101345837 max memory_allocated 49666.89892578125 
[2025-03-16 20:23:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 4 loss:0.02004709094762802 norm:0.00028749226476065814 max memory_allocated 49666.89892578125 
[2025-03-16 20:24:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 5 loss:0.01914583146572113 norm:0.00024524788022972643 max memory_allocated 49666.89892578125 
[2025-03-16 20:25:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 6 loss:0.01855500601232052 norm:0.0002125870669260621 max memory_allocated 49666.89892578125 
[2025-03-16 20:27:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 7 loss:0.018121255561709404 norm:0.00019730208441615105 max memory_allocated 49666.89892578125 
[2025-03-16 20:28:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 8 loss:0.017847415059804916 norm:0.0001830417604651302 max memory_allocated 49666.89892578125 
[2025-03-16 20:30:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 9 loss:0.01763450726866722 norm:0.00017256953287869692 max memory_allocated 49666.89892578125 
[2025-03-16 20:31:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 10 loss:0.017493775114417076 norm:0.0001664491428527981 max memory_allocated 49666.89892578125 
[2025-03-16 20:32:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 11 loss:0.01738540455698967 norm:0.00015872162475716323 max memory_allocated 49666.89892578125 
[2025-03-16 20:34:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 12 loss:0.017321502789855003 norm:0.00015425545279867947 max memory_allocated 49666.89892578125 
[2025-03-16 20:35:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 13 loss:0.01727179065346718 norm:0.00014788180124014616 max memory_allocated 49666.89892578125 
[2025-03-16 20:37:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 14 loss:0.01723080314695835 norm:0.00014550043852068484 max memory_allocated 49666.89892578125 
[2025-03-16 20:38:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 15 loss:0.017211537808179855 norm:0.00014238612493500113 max memory_allocated 49666.89892578125 
[2025-03-16 20:39:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 16 loss:0.017199082300066948 norm:0.00014270392421167344 max memory_allocated 49666.89892578125 
[2025-03-16 20:41:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 17 loss:0.017183642834424973 norm:0.0001407878880854696 max memory_allocated 49666.89892578125 
[2025-03-16 20:42:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 18 loss:0.017171919345855713 norm:0.0001394374412484467 max memory_allocated 49666.89892578125 
[2025-03-16 20:44:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 19 loss:0.01716870442032814 norm:0.0001408708340022713 max memory_allocated 49666.89892578125 
[2025-03-16 20:44:53 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 12 to 13 ===
[2025-03-16 20:46:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 0 loss:0.062488630414009094 norm:0.005464155226945877 max memory_allocated 49667.08642578125 
[2025-03-16 20:47:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 1 loss:0.03968825936317444 norm:0.0021685552783310413 max memory_allocated 49667.08642578125 
[2025-03-16 20:49:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 2 loss:0.030627956613898277 norm:0.0011065535945817828 max memory_allocated 49667.08642578125 
[2025-03-16 20:50:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 3 loss:0.026452723890542984 norm:0.0007564573315903544 max memory_allocated 49667.08642578125 
[2025-03-16 20:52:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 4 loss:0.024406980723142624 norm:0.0006087849615141749 max memory_allocated 49667.08642578125 
[2025-03-16 20:53:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 5 loss:0.023103253915905952 norm:0.0005101314163766801 max memory_allocated 49667.08642578125 
[2025-03-16 20:54:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 6 loss:0.02231513522565365 norm:0.00046395271783694625 max memory_allocated 49667.08642578125 
[2025-03-16 20:56:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 7 loss:0.021757367998361588 norm:0.00041831989074125886 max memory_allocated 49667.08642578125 
[2025-03-16 20:57:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 8 loss:0.021343622356653214 norm:0.00036401243414729834 max memory_allocated 49667.08642578125 
[2025-03-16 20:59:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 9 loss:0.021003907546401024 norm:0.000350775895640254 max memory_allocated 49667.08642578125 
[2025-03-16 21:00:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 10 loss:0.020767565816640854 norm:0.0003162286593578756 max memory_allocated 49667.08642578125 
[2025-03-16 21:01:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 11 loss:0.02067463845014572 norm:0.0003005016187671572 max memory_allocated 49667.08642578125 
[2025-03-16 21:03:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 12 loss:0.020577237010002136 norm:0.00028491561533883214 max memory_allocated 49667.08642578125 
[2025-03-16 21:04:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 13 loss:0.020443715155124664 norm:0.0002611973031889647 max memory_allocated 49667.08642578125 
[2025-03-16 21:06:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 14 loss:0.020426109433174133 norm:0.0002649774251040071 max memory_allocated 49667.08642578125 
[2025-03-16 21:07:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 15 loss:0.020394690334796906 norm:0.00026567684835754335 max memory_allocated 49667.08642578125 
[2025-03-16 21:08:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 16 loss:0.020358223468065262 norm:0.0002525635645724833 max memory_allocated 49667.08642578125 
[2025-03-16 21:10:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 17 loss:0.020335840061306953 norm:0.00024266609398182482 max memory_allocated 49667.08642578125 
[2025-03-16 21:11:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 18 loss:0.020374644547700882 norm:0.0002448411541990936 max memory_allocated 49667.08642578125 
[2025-03-16 21:13:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 19 loss:0.020388828590512276 norm:0.00024253549054265022 max memory_allocated 49667.08642578125 
[2025-03-16 21:13:54 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 13 to 14 ===
[2025-03-16 21:15:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 0 loss:0.060128115117549896 norm:0.002345216926187277 max memory_allocated 49667.08642578125 
[2025-03-16 21:16:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 1 loss:0.036263059824705124 norm:0.0009182216599583626 max memory_allocated 49667.08642578125 
[2025-03-16 21:18:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 2 loss:0.028729744255542755 norm:0.0005738993058912456 max memory_allocated 49667.08642578125 
[2025-03-16 21:19:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 3 loss:0.0252379160374403 norm:0.0004639711114577949 max memory_allocated 49667.08642578125 
[2025-03-16 21:21:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 4 loss:0.02344745583832264 norm:0.00039457500679418445 max memory_allocated 49667.08642578125 
[2025-03-16 21:22:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 5 loss:0.022407110780477524 norm:0.00036292767617851496 max memory_allocated 49667.08642578125 
[2025-03-16 21:23:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 6 loss:0.021686667576432228 norm:0.00034473114646971226 max memory_allocated 49667.08642578125 
[2025-03-16 21:25:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 7 loss:0.02112811617553234 norm:0.0003176843165419996 max memory_allocated 49667.08642578125 
[2025-03-16 21:26:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 8 loss:0.020692532882094383 norm:0.000300707237329334 max memory_allocated 49667.08642578125 
[2025-03-16 21:28:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 9 loss:0.020380837842822075 norm:0.00028871820541098714 max memory_allocated 49667.08642578125 
[2025-03-16 21:29:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 10 loss:0.020137876272201538 norm:0.00027412123745307326 max memory_allocated 49667.08642578125 
[2025-03-16 21:30:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 11 loss:0.019972816109657288 norm:0.00027200483600609004 max memory_allocated 49667.08642578125 
[2025-03-16 21:32:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 12 loss:0.019842220470309258 norm:0.0002664672501850873 max memory_allocated 49667.08642578125 
[2025-03-16 21:33:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 13 loss:0.019739173352718353 norm:0.00025591152370907366 max memory_allocated 49667.08642578125 
[2025-03-16 21:35:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 14 loss:0.01964845322072506 norm:0.0002594173711258918 max memory_allocated 49667.08642578125 
[2025-03-16 21:36:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 15 loss:0.019561823457479477 norm:0.00024385718279518187 max memory_allocated 49667.08642578125 
[2025-03-16 21:37:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 16 loss:0.019515138119459152 norm:0.00024088086502160877 max memory_allocated 49667.08642578125 
[2025-03-16 21:39:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 17 loss:0.019458016380667686 norm:0.00023772160056978464 max memory_allocated 49667.08642578125 
[2025-03-16 21:40:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 18 loss:0.01940450631082058 norm:0.00023720765602774918 max memory_allocated 49667.08642578125 
[2025-03-16 21:42:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 19 loss:0.01937088742852211 norm:0.00023949387832544744 max memory_allocated 49667.08642578125 
[2025-03-16 21:42:55 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 14 to 15 ===
[2025-03-16 21:44:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 0 loss:0.044119495898485184 norm:0.001718898769468069 max memory_allocated 49667.46142578125 
[2025-03-16 21:45:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 1 loss:0.030968274921178818 norm:0.0006691529415547848 max memory_allocated 49667.46142578125 
[2025-03-16 21:47:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 2 loss:0.02551240473985672 norm:0.00039800387457944453 max memory_allocated 49667.46142578125 
[2025-03-16 21:48:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 3 loss:0.02293754369020462 norm:0.00030255448655225337 max memory_allocated 49667.46142578125 
[2025-03-16 21:50:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 4 loss:0.021673841401934624 norm:0.00024855200899764895 max memory_allocated 49667.46142578125 
[2025-03-16 21:51:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 5 loss:0.020889246836304665 norm:0.00021838660177309066 max memory_allocated 49667.46142578125 
[2025-03-16 21:52:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 6 loss:0.020343117415905 norm:0.00020065621356479824 max memory_allocated 49667.46142578125 
[2025-03-16 21:54:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 7 loss:0.01997576467692852 norm:0.000187433572136797 max memory_allocated 49667.46142578125 
[2025-03-16 21:55:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 8 loss:0.01970263198018074 norm:0.00017755628505256027 max memory_allocated 49667.46142578125 
[2025-03-16 21:57:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 9 loss:0.01949397101998329 norm:0.00017199109424836934 max memory_allocated 49667.46142578125 
[2025-03-16 21:58:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 10 loss:0.01934809237718582 norm:0.0001644814183237031 max memory_allocated 49667.46142578125 
[2025-03-16 21:59:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 11 loss:0.019249627366662025 norm:0.00015983585035428405 max memory_allocated 49667.46142578125 
[2025-03-16 22:01:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 12 loss:0.019164614379405975 norm:0.00015577219892293215 max memory_allocated 49667.46142578125 
[2025-03-16 22:02:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 13 loss:0.019108597189188004 norm:0.00015386362792924047 max memory_allocated 49667.46142578125 
[2025-03-16 22:04:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 14 loss:0.01905030757188797 norm:0.000151934233144857 max memory_allocated 49667.46142578125 
[2025-03-16 22:05:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 15 loss:0.019003713503479958 norm:0.0001505158725194633 max memory_allocated 49667.46142578125 
[2025-03-16 22:06:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 16 loss:0.018980853259563446 norm:0.00014987580652814358 max memory_allocated 49667.46142578125 
[2025-03-16 22:08:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 17 loss:0.018962152302265167 norm:0.00014865415869280696 max memory_allocated 49667.46142578125 
[2025-03-16 22:09:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 18 loss:0.018933100625872612 norm:0.00014862381794955581 max memory_allocated 49667.46142578125 
[2025-03-16 22:11:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 19 loss:0.018907107412815094 norm:0.00014759451732970774 max memory_allocated 49667.46142578125 
[2025-03-16 22:11:57 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 15 to 16 ===
[2025-03-16 22:13:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 0 loss:0.04329593479633331 norm:0.0012723137624561787 max memory_allocated 49667.46142578125 
[2025-03-16 22:14:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 1 loss:0.03108026459813118 norm:0.0005149811040610075 max memory_allocated 49667.46142578125 
[2025-03-16 22:16:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 2 loss:0.02573869563639164 norm:0.00033589242957532406 max memory_allocated 49667.46142578125 
[2025-03-16 22:17:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 3 loss:0.023267973214387894 norm:0.00025613358593545854 max memory_allocated 49667.46142578125 
[2025-03-16 22:19:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 4 loss:0.02199292927980423 norm:0.0002174719120375812 max memory_allocated 49667.46142578125 
[2025-03-16 22:20:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 5 loss:0.02123703435063362 norm:0.00019964696548413485 max memory_allocated 49667.46142578125 
[2025-03-16 22:21:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 6 loss:0.020718371495604515 norm:0.00018786609871312976 max memory_allocated 49667.46142578125 
[2025-03-16 22:23:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 7 loss:0.020373672246932983 norm:0.00018088685465045273 max memory_allocated 49667.46142578125 
[2025-03-16 22:24:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 8 loss:0.020080363377928734 norm:0.00017128439503721893 max memory_allocated 49667.46142578125 
[2025-03-16 22:26:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 9 loss:0.019887840375304222 norm:0.00016780613805167377 max memory_allocated 49667.46142578125 
[2025-03-16 22:27:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 10 loss:0.019750189036130905 norm:0.00016508923727087677 max memory_allocated 49667.46142578125 
[2025-03-16 22:28:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 11 loss:0.019630804657936096 norm:0.00016135167970787734 max memory_allocated 49667.46142578125 
[2025-03-16 22:30:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 12 loss:0.019534293562173843 norm:0.00015750204329378903 max memory_allocated 49667.46142578125 
[2025-03-16 22:31:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 13 loss:0.019464947283267975 norm:0.00015686292317695916 max memory_allocated 49667.46142578125 
[2025-03-16 22:33:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 14 loss:0.019397109746932983 norm:0.00015387249004561454 max memory_allocated 49667.46142578125 
[2025-03-16 22:34:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 15 loss:0.019361471757292747 norm:0.0001546550338389352 max memory_allocated 49667.46142578125 
[2025-03-16 22:36:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 16 loss:0.0193238016217947 norm:0.00015255545440595597 max memory_allocated 49667.46142578125 
[2025-03-16 22:37:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 17 loss:0.01928221434354782 norm:0.0001508521818323061 max memory_allocated 49667.46142578125 
[2025-03-16 22:38:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 18 loss:0.019252074882388115 norm:0.00014937185915187 max memory_allocated 49667.46142578125 
[2025-03-16 22:40:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 19 loss:0.019225357100367546 norm:0.00014909532910678536 max memory_allocated 49667.46142578125 
[2025-03-16 22:41:00 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 16 to 17 ===
[2025-03-16 22:42:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 0 loss:0.04774609953165054 norm:0.0026166567113250494 max memory_allocated 49667.46142578125 
[2025-03-16 22:43:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 1 loss:0.03501506149768829 norm:0.0012729099253192544 max memory_allocated 49667.46142578125 
[2025-03-16 22:45:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 2 loss:0.029093487188220024 norm:0.0008036257931962609 max memory_allocated 49667.46142578125 
[2025-03-16 22:46:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 3 loss:0.02652614563703537 norm:0.0005948523757979274 max memory_allocated 49667.46142578125 
[2025-03-16 22:48:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 4 loss:0.025288688018918037 norm:0.0004992044996470213 max memory_allocated 49667.46142578125 
[2025-03-16 22:49:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 5 loss:0.024495761841535568 norm:0.00043613757588900626 max memory_allocated 49667.46142578125 
[2025-03-16 22:51:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 6 loss:0.02393024042248726 norm:0.00038688071072101593 max memory_allocated 49667.46142578125 
[2025-03-16 22:52:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 7 loss:0.023598672822117805 norm:0.0003638006455730647 max memory_allocated 49667.46142578125 
[2025-03-16 22:53:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 8 loss:0.02328139916062355 norm:0.0003244224935770035 max memory_allocated 49667.46142578125 
[2025-03-16 22:55:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 9 loss:0.023069968447089195 norm:0.00030255073215812445 max memory_allocated 49667.46142578125 
[2025-03-16 22:56:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 10 loss:0.02290141023695469 norm:0.00028654211200773716 max memory_allocated 49667.46142578125 
[2025-03-16 22:58:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 11 loss:0.02278372459113598 norm:0.0002761446812655777 max memory_allocated 49667.46142578125 
[2025-03-16 22:59:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 12 loss:0.02263881079852581 norm:0.0002602762542665005 max memory_allocated 49667.46142578125 
[2025-03-16 23:00:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 13 loss:0.0225840974599123 norm:0.0002524017181713134 max memory_allocated 49667.46142578125 
[2025-03-16 23:02:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 14 loss:0.022537708282470703 norm:0.000246725685428828 max memory_allocated 49667.46142578125 
[2025-03-16 23:03:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 15 loss:0.022509712725877762 norm:0.00024207150272559375 max memory_allocated 49667.46142578125 
[2025-03-16 23:05:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 16 loss:0.022464120760560036 norm:0.00023156317183747888 max memory_allocated 49667.46142578125 
[2025-03-16 23:06:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 17 loss:0.022434856742620468 norm:0.0002218717272626236 max memory_allocated 49667.46142578125 
[2025-03-16 23:07:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 18 loss:0.022417480126023293 norm:0.00021443860896397382 max memory_allocated 49667.46142578125 
[2025-03-16 23:09:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 19 loss:0.022396406158804893 norm:0.00021172960987314582 max memory_allocated 49667.46142578125 
[2025-03-16 23:10:04 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 17 to 18 ===
[2025-03-16 23:11:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 0 loss:0.08688952773809433 norm:0.007251233793795109 max memory_allocated 49667.46142578125 
[2025-03-16 23:13:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 1 loss:0.03856891766190529 norm:0.0010023876093328 max memory_allocated 49667.46142578125 
[2025-03-16 23:14:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 2 loss:0.0304616279900074 norm:0.0005926132434979081 max memory_allocated 49667.46142578125 
[2025-03-16 23:15:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 3 loss:0.027450233697891235 norm:0.0004883623332716525 max memory_allocated 49667.46142578125 
[2025-03-16 23:17:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 4 loss:0.02581315115094185 norm:0.0004383125342428684 max memory_allocated 49667.46142578125 
[2025-03-16 23:18:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 5 loss:0.0247171763330698 norm:0.0004023892688564956 max memory_allocated 49667.46142578125 
[2025-03-16 23:20:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 6 loss:0.023882482200860977 norm:0.0003761397674679756 max memory_allocated 49667.46142578125 
[2025-03-16 23:21:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 7 loss:0.023234013468027115 norm:0.00035351444967091084 max memory_allocated 49667.46142578125 
[2025-03-16 23:22:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 8 loss:0.022768033668398857 norm:0.0003388553159311414 max memory_allocated 49667.46142578125 
[2025-03-16 23:24:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 9 loss:0.022436056286096573 norm:0.00032176016247831285 max memory_allocated 49667.46142578125 
[2025-03-16 23:25:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 10 loss:0.02217072620987892 norm:0.00030869466718286276 max memory_allocated 49667.46142578125 
[2025-03-16 23:27:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 11 loss:0.021974598988890648 norm:0.0003021868469659239 max memory_allocated 49668.02392578125 
[2025-03-16 23:28:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 12 loss:0.02182404138147831 norm:0.0002977705153170973 max memory_allocated 49668.02392578125 
[2025-03-16 23:29:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 13 loss:0.021673934534192085 norm:0.0002901083789765835 max memory_allocated 49668.02392578125 
[2025-03-16 23:31:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 14 loss:0.0215502567589283 norm:0.0002797198831103742 max memory_allocated 49668.02392578125 
[2025-03-16 23:32:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 15 loss:0.021435681730508804 norm:0.00027046530158258975 max memory_allocated 49668.02392578125 
[2025-03-16 23:34:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 16 loss:0.02134227380156517 norm:0.0002613890974316746 max memory_allocated 49668.02392578125 
[2025-03-16 23:35:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 17 loss:0.02125120535492897 norm:0.00025446759536862373 max memory_allocated 49668.02392578125 
[2025-03-16 23:36:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 18 loss:0.021189874038100243 norm:0.00024795561330392957 max memory_allocated 49668.02392578125 
[2025-03-16 23:38:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 19 loss:0.02111980691552162 norm:0.00024284431128762662 max memory_allocated 49668.02392578125 
[2025-03-16 23:39:06 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 18 to 19 ===
[2025-03-16 23:40:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 0 loss:0.0437183678150177 norm:0.0031922422349452972 max memory_allocated 49668.02392578125 
[2025-03-16 23:42:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 1 loss:0.03328598663210869 norm:0.0016079959459602833 max memory_allocated 49668.02392578125 
[2025-03-16 23:43:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 2 loss:0.0279574953019619 norm:0.0010090041905641556 max memory_allocated 49668.02392578125 
[2025-03-16 23:44:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 3 loss:0.025732863694429398 norm:0.0007340718875639141 max memory_allocated 49668.02392578125 
[2025-03-16 23:46:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 4 loss:0.024533268064260483 norm:0.0005806854460388422 max memory_allocated 49668.02392578125 
[2025-03-16 23:47:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 5 loss:0.023769561201334 norm:0.0004954190226271749 max memory_allocated 49668.02392578125 
[2025-03-16 23:49:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 6 loss:0.023268824443221092 norm:0.0004415881703607738 max memory_allocated 49668.02392578125 
[2025-03-16 23:50:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 7 loss:0.022924384102225304 norm:0.00039882544660940766 max memory_allocated 49668.02392578125 
[2025-03-16 23:52:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 8 loss:0.0227060429751873 norm:0.00038525089621543884 max memory_allocated 49668.02392578125 
[2025-03-16 23:53:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 9 loss:0.0225397776812315 norm:0.0003474329423625022 max memory_allocated 49668.02392578125 
[2025-03-16 23:54:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 10 loss:0.022413719445466995 norm:0.0003262719255872071 max memory_allocated 49668.02392578125 
[2025-03-16 23:56:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 11 loss:0.02234269492328167 norm:0.00031542673241347075 max memory_allocated 49668.02392578125 
[2025-03-16 23:57:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 12 loss:0.022293297573924065 norm:0.0003038354916498065 max memory_allocated 49668.02392578125 
[2025-03-16 23:59:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 13 loss:0.02224264107644558 norm:0.000287257949821651 max memory_allocated 49668.02392578125 
[2025-03-17 00:00:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 14 loss:0.022212142124772072 norm:0.0002759292838163674 max memory_allocated 49668.02392578125 
[2025-03-17 00:01:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 15 loss:0.022164806723594666 norm:0.0002656526630744338 max memory_allocated 49668.02392578125 
[2025-03-17 00:03:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 16 loss:0.022101111710071564 norm:0.0002527552132960409 max memory_allocated 49668.02392578125 
[2025-03-17 00:04:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 17 loss:0.02204374223947525 norm:0.00023914617486298084 max memory_allocated 49668.02392578125 
[2025-03-17 00:06:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 18 loss:0.021992050111293793 norm:0.000232277117902413 max memory_allocated 49668.02392578125 
[2025-03-17 00:07:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 19 loss:0.02195761539041996 norm:0.00022664775315206498 max memory_allocated 49668.02392578125 
[2025-03-17 00:08:16 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 19 to 20 ===
[2025-03-17 00:09:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 0 loss:0.05480131506919861 norm:0.002857165178284049 max memory_allocated 49668.02392578125 
[2025-03-17 00:11:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 1 loss:0.03528006374835968 norm:0.0009359304676763713 max memory_allocated 49668.02392578125 
[2025-03-17 00:12:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 2 loss:0.029065540060400963 norm:0.0006363419233821332 max memory_allocated 49668.02392578125 
[2025-03-17 00:14:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 3 loss:0.026710430160164833 norm:0.000515796709805727 max memory_allocated 49668.02392578125 
[2025-03-17 00:15:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 4 loss:0.02536327764391899 norm:0.0004497644549701363 max memory_allocated 49668.02392578125 
[2025-03-17 00:16:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 5 loss:0.02440628595650196 norm:0.00041180691914632916 max memory_allocated 49668.02392578125 
[2025-03-17 00:18:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 6 loss:0.02368079498410225 norm:0.00038189569022506475 max memory_allocated 49668.02392578125 
[2025-03-17 00:19:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 7 loss:0.023118600249290466 norm:0.0003520206082612276 max memory_allocated 49668.02392578125 
[2025-03-17 00:21:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 8 loss:0.022754551842808723 norm:0.00033043816802091897 max memory_allocated 49668.02392578125 
[2025-03-17 00:22:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 9 loss:0.022494662553071976 norm:0.000311831827275455 max memory_allocated 49668.02392578125 
[2025-03-17 00:23:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 10 loss:0.02228163555264473 norm:0.00029395625460892916 max memory_allocated 49668.02392578125 
[2025-03-17 00:25:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 11 loss:0.02213108539581299 norm:0.00028143456438556314 max memory_allocated 49668.02392578125 
[2025-03-17 00:26:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 12 loss:0.02197699062526226 norm:0.00026716195861808956 max memory_allocated 49668.02392578125 
[2025-03-17 00:28:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 13 loss:0.02187892608344555 norm:0.000258151616435498 max memory_allocated 49668.02392578125 
[2025-03-17 00:29:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 14 loss:0.02176435850560665 norm:0.0002566463954281062 max memory_allocated 49668.02392578125 
[2025-03-17 00:30:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 15 loss:0.02167372778058052 norm:0.0002540342975407839 max memory_allocated 49668.02392578125 
[2025-03-17 00:32:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 16 loss:0.021589217707514763 norm:0.00024458469124510884 max memory_allocated 49668.02392578125 
[2025-03-17 00:33:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 17 loss:0.021514588966965675 norm:0.00023874384351074696 max memory_allocated 49668.02392578125 
[2025-03-17 00:35:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 18 loss:0.021452054381370544 norm:0.00023288650845643133 max memory_allocated 49668.02392578125 
[2025-03-17 00:36:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 19 loss:0.021416982635855675 norm:0.00022884718782734126 max memory_allocated 49668.02392578125 
[2025-03-17 00:37:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 20 to 21 ===
[2025-03-17 00:38:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 0 loss:0.03710075840353966 norm:0.0009228768176399171 max memory_allocated 49668.58642578125 
[2025-03-17 00:40:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 1 loss:0.027966244146227837 norm:0.0004358211299404502 max memory_allocated 49668.58642578125 
[2025-03-17 00:41:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 2 loss:0.02306925691664219 norm:0.000294712110189721 max memory_allocated 49668.58642578125 
[2025-03-17 00:43:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 3 loss:0.021297570317983627 norm:0.00022430448734667152 max memory_allocated 49668.58642578125 
[2025-03-17 00:44:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 4 loss:0.020377125591039658 norm:0.00019653271010611206 max memory_allocated 49668.58642578125 
[2025-03-17 00:45:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 5 loss:0.01973358541727066 norm:0.00018347817240282893 max memory_allocated 49668.58642578125 
[2025-03-17 00:47:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 6 loss:0.019255157560110092 norm:0.00016557922936044633 max memory_allocated 49668.58642578125 
[2025-03-17 00:48:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 7 loss:0.018909066915512085 norm:0.00015849870396777987 max memory_allocated 49668.58642578125 
[2025-03-17 00:50:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 8 loss:0.018694061785936356 norm:0.00014974415535107255 max memory_allocated 49668.58642578125 
[2025-03-17 00:51:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 9 loss:0.018560633063316345 norm:0.00014721075422130525 max memory_allocated 49668.58642578125 
[2025-03-17 00:52:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 10 loss:0.018469490110874176 norm:0.0001455431047361344 max memory_allocated 49668.58642578125 
[2025-03-17 00:54:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 11 loss:0.01839480921626091 norm:0.00014377765182871372 max memory_allocated 49668.58642578125 
[2025-03-17 00:55:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 12 loss:0.018344661220908165 norm:0.00014092215860728174 max memory_allocated 49668.58642578125 
[2025-03-17 00:57:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 13 loss:0.01829345151782036 norm:0.00013916933676227927 max memory_allocated 49668.58642578125 
[2025-03-17 00:58:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 14 loss:0.018237167969346046 norm:0.00013414920249488205 max memory_allocated 49668.58642578125 
[2025-03-17 01:00:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 15 loss:0.018193716183304787 norm:0.00013382043107412755 max memory_allocated 49668.58642578125 
[2025-03-17 01:01:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 16 loss:0.01813528500497341 norm:0.0001309537183260545 max memory_allocated 49668.58642578125 
[2025-03-17 01:02:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 17 loss:0.01809634640812874 norm:0.00013015059812460095 max memory_allocated 49668.58642578125 
[2025-03-17 01:04:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 18 loss:0.01807459630072117 norm:0.00012825858721043915 max memory_allocated 49668.58642578125 
[2025-03-17 01:05:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 19 loss:0.01804785057902336 norm:0.00012751732720062137 max memory_allocated 49668.58642578125 
[2025-03-17 01:06:25 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 21 to 22 ===
[2025-03-17 01:07:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 0 loss:0.040047965943813324 norm:0.001589230028912425 max memory_allocated 49668.58642578125 
[2025-03-17 01:09:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 1 loss:0.03139147162437439 norm:0.0009021590230986476 max memory_allocated 49668.58642578125 
[2025-03-17 01:10:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 2 loss:0.02656973898410797 norm:0.0006686492706649005 max memory_allocated 49668.58642578125 
[2025-03-17 01:12:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 3 loss:0.025002729147672653 norm:0.0005559687269851565 max memory_allocated 49668.58642578125 
[2025-03-17 01:13:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 4 loss:0.024021361023187637 norm:0.0004757216665893793 max memory_allocated 49668.58642578125 
[2025-03-17 01:14:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 5 loss:0.023236479610204697 norm:0.0004190221952740103 max memory_allocated 49668.58642578125 
[2025-03-17 01:16:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 6 loss:0.022752540186047554 norm:0.00038213556399568915 max memory_allocated 49668.58642578125 
[2025-03-17 01:17:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 7 loss:0.022279702126979828 norm:0.00034105294616892934 max memory_allocated 49668.58642578125 
[2025-03-17 01:19:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 8 loss:0.02216579206287861 norm:0.00033239982440136373 max memory_allocated 49668.58642578125 
[2025-03-17 01:20:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 9 loss:0.02198088727891445 norm:0.0003009796200785786 max memory_allocated 49668.58642578125 
[2025-03-17 01:22:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 10 loss:0.021886499598622322 norm:0.00029502715915441513 max memory_allocated 49668.58642578125 
[2025-03-17 01:23:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 11 loss:0.021671198308467865 norm:0.00029368497780524194 max memory_allocated 49668.58642578125 
[2025-03-17 01:24:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 12 loss:0.021563032642006874 norm:0.00027585975476540625 max memory_allocated 49668.58642578125 
[2025-03-17 01:26:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 13 loss:0.021578896790742874 norm:0.0002622462925501168 max memory_allocated 49668.58642578125 
[2025-03-17 01:27:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 14 loss:0.02149162068963051 norm:0.0002493413630872965 max memory_allocated 49668.58642578125 
[2025-03-17 01:29:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 15 loss:0.02142842672765255 norm:0.00024712111917324364 max memory_allocated 49668.58642578125 
[2025-03-17 01:30:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 16 loss:0.021345987915992737 norm:0.00023985897132661194 max memory_allocated 49668.58642578125 
[2025-03-17 01:31:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 17 loss:0.02128167822957039 norm:0.00023670130758546293 max memory_allocated 49668.58642578125 
[2025-03-17 01:33:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 18 loss:0.021290941163897514 norm:0.00024176623264793307 max memory_allocated 49668.58642578125 
[2025-03-17 01:34:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 19 loss:0.021245257928967476 norm:0.00023622663866262883 max memory_allocated 49668.58642578125 
[2025-03-17 01:35:26 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 22 to 23 ===
[2025-03-17 01:36:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 0 loss:0.047004856169223785 norm:0.022182825952768326 max memory_allocated 49668.96142578125 
[2025-03-17 01:38:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 1 loss:0.03679938241839409 norm:0.003088996745646 max memory_allocated 49668.96142578125 
[2025-03-17 01:39:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 2 loss:0.03088769130408764 norm:0.0013540416257455945 max memory_allocated 49668.96142578125 
[2025-03-17 01:41:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 3 loss:0.028884824365377426 norm:0.0009105752105824649 max memory_allocated 49668.96142578125 
[2025-03-17 01:42:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 4 loss:0.02766288071870804 norm:0.0007135435007512569 max memory_allocated 49668.96142578125 
[2025-03-17 01:44:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 5 loss:0.026695631444454193 norm:0.0005875025526620448 max memory_allocated 49668.96142578125 
[2025-03-17 01:45:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 6 loss:0.02600872330367565 norm:0.0005115889944136143 max memory_allocated 49668.96142578125 
[2025-03-17 01:46:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 7 loss:0.025600068271160126 norm:0.00045397557551041245 max memory_allocated 49668.96142578125 
[2025-03-17 01:48:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 8 loss:0.025346707552671432 norm:0.0004090210422873497 max memory_allocated 49668.96142578125 
[2025-03-17 01:49:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 9 loss:0.02515650913119316 norm:0.0003684367111418396 max memory_allocated 49668.96142578125 
[2025-03-17 01:51:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 10 loss:0.025000527501106262 norm:0.00034161555231548846 max memory_allocated 49668.96142578125 
[2025-03-17 01:52:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 11 loss:0.02487962320446968 norm:0.00032139860559254885 max memory_allocated 49668.96142578125 
[2025-03-17 01:53:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 12 loss:0.02478829026222229 norm:0.00030414853245019913 max memory_allocated 49668.96142578125 
[2025-03-17 01:55:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 13 loss:0.024695292115211487 norm:0.000290561089059338 max memory_allocated 49668.96142578125 
[2025-03-17 01:56:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 14 loss:0.024649467319250107 norm:0.0002809520228765905 max memory_allocated 49668.96142578125 
[2025-03-17 01:58:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 15 loss:0.0245500598102808 norm:0.00026848664856515825 max memory_allocated 49668.96142578125 
[2025-03-17 01:59:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 16 loss:0.02449236810207367 norm:0.000259191554505378 max memory_allocated 49668.96142578125 
[2025-03-17 02:00:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 17 loss:0.024441763758659363 norm:0.00025093351723626256 max memory_allocated 49668.96142578125 
[2025-03-17 02:02:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 18 loss:0.024381378665566444 norm:0.00024562302860431373 max memory_allocated 49668.96142578125 
[2025-03-17 02:03:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 19 loss:0.024347912520170212 norm:0.00023970671463757753 max memory_allocated 49668.96142578125 
[2025-03-17 02:04:34 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 23 to 24 ===
[2025-03-17 02:06:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 0 loss:0.04726467654109001 norm:0.0012115787249058485 max memory_allocated 49668.96142578125 
[2025-03-17 02:07:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 1 loss:0.03530754894018173 norm:0.0006724830600433052 max memory_allocated 49668.96142578125 
[2025-03-17 02:08:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 2 loss:0.02942049875855446 norm:0.0005299337208271027 max memory_allocated 49668.96142578125 
[2025-03-17 02:10:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 3 loss:0.027551209554076195 norm:0.0004399299214128405 max memory_allocated 49668.96142578125 
[2025-03-17 02:11:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 4 loss:0.026341242715716362 norm:0.0004000317712780088 max memory_allocated 49668.96142578125 
[2025-03-17 02:13:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 5 loss:0.02534690499305725 norm:0.000361888378392905 max memory_allocated 49668.96142578125 
[2025-03-17 02:14:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 6 loss:0.024688076227903366 norm:0.00033411988988518715 max memory_allocated 49668.96142578125 
[2025-03-17 02:16:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 7 loss:0.024281317368149757 norm:0.00032028721761889756 max memory_allocated 49668.96142578125 
[2025-03-17 02:17:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 8 loss:0.024017319083213806 norm:0.0002916120574809611 max memory_allocated 49668.96142578125 
[2025-03-17 02:18:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 9 loss:0.02382306195795536 norm:0.00027469039196148515 max memory_allocated 49668.96142578125 
[2025-03-17 02:20:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 10 loss:0.023684803396463394 norm:0.0002778292400762439 max memory_allocated 49668.96142578125 
[2025-03-17 02:21:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 11 loss:0.02357080765068531 norm:0.0002675969444680959 max memory_allocated 49668.96142578125 
[2025-03-17 02:23:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 12 loss:0.02342771366238594 norm:0.0002596468257252127 max memory_allocated 49668.96142578125 
[2025-03-17 02:24:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 13 loss:0.023328790441155434 norm:0.00026951590552926064 max memory_allocated 49668.96142578125 
[2025-03-17 02:25:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 14 loss:0.023240111768245697 norm:0.0002687048399820924 max memory_allocated 49668.96142578125 
[2025-03-17 02:27:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 15 loss:0.023155543953180313 norm:0.00026498863007873297 max memory_allocated 49668.96142578125 
[2025-03-17 02:28:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 16 loss:0.02307106740772724 norm:0.00023882334062363952 max memory_allocated 49668.96142578125 
[2025-03-17 02:30:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 17 loss:0.0230159442871809 norm:0.00023937461082823575 max memory_allocated 49668.96142578125 
[2025-03-17 02:31:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 18 loss:0.02294541709125042 norm:0.00023519352544099092 max memory_allocated 49668.96142578125 
[2025-03-17 02:32:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 19 loss:0.022901220247149467 norm:0.0002161296142730862 max memory_allocated 49668.96142578125 
[2025-03-17 02:33:39 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 24 to 25 ===
[2025-03-17 02:35:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 0 loss:0.040222764015197754 norm:0.0008592212689109147 max memory_allocated 49669.33642578125 
[2025-03-17 02:36:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 1 loss:0.03236062824726105 norm:0.0004633778298739344 max memory_allocated 49669.33642578125 
[2025-03-17 02:38:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 2 loss:0.02673809975385666 norm:0.0003603514633141458 max memory_allocated 49669.33642578125 
[2025-03-17 02:39:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 3 loss:0.025132549926638603 norm:0.0002957030665129423 max memory_allocated 49669.33642578125 
[2025-03-17 02:40:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 4 loss:0.024056965485215187 norm:0.00026419098139740527 max memory_allocated 49669.33642578125 
[2025-03-17 02:42:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 5 loss:0.023186111822724342 norm:0.00025129938148893416 max memory_allocated 49669.33642578125 
[2025-03-17 02:43:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 6 loss:0.022663623094558716 norm:0.00023611148935742676 max memory_allocated 49669.33642578125 
[2025-03-17 02:45:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 7 loss:0.02238459885120392 norm:0.0002214547712355852 max memory_allocated 49669.33642578125 
[2025-03-17 02:46:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 8 loss:0.022223716601729393 norm:0.00021375756477937102 max memory_allocated 49669.33642578125 
[2025-03-17 02:47:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 9 loss:0.022096555680036545 norm:0.00020645727636292577 max memory_allocated 49669.33642578125 
[2025-03-17 02:49:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 10 loss:0.021991506218910217 norm:0.00020509342721197754 max memory_allocated 49669.33642578125 
[2025-03-17 02:50:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 11 loss:0.021902142092585564 norm:0.00019932177383452654 max memory_allocated 49669.33642578125 
[2025-03-17 02:52:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 12 loss:0.0218256413936615 norm:0.00019624794367700815 max memory_allocated 49669.33642578125 
[2025-03-17 02:53:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 13 loss:0.021761201322078705 norm:0.0001896037138067186 max memory_allocated 49669.33642578125 
[2025-03-17 02:54:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 14 loss:0.02168567292392254 norm:0.00019052661082241684 max memory_allocated 49669.33642578125 
[2025-03-17 02:56:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 15 loss:0.021625224500894547 norm:0.00018764713604468852 max memory_allocated 49669.33642578125 
[2025-03-17 02:57:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 16 loss:0.021574286743998528 norm:0.00018216678290627897 max memory_allocated 49669.33642578125 
[2025-03-17 02:59:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 17 loss:0.021527545526623726 norm:0.0001764439803082496 max memory_allocated 49669.33642578125 
[2025-03-17 03:00:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 18 loss:0.021502718329429626 norm:0.00017265361384488642 max memory_allocated 49669.33642578125 
[2025-03-17 03:02:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 19 loss:0.02148803323507309 norm:0.00017064510029740632 max memory_allocated 49669.33642578125 
[2025-03-17 03:02:48 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 25 to 26 ===
[2025-03-17 03:04:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 0 loss:0.0544617585837841 norm:0.0019646116998046637 max memory_allocated 49669.52392578125 
[2025-03-17 03:05:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 1 loss:0.039051998406648636 norm:0.0007839032914489508 max memory_allocated 49669.52392578125 
[2025-03-17 03:07:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 2 loss:0.03196696192026138 norm:0.0005657484871335328 max memory_allocated 49669.52392578125 
[2025-03-17 03:08:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 3 loss:0.029588650912046432 norm:0.0004580866079777479 max memory_allocated 49669.52392578125 
[2025-03-17 03:10:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 4 loss:0.02808009833097458 norm:0.00039737203042022884 max memory_allocated 49669.52392578125 
[2025-03-17 03:11:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 5 loss:0.02695917710661888 norm:0.0003560575423762202 max memory_allocated 49669.52392578125 
[2025-03-17 03:12:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 6 loss:0.02636748179793358 norm:0.0003343126445543021 max memory_allocated 49669.52392578125 
[2025-03-17 03:14:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 7 loss:0.02598438411951065 norm:0.000309877039398998 max memory_allocated 49669.52392578125 
[2025-03-17 03:15:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 8 loss:0.025746919214725494 norm:0.00029453187016770244 max memory_allocated 49669.52392578125 
[2025-03-17 03:17:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 9 loss:0.025559131056070328 norm:0.000280043575912714 max memory_allocated 49669.52392578125 
[2025-03-17 03:18:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 10 loss:0.025408128276467323 norm:0.0002670389658305794 max memory_allocated 49669.52392578125 
[2025-03-17 03:19:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 11 loss:0.025295380502939224 norm:0.00025834733969531953 max memory_allocated 49669.52392578125 
[2025-03-17 03:21:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 12 loss:0.025186844170093536 norm:0.00025296222884207964 max memory_allocated 49669.52392578125 
[2025-03-17 03:22:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 13 loss:0.025109462440013885 norm:0.0002456367656122893 max memory_allocated 49669.52392578125 
[2025-03-17 03:24:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 14 loss:0.025034064427018166 norm:0.0002400471712462604 max memory_allocated 49669.52392578125 
[2025-03-17 03:25:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 15 loss:0.024954762309789658 norm:0.0002381262311246246 max memory_allocated 49669.52392578125 
[2025-03-17 03:26:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 16 loss:0.024907084181904793 norm:0.00023583004076499492 max memory_allocated 49669.52392578125 
[2025-03-17 03:28:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 17 loss:0.02481967955827713 norm:0.00022841010650154203 max memory_allocated 49669.52392578125 
[2025-03-17 03:29:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 18 loss:0.024770155549049377 norm:0.00022949796402826905 max memory_allocated 49669.52392578125 
[2025-03-17 03:31:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 19 loss:0.024715596809983253 norm:0.00022483074280899018 max memory_allocated 49669.52392578125 
[2025-03-17 03:31:54 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 26 to 27 ===
[2025-03-17 03:33:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 0 loss:0.052647046744823456 norm:0.0016057606553658843 max memory_allocated 49669.52392578125 
[2025-03-17 03:34:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 1 loss:0.040856942534446716 norm:0.000805331626906991 max memory_allocated 49669.52392578125 
[2025-03-17 03:36:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 2 loss:0.03402471914887428 norm:0.000611505878623575 max memory_allocated 49669.52392578125 
[2025-03-17 03:37:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 3 loss:0.03198578581213951 norm:0.0005383645766414702 max memory_allocated 49669.52392578125 
[2025-03-17 03:39:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 4 loss:0.030534759163856506 norm:0.00046082117478363216 max memory_allocated 49669.52392578125 
[2025-03-17 03:40:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 5 loss:0.029501793906092644 norm:0.00040531728882342577 max memory_allocated 49669.52392578125 
[2025-03-17 03:41:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 6 loss:0.028931599110364914 norm:0.0003578266769181937 max memory_allocated 49669.52392578125 
[2025-03-17 03:43:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 7 loss:0.02861911803483963 norm:0.0003432228695601225 max memory_allocated 49669.52392578125 
[2025-03-17 03:44:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 8 loss:0.028396200388669968 norm:0.00031728020985610783 max memory_allocated 49669.52392578125 
[2025-03-17 03:46:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 9 loss:0.02824637107551098 norm:0.00033053691731765866 max memory_allocated 49669.52392578125 
[2025-03-17 03:47:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 10 loss:0.028094960376620293 norm:0.0002984916209243238 max memory_allocated 49669.52392578125 
[2025-03-17 03:48:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 11 loss:0.02795695886015892 norm:0.0002886650327127427 max memory_allocated 49669.52392578125 
[2025-03-17 03:50:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 12 loss:0.02783823572099209 norm:0.00027105852495878935 max memory_allocated 49669.52392578125 
[2025-03-17 03:51:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 13 loss:0.027750182896852493 norm:0.0002768661070149392 max memory_allocated 49669.52392578125 
[2025-03-17 03:53:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 14 loss:0.027674010023474693 norm:0.00026280965539626777 max memory_allocated 49669.52392578125 
[2025-03-17 03:54:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 15 loss:0.027620799839496613 norm:0.0002613611868582666 max memory_allocated 49669.52392578125 
[2025-03-17 03:56:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 16 loss:0.027568073943257332 norm:0.00025056276354007423 max memory_allocated 49669.52392578125 
[2025-03-17 03:57:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 17 loss:0.027495699003338814 norm:0.0002457835653331131 max memory_allocated 49669.52392578125 
[2025-03-17 03:58:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 18 loss:0.027447404339909554 norm:0.00024332950124517083 max memory_allocated 49669.52392578125 
[2025-03-17 04:00:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 19 loss:0.02741255611181259 norm:0.00023989335750229657 max memory_allocated 49669.52392578125 
[2025-03-17 04:01:01 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 27 to 28 ===
[2025-03-17 04:02:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 0 loss:0.050501301884651184 norm:0.0014399350620806217 max memory_allocated 49669.52392578125 
[2025-03-17 04:03:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 1 loss:0.03702419996261597 norm:0.0007329468498937786 max memory_allocated 49669.52392578125 
[2025-03-17 04:05:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 2 loss:0.0299556665122509 norm:0.0005409546429291368 max memory_allocated 49669.52392578125 
[2025-03-17 04:06:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 3 loss:0.02780781500041485 norm:0.0004882286593783647 max memory_allocated 49669.52392578125 
[2025-03-17 04:08:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 4 loss:0.026346642524003983 norm:0.00043902371544390917 max memory_allocated 49669.52392578125 
[2025-03-17 04:09:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 5 loss:0.025383496657013893 norm:0.00036201151669956744 max memory_allocated 49669.52392578125 
[2025-03-17 04:11:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 6 loss:0.024934347718954086 norm:0.0003263658145442605 max memory_allocated 49669.52392578125 
[2025-03-17 04:12:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 7 loss:0.02464393898844719 norm:0.0003110911347903311 max memory_allocated 49669.52392578125 
[2025-03-17 04:13:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 8 loss:0.024449557065963745 norm:0.0002963627048302442 max memory_allocated 49669.52392578125 
[2025-03-17 04:15:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 9 loss:0.024266349151730537 norm:0.0003202904190402478 max memory_allocated 49669.52392578125 
[2025-03-17 04:16:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 10 loss:0.024113960564136505 norm:0.0002576303668320179 max memory_allocated 49669.52392578125 
[2025-03-17 04:18:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 11 loss:0.023998232558369637 norm:0.0002645412168931216 max memory_allocated 49669.52392578125 
[2025-03-17 04:19:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 12 loss:0.023874545469880104 norm:0.0002551938232500106 max memory_allocated 49669.52392578125 
[2025-03-17 04:20:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 13 loss:0.02379775606095791 norm:0.0002889642782974988 max memory_allocated 49669.52392578125 
[2025-03-17 04:22:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 14 loss:0.023700512945652008 norm:0.000231812140555121 max memory_allocated 49669.52392578125 
[2025-03-17 04:23:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 15 loss:0.023628288879990578 norm:0.00023669510846957564 max memory_allocated 49669.52392578125 
[2025-03-17 04:25:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 16 loss:0.023581931367516518 norm:0.0002481215342413634 max memory_allocated 49669.52392578125 
[2025-03-17 04:26:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 17 loss:0.02350865676999092 norm:0.00022773927776142955 max memory_allocated 49669.52392578125 
[2025-03-17 04:27:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 18 loss:0.023445092141628265 norm:0.000220431451452896 max memory_allocated 49669.52392578125 
[2025-03-17 04:29:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 19 loss:0.023371784016489983 norm:0.0002107147010974586 max memory_allocated 49669.52392578125 
[2025-03-17 04:30:09 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 28 to 29 ===
[2025-03-17 04:31:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 0 loss:0.04849004000425339 norm:0.0020207015331834555 max memory_allocated 49671.08642578125 
[2025-03-17 04:33:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 1 loss:0.039473503828048706 norm:0.0006301123648881912 max memory_allocated 49671.08642578125 
[2025-03-17 04:34:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 2 loss:0.032435812056064606 norm:0.0004077650955878198 max memory_allocated 49671.08642578125 
[2025-03-17 04:35:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 3 loss:0.030325667932629585 norm:0.0003224598476663232 max memory_allocated 49671.08642578125 
[2025-03-17 04:37:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 4 loss:0.028838511556386948 norm:0.00027639936888590455 max memory_allocated 49671.08642578125 
[2025-03-17 04:38:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 5 loss:0.028036989271640778 norm:0.0002419147058390081 max memory_allocated 49671.08642578125 
[2025-03-17 04:40:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 6 loss:0.02767178602516651 norm:0.00022216932848095894 max memory_allocated 49671.08642578125 
[2025-03-17 04:41:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 7 loss:0.027468154206871986 norm:0.0002101106074405834 max memory_allocated 49671.08642578125 
[2025-03-17 04:43:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 8 loss:0.02732955664396286 norm:0.00020379055058583617 max memory_allocated 49671.08642578125 
[2025-03-17 04:44:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 9 loss:0.027211755514144897 norm:0.0002000222448259592 max memory_allocated 49671.08642578125 
[2025-03-17 04:45:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 10 loss:0.027140295132994652 norm:0.00019409888773225248 max memory_allocated 49671.08642578125 
[2025-03-17 04:47:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 11 loss:0.027105651795864105 norm:0.00019239846733398736 max memory_allocated 49671.08642578125 
[2025-03-17 04:48:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 12 loss:0.02701057866215706 norm:0.00018936213746201247 max memory_allocated 49671.08642578125 
[2025-03-17 04:50:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 13 loss:0.026880888268351555 norm:0.00019651376351248473 max memory_allocated 49671.08642578125 
[2025-03-17 04:51:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 14 loss:0.026790961623191833 norm:0.0001829490065574646 max memory_allocated 49671.08642578125 
[2025-03-17 04:52:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 15 loss:0.026721738278865814 norm:0.0001807983499020338 max memory_allocated 49671.08642578125 
[2025-03-17 04:54:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 16 loss:0.026684816926717758 norm:0.000178806614712812 max memory_allocated 49671.08642578125 
[2025-03-17 04:55:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 17 loss:0.02665678784251213 norm:0.00017946941079571843 max memory_allocated 49671.08642578125 
[2025-03-17 04:57:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 18 loss:0.026622695848345757 norm:0.0001801360194804147 max memory_allocated 49671.08642578125 
[2025-03-17 04:58:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 19 loss:0.02656436339020729 norm:0.00018031617219094187 max memory_allocated 49671.08642578125 
[2025-03-17 04:59:18 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 29 to 30 ===
[2025-03-17 05:00:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 0 loss:0.0588676854968071 norm:0.0011779944179579616 max memory_allocated 49671.08642578125 
[2025-03-17 05:02:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 1 loss:0.04387645423412323 norm:0.0005335233290679753 max memory_allocated 49671.08642578125 
[2025-03-17 05:03:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 2 loss:0.03528006747364998 norm:0.00036931023350916803 max memory_allocated 49671.08642578125 
[2025-03-17 05:05:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 3 loss:0.03260784223675728 norm:0.0003007390769198537 max memory_allocated 49671.08642578125 
[2025-03-17 05:06:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 4 loss:0.030876968055963516 norm:0.00026037689531221986 max memory_allocated 49671.08642578125 
[2025-03-17 05:07:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 5 loss:0.03008284978568554 norm:0.00023702552425675094 max memory_allocated 49671.08642578125 
[2025-03-17 05:09:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 6 loss:0.02970968373119831 norm:0.00022342872398439795 max memory_allocated 49671.08642578125 
[2025-03-17 05:10:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 7 loss:0.029468301683664322 norm:0.00021148384257685393 max memory_allocated 49671.08642578125 
[2025-03-17 05:12:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 8 loss:0.02927953191101551 norm:0.00020664952171500772 max memory_allocated 49671.08642578125 
[2025-03-17 05:13:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 9 loss:0.02914244309067726 norm:0.0002028967282967642 max memory_allocated 49671.08642578125 
[2025-03-17 05:15:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 10 loss:0.0290189441293478 norm:0.00020067495643161237 max memory_allocated 49671.08642578125 
[2025-03-17 05:16:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 11 loss:0.028908567503094673 norm:0.00019619792874436826 max memory_allocated 49671.08642578125 
[2025-03-17 05:17:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 12 loss:0.02881391905248165 norm:0.00019562136731110513 max memory_allocated 49671.08642578125 
[2025-03-17 05:19:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 13 loss:0.028723731637001038 norm:0.0001941861119121313 max memory_allocated 49671.08642578125 
[2025-03-17 05:20:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 14 loss:0.02865971252322197 norm:0.0001913695887196809 max memory_allocated 49671.08642578125 
[2025-03-17 05:22:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 15 loss:0.02859272062778473 norm:0.00018937786808237433 max memory_allocated 49671.08642578125 
[2025-03-17 05:23:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 16 loss:0.02855362370610237 norm:0.00018759604427032173 max memory_allocated 49671.08642578125 
[2025-03-17 05:24:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 17 loss:0.02849925309419632 norm:0.00018736309721134603 max memory_allocated 49671.08642578125 
[2025-03-17 05:26:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 18 loss:0.028464172035455704 norm:0.00018597567395772785 max memory_allocated 49671.08642578125 
[2025-03-17 05:27:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 19 loss:0.028433669358491898 norm:0.0001860074553405866 max memory_allocated 49671.08642578125 
[2025-03-17 05:28:31 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 30 to 31 ===
[2025-03-17 05:30:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 0 loss:0.0617954358458519 norm:0.0009695816552266479 max memory_allocated 49671.08642578125 
[2025-03-17 05:31:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 1 loss:0.046851206570863724 norm:0.0004414136928971857 max memory_allocated 49671.08642578125 
[2025-03-17 05:32:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 2 loss:0.038181960582733154 norm:0.0003360033151693642 max memory_allocated 49671.08642578125 
[2025-03-17 05:34:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 3 loss:0.035311583429574966 norm:0.00028829550137743354 max memory_allocated 49671.08642578125 
[2025-03-17 05:35:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 4 loss:0.03355155140161514 norm:0.0002623705368023366 max memory_allocated 49671.08642578125 
[2025-03-17 05:37:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 5 loss:0.0328570120036602 norm:0.000245552568230778 max memory_allocated 49671.08642578125 
[2025-03-17 05:38:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 6 loss:0.032522574067115784 norm:0.00022852282563690096 max memory_allocated 49671.08642578125 
[2025-03-17 05:39:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 7 loss:0.032279856503009796 norm:0.00022082494979258627 max memory_allocated 49671.08642578125 
[2025-03-17 05:41:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 8 loss:0.03211028501391411 norm:0.0002149138890672475 max memory_allocated 49671.08642578125 
[2025-03-17 05:42:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 9 loss:0.03195580095052719 norm:0.00021291013399604708 max memory_allocated 49671.08642578125 
[2025-03-17 05:44:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 10 loss:0.031836144626140594 norm:0.00021172984270378947 max memory_allocated 49671.08642578125 
[2025-03-17 05:45:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 11 loss:0.0317368358373642 norm:0.0002087507746182382 max memory_allocated 49671.08642578125 
[2025-03-17 05:47:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 12 loss:0.03163905814290047 norm:0.00020746758673340082 max memory_allocated 49671.08642578125 
[2025-03-17 05:48:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 13 loss:0.031554579734802246 norm:0.00020585948368534446 max memory_allocated 49671.08642578125 
[2025-03-17 05:49:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 14 loss:0.031485360115766525 norm:0.0002046564477495849 max memory_allocated 49671.08642578125 
[2025-03-17 05:51:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 15 loss:0.03141885995864868 norm:0.00020193214004393667 max memory_allocated 49671.08642578125 
[2025-03-17 05:52:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 16 loss:0.03137713298201561 norm:0.0002041675033979118 max memory_allocated 49671.08642578125 
[2025-03-17 05:54:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 17 loss:0.031361088156700134 norm:0.00020296048023737967 max memory_allocated 49671.08642578125 
