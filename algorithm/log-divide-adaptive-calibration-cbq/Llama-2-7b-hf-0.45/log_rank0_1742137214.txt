[2025-03-16 15:00:14 root] (main_calib_config3_cbq.py 280): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-divide-adaptive-calibration-cbq/Llama-2-7b-hf-0.45', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=15, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.45.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-16 15:00:21 root] (main_calib_config3_cbq.py 347): INFO === start quantization ===
[2025-03-16 15:00:21 root] (main_calib_config3_cbq.py 353): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-16 15:00:21 root] (abq_llm_calib_config3_cbq.py 82): INFO Starting ...
[2025-03-16 15:00:21 root] (abq_llm_calib_config3_cbq.py 89): INFO Loaded quant_map from log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.45.pkl
[2025-03-16 15:00:26 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 0 to 1 ===
[2025-03-16 15:01:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 0 loss:0.20596465468406677 norm:0.5614199042320251 max memory_allocated 38105.85986328125 
[2025-03-16 15:02:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 1 loss:0.111343614757061 norm:0.15788103640079498 max memory_allocated 38105.85986328125 
[2025-03-16 15:03:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 2 loss:0.08895545452833176 norm:0.10526575148105621 max memory_allocated 38105.85986328125 
[2025-03-16 15:04:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 3 loss:0.0857326090335846 norm:0.1125977635383606 max memory_allocated 38105.85986328125 
[2025-03-16 15:05:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 4 loss:0.07961644977331161 norm:0.0859617069363594 max memory_allocated 38105.85986328125 
[2025-03-16 15:06:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 5 loss:0.07661956548690796 norm:0.08152132481336594 max memory_allocated 38105.85986328125 
[2025-03-16 15:07:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 6 loss:0.07453057169914246 norm:0.07197646796703339 max memory_allocated 38105.85986328125 
[2025-03-16 15:08:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 7 loss:0.07361655682325363 norm:0.0789458304643631 max memory_allocated 38105.85986328125 
[2025-03-16 15:09:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 8 loss:0.07193035632371902 norm:0.06652282178401947 max memory_allocated 38105.85986328125 
[2025-03-16 15:10:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 9 loss:0.16967198252677917 norm:0.3830205500125885 max memory_allocated 38105.85986328125 
[2025-03-16 15:10:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 10 loss:0.07731963694095612 norm:0.09691821038722992 max memory_allocated 38105.85986328125 
[2025-03-16 15:11:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 11 loss:0.11188596487045288 norm:0.256086528301239 max memory_allocated 38105.85986328125 
[2025-03-16 15:12:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 12 loss:0.06839840114116669 norm:0.049166738986968994 max memory_allocated 38105.85986328125 
[2025-03-16 15:13:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 13 loss:0.06844590604305267 norm:0.05224347487092018 max memory_allocated 38105.85986328125 
[2025-03-16 15:14:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 14 loss:0.06723809987306595 norm:0.04633920267224312 max memory_allocated 38105.85986328125 
[2025-03-16 15:15:16 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 1 to 2 ===
[2025-03-16 15:16:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 0 loss:0.20052498579025269 norm:0.08240444958209991 max memory_allocated 38138.54931640625 
[2025-03-16 15:17:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 1 loss:0.10819365829229355 norm:0.04309307783842087 max memory_allocated 38138.54931640625 
[2025-03-16 15:18:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 2 loss:0.08125993609428406 norm:0.033785656094551086 max memory_allocated 38138.54931640625 
[2025-03-16 15:19:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 3 loss:0.06748852878808975 norm:0.030661121010780334 max memory_allocated 38138.54931640625 
[2025-03-16 15:20:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 4 loss:0.0605073943734169 norm:0.02496068924665451 max memory_allocated 38138.54931640625 
[2025-03-16 15:21:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 5 loss:0.05563243106007576 norm:0.020876869559288025 max memory_allocated 38138.54931640625 
[2025-03-16 15:22:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 6 loss:0.0527217797935009 norm:0.02031775563955307 max memory_allocated 38138.54931640625 
[2025-03-16 15:22:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 7 loss:0.05029141157865524 norm:0.018345627933740616 max memory_allocated 38138.54931640625 
[2025-03-16 15:23:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 8 loss:0.04942077398300171 norm:0.018077045679092407 max memory_allocated 38138.54931640625 
[2025-03-16 15:24:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 9 loss:0.049018729478120804 norm:0.018537139520049095 max memory_allocated 38138.54931640625 
[2025-03-16 15:25:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 10 loss:0.048042211681604385 norm:0.01817357912659645 max memory_allocated 38138.54931640625 
[2025-03-16 15:26:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 11 loss:0.04823986813426018 norm:0.01951085962355137 max memory_allocated 38138.54931640625 
[2025-03-16 15:27:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 12 loss:0.054193995893001556 norm:0.03727076202630997 max memory_allocated 38138.54931640625 
[2025-03-16 15:28:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 13 loss:0.05416456609964371 norm:0.029387937858700752 max memory_allocated 38138.54931640625 
[2025-03-16 15:29:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 14 loss:0.05311965569853783 norm:0.029865209013223648 max memory_allocated 38138.54931640625 
[2025-03-16 15:30:10 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 2 to 3 ===
[2025-03-16 15:31:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 0 loss:0.05813879892230034 norm:0.021400175988674164 max memory_allocated 38138.54931640625 
[2025-03-16 15:32:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 1 loss:0.028839711099863052 norm:0.007913786917924881 max memory_allocated 38138.54931640625 
[2025-03-16 15:33:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 2 loss:0.020758340135216713 norm:0.004513000603765249 max memory_allocated 38138.54931640625 
[2025-03-16 15:34:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 3 loss:0.017405178397893906 norm:0.0036346628330647945 max memory_allocated 38138.54931640625 
[2025-03-16 15:35:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 4 loss:0.015749748796224594 norm:0.003205330343917012 max memory_allocated 38138.54931640625 
[2025-03-16 15:35:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 5 loss:0.014773895964026451 norm:0.0030011264607310295 max memory_allocated 38138.54931640625 
[2025-03-16 15:36:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 6 loss:0.014004720374941826 norm:0.0026288842782378197 max memory_allocated 38138.54931640625 
[2025-03-16 15:37:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 7 loss:0.013466413132846355 norm:0.002191368490457535 max memory_allocated 38138.54931640625 
[2025-03-16 15:38:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 8 loss:0.01311802864074707 norm:0.002064944477751851 max memory_allocated 38138.54931640625 
[2025-03-16 15:39:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 9 loss:0.012834076769649982 norm:0.0018510730005800724 max memory_allocated 38138.54931640625 
[2025-03-16 15:40:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 10 loss:0.012604042887687683 norm:0.001792204799130559 max memory_allocated 38138.54931640625 
[2025-03-16 15:41:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 11 loss:0.012395120225846767 norm:0.0015112110413610935 max memory_allocated 38138.54931640625 
[2025-03-16 15:42:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 12 loss:0.012210424989461899 norm:0.0015978401061147451 max memory_allocated 38138.54931640625 
[2025-03-16 15:43:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 13 loss:0.012053491547703743 norm:0.0014053467893972993 max memory_allocated 38138.54931640625 
[2025-03-16 15:44:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 14 loss:0.011918636970221996 norm:0.0012044499162584543 max memory_allocated 38138.54931640625 
[2025-03-16 15:45:01 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 3 to 4 ===
[2025-03-16 15:46:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 0 loss:0.052357111126184464 norm:0.2563268542289734 max memory_allocated 38138.54931640625 
[2025-03-16 15:47:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 1 loss:0.025102555751800537 norm:0.02877693995833397 max memory_allocated 38138.54931640625 
[2025-03-16 15:47:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 2 loss:0.018826376646757126 norm:0.015996506437659264 max memory_allocated 38138.54931640625 
[2025-03-16 15:48:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 3 loss:0.01600152812898159 norm:0.010786785744130611 max memory_allocated 38138.54931640625 
[2025-03-16 15:49:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 4 loss:0.014638587832450867 norm:0.007980679161846638 max memory_allocated 38138.54931640625 
[2025-03-16 15:50:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 5 loss:0.013788847252726555 norm:0.0061851912178099155 max memory_allocated 38138.54931640625 
[2025-03-16 15:51:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 6 loss:0.013209277763962746 norm:0.004949319642037153 max memory_allocated 38138.54931640625 
[2025-03-16 15:52:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 7 loss:0.012813914567232132 norm:0.00407028803601861 max memory_allocated 38138.54931640625 
[2025-03-16 15:53:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 8 loss:0.012469397857785225 norm:0.0033803535625338554 max memory_allocated 38138.54931640625 
[2025-03-16 15:54:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 9 loss:0.012062191031873226 norm:0.002814003499224782 max memory_allocated 38138.54931640625 
[2025-03-16 15:55:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 10 loss:0.011856092140078545 norm:0.002343781292438507 max memory_allocated 38138.54931640625 
[2025-03-16 15:56:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 11 loss:0.011805086396634579 norm:0.0019960952922701836 max memory_allocated 38138.54931640625 
[2025-03-16 15:57:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 12 loss:0.011744920164346695 norm:0.0017081423429772258 max memory_allocated 38138.54931640625 
[2025-03-16 15:58:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 13 loss:0.011669229716062546 norm:0.0014584274031221867 max memory_allocated 38138.54931640625 
[2025-03-16 15:59:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 14 loss:0.011628438718616962 norm:0.0012176641030237079 max memory_allocated 38138.54931640625 
[2025-03-16 15:59:51 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 4 to 5 ===
[2025-03-16 16:00:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 0 loss:0.021303504705429077 norm:0.0010261365678161383 max memory_allocated 38138.71923828125 
[2025-03-16 16:01:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 1 loss:0.014890613965690136 norm:0.00039287572144530714 max memory_allocated 38138.71923828125 
[2025-03-16 16:02:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 2 loss:0.012175573036074638 norm:0.00019269959011580795 max memory_allocated 38138.71923828125 
[2025-03-16 16:03:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 3 loss:0.011060687713325024 norm:0.0001374766870867461 max memory_allocated 38138.71923828125 
[2025-03-16 16:04:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 4 loss:0.010520732030272484 norm:0.0001146767899626866 max memory_allocated 38138.71923828125 
[2025-03-16 16:05:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 5 loss:0.010165003128349781 norm:0.00010220870899502188 max memory_allocated 38138.71923828125 
[2025-03-16 16:06:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 6 loss:0.009915568865835667 norm:9.8629949206952e-05 max memory_allocated 38138.71923828125 
[2025-03-16 16:07:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 7 loss:0.00973214115947485 norm:9.629038686398417e-05 max memory_allocated 38138.71923828125 
[2025-03-16 16:08:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 8 loss:0.00960623100399971 norm:9.352962661068887e-05 max memory_allocated 38138.71923828125 
[2025-03-16 16:09:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 9 loss:0.00951462984085083 norm:9.189302363665774e-05 max memory_allocated 38138.71923828125 
[2025-03-16 16:10:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 10 loss:0.00945429690182209 norm:9.36291107791476e-05 max memory_allocated 38138.71923828125 
[2025-03-16 16:11:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 11 loss:0.009403371252119541 norm:9.035344555741176e-05 max memory_allocated 38138.71923828125 
[2025-03-16 16:12:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 12 loss:0.009376110509037971 norm:9.120807953877375e-05 max memory_allocated 38138.71923828125 
[2025-03-16 16:13:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 13 loss:0.00934500340372324 norm:9.158658212982118e-05 max memory_allocated 38138.71923828125 
[2025-03-16 16:14:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 14 loss:0.00933677889406681 norm:9.16444550966844e-05 max memory_allocated 38138.71923828125 
[2025-03-16 16:14:41 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 5 to 6 ===
[2025-03-16 16:15:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 0 loss:0.029936833307147026 norm:0.005898242816329002 max memory_allocated 38138.89111328125 
[2025-03-16 16:16:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 1 loss:0.02110449969768524 norm:0.0025522946380078793 max memory_allocated 38138.89111328125 
[2025-03-16 16:17:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 2 loss:0.016732042655348778 norm:0.0014078894164413214 max memory_allocated 38138.89111328125 
[2025-03-16 16:18:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 3 loss:0.014643474481999874 norm:0.00087002880172804 max memory_allocated 38138.89111328125 
[2025-03-16 16:19:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 4 loss:0.013579407706856728 norm:0.000599193328525871 max memory_allocated 38138.89111328125 
[2025-03-16 16:20:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 5 loss:0.012956155464053154 norm:0.0004757896822411567 max memory_allocated 38138.89111328125 
[2025-03-16 16:21:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 6 loss:0.012531750835478306 norm:0.0003866378974635154 max memory_allocated 38138.89111328125 
[2025-03-16 16:22:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 7 loss:0.012230092659592628 norm:0.00033259743941016495 max memory_allocated 38138.89111328125 
[2025-03-16 16:23:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 8 loss:0.011998575180768967 norm:0.0002926209126599133 max memory_allocated 38138.89111328125 
[2025-03-16 16:24:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 9 loss:0.01185265276581049 norm:0.00025664616259746253 max memory_allocated 38138.89111328125 
[2025-03-16 16:25:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 10 loss:0.011745838448405266 norm:0.00024170882534235716 max memory_allocated 38138.89111328125 
[2025-03-16 16:26:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 11 loss:0.011656106449663639 norm:0.00022635748609900475 max memory_allocated 38138.89111328125 
[2025-03-16 16:27:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 12 loss:0.011598821729421616 norm:0.00020933093037456274 max memory_allocated 38138.89111328125 
[2025-03-16 16:28:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 13 loss:0.011549199931323528 norm:0.0001964569673873484 max memory_allocated 38138.89111328125 
[2025-03-16 16:29:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 14 loss:0.011501237750053406 norm:0.00018658101907931268 max memory_allocated 38138.89111328125 
[2025-03-16 16:29:31 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 6 to 7 ===
[2025-03-16 16:30:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 0 loss:0.023954257369041443 norm:0.001514600240625441 max memory_allocated 38139.06298828125 
[2025-03-16 16:31:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 1 loss:0.017097972333431244 norm:0.0006468019564636052 max memory_allocated 38139.06298828125 
[2025-03-16 16:32:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 2 loss:0.01391199603676796 norm:0.00030626810621470213 max memory_allocated 38139.06298828125 
[2025-03-16 16:33:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 3 loss:0.012526378035545349 norm:0.00021097625722177327 max memory_allocated 38139.06298828125 
[2025-03-16 16:34:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 4 loss:0.011880101636052132 norm:0.00016862701158970594 max memory_allocated 38139.06298828125 
[2025-03-16 16:35:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 5 loss:0.011453893966972828 norm:0.00014432001626119018 max memory_allocated 38139.06298828125 
[2025-03-16 16:36:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 6 loss:0.011169347912073135 norm:0.00013494843733496964 max memory_allocated 38139.06298828125 
[2025-03-16 16:37:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 7 loss:0.010963769629597664 norm:0.00012702414824161679 max memory_allocated 38139.06298828125 
[2025-03-16 16:38:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 8 loss:0.01080691535025835 norm:0.00011904050188604742 max memory_allocated 38139.06298828125 
[2025-03-16 16:39:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 9 loss:0.010726764798164368 norm:0.00011749448458431289 max memory_allocated 38139.06298828125 
[2025-03-16 16:40:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 10 loss:0.010677083395421505 norm:0.00011765755334636196 max memory_allocated 38139.06298828125 
[2025-03-16 16:41:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 11 loss:0.01061753649264574 norm:0.00011214122787350789 max memory_allocated 38139.06298828125 
[2025-03-16 16:41:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 12 loss:0.01057229284197092 norm:0.00011360851203789935 max memory_allocated 38139.06298828125 
[2025-03-16 16:42:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 13 loss:0.010534997098147869 norm:0.00010966260742861778 max memory_allocated 38139.06298828125 
[2025-03-16 16:43:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 14 loss:0.010506197810173035 norm:0.0001093662140192464 max memory_allocated 38139.06298828125 
[2025-03-16 16:44:23 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 7 to 8 ===
[2025-03-16 16:45:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 0 loss:0.0185559019446373 norm:0.0005704176728613675 max memory_allocated 38139.23486328125 
[2025-03-16 16:46:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 1 loss:0.013674093410372734 norm:0.00020621763542294502 max memory_allocated 38139.23486328125 
[2025-03-16 16:47:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 2 loss:0.0112496018409729 norm:0.00013491432764567435 max memory_allocated 38139.23486328125 
[2025-03-16 16:48:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 3 loss:0.010188085958361626 norm:0.00010693099466152489 max memory_allocated 38139.23486328125 
[2025-03-16 16:49:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 4 loss:0.00966033898293972 norm:9.52250265982002e-05 max memory_allocated 38139.23486328125 
[2025-03-16 16:50:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 5 loss:0.00930067989975214 norm:8.79319486557506e-05 max memory_allocated 38139.23486328125 
[2025-03-16 16:51:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 6 loss:0.009089156985282898 norm:8.523109136149287e-05 max memory_allocated 38139.23486328125 
[2025-03-16 16:52:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 7 loss:0.008941203355789185 norm:8.335450547747314e-05 max memory_allocated 38139.23486328125 
[2025-03-16 16:53:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 8 loss:0.00881290528923273 norm:8.663471089676023e-05 max memory_allocated 38139.23486328125 
[2025-03-16 16:54:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 9 loss:0.008758969604969025 norm:8.182391320588067e-05 max memory_allocated 38139.23486328125 
[2025-03-16 16:54:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 10 loss:0.008712603710591793 norm:7.812771946191788e-05 max memory_allocated 38139.23486328125 
[2025-03-16 16:55:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 11 loss:0.008667990565299988 norm:7.86368764238432e-05 max memory_allocated 38139.23486328125 
[2025-03-16 16:56:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 12 loss:0.008648410439491272 norm:7.776584970997646e-05 max memory_allocated 38139.23486328125 
[2025-03-16 16:57:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 13 loss:0.008643043227493763 norm:7.913904846645892e-05 max memory_allocated 38139.23486328125 
[2025-03-16 16:58:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 14 loss:0.008616114966571331 norm:7.835466385586187e-05 max memory_allocated 38139.23486328125 
[2025-03-16 16:59:18 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 8 to 9 ===
[2025-03-16 17:00:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 0 loss:0.020597605034708977 norm:0.001142226392403245 max memory_allocated 38139.40673828125 
[2025-03-16 17:01:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 1 loss:0.015055117197334766 norm:0.00040464670746587217 max memory_allocated 38139.40673828125 
[2025-03-16 17:02:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 2 loss:0.012260772287845612 norm:0.0002230280515505001 max memory_allocated 38139.40673828125 
[2025-03-16 17:03:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 3 loss:0.010906555689871311 norm:0.0001533320901216939 max memory_allocated 38139.40673828125 
[2025-03-16 17:04:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 4 loss:0.01023016031831503 norm:0.00012259624782018363 max memory_allocated 38139.40673828125 
[2025-03-16 17:05:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 5 loss:0.009806506335735321 norm:0.00010894989827647805 max memory_allocated 38139.40673828125 
[2025-03-16 17:06:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 6 loss:0.009536565281450748 norm:0.00010097224003402516 max memory_allocated 38139.40673828125 
[2025-03-16 17:07:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 7 loss:0.009352140128612518 norm:9.469073847867548e-05 max memory_allocated 38139.40673828125 
[2025-03-16 17:08:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 8 loss:0.009233088232576847 norm:8.855282794684172e-05 max memory_allocated 38139.40673828125 
[2025-03-16 17:08:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 9 loss:0.00916691217571497 norm:9.149387187790126e-05 max memory_allocated 38139.40673828125 
[2025-03-16 17:09:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 10 loss:0.009108503349125385 norm:9.139542817138135e-05 max memory_allocated 38139.40673828125 
[2025-03-16 17:10:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 11 loss:0.009075208567082882 norm:9.118323941947892e-05 max memory_allocated 38139.40673828125 
[2025-03-16 17:11:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 12 loss:0.00906007643789053 norm:9.237905032932758e-05 max memory_allocated 38139.40673828125 
[2025-03-16 17:12:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 13 loss:0.009055286645889282 norm:9.1373804025352e-05 max memory_allocated 38139.40673828125 
[2025-03-16 17:13:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 14 loss:0.009032570756971836 norm:9.030912769958377e-05 max memory_allocated 38139.40673828125 
[2025-03-16 17:14:14 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 9 to 10 ===
[2025-03-16 17:15:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 0 loss:0.02183607593178749 norm:0.0005575494142249227 max memory_allocated 38139.57861328125 
[2025-03-16 17:16:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 1 loss:0.01635080575942993 norm:0.00029101109248586 max memory_allocated 38139.57861328125 
[2025-03-16 17:17:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 2 loss:0.013458460569381714 norm:0.00018354355415794998 max memory_allocated 38139.57861328125 
[2025-03-16 17:18:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 3 loss:0.012027233839035034 norm:0.00013379211304709315 max memory_allocated 38139.57861328125 
[2025-03-16 17:19:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 4 loss:0.01135286595672369 norm:0.00011269147216808051 max memory_allocated 38139.57861328125 
[2025-03-16 17:20:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 5 loss:0.010942187160253525 norm:0.00010398909944342449 max memory_allocated 38139.57861328125 
[2025-03-16 17:21:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 6 loss:0.010655819438397884 norm:9.600806515663862e-05 max memory_allocated 38139.57861328125 
[2025-03-16 17:21:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 7 loss:0.010452785529196262 norm:9.198053885484114e-05 max memory_allocated 38139.57861328125 
[2025-03-16 17:22:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 8 loss:0.010330870747566223 norm:8.790257561486214e-05 max memory_allocated 38139.57861328125 
[2025-03-16 17:23:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 9 loss:0.010251076892018318 norm:8.658962906338274e-05 max memory_allocated 38139.57861328125 
[2025-03-16 17:24:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 10 loss:0.0101937809959054 norm:8.618787251180038e-05 max memory_allocated 38139.57861328125 
[2025-03-16 17:25:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 11 loss:0.010144882835447788 norm:8.450272434856743e-05 max memory_allocated 38139.57861328125 
[2025-03-16 17:26:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 12 loss:0.010081680491566658 norm:8.258502930402756e-05 max memory_allocated 38139.57861328125 
[2025-03-16 17:27:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 13 loss:0.010053875856101513 norm:8.44864989630878e-05 max memory_allocated 38139.57861328125 
[2025-03-16 17:28:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 14 loss:0.010039483197033405 norm:8.368247654289007e-05 max memory_allocated 38139.57861328125 
[2025-03-16 17:29:06 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 10 to 11 ===
[2025-03-16 17:30:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 0 loss:0.030067596584558487 norm:0.0038001425564289093 max memory_allocated 38139.75048828125 
[2025-03-16 17:31:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 1 loss:0.02123730629682541 norm:0.0015652067959308624 max memory_allocated 38139.75048828125 
[2025-03-16 17:32:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 2 loss:0.017219018191099167 norm:0.0008242131443694234 max memory_allocated 38139.75048828125 
[2025-03-16 17:33:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 3 loss:0.015154541470110416 norm:0.0004965358530171216 max memory_allocated 38139.75048828125 
[2025-03-16 17:33:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 4 loss:0.014126821421086788 norm:0.0003334956127218902 max memory_allocated 38139.75048828125 
[2025-03-16 17:34:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 5 loss:0.013507689349353313 norm:0.0002566608600318432 max memory_allocated 38139.75048828125 
[2025-03-16 17:35:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 6 loss:0.013102717697620392 norm:0.00021654233569279313 max memory_allocated 38139.75048828125 
[2025-03-16 17:36:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 7 loss:0.012857254594564438 norm:0.00021172279957681894 max memory_allocated 38139.75048828125 
[2025-03-16 17:37:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 8 loss:0.012670967727899551 norm:0.0002017340448219329 max memory_allocated 38139.75048828125 
[2025-03-16 17:38:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 9 loss:0.012540819123387337 norm:0.00017530594777781516 max memory_allocated 38139.75048828125 
[2025-03-16 17:39:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 10 loss:0.01243164949119091 norm:0.00015053999959491193 max memory_allocated 38139.75048828125 
[2025-03-16 17:40:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 11 loss:0.012350919656455517 norm:0.0001443158253096044 max memory_allocated 38139.75048828125 
[2025-03-16 17:41:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 12 loss:0.012332594022154808 norm:0.00016776661504991353 max memory_allocated 38139.75048828125 
[2025-03-16 17:42:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 13 loss:0.012305831536650658 norm:0.0001661513524595648 max memory_allocated 38139.75048828125 
[2025-03-16 17:43:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 14 loss:0.012232977896928787 norm:0.00013688812032341957 max memory_allocated 38139.75048828125 
[2025-03-16 17:43:58 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 11 to 12 ===
[2025-03-16 17:45:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 0 loss:0.02376851812005043 norm:0.0023757857270538807 max memory_allocated 38140.92236328125 
[2025-03-16 17:45:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 1 loss:0.017907386645674706 norm:0.0004697843105532229 max memory_allocated 38140.92236328125 
[2025-03-16 17:46:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 2 loss:0.01495975162833929 norm:0.00028518782346509397 max memory_allocated 38140.92236328125 
[2025-03-16 17:47:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 3 loss:0.013437187299132347 norm:0.0002082870196318254 max memory_allocated 38140.92236328125 
[2025-03-16 17:48:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 4 loss:0.012691610492765903 norm:0.00016790279187262058 max memory_allocated 38140.92236328125 
[2025-03-16 17:49:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 5 loss:0.012236167676746845 norm:0.00014450195885729045 max memory_allocated 38141.92236328125 
[2025-03-16 17:50:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 6 loss:0.011926000937819481 norm:0.0001309570507146418 max memory_allocated 38141.92236328125 
[2025-03-16 17:51:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 7 loss:0.011718496680259705 norm:0.0001222736173076555 max memory_allocated 38141.92236328125 
[2025-03-16 17:52:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 8 loss:0.011580891907215118 norm:0.00011709531827364117 max memory_allocated 38141.92236328125 
[2025-03-16 17:53:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 9 loss:0.011491953395307064 norm:0.00011375264875823632 max memory_allocated 38141.92236328125 
[2025-03-16 17:54:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 10 loss:0.011426531709730625 norm:0.00011025412095477805 max memory_allocated 38141.92236328125 
[2025-03-16 17:55:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 11 loss:0.011375467292964458 norm:0.00010750976070994511 max memory_allocated 38141.92236328125 
[2025-03-16 17:56:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 12 loss:0.011329690925776958 norm:0.00010469976405147463 max memory_allocated 38141.92236328125 
[2025-03-16 17:57:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 13 loss:0.011296000331640244 norm:0.00010380533058196306 max memory_allocated 38141.92236328125 
[2025-03-16 17:58:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 14 loss:0.011272086761891842 norm:0.00010287012264598161 max memory_allocated 38141.92236328125 
[2025-03-16 17:58:48 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 12 to 13 ===
[2025-03-16 17:59:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 0 loss:0.0192052461206913 norm:0.0005139284767210484 max memory_allocated 38141.92236328125 
[2025-03-16 18:00:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 1 loss:0.014463130384683609 norm:0.0002437265357002616 max memory_allocated 38141.92236328125 
[2025-03-16 18:01:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 2 loss:0.011846647597849369 norm:0.00016568388673476875 max memory_allocated 38141.92236328125 
[2025-03-16 18:02:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 3 loss:0.01064325962215662 norm:0.0001177910016849637 max memory_allocated 38141.92236328125 
[2025-03-16 18:03:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 4 loss:0.010013433173298836 norm:9.918658179230988e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:04:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 5 loss:0.009618880227208138 norm:8.871766476659104e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:05:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 6 loss:0.009359296411275864 norm:8.117579272948205e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:06:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 7 loss:0.00918546412140131 norm:7.877041934989393e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:07:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 8 loss:0.009098065085709095 norm:7.810268289176747e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:08:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 9 loss:0.009017539210617542 norm:7.626543811056763e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:09:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 10 loss:0.00896019209176302 norm:7.320217991946265e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:10:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 11 loss:0.008924605324864388 norm:7.432802522089332e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:11:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 12 loss:0.008905178867280483 norm:7.63054340495728e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:12:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 13 loss:0.008915724232792854 norm:7.349220686592162e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:13:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 14 loss:0.008896570652723312 norm:7.05624115653336e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:13:39 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 13 to 14 ===
[2025-03-16 18:14:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 0 loss:0.02454758994281292 norm:0.0007817583973519504 max memory_allocated 38141.92236328125 
[2025-03-16 18:15:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 1 loss:0.018737975507974625 norm:0.0003915618872269988 max memory_allocated 38141.92236328125 
[2025-03-16 18:16:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 2 loss:0.015596967190504074 norm:0.0002504136355128139 max memory_allocated 38141.92236328125 
[2025-03-16 18:17:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 3 loss:0.014105387963354588 norm:0.00018682683003135026 max memory_allocated 38141.92236328125 
[2025-03-16 18:18:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 4 loss:0.013334117829799652 norm:0.00015326705761253834 max memory_allocated 38141.92236328125 
[2025-03-16 18:19:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 5 loss:0.012830730527639389 norm:0.0001337133871857077 max memory_allocated 38141.92236328125 
[2025-03-16 18:20:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 6 loss:0.012505462393164635 norm:0.00012434515519998968 max memory_allocated 38141.92236328125 
[2025-03-16 18:21:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 7 loss:0.012273197993636131 norm:0.00011622619058471173 max memory_allocated 38141.92236328125 
[2025-03-16 18:22:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 8 loss:0.012123269960284233 norm:0.00011109975457657129 max memory_allocated 38141.92236328125 
[2025-03-16 18:23:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 9 loss:0.012018043547868729 norm:0.00010968125570798293 max memory_allocated 38141.92236328125 
[2025-03-16 18:24:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 10 loss:0.011942107230424881 norm:0.00010774211841635406 max memory_allocated 38141.92236328125 
[2025-03-16 18:25:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 11 loss:0.011887208558619022 norm:0.0001071691294782795 max memory_allocated 38141.92236328125 
[2025-03-16 18:26:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 12 loss:0.011822293512523174 norm:0.00010617960651870817 max memory_allocated 38141.92236328125 
[2025-03-16 18:27:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 13 loss:0.011793346144258976 norm:0.00010379986633779481 max memory_allocated 38141.92236328125 
[2025-03-16 18:27:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 14 loss:0.011764994822442532 norm:0.00010247208410874009 max memory_allocated 38141.92236328125 
[2025-03-16 18:28:29 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 14 to 15 ===
[2025-03-16 18:29:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 0 loss:0.022771373391151428 norm:0.0005051876069046557 max memory_allocated 38141.92236328125 
[2025-03-16 18:30:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 1 loss:0.017292365431785583 norm:0.00024690793361514807 max memory_allocated 38141.92236328125 
[2025-03-16 18:31:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 2 loss:0.014164021238684654 norm:0.00016209532623179257 max memory_allocated 38141.92236328125 
[2025-03-16 18:32:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 3 loss:0.012830250896513462 norm:0.0001257647090824321 max memory_allocated 38141.92236328125 
[2025-03-16 18:33:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 4 loss:0.012123181484639645 norm:0.00010628455493133515 max memory_allocated 38141.92236328125 
[2025-03-16 18:34:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 5 loss:0.011728201992809772 norm:9.683818643679842e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:35:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 6 loss:0.011448284611105919 norm:9.00394661584869e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:36:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 7 loss:0.011255803517997265 norm:8.691748371347785e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:37:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 8 loss:0.011117661371827126 norm:8.409679867327213e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:38:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 9 loss:0.01103584561496973 norm:8.130839705700055e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:39:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 10 loss:0.01097005233168602 norm:8.034556230995804e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:39:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 11 loss:0.010913275182247162 norm:8.020304812816903e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:40:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 12 loss:0.010861942544579506 norm:7.727334013907239e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:41:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 13 loss:0.010833962820470333 norm:7.757861021673307e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:42:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 14 loss:0.010804042220115662 norm:7.57964953663759e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:43:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 15 to 16 ===
[2025-03-16 18:44:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 0 loss:0.024942927062511444 norm:0.0008194678812287748 max memory_allocated 38141.92236328125 
[2025-03-16 18:45:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 1 loss:0.01878114975988865 norm:0.0003714562626555562 max memory_allocated 38141.92236328125 
[2025-03-16 18:46:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 2 loss:0.015066332183778286 norm:0.00022171760792843997 max memory_allocated 38141.92236328125 
[2025-03-16 18:47:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 3 loss:0.013555482029914856 norm:0.00015987026563379914 max memory_allocated 38141.92236328125 
[2025-03-16 18:48:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 4 loss:0.012786367908120155 norm:0.0001308758946834132 max memory_allocated 38141.92236328125 
[2025-03-16 18:49:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 5 loss:0.012323025614023209 norm:0.00011639037256827578 max memory_allocated 38141.92236328125 
[2025-03-16 18:50:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 6 loss:0.012005646713078022 norm:0.000104303311672993 max memory_allocated 38141.92236328125 
[2025-03-16 18:51:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 7 loss:0.011786295101046562 norm:9.72488196566701e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:52:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 8 loss:0.011622794903814793 norm:9.12906980374828e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:52:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 9 loss:0.011499913409352303 norm:8.768425323069096e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:53:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 10 loss:0.011414662003517151 norm:8.31141514936462e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:54:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 11 loss:0.011344601400196552 norm:8.208487997762859e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:55:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 12 loss:0.011287344619631767 norm:8.015834464458749e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:56:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 13 loss:0.011260032653808594 norm:7.993233157321811e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:57:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 14 loss:0.011232057586312294 norm:7.975749031174928e-05 max memory_allocated 38141.92236328125 
[2025-03-16 18:58:12 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 16 to 17 ===
[2025-03-16 18:59:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 0 loss:0.024114016443490982 norm:0.0007104125106707215 max memory_allocated 38141.92236328125 
[2025-03-16 19:00:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 1 loss:0.01881125196814537 norm:0.0003134108555968851 max memory_allocated 38141.92236328125 
[2025-03-16 19:01:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 2 loss:0.015716133639216423 norm:0.0002110467612510547 max memory_allocated 38141.92236328125 
[2025-03-16 19:02:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 3 loss:0.014484617859125137 norm:0.00016178011719603091 max memory_allocated 38141.92236328125 
[2025-03-16 19:03:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 4 loss:0.01378033496439457 norm:0.00013023734209127724 max memory_allocated 38141.92236328125 
[2025-03-16 19:04:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 5 loss:0.013331811875104904 norm:0.00011429874575696886 max memory_allocated 38141.92236328125 
[2025-03-16 19:04:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 6 loss:0.013024291023612022 norm:0.00010981356899719685 max memory_allocated 38141.92236328125 
[2025-03-16 19:05:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 7 loss:0.012799948453903198 norm:0.0001038433110807091 max memory_allocated 38141.92236328125 
[2025-03-16 19:06:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 8 loss:0.012644276022911072 norm:9.495592530583963e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:07:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 9 loss:0.01254135649651289 norm:8.845988486427814e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:08:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 10 loss:0.01249233540147543 norm:8.737465395824984e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:09:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 11 loss:0.012454884126782417 norm:8.564640302211046e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:10:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 12 loss:0.012419933453202248 norm:8.411470480496064e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:11:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 13 loss:0.01239420659840107 norm:8.39615604490973e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:12:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 14 loss:0.012362414039671421 norm:8.514525688951835e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:13:04 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 17 to 18 ===
[2025-03-16 19:14:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 0 loss:0.025764187797904015 norm:0.0007627911400049925 max memory_allocated 38141.92236328125 
[2025-03-16 19:15:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 1 loss:0.019977334886789322 norm:0.00035073678009212017 max memory_allocated 38141.92236328125 
[2025-03-16 19:16:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 2 loss:0.016315873712301254 norm:0.00021492390078492463 max memory_allocated 38141.92236328125 
[2025-03-16 19:16:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 3 loss:0.015043787658214569 norm:0.0001655633095651865 max memory_allocated 38141.92236328125 
[2025-03-16 19:17:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 4 loss:0.014372661709785461 norm:0.00013810116797685623 max memory_allocated 38141.92236328125 
[2025-03-16 19:18:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 5 loss:0.013870845548808575 norm:0.00012304382107686251 max memory_allocated 38141.92236328125 
[2025-03-16 19:19:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 6 loss:0.013517686165869236 norm:0.00011476012878119946 max memory_allocated 38141.92236328125 
[2025-03-16 19:20:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 7 loss:0.013276140205562115 norm:0.00010793285036925226 max memory_allocated 38141.92236328125 
[2025-03-16 19:21:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 8 loss:0.013133944943547249 norm:0.00010258660768158734 max memory_allocated 38141.92236328125 
[2025-03-16 19:22:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 9 loss:0.013018234632909298 norm:9.839319682214409e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:23:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 10 loss:0.012929758056998253 norm:9.551020048093051e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:24:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 11 loss:0.012880650348961353 norm:9.274479816667736e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:25:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 12 loss:0.01283099502325058 norm:9.059526200871915e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:26:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 13 loss:0.012785756029188633 norm:8.739680924918503e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:27:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 14 loss:0.012753773480653763 norm:8.760607306612656e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:27:55 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 18 to 19 ===
[2025-03-16 19:28:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 0 loss:0.025456992909312248 norm:0.000652820453979075 max memory_allocated 38141.92236328125 
[2025-03-16 19:29:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 1 loss:0.019789740443229675 norm:0.0003544617793522775 max memory_allocated 38141.92236328125 
[2025-03-16 19:30:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 2 loss:0.016300130635499954 norm:0.00022256524243857712 max memory_allocated 38141.92236328125 
[2025-03-16 19:31:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 3 loss:0.015228244476020336 norm:0.00017697762814350426 max memory_allocated 38141.92236328125 
[2025-03-16 19:32:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 4 loss:0.014570081606507301 norm:0.00015385360165964812 max memory_allocated 38141.92236328125 
[2025-03-16 19:33:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 5 loss:0.014054878614842892 norm:0.00013794662663713098 max memory_allocated 38141.92236328125 
[2025-03-16 19:34:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 6 loss:0.013717018067836761 norm:0.00012498631258495152 max memory_allocated 38141.92236328125 
[2025-03-16 19:35:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 7 loss:0.013496305793523788 norm:0.0001158575396402739 max memory_allocated 38141.92236328125 
[2025-03-16 19:36:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 8 loss:0.013355014845728874 norm:0.00010978293721564114 max memory_allocated 38141.92236328125 
[2025-03-16 19:37:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 9 loss:0.013283099979162216 norm:0.00010754582763183862 max memory_allocated 38141.92236328125 
[2025-03-16 19:38:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 10 loss:0.01322543527930975 norm:0.00010548288992140442 max memory_allocated 38141.92236328125 
[2025-03-16 19:39:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 11 loss:0.013190671801567078 norm:0.00010418609599582851 max memory_allocated 38141.92236328125 
[2025-03-16 19:40:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 12 loss:0.01313995011150837 norm:0.00010335844854125753 max memory_allocated 38141.92236328125 
[2025-03-16 19:41:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 13 loss:0.013092121109366417 norm:0.00010035459126811475 max memory_allocated 38141.92236328125 
[2025-03-16 19:42:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 14 loss:0.013047830201685429 norm:9.808019240153953e-05 max memory_allocated 38141.92236328125 
[2025-03-16 19:42:46 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 19 to 20 ===
[2025-03-16 19:43:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 0 loss:0.02990148402750492 norm:0.0027483839076012373 max memory_allocated 38141.92236328125 
[2025-03-16 19:44:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 1 loss:0.022439630702137947 norm:0.0005361161311157048 max memory_allocated 38141.92236328125 
[2025-03-16 19:45:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 2 loss:0.018252888694405556 norm:0.00030426264856942 max memory_allocated 38141.92236328125 
[2025-03-16 19:46:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 3 loss:0.016840241849422455 norm:0.00021125521743670106 max memory_allocated 38141.92236328125 
[2025-03-16 19:47:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 4 loss:0.01599942520260811 norm:0.00017419418145436794 max memory_allocated 38141.92236328125 
[2025-03-16 19:48:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 5 loss:0.015364560298621655 norm:0.00015517539577558637 max memory_allocated 38141.92236328125 
[2025-03-16 19:49:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 6 loss:0.014915281906723976 norm:0.0001430463744327426 max memory_allocated 38141.92236328125 
[2025-03-16 19:50:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 7 loss:0.014653695747256279 norm:0.00013552836026065052 max memory_allocated 38141.92236328125 
[2025-03-16 19:51:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 8 loss:0.014472594484686852 norm:0.00012347515439614654 max memory_allocated 38141.92236328125 
[2025-03-16 19:52:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 9 loss:0.01437402330338955 norm:0.00012321516987867653 max memory_allocated 38141.92236328125 
[2025-03-16 19:53:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 10 loss:0.0142768993973732 norm:0.00011893656483152881 max memory_allocated 38141.92236328125 
[2025-03-16 19:54:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 11 loss:0.014189034700393677 norm:0.00011068359890487045 max memory_allocated 38141.92236328125 
[2025-03-16 19:55:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 12 loss:0.014147467911243439 norm:0.00010776448471006006 max memory_allocated 38141.92236328125 
[2025-03-16 19:56:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 13 loss:0.014078034088015556 norm:0.00010501972428755835 max memory_allocated 38141.92236328125 
[2025-03-16 19:57:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 14 loss:0.014017720706760883 norm:0.00010392358672106639 max memory_allocated 38141.92236328125 
[2025-03-16 19:57:37 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 20 to 21 ===
[2025-03-16 19:58:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 0 loss:0.029960695654153824 norm:0.001053494750522077 max memory_allocated 38141.92236328125 
[2025-03-16 19:59:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 1 loss:0.02354198880493641 norm:0.0004091995069757104 max memory_allocated 38141.92236328125 
[2025-03-16 20:00:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 2 loss:0.019270744174718857 norm:0.00025425927015021443 max memory_allocated 38141.92236328125 
[2025-03-16 20:01:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 3 loss:0.01796294003725052 norm:0.00020543299615383148 max memory_allocated 38141.92236328125 
[2025-03-16 20:02:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 4 loss:0.017111225053668022 norm:0.00017922533152159303 max memory_allocated 38141.92236328125 
[2025-03-16 20:03:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 5 loss:0.01642341911792755 norm:0.0001693387166596949 max memory_allocated 38141.92236328125 
[2025-03-16 20:04:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 6 loss:0.015992075204849243 norm:0.00015943706966936588 max memory_allocated 38141.92236328125 
[2025-03-16 20:05:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 7 loss:0.01573701575398445 norm:0.00015132164116948843 max memory_allocated 38141.92236328125 
[2025-03-16 20:06:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 8 loss:0.015560675412416458 norm:0.00014078838285058737 max memory_allocated 38141.92236328125 
[2025-03-16 20:07:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 9 loss:0.015427055768668652 norm:0.00013709611084777862 max memory_allocated 38141.92236328125 
[2025-03-16 20:08:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 10 loss:0.01530962809920311 norm:0.00013428118836600333 max memory_allocated 38141.92236328125 
[2025-03-16 20:09:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 11 loss:0.01521536149084568 norm:0.00012810072803404182 max memory_allocated 38141.92236328125 
[2025-03-16 20:10:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 12 loss:0.015134441666305065 norm:0.0001244457089342177 max memory_allocated 38141.92236328125 
[2025-03-16 20:11:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 13 loss:0.015052370727062225 norm:0.00012118206359446049 max memory_allocated 38141.92236328125 
[2025-03-16 20:11:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 14 loss:0.014980848878622055 norm:0.00011567877663765103 max memory_allocated 38141.92236328125 
[2025-03-16 20:12:28 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 21 to 22 ===
[2025-03-16 20:13:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 0 loss:0.03181226924061775 norm:0.001113042002543807 max memory_allocated 38141.92236328125 
[2025-03-16 20:14:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 1 loss:0.024961084127426147 norm:0.0005248853121884167 max memory_allocated 38141.92236328125 
[2025-03-16 20:15:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 2 loss:0.020524661988019943 norm:0.0003469570365268737 max memory_allocated 38141.92236328125 
[2025-03-16 20:16:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 3 loss:0.01892528310418129 norm:0.0002790292783174664 max memory_allocated 38141.92236328125 
[2025-03-16 20:17:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 4 loss:0.017930518835783005 norm:0.00023156778479460627 max memory_allocated 38141.92236328125 
[2025-03-16 20:18:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 5 loss:0.017229486256837845 norm:0.00020165480964351445 max memory_allocated 38141.92236328125 
[2025-03-16 20:19:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 6 loss:0.016801755875349045 norm:0.0001843787613324821 max memory_allocated 38141.92236328125 
[2025-03-16 20:20:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 7 loss:0.016570884734392166 norm:0.00017423948156647384 max memory_allocated 38141.92236328125 
[2025-03-16 20:21:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 8 loss:0.016392480581998825 norm:0.00016625577700324357 max memory_allocated 38141.92236328125 
[2025-03-16 20:22:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 9 loss:0.01621914654970169 norm:0.00016059780318755656 max memory_allocated 38141.92236328125 
[2025-03-16 20:23:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 10 loss:0.01607665792107582 norm:0.0001532355381641537 max memory_allocated 38141.92236328125 
[2025-03-16 20:23:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 11 loss:0.015955256298184395 norm:0.00015249605348799378 max memory_allocated 38141.92236328125 
[2025-03-16 20:24:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 12 loss:0.015855345875024796 norm:0.00014328586985357106 max memory_allocated 38141.92236328125 
[2025-03-16 20:25:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 13 loss:0.015757624059915543 norm:0.00013845058856531978 max memory_allocated 38141.92236328125 
[2025-03-16 20:26:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 14 loss:0.015666594728827477 norm:0.00013595230120699853 max memory_allocated 38141.92236328125 
[2025-03-16 20:27:19 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 22 to 23 ===
[2025-03-16 20:28:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 0 loss:0.035391539335250854 norm:0.04267720878124237 max memory_allocated 38141.92236328125 
[2025-03-16 20:29:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 1 loss:0.026524201035499573 norm:0.0022588048595935106 max memory_allocated 38141.92236328125 
[2025-03-16 20:30:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 2 loss:0.021465592086315155 norm:0.001460275612771511 max memory_allocated 38141.92236328125 
[2025-03-16 20:31:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 3 loss:0.01980544812977314 norm:0.0011283636558800936 max memory_allocated 38141.92236328125 
[2025-03-16 20:32:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 4 loss:0.018705546855926514 norm:0.0009630254935473204 max memory_allocated 38141.92236328125 
[2025-03-16 20:33:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 5 loss:0.017891351133584976 norm:0.0008267922094091773 max memory_allocated 38141.92236328125 
[2025-03-16 20:34:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 6 loss:0.01748182438313961 norm:0.0007136210915632546 max memory_allocated 38141.92236328125 
[2025-03-16 20:35:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 7 loss:0.01721578650176525 norm:0.0006033001700416207 max memory_allocated 38141.92236328125 
[2025-03-16 20:35:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 8 loss:0.017018893733620644 norm:0.0005350622814148664 max memory_allocated 38141.92236328125 
[2025-03-16 20:36:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 9 loss:0.01681443862617016 norm:0.00047562760300934315 max memory_allocated 38141.92236328125 
[2025-03-16 20:37:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 10 loss:0.016679372638463974 norm:0.00042955236858688295 max memory_allocated 38141.92236328125 
[2025-03-16 20:38:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 11 loss:0.01653813011944294 norm:0.0003868228814098984 max memory_allocated 38141.92236328125 
[2025-03-16 20:39:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 12 loss:0.016428424045443535 norm:0.0003584826772566885 max memory_allocated 38141.92236328125 
[2025-03-16 20:40:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 13 loss:0.01632067561149597 norm:0.00033349625300616026 max memory_allocated 38141.92236328125 
[2025-03-16 20:41:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 14 loss:0.016229448840022087 norm:0.00030999042792245746 max memory_allocated 38141.92236328125 
[2025-03-16 20:42:10 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 23 to 24 ===
[2025-03-16 20:43:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 0 loss:0.03670155629515648 norm:0.00131139880977571 max memory_allocated 38141.98486328125 
[2025-03-16 20:44:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 1 loss:0.02888999693095684 norm:0.0005016976501792669 max memory_allocated 38141.98486328125 
[2025-03-16 20:45:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 2 loss:0.02317887358367443 norm:0.00032875800388865173 max memory_allocated 38141.98486328125 
[2025-03-16 20:46:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 3 loss:0.021213240921497345 norm:0.0002526364987716079 max memory_allocated 38141.98486328125 
[2025-03-16 20:46:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 4 loss:0.01998087763786316 norm:0.0002193008258473128 max memory_allocated 38141.98486328125 
[2025-03-16 20:47:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 5 loss:0.019202115014195442 norm:0.00019285806047264487 max memory_allocated 38141.98486328125 
[2025-03-16 20:48:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 6 loss:0.018824713304638863 norm:0.00017807880067266524 max memory_allocated 38141.98486328125 
[2025-03-16 20:49:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 7 loss:0.018598536029458046 norm:0.00017248622316401452 max memory_allocated 38141.98486328125 
[2025-03-16 20:50:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 8 loss:0.018382413312792778 norm:0.0001563759578857571 max memory_allocated 38141.98486328125 
[2025-03-16 20:51:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 9 loss:0.018230415880680084 norm:0.00015510735101997852 max memory_allocated 38141.98486328125 
[2025-03-16 20:52:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 10 loss:0.018077414482831955 norm:0.00014869892038404942 max memory_allocated 38141.98486328125 
[2025-03-16 20:53:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 11 loss:0.01795116811990738 norm:0.00014739787729922682 max memory_allocated 38141.98486328125 
[2025-03-16 20:54:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 12 loss:0.017843211069703102 norm:0.0001413132849847898 max memory_allocated 38141.98486328125 
[2025-03-16 20:55:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 13 loss:0.01775193400681019 norm:0.00014073045167606324 max memory_allocated 38141.98486328125 
[2025-03-16 20:56:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 14 loss:0.0176788829267025 norm:0.0001402654015691951 max memory_allocated 38141.98486328125 
[2025-03-16 20:57:00 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 24 to 25 ===
[2025-03-16 20:58:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 0 loss:0.044024888426065445 norm:0.0016761496663093567 max memory_allocated 38142.15673828125 
[2025-03-16 20:58:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 1 loss:0.03347965329885483 norm:0.0008532741921953857 max memory_allocated 38142.15673828125 
[2025-03-16 20:59:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 2 loss:0.02660994417965412 norm:0.0004901080392301083 max memory_allocated 38142.15673828125 
[2025-03-16 21:00:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 3 loss:0.0242775846272707 norm:0.0003724786511156708 max memory_allocated 38142.15673828125 
[2025-03-16 21:01:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 4 loss:0.022809617221355438 norm:0.0003077828441746533 max memory_allocated 38142.15673828125 
[2025-03-16 21:02:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 5 loss:0.022016508504748344 norm:0.0002674484858289361 max memory_allocated 38142.15673828125 
[2025-03-16 21:03:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 6 loss:0.021606743335723877 norm:0.00025307160103693604 max memory_allocated 38142.15673828125 
[2025-03-16 21:04:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 7 loss:0.02130412869155407 norm:0.00022562847880180925 max memory_allocated 38142.15673828125 
[2025-03-16 21:05:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 8 loss:0.021071508526802063 norm:0.00021215900778770447 max memory_allocated 38142.15673828125 
[2025-03-16 21:06:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 9 loss:0.020884841680526733 norm:0.00020646183111239225 max memory_allocated 38142.15673828125 
[2025-03-16 21:07:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 10 loss:0.020738322287797928 norm:0.00019752832304220647 max memory_allocated 38142.15673828125 
[2025-03-16 21:08:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 11 loss:0.02060195803642273 norm:0.00019508108380250633 max memory_allocated 38142.15673828125 
[2025-03-16 21:09:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 12 loss:0.02049393206834793 norm:0.0001822388294385746 max memory_allocated 38142.15673828125 
[2025-03-16 21:10:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 13 loss:0.02040237933397293 norm:0.00017400291108060628 max memory_allocated 38142.15673828125 
[2025-03-16 21:11:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 14 loss:0.02034994587302208 norm:0.00017630934598855674 max memory_allocated 38142.15673828125 
[2025-03-16 21:11:50 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 25 to 26 ===
[2025-03-16 21:12:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 0 loss:0.0488680936396122 norm:0.001866037491708994 max memory_allocated 38142.32861328125 
[2025-03-16 21:13:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 1 loss:0.03744461387395859 norm:0.0008910865290090442 max memory_allocated 38142.32861328125 
[2025-03-16 21:14:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 2 loss:0.030173882842063904 norm:0.0005226593930274248 max memory_allocated 38142.32861328125 
[2025-03-16 21:15:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 3 loss:0.027490857988595963 norm:0.0003991380799561739 max memory_allocated 38142.32861328125 
[2025-03-16 21:16:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 4 loss:0.025843078270554543 norm:0.0003175767487846315 max memory_allocated 38142.32861328125 
[2025-03-16 21:17:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 5 loss:0.02506871521472931 norm:0.00027938862331211567 max memory_allocated 38142.32861328125 
[2025-03-16 21:18:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 6 loss:0.024647172540426254 norm:0.00026612848159857094 max memory_allocated 38142.32861328125 
[2025-03-16 21:19:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 7 loss:0.02434203028678894 norm:0.0002506969030946493 max memory_allocated 38142.32861328125 
[2025-03-16 21:20:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 8 loss:0.024111367762088776 norm:0.00022443693887908012 max memory_allocated 38142.32861328125 
[2025-03-16 21:21:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 9 loss:0.023887721821665764 norm:0.0002122341829817742 max memory_allocated 38142.32861328125 
[2025-03-16 21:22:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 10 loss:0.023696765303611755 norm:0.0002019416424445808 max memory_allocated 38142.32861328125 
[2025-03-16 21:23:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 11 loss:0.02355070598423481 norm:0.00019683589925989509 max memory_allocated 38142.32861328125 
[2025-03-16 21:24:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 12 loss:0.02342706359922886 norm:0.00019254312792327255 max memory_allocated 38142.32861328125 
[2025-03-16 21:25:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 13 loss:0.023305652663111687 norm:0.0001891746505862102 max memory_allocated 38142.32861328125 
[2025-03-16 21:26:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 14 loss:0.023237425833940506 norm:0.00018614670261740685 max memory_allocated 38142.32861328125 
[2025-03-16 21:26:41 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 26 to 27 ===
[2025-03-16 21:27:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 0 loss:0.052626412361860275 norm:0.0027244642842561007 max memory_allocated 38142.50048828125 
[2025-03-16 21:28:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 1 loss:0.04064464569091797 norm:0.0014904990093782544 max memory_allocated 38142.50048828125 
[2025-03-16 21:29:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 2 loss:0.03279419243335724 norm:0.0009335335926152766 max memory_allocated 38142.50048828125 
[2025-03-16 21:30:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 3 loss:0.029741652309894562 norm:0.0006534912390634418 max memory_allocated 38142.50048828125 
[2025-03-16 21:31:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 4 loss:0.02799178659915924 norm:0.0004937849589623511 max memory_allocated 38142.50048828125 
[2025-03-16 21:32:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 5 loss:0.027241947129368782 norm:0.000404277874622494 max memory_allocated 38142.50048828125 
[2025-03-16 21:33:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 6 loss:0.026742039248347282 norm:0.0003425615723244846 max memory_allocated 38142.50048828125 
[2025-03-16 21:34:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 7 loss:0.026336930692195892 norm:0.0002948112669400871 max memory_allocated 38142.50048828125 
[2025-03-16 21:35:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 8 loss:0.026047714054584503 norm:0.0002649921807460487 max memory_allocated 38142.50048828125 
[2025-03-16 21:36:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 9 loss:0.02587195672094822 norm:0.00024447095347568393 max memory_allocated 38142.50048828125 
[2025-03-16 21:37:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 10 loss:0.02572742849588394 norm:0.0002247268275823444 max memory_allocated 38142.50048828125 
[2025-03-16 21:38:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 11 loss:0.025622431188821793 norm:0.0002150128857465461 max memory_allocated 38142.50048828125 
[2025-03-16 21:39:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 12 loss:0.025524770841002464 norm:0.00020296406000852585 max memory_allocated 38142.50048828125 
[2025-03-16 21:40:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 13 loss:0.02539263293147087 norm:0.0001951696176547557 max memory_allocated 38142.50048828125 
[2025-03-16 21:41:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 14 loss:0.025313926860690117 norm:0.0001898519112728536 max memory_allocated 38142.50048828125 
[2025-03-16 21:41:32 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 27 to 28 ===
[2025-03-16 21:42:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 0 loss:0.061953965574502945 norm:0.008521780371665955 max memory_allocated 38142.84521484375 
[2025-03-16 21:43:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 1 loss:0.04767307639122009 norm:0.006024619098752737 max memory_allocated 38142.84521484375 
[2025-03-16 21:44:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 2 loss:0.038171447813510895 norm:0.004255747422575951 max memory_allocated 38142.84521484375 
[2025-03-16 21:45:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 3 loss:0.03445930406451225 norm:0.003442911198362708 max memory_allocated 38142.84521484375 
[2025-03-16 21:46:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 4 loss:0.03271794319152832 norm:0.0028718782123178244 max memory_allocated 38142.84521484375 
[2025-03-16 21:47:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 5 loss:0.031799253076314926 norm:0.0024193227291107178 max memory_allocated 38142.84521484375 
[2025-03-16 21:48:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 6 loss:0.03110935352742672 norm:0.002020479878410697 max memory_allocated 38142.84521484375 
[2025-03-16 21:49:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 7 loss:0.030588101595640182 norm:0.001842894940637052 max memory_allocated 38142.84521484375 
[2025-03-16 21:50:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 8 loss:0.03017532452940941 norm:0.0018158897291868925 max memory_allocated 38142.84521484375 
[2025-03-16 21:51:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 9 loss:0.02988963946700096 norm:0.001773496507667005 max memory_allocated 38142.84521484375 
[2025-03-16 21:52:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 10 loss:0.029598787426948547 norm:0.0016745708417147398 max memory_allocated 38142.84521484375 
[2025-03-16 21:53:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 11 loss:0.029322542250156403 norm:0.0015765838325023651 max memory_allocated 38142.84521484375 
[2025-03-16 21:53:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 12 loss:0.029198186472058296 norm:0.001537799253128469 max memory_allocated 38142.84521484375 
[2025-03-16 21:54:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 13 loss:0.029084740206599236 norm:0.0015430743806064129 max memory_allocated 38142.84521484375 
[2025-03-16 21:55:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 14 loss:0.0289238840341568 norm:0.001457013888284564 max memory_allocated 38142.84521484375 
[2025-03-16 21:56:24 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 28 to 29 ===
[2025-03-16 21:57:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 0 loss:0.08619801700115204 norm:0.013404724188148975 max memory_allocated 38143.18994140625 
[2025-03-16 21:58:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 1 loss:0.06412511318922043 norm:0.008426268585026264 max memory_allocated 38143.18994140625 
[2025-03-16 21:59:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 2 loss:0.05060790851712227 norm:0.005658552050590515 max memory_allocated 38143.18994140625 
[2025-03-16 22:00:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 3 loss:0.04561779648065567 norm:0.004088722635060549 max memory_allocated 38143.18994140625 
[2025-03-16 22:01:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 4 loss:0.043021537363529205 norm:0.0031665454152971506 max memory_allocated 38143.18994140625 
[2025-03-16 22:02:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 5 loss:0.04148051515221596 norm:0.0029748212546110153 max memory_allocated 38143.18994140625 
[2025-03-16 22:03:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 6 loss:0.040588464587926865 norm:0.0029886418487876654 max memory_allocated 38143.18994140625 
[2025-03-16 22:04:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 7 loss:0.03997797891497612 norm:0.00289498851634562 max memory_allocated 38143.18994140625 
[2025-03-16 22:05:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 8 loss:0.03957941383123398 norm:0.0029330935794860125 max memory_allocated 38143.18994140625 
[2025-03-16 22:06:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 9 loss:0.03922655060887337 norm:0.0026646440383046865 max memory_allocated 38143.18994140625 
[2025-03-16 22:06:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 10 loss:0.03900158777832985 norm:0.002227925695478916 max memory_allocated 38143.18994140625 
[2025-03-16 22:07:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 11 loss:0.038897037506103516 norm:0.0021734116598963737 max memory_allocated 38143.18994140625 
[2025-03-16 22:08:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 12 loss:0.03889509290456772 norm:0.0021557200234383345 max memory_allocated 38143.18994140625 
[2025-03-16 22:09:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 13 loss:0.038709599524736404 norm:0.002104919170960784 max memory_allocated 38143.18994140625 
[2025-03-16 22:10:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 14 loss:0.03842496871948242 norm:0.001938176923431456 max memory_allocated 38143.18994140625 
[2025-03-16 22:11:17 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 29 to 30 ===
[2025-03-16 22:12:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 0 loss:97.89329528808594 norm:218.111328125 max memory_allocated 38143.36181640625 
[2025-03-16 22:13:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 1 loss:27.590057373046875 norm:113.23817443847656 max memory_allocated 38143.36181640625 
[2025-03-16 22:14:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 2 loss:13.699487686157227 norm:62.61887741088867 max memory_allocated 38143.36181640625 
[2025-03-16 22:15:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 3 loss:8.644015312194824 norm:42.90912628173828 max memory_allocated 38143.36181640625 
[2025-03-16 22:16:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 4 loss:6.312463283538818 norm:33.48757553100586 max memory_allocated 38143.36181640625 
[2025-03-16 22:17:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 5 loss:4.441059112548828 norm:25.45598793029785 max memory_allocated 38143.36181640625 
[2025-03-16 22:18:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 6 loss:4.138828277587891 norm:24.861928939819336 max memory_allocated 38143.36181640625 
[2025-03-16 22:18:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 7 loss:3.7083685398101807 norm:22.889554977416992 max memory_allocated 38143.36181640625 
[2025-03-16 22:19:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 8 loss:3.2065248489379883 norm:21.292556762695312 max memory_allocated 38143.36181640625 
[2025-03-16 22:20:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 9 loss:3.2834713459014893 norm:22.762042999267578 max memory_allocated 38143.36181640625 
[2025-03-16 22:21:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 10 loss:3.307435989379883 norm:22.14293670654297 max memory_allocated 38143.36181640625 
[2025-03-16 22:22:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 11 loss:2.9339284896850586 norm:20.43702507019043 max memory_allocated 38143.36181640625 
[2025-03-16 22:23:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 12 loss:2.680649518966675 norm:19.75999641418457 max memory_allocated 38143.36181640625 
[2025-03-16 22:24:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 13 loss:2.408221960067749 norm:17.878313064575195 max memory_allocated 38143.36181640625 
[2025-03-16 22:25:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 29-30 epoch 14 loss:2.143688440322876 norm:17.072391510009766 max memory_allocated 38143.36181640625 
[2025-03-16 22:26:10 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 30 to 31 ===
[2025-03-16 22:27:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 0 loss:1.6626836061477661 norm:0.3941594660282135 max memory_allocated 38143.53369140625 
[2025-03-16 22:28:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 1 loss:1.0707480907440186 norm:0.21342913806438446 max memory_allocated 38143.53369140625 
[2025-03-16 22:29:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 2 loss:0.8403425216674805 norm:0.1590091735124588 max memory_allocated 38143.53369140625 
[2025-03-16 22:30:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 3 loss:0.7170351147651672 norm:0.13107822835445404 max memory_allocated 38143.53369140625 
[2025-03-16 22:31:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 4 loss:0.6389126777648926 norm:0.11243771016597748 max memory_allocated 38143.53369140625 
[2025-03-16 22:31:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 5 loss:0.5706868171691895 norm:0.09767265617847443 max memory_allocated 38143.53369140625 
[2025-03-16 22:32:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 6 loss:0.5231682062149048 norm:0.0869549810886383 max memory_allocated 38143.53369140625 
[2025-03-16 22:33:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 7 loss:0.48344939947128296 norm:0.07463856041431427 max memory_allocated 38143.53369140625 
[2025-03-16 22:34:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 8 loss:0.45534563064575195 norm:0.06947711855173111 max memory_allocated 38143.53369140625 
[2025-03-16 22:35:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 9 loss:0.42542731761932373 norm:0.061880942434072495 max memory_allocated 38143.53369140625 
[2025-03-16 22:36:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 10 loss:0.40193259716033936 norm:0.05713752657175064 max memory_allocated 38143.53369140625 
[2025-03-16 22:37:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 11 loss:0.38084080815315247 norm:0.0519091971218586 max memory_allocated 38143.53369140625 
[2025-03-16 22:38:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 12 loss:0.35995274782180786 norm:0.04513343796133995 max memory_allocated 38143.53369140625 
[2025-03-16 22:39:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 13 loss:0.3417431116104126 norm:0.04141264781355858 max memory_allocated 38143.53369140625 
[2025-03-16 22:40:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 30-31 epoch 14 loss:0.3272811770439148 norm:0.038766104727983475 max memory_allocated 38143.53369140625 
[2025-03-16 22:41:01 root] (main_calib_config3_cbq.py 376): INFO 27640.679968118668
[2025-03-16 22:41:06 root] (main_calib_config3_cbq.py 117): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-16 22:42:06 root] (main_calib_config3_cbq.py 161): INFO wikitext2 : nan
[2025-03-16 22:42:06 root] (main_calib_config3_cbq.py 117): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-16 22:43:39 root] (main_calib_config3_cbq.py 161): INFO c4 : nan
[2025-03-16 23:57:09 root] (main_calib_config3_cbq.py 172): INFO {'wikitext2': nan, 'c4': nan, 'results': {'arc_easy': {'acc': 0.25084175084175087, 'acc_stderr': 0.008895183010487395, 'acc_norm': 0.25084175084175087, 'acc_norm_stderr': 0.008895183010487395}, 'arc_challenge': {'acc': 0.22696245733788395, 'acc_stderr': 0.012240491536132861, 'acc_norm': 0.22696245733788395, 'acc_norm_stderr': 0.012240491536132861}, 'boolq': {'acc': 0.3782874617737003, 'acc_stderr': 0.008482001133931005}, 'piqa': {'acc': 0.49510337323177367, 'acc_stderr': 0.011665264730078137, 'acc_norm': 0.49510337323177367, 'acc_norm_stderr': 0.011665264730078137}, 'hellaswag': {'acc': 0.25114519020115517, 'acc_stderr': 0.004327855588466416, 'acc_norm': 0.2515435172276439, 'acc_norm_stderr': 0.0043301342197628444}, 'winogrande': {'acc': 0.579321231254933, 'acc_stderr': 0.013874526372008315}}, 'versions': {'arc_easy': 0, 'arc_challenge': 0, 'boolq': 1, 'piqa': 0, 'hellaswag': 0, 'winogrande': 0}, 'config': {'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
[2025-03-16 23:57:09 root] (main_calib_config3_cbq.py 175): INFO 22.70,25.08,37.83,25.11,49.51,57.93
