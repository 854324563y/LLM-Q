[2025-03-16 02:47:32 root] (main_calib_config3_cbq.py 280): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-divide-adaptive-calibration-cbq/Llama-2-7b-hf-0.45', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.45.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-16 02:48:52 root] (main_calib_config3_cbq.py 347): INFO === start quantization ===
[2025-03-16 02:48:52 root] (main_calib_config3_cbq.py 353): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-16 02:48:52 root] (abq_llm_calib_config3_cbq.py 82): INFO Starting ...
[2025-03-16 02:48:52 root] (abq_llm_calib_config3_cbq.py 89): INFO Loaded quant_map from log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.45.pkl
[2025-03-16 02:48:56 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 0 to 1 ===
[2025-03-16 02:49:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 0 loss:0.20596465468406677 norm:0.5614199042320251 max memory_allocated 38105.85986328125 
[2025-03-16 02:50:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 1 loss:0.111343614757061 norm:0.15788103640079498 max memory_allocated 38105.85986328125 
[2025-03-16 02:51:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 2 loss:0.08895545452833176 norm:0.10526575148105621 max memory_allocated 38105.85986328125 
[2025-03-16 02:52:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 3 loss:0.0857326090335846 norm:0.1125977635383606 max memory_allocated 38105.85986328125 
[2025-03-16 02:53:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 4 loss:0.07961644977331161 norm:0.0859617069363594 max memory_allocated 38105.85986328125 
[2025-03-16 02:54:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 5 loss:0.07661956548690796 norm:0.08152132481336594 max memory_allocated 38105.85986328125 
[2025-03-16 02:55:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 6 loss:0.07453057169914246 norm:0.07197646796703339 max memory_allocated 38105.85986328125 
[2025-03-16 02:56:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 7 loss:0.07361655682325363 norm:0.0789458304643631 max memory_allocated 38105.85986328125 
[2025-03-16 02:57:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 8 loss:0.07193035632371902 norm:0.06652282178401947 max memory_allocated 38105.85986328125 
[2025-03-16 02:58:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 9 loss:0.16967198252677917 norm:0.3830205500125885 max memory_allocated 38105.85986328125 
[2025-03-16 02:59:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 10 loss:0.07731963694095612 norm:0.09691821038722992 max memory_allocated 38105.85986328125 
[2025-03-16 03:00:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 11 loss:0.11188596487045288 norm:0.256086528301239 max memory_allocated 38105.85986328125 
[2025-03-16 03:01:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 12 loss:0.06839840114116669 norm:0.049166738986968994 max memory_allocated 38105.85986328125 
[2025-03-16 03:02:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 13 loss:0.06844590604305267 norm:0.05224347487092018 max memory_allocated 38105.85986328125 
[2025-03-16 03:03:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 14 loss:0.06723809987306595 norm:0.04633920267224312 max memory_allocated 38105.85986328125 
[2025-03-16 03:04:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 15 loss:0.06712181866168976 norm:0.048336442559957504 max memory_allocated 38105.85986328125 
[2025-03-16 03:05:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 16 loss:0.6519009470939636 norm:1.0473277568817139 max memory_allocated 38105.85986328125 
[2025-03-16 03:06:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 17 loss:0.2064402997493744 norm:0.5395591855049133 max memory_allocated 38105.85986328125 
[2025-03-16 03:07:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 18 loss:0.12381533533334732 norm:0.23862536251544952 max memory_allocated 38105.85986328125 
[2025-03-16 03:08:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 0-1 epoch 19 loss:0.11368339508771896 norm:0.277671754360199 max memory_allocated 38105.85986328125 
[2025-03-16 03:08:31 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 1 to 2 ===
[2025-03-16 03:09:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 0 loss:0.2778609097003937 norm:0.5828299522399902 max memory_allocated 38138.54931640625 
[2025-03-16 03:10:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 1 loss:0.12044145166873932 norm:0.057017359882593155 max memory_allocated 38138.54931640625 
[2025-03-16 03:11:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 2 loss:0.09241856634616852 norm:0.042591504752635956 max memory_allocated 38138.54931640625 
[2025-03-16 03:12:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 3 loss:0.07446406036615372 norm:0.034466277807950974 max memory_allocated 38138.54931640625 
[2025-03-16 03:13:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 4 loss:0.06444250792264938 norm:0.026920635253190994 max memory_allocated 38138.54931640625 
[2025-03-16 03:14:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 5 loss:0.05939575284719467 norm:0.024618685245513916 max memory_allocated 38138.54931640625 
[2025-03-16 03:15:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 6 loss:0.05836566537618637 norm:0.03198812156915665 max memory_allocated 38138.54931640625 
[2025-03-16 03:16:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 7 loss:0.053191736340522766 norm:0.025007810443639755 max memory_allocated 38138.54931640625 
[2025-03-16 03:17:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 8 loss:0.04970680549740791 norm:0.024827368557453156 max memory_allocated 38138.54931640625 
[2025-03-16 03:18:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 9 loss:0.04708288237452507 norm:0.020180583000183105 max memory_allocated 38138.54931640625 
[2025-03-16 03:19:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 10 loss:0.04480106756091118 norm:0.01733984984457493 max memory_allocated 38138.54931640625 
[2025-03-16 03:20:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 11 loss:0.043675199151039124 norm:0.018890604376792908 max memory_allocated 38138.54931640625 
[2025-03-16 03:20:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 12 loss:0.04271736368536949 norm:0.020175641402602196 max memory_allocated 38138.54931640625 
[2025-03-16 03:21:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 13 loss:0.040789250284433365 norm:0.017283670604228973 max memory_allocated 38138.54931640625 
[2025-03-16 03:22:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 14 loss:0.04013168439269066 norm:0.018053222447633743 max memory_allocated 38138.54931640625 
[2025-03-16 03:23:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 15 loss:0.038850829005241394 norm:0.017734790220856667 max memory_allocated 38138.54931640625 
[2025-03-16 03:24:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 16 loss:0.03852337226271629 norm:0.017807066440582275 max memory_allocated 38138.54931640625 
[2025-03-16 03:25:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 17 loss:0.038484152406454086 norm:0.019771909341216087 max memory_allocated 38138.54931640625 
[2025-03-16 03:26:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 18 loss:0.0371621809899807 norm:0.01788359321653843 max memory_allocated 38138.54931640625 
[2025-03-16 03:27:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 1-2 epoch 19 loss:0.03562501445412636 norm:0.015502896159887314 max memory_allocated 38138.54931640625 
[2025-03-16 03:28:09 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 2 to 3 ===
[2025-03-16 03:29:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 0 loss:0.047515757381916046 norm:0.04045996814966202 max memory_allocated 38138.54931640625 
[2025-03-16 03:30:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 1 loss:0.022679727524518967 norm:0.012137145735323429 max memory_allocated 38138.54931640625 
[2025-03-16 03:31:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 2 loss:0.01598241552710533 norm:0.006486308295279741 max memory_allocated 38138.54931640625 
[2025-03-16 03:32:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 3 loss:0.012933682650327682 norm:0.005347663536667824 max memory_allocated 38138.54931640625 
[2025-03-16 03:32:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 4 loss:0.010964772664010525 norm:0.004868905991315842 max memory_allocated 38138.54931640625 
[2025-03-16 03:33:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 5 loss:0.009757991880178452 norm:0.004785260651260614 max memory_allocated 38138.54931640625 
[2025-03-16 03:34:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 6 loss:0.008915373124182224 norm:0.0039681196212768555 max memory_allocated 38138.54931640625 
[2025-03-16 03:35:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 7 loss:0.008394709788262844 norm:0.003879430005326867 max memory_allocated 38138.54931640625 
[2025-03-16 03:36:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 8 loss:0.00796353630721569 norm:0.003795524127781391 max memory_allocated 38138.54931640625 
[2025-03-16 03:37:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 9 loss:0.0075906445272266865 norm:0.003191782161593437 max memory_allocated 38138.54931640625 
[2025-03-16 03:38:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 10 loss:0.007295337971299887 norm:0.0028120316565036774 max memory_allocated 38138.54931640625 
[2025-03-16 03:39:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 11 loss:0.007132468745112419 norm:0.002810621866956353 max memory_allocated 38138.54931640625 
[2025-03-16 03:40:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 12 loss:0.007001063320785761 norm:0.00266014551743865 max memory_allocated 38138.54931640625 
[2025-03-16 03:41:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 13 loss:0.006875908933579922 norm:0.0023996741510927677 max memory_allocated 38138.54931640625 
[2025-03-16 03:42:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 14 loss:0.0068612187169492245 norm:0.0033954735845327377 max memory_allocated 38138.54931640625 
[2025-03-16 03:43:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 15 loss:0.006769245490431786 norm:0.0030122657772153616 max memory_allocated 38138.54931640625 
[2025-03-16 03:44:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 16 loss:0.006550287827849388 norm:0.001769375754520297 max memory_allocated 38138.54931640625 
[2025-03-16 03:45:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 17 loss:0.006471069995313883 norm:0.0016683363355696201 max memory_allocated 38138.54931640625 
[2025-03-16 03:46:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 18 loss:0.006394788157194853 norm:0.0018288173014298081 max memory_allocated 38138.54931640625 
[2025-03-16 03:47:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 2-3 epoch 19 loss:0.006375870201736689 norm:0.0019655609503388405 max memory_allocated 38138.54931640625 
[2025-03-16 03:47:46 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 3 to 4 ===
[2025-03-16 03:48:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 0 loss:0.04750184714794159 norm:0.010519472882151604 max memory_allocated 38138.54931640625 
[2025-03-16 03:49:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 1 loss:0.02493593841791153 norm:0.0029628498014062643 max memory_allocated 38138.54931640625 
[2025-03-16 03:50:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 2 loss:0.017562096938490868 norm:0.0016001485055312514 max memory_allocated 38138.54931640625 
[2025-03-16 03:51:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 3 loss:0.0141393868252635 norm:0.0009918175637722015 max memory_allocated 38138.54931640625 
[2025-03-16 03:52:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 4 loss:0.01230696588754654 norm:0.0007313297246582806 max memory_allocated 38138.54931640625 
[2025-03-16 03:53:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 5 loss:0.01082852017134428 norm:0.0005853924667462707 max memory_allocated 38138.54931640625 
[2025-03-16 03:54:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 6 loss:0.009766162373125553 norm:0.0005106725730001926 max memory_allocated 38138.54931640625 
[2025-03-16 03:55:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 7 loss:0.009194331243634224 norm:0.00048604761832393706 max memory_allocated 38138.54931640625 
[2025-03-16 03:56:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 8 loss:0.008858969435095787 norm:0.00048423747648485005 max memory_allocated 38138.54931640625 
[2025-03-16 03:57:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 9 loss:0.008596095256507397 norm:0.0004187343583907932 max memory_allocated 38138.54931640625 
[2025-03-16 03:58:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 10 loss:0.008388937450945377 norm:0.00046706979628652334 max memory_allocated 38138.54931640625 
[2025-03-16 03:59:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 11 loss:0.008099253289401531 norm:0.0004368607187643647 max memory_allocated 38138.54931640625 
[2025-03-16 04:00:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 12 loss:0.007734072860330343 norm:0.0004063275409862399 max memory_allocated 38138.54931640625 
[2025-03-16 04:01:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 13 loss:0.007567690685391426 norm:0.00048272020649164915 max memory_allocated 38138.54931640625 
[2025-03-16 04:02:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 14 loss:0.007475392892956734 norm:0.0004180413670837879 max memory_allocated 38138.54931640625 
[2025-03-16 04:03:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 15 loss:0.007364627905189991 norm:0.00041869597043842077 max memory_allocated 38138.54931640625 
[2025-03-16 04:03:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 16 loss:0.007313891313970089 norm:0.0005208810907788575 max memory_allocated 38138.54931640625 
[2025-03-16 04:04:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 17 loss:0.007249836809933186 norm:0.0004683010920416564 max memory_allocated 38138.54931640625 
[2025-03-16 04:05:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 18 loss:0.007191598881036043 norm:0.00045651179971173406 max memory_allocated 38138.54931640625 
[2025-03-16 04:06:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 3-4 epoch 19 loss:0.007139709312468767 norm:0.0004617331433109939 max memory_allocated 38138.54931640625 
[2025-03-16 04:07:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 4 to 5 ===
[2025-03-16 04:08:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 0 loss:0.018195275217294693 norm:0.0023249699734151363 max memory_allocated 38138.71923828125 
[2025-03-16 04:09:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 1 loss:0.011079313233494759 norm:0.0007412942359223962 max memory_allocated 38138.71923828125 
[2025-03-16 04:10:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 2 loss:0.008865507319569588 norm:0.0004293021629564464 max memory_allocated 38138.71923828125 
[2025-03-16 04:11:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 3 loss:0.00764396833255887 norm:0.0003229847934562713 max memory_allocated 38138.71923828125 
[2025-03-16 04:12:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 4 loss:0.007064794190227985 norm:0.00025929324328899384 max memory_allocated 38138.71923828125 
[2025-03-16 04:13:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 5 loss:0.006725925952196121 norm:0.00020724603382404894 max memory_allocated 38138.71923828125 
[2025-03-16 04:14:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 6 loss:0.006509627681225538 norm:0.00022741235443390906 max memory_allocated 38138.71923828125 
[2025-03-16 04:15:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 7 loss:0.0063013238832354546 norm:0.00018205890955869108 max memory_allocated 38138.71923828125 
[2025-03-16 04:16:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 8 loss:0.006193174980580807 norm:0.00023592723300680518 max memory_allocated 38138.71923828125 
[2025-03-16 04:16:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 9 loss:0.006096689961850643 norm:0.00022847738000564277 max memory_allocated 38138.71923828125 
[2025-03-16 04:17:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 10 loss:0.005942720454186201 norm:0.00019287830218672752 max memory_allocated 38138.71923828125 
[2025-03-16 04:18:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 11 loss:0.005872993730008602 norm:0.00021258344349917024 max memory_allocated 38138.71923828125 
[2025-03-16 04:19:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 12 loss:0.0057449801824986935 norm:0.00013446981029119343 max memory_allocated 38138.71923828125 
[2025-03-16 04:20:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 13 loss:0.005813561845570803 norm:0.00021546630887314677 max memory_allocated 38138.71923828125 
[2025-03-16 04:21:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 14 loss:0.005589642096310854 norm:0.00011859174264827743 max memory_allocated 38138.71923828125 
[2025-03-16 04:22:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 15 loss:0.005517042241990566 norm:0.0001102757451008074 max memory_allocated 38138.71923828125 
[2025-03-16 04:23:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 16 loss:0.005567083600908518 norm:0.0001432864519301802 max memory_allocated 38138.71923828125 
[2025-03-16 04:24:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 17 loss:0.005468318238854408 norm:0.00011055418872274458 max memory_allocated 38138.71923828125 
[2025-03-16 04:25:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 18 loss:0.005358255933970213 norm:8.154958777595311e-05 max memory_allocated 38138.71923828125 
[2025-03-16 04:26:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 4-5 epoch 19 loss:0.005392290651798248 norm:0.00012785816215910017 max memory_allocated 38138.71923828125 
[2025-03-16 04:26:58 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 5 to 6 ===
[2025-03-16 04:27:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 0 loss:0.02125217765569687 norm:0.0028052092529833317 max memory_allocated 38138.89111328125 
[2025-03-16 04:28:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 1 loss:0.014156252145767212 norm:0.0011918613454326987 max memory_allocated 38138.89111328125 
[2025-03-16 04:29:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 2 loss:0.011153260245919228 norm:0.0007269136258400977 max memory_allocated 38138.89111328125 
[2025-03-16 04:30:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 3 loss:0.009510752744972706 norm:0.0005249177920632064 max memory_allocated 38138.89111328125 
[2025-03-16 04:31:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 4 loss:0.00857073999941349 norm:0.00033785856794565916 max memory_allocated 38138.89111328125 
[2025-03-16 04:32:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 5 loss:0.008042863570153713 norm:0.0002656826691236347 max memory_allocated 38138.89111328125 
[2025-03-16 04:33:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 6 loss:0.007631407119333744 norm:0.00021068875503260642 max memory_allocated 38138.89111328125 
[2025-03-16 04:34:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 7 loss:0.0073599983006715775 norm:0.00020246434723958373 max memory_allocated 38138.89111328125 
[2025-03-16 04:35:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 8 loss:0.007153784856200218 norm:0.00017850090807769448 max memory_allocated 38138.89111328125 
[2025-03-16 04:36:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 9 loss:0.006962602958083153 norm:0.00014755057054571807 max memory_allocated 38138.89111328125 
[2025-03-16 04:37:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 10 loss:0.006835015490651131 norm:0.00012817936658393592 max memory_allocated 38138.89111328125 
[2025-03-16 04:38:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 11 loss:0.006736991927027702 norm:0.00011891796020790935 max memory_allocated 38138.89111328125 
[2025-03-16 04:39:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 12 loss:0.00664382241666317 norm:0.00011356428876752034 max memory_allocated 38138.89111328125 
[2025-03-16 04:40:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 13 loss:0.006572048645466566 norm:0.00011069318134104833 max memory_allocated 38138.89111328125 
[2025-03-16 04:41:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 14 loss:0.006514559965580702 norm:0.00010831176768988371 max memory_allocated 38138.89111328125 
[2025-03-16 04:42:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 15 loss:0.006456587463617325 norm:0.0001042774019879289 max memory_allocated 38138.89111328125 
[2025-03-16 04:43:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 16 loss:0.006412136368453503 norm:0.00010304687748430297 max memory_allocated 38138.89111328125 
[2025-03-16 04:44:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 17 loss:0.006380743347108364 norm:0.00010172036127187312 max memory_allocated 38138.89111328125 
[2025-03-16 04:45:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 18 loss:0.006366296671330929 norm:0.0001014630397548899 max memory_allocated 38138.89111328125 
[2025-03-16 04:46:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 5-6 epoch 19 loss:0.0063320789486169815 norm:0.00010104730608873069 max memory_allocated 38138.89111328125 
[2025-03-16 04:46:34 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 6 to 7 ===
[2025-03-16 04:47:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 0 loss:0.018251795321702957 norm:0.0015347023727372289 max memory_allocated 38139.06298828125 
[2025-03-16 04:48:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 1 loss:0.012314816936850548 norm:0.0007413101848214865 max memory_allocated 38139.06298828125 
[2025-03-16 04:49:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 2 loss:0.009769507683813572 norm:0.00037648959551006556 max memory_allocated 38139.06298828125 
[2025-03-16 04:50:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 3 loss:0.008355570957064629 norm:0.00024871653295122087 max memory_allocated 38139.06298828125 
[2025-03-16 04:51:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 4 loss:0.0077384719625115395 norm:0.0001840771728893742 max memory_allocated 38139.06298828125 
[2025-03-16 04:52:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 5 loss:0.007358807139098644 norm:0.0001536301278974861 max memory_allocated 38139.06298828125 
[2025-03-16 04:53:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 6 loss:0.007066887337714434 norm:0.00013331745867617428 max memory_allocated 38139.06298828125 
[2025-03-16 04:54:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 7 loss:0.006871661636978388 norm:0.00011463452392490581 max memory_allocated 38139.06298828125 
[2025-03-16 04:55:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 8 loss:0.006684411317110062 norm:0.00010725899483077228 max memory_allocated 38139.06298828125 
[2025-03-16 04:56:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 9 loss:0.006563905160874128 norm:0.00010126264533028007 max memory_allocated 38139.06298828125 
[2025-03-16 04:57:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 10 loss:0.006453756708651781 norm:9.436601976631209e-05 max memory_allocated 38139.06298828125 
[2025-03-16 04:58:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 11 loss:0.006383080035448074 norm:8.967408939497545e-05 max memory_allocated 38139.06298828125 
[2025-03-16 04:59:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 12 loss:0.00632669311016798 norm:8.570466889068484e-05 max memory_allocated 38139.06298828125 
[2025-03-16 04:59:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 13 loss:0.006268937140703201 norm:8.395830082008615e-05 max memory_allocated 38139.06298828125 
[2025-03-16 05:00:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 14 loss:0.006220646668225527 norm:8.267035445896909e-05 max memory_allocated 38139.06298828125 
[2025-03-16 05:01:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 15 loss:0.006174818612635136 norm:7.942556840134785e-05 max memory_allocated 38139.06298828125 
[2025-03-16 05:02:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 16 loss:0.0061187599785625935 norm:7.896679016994312e-05 max memory_allocated 38139.06298828125 
[2025-03-16 05:03:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 17 loss:0.006091850809752941 norm:7.690167694818228e-05 max memory_allocated 38139.06298828125 
[2025-03-16 05:04:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 18 loss:0.006063462700694799 norm:7.774480764055625e-05 max memory_allocated 38139.06298828125 
[2025-03-16 05:05:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 6-7 epoch 19 loss:0.006041396874934435 norm:7.653229113202542e-05 max memory_allocated 38139.06298828125 
[2025-03-16 05:06:10 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 7 to 8 ===
[2025-03-16 05:07:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 0 loss:0.014348949305713177 norm:0.0007167421281337738 max memory_allocated 38139.23486328125 
[2025-03-16 05:08:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 1 loss:0.009821029379963875 norm:0.0002696904994081706 max memory_allocated 38139.23486328125 
[2025-03-16 05:09:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 2 loss:0.007939863950014114 norm:0.0001572101900819689 max memory_allocated 38139.23486328125 
[2025-03-16 05:10:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 3 loss:0.006869158241897821 norm:0.00011170720244990662 max memory_allocated 38139.23486328125 
[2025-03-16 05:11:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 4 loss:0.006395923905074596 norm:9.540184692014009e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:11:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 5 loss:0.006122313439846039 norm:8.720739424461499e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:12:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 6 loss:0.005921667441725731 norm:8.17902764538303e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:13:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 7 loss:0.005762369837611914 norm:7.784987974446267e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:14:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 8 loss:0.0056376694701612 norm:7.484524394385517e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:15:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 9 loss:0.005534772761166096 norm:7.195157377282158e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:16:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 10 loss:0.005457165651023388 norm:6.926129572093487e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:17:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 11 loss:0.005408069118857384 norm:6.955383287277073e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:18:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 12 loss:0.005359689239412546 norm:6.911221134942025e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:19:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 13 loss:0.005313884932547808 norm:7.191686745500192e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:20:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 14 loss:0.005276675336062908 norm:6.982866761973128e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:21:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 15 loss:0.005237940698862076 norm:6.8624438426923e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:22:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 16 loss:0.0052116005681455135 norm:6.569041579496115e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:23:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 17 loss:0.005175322759896517 norm:6.818734982516617e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:24:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 18 loss:0.005174115765839815 norm:6.744983693351969e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:25:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 7-8 epoch 19 loss:0.005133036058396101 norm:6.593733269255608e-05 max memory_allocated 38139.23486328125 
[2025-03-16 05:25:46 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 8 to 9 ===
[2025-03-16 05:26:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 0 loss:0.016726402565836906 norm:0.0013357378775253892 max memory_allocated 38139.40673828125 
[2025-03-16 05:27:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 1 loss:0.011533672921359539 norm:0.0006043343455530703 max memory_allocated 38139.40673828125 
[2025-03-16 05:28:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 2 loss:0.009223763830959797 norm:0.00033876579254865646 max memory_allocated 38139.40673828125 
[2025-03-16 05:29:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 3 loss:0.007871882058680058 norm:0.00021429643675219268 max memory_allocated 38139.40673828125 
[2025-03-16 05:30:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 4 loss:0.007243689149618149 norm:0.00016337374108843505 max memory_allocated 38139.40673828125 
[2025-03-16 05:31:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 5 loss:0.0068504600785672665 norm:0.0001317302230745554 max memory_allocated 38139.40673828125 
[2025-03-16 05:32:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 6 loss:0.006576616782695055 norm:0.00011407816054997966 max memory_allocated 38139.40673828125 
[2025-03-16 05:33:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 7 loss:0.006386629305779934 norm:0.00010091454169014469 max memory_allocated 38139.40673828125 
[2025-03-16 05:34:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 8 loss:0.006230547558516264 norm:9.047974890563637e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:35:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 9 loss:0.006124612409621477 norm:8.514108048984781e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:36:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 10 loss:0.006044489797204733 norm:8.202386379707605e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:37:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 11 loss:0.005964728072285652 norm:7.767667557345703e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:38:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 12 loss:0.00589915132150054 norm:7.362951873801649e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:39:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 13 loss:0.005864833015948534 norm:7.346277561737224e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:40:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 14 loss:0.005829296540468931 norm:7.041845674393699e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:41:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 15 loss:0.0057955714873969555 norm:6.983587081776932e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:42:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 16 loss:0.005757768638432026 norm:6.819574628025293e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:42:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 17 loss:0.005741555243730545 norm:6.698654760839418e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:43:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 18 loss:0.005732446908950806 norm:6.62123056827113e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:44:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 8-9 epoch 19 loss:0.005726968869566917 norm:6.718229997204617e-05 max memory_allocated 38139.40673828125 
[2025-03-16 05:45:22 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 9 to 10 ===
[2025-03-16 05:46:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 0 loss:0.018440334126353264 norm:0.0008483604760840535 max memory_allocated 38139.57861328125 
[2025-03-16 05:47:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 1 loss:0.012794602662324905 norm:0.0003984239010605961 max memory_allocated 38139.57861328125 
[2025-03-16 05:48:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 2 loss:0.010378515347838402 norm:0.00023669941583648324 max memory_allocated 38139.57861328125 
[2025-03-16 05:49:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 3 loss:0.008990798145532608 norm:0.00016595139459241182 max memory_allocated 38139.57861328125 
[2025-03-16 05:50:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 4 loss:0.008317079395055771 norm:0.00012969967792741954 max memory_allocated 38139.57861328125 
[2025-03-16 05:51:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 5 loss:0.007913576439023018 norm:0.0001101701709558256 max memory_allocated 38139.57861328125 
[2025-03-16 05:52:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 6 loss:0.007660025730729103 norm:9.808292816160247e-05 max memory_allocated 38139.57861328125 
[2025-03-16 05:53:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 7 loss:0.007474532816559076 norm:9.209208656102419e-05 max memory_allocated 38139.57861328125 
[2025-03-16 05:54:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 8 loss:0.007354822475463152 norm:8.456711657345295e-05 max memory_allocated 38139.57861328125 
[2025-03-16 05:54:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 9 loss:0.0072339000180363655 norm:8.013626211322844e-05 max memory_allocated 38139.57861328125 
[2025-03-16 05:55:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 10 loss:0.007153153885155916 norm:7.917307812022045e-05 max memory_allocated 38139.57861328125 
[2025-03-16 05:56:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 11 loss:0.007092793006449938 norm:7.743282912997529e-05 max memory_allocated 38139.57861328125 
[2025-03-16 05:57:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 12 loss:0.007027253974229097 norm:7.386133074760437e-05 max memory_allocated 38139.57861328125 
[2025-03-16 05:58:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 13 loss:0.006978542543947697 norm:7.418103632517159e-05 max memory_allocated 38139.57861328125 
[2025-03-16 05:59:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 14 loss:0.006942613050341606 norm:7.507373811677098e-05 max memory_allocated 38139.57861328125 
[2025-03-16 06:00:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 15 loss:0.006904863752424717 norm:7.428756362060085e-05 max memory_allocated 38139.57861328125 
[2025-03-16 06:01:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 16 loss:0.00688267732039094 norm:7.335939153563231e-05 max memory_allocated 38139.57861328125 
[2025-03-16 06:02:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 17 loss:0.006849109195172787 norm:7.26783910067752e-05 max memory_allocated 38139.57861328125 
[2025-03-16 06:03:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 18 loss:0.00681921374052763 norm:7.247400935739279e-05 max memory_allocated 38139.57861328125 
[2025-03-16 06:04:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 9-10 epoch 19 loss:0.006801209412515163 norm:7.344572804868221e-05 max memory_allocated 38139.57861328125 
[2025-03-16 06:04:58 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 10 to 11 ===
[2025-03-16 06:05:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 0 loss:0.024206141009926796 norm:0.002869372721761465 max memory_allocated 38139.75048828125 
[2025-03-16 06:06:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 1 loss:0.016236525028944016 norm:0.0012899399735033512 max memory_allocated 38139.75048828125 
[2025-03-16 06:07:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 2 loss:0.012957490049302578 norm:0.000694339512847364 max memory_allocated 38139.75048828125 
[2025-03-16 06:08:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 3 loss:0.01110403798520565 norm:0.0004447732644621283 max memory_allocated 38139.75048828125 
[2025-03-16 06:09:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 4 loss:0.010157285258173943 norm:0.000314957374939695 max memory_allocated 38139.75048828125 
[2025-03-16 06:10:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 5 loss:0.009586397558450699 norm:0.00025197077775374055 max memory_allocated 38139.75048828125 
[2025-03-16 06:11:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 6 loss:0.009212180972099304 norm:0.00020095669606234878 max memory_allocated 38139.75048828125 
[2025-03-16 06:12:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 7 loss:0.008916580118238926 norm:0.00016629535821266472 max memory_allocated 38139.75048828125 
[2025-03-16 06:13:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 8 loss:0.008723965846002102 norm:0.00014666173956356943 max memory_allocated 38139.75048828125 
[2025-03-16 06:14:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 9 loss:0.008589355275034904 norm:0.0001337772118858993 max memory_allocated 38139.75048828125 
[2025-03-16 06:15:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 10 loss:0.008479388430714607 norm:0.00012329228047747165 max memory_allocated 38139.75048828125 
[2025-03-16 06:16:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 11 loss:0.008392782881855965 norm:0.00011838445061584935 max memory_allocated 38139.75048828125 
[2025-03-16 06:17:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 12 loss:0.008314795792102814 norm:0.00011668878141790628 max memory_allocated 38139.75048828125 
[2025-03-16 06:18:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 13 loss:0.008253250271081924 norm:0.00011075373186031356 max memory_allocated 38139.75048828125 
[2025-03-16 06:19:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 14 loss:0.00821632705628872 norm:0.00010807605576701462 max memory_allocated 38139.75048828125 
[2025-03-16 06:20:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 15 loss:0.008163005113601685 norm:0.0001036227768054232 max memory_allocated 38139.75048828125 
[2025-03-16 06:21:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 16 loss:0.008124900981783867 norm:9.977623994927853e-05 max memory_allocated 38139.75048828125 
[2025-03-16 06:22:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 17 loss:0.008085175417363644 norm:9.746394789544865e-05 max memory_allocated 38139.75048828125 
[2025-03-16 06:23:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 18 loss:0.00804443471133709 norm:9.579927427694201e-05 max memory_allocated 38139.75048828125 
[2025-03-16 06:24:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 10-11 epoch 19 loss:0.00803682766854763 norm:9.404010779689997e-05 max memory_allocated 38139.75048828125 
[2025-03-16 06:24:34 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 11 to 12 ===
[2025-03-16 06:25:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 0 loss:0.020034248009324074 norm:0.006344896275550127 max memory_allocated 38139.92236328125 
[2025-03-16 06:26:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 1 loss:0.014119764789938927 norm:0.0010046105599030852 max memory_allocated 38139.92236328125 
[2025-03-16 06:27:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 2 loss:0.011692697182297707 norm:0.0005575725808739662 max memory_allocated 38139.92236328125 
[2025-03-16 06:28:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 3 loss:0.010222102515399456 norm:0.00036509070196188986 max memory_allocated 38139.92236328125 
[2025-03-16 06:29:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 4 loss:0.009498707950115204 norm:0.0002711863780859858 max memory_allocated 38139.92236328125 
[2025-03-16 06:30:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 5 loss:0.009036339819431305 norm:0.0002175172121496871 max memory_allocated 38139.92236328125 
[2025-03-16 06:31:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 6 loss:0.00873463787138462 norm:0.0001836353330872953 max memory_allocated 38139.92236328125 
[2025-03-16 06:32:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 7 loss:0.008515468798577785 norm:0.0001642278948565945 max memory_allocated 38139.92236328125 
[2025-03-16 06:33:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 8 loss:0.008370920084416866 norm:0.00014439222286455333 max memory_allocated 38139.92236328125 
[2025-03-16 06:34:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 9 loss:0.008254054933786392 norm:0.00013026740634813905 max memory_allocated 38139.92236328125 
[2025-03-16 06:35:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 10 loss:0.008153881877660751 norm:0.00012093261466361582 max memory_allocated 38139.92236328125 
[2025-03-16 06:36:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 11 loss:0.008078651502728462 norm:0.00011360770440660417 max memory_allocated 38139.92236328125 
[2025-03-16 06:37:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 12 loss:0.008015464060008526 norm:0.00010785578342620283 max memory_allocated 38139.92236328125 
[2025-03-16 06:37:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 13 loss:0.007971551269292831 norm:0.00010307766206096858 max memory_allocated 38139.92236328125 
[2025-03-16 06:38:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 14 loss:0.007937777787446976 norm:9.944311750587076e-05 max memory_allocated 38139.92236328125 
[2025-03-16 06:39:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 15 loss:0.007891717366874218 norm:9.510853851679713e-05 max memory_allocated 38139.92236328125 
[2025-03-16 06:40:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 16 loss:0.00786171481013298 norm:9.438245615456253e-05 max memory_allocated 38139.92236328125 
[2025-03-16 06:41:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 17 loss:0.007821954786777496 norm:9.075763955479488e-05 max memory_allocated 38139.92236328125 
[2025-03-16 06:42:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 18 loss:0.007794042117893696 norm:8.974442607723176e-05 max memory_allocated 38139.92236328125 
[2025-03-16 06:43:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 11-12 epoch 19 loss:0.007766100112348795 norm:8.798576891422272e-05 max memory_allocated 38139.92236328125 
[2025-03-16 06:44:10 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 12 to 13 ===
[2025-03-16 06:45:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 0 loss:0.017415884882211685 norm:0.0010051316348835826 max memory_allocated 38140.09423828125 
[2025-03-16 06:46:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 1 loss:0.012374918907880783 norm:0.0005115692620165646 max memory_allocated 38140.09423828125 
[2025-03-16 06:47:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 2 loss:0.010068763978779316 norm:0.0002945431333500892 max memory_allocated 38140.09423828125 
[2025-03-16 06:48:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 3 loss:0.008749906904995441 norm:0.0001697693660389632 max memory_allocated 38140.09423828125 
[2025-03-16 06:49:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 4 loss:0.008175776340067387 norm:0.0001296147092944011 max memory_allocated 38140.09423828125 
[2025-03-16 06:49:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 5 loss:0.00775124691426754 norm:0.00010963880777126178 max memory_allocated 38140.09423828125 
[2025-03-16 06:50:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 6 loss:0.007507458329200745 norm:9.719973604660481e-05 max memory_allocated 38140.09423828125 
[2025-03-16 06:51:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 7 loss:0.00733399111777544 norm:9.145452349912375e-05 max memory_allocated 38140.09423828125 
[2025-03-16 06:52:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 8 loss:0.007215412333607674 norm:8.63816385390237e-05 max memory_allocated 38140.09423828125 
[2025-03-16 06:53:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 9 loss:0.00711377989500761 norm:8.129383786581457e-05 max memory_allocated 38140.09423828125 
[2025-03-16 06:54:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 10 loss:0.007017196621745825 norm:7.789913797751069e-05 max memory_allocated 38140.09423828125 
[2025-03-16 06:55:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 11 loss:0.00696580670773983 norm:7.436775194946676e-05 max memory_allocated 38140.09423828125 
[2025-03-16 06:56:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 12 loss:0.006919526495039463 norm:7.066559919621795e-05 max memory_allocated 38140.09423828125 
[2025-03-16 06:57:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 13 loss:0.00686267577111721 norm:6.930311064934358e-05 max memory_allocated 38140.09423828125 
[2025-03-16 06:58:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 14 loss:0.006823631934821606 norm:6.960044265724719e-05 max memory_allocated 38140.09423828125 
[2025-03-16 06:59:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 15 loss:0.006806094199419022 norm:6.839323759777471e-05 max memory_allocated 38140.09423828125 
[2025-03-16 07:00:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 16 loss:0.0068013048730790615 norm:6.668642163276672e-05 max memory_allocated 38140.09423828125 
[2025-03-16 07:01:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 17 loss:0.006778990384191275 norm:6.606701936107129e-05 max memory_allocated 38140.09423828125 
[2025-03-16 07:02:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 18 loss:0.006760064512491226 norm:6.618145562242717e-05 max memory_allocated 38140.09423828125 
[2025-03-16 07:03:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 12-13 epoch 19 loss:0.00673520565032959 norm:6.776988448109478e-05 max memory_allocated 38140.09423828125 
[2025-03-16 07:03:48 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 13 to 14 ===
[2025-03-16 07:04:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 0 loss:0.022193504497408867 norm:0.0010462618665769696 max memory_allocated 38140.26611328125 
[2025-03-16 07:05:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 1 loss:0.016315700486302376 norm:0.000512761645950377 max memory_allocated 38140.26611328125 
[2025-03-16 07:06:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 2 loss:0.01351003535091877 norm:0.00032737705623731017 max memory_allocated 38140.26611328125 
[2025-03-16 07:07:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 3 loss:0.011998546309769154 norm:0.00023976367083378136 max memory_allocated 38140.26611328125 
[2025-03-16 07:08:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 4 loss:0.011295080184936523 norm:0.00020246724307071418 max memory_allocated 38140.26611328125 
[2025-03-16 07:09:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 5 loss:0.010675283148884773 norm:0.0001635460212128237 max memory_allocated 38140.26611328125 
[2025-03-16 07:10:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 6 loss:0.010454529896378517 norm:0.00018757162615656853 max memory_allocated 38140.26611328125 
[2025-03-16 07:11:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 7 loss:0.010117683559656143 norm:0.00012829290062654763 max memory_allocated 38140.26611328125 
[2025-03-16 07:12:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 8 loss:0.009946479462087154 norm:0.00016707702889107168 max memory_allocated 38140.26611328125 
[2025-03-16 07:13:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 9 loss:0.009823479689657688 norm:0.00017274191486649215 max memory_allocated 38140.26611328125 
[2025-03-16 07:14:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 10 loss:0.009790755808353424 norm:0.00013834537821821868 max memory_allocated 38140.26611328125 
[2025-03-16 07:15:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 11 loss:0.009593299590051174 norm:0.00014044030103832483 max memory_allocated 38140.26611328125 
[2025-03-16 07:16:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 12 loss:0.009599147364497185 norm:0.00012189990957267582 max memory_allocated 38140.26611328125 
[2025-03-16 07:17:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 13 loss:0.009400738403201103 norm:0.0001077130000339821 max memory_allocated 38140.26611328125 
[2025-03-16 07:18:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 14 loss:0.009508579969406128 norm:0.00011171474034199491 max memory_allocated 38140.26611328125 
[2025-03-16 07:19:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 15 loss:0.009576903656125069 norm:0.0001951864396687597 max memory_allocated 38140.26611328125 
[2025-03-16 07:20:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 16 loss:0.00939877424389124 norm:0.0001091513768187724 max memory_allocated 38140.26611328125 
[2025-03-16 07:21:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 17 loss:0.009529069066047668 norm:0.00016093581507448107 max memory_allocated 38140.26611328125 
[2025-03-16 07:21:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 18 loss:0.00930552277714014 norm:0.00010994084732374176 max memory_allocated 38140.26611328125 
[2025-03-16 07:22:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 13-14 epoch 19 loss:0.00922490656375885 norm:9.910913649946451e-05 max memory_allocated 38140.26611328125 
[2025-03-16 07:23:24 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 14 to 15 ===
[2025-03-16 07:24:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 0 loss:0.022497087717056274 norm:0.0009955717250704765 max memory_allocated 38140.43798828125 
[2025-03-16 07:25:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 1 loss:0.0161434356123209 norm:0.0004235617525409907 max memory_allocated 38140.43798828125 
[2025-03-16 07:26:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 2 loss:0.012999190017580986 norm:0.00025846200878731906 max memory_allocated 38140.43798828125 
[2025-03-16 07:27:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 3 loss:0.011534896679222584 norm:0.00018435574020259082 max memory_allocated 38140.43798828125 
[2025-03-16 07:28:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 4 loss:0.010796735994517803 norm:0.00015013078518677503 max memory_allocated 38140.43798828125 
[2025-03-16 07:29:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 5 loss:0.010318550281226635 norm:0.00012915449042338878 max memory_allocated 38140.43798828125 
[2025-03-16 07:30:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 6 loss:0.009998876601457596 norm:0.00011296799493720755 max memory_allocated 38140.43798828125 
[2025-03-16 07:31:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 7 loss:0.009762110188603401 norm:0.00010345432383473963 max memory_allocated 38140.43798828125 
[2025-03-16 07:32:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 8 loss:0.00959425326436758 norm:9.757737279869616e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:32:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 9 loss:0.009482833556830883 norm:9.482251334702596e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:33:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 10 loss:0.009400554932653904 norm:9.086444333661348e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:34:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 11 loss:0.009343347512185574 norm:8.983904990600422e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:35:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 12 loss:0.009280988946557045 norm:8.79201470525004e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:36:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 13 loss:0.009228652343153954 norm:8.600018918514252e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:37:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 14 loss:0.009183656424283981 norm:8.616727427579463e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:38:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 15 loss:0.009135366417467594 norm:8.472446643281728e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:39:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 16 loss:0.009091177023947239 norm:8.361562504433095e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:40:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 17 loss:0.00905610155314207 norm:8.14945888123475e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:41:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 18 loss:0.009034087881445885 norm:8.00965863163583e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:42:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 14-15 epoch 19 loss:0.009014365263283253 norm:8.068470924627036e-05 max memory_allocated 38140.43798828125 
[2025-03-16 07:43:00 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 15 to 16 ===
[2025-03-16 07:44:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 0 loss:0.024524366483092308 norm:0.0014745945809409022 max memory_allocated 38140.60986328125 
[2025-03-16 07:44:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 1 loss:0.01791696809232235 norm:0.00066426582634449 max memory_allocated 38140.60986328125 
[2025-03-16 07:45:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 2 loss:0.0143777159973979 norm:0.00039115577237680554 max memory_allocated 38140.60986328125 
[2025-03-16 07:46:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 3 loss:0.012757624499499798 norm:0.0002786155673675239 max memory_allocated 38140.60986328125 
[2025-03-16 07:47:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 4 loss:0.012053241953253746 norm:0.00022356046247296035 max memory_allocated 38140.60986328125 
[2025-03-16 07:48:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 5 loss:0.011553999967873096 norm:0.00019522832008078694 max memory_allocated 38140.60986328125 
[2025-03-16 07:49:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 6 loss:0.01121525838971138 norm:0.00017858692444860935 max memory_allocated 38140.60986328125 
[2025-03-16 07:50:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 7 loss:0.010981050319969654 norm:0.00015033598174341023 max memory_allocated 38140.60986328125 
[2025-03-16 07:51:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 8 loss:0.01085320208221674 norm:0.0001853937574196607 max memory_allocated 38140.60986328125 
[2025-03-16 07:52:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 9 loss:0.010482776910066605 norm:0.00012515003618318588 max memory_allocated 38140.60986328125 
[2025-03-16 07:53:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 10 loss:0.010537564754486084 norm:0.00012121616600779817 max memory_allocated 38140.60986328125 
[2025-03-16 07:54:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 11 loss:0.01050717942416668 norm:0.00017303797358181328 max memory_allocated 38140.60986328125 
[2025-03-16 07:55:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 12 loss:0.010232936590909958 norm:0.0001146489885286428 max memory_allocated 38140.60986328125 
[2025-03-16 07:56:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 13 loss:0.01030820794403553 norm:0.00010578299406915903 max memory_allocated 38140.60986328125 
[2025-03-16 07:57:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 14 loss:0.01014527678489685 norm:0.00014870062295813113 max memory_allocated 38140.60986328125 
[2025-03-16 07:58:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 15 loss:0.010060306638479233 norm:0.00010579240915831178 max memory_allocated 38140.60986328125 
[2025-03-16 07:59:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 16 loss:0.01003856398165226 norm:0.00013177235086914152 max memory_allocated 38140.60986328125 
[2025-03-16 08:00:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 17 loss:0.010141911916434765 norm:9.573044371791184e-05 max memory_allocated 38140.60986328125 
[2025-03-16 08:01:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 18 loss:0.009981947019696236 norm:0.00014197744894772768 max memory_allocated 38140.60986328125 
[2025-03-16 08:02:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 15-16 epoch 19 loss:0.009984558448195457 norm:9.707230492495e-05 max memory_allocated 38140.60986328125 
[2025-03-16 08:02:35 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 16 to 17 ===
[2025-03-16 08:03:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 0 loss:0.021769218146800995 norm:0.0008289455436170101 max memory_allocated 38140.78173828125 
[2025-03-16 08:04:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 1 loss:0.016544252634048462 norm:0.00037013384280726314 max memory_allocated 38140.78173828125 
[2025-03-16 08:05:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 2 loss:0.01370781660079956 norm:0.00022106892720330507 max memory_allocated 38140.78173828125 
[2025-03-16 08:06:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 3 loss:0.012564074248075485 norm:0.00016053880972322077 max memory_allocated 38140.78173828125 
[2025-03-16 08:07:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 4 loss:0.011979862116277218 norm:0.00012970680836588144 max memory_allocated 38140.78173828125 
[2025-03-16 08:08:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 5 loss:0.011548124253749847 norm:0.00011053659545723349 max memory_allocated 38140.78173828125 
[2025-03-16 08:09:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 6 loss:0.011268017813563347 norm:0.0001001575292320922 max memory_allocated 38140.78173828125 
[2025-03-16 08:10:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 7 loss:0.011068060994148254 norm:9.734519699122757e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:11:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 8 loss:0.010903391987085342 norm:9.174195292871445e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:12:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 9 loss:0.010756424628198147 norm:8.697205339558423e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:13:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 10 loss:0.010666186921298504 norm:8.533222717233002e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:14:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 11 loss:0.010584114119410515 norm:8.128830086207017e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:15:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 12 loss:0.010540968738496304 norm:8.288297976832837e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:15:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 13 loss:0.010476423427462578 norm:7.867191743571311e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:16:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 14 loss:0.010441500693559647 norm:7.700480637140572e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:17:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 15 loss:0.010408670641481876 norm:7.60643306421116e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:18:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 16 loss:0.01037500984966755 norm:7.618937524966896e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:19:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 17 loss:0.01034208107739687 norm:7.445871597155929e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:20:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 18 loss:0.010313207283616066 norm:7.507412374252453e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:21:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 16-17 epoch 19 loss:0.010275689885020256 norm:7.641905540367588e-05 max memory_allocated 38140.78173828125 
[2025-03-16 08:22:13 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 17 to 18 ===
[2025-03-16 08:23:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 0 loss:0.023269619792699814 norm:0.0007725800387561321 max memory_allocated 38140.95361328125 
[2025-03-16 08:24:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 1 loss:0.01769580878317356 norm:0.00035734829725697637 max memory_allocated 38140.95361328125 
[2025-03-16 08:25:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 2 loss:0.014301791787147522 norm:0.00021226683747954667 max memory_allocated 38140.95361328125 
[2025-03-16 08:26:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 3 loss:0.013047413900494576 norm:0.0001528580323792994 max memory_allocated 38140.95361328125 
[2025-03-16 08:27:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 4 loss:0.012435825541615486 norm:0.00012680358486250043 max memory_allocated 38140.95361328125 
[2025-03-16 08:28:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 5 loss:0.011988935992121696 norm:0.00010862194176297635 max memory_allocated 38140.95361328125 
[2025-03-16 08:28:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 6 loss:0.011662190780043602 norm:0.0001003608776954934 max memory_allocated 38140.95361328125 
[2025-03-16 08:29:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 7 loss:0.01145286113023758 norm:9.524112829240039e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:30:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 8 loss:0.011280642822384834 norm:8.876690844772384e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:31:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 9 loss:0.01118750125169754 norm:8.561545837437734e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:32:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 10 loss:0.011115721426904202 norm:8.258540037786588e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:33:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 11 loss:0.011061464436352253 norm:8.138752309605479e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:34:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 12 loss:0.01102358102798462 norm:8.149222412612289e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:35:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 13 loss:0.010983693413436413 norm:8.045610593399033e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:36:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 14 loss:0.01093357428908348 norm:7.779902807669714e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:37:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 15 loss:0.010893951170146465 norm:7.772623212076724e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:38:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 16 loss:0.010850532911717892 norm:7.6917844126001e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:39:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 17 loss:0.010825366713106632 norm:7.821500184945762e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:40:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 18 loss:0.010810643434524536 norm:7.843539060559124e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:41:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 17-18 epoch 19 loss:0.010769027285277843 norm:7.695896783843637e-05 max memory_allocated 38140.95361328125 
[2025-03-16 08:41:51 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 18 to 19 ===
[2025-03-16 08:42:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 0 loss:0.023988984525203705 norm:0.000999067910015583 max memory_allocated 38141.12548828125 
[2025-03-16 08:43:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 1 loss:0.018192986026406288 norm:0.00048210908425971866 max memory_allocated 38141.12548828125 
[2025-03-16 08:44:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 2 loss:0.014719126746058464 norm:0.00027853011852130294 max memory_allocated 38141.12548828125 
[2025-03-16 08:45:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 3 loss:0.01350387092679739 norm:0.00020005585975013673 max memory_allocated 38141.12548828125 
[2025-03-16 08:46:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 4 loss:0.012934091500937939 norm:0.00016726847388781607 max memory_allocated 38141.12548828125 
[2025-03-16 08:47:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 5 loss:0.012455752119421959 norm:0.00013976686750538647 max memory_allocated 38141.12548828125 
[2025-03-16 08:48:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 6 loss:0.012132869102060795 norm:0.00012178241740912199 max memory_allocated 38141.12548828125 
[2025-03-16 08:49:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 7 loss:0.011901525780558586 norm:0.00011248225928284228 max memory_allocated 38141.12548828125 
[2025-03-16 08:50:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 8 loss:0.011735543608665466 norm:0.00010892085265368223 max memory_allocated 38141.12548828125 
[2025-03-16 08:51:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 9 loss:0.011670615524053574 norm:0.00010417055455036461 max memory_allocated 38141.12548828125 
[2025-03-16 08:52:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 10 loss:0.011587121523916721 norm:0.00010427604138385504 max memory_allocated 38141.12548828125 
[2025-03-16 08:53:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 11 loss:0.011564732529222965 norm:0.00010034106526290998 max memory_allocated 38141.12548828125 
[2025-03-16 08:54:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 12 loss:0.01149862352758646 norm:0.00010300979920430109 max memory_allocated 38141.12548828125 
[2025-03-16 08:55:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 13 loss:0.01148383691906929 norm:9.913189569488168e-05 max memory_allocated 38141.12548828125 
[2025-03-16 08:56:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 14 loss:0.011461826041340828 norm:9.727138967718929e-05 max memory_allocated 38141.12548828125 
[2025-03-16 08:57:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 15 loss:0.011386406607925892 norm:9.804998990148306e-05 max memory_allocated 38141.12548828125 
[2025-03-16 08:58:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 16 loss:0.011402172967791557 norm:9.650876745581627e-05 max memory_allocated 38141.12548828125 
[2025-03-16 08:59:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 17 loss:0.011337894946336746 norm:9.882834274321795e-05 max memory_allocated 38141.12548828125 
[2025-03-16 08:59:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 18 loss:0.011314340867102146 norm:9.383989527123049e-05 max memory_allocated 38141.12548828125 
[2025-03-16 09:00:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 18-19 epoch 19 loss:0.011288532987236977 norm:9.593824506737292e-05 max memory_allocated 38141.12548828125 
[2025-03-16 09:01:26 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 19 to 20 ===
[2025-03-16 09:02:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 0 loss:0.02739879861474037 norm:0.0012521621538326144 max memory_allocated 38141.29736328125 
[2025-03-16 09:03:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 1 loss:0.020241817459464073 norm:0.0005266285734251142 max memory_allocated 38141.29736328125 
[2025-03-16 09:04:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 2 loss:0.016326667740941048 norm:0.0003120902110822499 max memory_allocated 38141.29736328125 
[2025-03-16 09:05:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 3 loss:0.01484664622694254 norm:0.00022388785146176815 max memory_allocated 38141.29736328125 
[2025-03-16 09:06:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 4 loss:0.01409220788627863 norm:0.00019414644339121878 max memory_allocated 38141.29736328125 
[2025-03-16 09:07:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 5 loss:0.013521515764296055 norm:0.00016766930639278144 max memory_allocated 38141.29736328125 
[2025-03-16 09:08:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 6 loss:0.013117853552103043 norm:0.00014887088036630303 max memory_allocated 38141.29736328125 
[2025-03-16 09:09:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 7 loss:0.012792572379112244 norm:0.00013745737669523805 max memory_allocated 38141.29736328125 
[2025-03-16 09:10:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 8 loss:0.012605559080839157 norm:0.00013055605813860893 max memory_allocated 38141.29736328125 
[2025-03-16 09:11:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 9 loss:0.012506869621574879 norm:0.00012585186050273478 max memory_allocated 38141.29736328125 
[2025-03-16 09:11:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 10 loss:0.012365534901618958 norm:0.00011637793795671314 max memory_allocated 38141.29736328125 
[2025-03-16 09:12:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 11 loss:0.012276737950742245 norm:0.00011358941264916211 max memory_allocated 38141.29736328125 
[2025-03-16 09:13:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 12 loss:0.012220676057040691 norm:0.00010946305701509118 max memory_allocated 38141.29736328125 
[2025-03-16 09:14:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 13 loss:0.012133839540183544 norm:0.00010832222324097529 max memory_allocated 38141.29736328125 
[2025-03-16 09:15:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 14 loss:0.012056658044457436 norm:0.00010331359226256609 max memory_allocated 38141.29736328125 
[2025-03-16 09:16:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 15 loss:0.012005086988210678 norm:0.00010277719411533326 max memory_allocated 38141.29736328125 
[2025-03-16 09:17:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 16 loss:0.011956374160945415 norm:0.0001011383137665689 max memory_allocated 38141.29736328125 
[2025-03-16 09:18:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 17 loss:0.011929015628993511 norm:0.00010269736230839044 max memory_allocated 38141.29736328125 
[2025-03-16 09:19:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 18 loss:0.01187158189713955 norm:0.0001004791702143848 max memory_allocated 38141.29736328125 
[2025-03-16 09:20:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 19-20 epoch 19 loss:0.011838000267744064 norm:9.772084740689024e-05 max memory_allocated 38141.29736328125 
[2025-03-16 09:21:01 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 20 to 21 ===
[2025-03-16 09:22:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 0 loss:0.026132019236683846 norm:0.0010515087051317096 max memory_allocated 38141.46923828125 
[2025-03-16 09:22:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 1 loss:0.020167503505945206 norm:0.00045318849151954055 max memory_allocated 38141.46923828125 
[2025-03-16 09:23:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 2 loss:0.01627412438392639 norm:0.0002717049792408943 max memory_allocated 38141.46923828125 
[2025-03-16 09:24:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 3 loss:0.014958742074668407 norm:0.00020547304302453995 max memory_allocated 38141.46923828125 
[2025-03-16 09:25:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 4 loss:0.014291016384959221 norm:0.00017723040946293622 max memory_allocated 38141.46923828125 
[2025-03-16 09:26:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 5 loss:0.013732727617025375 norm:0.00015532643010374159 max memory_allocated 38141.46923828125 
[2025-03-16 09:27:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 6 loss:0.013329495675861835 norm:0.00014692018157802522 max memory_allocated 38141.46923828125 
[2025-03-16 09:28:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 7 loss:0.013054989278316498 norm:0.0001328451035078615 max memory_allocated 38141.46923828125 
[2025-03-16 09:29:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 8 loss:0.012870704755187035 norm:0.00012835544475819916 max memory_allocated 38141.46923828125 
[2025-03-16 09:30:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 9 loss:0.012748763896524906 norm:0.00012472967500798404 max memory_allocated 38141.46923828125 
[2025-03-16 09:31:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 10 loss:0.012639566324651241 norm:0.00011827725393231958 max memory_allocated 38141.46923828125 
[2025-03-16 09:32:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 11 loss:0.012570766732096672 norm:0.00011315640585962683 max memory_allocated 38141.46923828125 
[2025-03-16 09:33:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 12 loss:0.012525291182100773 norm:0.00011004590487573296 max memory_allocated 38141.46923828125 
[2025-03-16 09:34:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 13 loss:0.012472253292798996 norm:0.00010773876419989392 max memory_allocated 38141.46923828125 
[2025-03-16 09:35:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 14 loss:0.012403455562889576 norm:0.00010249227489111945 max memory_allocated 38141.46923828125 
[2025-03-16 09:36:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 15 loss:0.012354489415884018 norm:9.994796710088849e-05 max memory_allocated 38141.46923828125 
[2025-03-16 09:37:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 16 loss:0.01230943389236927 norm:9.909010987030342e-05 max memory_allocated 38141.46923828125 
[2025-03-16 09:38:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 17 loss:0.012297708541154861 norm:9.909104846883565e-05 max memory_allocated 38141.46923828125 
[2025-03-16 09:39:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 18 loss:0.012267728336155415 norm:9.768891322892159e-05 max memory_allocated 38141.46923828125 
[2025-03-16 09:40:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 20-21 epoch 19 loss:0.012237362563610077 norm:9.7173877293244e-05 max memory_allocated 38141.46923828125 
[2025-03-16 09:40:35 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 21 to 22 ===
[2025-03-16 09:41:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 0 loss:0.02734309434890747 norm:0.0013576485216617584 max memory_allocated 38141.64111328125 
[2025-03-16 09:42:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 1 loss:0.021054232493042946 norm:0.0006646825349889696 max memory_allocated 38141.64111328125 
[2025-03-16 09:43:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 2 loss:0.01704799383878708 norm:0.00042810480226762593 max memory_allocated 38141.64111328125 
[2025-03-16 09:44:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 3 loss:0.015585352666676044 norm:0.00032225108589045703 max memory_allocated 38141.64111328125 
[2025-03-16 09:45:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 4 loss:0.014787085354328156 norm:0.0002568306808825582 max memory_allocated 38141.64111328125 
[2025-03-16 09:46:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 5 loss:0.01419918704777956 norm:0.0002127523475792259 max memory_allocated 38141.64111328125 
[2025-03-16 09:47:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 6 loss:0.013767817057669163 norm:0.00018646576791070402 max memory_allocated 38141.64111328125 
[2025-03-16 09:48:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 7 loss:0.013507192954421043 norm:0.00017187029880005866 max memory_allocated 38141.64111328125 
[2025-03-16 09:49:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 8 loss:0.013315398246049881 norm:0.00015369367611128837 max memory_allocated 38141.64111328125 
[2025-03-16 09:50:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 9 loss:0.013197969645261765 norm:0.00014431118324864656 max memory_allocated 38141.64111328125 
[2025-03-16 09:51:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 10 loss:0.013103139586746693 norm:0.00013628035958390683 max memory_allocated 38141.64111328125 
[2025-03-16 09:52:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 11 loss:0.0130541380494833 norm:0.00013296768884174526 max memory_allocated 38141.64111328125 
[2025-03-16 09:53:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 12 loss:0.012991880998015404 norm:0.00013024022337049246 max memory_allocated 38141.64111328125 
[2025-03-16 09:53:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 13 loss:0.01289045624434948 norm:0.00012084159970982 max memory_allocated 38141.64111328125 
[2025-03-16 09:54:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 14 loss:0.012819858267903328 norm:0.00012214579328428954 max memory_allocated 38141.64111328125 
[2025-03-16 09:55:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 15 loss:0.012772122398018837 norm:0.000117341463919729 max memory_allocated 38141.64111328125 
[2025-03-16 09:56:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 16 loss:0.012716122902929783 norm:0.00011552367504918948 max memory_allocated 38141.64111328125 
[2025-03-16 09:57:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 17 loss:0.01267659105360508 norm:0.00010914708400378004 max memory_allocated 38141.64111328125 
[2025-03-16 09:58:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 18 loss:0.012648739852011204 norm:0.00010878803732339293 max memory_allocated 38141.64111328125 
[2025-03-16 09:59:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 21-22 epoch 19 loss:0.0126207759603858 norm:0.00010734614625107497 max memory_allocated 38141.64111328125 
[2025-03-16 10:00:11 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 22 to 23 ===
[2025-03-16 10:01:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 0 loss:0.02835206687450409 norm:0.001841427874751389 max memory_allocated 38141.81298828125 
[2025-03-16 10:02:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 1 loss:0.021654848009347916 norm:0.0009512134129181504 max memory_allocated 38141.81298828125 
[2025-03-16 10:03:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 2 loss:0.017227552831172943 norm:0.0005985058378428221 max memory_allocated 38141.81298828125 
[2025-03-16 10:04:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 3 loss:0.01576169766485691 norm:0.0004184478602837771 max memory_allocated 38141.81298828125 
[2025-03-16 10:05:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 4 loss:0.014938486739993095 norm:0.000330038252286613 max memory_allocated 38141.81298828125 
[2025-03-16 10:05:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 5 loss:0.014268453232944012 norm:0.00026539276586845517 max memory_allocated 38141.81298828125 
[2025-03-16 10:06:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 6 loss:0.013806680217385292 norm:0.00022225188149604946 max memory_allocated 38141.81298828125 
[2025-03-16 10:07:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 7 loss:0.013555685989558697 norm:0.0001946415868587792 max memory_allocated 38141.81298828125 
[2025-03-16 10:08:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 8 loss:0.013396140187978745 norm:0.0001746604248182848 max memory_allocated 38141.81298828125 
[2025-03-16 10:09:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 9 loss:0.013293134048581123 norm:0.00016004493227228522 max memory_allocated 38141.81298828125 
[2025-03-16 10:10:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 10 loss:0.013189286924898624 norm:0.00014594911772292107 max memory_allocated 38141.81298828125 
[2025-03-16 10:11:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 11 loss:0.013115163892507553 norm:0.00013672001659870148 max memory_allocated 38141.81298828125 
[2025-03-16 10:12:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 12 loss:0.013043719343841076 norm:0.00012877729022875428 max memory_allocated 38141.81298828125 
[2025-03-16 10:13:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 13 loss:0.012987960129976273 norm:0.0001218276156578213 max memory_allocated 38141.81298828125 
[2025-03-16 10:14:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 14 loss:0.012930229306221008 norm:0.00011934611393371597 max memory_allocated 38141.81298828125 
[2025-03-16 10:15:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 15 loss:0.01290280930697918 norm:0.0001156091020675376 max memory_allocated 38141.81298828125 
[2025-03-16 10:16:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 16 loss:0.01286459993571043 norm:0.00011269529932178557 max memory_allocated 38141.81298828125 
[2025-03-16 10:17:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 17 loss:0.01284714974462986 norm:0.00010994909825967625 max memory_allocated 38141.81298828125 
[2025-03-16 10:18:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 18 loss:0.01280507817864418 norm:0.00010820170427905396 max memory_allocated 38141.81298828125 
[2025-03-16 10:19:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 22-23 epoch 19 loss:0.012784472666680813 norm:0.0001079742651199922 max memory_allocated 38141.81298828125 
[2025-03-16 10:19:46 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 23 to 24 ===
[2025-03-16 10:20:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 0 loss:0.031815677881240845 norm:0.0014737676829099655 max memory_allocated 38141.98486328125 
[2025-03-16 10:21:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 1 loss:0.0243556946516037 norm:0.0005931707564741373 max memory_allocated 38141.98486328125 
[2025-03-16 10:22:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 2 loss:0.019406363368034363 norm:0.00037367912591435015 max memory_allocated 38141.98486328125 
[2025-03-16 10:23:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 3 loss:0.017628507688641548 norm:0.00028411843231879175 max memory_allocated 38141.98486328125 
[2025-03-16 10:24:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 4 loss:0.016679413616657257 norm:0.00023338008031714708 max memory_allocated 38141.98486328125 
[2025-03-16 10:25:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 5 loss:0.015904918313026428 norm:0.00020310678519308567 max memory_allocated 38141.98486328125 
[2025-03-16 10:26:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 6 loss:0.015529478900134563 norm:0.00018314299813937396 max memory_allocated 38141.98486328125 
[2025-03-16 10:27:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 7 loss:0.015219908207654953 norm:0.00016811345994938165 max memory_allocated 38141.98486328125 
[2025-03-16 10:28:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 8 loss:0.015069106593728065 norm:0.00015949379303492606 max memory_allocated 38141.98486328125 
[2025-03-16 10:29:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 9 loss:0.014926985837519169 norm:0.00014997406105976552 max memory_allocated 38141.98486328125 
[2025-03-16 10:30:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 10 loss:0.01486378163099289 norm:0.00014880741946399212 max memory_allocated 38141.98486328125 
[2025-03-16 10:31:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 11 loss:0.014736315235495567 norm:0.00014865334378555417 max memory_allocated 38141.98486328125 
[2025-03-16 10:32:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 12 loss:0.01468663476407528 norm:0.0001442636566935107 max memory_allocated 38141.98486328125 
[2025-03-16 10:33:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 13 loss:0.014590853825211525 norm:0.0001371665857732296 max memory_allocated 38141.98486328125 
[2025-03-16 10:34:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 14 loss:0.014523069374263287 norm:0.00014415588520932943 max memory_allocated 38141.98486328125 
[2025-03-16 10:35:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 15 loss:0.014498049393296242 norm:0.0001399410393787548 max memory_allocated 38141.98486328125 
[2025-03-16 10:35:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 16 loss:0.014473175629973412 norm:0.0001374100538669154 max memory_allocated 38141.98486328125 
[2025-03-16 10:36:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 17 loss:0.014402865432202816 norm:0.00013828776718582958 max memory_allocated 38141.98486328125 
[2025-03-16 10:37:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 18 loss:0.014433289878070354 norm:0.0001352396357106045 max memory_allocated 38141.98486328125 
[2025-03-16 10:38:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 23-24 epoch 19 loss:0.014364163391292095 norm:0.00012759128003381193 max memory_allocated 38141.98486328125 
[2025-03-16 10:39:21 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 24 to 25 ===
[2025-03-16 10:40:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 0 loss:0.03754600137472153 norm:0.0016779947327449918 max memory_allocated 38142.15673828125 
[2025-03-16 10:41:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 1 loss:0.028079727664589882 norm:0.0008745160885155201 max memory_allocated 38142.15673828125 
[2025-03-16 10:42:19 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 2 loss:0.02222062274813652 norm:0.0005543929873965681 max memory_allocated 38142.15673828125 
[2025-03-16 10:43:16 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 3 loss:0.01994679681956768 norm:0.00039341021329164505 max memory_allocated 38142.15673828125 
[2025-03-16 10:44:13 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 4 loss:0.018749544396996498 norm:0.0003278241492807865 max memory_allocated 38142.15673828125 
[2025-03-16 10:45:10 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 5 loss:0.01789281517267227 norm:0.00027811957988888025 max memory_allocated 38142.15673828125 
[2025-03-16 10:46:07 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 6 loss:0.017364919185638428 norm:0.00024591461988165975 max memory_allocated 38142.15673828125 
[2025-03-16 10:47:04 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 7 loss:0.01705142855644226 norm:0.00022532703587785363 max memory_allocated 38142.15673828125 
[2025-03-16 10:48:01 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 8 loss:0.01678997278213501 norm:0.00020738683815579861 max memory_allocated 38142.15673828125 
[2025-03-16 10:48:58 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 9 loss:0.016629325225949287 norm:0.00019970379071310163 max memory_allocated 38142.15673828125 
[2025-03-16 10:49:55 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 10 loss:0.016432607546448708 norm:0.00019420772150624543 max memory_allocated 38142.15673828125 
[2025-03-16 10:50:52 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 11 loss:0.016320915892720222 norm:0.00017892193864099681 max memory_allocated 38142.15673828125 
[2025-03-16 10:51:49 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 12 loss:0.016193445771932602 norm:0.00017023470718413591 max memory_allocated 38142.15673828125 
[2025-03-16 10:52:46 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 13 loss:0.016107458621263504 norm:0.00017970551562029868 max memory_allocated 38142.15673828125 
[2025-03-16 10:53:43 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 14 loss:0.016036005690693855 norm:0.00016060486086644232 max memory_allocated 38142.15673828125 
[2025-03-16 10:54:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 15 loss:0.015960287302732468 norm:0.00016663562564644963 max memory_allocated 38142.15673828125 
[2025-03-16 10:55:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 16 loss:0.015897681936621666 norm:0.00015655226889066398 max memory_allocated 38142.15673828125 
[2025-03-16 10:56:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 17 loss:0.015837984159588814 norm:0.0001627722813282162 max memory_allocated 38142.15673828125 
[2025-03-16 10:57:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 18 loss:0.01582513377070427 norm:0.00015552948752883822 max memory_allocated 38142.15673828125 
[2025-03-16 10:58:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 24-25 epoch 19 loss:0.01578136533498764 norm:0.00016008506645448506 max memory_allocated 38142.15673828125 
[2025-03-16 10:58:58 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 25 to 26 ===
[2025-03-16 11:00:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 0 loss:0.04208116605877876 norm:0.002447520848363638 max memory_allocated 38142.32861328125 
[2025-03-16 11:00:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 1 loss:0.0315413735806942 norm:0.0011775665916502476 max memory_allocated 38142.32861328125 
[2025-03-16 11:01:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 2 loss:0.02512235939502716 norm:0.0007011740817688406 max memory_allocated 38142.32861328125 
[2025-03-16 11:02:51 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 3 loss:0.02261624112725258 norm:0.000495699408929795 max memory_allocated 38142.32861328125 
[2025-03-16 11:03:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 4 loss:0.021220343187451363 norm:0.0003849835484288633 max memory_allocated 38142.32861328125 
[2025-03-16 11:04:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 5 loss:0.020280983299016953 norm:0.00030995276756584644 max memory_allocated 38142.32861328125 
[2025-03-16 11:05:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 6 loss:0.019791193306446075 norm:0.00027288738056086004 max memory_allocated 38142.32861328125 
[2025-03-16 11:06:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 7 loss:0.01951190084218979 norm:0.00024375933571718633 max memory_allocated 38142.32861328125 
[2025-03-16 11:07:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 8 loss:0.019302142783999443 norm:0.00022397753491532058 max memory_allocated 38142.32861328125 
[2025-03-16 11:08:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 9 loss:0.019122274592518806 norm:0.00020584701269399375 max memory_allocated 38142.32861328125 
[2025-03-16 11:09:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 10 loss:0.01895817741751671 norm:0.00019531020370777696 max memory_allocated 38142.32861328125 
[2025-03-16 11:10:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 11 loss:0.01882660575211048 norm:0.0001903968513943255 max memory_allocated 38142.32861328125 
[2025-03-16 11:11:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 12 loss:0.018743649125099182 norm:0.0001845784718170762 max memory_allocated 38142.32861328125 
[2025-03-16 11:12:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 13 loss:0.01863676682114601 norm:0.00017373368609696627 max memory_allocated 38142.32861328125 
[2025-03-16 11:13:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 14 loss:0.018564993515610695 norm:0.0001707933988654986 max memory_allocated 38142.32861328125 
[2025-03-16 11:14:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 15 loss:0.01853231154382229 norm:0.00016738598060328513 max memory_allocated 38142.32861328125 
[2025-03-16 11:15:12 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 16 loss:0.01851724460721016 norm:0.00016501033678650856 max memory_allocated 38142.32861328125 
[2025-03-16 11:16:09 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 17 loss:0.018469668924808502 norm:0.00016472386778332293 max memory_allocated 38142.32861328125 
[2025-03-16 11:17:06 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 18 loss:0.018421854823827744 norm:0.00015927874483168125 max memory_allocated 38142.32861328125 
[2025-03-16 11:18:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 25-26 epoch 19 loss:0.018401267006993294 norm:0.0001596115907886997 max memory_allocated 38142.32861328125 
[2025-03-16 11:18:34 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 26 to 27 ===
[2025-03-16 11:19:35 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 0 loss:0.04599899426102638 norm:0.003532072529196739 max memory_allocated 38143.50048828125 
[2025-03-16 11:20:32 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 1 loss:0.03489472344517708 norm:0.001960909925401211 max memory_allocated 38144.50048828125 
[2025-03-16 11:21:29 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 2 loss:0.02768227458000183 norm:0.0012730190064758062 max memory_allocated 38144.50048828125 
[2025-03-16 11:22:26 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 3 loss:0.0249750018119812 norm:0.0009140644106082618 max memory_allocated 38144.50048828125 
[2025-03-16 11:23:23 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 4 loss:0.023383110761642456 norm:0.0006963680498301983 max memory_allocated 38144.50048828125 
[2025-03-16 11:24:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 5 loss:0.022441580891609192 norm:0.000552010431420058 max memory_allocated 38144.50048828125 
[2025-03-16 11:25:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 6 loss:0.02193398028612137 norm:0.00045366192352958024 max memory_allocated 38144.50048828125 
[2025-03-16 11:26:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 7 loss:0.021682335063815117 norm:0.00038542886613868177 max memory_allocated 38144.50048828125 
[2025-03-16 11:27:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 8 loss:0.021442322060465813 norm:0.0003378181718289852 max memory_allocated 38144.50048828125 
[2025-03-16 11:28:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 9 loss:0.021301869302988052 norm:0.0003076888096984476 max memory_allocated 38144.50048828125 
[2025-03-16 11:29:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 10 loss:0.021156039088964462 norm:0.0002811500453390181 max memory_allocated 38144.50048828125 
[2025-03-16 11:30:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 11 loss:0.021063009276986122 norm:0.0002591520023997873 max memory_allocated 38144.50048828125 
[2025-03-16 11:30:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 12 loss:0.02095259167253971 norm:0.0002452646440360695 max memory_allocated 38144.50048828125 
[2025-03-16 11:31:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 13 loss:0.02088085003197193 norm:0.00023054472694639117 max memory_allocated 38144.50048828125 
[2025-03-16 11:32:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 14 loss:0.02079186588525772 norm:0.00022454251302406192 max memory_allocated 38144.50048828125 
[2025-03-16 11:33:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 15 loss:0.020708370953798294 norm:0.0002134219103027135 max memory_allocated 38144.50048828125 
[2025-03-16 11:34:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 16 loss:0.020683176815509796 norm:0.0002078792458632961 max memory_allocated 38144.50048828125 
[2025-03-16 11:35:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 17 loss:0.020611640065908432 norm:0.00020237156422808766 max memory_allocated 38144.50048828125 
[2025-03-16 11:36:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 18 loss:0.02058502472937107 norm:0.00020263601618353277 max memory_allocated 38144.50048828125 
[2025-03-16 11:37:38 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 26-27 epoch 19 loss:0.020544638857245445 norm:0.00020008569117635489 max memory_allocated 38144.50048828125 
[2025-03-16 11:38:09 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 27 to 28 ===
[2025-03-16 11:39:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 0 loss:0.05487881973385811 norm:0.01061089988797903 max memory_allocated 38144.50048828125 
[2025-03-16 11:40:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 1 loss:0.0416586771607399 norm:0.007314291782677174 max memory_allocated 38144.50048828125 
[2025-03-16 11:41:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 2 loss:0.032941997051239014 norm:0.005240832455456257 max memory_allocated 38144.50048828125 
[2025-03-16 11:42:02 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 3 loss:0.02953137457370758 norm:0.004201853647828102 max memory_allocated 38144.50048828125 
[2025-03-16 11:42:59 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 4 loss:0.02743242122232914 norm:0.0035744421184062958 max memory_allocated 38144.50048828125 
[2025-03-16 11:43:56 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 5 loss:0.02626962400972843 norm:0.0031306957826018333 max memory_allocated 38144.50048828125 
[2025-03-16 11:44:53 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 6 loss:0.02556958608329296 norm:0.002802272792905569 max memory_allocated 38144.50048828125 
[2025-03-16 11:45:50 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 7 loss:0.025067269802093506 norm:0.0024765771813690662 max memory_allocated 38144.50048828125 
[2025-03-16 11:46:47 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 8 loss:0.024705152958631516 norm:0.002338175429031253 max memory_allocated 38144.50048828125 
[2025-03-16 11:47:44 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 9 loss:0.024545177817344666 norm:0.0022817100398242474 max memory_allocated 38144.50048828125 
[2025-03-16 11:48:41 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 10 loss:0.024308698251843452 norm:0.002308183815330267 max memory_allocated 38144.50048828125 
[2025-03-16 11:49:39 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 11 loss:0.024162808433175087 norm:0.002037724480032921 max memory_allocated 38144.50048828125 
[2025-03-16 11:50:36 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 12 loss:0.02388632483780384 norm:0.0019413415575399995 max memory_allocated 38144.50048828125 
[2025-03-16 11:51:33 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 13 loss:0.023749109357595444 norm:0.001828146749176085 max memory_allocated 38144.50048828125 
[2025-03-16 11:52:30 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 14 loss:0.02361069619655609 norm:0.0017663525650277734 max memory_allocated 38144.50048828125 
[2025-03-16 11:53:27 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 15 loss:0.02358504943549633 norm:0.001854105619713664 max memory_allocated 38144.50048828125 
[2025-03-16 11:54:24 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 16 loss:0.023440105840563774 norm:0.0017599251586943865 max memory_allocated 38144.50048828125 
[2025-03-16 11:55:21 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 17 loss:0.023439941927790642 norm:0.0017351302085444331 max memory_allocated 38144.50048828125 
[2025-03-16 11:56:18 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 18 loss:0.023385964334011078 norm:0.00173493183683604 max memory_allocated 38144.50048828125 
[2025-03-16 11:57:15 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 27-28 epoch 19 loss:0.023248080164194107 norm:0.0015566785586997867 max memory_allocated 38144.50048828125 
[2025-03-16 11:57:46 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 28 to 29 ===
[2025-03-16 11:58:48 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 0 loss:0.07709933817386627 norm:0.014034569263458252 max memory_allocated 38144.50048828125 
[2025-03-16 11:59:45 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 1 loss:0.056932590901851654 norm:0.008706914260983467 max memory_allocated 38144.50048828125 
[2025-03-16 12:00:42 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 2 loss:0.04480654001235962 norm:0.006155282724648714 max memory_allocated 38144.50048828125 
[2025-03-16 12:01:40 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 3 loss:0.039862316101789474 norm:0.004666005726903677 max memory_allocated 38144.50048828125 
[2025-03-16 12:02:37 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 4 loss:0.03726409748196602 norm:0.003730165772140026 max memory_allocated 38144.50048828125 
[2025-03-16 12:03:34 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 5 loss:0.03548416122794151 norm:0.0031278799287974834 max memory_allocated 38144.50048828125 
[2025-03-16 12:04:31 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 6 loss:0.03432136029005051 norm:0.0030136562418192625 max memory_allocated 38144.50048828125 
[2025-03-16 12:05:28 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 7 loss:0.03366158902645111 norm:0.0032532312907278538 max memory_allocated 38144.50048828125 
[2025-03-16 12:06:25 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 8 loss:0.03325231745839119 norm:0.0030622207559645176 max memory_allocated 38144.50048828125 
[2025-03-16 12:07:22 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 9 loss:0.03296169638633728 norm:0.002652975497767329 max memory_allocated 38144.50048828125 
[2025-03-16 12:08:20 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 10 loss:0.032774120569229126 norm:0.0024765904527157545 max memory_allocated 38144.50048828125 
[2025-03-16 12:09:17 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 11 loss:0.03260529413819313 norm:0.002542041940614581 max memory_allocated 38144.50048828125 
[2025-03-16 12:10:14 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 12 loss:0.032315079122781754 norm:0.002361919730901718 max memory_allocated 38144.50048828125 
[2025-03-16 12:11:11 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 13 loss:0.032183319330215454 norm:0.0021897261030972004 max memory_allocated 38144.50048828125 
[2025-03-16 12:12:08 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 14 loss:0.03220761567354202 norm:0.0021849642507731915 max memory_allocated 38144.50048828125 
[2025-03-16 12:13:05 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 15 loss:0.03214277699589729 norm:0.002152511151507497 max memory_allocated 38144.50048828125 
[2025-03-16 12:14:03 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 16 loss:0.032033078372478485 norm:0.002092324197292328 max memory_allocated 38144.50048828125 
[2025-03-16 12:15:00 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 17 loss:0.03184647858142853 norm:0.0019068766850978136 max memory_allocated 38144.50048828125 
[2025-03-16 12:15:57 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 18 loss:0.03186967968940735 norm:0.001884013181552291 max memory_allocated 38144.50048828125 
[2025-03-16 12:16:54 root] (abq_llm_calib_config3_cbq.py 447): INFO layers 28-29 epoch 19 loss:0.03187417984008789 norm:0.0018187030218541622 max memory_allocated 38144.50048828125 
[2025-03-16 12:17:25 root] (abq_llm_calib_config3_cbq.py 294): INFO === Start quantize layers 29 to 30 ===
[2025-03-16 12:17:31 root] (abq_llm_calib_config3_cbq.py 431): INFO Loss is NAN, stopping training
