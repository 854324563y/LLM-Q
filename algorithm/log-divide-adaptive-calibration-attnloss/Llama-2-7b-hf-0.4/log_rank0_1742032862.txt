[2025-03-15 10:01:02 root] (main_calib_config3.py 283): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-divide-adaptive-calibration-attnloss/Llama-2-7b-hf-0.4', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.4.pkl', blocks_pkl='./log-divide/Llama-2-7b-hf-w4a4/Llama-2-7b-hf_blocks.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-15 10:01:09 root] (main_calib_config3.py 350): INFO === start quantization ===
[2025-03-15 10:01:09 root] (main_calib_config3.py 356): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-15 10:01:09 root] (abq_llm_calib_config3.py 82): INFO Starting ...
[2025-03-15 10:01:09 root] (abq_llm_calib_config3.py 89): INFO Loaded quant_map from log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.4.pkl
[2025-03-15 10:01:09 root] (abq_llm_calib_config3.py 96): INFO Loaded blocks from ./log-divide/Llama-2-7b-hf-w4a4/Llama-2-7b-hf_blocks.pkl: [(0, 1), (1, 2), (2, 3), (3, 6), (6, 9), (9, 11), (11, 14), (14, 17), (17, 20), (20, 23), (23, 26), (26, 29), (29, 30), (30, 31), (31, 32)]
[2025-03-15 10:01:09 root] (abq_llm_calib_config3.py 102): INFO Processed blocks: [[0], [1], [2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12, 13], [14, 15, 16], [17, 18, 19], [20, 21, 22], [23, 24, 25], [26, 27, 28], [29], [30], [31]]
[2025-03-15 10:01:10 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 0 with layers [0] ===
[2025-03-15 10:01:10 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 10:01:40 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 0 loss:0.008308044634759426 norm:0.01283178385347128 max memory_allocated 34633.880859375 
[2025-03-15 10:02:07 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 1 loss:0.004624516237527132 norm:0.007592895999550819 max memory_allocated 34633.880859375 
[2025-03-15 10:02:34 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 2 loss:0.0031226298306137323 norm:0.005292136687785387 max memory_allocated 34633.880859375 
[2025-03-15 10:03:01 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 3 loss:0.00257560214959085 norm:0.004187874495983124 max memory_allocated 34633.880859375 
[2025-03-15 10:03:28 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 4 loss:0.002414178801700473 norm:0.003462668973952532 max memory_allocated 34633.880859375 
[2025-03-15 10:03:55 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 5 loss:0.0023077516816556454 norm:0.0029456315096467733 max memory_allocated 34633.880859375 
[2025-03-15 10:04:22 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 6 loss:0.002263115020468831 norm:0.002637614496052265 max memory_allocated 34633.880859375 
[2025-03-15 10:04:49 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 7 loss:0.0022089642006903887 norm:0.0023967106826603413 max memory_allocated 34633.880859375 
[2025-03-15 10:05:16 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 8 loss:0.0021747350692749023 norm:0.002067222958430648 max memory_allocated 34633.880859375 
[2025-03-15 10:05:43 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 9 loss:0.00211614859290421 norm:0.001800770522095263 max memory_allocated 34633.880859375 
[2025-03-15 10:06:10 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 10 loss:0.0020775131415575743 norm:0.001601334079168737 max memory_allocated 34633.880859375 
[2025-03-15 10:06:37 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 11 loss:0.0020921663381159306 norm:0.0014141459250822663 max memory_allocated 34633.880859375 
[2025-03-15 10:07:04 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 12 loss:0.0020837881602346897 norm:0.0012948352377861738 max memory_allocated 34633.880859375 
[2025-03-15 10:07:31 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 13 loss:0.002077151322737336 norm:0.0011660916497930884 max memory_allocated 34633.880859375 
[2025-03-15 10:07:58 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 14 loss:0.0020744078792631626 norm:0.0011700369650498033 max memory_allocated 34633.880859375 
[2025-03-15 10:08:25 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 15 loss:0.0020017423667013645 norm:0.0010277517139911652 max memory_allocated 34633.880859375 
[2025-03-15 10:08:52 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 16 loss:0.0019806965719908476 norm:0.0009244356770068407 max memory_allocated 34633.880859375 
[2025-03-15 10:09:19 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 17 loss:0.0019748061895370483 norm:0.0008857278735376894 max memory_allocated 34633.880859375 
[2025-03-15 10:09:46 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 18 loss:0.0019506942480802536 norm:0.0008941451669670641 max memory_allocated 34633.880859375 
[2025-03-15 10:10:13 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 19 loss:0.0019514854066073895 norm:0.000811669509857893 max memory_allocated 34633.880859375 
[2025-03-15 10:10:49 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 1 with layers [1] ===
[2025-03-15 10:10:49 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 10:11:19 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 0 loss:0.02811942994594574 norm:0.024772651493549347 max memory_allocated 35100.7724609375 
[2025-03-15 10:11:46 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 1 loss:0.017022989690303802 norm:0.014217107556760311 max memory_allocated 35100.7724609375 
[2025-03-15 10:12:13 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 2 loss:0.01269824244081974 norm:0.009550893679261208 max memory_allocated 35100.7724609375 
[2025-03-15 10:12:40 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 3 loss:0.011336817406117916 norm:0.012880713678896427 max memory_allocated 35100.7724609375 
[2025-03-15 10:13:07 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 4 loss:0.010511713102459908 norm:0.009888132102787495 max memory_allocated 35100.7724609375 
[2025-03-15 10:13:34 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 5 loss:0.010044561699032784 norm:0.008013379760086536 max memory_allocated 35100.7724609375 
[2025-03-15 10:14:01 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 6 loss:0.010298424400389194 norm:0.008421109989285469 max memory_allocated 35100.7724609375 
[2025-03-15 10:14:28 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 7 loss:0.010494190268218517 norm:0.008478648960590363 max memory_allocated 35100.7724609375 
[2025-03-15 10:14:55 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 8 loss:0.009436463937163353 norm:0.008250758051872253 max memory_allocated 35100.7724609375 
[2025-03-15 10:15:22 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 9 loss:0.009163402020931244 norm:0.007720480673015118 max memory_allocated 35100.7724609375 
[2025-03-15 10:15:49 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 10 loss:0.009019150398671627 norm:0.0072352527640759945 max memory_allocated 35100.7724609375 
[2025-03-15 10:16:16 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 11 loss:0.00953727401793003 norm:0.008603397756814957 max memory_allocated 35100.7724609375 
[2025-03-15 10:16:43 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 12 loss:0.009239481762051582 norm:0.00796583667397499 max memory_allocated 35100.7724609375 
[2025-03-15 10:17:10 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 13 loss:0.009185954928398132 norm:0.008115066215395927 max memory_allocated 35100.7724609375 
[2025-03-15 10:17:37 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 14 loss:0.009045885875821114 norm:0.007353545632213354 max memory_allocated 35100.7724609375 
[2025-03-15 10:18:04 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 15 loss:0.00987364910542965 norm:0.008376100100576878 max memory_allocated 35100.7724609375 
[2025-03-15 10:18:31 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 16 loss:0.009029907174408436 norm:0.007417944725602865 max memory_allocated 35100.7724609375 
[2025-03-15 10:18:58 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 17 loss:0.009116151370108128 norm:0.007183887530118227 max memory_allocated 35100.7724609375 
[2025-03-15 10:19:25 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 18 loss:0.009248221293091774 norm:0.007138457149267197 max memory_allocated 35100.7724609375 
[2025-03-15 10:19:52 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 19 loss:0.009264810010790825 norm:0.007380855269730091 max memory_allocated 35100.7724609375 
[2025-03-15 10:20:26 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 2 with layers [2] ===
[2025-03-15 10:20:26 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 10:20:55 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 0 loss:0.026827994734048843 norm:0.013365215621888638 max memory_allocated 35101.8349609375 
[2025-03-15 10:21:22 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 1 loss:0.01800558716058731 norm:0.008641108870506287 max memory_allocated 35101.8349609375 
[2025-03-15 10:21:49 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 2 loss:0.014370562508702278 norm:0.0060331434942781925 max memory_allocated 35101.8349609375 
[2025-03-15 10:22:16 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 3 loss:0.013171251863241196 norm:0.004647336434572935 max memory_allocated 35101.8349609375 
[2025-03-15 10:22:43 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 4 loss:0.012499566189944744 norm:0.0038784625940024853 max memory_allocated 35101.8349609375 
[2025-03-15 10:23:10 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 5 loss:0.012021901085972786 norm:0.0033635967411100864 max memory_allocated 35101.8349609375 
[2025-03-15 10:23:37 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 6 loss:0.011785428039729595 norm:0.002908590016886592 max memory_allocated 35101.8349609375 
[2025-03-15 10:24:04 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 7 loss:0.0116339810192585 norm:0.00252906559035182 max memory_allocated 35101.8349609375 
[2025-03-15 10:24:32 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 8 loss:0.011521688662469387 norm:0.0021270557772368193 max memory_allocated 35101.8349609375 
[2025-03-15 10:24:59 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 9 loss:0.011457458138465881 norm:0.0017940693069249392 max memory_allocated 35101.8349609375 
[2025-03-15 10:25:26 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 10 loss:0.01141289435327053 norm:0.0014921356923878193 max memory_allocated 35101.8349609375 
[2025-03-15 10:25:53 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 11 loss:0.011378628201782703 norm:0.0012695851037278771 max memory_allocated 35101.8349609375 
[2025-03-15 10:26:20 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 12 loss:0.011398158967494965 norm:0.001336580840870738 max memory_allocated 35101.8349609375 
[2025-03-15 10:26:47 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 13 loss:0.011402521282434464 norm:0.0012981194304302335 max memory_allocated 35101.8349609375 
[2025-03-15 10:27:14 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 14 loss:0.01138080470263958 norm:0.001215900992974639 max memory_allocated 35101.8349609375 
[2025-03-15 10:27:41 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 15 loss:0.011405627243220806 norm:0.00117480696644634 max memory_allocated 35101.8349609375 
[2025-03-15 10:28:08 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 16 loss:0.011456532403826714 norm:0.0011186596238985658 max memory_allocated 35101.8349609375 
[2025-03-15 10:28:35 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 17 loss:0.01143263466656208 norm:0.0010954538593068719 max memory_allocated 35101.8349609375 
[2025-03-15 10:29:02 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 18 loss:0.011414442211389542 norm:0.001023339107632637 max memory_allocated 35101.8349609375 
[2025-03-15 10:29:29 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 19 loss:0.011399512179195881 norm:0.0010271951323375106 max memory_allocated 35101.8349609375 
[2025-03-15 10:30:03 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 3 with layers [3, 4, 5] ===
[2025-03-15 10:31:31 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 0 loss:0.06771862506866455 norm:0.003938284702599049 max memory_allocated 47477.6044921875 
[2025-03-15 10:32:51 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 1 loss:0.04778030887246132 norm:0.000890515570063144 max memory_allocated 47477.6044921875 
[2025-03-15 10:34:11 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 2 loss:0.03690589591860771 norm:0.0005115712992846966 max memory_allocated 47477.6044921875 
[2025-03-15 10:35:31 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 3 loss:0.03209858387708664 norm:0.00038554490311071277 max memory_allocated 47477.6044921875 
[2025-03-15 10:36:51 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 4 loss:0.029620669782161713 norm:0.00035163434222340584 max memory_allocated 47477.6044921875 
[2025-03-15 10:38:11 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 5 loss:0.028217345476150513 norm:0.0003345782170072198 max memory_allocated 47477.6044921875 
[2025-03-15 10:39:31 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 6 loss:0.02731013298034668 norm:0.0003787724708672613 max memory_allocated 47477.6044921875 
[2025-03-15 10:40:51 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 7 loss:0.02668887749314308 norm:0.00041732442332431674 max memory_allocated 47477.6044921875 
[2025-03-15 10:42:11 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 8 loss:0.026279451325535774 norm:0.00040920163155533373 max memory_allocated 47477.6044921875 
[2025-03-15 10:43:31 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 9 loss:0.02610991708934307 norm:0.0004743131867144257 max memory_allocated 47477.6044921875 
[2025-03-15 10:44:51 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 10 loss:0.026030657812952995 norm:0.00047311600064858794 max memory_allocated 47477.6044921875 
[2025-03-15 10:46:12 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 11 loss:0.025889217853546143 norm:0.00040702990372665226 max memory_allocated 47477.6044921875 
[2025-03-15 10:47:32 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 12 loss:0.025798620656132698 norm:0.0004552182217594236 max memory_allocated 47477.6044921875 
[2025-03-15 10:48:52 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 13 loss:0.025744032114744186 norm:0.0004958085482940078 max memory_allocated 47477.6044921875 
[2025-03-15 10:50:12 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 14 loss:0.02569616585969925 norm:0.0004504617245402187 max memory_allocated 47477.6044921875 
[2025-03-15 10:51:32 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 15 loss:0.025640960782766342 norm:0.00047619029646739364 max memory_allocated 47477.6044921875 
[2025-03-15 10:52:52 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 16 loss:0.025633707642555237 norm:0.0004629713366739452 max memory_allocated 47477.6044921875 
[2025-03-15 10:54:12 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 17 loss:0.025677580386400223 norm:0.0004706158069893718 max memory_allocated 47477.6044921875 
[2025-03-15 10:55:32 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 18 loss:0.025678757578134537 norm:0.0004910271381959319 max memory_allocated 47477.6044921875 
[2025-03-15 10:56:52 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 19 loss:0.02567429468035698 norm:0.0005013507907278836 max memory_allocated 47477.6044921875 
[2025-03-15 10:58:37 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 4 with layers [6, 7, 8] ===
[2025-03-15 11:00:04 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 0 loss:0.08352898806333542 norm:0.0018365464638918638 max memory_allocated 47477.7919921875 
[2025-03-15 11:01:24 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 1 loss:0.062039077281951904 norm:0.0007179729291237891 max memory_allocated 47477.7919921875 
[2025-03-15 11:02:44 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 2 loss:0.048797886818647385 norm:0.0004657335812225938 max memory_allocated 47477.7919921875 
[2025-03-15 11:04:04 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 3 loss:0.04294919595122337 norm:0.0003878633142448962 max memory_allocated 47477.7919921875 
[2025-03-15 11:05:24 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 4 loss:0.03996269777417183 norm:0.00035975666833110154 max memory_allocated 47477.7919921875 
[2025-03-15 11:06:44 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 5 loss:0.03818058222532272 norm:0.000346054439432919 max memory_allocated 47477.7919921875 
[2025-03-15 11:08:04 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 6 loss:0.03696305304765701 norm:0.0003364905423950404 max memory_allocated 47477.7919921875 
[2025-03-15 11:09:24 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 7 loss:0.03622494637966156 norm:0.00033711246214807034 max memory_allocated 47477.7919921875 
[2025-03-15 11:10:44 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 8 loss:0.03577978163957596 norm:0.00033120650914497674 max memory_allocated 47477.7919921875 
[2025-03-15 11:12:04 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 9 loss:0.035373203456401825 norm:0.0003214467433281243 max memory_allocated 47477.7919921875 
[2025-03-15 11:13:24 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 10 loss:0.03511466458439827 norm:0.00032665784237906337 max memory_allocated 47477.7919921875 
[2025-03-15 11:14:44 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 11 loss:0.03496212512254715 norm:0.0003261516976635903 max memory_allocated 47477.7919921875 
[2025-03-15 11:16:04 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 12 loss:0.03482736274600029 norm:0.0003288724401500076 max memory_allocated 47477.7919921875 
[2025-03-15 11:17:24 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 13 loss:0.034715473651885986 norm:0.00034162509837187827 max memory_allocated 47477.7919921875 
[2025-03-15 11:18:45 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 14 loss:0.03463336080312729 norm:0.00031962970388121903 max memory_allocated 47477.7919921875 
[2025-03-15 11:20:05 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 15 loss:0.03453817963600159 norm:0.0003194805176462978 max memory_allocated 47477.7919921875 
[2025-03-15 11:21:25 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 16 loss:0.03443407639861107 norm:0.000311684503685683 max memory_allocated 47477.7919921875 
[2025-03-15 11:22:45 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 17 loss:0.03435106575489044 norm:0.00030744142713956535 max memory_allocated 47477.7919921875 
[2025-03-15 11:24:05 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 18 loss:0.03431563079357147 norm:0.00031053979182615876 max memory_allocated 47477.7919921875 
[2025-03-15 11:25:25 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 19 loss:0.034331854432821274 norm:0.000328344147419557 max memory_allocated 47477.7919921875 
[2025-03-15 11:27:08 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 5 with layers [9, 10] ===
[2025-03-15 11:28:06 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 0 loss:0.07329969108104706 norm:0.0019122594967484474 max memory_allocated 47477.7919921875 
[2025-03-15 11:29:00 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 1 loss:0.057165078818798065 norm:0.0009447340853512287 max memory_allocated 47477.7919921875 
[2025-03-15 11:29:53 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 2 loss:0.04567747190594673 norm:0.00045061999117024243 max memory_allocated 47477.7919921875 
[2025-03-15 11:30:46 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 3 loss:0.04101910442113876 norm:0.0002984545426443219 max memory_allocated 47477.7919921875 
[2025-03-15 11:31:40 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 4 loss:0.03889527916908264 norm:0.00024381311959587038 max memory_allocated 47477.7919921875 
[2025-03-15 11:32:33 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 5 loss:0.037735749036073685 norm:0.00023119356774259359 max memory_allocated 47477.7919921875 
[2025-03-15 11:33:27 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 6 loss:0.03709768131375313 norm:0.00021808341261930764 max memory_allocated 47477.7919921875 
[2025-03-15 11:34:20 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 7 loss:0.036748241633176804 norm:0.00020210142247378826 max memory_allocated 47477.7919921875 
[2025-03-15 11:35:14 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 8 loss:0.036474745720624924 norm:0.0001981747627723962 max memory_allocated 47477.7919921875 
[2025-03-15 11:36:07 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 9 loss:0.036332156509160995 norm:0.00019762104784604162 max memory_allocated 47477.7919921875 
[2025-03-15 11:37:01 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 10 loss:0.036248158663511276 norm:0.0002082214195979759 max memory_allocated 47477.7919921875 
[2025-03-15 11:37:54 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 11 loss:0.03615665063261986 norm:0.00021571714023593813 max memory_allocated 47477.7919921875 
[2025-03-15 11:38:48 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 12 loss:0.03602764755487442 norm:0.00020939928072039038 max memory_allocated 47477.7919921875 
[2025-03-15 11:39:41 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 13 loss:0.0359732061624527 norm:0.0002139405842171982 max memory_allocated 47477.7919921875 
[2025-03-15 11:40:35 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 14 loss:0.03591006621718407 norm:0.00021494885731954128 max memory_allocated 47477.7919921875 
[2025-03-15 11:41:28 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 15 loss:0.03582802787423134 norm:0.00021427724277600646 max memory_allocated 47477.7919921875 
[2025-03-15 11:42:22 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 16 loss:0.035763390362262726 norm:0.00020962666894774884 max memory_allocated 47477.7919921875 
[2025-03-15 11:43:15 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 17 loss:0.03574586659669876 norm:0.00021006127644795924 max memory_allocated 47477.7919921875 
[2025-03-15 11:44:08 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 18 loss:0.03569570183753967 norm:0.00020804333325941116 max memory_allocated 47477.7919921875 
[2025-03-15 11:45:02 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 19 loss:0.03566814213991165 norm:0.00021493385429494083 max memory_allocated 47477.7919921875 
[2025-03-15 11:46:12 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 6 with layers [11, 12, 13] ===
[2025-03-15 11:47:40 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 0 loss:0.08542636036872864 norm:0.001863126177340746 max memory_allocated 47478.1044921875 
[2025-03-15 11:49:00 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 1 loss:0.06718850135803223 norm:0.000859580235555768 max memory_allocated 47478.1044921875 
[2025-03-15 11:50:20 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 2 loss:0.05437122657895088 norm:0.0004703507001977414 max memory_allocated 47478.1044921875 
[2025-03-15 11:51:40 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 3 loss:0.04855490103363991 norm:0.00033931605867110193 max memory_allocated 47478.1044921875 
[2025-03-15 11:53:00 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 4 loss:0.045613452792167664 norm:0.0002763435186352581 max memory_allocated 47478.1044921875 
[2025-03-15 11:54:20 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 5 loss:0.04383067041635513 norm:0.0002537615073379129 max memory_allocated 47478.1044921875 
[2025-03-15 11:55:40 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 6 loss:0.04270736873149872 norm:0.00023782660719007254 max memory_allocated 47478.1044921875 
[2025-03-15 11:57:00 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 7 loss:0.04198351874947548 norm:0.00022425863426178694 max memory_allocated 47478.1044921875 
[2025-03-15 11:58:20 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 8 loss:0.0415298193693161 norm:0.0002291769051225856 max memory_allocated 47478.1044921875 
[2025-03-15 11:59:41 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 9 loss:0.04117449373006821 norm:0.00022187427384778857 max memory_allocated 47478.1044921875 
[2025-03-15 12:01:01 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 10 loss:0.0409664586186409 norm:0.00022400700254365802 max memory_allocated 47478.1044921875 
[2025-03-15 12:02:21 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 11 loss:0.040828637778759 norm:0.00021873993682675064 max memory_allocated 47478.1044921875 
[2025-03-15 12:03:41 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 12 loss:0.040695670992136 norm:0.0002164935867767781 max memory_allocated 47478.1044921875 
[2025-03-15 12:05:01 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 13 loss:0.04059845209121704 norm:0.00021966623899061233 max memory_allocated 47478.1044921875 
[2025-03-15 12:06:21 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 14 loss:0.04050367325544357 norm:0.00021473462402354926 max memory_allocated 47478.1044921875 
[2025-03-15 12:07:41 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 15 loss:0.04041304811835289 norm:0.00020842735830228776 max memory_allocated 47478.1044921875 
[2025-03-15 12:09:01 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 16 loss:0.040314096957445145 norm:0.00020226521883159876 max memory_allocated 47478.1044921875 
[2025-03-15 12:10:21 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 17 loss:0.04027288034558296 norm:0.0002079297264572233 max memory_allocated 47478.1044921875 
[2025-03-15 12:11:41 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 18 loss:0.04018867760896683 norm:0.00021008642215747386 max memory_allocated 47478.1044921875 
[2025-03-15 12:13:01 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 19 loss:0.04011473432183266 norm:0.00021292731980793178 max memory_allocated 47478.1044921875 
[2025-03-15 12:14:46 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 7 with layers [14, 15, 16] ===
[2025-03-15 12:16:14 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 0 loss:0.08137250691652298 norm:0.0013228263705968857 max memory_allocated 47478.2919921875 
[2025-03-15 12:17:34 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 1 loss:0.06511185318231583 norm:0.0005545602180063725 max memory_allocated 47478.2919921875 
[2025-03-15 12:18:54 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 2 loss:0.05321112275123596 norm:0.0003321829135529697 max memory_allocated 47478.2919921875 
[2025-03-15 12:20:14 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 3 loss:0.04824427142739296 norm:0.0002600968873593956 max memory_allocated 47478.2919921875 
[2025-03-15 12:21:34 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 4 loss:0.045753151178359985 norm:0.00022896136215422302 max memory_allocated 47478.2919921875 
[2025-03-15 12:22:54 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 5 loss:0.044172223657369614 norm:0.00020838119962718338 max memory_allocated 47478.2919921875 
[2025-03-15 12:24:14 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 6 loss:0.04314938187599182 norm:0.0002007519651670009 max memory_allocated 47478.2919921875 
[2025-03-15 12:25:34 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 7 loss:0.04249713942408562 norm:0.0001958787179319188 max memory_allocated 47478.2919921875 
[2025-03-15 12:26:54 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 8 loss:0.04204346612095833 norm:0.0001898052723845467 max memory_allocated 47478.2919921875 
[2025-03-15 12:28:14 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 9 loss:0.041661351919174194 norm:0.0001826182269724086 max memory_allocated 47478.2919921875 
[2025-03-15 12:29:34 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 10 loss:0.0413961224257946 norm:0.00018086910131387413 max memory_allocated 47478.2919921875 
[2025-03-15 12:30:54 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 11 loss:0.04116265848278999 norm:0.0001796921860659495 max memory_allocated 47478.2919921875 
[2025-03-15 12:32:14 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 12 loss:0.04096321016550064 norm:0.0001704845781205222 max memory_allocated 47478.2919921875 
[2025-03-15 12:33:34 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 13 loss:0.04083419591188431 norm:0.0001717752602417022 max memory_allocated 47478.2919921875 
[2025-03-15 12:34:54 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 14 loss:0.04069960117340088 norm:0.00016597885405644774 max memory_allocated 47478.2919921875 
[2025-03-15 12:36:14 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 15 loss:0.04063030332326889 norm:0.0001669691118877381 max memory_allocated 47478.2919921875 
[2025-03-15 12:37:35 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 16 loss:0.0405488945543766 norm:0.00016096487524919212 max memory_allocated 47478.2919921875 
[2025-03-15 12:38:55 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 17 loss:0.040473319590091705 norm:0.00015935054398141801 max memory_allocated 47478.2919921875 
[2025-03-15 12:40:15 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 18 loss:0.04043183848261833 norm:0.00016031878476496786 max memory_allocated 47478.2919921875 
[2025-03-15 12:41:35 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 19 loss:0.04037308692932129 norm:0.000159366536536254 max memory_allocated 47478.2919921875 
[2025-03-15 12:43:18 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 8 with layers [17, 18, 19] ===
[2025-03-15 12:44:45 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 0 loss:0.08822324126958847 norm:0.002047374378889799 max memory_allocated 47478.4794921875 
[2025-03-15 12:46:05 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 1 loss:0.07163998484611511 norm:0.0006487206555902958 max memory_allocated 47478.4794921875 
[2025-03-15 12:47:25 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 2 loss:0.059041447937488556 norm:0.0003183343505952507 max memory_allocated 47478.4794921875 
[2025-03-15 12:48:45 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 3 loss:0.054718539118766785 norm:0.00023566001618746668 max memory_allocated 47478.4794921875 
[2025-03-15 12:50:05 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 4 loss:0.05218200385570526 norm:0.0002096825191983953 max memory_allocated 47478.4794921875 
[2025-03-15 12:51:25 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 5 loss:0.05041128396987915 norm:0.00018931787053588778 max memory_allocated 47478.4794921875 
[2025-03-15 12:52:45 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 6 loss:0.04943663254380226 norm:0.00018300462397746742 max memory_allocated 47478.4794921875 
[2025-03-15 12:54:06 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 7 loss:0.04883129894733429 norm:0.0001807197550078854 max memory_allocated 47478.4794921875 
[2025-03-15 12:55:26 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 8 loss:0.04839751124382019 norm:0.00017571242642588913 max memory_allocated 47478.4794921875 
[2025-03-15 12:56:46 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 9 loss:0.048081159591674805 norm:0.00016988030984066427 max memory_allocated 47478.4794921875 
[2025-03-15 12:58:06 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 10 loss:0.04783634841442108 norm:0.0001638772082515061 max memory_allocated 47478.4794921875 
[2025-03-15 12:59:26 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 11 loss:0.047604095190763474 norm:0.00015694393368903548 max memory_allocated 47478.4794921875 
[2025-03-15 13:00:46 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 12 loss:0.047438330948352814 norm:0.00015350854664575309 max memory_allocated 47478.4794921875 
[2025-03-15 13:02:06 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 13 loss:0.04726071655750275 norm:0.00014947498857509345 max memory_allocated 47478.4794921875 
[2025-03-15 13:03:26 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 14 loss:0.0471147745847702 norm:0.00014925441064406186 max memory_allocated 47478.4794921875 
[2025-03-15 13:04:46 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 15 loss:0.04701908677816391 norm:0.00014698113955091685 max memory_allocated 47478.4794921875 
[2025-03-15 13:06:06 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 16 loss:0.04693402349948883 norm:0.00014367639960255474 max memory_allocated 47478.4794921875 
[2025-03-15 13:07:26 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 17 loss:0.04686177521944046 norm:0.00014157543773762882 max memory_allocated 47478.4794921875 
[2025-03-15 13:08:46 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 18 loss:0.04679010063409805 norm:0.000144483259646222 max memory_allocated 47478.4794921875 
[2025-03-15 13:10:06 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 19 loss:0.04671498388051987 norm:0.00014517860836349428 max memory_allocated 47478.4794921875 
[2025-03-15 13:11:48 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 9 with layers [20, 21, 22] ===
[2025-03-15 13:13:16 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 0 loss:0.11061690747737885 norm:0.0018261298537254333 max memory_allocated 47478.6669921875 
[2025-03-15 13:14:36 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 1 loss:0.0929495170712471 norm:0.00073116464773193 max memory_allocated 47478.6669921875 
[2025-03-15 13:15:56 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 2 loss:0.07791082561016083 norm:0.00036204984644427896 max memory_allocated 47478.6669921875 
[2025-03-15 13:17:16 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 3 loss:0.07310933619737625 norm:0.0002935833763331175 max memory_allocated 47478.6669921875 
[2025-03-15 13:18:36 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 4 loss:0.07006703317165375 norm:0.00026766344672068954 max memory_allocated 47478.6669921875 
[2025-03-15 13:19:56 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 5 loss:0.06809872388839722 norm:0.000252025987720117 max memory_allocated 47478.6669921875 
[2025-03-15 13:21:16 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 6 loss:0.06707294285297394 norm:0.0002425583079457283 max memory_allocated 47478.6669921875 
[2025-03-15 13:22:36 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 7 loss:0.06642630696296692 norm:0.00022600675583817065 max memory_allocated 47478.6669921875 
[2025-03-15 13:23:56 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 8 loss:0.06598609685897827 norm:0.0002186343917855993 max memory_allocated 47478.6669921875 
[2025-03-15 13:25:16 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 9 loss:0.06563185900449753 norm:0.00021559801825787872 max memory_allocated 47478.6669921875 
[2025-03-15 13:26:36 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 10 loss:0.06532928347587585 norm:0.0002161286392947659 max memory_allocated 47478.6669921875 
[2025-03-15 13:27:56 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 11 loss:0.06501486152410507 norm:0.00021343051048461348 max memory_allocated 47478.6669921875 
[2025-03-15 13:29:16 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 12 loss:0.06479866802692413 norm:0.00020720547763630748 max memory_allocated 47478.6669921875 
[2025-03-15 13:30:36 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 13 loss:0.06458212435245514 norm:0.00019883294589817524 max memory_allocated 47478.6669921875 
[2025-03-15 13:31:56 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 14 loss:0.06437927484512329 norm:0.00019457323651295155 max memory_allocated 47478.6669921875 
[2025-03-15 13:33:17 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 15 loss:0.06419791281223297 norm:0.00019852514378726482 max memory_allocated 47478.6669921875 
[2025-03-15 13:34:37 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 16 loss:0.06405644863843918 norm:0.00019117415649816394 max memory_allocated 47478.6669921875 
[2025-03-15 13:35:57 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 17 loss:0.06393283605575562 norm:0.00018508803623262793 max memory_allocated 47478.6669921875 
[2025-03-15 13:37:17 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 18 loss:0.0637870579957962 norm:0.00018470043141860515 max memory_allocated 47478.6669921875 
[2025-03-15 13:38:37 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 19 loss:0.0636947825551033 norm:0.00018313615873921663 max memory_allocated 47478.6669921875 
[2025-03-15 13:40:22 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 10 with layers [23, 24, 25] ===
[2025-03-15 13:41:49 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 0 loss:0.15916694700717926 norm:0.0041116331703960896 max memory_allocated 47478.8544921875 
[2025-03-15 13:43:09 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 1 loss:0.1312631517648697 norm:0.0008898132364265621 max memory_allocated 47478.8544921875 
[2025-03-15 13:44:29 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 2 loss:0.10987138748168945 norm:0.00043772501521743834 max memory_allocated 47478.8544921875 
[2025-03-15 13:45:49 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 3 loss:0.10324796289205551 norm:0.0003354472864884883 max memory_allocated 47478.8544921875 
[2025-03-15 13:47:09 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 4 loss:0.09938080608844757 norm:0.00031891214894130826 max memory_allocated 47478.8544921875 
[2025-03-15 13:48:29 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 5 loss:0.09744436293840408 norm:0.00029551604529842734 max memory_allocated 47478.8544921875 
[2025-03-15 13:49:49 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 6 loss:0.0965363159775734 norm:0.00027767877327278256 max memory_allocated 47478.8544921875 
[2025-03-15 13:51:10 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 7 loss:0.09591307491064072 norm:0.0002739607007242739 max memory_allocated 47478.8544921875 
[2025-03-15 13:52:30 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 8 loss:0.09541763365268707 norm:0.0002738655894063413 max memory_allocated 47478.8544921875 
[2025-03-15 13:53:50 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 9 loss:0.09496812522411346 norm:0.00025379855651408434 max memory_allocated 47478.8544921875 
[2025-03-15 13:55:10 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 10 loss:0.09458333253860474 norm:0.00024417636450380087 max memory_allocated 47478.8544921875 
[2025-03-15 13:56:30 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 11 loss:0.09422334283590317 norm:0.0002421933604637161 max memory_allocated 47478.8544921875 
[2025-03-15 13:57:50 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 12 loss:0.09390351921319962 norm:0.00024110829690471292 max memory_allocated 47478.8544921875 
[2025-03-15 13:59:10 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 13 loss:0.09362469613552094 norm:0.0002359057980356738 max memory_allocated 47478.8544921875 
[2025-03-15 14:00:30 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 14 loss:0.09341934323310852 norm:0.0002382799139013514 max memory_allocated 47478.8544921875 
[2025-03-15 14:01:50 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 15 loss:0.09319699555635452 norm:0.00025603437097743154 max memory_allocated 47478.8544921875 
[2025-03-15 14:03:10 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 16 loss:0.09305727481842041 norm:0.0002364313113503158 max memory_allocated 47478.8544921875 
[2025-03-15 14:04:30 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 17 loss:0.09284558892250061 norm:0.0002202884352300316 max memory_allocated 47478.8544921875 
[2025-03-15 14:05:50 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 18 loss:0.09270167350769043 norm:0.00021165379439480603 max memory_allocated 47478.8544921875 
[2025-03-15 14:07:10 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 19 loss:0.09255814552307129 norm:0.00022492615971714258 max memory_allocated 47478.8544921875 
[2025-03-15 14:08:52 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 11 with layers [26, 27, 28] ===
[2025-03-15 14:08:52 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 14:10:19 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 0 loss:0.21586287021636963 norm:0.023195086047053337 max memory_allocated 47479.0419921875 
[2025-03-15 14:11:40 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 1 loss:0.185254767537117 norm:0.015982946380972862 max memory_allocated 47479.0419921875 
[2025-03-15 14:13:00 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 2 loss:0.15912297368049622 norm:0.009018685668706894 max memory_allocated 47479.0419921875 
[2025-03-15 14:14:20 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 3 loss:0.15007618069648743 norm:0.007032048888504505 max memory_allocated 47479.0419921875 
[2025-03-15 14:15:40 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 4 loss:0.14581182599067688 norm:0.005986514501273632 max memory_allocated 47479.0419921875 
[2025-03-15 14:17:00 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 5 loss:0.14402219653129578 norm:0.005210292525589466 max memory_allocated 47479.0419921875 
[2025-03-15 14:18:20 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 6 loss:0.14287129044532776 norm:0.004558950662612915 max memory_allocated 47479.0419921875 
[2025-03-15 14:19:40 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 7 loss:0.14203575253486633 norm:0.0039322515949606895 max memory_allocated 47479.0419921875 
[2025-03-15 14:21:01 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 8 loss:0.1412508189678192 norm:0.003381244372576475 max memory_allocated 47479.0419921875 
[2025-03-15 14:22:21 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 9 loss:0.1406877338886261 norm:0.003026556922122836 max memory_allocated 47479.0419921875 
[2025-03-15 14:23:41 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 10 loss:0.14016325771808624 norm:0.0029446284752339125 max memory_allocated 47479.0419921875 
[2025-03-15 14:25:01 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 11 loss:0.1398853361606598 norm:0.0031527315732091665 max memory_allocated 47479.0419921875 
[2025-03-15 14:26:21 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 12 loss:0.13940396904945374 norm:0.002818893641233444 max memory_allocated 47479.0419921875 
[2025-03-15 14:27:41 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 13 loss:0.1390460729598999 norm:0.002740520052611828 max memory_allocated 47479.0419921875 
[2025-03-15 14:29:02 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 14 loss:0.13888707756996155 norm:0.002861759392544627 max memory_allocated 47479.0419921875 
[2025-03-15 14:30:22 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 15 loss:0.13852152228355408 norm:0.0026109430473297834 max memory_allocated 47479.0419921875 
[2025-03-15 14:31:42 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 16 loss:0.13822975754737854 norm:0.0022711774799972773 max memory_allocated 47479.0419921875 
[2025-03-15 14:33:02 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 17 loss:0.13799361884593964 norm:0.0022760420106351376 max memory_allocated 47479.0419921875 
[2025-03-15 14:34:22 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 18 loss:0.13786351680755615 norm:0.0023735822178423405 max memory_allocated 47479.0419921875 
[2025-03-15 14:35:42 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 19 loss:0.13770802319049835 norm:0.002420612145215273 max memory_allocated 47479.0419921875 
[2025-03-15 14:37:25 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 12 with layers [29] ===
[2025-03-15 14:37:25 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 14:37:55 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 0 loss:0.17655408382415771 norm:0.0123530812561512 max memory_allocated 47479.0419921875 
[2025-03-15 14:38:22 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 1 loss:0.16326212882995605 norm:0.009050585329532623 max memory_allocated 47479.0419921875 
[2025-03-15 14:38:49 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 2 loss:0.1528458297252655 norm:0.0057510086335241795 max memory_allocated 47479.0419921875 
[2025-03-15 14:39:16 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 3 loss:0.14968004822731018 norm:0.004802390933036804 max memory_allocated 47479.0419921875 
[2025-03-15 14:39:43 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 4 loss:0.1486106514930725 norm:0.004133949056267738 max memory_allocated 47479.0419921875 
[2025-03-15 14:40:10 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 5 loss:0.1480768620967865 norm:0.0035277712158858776 max memory_allocated 47479.0419921875 
[2025-03-15 14:40:37 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 6 loss:0.1476679891347885 norm:0.002983744954690337 max memory_allocated 47479.0419921875 
[2025-03-15 14:41:04 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 7 loss:0.14732542634010315 norm:0.0025934907607734203 max memory_allocated 47479.0419921875 
[2025-03-15 14:41:31 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 8 loss:0.14716818928718567 norm:0.0025034749414771795 max memory_allocated 47479.0419921875 
[2025-03-15 14:41:58 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 9 loss:0.14705151319503784 norm:0.0026246169582009315 max memory_allocated 47479.0419921875 
[2025-03-15 14:42:25 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 10 loss:0.14701108634471893 norm:0.0023249415680766106 max memory_allocated 47479.0419921875 
[2025-03-15 14:42:52 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 11 loss:0.1467123031616211 norm:0.002306184731423855 max memory_allocated 47479.0419921875 
[2025-03-15 14:43:19 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 12 loss:0.14656159281730652 norm:0.0020811734721064568 max memory_allocated 47479.0419921875 
[2025-03-15 14:43:46 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 13 loss:0.14642946422100067 norm:0.0020461897365748882 max memory_allocated 47479.0419921875 
[2025-03-15 14:44:13 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 14 loss:0.14634299278259277 norm:0.0019545340910553932 max memory_allocated 47479.0419921875 
[2025-03-15 14:44:40 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 15 loss:0.14624662697315216 norm:0.0018738412763923407 max memory_allocated 47479.0419921875 
[2025-03-15 14:45:07 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 16 loss:0.14615099132061005 norm:0.0018180949846282601 max memory_allocated 47479.0419921875 
[2025-03-15 14:45:34 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 17 loss:0.14607912302017212 norm:0.0018496694974601269 max memory_allocated 47479.0419921875 
[2025-03-15 14:46:01 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 18 loss:0.14611557126045227 norm:0.0019179793307557702 max memory_allocated 47479.0419921875 
[2025-03-15 14:46:28 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 19 loss:0.14600157737731934 norm:0.001906807767227292 max memory_allocated 47479.0419921875 
[2025-03-15 14:47:05 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 13 with layers [30] ===
[2025-03-15 14:47:06 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 14:47:36 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 0 loss:0.2508682310581207 norm:0.035123102366924286 max memory_allocated 47479.0419921875 
[2025-03-15 14:48:03 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 1 loss:0.2182522714138031 norm:0.01918673887848854 max memory_allocated 47479.0419921875 
[2025-03-15 14:48:30 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 2 loss:0.19869054853916168 norm:0.01325786579400301 max memory_allocated 47479.0419921875 
[2025-03-15 14:48:57 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 3 loss:0.19412386417388916 norm:0.011619451455771923 max memory_allocated 47479.0419921875 
[2025-03-15 14:49:24 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 4 loss:0.19277752935886383 norm:0.01101385522633791 max memory_allocated 47479.0419921875 
[2025-03-15 14:49:51 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 5 loss:0.19223597645759583 norm:0.010162930935621262 max memory_allocated 47479.0419921875 
[2025-03-15 14:50:18 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 6 loss:0.19170409440994263 norm:0.009864246472716331 max memory_allocated 47479.0419921875 
[2025-03-15 14:50:45 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 7 loss:0.19078299403190613 norm:0.008944464847445488 max memory_allocated 47479.0419921875 
[2025-03-15 14:51:12 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 8 loss:0.19067928194999695 norm:0.008999766781926155 max memory_allocated 47479.0419921875 
[2025-03-15 14:51:39 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 9 loss:0.19054803252220154 norm:0.00864561926573515 max memory_allocated 47479.0419921875 
[2025-03-15 14:52:06 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 10 loss:0.1901247799396515 norm:0.008321136236190796 max memory_allocated 47479.0419921875 
[2025-03-15 14:52:33 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 11 loss:0.1898297518491745 norm:0.00824118684977293 max memory_allocated 47479.0419921875 
[2025-03-15 14:53:01 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 12 loss:0.1898224800825119 norm:0.007765231654047966 max memory_allocated 47479.0419921875 
[2025-03-15 14:53:28 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 13 loss:0.189724862575531 norm:0.007874337956309319 max memory_allocated 47479.0419921875 
[2025-03-15 14:53:55 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 14 loss:0.18971388041973114 norm:0.007740184664726257 max memory_allocated 47479.0419921875 
[2025-03-15 14:54:22 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 15 loss:0.18965256214141846 norm:0.007791745010763407 max memory_allocated 47479.0419921875 
[2025-03-15 14:54:49 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 16 loss:0.18957865238189697 norm:0.007480180356651545 max memory_allocated 47479.0419921875 
[2025-03-15 14:55:16 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 17 loss:0.18907701969146729 norm:0.007223076187074184 max memory_allocated 47479.0419921875 
[2025-03-15 14:55:43 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 18 loss:0.1894039362668991 norm:0.007336239330470562 max memory_allocated 47479.0419921875 
[2025-03-15 14:56:10 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 19 loss:0.18880575895309448 norm:0.007095173001289368 max memory_allocated 47479.0419921875 
[2025-03-15 14:56:47 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 14 with layers [31] ===
[2025-03-15 14:56:48 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 14:57:17 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 0 loss:0.42042842507362366 norm:0.05961894243955612 max memory_allocated 47479.0419921875 
[2025-03-15 14:57:44 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 1 loss:0.3681713044643402 norm:0.04221376031637192 max memory_allocated 47479.0419921875 
[2025-03-15 14:58:12 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 2 loss:0.32906630635261536 norm:0.026277855038642883 max memory_allocated 47479.0419921875 
[2025-03-15 14:58:39 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 3 loss:0.3197048008441925 norm:0.023327037692070007 max memory_allocated 47479.0419921875 
[2025-03-15 14:59:06 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 4 loss:0.31556031107902527 norm:0.020494520664215088 max memory_allocated 47479.0419921875 
[2025-03-15 14:59:33 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 5 loss:0.31301432847976685 norm:0.018930938094854355 max memory_allocated 47479.0419921875 
[2025-03-15 15:00:00 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 6 loss:0.31097573041915894 norm:0.01725700870156288 max memory_allocated 47479.0419921875 
[2025-03-15 15:00:27 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 7 loss:0.309425950050354 norm:0.01594844087958336 max memory_allocated 47479.0419921875 
[2025-03-15 15:00:54 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 8 loss:0.3081578314304352 norm:0.014790083281695843 max memory_allocated 47479.0419921875 
[2025-03-15 15:01:21 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 9 loss:0.3069232702255249 norm:0.013969289138913155 max memory_allocated 47479.0419921875 
[2025-03-15 15:01:48 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 10 loss:0.3061486482620239 norm:0.013711504638195038 max memory_allocated 47479.0419921875 
[2025-03-15 15:02:15 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 11 loss:0.3053816854953766 norm:0.013326678425073624 max memory_allocated 47479.0419921875 
[2025-03-15 15:02:42 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 12 loss:0.3043692708015442 norm:0.012231983244419098 max memory_allocated 47479.0419921875 
[2025-03-15 15:03:10 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 13 loss:0.3033631443977356 norm:0.011305293068289757 max memory_allocated 47479.0419921875 
[2025-03-15 15:03:37 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 14 loss:0.3031875193119049 norm:0.011585436761379242 max memory_allocated 47479.0419921875 
[2025-03-15 15:04:04 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 15 loss:0.30276793241500854 norm:0.01071912795305252 max memory_allocated 47479.0419921875 
[2025-03-15 15:04:31 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 16 loss:0.30206549167633057 norm:0.01012085285037756 max memory_allocated 47479.0419921875 
[2025-03-15 15:04:58 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 17 loss:0.3021138906478882 norm:0.010164385661482811 max memory_allocated 47479.0419921875 
[2025-03-15 15:05:25 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 18 loss:0.30246517062187195 norm:0.011548246257007122 max memory_allocated 47479.0419921875 
[2025-03-15 15:05:52 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 19 loss:0.3012951910495758 norm:0.009939967654645443 max memory_allocated 47479.0419921875 
[2025-03-15 15:06:29 root] (main_calib_config3.py 379): INFO 18320.24906897545
[2025-03-15 15:06:34 root] (main_calib_config3.py 117): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-15 15:07:21 root] (main_calib_config3.py 161): INFO wikitext2 : 5.629901885986328
[2025-03-15 15:07:21 root] (main_calib_config3.py 117): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-15 15:08:32 root] (main_calib_config3.py 161): INFO c4 : 7.190747261047363
