[2025-03-15 10:00:56 root] (main_calib_config3.py 283): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', cache_dir='./cache', output_dir='./log-divide-adaptive-calibration-attnloss/Llama-2-7b-hf-0.45', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=4, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=20, let=True, lwc=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=True, attn_implementation='eager', net=None, act_scales=None, act_shifts=None, quant_map='log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.45.pkl', blocks_pkl='./log-divide/Llama-2-7b-hf-w4a4/Llama-2-7b-hf_blocks.pkl', scale_calibration=True, compensation_calibration=True)
[2025-03-15 10:01:06 root] (main_calib_config3.py 350): INFO === start quantization ===
[2025-03-15 10:01:06 root] (main_calib_config3.py 356): INFO load calibration from ./cache/dataloader_Llama_wikitext2_128.cache
[2025-03-15 10:01:06 root] (abq_llm_calib_config3.py 82): INFO Starting ...
[2025-03-15 10:01:06 root] (abq_llm_calib_config3.py 89): INFO Loaded quant_map from log-divide-adaptive/Llama-2-7b-hf/quant_map_Llama-2-7b-hf_0.45.pkl
[2025-03-15 10:01:06 root] (abq_llm_calib_config3.py 96): INFO Loaded blocks from ./log-divide/Llama-2-7b-hf-w4a4/Llama-2-7b-hf_blocks.pkl: [(0, 1), (1, 2), (2, 3), (3, 6), (6, 9), (9, 11), (11, 14), (14, 17), (17, 20), (20, 23), (23, 26), (26, 29), (29, 30), (30, 31), (31, 32)]
[2025-03-15 10:01:06 root] (abq_llm_calib_config3.py 102): INFO Processed blocks: [[0], [1], [2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12, 13], [14, 15, 16], [17, 18, 19], [20, 21, 22], [23, 24, 25], [26, 27, 28], [29], [30], [31]]
[2025-03-15 10:01:08 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 0 with layers [0] ===
[2025-03-15 10:01:08 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 10:01:38 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 0 loss:0.008308044634759426 norm:0.01283178385347128 max memory_allocated 34633.880859375 
[2025-03-15 10:02:05 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 1 loss:0.004624516237527132 norm:0.007592895999550819 max memory_allocated 34633.880859375 
[2025-03-15 10:02:32 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 2 loss:0.0031226298306137323 norm:0.005292136687785387 max memory_allocated 34633.880859375 
[2025-03-15 10:02:59 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 3 loss:0.00257560214959085 norm:0.004187874495983124 max memory_allocated 34633.880859375 
[2025-03-15 10:03:26 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 4 loss:0.002414178801700473 norm:0.003462668973952532 max memory_allocated 34633.880859375 
[2025-03-15 10:03:53 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 5 loss:0.0023077516816556454 norm:0.0029456315096467733 max memory_allocated 34633.880859375 
[2025-03-15 10:04:20 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 6 loss:0.002263115020468831 norm:0.002637614496052265 max memory_allocated 34633.880859375 
[2025-03-15 10:04:47 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 7 loss:0.0022089642006903887 norm:0.0023967106826603413 max memory_allocated 34633.880859375 
[2025-03-15 10:05:14 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 8 loss:0.0021747350692749023 norm:0.002067222958430648 max memory_allocated 34633.880859375 
[2025-03-15 10:05:41 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 9 loss:0.00211614859290421 norm:0.001800770522095263 max memory_allocated 34633.880859375 
[2025-03-15 10:06:08 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 10 loss:0.0020775131415575743 norm:0.001601334079168737 max memory_allocated 34633.880859375 
[2025-03-15 10:06:35 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 11 loss:0.0020921663381159306 norm:0.0014141459250822663 max memory_allocated 34633.880859375 
[2025-03-15 10:07:02 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 12 loss:0.0020837881602346897 norm:0.0012948352377861738 max memory_allocated 34633.880859375 
[2025-03-15 10:07:29 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 13 loss:0.002077151322737336 norm:0.0011660916497930884 max memory_allocated 34633.880859375 
[2025-03-15 10:07:56 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 14 loss:0.0020744078792631626 norm:0.0011700369650498033 max memory_allocated 34633.880859375 
[2025-03-15 10:08:23 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 15 loss:0.0020017423667013645 norm:0.0010277517139911652 max memory_allocated 34633.880859375 
[2025-03-15 10:08:50 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 16 loss:0.0019806965719908476 norm:0.0009244356770068407 max memory_allocated 34633.880859375 
[2025-03-15 10:09:17 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 17 loss:0.0019748061895370483 norm:0.0008857278735376894 max memory_allocated 34633.880859375 
[2025-03-15 10:09:44 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 18 loss:0.0019506942480802536 norm:0.0008941451669670641 max memory_allocated 34633.880859375 
[2025-03-15 10:10:11 root] (abq_llm_calib_config3.py 464): INFO block 0 (layers [0]) iter 19 loss:0.0019514854066073895 norm:0.000811669509857893 max memory_allocated 34633.880859375 
[2025-03-15 10:10:46 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 1 with layers [1] ===
[2025-03-15 10:10:46 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 10:11:16 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 0 loss:0.02811942994594574 norm:0.024772651493549347 max memory_allocated 35100.7724609375 
[2025-03-15 10:11:43 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 1 loss:0.017022989690303802 norm:0.014217107556760311 max memory_allocated 35100.7724609375 
[2025-03-15 10:12:10 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 2 loss:0.01269824244081974 norm:0.009550893679261208 max memory_allocated 35100.7724609375 
[2025-03-15 10:12:37 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 3 loss:0.011336817406117916 norm:0.012880713678896427 max memory_allocated 35100.7724609375 
[2025-03-15 10:13:04 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 4 loss:0.010511713102459908 norm:0.009888132102787495 max memory_allocated 35100.7724609375 
[2025-03-15 10:13:31 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 5 loss:0.010044561699032784 norm:0.008013379760086536 max memory_allocated 35100.7724609375 
[2025-03-15 10:13:58 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 6 loss:0.010298424400389194 norm:0.008421109989285469 max memory_allocated 35100.7724609375 
[2025-03-15 10:14:25 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 7 loss:0.010494190268218517 norm:0.008478648960590363 max memory_allocated 35100.7724609375 
[2025-03-15 10:14:52 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 8 loss:0.009436463937163353 norm:0.008250758051872253 max memory_allocated 35100.7724609375 
[2025-03-15 10:15:19 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 9 loss:0.009163402020931244 norm:0.007720480673015118 max memory_allocated 35100.7724609375 
[2025-03-15 10:15:46 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 10 loss:0.009019150398671627 norm:0.0072352527640759945 max memory_allocated 35100.7724609375 
[2025-03-15 10:16:13 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 11 loss:0.00953727401793003 norm:0.008603397756814957 max memory_allocated 35100.7724609375 
[2025-03-15 10:16:40 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 12 loss:0.009239481762051582 norm:0.00796583667397499 max memory_allocated 35100.7724609375 
[2025-03-15 10:17:07 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 13 loss:0.009185954928398132 norm:0.008115066215395927 max memory_allocated 35100.7724609375 
[2025-03-15 10:17:34 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 14 loss:0.009045885875821114 norm:0.007353545632213354 max memory_allocated 35100.7724609375 
[2025-03-15 10:18:01 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 15 loss:0.00987364910542965 norm:0.008376100100576878 max memory_allocated 35100.7724609375 
[2025-03-15 10:18:28 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 16 loss:0.009029907174408436 norm:0.007417944725602865 max memory_allocated 35100.7724609375 
[2025-03-15 10:18:55 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 17 loss:0.009116151370108128 norm:0.007183887530118227 max memory_allocated 35100.7724609375 
[2025-03-15 10:19:22 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 18 loss:0.009248221293091774 norm:0.007138457149267197 max memory_allocated 35100.7724609375 
[2025-03-15 10:19:49 root] (abq_llm_calib_config3.py 464): INFO block 1 (layers [1]) iter 19 loss:0.009264810010790825 norm:0.007380855269730091 max memory_allocated 35100.7724609375 
[2025-03-15 10:20:24 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 2 with layers [2] ===
[2025-03-15 10:20:24 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 10:20:54 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 0 loss:0.026827994734048843 norm:0.013365215621888638 max memory_allocated 35101.8349609375 
[2025-03-15 10:21:21 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 1 loss:0.01800558716058731 norm:0.008641108870506287 max memory_allocated 35101.8349609375 
[2025-03-15 10:21:48 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 2 loss:0.014370562508702278 norm:0.0060331434942781925 max memory_allocated 35101.8349609375 
[2025-03-15 10:22:15 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 3 loss:0.013171251863241196 norm:0.004647336434572935 max memory_allocated 35101.8349609375 
[2025-03-15 10:22:42 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 4 loss:0.012499566189944744 norm:0.0038784625940024853 max memory_allocated 35101.8349609375 
[2025-03-15 10:23:09 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 5 loss:0.012021901085972786 norm:0.0033635967411100864 max memory_allocated 35101.8349609375 
[2025-03-15 10:23:36 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 6 loss:0.011785428039729595 norm:0.002908590016886592 max memory_allocated 35101.8349609375 
[2025-03-15 10:24:03 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 7 loss:0.0116339810192585 norm:0.00252906559035182 max memory_allocated 35101.8349609375 
[2025-03-15 10:24:30 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 8 loss:0.011521688662469387 norm:0.0021270557772368193 max memory_allocated 35101.8349609375 
[2025-03-15 10:24:57 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 9 loss:0.011457458138465881 norm:0.0017940693069249392 max memory_allocated 35101.8349609375 
[2025-03-15 10:25:24 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 10 loss:0.01141289435327053 norm:0.0014921356923878193 max memory_allocated 35101.8349609375 
[2025-03-15 10:25:51 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 11 loss:0.011378628201782703 norm:0.0012695851037278771 max memory_allocated 35101.8349609375 
[2025-03-15 10:26:18 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 12 loss:0.011398158967494965 norm:0.001336580840870738 max memory_allocated 35101.8349609375 
[2025-03-15 10:26:45 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 13 loss:0.011402521282434464 norm:0.0012981194304302335 max memory_allocated 35101.8349609375 
[2025-03-15 10:27:12 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 14 loss:0.01138080470263958 norm:0.001215900992974639 max memory_allocated 35101.8349609375 
[2025-03-15 10:27:39 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 15 loss:0.011405627243220806 norm:0.00117480696644634 max memory_allocated 35101.8349609375 
[2025-03-15 10:28:06 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 16 loss:0.011456532403826714 norm:0.0011186596238985658 max memory_allocated 35101.8349609375 
[2025-03-15 10:28:33 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 17 loss:0.01143263466656208 norm:0.0010954538593068719 max memory_allocated 35101.8349609375 
[2025-03-15 10:29:00 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 18 loss:0.011414442211389542 norm:0.001023339107632637 max memory_allocated 35101.8349609375 
[2025-03-15 10:29:27 root] (abq_llm_calib_config3.py 464): INFO block 2 (layers [2]) iter 19 loss:0.011399512179195881 norm:0.0010271951323375106 max memory_allocated 35101.8349609375 
[2025-03-15 10:30:01 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 3 with layers [3, 4, 5] ===
[2025-03-15 10:31:29 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 0 loss:0.06649649143218994 norm:0.004297271370887756 max memory_allocated 47477.6044921875 
[2025-03-15 10:32:49 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 1 loss:0.046519119292497635 norm:0.0012142184423282743 max memory_allocated 47477.6044921875 
[2025-03-15 10:34:09 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 2 loss:0.03597433865070343 norm:0.0006445139879360795 max memory_allocated 47477.6044921875 
[2025-03-15 10:35:29 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 3 loss:0.03132234886288643 norm:0.0004682323196902871 max memory_allocated 47477.6044921875 
[2025-03-15 10:36:49 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 4 loss:0.029013147577643394 norm:0.00037366716424003243 max memory_allocated 47477.6044921875 
[2025-03-15 10:38:09 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 5 loss:0.027520261704921722 norm:0.0003749763418454677 max memory_allocated 47477.6044921875 
[2025-03-15 10:39:30 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 6 loss:0.02661437913775444 norm:0.00038999842945486307 max memory_allocated 47477.6044921875 
[2025-03-15 10:40:50 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 7 loss:0.02600761689245701 norm:0.00034403573954477906 max memory_allocated 47477.6044921875 
[2025-03-15 10:42:10 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 8 loss:0.025627437978982925 norm:0.0003769905015360564 max memory_allocated 47477.6044921875 
[2025-03-15 10:43:30 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 9 loss:0.02536306530237198 norm:0.00042997984564863145 max memory_allocated 47477.6044921875 
[2025-03-15 10:44:50 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 10 loss:0.025326892733573914 norm:0.0004263757437001914 max memory_allocated 47477.6044921875 
[2025-03-15 10:46:10 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 11 loss:0.025161137804389 norm:0.0004488354898057878 max memory_allocated 47477.6044921875 
[2025-03-15 10:47:31 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 12 loss:0.02514979988336563 norm:0.00041618270915932953 max memory_allocated 47477.6044921875 
[2025-03-15 10:48:51 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 13 loss:0.02503916248679161 norm:0.00038237590342760086 max memory_allocated 47477.6044921875 
[2025-03-15 10:50:11 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 14 loss:0.024986863136291504 norm:0.00039398582885041833 max memory_allocated 47477.6044921875 
[2025-03-15 10:51:31 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 15 loss:0.025009779259562492 norm:0.0004259095003362745 max memory_allocated 47477.6044921875 
[2025-03-15 10:52:51 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 16 loss:0.02500215359032154 norm:0.0004319599538575858 max memory_allocated 47477.6044921875 
[2025-03-15 10:54:11 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 17 loss:0.024960558861494064 norm:0.00038876323378644884 max memory_allocated 47477.6044921875 
[2025-03-15 10:55:32 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 18 loss:0.024962829425930977 norm:0.0004063618544023484 max memory_allocated 47477.6044921875 
[2025-03-15 10:56:52 root] (abq_llm_calib_config3.py 464): INFO block 3 (layers [3, 4, 5]) iter 19 loss:0.025026636198163033 norm:0.00042041915003210306 max memory_allocated 47477.6044921875 
[2025-03-15 10:58:37 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 4 with layers [6, 7, 8] ===
[2025-03-15 11:00:04 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 0 loss:0.08330121636390686 norm:0.0018520005978643894 max memory_allocated 47477.7919921875 
[2025-03-15 11:01:24 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 1 loss:0.06192848086357117 norm:0.0007277486729435623 max memory_allocated 47477.7919921875 
[2025-03-15 11:02:44 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 2 loss:0.04869020730257034 norm:0.00045639160089194775 max memory_allocated 47477.7919921875 
[2025-03-15 11:04:05 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 3 loss:0.04278896376490593 norm:0.00038446823600679636 max memory_allocated 47477.7919921875 
[2025-03-15 11:05:25 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 4 loss:0.039808645844459534 norm:0.0003489230293780565 max memory_allocated 47477.7919921875 
[2025-03-15 11:06:45 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 5 loss:0.037970833480358124 norm:0.0003519227902870625 max memory_allocated 47477.7919921875 
[2025-03-15 11:08:05 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 6 loss:0.0367598831653595 norm:0.00033273285953328013 max memory_allocated 47477.7919921875 
[2025-03-15 11:09:25 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 7 loss:0.03609558194875717 norm:0.00033122298191301525 max memory_allocated 47477.7919921875 
[2025-03-15 11:10:45 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 8 loss:0.03560609370470047 norm:0.0003402492147870362 max memory_allocated 47477.7919921875 
[2025-03-15 11:12:05 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 9 loss:0.03520830720663071 norm:0.0003325131256133318 max memory_allocated 47477.7919921875 
[2025-03-15 11:13:25 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 10 loss:0.03491641581058502 norm:0.00034399275318719447 max memory_allocated 47477.7919921875 
[2025-03-15 11:14:45 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 11 loss:0.03481348231434822 norm:0.00035340472823008895 max memory_allocated 47477.7919921875 
[2025-03-15 11:16:05 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 12 loss:0.034697145223617554 norm:0.0003301366523373872 max memory_allocated 47477.7919921875 
[2025-03-15 11:17:25 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 13 loss:0.034473732113838196 norm:0.0003075732965953648 max memory_allocated 47477.7919921875 
[2025-03-15 11:18:46 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 14 loss:0.034374821931123734 norm:0.00031389444484375417 max memory_allocated 47477.7919921875 
[2025-03-15 11:20:06 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 15 loss:0.03432656079530716 norm:0.0003096341388300061 max memory_allocated 47477.7919921875 
[2025-03-15 11:21:26 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 16 loss:0.034227728843688965 norm:0.0003055268316529691 max memory_allocated 47477.7919921875 
[2025-03-15 11:22:46 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 17 loss:0.03421865776181221 norm:0.0003271682362537831 max memory_allocated 47477.7919921875 
[2025-03-15 11:24:06 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 18 loss:0.03418685868382454 norm:0.0003138236643280834 max memory_allocated 47477.7919921875 
[2025-03-15 11:25:26 root] (abq_llm_calib_config3.py 464): INFO block 4 (layers [6, 7, 8]) iter 19 loss:0.03414556384086609 norm:0.000311547628371045 max memory_allocated 47477.7919921875 
[2025-03-15 11:27:10 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 5 with layers [9, 10] ===
[2025-03-15 11:28:08 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 0 loss:0.07335145026445389 norm:0.0019257180392742157 max memory_allocated 47477.7919921875 
[2025-03-15 11:29:01 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 1 loss:0.05712131783366203 norm:0.0009420330170542002 max memory_allocated 47477.7919921875 
[2025-03-15 11:29:55 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 2 loss:0.04562084376811981 norm:0.0004578916705213487 max memory_allocated 47477.7919921875 
[2025-03-15 11:30:48 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 3 loss:0.040923796594142914 norm:0.00029629425262100995 max memory_allocated 47477.7919921875 
[2025-03-15 11:31:42 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 4 loss:0.038767535239458084 norm:0.0002377207129029557 max memory_allocated 47477.7919921875 
[2025-03-15 11:32:35 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 5 loss:0.037698592990636826 norm:0.00022500476916320622 max memory_allocated 47477.7919921875 
[2025-03-15 11:33:29 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 6 loss:0.03700921684503555 norm:0.00021362834377214313 max memory_allocated 47477.7919921875 
[2025-03-15 11:34:23 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 7 loss:0.03669896349310875 norm:0.00021209687110967934 max memory_allocated 47477.7919921875 
[2025-03-15 11:35:16 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 8 loss:0.03641168028116226 norm:0.00020052396575920284 max memory_allocated 47477.7919921875 
[2025-03-15 11:36:10 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 9 loss:0.036247387528419495 norm:0.0001984365953831002 max memory_allocated 47477.7919921875 
[2025-03-15 11:37:03 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 10 loss:0.03612525016069412 norm:0.00019420796888880432 max memory_allocated 47477.7919921875 
[2025-03-15 11:37:57 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 11 loss:0.03609731048345566 norm:0.00020308420062065125 max memory_allocated 47477.7919921875 
[2025-03-15 11:38:50 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 12 loss:0.0360078327357769 norm:0.00021059392020106316 max memory_allocated 47477.7919921875 
[2025-03-15 11:39:44 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 13 loss:0.03593703359365463 norm:0.00020590786880347878 max memory_allocated 47477.7919921875 
[2025-03-15 11:40:37 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 14 loss:0.03585819527506828 norm:0.00020603786106221378 max memory_allocated 47477.7919921875 
[2025-03-15 11:41:31 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 15 loss:0.035750724375247955 norm:0.0002002672990784049 max memory_allocated 47477.7919921875 
[2025-03-15 11:42:24 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 16 loss:0.03572424501180649 norm:0.00020564085571095347 max memory_allocated 47477.7919921875 
[2025-03-15 11:43:18 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 17 loss:0.035675451159477234 norm:0.00020510419562924653 max memory_allocated 47477.7919921875 
[2025-03-15 11:44:11 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 18 loss:0.03561309352517128 norm:0.00020754239812958986 max memory_allocated 47477.7919921875 
[2025-03-15 11:45:05 root] (abq_llm_calib_config3.py 464): INFO block 5 (layers [9, 10]) iter 19 loss:0.03559422865509987 norm:0.00020902196411043406 max memory_allocated 47477.7919921875 
[2025-03-15 11:46:14 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 6 with layers [11, 12, 13] ===
[2025-03-15 11:47:42 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 0 loss:0.08568105101585388 norm:0.0018741593230515718 max memory_allocated 47478.1044921875 
[2025-03-15 11:49:02 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 1 loss:0.06732002645730972 norm:0.0008614615071564913 max memory_allocated 47478.1044921875 
[2025-03-15 11:50:22 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 2 loss:0.054428040981292725 norm:0.000473534018965438 max memory_allocated 47478.1044921875 
[2025-03-15 11:51:42 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 3 loss:0.04855366796255112 norm:0.0003423021116759628 max memory_allocated 47478.1044921875 
[2025-03-15 11:53:02 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 4 loss:0.045588381588459015 norm:0.0002773475425783545 max memory_allocated 47478.1044921875 
[2025-03-15 11:54:22 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 5 loss:0.04376900941133499 norm:0.0002530851634219289 max memory_allocated 47478.1044921875 
[2025-03-15 11:55:43 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 6 loss:0.04271308705210686 norm:0.000240699082496576 max memory_allocated 47478.1044921875 
[2025-03-15 11:57:03 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 7 loss:0.042000073939561844 norm:0.00022976534091867507 max memory_allocated 47478.1044921875 
[2025-03-15 11:58:23 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 8 loss:0.04151669144630432 norm:0.0002364492102060467 max memory_allocated 47478.1044921875 
[2025-03-15 11:59:43 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 9 loss:0.041185446083545685 norm:0.00022244280262384564 max memory_allocated 47478.1044921875 
[2025-03-15 12:01:03 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 10 loss:0.04094294458627701 norm:0.00022542280203197151 max memory_allocated 47478.1044921875 
[2025-03-15 12:02:23 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 11 loss:0.040795158594846725 norm:0.0002163378376280889 max memory_allocated 47478.1044921875 
[2025-03-15 12:03:44 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 12 loss:0.04066479578614235 norm:0.00022007545339874923 max memory_allocated 47478.1044921875 
[2025-03-15 12:05:04 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 13 loss:0.04053564369678497 norm:0.0002241852635052055 max memory_allocated 47478.1044921875 
[2025-03-15 12:06:24 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 14 loss:0.0404638834297657 norm:0.00022287637693807483 max memory_allocated 47478.1044921875 
[2025-03-15 12:07:44 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 15 loss:0.04035906493663788 norm:0.00020734337158501148 max memory_allocated 47478.1044921875 
[2025-03-15 12:09:04 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 16 loss:0.04025748372077942 norm:0.00021290205768309534 max memory_allocated 47478.1044921875 
[2025-03-15 12:10:24 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 17 loss:0.040197886526584625 norm:0.00021590224059764296 max memory_allocated 47478.1044921875 
[2025-03-15 12:11:44 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 18 loss:0.04013163596391678 norm:0.00021068470960017294 max memory_allocated 47478.1044921875 
[2025-03-15 12:13:05 root] (abq_llm_calib_config3.py 464): INFO block 6 (layers [11, 12, 13]) iter 19 loss:0.04006136953830719 norm:0.00021189400285948068 max memory_allocated 47478.1044921875 
[2025-03-15 12:14:49 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 7 with layers [14, 15, 16] ===
[2025-03-15 12:16:16 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 0 loss:0.08145453035831451 norm:0.0013228940078988671 max memory_allocated 47478.2919921875 
[2025-03-15 12:17:36 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 1 loss:0.06512153893709183 norm:0.0005562067963182926 max memory_allocated 47478.2919921875 
[2025-03-15 12:18:56 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 2 loss:0.05320025607943535 norm:0.0003322351258248091 max memory_allocated 47478.2919921875 
[2025-03-15 12:20:16 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 3 loss:0.0482499822974205 norm:0.0002698769385460764 max memory_allocated 47478.2919921875 
[2025-03-15 12:21:37 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 4 loss:0.045715875923633575 norm:0.0002257017622468993 max memory_allocated 47478.2919921875 
[2025-03-15 12:22:57 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 5 loss:0.04412674531340599 norm:0.00020913302432745695 max memory_allocated 47478.2919921875 
[2025-03-15 12:24:17 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 6 loss:0.04311402887105942 norm:0.00020162714645266533 max memory_allocated 47478.2919921875 
[2025-03-15 12:25:37 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 7 loss:0.04244411364197731 norm:0.00019815575797110796 max memory_allocated 47478.2919921875 
[2025-03-15 12:26:57 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 8 loss:0.04196110740303993 norm:0.00019255645747762173 max memory_allocated 47478.2919921875 
[2025-03-15 12:28:18 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 9 loss:0.04161614924669266 norm:0.00018471520161256194 max memory_allocated 47478.2919921875 
[2025-03-15 12:29:38 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 10 loss:0.04133676365017891 norm:0.0001800336322048679 max memory_allocated 47478.2919921875 
[2025-03-15 12:30:58 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 11 loss:0.041098497807979584 norm:0.00017532010679133236 max memory_allocated 47478.2919921875 
[2025-03-15 12:32:18 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 12 loss:0.04090473800897598 norm:0.0001734469406073913 max memory_allocated 47478.2919921875 
[2025-03-15 12:33:38 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 13 loss:0.040768466889858246 norm:0.00016972757293842733 max memory_allocated 47478.2919921875 
[2025-03-15 12:34:58 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 14 loss:0.04064714536070824 norm:0.00016748685447964817 max memory_allocated 47478.2919921875 
[2025-03-15 12:36:19 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 15 loss:0.040544070303440094 norm:0.00016450739349238575 max memory_allocated 47478.2919921875 
[2025-03-15 12:37:39 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 16 loss:0.040461380034685135 norm:0.00016253010835498571 max memory_allocated 47478.2919921875 
[2025-03-15 12:38:59 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 17 loss:0.04040515422821045 norm:0.00016154425975400954 max memory_allocated 47478.2919921875 
[2025-03-15 12:40:20 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 18 loss:0.04033873602747917 norm:0.00015703780809417367 max memory_allocated 47478.2919921875 
[2025-03-15 12:41:40 root] (abq_llm_calib_config3.py 464): INFO block 7 (layers [14, 15, 16]) iter 19 loss:0.04027996584773064 norm:0.00015544697816949338 max memory_allocated 47478.2919921875 
[2025-03-15 12:43:24 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 8 with layers [17, 18, 19] ===
[2025-03-15 12:44:51 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 0 loss:0.08329393714666367 norm:0.0013015347067266703 max memory_allocated 47478.4794921875 
[2025-03-15 12:46:11 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 1 loss:0.06887390464544296 norm:0.0005016752402298152 max memory_allocated 47478.4794921875 
[2025-03-15 12:47:31 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 2 loss:0.05713769048452377 norm:0.00028918441967107356 max memory_allocated 47478.4794921875 
[2025-03-15 12:48:52 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 3 loss:0.05321681872010231 norm:0.00022135136532597244 max memory_allocated 47478.4794921875 
[2025-03-15 12:50:12 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 4 loss:0.05086343362927437 norm:0.00019385560881346464 max memory_allocated 47478.4794921875 
[2025-03-15 12:51:32 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 5 loss:0.04928196221590042 norm:0.00018522182654123753 max memory_allocated 47478.4794921875 
[2025-03-15 12:52:52 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 6 loss:0.048393476754426956 norm:0.00017938873497769237 max memory_allocated 47478.4794921875 
[2025-03-15 12:54:12 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 7 loss:0.047844357788562775 norm:0.0001770687085809186 max memory_allocated 47478.4794921875 
[2025-03-15 12:55:32 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 8 loss:0.047437313944101334 norm:0.00017346847744192928 max memory_allocated 47478.4794921875 
[2025-03-15 12:56:52 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 9 loss:0.04713919386267662 norm:0.00015972489200066775 max memory_allocated 47478.4794921875 
[2025-03-15 12:58:13 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 10 loss:0.04688643664121628 norm:0.0001553109468659386 max memory_allocated 47478.4794921875 
[2025-03-15 12:59:33 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 11 loss:0.04667211323976517 norm:0.00015142327174544334 max memory_allocated 47478.4794921875 
[2025-03-15 13:00:53 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 12 loss:0.04651240259408951 norm:0.00014867368736304343 max memory_allocated 47478.4794921875 
[2025-03-15 13:02:13 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 13 loss:0.04635314643383026 norm:0.00014439100050367415 max memory_allocated 47478.4794921875 
[2025-03-15 13:03:34 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 14 loss:0.046237580478191376 norm:0.00014502329577226192 max memory_allocated 47478.4794921875 
[2025-03-15 13:04:54 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 15 loss:0.04610724002122879 norm:0.00013531437434721738 max memory_allocated 47478.4794921875 
[2025-03-15 13:06:14 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 16 loss:0.04602394998073578 norm:0.0001391297992086038 max memory_allocated 47478.4794921875 
[2025-03-15 13:07:34 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 17 loss:0.045943986624479294 norm:0.00014440044469665736 max memory_allocated 47478.4794921875 
[2025-03-15 13:08:54 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 18 loss:0.045868225395679474 norm:0.00014301638293545693 max memory_allocated 47478.4794921875 
[2025-03-15 13:10:15 root] (abq_llm_calib_config3.py 464): INFO block 8 (layers [17, 18, 19]) iter 19 loss:0.045790936797857285 norm:0.0001366211799904704 max memory_allocated 47478.4794921875 
[2025-03-15 13:11:58 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 9 with layers [20, 21, 22] ===
[2025-03-15 13:13:25 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 0 loss:0.10869313031435013 norm:0.0019277713727205992 max memory_allocated 47478.6669921875 
[2025-03-15 13:14:45 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 1 loss:0.09134368598461151 norm:0.0007554461481049657 max memory_allocated 47478.6669921875 
[2025-03-15 13:16:06 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 2 loss:0.07655912637710571 norm:0.0003845656174235046 max memory_allocated 47478.6669921875 
[2025-03-15 13:17:26 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 3 loss:0.07190993428230286 norm:0.00029891388840042055 max memory_allocated 47478.6669921875 
[2025-03-15 13:18:46 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 4 loss:0.06892079859972 norm:0.0002618547296151519 max memory_allocated 47478.6669921875 
[2025-03-15 13:20:06 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 5 loss:0.06700848042964935 norm:0.00024186364316847175 max memory_allocated 47478.6669921875 
[2025-03-15 13:21:26 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 6 loss:0.06600400060415268 norm:0.00023542952840216458 max memory_allocated 47478.6669921875 
[2025-03-15 13:22:46 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 7 loss:0.0654323622584343 norm:0.00022919540060684085 max memory_allocated 47478.6669921875 
[2025-03-15 13:24:06 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 8 loss:0.06500795483589172 norm:0.00022177849314175546 max memory_allocated 47478.6669921875 
[2025-03-15 13:25:27 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 9 loss:0.06465435028076172 norm:0.00021687819389626384 max memory_allocated 47478.6669921875 
[2025-03-15 13:26:47 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 10 loss:0.06431654840707779 norm:0.000209685749723576 max memory_allocated 47478.6669921875 
[2025-03-15 13:28:07 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 11 loss:0.06405805796384811 norm:0.00020236668933648616 max memory_allocated 47478.6669921875 
[2025-03-15 13:29:27 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 12 loss:0.06381171941757202 norm:0.0001964109396794811 max memory_allocated 47478.6669921875 
[2025-03-15 13:30:47 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 13 loss:0.06359168887138367 norm:0.00019195472123101354 max memory_allocated 47478.6669921875 
[2025-03-15 13:32:07 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 14 loss:0.06339216232299805 norm:0.0001828613894758746 max memory_allocated 47478.6669921875 
[2025-03-15 13:33:28 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 15 loss:0.06322189420461655 norm:0.00018292911408934742 max memory_allocated 47478.6669921875 
[2025-03-15 13:34:48 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 16 loss:0.06305538862943649 norm:0.00017252318502869457 max memory_allocated 47478.6669921875 
[2025-03-15 13:36:08 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 17 loss:0.06291510164737701 norm:0.00017328359535895288 max memory_allocated 47478.6669921875 
[2025-03-15 13:37:28 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 18 loss:0.06278523802757263 norm:0.0001701403089100495 max memory_allocated 47478.6669921875 
[2025-03-15 13:38:48 root] (abq_llm_calib_config3.py 464): INFO block 9 (layers [20, 21, 22]) iter 19 loss:0.0626482143998146 norm:0.00016908932593651116 max memory_allocated 47478.6669921875 
[2025-03-15 13:40:32 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 10 with layers [23, 24, 25] ===
[2025-03-15 13:42:00 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 0 loss:0.15682265162467957 norm:0.004199639894068241 max memory_allocated 47478.8544921875 
[2025-03-15 13:43:20 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 1 loss:0.12907475233078003 norm:0.0009682140662334859 max memory_allocated 47478.8544921875 
[2025-03-15 13:44:40 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 2 loss:0.10814887285232544 norm:0.00046841753646731377 max memory_allocated 47478.8544921875 
[2025-03-15 13:46:00 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 3 loss:0.10162903368473053 norm:0.00034623799729160964 max memory_allocated 47478.8544921875 
[2025-03-15 13:47:20 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 4 loss:0.09781494736671448 norm:0.00032000328064896166 max memory_allocated 47478.8544921875 
[2025-03-15 13:48:40 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 5 loss:0.0959329605102539 norm:0.00029662303859367967 max memory_allocated 47478.8544921875 
[2025-03-15 13:50:00 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 6 loss:0.0950777605175972 norm:0.00027759658405557275 max memory_allocated 47478.8544921875 
[2025-03-15 13:51:20 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 7 loss:0.09444126486778259 norm:0.00027600114117376506 max memory_allocated 47478.8544921875 
[2025-03-15 13:52:41 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 8 loss:0.09397274255752563 norm:0.0002834554179571569 max memory_allocated 47478.8544921875 
[2025-03-15 13:54:01 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 9 loss:0.09350551664829254 norm:0.0002563942689448595 max memory_allocated 47478.8544921875 
[2025-03-15 13:55:21 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 10 loss:0.09312105923891068 norm:0.00025250244652852416 max memory_allocated 47478.8544921875 
[2025-03-15 13:56:41 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 11 loss:0.09276343882083893 norm:0.00024204149667639285 max memory_allocated 47478.8544921875 
[2025-03-15 13:58:01 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 12 loss:0.0924367606639862 norm:0.00024892360670492053 max memory_allocated 47478.8544921875 
[2025-03-15 13:59:21 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 13 loss:0.09212861955165863 norm:0.00022694779909215868 max memory_allocated 47478.8544921875 
[2025-03-15 14:00:42 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 14 loss:0.09189753234386444 norm:0.00022031222761143 max memory_allocated 47478.8544921875 
[2025-03-15 14:02:02 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 15 loss:0.09170135110616684 norm:0.00022347123012878 max memory_allocated 47478.8544921875 
[2025-03-15 14:03:22 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 16 loss:0.09154070913791656 norm:0.0002167350030504167 max memory_allocated 47478.8544921875 
[2025-03-15 14:04:42 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 17 loss:0.09136810898780823 norm:0.00021752619068138301 max memory_allocated 47478.8544921875 
[2025-03-15 14:06:02 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 18 loss:0.091225266456604 norm:0.00020797811157535762 max memory_allocated 47478.8544921875 
[2025-03-15 14:07:23 root] (abq_llm_calib_config3.py 464): INFO block 10 (layers [23, 24, 25]) iter 19 loss:0.09110397100448608 norm:0.00021184739307500422 max memory_allocated 47478.8544921875 
[2025-03-15 14:09:06 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 11 with layers [26, 27, 28] ===
[2025-03-15 14:09:07 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 14:10:36 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 0 loss:0.20774345099925995 norm:0.016519444063305855 max memory_allocated 47479.0419921875 
[2025-03-15 14:11:56 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 1 loss:0.17990058660507202 norm:0.011662585660815239 max memory_allocated 47479.0419921875 
[2025-03-15 14:13:17 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 2 loss:0.15473954379558563 norm:0.0070825256407260895 max memory_allocated 47479.0419921875 
[2025-03-15 14:14:37 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 3 loss:0.14650826156139374 norm:0.005865441635251045 max memory_allocated 47479.0419921875 
[2025-03-15 14:15:57 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 4 loss:0.1426067352294922 norm:0.004845197778195143 max memory_allocated 47479.0419921875 
[2025-03-15 14:17:17 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 5 loss:0.14092667400836945 norm:0.004182938951998949 max memory_allocated 47479.0419921875 
[2025-03-15 14:18:38 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 6 loss:0.13986124098300934 norm:0.0036055906675755978 max memory_allocated 47479.0419921875 
[2025-03-15 14:19:58 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 7 loss:0.13901622593402863 norm:0.003057978581637144 max memory_allocated 47479.0419921875 
[2025-03-15 14:21:18 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 8 loss:0.1383475661277771 norm:0.002747036749497056 max memory_allocated 47479.0419921875 
[2025-03-15 14:22:39 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 9 loss:0.13794024288654327 norm:0.0029067317955195904 max memory_allocated 47479.0419921875 
[2025-03-15 14:23:59 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 10 loss:0.13741740584373474 norm:0.0029068118892610073 max memory_allocated 47479.0419921875 
[2025-03-15 14:25:19 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 11 loss:0.13704189658164978 norm:0.002570376032963395 max memory_allocated 47479.0419921875 
[2025-03-15 14:26:39 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 12 loss:0.13662800192832947 norm:0.0024706567637622356 max memory_allocated 47479.0419921875 
[2025-03-15 14:28:00 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 13 loss:0.13622207939624786 norm:0.002305419184267521 max memory_allocated 47479.0419921875 
[2025-03-15 14:29:20 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 14 loss:0.13593854010105133 norm:0.0022077334579080343 max memory_allocated 47479.0419921875 
[2025-03-15 14:30:40 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 15 loss:0.1356692761182785 norm:0.0022382820025086403 max memory_allocated 47479.0419921875 
[2025-03-15 14:32:01 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 16 loss:0.13545669615268707 norm:0.002197309397161007 max memory_allocated 47479.0419921875 
[2025-03-15 14:33:21 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 17 loss:0.13525104522705078 norm:0.00212865206412971 max memory_allocated 47479.0419921875 
[2025-03-15 14:34:41 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 18 loss:0.13505440950393677 norm:0.002080162987112999 max memory_allocated 47479.0419921875 
[2025-03-15 14:36:01 root] (abq_llm_calib_config3.py 464): INFO block 11 (layers [26, 27, 28]) iter 19 loss:0.1349102407693863 norm:0.0019529700512066483 max memory_allocated 47479.0419921875 
[2025-03-15 14:37:46 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 12 with layers [29] ===
[2025-03-15 14:37:47 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 14:38:16 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 0 loss:0.17408476769924164 norm:0.012292850762605667 max memory_allocated 47479.0419921875 
[2025-03-15 14:38:43 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 1 loss:0.16079983115196228 norm:0.00904599018394947 max memory_allocated 47479.0419921875 
[2025-03-15 14:39:10 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 2 loss:0.15039139986038208 norm:0.005693922750651836 max memory_allocated 47479.0419921875 
[2025-03-15 14:39:37 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 3 loss:0.1472296118736267 norm:0.004754405003041029 max memory_allocated 47479.0419921875 
[2025-03-15 14:40:04 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 4 loss:0.1461397111415863 norm:0.004078258294612169 max memory_allocated 47479.0419921875 
[2025-03-15 14:40:32 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 5 loss:0.1456407755613327 norm:0.003519481746479869 max memory_allocated 47479.0419921875 
[2025-03-15 14:40:59 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 6 loss:0.1452459692955017 norm:0.0029917925130575895 max memory_allocated 47479.0419921875 
[2025-03-15 14:41:26 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 7 loss:0.14492106437683105 norm:0.002562392968684435 max memory_allocated 47479.0419921875 
[2025-03-15 14:41:53 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 8 loss:0.14466838538646698 norm:0.0023806444369256496 max memory_allocated 47479.0419921875 
[2025-03-15 14:42:20 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 9 loss:0.14460289478302002 norm:0.002460015704855323 max memory_allocated 47479.0419921875 
[2025-03-15 14:42:47 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 10 loss:0.14452584087848663 norm:0.0024650562554597855 max memory_allocated 47479.0419921875 
[2025-03-15 14:43:14 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 11 loss:0.14431564509868622 norm:0.0023074615746736526 max memory_allocated 47479.0419921875 
[2025-03-15 14:43:41 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 12 loss:0.14420416951179504 norm:0.0020729315001517534 max memory_allocated 47479.0419921875 
[2025-03-15 14:44:08 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 13 loss:0.14408640563488007 norm:0.002135735470801592 max memory_allocated 47479.0419921875 
[2025-03-15 14:44:35 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 14 loss:0.14395272731781006 norm:0.001974568236619234 max memory_allocated 47479.0419921875 
[2025-03-15 14:45:02 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 15 loss:0.14387522637844086 norm:0.001958762761205435 max memory_allocated 47479.0419921875 
[2025-03-15 14:45:29 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 16 loss:0.14376665651798248 norm:0.001814084011130035 max memory_allocated 47479.0419921875 
[2025-03-15 14:45:57 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 17 loss:0.14368389546871185 norm:0.0017846249975264072 max memory_allocated 47479.0419921875 
[2025-03-15 14:46:24 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 18 loss:0.14366976916790009 norm:0.0018519649747759104 max memory_allocated 47479.0419921875 
[2025-03-15 14:46:51 root] (abq_llm_calib_config3.py 464): INFO block 12 (layers [29]) iter 19 loss:0.14361293613910675 norm:0.0018322443356737494 max memory_allocated 47479.0419921875 
[2025-03-15 14:47:28 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 13 with layers [30] ===
[2025-03-15 14:47:29 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 14:47:58 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 0 loss:0.24793115258216858 norm:0.03007911518216133 max memory_allocated 47479.0419921875 
[2025-03-15 14:48:25 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 1 loss:0.21501530706882477 norm:0.019555745646357536 max memory_allocated 47479.0419921875 
[2025-03-15 14:48:52 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 2 loss:0.19520501792430878 norm:0.012152439914643764 max memory_allocated 47479.0419921875 
[2025-03-15 14:49:20 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 3 loss:0.1901891976594925 norm:0.010888353921473026 max memory_allocated 47479.0419921875 
[2025-03-15 14:49:47 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 4 loss:0.18868426978588104 norm:0.009877659380435944 max memory_allocated 47479.0419921875 
[2025-03-15 14:50:14 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 5 loss:0.18765661120414734 norm:0.009047836996614933 max memory_allocated 47479.0419921875 
[2025-03-15 14:50:41 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 6 loss:0.18735066056251526 norm:0.008731449954211712 max memory_allocated 47479.0419921875 
[2025-03-15 14:51:08 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 7 loss:0.1866389960050583 norm:0.008043816313147545 max memory_allocated 47479.0419921875 
[2025-03-15 14:51:35 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 8 loss:0.1862860471010208 norm:0.00817791186273098 max memory_allocated 47479.0419921875 
[2025-03-15 14:52:02 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 9 loss:0.18613120913505554 norm:0.00761138740926981 max memory_allocated 47479.0419921875 
[2025-03-15 14:52:30 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 10 loss:0.18609657883644104 norm:0.007593488786369562 max memory_allocated 47479.0419921875 
[2025-03-15 14:52:57 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 11 loss:0.18567003309726715 norm:0.00712707219645381 max memory_allocated 47479.0419921875 
[2025-03-15 14:53:24 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 12 loss:0.1854681372642517 norm:0.0069939494132995605 max memory_allocated 47479.0419921875 
[2025-03-15 14:53:51 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 13 loss:0.18547914922237396 norm:0.007178639527410269 max memory_allocated 47479.0419921875 
[2025-03-15 14:54:18 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 14 loss:0.18513712286949158 norm:0.007186961360275745 max memory_allocated 47479.0419921875 
[2025-03-15 14:54:45 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 15 loss:0.18529899418354034 norm:0.007185386959463358 max memory_allocated 47479.0419921875 
[2025-03-15 14:55:12 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 16 loss:0.18491050601005554 norm:0.006640848238021135 max memory_allocated 47479.0419921875 
[2025-03-15 14:55:40 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 17 loss:0.18479256331920624 norm:0.006423566024750471 max memory_allocated 47479.0419921875 
[2025-03-15 14:56:07 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 18 loss:0.18487468361854553 norm:0.006603446323424578 max memory_allocated 47479.0419921875 
[2025-03-15 14:56:34 root] (abq_llm_calib_config3.py 464): INFO block 13 (layers [30]) iter 19 loss:0.18522854149341583 norm:0.006427161395549774 max memory_allocated 47479.0419921875 
[2025-03-15 14:57:11 root] (abq_llm_calib_config3.py 257): INFO === Start quantize block 14 with layers [31] ===
[2025-03-15 14:57:11 root] (abq_llm_calib_config3.py 309): INFO use compensation vector
[2025-03-15 14:57:41 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 0 loss:0.41981443762779236 norm:0.06025601550936699 max memory_allocated 47479.0419921875 
[2025-03-15 14:58:08 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 1 loss:0.36693131923675537 norm:0.04219387471675873 max memory_allocated 47479.0419921875 
[2025-03-15 14:58:35 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 2 loss:0.32773610949516296 norm:0.026664502918720245 max memory_allocated 47479.0419921875 
[2025-03-15 14:59:02 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 3 loss:0.3182423710823059 norm:0.023403307422995567 max memory_allocated 47479.0419921875 
[2025-03-15 14:59:29 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 4 loss:0.3140261471271515 norm:0.02110162004828453 max memory_allocated 47479.0419921875 
[2025-03-15 14:59:56 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 5 loss:0.31163716316223145 norm:0.01896081119775772 max memory_allocated 47479.0419921875 
[2025-03-15 15:00:23 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 6 loss:0.309573769569397 norm:0.016733374446630478 max memory_allocated 47479.0419921875 
[2025-03-15 15:00:50 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 7 loss:0.3080041706562042 norm:0.015508689917623997 max memory_allocated 47479.0419921875 
[2025-03-15 15:01:17 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 8 loss:0.30658236145973206 norm:0.014772236347198486 max memory_allocated 47479.0419921875 
[2025-03-15 15:01:45 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 9 loss:0.30612102150917053 norm:0.014073953032493591 max memory_allocated 47479.0419921875 
[2025-03-15 15:02:12 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 10 loss:0.30512380599975586 norm:0.013634190894663334 max memory_allocated 47479.0419921875 
[2025-03-15 15:02:39 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 11 loss:0.3042964041233063 norm:0.012998362071812153 max memory_allocated 47479.0419921875 
[2025-03-15 15:03:06 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 12 loss:0.3040217459201813 norm:0.01314210519194603 max memory_allocated 47479.0419921875 
[2025-03-15 15:03:33 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 13 loss:0.3034077286720276 norm:0.012656097300350666 max memory_allocated 47479.0419921875 
[2025-03-15 15:04:00 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 14 loss:0.30279627442359924 norm:0.012321618385612965 max memory_allocated 47479.0419921875 
[2025-03-15 15:04:27 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 15 loss:0.3022546172142029 norm:0.011959969066083431 max memory_allocated 47479.0419921875 
[2025-03-15 15:04:54 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 16 loss:0.3018287718296051 norm:0.011969302780926228 max memory_allocated 47479.0419921875 
[2025-03-15 15:05:21 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 17 loss:0.3011413514614105 norm:0.011095358058810234 max memory_allocated 47479.0419921875 
[2025-03-15 15:05:49 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 18 loss:0.3007209300994873 norm:0.011009858921170235 max memory_allocated 47479.0419921875 
[2025-03-15 15:06:16 root] (abq_llm_calib_config3.py 464): INFO block 14 (layers [31]) iter 19 loss:0.30037811398506165 norm:0.010796936228871346 max memory_allocated 47479.0419921875 
[2025-03-15 15:06:54 root] (main_calib_config3.py 379): INFO 18348.061339855194
[2025-03-15 15:06:59 root] (main_calib_config3.py 117): INFO load calibration from ./cache/testloader_Llama_wikitext2_all.cache
[2025-03-15 15:07:46 root] (main_calib_config3.py 161): INFO wikitext2 : 5.623397350311279
[2025-03-15 15:07:46 root] (main_calib_config3.py 117): INFO load calibration from ./cache/testloader_Llama_c4_all.cache
[2025-03-15 15:08:58 root] (main_calib_config3.py 161): INFO c4 : 7.1884565353393555
